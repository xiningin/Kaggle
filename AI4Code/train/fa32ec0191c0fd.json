{"cell_type":{"6ea1323f":"code","4f500e81":"code","6088b33b":"code","6bcf23c6":"code","63cc1fe2":"code","3616470d":"code","7a2ec6f7":"code","57b0eb8e":"code","697758fb":"code","c9baa504":"code","31e65be4":"code","36e1d5f1":"code","dee6ba28":"code","1284aa10":"code","f4ad81b4":"code","fe55e69f":"code","fd7dae42":"markdown","e7b481fc":"markdown","2733c41d":"markdown","c8e7618a":"markdown","9b8d7cbd":"markdown","3f8c4ebf":"markdown","a636c270":"markdown","f82c39b7":"markdown","bd5b0a0b":"markdown","bf7689a0":"markdown","73313ed2":"markdown","a00efd25":"markdown","03b8cb09":"markdown","eb43da1a":"markdown","b66f20b2":"markdown","84c5af05":"markdown"},"source":{"6ea1323f":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras import models, layers, utils\nfrom tensorflow.keras import Sequential\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, MaxPool2D\nfrom keras.datasets import mnist","4f500e81":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","6088b33b":"train = train \/ 255.0\ntest = test \/ 255.0","6bcf23c6":"X_train = train.iloc[0:,1:]\nY_train = train.iloc[0:,0]","63cc1fe2":"X_train = np.array(X_train)\nX_train = X_train.reshape((-1, 28, 28, 1))\n\ntest = np.array(test)\ntest = test.reshape((-1, 28, 28, 1))","3616470d":"Y_train = utils.to_categorical(Y_train, num_classes=10)","7a2ec6f7":"x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size = 0.2, random_state = 2)","57b0eb8e":"def define_model():\n    model = Sequential()\n    model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    \n    model.add(MaxPooling2D((2, 2)))\n    model.add(layers.BatchNormalization())\n    model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n    model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n    \n    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n    model.add(layers.BatchNormalization())\n    model.add(Conv2D(filters=256, kernel_size=(3,3), activation=\"relu\"))\n    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n\n    model.add(Flatten())\n    model.add(layers.BatchNormalization())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n    \n    return model","697758fb":"model = define_model()\nmodel.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])","c9baa504":"model.summary()","31e65be4":"model.fit(train_X, train_Y , epochs=30)","36e1d5f1":"# Use model.evaluate() function to test the model accuracy when you have test labels also\n# accuracy = model.evaluate(x_val , y_val)","dee6ba28":"pred = model.predict(test)","1284aa10":"p = np.argmax(pred, axis=1)\nout = pd.DataFrame({'Label' : p})\nout.index += 1\nout.index.name = \"ImageId\"","f4ad81b4":"out.to_csv(\"mnist_kaggle_submission.csv\", index = True)","fe55e69f":"model.save('LatestModel')","fd7dae42":"# Splitting the dataset for training and testing","e7b481fc":"# Compiling Model","2733c41d":"> Getting training data and labels for training the model","c8e7618a":"# Reading Dataset","9b8d7cbd":"> Using One Hot Encoder to change the categories to number","3f8c4ebf":"# Data Preprocessing","a636c270":"# Evaluation Model on Testing Data","f82c39b7":"> Normalizing the data to minimize the effect of illumination's difference","bd5b0a0b":"#### In Our case we don't have test labels that's why we will use predict() function to get the predictions","bf7689a0":"# 99.96% accuracy was achieved on the test data.","73313ed2":"> Rehaping Dataset to height=28px , width=28px","a00efd25":"# Building Model Architecture","03b8cb09":"# Model Summary","eb43da1a":"# Model Training","b66f20b2":"### Saving Predictions to csv ","84c5af05":"# Importing Libraries"}}