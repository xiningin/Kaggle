{"cell_type":{"3654eca5":"code","9aeebdb7":"code","5c0dfa18":"code","d7566847":"code","43b66bb0":"code","b873b625":"code","8390ef22":"code","c6f1cc03":"code","b0ffd0b8":"code","dab5ea77":"code","97497243":"code","14f25067":"code","a4556200":"code","e90ae49e":"code","d127447d":"code","d910b16d":"code","cc815f1b":"code","d975fd47":"code","dada2e89":"code","30f1ac72":"code","40ee23f5":"code","4d01dd03":"code","86557373":"code","968b2a24":"code","ea02a24b":"code","64658cbb":"code","ae263257":"code","5278ece3":"markdown","27c9a6ce":"markdown","8dd564cd":"markdown","fe6c11a0":"markdown","400bb047":"markdown","10f76601":"markdown","2e458b61":"markdown","d6be7201":"markdown","2f0f0e52":"markdown","64faf7c8":"markdown","7ca303e6":"markdown","bf062a6f":"markdown"},"source":{"3654eca5":"import pandas as pd\nimport numpy as np\nimport random\nimport os\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n\nimport lightgbm as lgb\nimport catboost as ctb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\n\nimport graphviz\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter('ignore')","9aeebdb7":"TARGET = 'Survived'\n\nDEBUG = False #True #\n\nif DEBUG:\n    N_ESTIMATORS = 1\n    N_SPLITS = 2\n    SEED = 2021\n    EARLY_STOPPING_ROUNDS = 1\n    VERBOSE = 100\n    N_ITERS = 2\nelse:\n    N_ESTIMATORS = 1000\n    N_SPLITS = 10\n    SEED = 990121\n    EARLY_STOPPING_ROUNDS = 100\n    VERBOSE = 100\n    N_ITERS = 30","5c0dfa18":"def set_seed(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    \nset_seed(SEED)","d7566847":"train_df = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest_df = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')\nsubmission = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/sample_submission.csv')\ntest_df[TARGET] = pd.read_csv(\"..\/input\/autowoe81577\/AutoWoE_submission_combo.csv\")[TARGET]\n\nall_df = pd.concat([train_df, test_df]).reset_index(drop=True)","43b66bb0":"# Age fillna with mean age for each class\nall_df['Age'] = all_df['Age'].fillna(all_df['Age'].mean())\n\n# Cabin, fillna with 'X' and take first letter\nall_df['Cabin'] = all_df['Cabin'].fillna('X').map(lambda x: x[0].strip())\n\n# Ticket, fillna with 'X', split string and take first split \nall_df['Ticket'] = all_df['Ticket'].fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n\n# Fare, fillna with mean value\nfare_map = all_df[['Fare', 'Pclass']].dropna().groupby('Pclass').median().to_dict()\nall_df['Fare'] = all_df['Fare'].fillna(all_df['Pclass'].map(fare_map['Fare']))\nall_df['Fare'] = np.log1p(all_df['Fare'])\n\n# Embarked, fillna with 'X' value\nall_df['Embarked'] = all_df['Embarked'].fillna('X')\n\n# Name, take only surnames\nall_df['Name'] = all_df['Name'].map(lambda x: x.split(',')[0])","b873b625":"label_cols = ['Name', 'Ticket', 'Sex']\nonehot_cols = ['Cabin', 'Embarked']\nnumerical_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']","8390ef22":"def label_encoder(c):\n    le = LabelEncoder()\n    return le.fit_transform(c)\n\nscaler = StandardScaler()\n\nonehot_encoded_df = pd.get_dummies(all_df[onehot_cols])\nlabel_encoded_df = all_df[label_cols].apply(label_encoder)\nnumerical_df = pd.DataFrame(scaler.fit_transform(all_df[numerical_cols]), columns=numerical_cols)\ntarget_df = all_df[TARGET]\n\nall_df = pd.concat([numerical_df, label_encoded_df, onehot_encoded_df, target_df], axis=1)","c6f1cc03":"def apply_noise(df, p=.75):\n#     return df\n    should_not_swap = np.random.binomial(1, p, df.shape)\n    corrupted_df = df.where(should_not_swap == 1, np.random.permutation(df))\n    return corrupted_df","b0ffd0b8":"params = {\n    'metric': 'binary_logloss',\n    'n_estimators': N_ESTIMATORS,\n    'objective': 'binary',\n    'random_state': SEED,\n    'learning_rate': 0.01,\n    'min_child_samples': 150,\n    'reg_alpha': 3e-5,\n    'reg_lambda': 9e-2,\n    'num_leaves': 20,\n    'max_depth': 16,\n    'colsample_bytree': 0.8,\n    'subsample': 0.8,\n    'subsample_freq': 2,\n    'max_bin': 240,\n}","dab5ea77":"lgb_full_preds = []\nfor SEED in range(N_ITERS):\n    lgb_oof = np.zeros(train_df.shape[0])\n    lgb_preds = np.zeros(test_df.shape[0])\n    feature_importances = pd.DataFrame()\n\n    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n\n    for fold, (train_idx, valid_idx) in enumerate(skf.split(all_df, all_df[TARGET])):\n        print(f\"===== FOLD {fold} =====\")\n        oof_idx = np.array([idx for idx in valid_idx if idx < train_df.shape[0]])\n        preds_idx = np.array([idx for idx in valid_idx if idx >= train_df.shape[0]])\n\n        X_train, y_train = all_df.iloc[train_idx].drop(TARGET, axis=1), all_df.iloc[train_idx][TARGET]\n        X_train = apply_noise(X_train)\n        X_valid, y_valid = all_df.iloc[oof_idx].drop(TARGET, axis=1), all_df.iloc[oof_idx][TARGET]\n        X_test = all_df.iloc[preds_idx].drop(TARGET, axis=1)\n\n        pre_model = lgb.LGBMRegressor(**params)\n        pre_model.fit(\n            X_train, y_train,\n            eval_set=[(X_train, y_train),(X_valid, y_valid)],\n            early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n            verbose=VERBOSE\n        )\n\n        params2 = params.copy()\n        params2['learning_rate'] = params['learning_rate'] * 0.1\n        model = lgb.LGBMRegressor(**params2)\n        model.fit(\n            X_train, y_train,\n            eval_set=[(X_train, y_train),(X_valid, y_valid)],\n            early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n            verbose=VERBOSE,\n            init_model=pre_model\n        )\n\n        fi_tmp = pd.DataFrame()\n        fi_tmp[\"feature\"] = model.feature_name_\n        fi_tmp[\"importance\"] = model.feature_importances_\n        fi_tmp[\"fold\"] = fold\n        fi_tmp[\"seed\"] = SEED\n        feature_importances = feature_importances.append(fi_tmp)\n\n        lgb_oof[oof_idx] = model.predict(X_valid)\n        lgb_preds[preds_idx-train_df.shape[0]] = model.predict(X_test)\n\n        acc_score = accuracy_score(y_valid, np.where(lgb_oof[oof_idx]>0.5, 1, 0))\n        print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")\n\n    acc_score = accuracy_score(all_df[:train_df.shape[0]][TARGET], np.where(lgb_oof>0.5, 1, 0))\n    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\")\n    lgb_full_preds.append(lgb_preds)\nlgb_full_preds = np.stack(lgb_full_preds, axis=1)","97497243":"# just to get ideas to improve\norder = list(feature_importances.groupby(\"feature\").mean().sort_values(\"importance\", ascending=False).index)\nplt.figure(figsize=(10, 10))\nsns.barplot(x=\"importance\", y=\"feature\", data=feature_importances, order=order)\nplt.title(\"{} importance\".format(\"LGBMRegressor\"))\nplt.tight_layout()","14f25067":"params = {\n    'bootstrap_type': 'Poisson',\n    'loss_function': 'Logloss',\n    'eval_metric': 'Logloss',\n    'random_seed': SEED,\n    'task_type': 'GPU',\n    'max_depth': 8,\n    'learning_rate': 0.01,\n    'n_estimators': N_ESTIMATORS,\n    'max_bin': 280,\n    'min_data_in_leaf': 64,\n    'l2_leaf_reg': 0.01,\n    'subsample': 0.8\n}","a4556200":"ctb_full_preds = []\nfor SEED in range(N_ITERS):\n    ctb_oof = np.zeros(train_df.shape[0])\n    ctb_preds = np.zeros(test_df.shape[0])\n    feature_importances = pd.DataFrame()\n\n    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n\n    for fold, (train_idx, valid_idx) in enumerate(skf.split(all_df, all_df[TARGET])):\n        print(f\"===== FOLD {fold} =====\")\n        oof_idx = np.array([idx for idx in valid_idx if idx < train_df.shape[0]])\n        preds_idx = np.array([idx for idx in valid_idx if idx >= train_df.shape[0]])\n\n        X_train, y_train = all_df.iloc[train_idx].drop(TARGET, axis=1), all_df.iloc[train_idx][TARGET]\n        X_train = apply_noise(X_train)\n        X_valid, y_valid = all_df.iloc[oof_idx].drop(TARGET, axis=1), all_df.iloc[oof_idx][TARGET]\n        X_test = all_df.iloc[preds_idx].drop(TARGET, axis=1)\n\n        model = ctb.CatBoostClassifier(**params)\n        model.fit(X_train, y_train,\n                  eval_set=[(X_valid, y_valid)],\n                  use_best_model=True,\n                  early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n                  verbose=VERBOSE\n                  )\n\n        fi_tmp = pd.DataFrame()\n        fi_tmp[\"feature\"] = X_test.columns.to_list()\n        fi_tmp[\"importance\"] = model.get_feature_importance()\n        fi_tmp[\"fold\"] = fold\n        fi_tmp[\"seed\"] = SEED\n        feature_importances = feature_importances.append(fi_tmp)\n\n        ctb_oof[oof_idx] = model.predict(X_valid)\n        ctb_preds[preds_idx-train_df.shape[0]] = model.predict(X_test)\n\n        acc_score = accuracy_score(y_valid, np.where(ctb_oof[oof_idx]>0.5, 1, 0))\n        print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")\n\n    acc_score = accuracy_score(all_df[:train_df.shape[0]][TARGET], np.where(ctb_oof>0.5, 1, 0))\n    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\")\n    ctb_full_preds.append(ctb_preds)\nctb_full_preds = np.stack(ctb_full_preds, axis=1)","e90ae49e":"# just to get ideas to improve\norder = list(feature_importances.groupby(\"feature\").mean().sort_values(\"importance\", ascending=False).index)\nplt.figure(figsize=(10, 10))\nsns.barplot(x=\"importance\", y=\"feature\", data=feature_importances, order=order)\nplt.title(\"{} importance\".format(\"CatBoostClassifier\"))\nplt.tight_layout()","d127447d":"# Tuning the DecisionTreeClassifier by the GridSearchCV\nparameters = {\n    'max_depth': np.arange(2, 5, dtype=int),\n    'min_samples_leaf':  np.arange(2, 5, dtype=int)\n}\n\nclassifier = DecisionTreeClassifier(random_state=2021)\n\nmodel = GridSearchCV(\n    estimator=classifier,\n    param_grid=parameters,\n    scoring='accuracy',\n    cv=10,\n    n_jobs=-1)\nmodel.fit(X_train, y_train)\n\nbest_parameters = model.best_params_\nprint(best_parameters)","d910b16d":"dtm_full_preds = []\nfor SEED in range(N_ITERS):\n    dtm_oof = np.zeros(train_df.shape[0])\n    dtm_preds = np.zeros(test_df.shape[0])\n    feature_importances = pd.DataFrame()\n\n    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n\n    for fold, (train_idx, valid_idx) in enumerate(skf.split(all_df, all_df[TARGET])):\n        print(f\"===== FOLD {fold} =====\")\n        oof_idx = np.array([idx for idx in valid_idx if idx < train_df.shape[0]])\n        preds_idx = np.array([idx for idx in valid_idx if idx >= train_df.shape[0]])\n\n        X_train, y_train = all_df.iloc[train_idx].drop(TARGET, axis=1), all_df.iloc[train_idx][TARGET]\n        X_train = apply_noise(X_train)\n        X_valid, y_valid = all_df.iloc[oof_idx].drop(TARGET, axis=1), all_df.iloc[oof_idx][TARGET]\n        X_test = all_df.iloc[preds_idx].drop(TARGET, axis=1)\n\n        model = DecisionTreeClassifier(\n            max_depth=best_parameters['max_depth'],\n            min_samples_leaf=best_parameters['min_samples_leaf'],\n            random_state=SEED\n        )\n        model.fit(X_train, y_train)\n\n        dtm_oof[oof_idx] = model.predict(X_valid)\n        dtm_preds[preds_idx-train_df.shape[0]] = model.predict(X_test)\n\n        acc_score = accuracy_score(y_valid, np.where(dtm_oof[oof_idx]>0.5, 1, 0))\n        print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")\n\n    acc_score = accuracy_score(all_df[:train_df.shape[0]][TARGET], np.where(dtm_oof>0.5, 1, 0))\n    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\")\n    dtm_full_preds.append(dtm_preds)\ndtm_full_preds = np.stack(dtm_full_preds, axis=1)","cc815f1b":"# plot tree\ndot_data = export_graphviz(\n    model,\n    out_file=None,\n    feature_names=X_train.columns,\n    class_names=['0', '1'],\n    filled=True,\n    rounded=False,\n    special_characters=True,\n    precision=3\n)\ngraph = graphviz.Source(dot_data)\ngraph ","d975fd47":"submission[['submit_lgb_{}'.format(i) for i in range(N_ITERS)]] = np.where(lgb_full_preds>0.5, 1, 0)\nsubmission[['submit_ctb_{}'.format(i) for i in range(N_ITERS)]] = np.where(ctb_full_preds>0.5, 1, 0)\nsubmission[['submit_dtm_{}'.format(i) for i in range(N_ITERS)]] = np.where(dtm_full_preds>0.5, 1, 0)","dada2e89":"submission.head()","30f1ac72":"submission[[col for col in submission.columns if col.startswith('submit_')]].sum(axis = 1).value_counts()","40ee23f5":"submission[TARGET] = (submission[[col for col in submission.columns if col.startswith('submit_')]].sum(axis=1) >= 1.5*N_ITERS).astype(int)\nsubmission.drop([col for col in submission.columns if col.startswith('submit_')], axis=1, inplace=True)","4d01dd03":"submission['submit_1'] = submission[TARGET].copy()\nsubmission['submit_2'] = pd.read_csv(\"..\/input\/tps-apr-2021-label\/dae.csv\")[TARGET]\nsubmission['submit_3'] = pd.read_csv(\"..\/input\/autowoe81577\/AutoWoE_submission_combo.csv\")[TARGET]","86557373":"submission[[col for col in submission.columns if col.startswith('submit_')]].sum(axis = 1).value_counts()","968b2a24":"submission[TARGET] = (submission[[col for col in submission.columns if col.startswith('submit_')]].sum(axis=1) >= 2).astype(int)","ea02a24b":"submission[['PassengerId', TARGET]].to_csv(\"voting_submission.csv\", index = False)","64658cbb":"submission[TARGET].hist()","ae263257":"submission.head()","5278ece3":"# Filling missing values","27c9a6ce":"# Libraries","8dd564cd":"# DecisionTreeModel","fe6c11a0":"# Ensemble","400bb047":"### Feature importance","10f76601":"# Load data","2e458b61":"# Encoding","d6be7201":"### Plot tree","2f0f0e52":"# CatBoost","64faf7c8":"# Ensemble\/Submission","7ca303e6":"### Feature importance","bf062a6f":"# LightGBM"}}