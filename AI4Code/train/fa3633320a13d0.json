{"cell_type":{"f06db0ea":"code","5a56bf83":"code","53075db0":"code","2b1c6ef9":"code","61986b0e":"code","fd4ce1c5":"code","e603f05f":"code","9a42defe":"code","b41cd6c3":"code","eba82af0":"code","01c8c91e":"code","c3a97a16":"code","d2f18d3a":"markdown"},"source":{"f06db0ea":"import numpy as np # linear algebra\n\nimport os\nfrom glob import glob\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5a56bf83":"name_train = sorted(glob(\"\/kaggle\/input\/cerfacs\/TRAIN\/TRAIN\/*\"))\nname_test = sorted(glob(\"\/kaggle\/input\/cerfacs\/TEST\/TEST\/*\"))\n\ny_train = np.load(\"\/kaggle\/input\/cerfacs\/y_train.npy\")\n\nprint (len(name_train), len(name_test))","53075db0":"print (name_train[:3])","2b1c6ef9":"import matplotlib.pyplot as plt\nfrom PIL import Image\n\nnum = np.random.randint(len(name_train))\nplt.figure(figsize=(6, 6))\nplt.title(\"Image {} : {}\".format(num, y_train[num]))\nplt.imshow(Image.open(name_train[num]));","61986b0e":"X_train = np.array([np.array(Image.open(jpg)) for jpg in name_train])\nX_test = np.array([np.array(Image.open(jpg)) for jpg in name_test])\ny_train = np.load(\"\/kaggle\/input\/cerfacs\/y_train.npy\")\n\nprint (X_train.shape, X_test.shape)\nprint (y_train.shape)","fd4ce1c5":"print (y_train.shape)","e603f05f":"from sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder()\ny_train = encoder.fit_transform(y_train.reshape(-1, 1)).toarray()\n\nX_train, X_valid = X_train[:15000], X_train[15000:]\ny_train, y_valid = y_train[:15000], y_train[15000:]","9a42defe":"X_train, X_valid, X_test = X_train\/255, X_valid\/255, X_test\/255","b41cd6c3":"import keras \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(64, 64, 3)))\nmodel.add(Conv2D(32, kernel_size = (3, 3), activation='relu'))\nmodel.add(Conv2D(32, kernel_size = (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(32, kernel_size = (3, 3), activation='relu'))\nmodel.add(Conv2D(32, kernel_size = (3, 3), activation='relu'))\nmodel.add(Conv2D(32, kernel_size = (3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(10, activation = 'softmax'))","eba82af0":"model.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.SGD(),\n              metrics=['accuracy'])","01c8c91e":"history = model.fit(X_train, y_train, batch_size = 32, \n                   validation_data=(X_valid, y_valid), epochs=30)","c3a97a16":"loss, metrics = model.evaluate(X_valid, y_valid)\n\nprint (metrics)","d2f18d3a":"Our dataset is divided in a training and a test set containing respectively 20 000 and 7000 images.  \nLet's visualise some of them :"}}