{"cell_type":{"5328fe93":"code","5e110166":"code","f4aa84fb":"code","77d100c6":"code","835f51f1":"code","25d56648":"code","2a28bf18":"code","3a6a8e30":"code","8ea74c0a":"code","ad3a3f4d":"code","1a51f38f":"code","8eac73d5":"code","73981da8":"code","a6f76dc1":"code","5e5a57ff":"code","a1cfe322":"code","8f128601":"code","82425686":"code","a499af31":"code","905bdc5a":"code","bae88752":"code","0739960b":"code","344ca198":"code","44fd06f3":"code","99389f21":"code","00cc2e7b":"code","b4128d98":"code","b552c3f9":"code","e7d587cf":"code","95534656":"code","0be726a9":"code","cfd50b59":"code","b99be83a":"code","45b962db":"code","8febdb78":"code","5ac558e8":"code","f83d0a96":"code","961b4b14":"code","795aa2d3":"code","cafad80b":"code","942670e8":"code","de85f6f4":"code","9fefb813":"code","1542ca7e":"code","6f1f8ea8":"code","7d8b7aac":"code","e6f4b458":"code","0be4c19f":"code","bfbd5b12":"code","bc0f3d56":"code","74c41040":"code","097067fd":"code","767ab734":"code","27d98baa":"code","8b40e2f6":"code","ea8c1b2c":"code","378b351d":"code","02051dcf":"code","15d6ed59":"code","f3dd6392":"code","ee42b215":"code","e29c7855":"code","c74a77fa":"code","aa81eafe":"code","b5c6da4b":"code","00423d91":"code","8ecec6c3":"code","7f862b10":"code","3aaf224c":"code","1ee3c681":"code","fdc764c7":"code","f0a4d189":"code","c8e63ae6":"code","e1784268":"code","82f6496c":"code","3cef0d2d":"code","6a65923a":"code","2a9258e6":"code","f1fcead6":"code","c139d568":"code","edec3b31":"code","5f675778":"code","e0d9c26c":"code","61d3b817":"code","08d0f8ab":"code","1d3c5a6f":"code","e13e5d47":"code","ab6202d9":"code","6c71897e":"code","36dffd52":"code","8c8feeb4":"code","973ec41c":"code","f8377f88":"code","b3eddc38":"code","4c67dfb9":"code","d4109a13":"markdown","fb6e2c9e":"markdown","0baf062a":"markdown","c0b01cb5":"markdown","5d757ffa":"markdown","49a45074":"markdown","2f0e0561":"markdown","274bd7e7":"markdown","229209dd":"markdown","2fe63b75":"markdown","3b8be541":"markdown","16833c41":"markdown","1bb894a3":"markdown","f0d9df5f":"markdown","f8edbca0":"markdown","a9fb6959":"markdown","8d96115d":"markdown","4b1d89f5":"markdown","419d8882":"markdown","2c703b56":"markdown","d2f46a7f":"markdown","d9628b01":"markdown","d0e79a73":"markdown","b5bae900":"markdown","6310a353":"markdown","6c54b237":"markdown","52c0fe9f":"markdown","0fe6b02f":"markdown","1100c24d":"markdown","d22a472b":"markdown","41c1375c":"markdown","e752d81e":"markdown","5f58667a":"markdown","653bccac":"markdown","fcf7dcaf":"markdown","68c865d1":"markdown","e41e3fc9":"markdown"},"source":{"5328fe93":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5e110166":"import os\nimport numpy as np\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestRegressor\nimport matplotlib as mpl\nfrom pandas.plotting import scatter_matrix\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\npd.set_option(\"display.max_columns\", 100)\npd.set_option(\"display.max_rows\", 100)\n\nos.mkdir(\"images\")\ndef save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n    IMAGES_PATH = os.path.join(\".\",\"images\")\n    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n    print(\"Saving figure\", fig_id)\n    if tight_layout:\n        plt.tight_layout()\n    plt.savefig(path, format=fig_extension, dpi=resolution)","f4aa84fb":"home_data = pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/train.csv\")\n    ","77d100c6":"home_data.info()","835f51f1":"home_data.head(10)","25d56648":"home_data.tail(10)","2a28bf18":"home_data.describe()","3a6a8e30":"#type(cat_features)\ncat_features = home_data.select_dtypes(exclude=['int64', 'float64']).columns\ncat_features = list(cat_features)\ncat_features.extend(['Id','MSSubClass', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'MoSold', 'YrSold'])\ncat_features","8ea74c0a":"print(len(cat_features))","ad3a3f4d":"s = home_data[cat_features].isnull().sum()\ncat_missing_values = s[s > 0]\ncat_missing_values","1a51f38f":"home_data_nan = home_data[home_data.isnull().any(axis=1)]","8eac73d5":"home_data_nan['MasVnrType'].isnull()","73981da8":"home_data.isnull().any(axis=1)","a6f76dc1":"# MasVnrType: Masonry veneer type\nmsnr_data_nan = home_data_nan[home_data_nan['MasVnrType'].isnull()]\nmsnr_data_nan.info()","5e5a57ff":"home_data.head(10)","a1cfe322":"home_data[home_data['MasVnrType'] == \"None\"]","8f128601":"home_data[home_data['MasVnrType'].isnull()].equals(home_data[home_data['MasVnrArea'].isnull()])","82425686":"home_data[home_data['MasVnrType'] == \"None\"].equals(home_data[home_data['MasVnrArea'] == 0.0])","a499af31":"print(home_data[home_data['MasVnrType'] == \"None\"].shape,home_data[home_data['MasVnrArea'] == 0.0].shape)","905bdc5a":"masvnrtp = home_data[home_data['MasVnrType'] == \"None\"]\nmasvnrar = home_data[home_data['MasVnrArea'] == 0.0]\npd.concat([masvnrtp, masvnrar]).drop_duplicates(keep=False)","bae88752":"garage_data = home_data_nan.filter(regex=(\"Garage.*\"))\ngarage_data_nan = home_data_nan[garage_data.isnull().any(axis=1)]\ngarage_data_nan","0739960b":"home_data['GarageYrBlt'].dtype","344ca198":"fireplaces_data = home_data_nan.filter(regex=(\"Fireplace.*\"))\nfireplaces_data_nan = home_data_nan[fireplaces_data.isnull().any(axis=1)]\nfireplaces_data_nan","44fd06f3":"alley_data = home_data_nan.filter(regex=(\"Alley.*\"))\nalley_data_nan = home_data_nan[alley_data.isnull().any(axis=1)]\nalley_data_nan.info()","99389f21":"alley_data_nan.describe()","00cc2e7b":"alley_data_nan[cat_features].head(100)","b4128d98":"# pool_data = home_data_nan.filter(regex=(\"Pool.*\"))\npool_data_nan = home_data_nan[home_data_nan[\"PoolQC\"].notnull()]\npool_data_nan","b552c3f9":"home_data_nan[home_data_nan[\"PoolArea\"] > 0]","e7d587cf":"bsmt_data = home_data_nan.filter(regex=(\".*Bsmt.*\"))\nbsmt_data_nan = home_data_nan[bsmt_data.isnull().any(axis=1)]\nbsmt_data_nan.head()","95534656":"fence_data = home_data_nan.filter(regex=(\".*Fence.*\"))\nfence_data_nan = home_data_nan[fence_data.isnull().any(axis=1)]\nfence_data_nan.tail(100)","0be726a9":"elec_data_nan = home_data_nan[home_data_nan['Electrical'].isnull()]\nelec_data_nan","cfd50b59":"int_float = home_data.select_dtypes(include=['int64', 'float64']).columns\nnum_features = [col_name for col_name in int_float if col_name not in cat_features]","b99be83a":"print(num_features)\nprint(len(num_features))","45b962db":"home_data[num_features].describe()","8febdb78":"num_missing_values = ['LotFrontage', 'MasVnrArea']\nhome_data[num_missing_values].isnull().sum()","5ac558e8":"home_data.hist(bins=50, figsize=(20,15))\nsave_fig(\"attribute_histogram_plots\")\nplt.show()","f83d0a96":"# correlation between features\ncorr_matrix = home_data.corr()","961b4b14":"corr_matrix[\"SalePrice\"].sort_values(ascending=True)","795aa2d3":"most_corr_attribs = [feature for feature in corr_matrix['SalePrice'].keys() if corr_matrix['SalePrice'].get(key=feature) > 0.2]","cafad80b":"most_corr_attribs","942670e8":"for feature in most_corr_attribs:\n    home_data.plot(kind='scatter', x=feature, y='SalePrice', alpha=0.1)\n    save_fig(feature+\"_vs_SalePrice_scatterplot\")","de85f6f4":"target = 'SalePrice'\nfeatures = home_data.drop(columns=['SalePrice'], inplace=False).columns\nX = home_data[features].copy()\ny = np.log(home_data[target].copy())","9fefb813":"y.rename('SalePrice_log')","1542ca7e":"X.head()","6f1f8ea8":"X.shape","7d8b7aac":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.base import BaseEstimator, TransformerMixin","e6f4b458":"none_feat = ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2', 'GarageType', 'GarageFinish', 'GarageQual','GarageCond', 'FireplaceQu', 'PoolQC']\ndrop = [c for c in cat_features if X[c].isnull().sum()\/X.shape[0] >= 0.8] # drop column if t contains more than 80% missing data\ndrop.extend(['Id', 'GarageYrBlt'])\nnone = [c for c in none_feat if c not in drop]\nmost_freq = [c for c in cat_features if (c not in (none + drop) and X[c].isnull().sum() > 0)]","0be4c19f":"print(\"none \", none)\nprint(\"drop \", drop)\nprint(\"most freq \", most_freq)","bfbd5b12":"STRATEGY_FEATURES = {\"None\": none, \"most_frequent\": most_freq, \"drop\": drop}","bc0f3d56":"# When used, this code raises a warning and an error can you guess what is it?\nclass CatDataImputer1(BaseEstimator, TransformerMixin):\n    def __init__(self, strategy_features=STRATEGY_FEATURES): # no *args or **kwargs\n        '''\n            strategy_features is a dict where the key is the strategy used to handle the missing categorical data, \n            and the value is a list of feature names on which to apply that strategy.\n            strategy can be:\n                * \"None\": the NaN is replaced with string value \"None\".\n                * \"most_frequent\": the NaN is replaced with the most frequent value for that feature.\n                * \"drop\": the feature is dropped from the dataframe entirely.\n        '''\n        self.strategy_features = strategy_features\n    def fit(self, X, y=None):\n        return self  # nothing else to do\n    def transform(self, X, y=None):\n        for strategy in self.strategy_features.keys():\n            if strategy == \"None\":\n                X[self.strategy_features[strategy]].fillna(\"None\", inplace=True)\n            elif strategy == \"most_frequent\":\n                X[self.strategy_features[strategy]].fillna(X[self.strategy_features[strategy]].mode().iloc[0], inplace=True)\n            elif strategy == \"drop\":\n                X.drop(columns=self.strategy_features[strategy], inplace=True)\n            else: raise Exception(\"invalid strategy\")\n        return X\n\n","74c41040":"cat_pipeline1 = Pipeline([\n    ('cat_data_imputer',CatDataImputer1()),\n    ('1hot_encoder', OneHotEncoder(sparse=False))\n])","097067fd":"cat_data_imputer = CatDataImputer1()\ncat_data_nonan = cat_data_imputer.fit_transform(X[cat_features])","767ab734":"s1 = cat_data_nonan[[c for c in cat_features if c not in ['Id','MiscFeature', 'Fence', 'PoolQC', 'GarageYrBlt', 'Alley']]].isnull().sum()\ncat_missing_val = s1[s1 > 0]\ncat_missing_val","27d98baa":"cat_home_data = cat_pipeline1.fit_transform(X[cat_features])","8b40e2f6":"OneHotEncoder?","ea8c1b2c":"class CatDataImputer(BaseEstimator, TransformerMixin):\n    def __init__(self, strategy_features=STRATEGY_FEATURES): # no *args or **kwargs\n        '''\n            strategy_features is a dict where the key is the strategy used to handle the missing categorical data, \n            and the value is a list of feature names on which to apply that strategy.\n            strategy can be:\n                * \"None\": the NaN is replaced with string value \"None\".\n                * \"most_frequent\": the NaN is replaced with the most frequent value for that feature.\n                * \"drop\": the feature is dropped from the dataframe entirely.\n        '''\n        self.strategy_features = strategy_features\n    def fit(self, X, y=None):\n        return self  # nothing else to do\n    def transform(self, X, y=None):\n        for strategy in self.strategy_features.keys():\n            if strategy == \"None\":\n                replaced_with_none = X[self.strategy_features[strategy]].fillna(\"None\", inplace=False)\n                X.drop(columns=self.strategy_features[strategy], inplace=True)\n            elif strategy == \"most_frequent\":\n                replaced_with_mf = X[self.strategy_features[strategy]].fillna(X[self.strategy_features[strategy]].mode().iloc[0], inplace=False)\n                X.drop(columns=self.strategy_features[strategy], inplace=True)\n            elif strategy == \"drop\":\n                X.drop(columns=self.strategy_features[strategy], inplace=True)\n            else: raise Exception(\"unvalid strategy\")\n        return pd.concat([X, replaced_with_none, replaced_with_mf], axis=1, sort=False)\n    #np.c_[X, replaced_with_none, replaced_with_mf] ","378b351d":"cat_data_imputer = CatDataImputer()\ncat_data_nonan = cat_data_imputer.fit_transform(X[cat_features])","02051dcf":"cat_data_nonan = pd.DataFrame(cat_data_nonan,columns=['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities',\n       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n       'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation', 'Heating',\n       'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive',\n       'SaleType', 'SaleCondition', 'MSSubClass', 'OverallQual', 'OverallCond',\n       'YearBuilt', 'YearRemodAdd', 'MoSold', 'YrSold', 'BsmtQual', 'BsmtCond',\n       'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'GarageType',\n       'GarageFinish', 'GarageQual', 'GarageCond', 'FireplaceQu', 'MasVnrType',\n       'Electrical'])","15d6ed59":"nan_cat_feat = [c for c in cat_features if c not in ['Id','MiscFeature', 'Fence', 'PoolQC', 'GarageYrBlt', 'Alley']]\ns1 =cat_data_nonan[nan_cat_feat].isnull().sum()\ncat_missing_val = s1[s1 > 0]\ncat_missing_val","f3dd6392":"X['MoSold']","ee42b215":"seasons = ['winter','winter','spring','spring','spring','summer','summer','summer','autumn','autumn','autumn','winter'] #dec - feb is winter, then spring, summer, fall etc\nquarters = ['Q1','Q1','Q1','Q2','Q2','Q2','Q3','Q3','Q3','Q4','Q4','Q4']\nis_end_quarter = [False,False,True,False,False,True,False,False,True,False,False,True]\nis_start_quarter = [True,False,False,True,False,False,True,False,False,True,False,False]\nis_end_year = [False,False,False,False,False,False,False,False,False,False,True,True]\nis_start_year = [True,True,False,False,False,False,False,False,False,False,False,False]\nmonth_features = {'season': seasons, 'quarter': quarters, 'is_end_quarter': is_end_quarter, 'is_start_quarter': is_start_quarter, 'is_end_year': is_end_year, 'is_start_year': is_start_year}\nclass MonthFeaturesExtractor(BaseEstimator, TransformerMixin):\n    '''\n        month_features is a dict of lists, each element in these lists represents the label of the corresponding month\n        example:\n            * season = ['winter','winter','spring','spring','spring','summer','summer','summer','autumn','autumn','autumn','winter'] #dec - feb is winter, then spring, summer, fall etc\n            * quarter = ['Q1','Q1','Q1','Q2','Q2','Q2','Q3','Q3','Q3','Q4','Q4','Q4']\n            * month_features = {'season': season, 'quarter': quarter}\n            * month_features[quarter][11] gives the quarter of December (Q4 <==> the 4th quarter) \n    '''\n    def __init__(self, month_features=month_features, col_name='MoSold'): # no *args or **kwargs\n        self.month_features = month_features\n        self.col_name = col_name\n    def fit(self, X, y=None):\n        return self  \n    def transform(self, X, y=None):\n        new_features = pd.DataFrame()\n        for feature in self.month_features.keys():\n            # create a new column for the new feature:\n            new_features[feature] = pd.Series(data=[self.month_features[feature][x-1] for x in X[self.col_name]], name=feature)\n        return pd.concat([X, new_features], axis=1, sort=False)\n    #np.c_[X, new_features]    ","e29c7855":"cols = ['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n       'SaleCondition', 'season', 'quarter', 'is_end_quarter',\n       'is_start_quarter', 'is_end_year', 'is_start_year']","c74a77fa":"date_hacker = MonthFeaturesExtractor()\nX_cols_add = date_hacker.fit_transform(X)\nX_cols_add = pd.DataFrame(X_cols_add)\nX_cols_add","aa81eafe":"class Custom1HotEncoder(BaseEstimator, TransformerMixin):\n    def __init__(self, sparse=False): # no *args or **kwargs\n        self.cat_encoder = OneHotEncoder(sparse=sparse)\n    def fit(self, X, y=None):\n        self.X_str = X.astype('object')\n        self.cat_encoder.fit(self.X_str)\n        return self  \n    def transform(self, X, y=None):\n        return self.cat_encoder.transform(self.X_str)","b5c6da4b":"cust_1hot_encoder = Custom1HotEncoder()\nresult = cust_1hot_encoder.fit_transform(cat_data_nonan[nan_cat_feat])","00423d91":"result","8ecec6c3":"result.shape","7f862b10":"cat_pipeline = Pipeline([\n    ('cat_data_imputer',CatDataImputer()),\n    ('date_hacker', MonthFeaturesExtractor()),\n    ('1hot_encoder', Custom1HotEncoder())\n])","3aaf224c":"X.info()","1ee3c681":"cat_features = X.select_dtypes(exclude=['int64', 'float64']).columns\ncat_features = list(cat_features)\ncat_features.extend(['Id','MSSubClass', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'MoSold', 'YrSold'])\ncat_features","fdc764c7":"cat_data_prep = cat_pipeline.fit_transform(X[cat_features])\ncat_data_prep","f0a4d189":"cat_data_prep.shape","c8e63ae6":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer","e1784268":"int_float = X.select_dtypes(include=['int64', 'float64']).columns\nnum_features = [col_name for col_name in int_float if col_name not in cat_features]\nnum_features","82f6496c":"num_pipeline = Pipeline([\n        ('mice', IterativeImputer(random_state=0)),\n        ('std_scaler', StandardScaler()),\n    ])","3cef0d2d":"num_data_prep = num_pipeline.fit_transform(X[num_features])","6a65923a":"num_data_prep.shape","2a9258e6":"from sklearn.compose import ColumnTransformer","f1fcead6":"full_pipeline = ColumnTransformer([\n    (\"cat_pipeline\", cat_pipeline, cat_features),\n    (\"num_pipeline\", num_pipeline, num_features)\n])\n\nX_prep = full_pipeline.fit_transform(X)\n","c139d568":"X_prep","edec3b31":"X_prep.shape","5f675778":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint","e0d9c26c":"r = randint(low=10,high=15)\n","61d3b817":"param_distribs = {\n    'n_estimators': randint(low=100, high=500),\n    'max_features': randint(low=10, high=517),\n    'max_depth': randint(low=10, high=500),\n    'bootstrap': [True, False],\n}\n\nforest_reg = RandomForestRegressor(random_state=42)\nrnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n                                n_iter=50, cv=5, scoring='neg_mean_squared_error', random_state=42)\nrnd_search.fit(X_prep, y)","08d0f8ab":"import os\nos.chdir(r'\/kaggle\/working')","1d3c5a6f":"from sklearn.externals import joblib\njoblib.dump(rnd_search.best_estimator_, \"best_rnd_estim.pkl\")","e13e5d47":"from IPython.display import FileLink\nFileLink(r'best_rnd_estim.pkl')","ab6202d9":"from sklearn.externals import joblib\nbest_rf_rnds = joblib.load('\/kaggle\/input\/best-random-forest-estimator\/best_rnd_estim.pkl')","6c71897e":"best_rf_rnds","36dffd52":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(best_rf_rnds, X_prep, y, cv=5, scoring='neg_mean_squared_error')\nforest_rmse_scores = np.sqrt(-scores)","8c8feeb4":"forest_rmse_scores","973ec41c":"full_pipeline1 = ColumnTransformer([\n    (\"cat_pipeline\", cat_pipeline, cat_features),\n    (\"num_pipeline\", num_pipeline, num_features),\n    \n])\nX.drop(1459, inplace=True)\nX_prep = full_pipeline.fit_transform(X)","f8377f88":"# path to file you will use for predictions\ntest_data_path = '\/kaggle\/input\/home-data-for-ml-course\/test.csv'\n\n# read test data file using pandas\ntest_data = pd.read_csv(test_data_path)\n\n# create test_X which comes from test_data but includes only the columns you used for prediction.\n# The list of columns is stored in a variable called features\nX_test = test_data[features].copy()","b3eddc38":"X_test.info()","4c67dfb9":"X_test_prep = full_pipeline.transform(X_test)\n# make predictions which we will submit. \ntest_preds = best_rf_rnds.predict(X_test_prep)\n\n# The lines below shows how to save predictions in format used for competition scoring\n# Just uncomment them.\n\noutput = pd.DataFrame({'Id': test_data.Id,\n                      'SalePrice': test_preds})\noutput.head()\noutput.to_csv('submission.csv', index=False)","d4109a13":"### Missing data:","fb6e2c9e":"## Custom OneHotEncoding:\nSince OneHotEncoder can only take an input that's  either entirely integer or entirely string, I need to cast my categorical columns to string including the ones whose dtype is np.number. Only then I can apply the OneHotEncoder  ","0baf062a":"## Observations:\n   * there are many outliers at the value 0 of many features on the x axis. ","c0b01cb5":"## Numerical Data Transformation Pipeline","5d757ffa":"## Hypythesis:\nHere I get the assumption that when the MasVnrType is `Nan` when the MasVnrArea is `Nan` also and `\"None\"` when MasVnrArea is 0.0 (the second one is sort of obvious). Let's make sure. ","49a45074":"## Observation:\n   * Obviously, all the garage related columns are Nan or 0 when the garage area is 0 (when there is no garage), so imputing these missig data by replacing them with most frequent value (or anyvalue at that) doesn't make sense at all. I need to find a more logical and valid way to deal with this missing data. If only I could tell the model to take these columns in consideration only when GarageArea > 0!! \n   * The best solution I found is to replace all `NaN` values with a string values `\"None\"` thus creating a new category that indicates that there isno garage instead of the previous `NaN`. Except for GarageYrBlt, since this column contains floats (originally integers but because of the NaN values it is considered by pandas as float) this imputation won't work, and replacing it with a random or mean or most frequent...etc wouldn't make any sense at all I'd just rather drop this variable, it doesn't seem very pertinent anyway.","2f0e0561":"## Observations:\n   * the only numerical features with missing values are LotFrontage (missing 259 values) and MasVnrArea (missing 8 values).","274bd7e7":"#### Observation:\nThe error generated is `ValueError: Input contains NaN` because the OneHotEncoder doesn't take missing values and the imputations we (thought we) did in the catdataimputer1 didn't work so our data still contains missing values.","229209dd":"### Random forest:","2fe63b75":"#### Let's see for ourselves:","3b8be541":"# Submitting:","16833c41":"# Loading the data:","1bb894a3":" ## Observation:\n   * When the PoolArea is 0 the PoolQC is NaN,but since there are 1453 missing values so there's no need to bother think of the best way to make up for the missing data since it will do more harm than good.  ","f0d9df5f":"## Extracting categorical and numerical features for futur transformations:\nThere is one tricky apect about this dataset, there are `\u00ecnt64` columns that are categorical like MSSubClass. So what I'll do is extract all features that are not numerical data types, then I will manually add to them the missing categorical features as listed in the data fields disciption. ","f8edbca0":"# EDA:","a9fb6959":"### Extracting interesting features from `'MoSold'`:  ","8d96115d":"### Let's the results now:","4b1d89f5":"# Modeling:","419d8882":"**Resource**: [SettingWithCopyWarning, dataquest.io.](https:\/\/www.dataquest.io\/blog\/settingwithcopywarning\/)\n### What is SettingWithCopyWarning?\nThe first thing to understand is that SettingWithCopyWarning is a warning, and not an error.\n\nWhile an error indicates that something is broken, such as invalid syntax or an attempt to reference an undefined variable, the job of a warning is to alert the programmer to potential bugs or issues with their code that are still permitted operations within the language. In this case, the warning very likely indicates a serious but inconspicuous mistake.\n\nSettingWithCopyWarning informs you that your operation might not have worked as expected and that you should check the result to make sure you haven\u2019t made a mistake, i.e. whether your code is modifying your original dataframe and not a copy of it only, and does it match your expectations?.\n\nIt can be tempting to ignore the warning if your code still works as expected. This is bad practice and SettingWithCopyWarning should never be ignored. Take some time to understand why you are getting the warning before taking action.\n\nTo understand what SettingWithCopyWarning is about, it\u2019s helpful to understand that some actions in pandas can return a view of your data, and others will return a copy.\n![view_vs_copy](https:\/\/www.dataquest.io\/wp-content\/uploads\/2019\/01\/view-vs-copy.png)\n![modifying_view_vs_copy](http:\/\/www.dataquest.io\/wp-content\/uploads\/2019\/01\/modifying.png)","2c703b56":"## Observations:\n   * there are many columns that contain missing values.\n   * many columns are non-numerical.","d2f46a7f":"## Observations:\n   * the Fence column has 1179 missing values, so for the same reasons as Alley and PoolQC we're better off dropping the variable.","d9628b01":"# Set-up:","d0e79a73":"## Observation:\n   * when there is no basement all categorical data related to basements is NaN and all numerical data related to basements is 0.","b5bae900":"## N.B.\n   * there can be some nice feature extraction from the MoSold, what does the month represent? end of year? quarter? winter?...etc\n   * the Id feature logically should not be included in the training features cause it makes no sense to make a prediction based on the Id.","6310a353":"hmmm what are the different rows??","6c54b237":"## Observations:\n   * the data discription file indicates that when MasVnrType is `None` then this means there's no masonry veneer so the MasVnrArea must be 0.0 and vice versa. But since I'm not sure about this and this 'anomaly' doesn't affect many rows, I prefer not to mess with the data.\n   * For all the other rows when MasVnrArea == 0.0 it is the same as saying that MasVnrType is `'None'`, and when the MasVnrArea is missing the MasVnrType is missing too so this is (I believe) missing data not at random MNAR since it's neither MCAR nor MAR (i.e. the value of the variable that's missing is related to the reason it's missing), so the best thing I can think of doing here is to replace the missing MasVnrType values with the most frequent value, luckily we have only 8 missing values for MasVnrType so that won't be much of a trouble.","52c0fe9f":"## Categorical data pipeline:","0fe6b02f":"# Preparing the data:\n","1100c24d":"## Observation:\n   * Same goes for FireplaceQu, it is Nan when Fireplaces == 0. It makes absolutely no sense to replace FireplaceQu with a value when it is missing.","d22a472b":"### N.B.\nWe can ignore the warning here since we don't care whether we're working on a view of the dataframe X or a copy of it, all we need is the return value which we're sure we're getting. ","41c1375c":"## Exploring the missing rows containing missing values:","e752d81e":"## Observation:\n   * the Alley column contains 1390 missing values, so any attempt to replace these missing values is just gonna mess up the data ( we have only 70 non-null values to use for filling in the missing data!). So dropping it is the best solution.\n   * Same goes for MiscFeatures.","5f58667a":"***ET VOILA!!***","653bccac":"## Categorical Data Transformation Pipeline","fcf7dcaf":"## Full pipeline","68c865d1":"## Detecting categorical features that present missing values: ","e41e3fc9":"#### Observation and explanation:\n   * The columns we wanted to drop were droped but the missing data in the other columns weren't replaced by any desired value at all!!\n   * this is because of the slicing done here `X[self.strategy_features[strategy]]` ceates a copy of the dataframe instead of a view on the desired columns,thus we are working on the slice we created and not on `X` as we have intended."}}