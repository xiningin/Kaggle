{"cell_type":{"4c616545":"code","74260948":"code","ba5ce3cb":"code","b902d209":"code","07ac89cf":"code","612995ba":"code","021aa63f":"code","e7f12cc7":"code","6043b619":"code","f1d3e675":"code","07900a11":"code","7cd7e84d":"code","718483a5":"code","d5d944f9":"code","9a6dd6b1":"markdown","45fff00f":"markdown","32038e97":"markdown","27e35019":"markdown","1a75c946":"markdown","01b0ec65":"markdown","f902f102":"markdown"},"source":{"4c616545":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, HuberRegressor\nfrom sklearn.svm import LinearSVR\nfrom sklearn.tree import DecisionTreeRegressor","74260948":"data = pd.read_csv('..\/input\/korea-income-and-welfare\/Korea Income and Welfare.csv')","ba5ce3cb":"data","b902d209":"data.info()","07ac89cf":"data","612995ba":"def onehot_encode(df, column, prefix):\n    df = df.copy()\n    dummies = pd.get_dummies(df[column], prefix=prefix)\n    df = pd.concat([df, dummies], axis=1)\n    df = df.drop(column, axis=1)\n    return df","021aa63f":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop id column\n    df = df.drop('id', axis=1)\n    \n    # Encode missing values properly\n    df = df.replace(' ', np.NaN)\n    \n    # One-hot encode categorical variables\n    nominal_features = [\n        ('region', \"reg\"),\n        ('marriage', \"mar\"),\n        ('religion', \"rel\"),\n        ('occupation', \"occ\"),\n        ('reason_none_worker', \"rsn\")\n    ]\n    for column, prefix in nominal_features:\n        df = onehot_encode(df, column=column, prefix=prefix)\n    \n    # Fill company_size missing values with 0\n    df['company_size'] = df['company_size'].fillna(0)\n    \n    # Split df into X and y\n    y = df['income']\n    X = df.drop('income', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    \n    X_train = pd.DataFrame(scaler.transform(X_train), columns=X.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n    \n    return X_train, X_test, y_train, y_test","e7f12cc7":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","6043b619":"X_train","f1d3e675":"y_train","07900a11":"models = {\n    \"                   Linear Regression\": LinearRegression(),\n    \"    L2-Regularized Linear Regression\": Ridge(),\n    \"    L1-Regularized Linear Regression\": Lasso(),\n    \"           Huber (Robust) Regression\": HuberRegressor(),\n    \"Linear Kernel Support Vector Machine\": LinearSVR(),\n    \"                       Decision Tree\": DecisionTreeRegressor()\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + \" trained.\")","7cd7e84d":"print(\"Model R^2 Scores (Test Set):\")\nfor name, model in models.items():\n    print(name + \": {:.4f}\".format(model.score(X_test, y_test)))","718483a5":"l2_reg_strength = 1.0\n\nl2_model = Ridge(alpha=l2_reg_strength)\nl2_model.fit(X_train, y_train)\n\nprint(\"Ridge Regression Test R^2 (alpha={}): {:.5f}\".format(l2_reg_strength, l2_model.score(X_test, y_test)))","d5d944f9":"l1_reg_strength = 0.01\n\nl1_model = Lasso(alpha=l1_reg_strength)\nl1_model.fit(X_train, y_train)\n\nprint(\"Lasso Regression Test R^2 (alpha={}): {:.5f}\".format(l1_reg_strength, l1_model.score(X_test, y_test)))","9a6dd6b1":"# Training","45fff00f":"# Results","32038e97":"# Getting Started","27e35019":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/2JwDkvWEVlM","1a75c946":"# Task for Today  \n\n***\n\n## Household Income Prediction  \n\nGiven *data about households in Korea*, let's try to predict the **income** of a given household.  \n  \nWe will use various regression models to make our predictions.","01b0ec65":"# Optimizing Regularization Strength of L2 and L1 Regression Models","f902f102":"# Preprocessing"}}