{"cell_type":{"848a114b":"code","4f95c3fd":"code","5a3560d4":"code","1b02c338":"code","4b4a028d":"code","ead9d016":"code","a6d4051b":"code","ecd28e6d":"code","8da5333d":"code","7123087f":"code","9a10255d":"code","a20480c1":"code","a7fea5f1":"code","2d8d34c1":"code","106fb806":"code","53566728":"code","3598d0cc":"code","6b239345":"code","bbecc3fe":"code","09ad397d":"code","2eb3a9bf":"code","992ad06d":"code","ad5e9f9e":"code","90793b77":"code","a643462d":"code","fb460fb8":"code","6f68d466":"markdown","75679e2f":"markdown","0e9ab96d":"markdown","5b1225c9":"markdown","75d21a0a":"markdown","d9270b79":"markdown","8007f8d0":"markdown","6a2852ad":"markdown","85d53648":"markdown","c0460131":"markdown","3c56318d":"markdown"},"source":{"848a114b":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","4f95c3fd":"DataPath = \"..\/input\/30-days-of-ml\/train.csv\"\nTestDataPath = \"..\/input\/30-days-of-ml\/test.csv\"\nSubPath = \"..\/input\/30-days-of-ml\/sample_submission.csv\"\nData = pd.read_csv(DataPath)\nTestData = pd.read_csv(TestDataPath)\ny_test = pd.read_csv(SubPath)","5a3560d4":"Data.head(10) #display first 10 rows of the dataset","1b02c338":"Data = Data.drop(columns=\"id\")","4b4a028d":"Data.info()","ead9d016":"Data.isnull().sum()","a6d4051b":"Data.describe()","ecd28e6d":"h = Data.hist(figsize=(20,20))","8da5333d":"Data.columns","7123087f":"Data.nunique()","9a10255d":"import seaborn as sns\nf,ax = plt.subplots(figsize=(30,30))\ncorr = Data.corr()\nDC = sns.heatmap(corr,square=True,ax=ax,annot=True)\nDC.set_title(label=\"Data Correlation\",fontsize=50)","a20480c1":"target = Data['target']\ntarget.head()","a7fea5f1":"Features = Data.drop(columns='target')\nFeatures.head()","2d8d34c1":"categorical_cols = [col for col in Features.columns if Features[col].nunique()<=15 and Features[col].dtype==\"object\" ]\ncategorical_cols","106fb806":"numerical_cols = [col for col in Features.columns if Features[col].dtype in ['int64','float64']]\nnumerical_cols","53566728":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(Features,target,test_size=0.2,shuffle=True,random_state=44)","3598d0cc":"print(f\"Training Data Shape = {X_train.shape}\")\nprint(f\"Validating Data Shape = {X_valid.shape}\")","6b239345":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder\n\n\nnumerical_transformer = Pipeline(steps=[('scale',MinMaxScaler())])\n \ncategorical_transformer = Pipeline(steps=[('onehot',OneHotEncoder(handle_unknown=\"ignore\"))])\n\npreprocessor = ColumnTransformer(transformers=[('num',numerical_transformer,numerical_cols),('cat',categorical_transformer,categorical_cols)])","bbecc3fe":"from sklearn.ensemble import RandomForestRegressor\n\nmodel = RandomForestRegressor(n_estimators=500,max_depth=60,random_state=0)","09ad397d":"my_pipeline = Pipeline(steps=[('preprocessor',preprocessor),('model',model)])\n# Visualize the pipeline\nfrom sklearn import set_config\nset_config(display='diagram')\nmy_pipeline","2eb3a9bf":"my_pipeline.fit(Features,target)","992ad06d":"preds = my_pipeline.predict(X_valid)","ad5e9f9e":"from sklearn.metrics import mean_absolute_error\nscore = mean_absolute_error(y_valid,preds)\nprint(f\"MAE = {score}\")","90793b77":"sns.regplot(y_valid, preds, scatter_kws={'alpha':0.3, 'color':'b'})\nplt.xlabel('Actual target')\nplt.ylabel('Predicted target')\nplt.show()","a643462d":"#Features of training data the we applied model on it\nfeatures_cols = Features.columns\n\nX_test = TestData[features_cols]\ntest_preds = my_pipeline.predict(X_test)","fb460fb8":"#Generate submission\noutput = pd.DataFrame({\"ID\":TestData[\"id\"],\"target\":test_preds})\noutput.to_csv(\"my_submission_4.csv\",index=False)","6f68d466":"# Import Important Libraries","75679e2f":"# There aren't any correlated features to be removed.","0e9ab96d":"There is no missing values in our dataset","5b1225c9":"# Model Evaluation","75d21a0a":"# Apply the model on test data to make prediction and generate a submission file","d9270b79":"# Read Dataset","8007f8d0":"# Define the Model","6a2852ad":"# Preprocessing of training data and fit the model","85d53648":"# Validation data preprocessing and make predictions","c0460131":"# Exploratory Data Analysis (EDA)\n#### Explore the data. Look for the shape of the dataset and explore the columns and the types of columns we're working with (numerical, categorical). Consider performing basic statistics on the features to get a sense of feature means and ranges. Take a close look at the target column and determine its distribution.","3c56318d":"# Split Dataset into 80% (train) 20% (validate)"}}