{"cell_type":{"8eb77dc1":"code","4d4afaec":"code","5a3ee5b0":"code","a3ff5d6f":"code","279addc6":"code","f7ed89e2":"code","ed8d4726":"code","7ed87e75":"code","7de83b2e":"code","36790852":"code","4927399c":"code","0d315b8a":"code","9c717552":"code","835c2fd9":"code","d9088e90":"code","4c1e6603":"code","41aba262":"code","16ea45fe":"code","e867da30":"code","4a41466c":"code","eb9f0f28":"code","69bd00fe":"code","948b71f5":"code","83077216":"code","bb4914c6":"code","27622af7":"code","f5bf1b3e":"code","7b788159":"code","282db8b8":"code","789af41e":"code","68e2d629":"code","19003823":"code","0620e73b":"code","ef6e9517":"code","aef262de":"code","98958250":"code","2ecab0d8":"code","dfa85698":"code","c34e2b2d":"code","1d87c6d8":"code","cf461a76":"code","6442139a":"code","87b8f28a":"code","2a9cdeeb":"code","85d31f1a":"code","b4ce0a71":"code","7d6e773c":"code","e8dc1f97":"code","705bf9e4":"code","de40ceba":"code","c9cd3459":"code","c79da742":"code","ba335164":"code","6f80ae96":"markdown","4cfedccc":"markdown","70ee5cf2":"markdown","cec76d73":"markdown","f57a115d":"markdown","3aa3c2c8":"markdown","2073e883":"markdown","46c25df2":"markdown","d3e59114":"markdown","5e7ed203":"markdown","3dfc7da0":"markdown","27f40e85":"markdown","de735c61":"markdown","d38740bd":"markdown","83b66653":"markdown","a0f069fa":"markdown","384a14ea":"markdown","06b2e1b7":"markdown","95e2749d":"markdown","b5f8e0cd":"markdown","70b323c5":"markdown","e2056c17":"markdown","0ea8562e":"markdown","8acee972":"markdown","6b4adec1":"markdown","bd6a4d8e":"markdown","57cc9193":"markdown","66f9b415":"markdown"},"source":{"8eb77dc1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4d4afaec":"# modules we'll use\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n\n# read in all our data\neducation_expenditure_supplementary_data = pd.read_csv(\"..\/input\/world-university-rankings\/education_expenditure_supplementary_data.csv\" ,engine='python')\neducation_expenditure_supplementary_data.name='education_expenditure_supplementary_data'\nshanghaiData = pd.read_csv(\"\/kaggle\/input\/world-university-rankings\/shanghaiData.csv\")\nshanghaiData.name='shanghaiData'\ntimesData= pd.read_csv(\"\/kaggle\/input\/world-university-rankings\/timesData.csv\")\ntimesData.name='timesData'\ncwurData = pd.read_csv(\"\/kaggle\/input\/world-university-rankings\/cwurData.csv\")\ncwurData.name='cwurData'\nschool_and_country_table= pd.read_csv(\"\/kaggle\/input\/world-university-rankings\/school_and_country_table.csv\")\nschool_and_country_table.name='school_and_country_table'","5a3ee5b0":"Data_List=[education_expenditure_supplementary_data,shanghaiData,timesData,cwurData,school_and_country_table]\nfor x in Data_List:\n    # how many total missing values do we have?\n    #totale values in our dataset\n    total_cells = np.product(x.shape)\n    #description of  missing values in each column\n    missing_values_count = x.isnull().sum()\n    print(\"Data Frame :\",'\\033[1m' + x.name + '\\033[0m')\n    #print('Data Frame :',x.name)\n    print(missing_values_count.sort_values(ascending=False))\n    #totale missing values in our dataset\n    total_missing = missing_values_count.sum()\n    # percent of data that is missing\n    percent_missing = (total_missing\/total_cells) * 100\n    print('Data shape :',x.shape[0],'by', x.shape[1])\n    print('% of data that is missing :',\"{:.2f}\".format(percent_missing),'\\n')","a3ff5d6f":"education_expenditure_supplementary_data.head(5)","279addc6":"education_expenditure_supplementary_data.describe(include='all')","f7ed89e2":"cols_with_missing = [col for col in education_expenditure_supplementary_data.columns\n                     if education_expenditure_supplementary_data[col].isnull().any()]\nprint('dropped Columns :',cols_with_missing)\n\n\neducation_expenditure_supplementary_data = education_expenditure_supplementary_data.drop(cols_with_missing, axis=1)","ed8d4726":"education_expenditure_supplementary_data.head()","7ed87e75":"education_expenditure_supplementary_data['country'] = education_expenditure_supplementary_data['country'].str.strip()\ncountries = education_expenditure_supplementary_data['country'].unique()\n# sort them alphabetically and then take a closer look\ncountries.sort()\ncountries","7de83b2e":"shanghaiData.head(10)","36790852":"shanghaiData.shape","4927399c":"#dropping Totale score column with the most missing values (70%+)\nshanghaiData=shanghaiData.drop(['total_score'], axis = 1)\n#replacing all the NaN's in the shanghaiData data with the one that comes directly after it \n#and then replacing any remaining NaN's with 0\nshanghaiData = shanghaiData.fillna(method='bfill', axis=0).fillna(0)","0d315b8a":"shanghaiData.describe()","9c717552":"# Number of missing values in each column of data\nmissing_val_count_by_column = (shanghaiData.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])","835c2fd9":"shanghaiData.columns","d9088e90":"shanghaiData_features = ['alumni', 'award',\n       'hici', 'ns', 'pub', 'pcp']\nshanghaiData[\"Score\"] = (shanghaiData[shanghaiData_features].sum(axis=1)\/len(shanghaiData_features))*0.1\nshanghaiData[\"Score_rank\"]=(10-shanghaiData[\"Score\"]).apply(np.ceil)\nshanghaiData.award=shanghaiData.award*0.1\nshanghaiData.head(10)","4c1e6603":"def linelivechart(data,tr_1,tr_2):\n    # prepare data frame\n    df = data.iloc[:10,:]\n\n    # import graph objects as \"go\"\n    import plotly.graph_objs as go\n    from plotly.offline import iplot\n\n    # Creating trace1\n    trace1 = go.Scatter(\n                        x = df[tr_1],\n                        y = df[tr_2],\n                        mode = \"lines+markers\",\n                        name = \"Score rank\",\n                        marker = dict(color = 'rgba(16, 112, 2, 0.8)'),\n                        text= df.university_name)\n    # Creating trace2\n    trace2 = go.Scatter(\n                        x = df.world_rank,\n                        y = df.national_rank,\n                        mode = \"lines+markers\",\n                        name = \"National Rank\",\n                        marker = dict(color = 'rgba(80, 26, 80, 0.8)'),\n                        text= df.university_name)\n    data = [trace1, trace2]\n    layout = dict(title = 'New Score Rank and national rank vs World Rank of Top 10 Universities',\n                  xaxis= dict(title= 'World Rank',ticklen= 5,zeroline= True)\n                 )\n    fig = dict(data = data, layout = layout)\n    iplot(fig)","41aba262":"linelivechart(shanghaiData,'world_rank', 'Score_rank')","16ea45fe":"timesData.head(10)","e867da30":"timesData.shape","4a41466c":"#replacing all the NaN's in the timesData data with the one that comes directly after it \ntimesData = timesData.fillna(method='bfill', axis=0)\n# Number of missing values in each column of data\nmissing_val_count_by_column = (timesData.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])","eb9f0f28":"timesData.head(10)","69bd00fe":"#Replacing '-' with NaN\ntimesData=timesData.replace('-', np.NaN)\n#replacing all the NaN's in the timesData with the one that comes directly after it \ntimesData = timesData.fillna(method='bfill', axis=0)\n\n#removing white space from left and right!\ntimesData['female_male_ratio'] = timesData['female_male_ratio'].str.strip()\n# new data frame with split value columns\nnew = timesData[\"female_male_ratio\"].str.split(\":\", n = 1, expand = True)\n# making separate female ratio from new data frame and making sure no white space exist,\n#making sure it has a good datatype for ploting\n\ntimesData[\"Female_ratio\"]= new[0]  \ntimesData[\"Female_ratio\"]=timesData['Female_ratio'].str.strip()\n\n#changing column type\ntimesData = timesData.astype({\"Female_ratio\": int})\n# making separate male ratio from new data frame and making sure no white space exist ,\n#making sure it has a good datatype for ploting\ntimesData[\"male_ratio\"]= new[1]  \ntimesData[\"male_ratio\"]=timesData['male_ratio'].str.strip()\n#changing column type\ntimesData = timesData.astype({\"male_ratio\": int})\n# Dropping old female_male_ratio columns\ntimesData.drop(columns =[\"female_male_ratio\"], inplace = True)\ntimesData.head()","948b71f5":"timesData['international_students'] = timesData['international_students'].str.strip()\nnew2 = timesData[\"international_students\"].str.split(\"%\", n = 1, expand = True)\ntimesData[\"international_students\"]= new2[0]\ntimesData[\"international_students\"]=timesData['international_students'].str.strip()\ntimesData = timesData.astype({\"international_students\": int})","83077216":"timesData.rename(columns={'international_students': 'international_students % ', 'Female_ratio': 'Female_ratio % ', 'male_ratio': 'male_ratio % '}, inplace=True)\ntimesData.head()","bb4914c6":"#Checking the datatype of the each column of the timesData DataFrame to make sure we are looking good so far ....\ndataTypeSeries = timesData.dtypes\nprint('Data type of each column of timesData Dataframe :')\nprint(dataTypeSeries)","27622af7":"timesData = timesData.astype({\"international\": float , \"income\":float , \"total_score\":float})","f5bf1b3e":"timesData[\"num_students\"]=timesData[\"num_students\"].str.replace(',','.')\ntimesData[\"num_students\"] = timesData[\"num_students\"].apply(pd.to_numeric)","7b788159":"#Checking the datatype of the each column of the timesData DataFrame to make sure we are looking good so far ....\n#Again ..............\ndataTypeSeries = timesData.dtypes\nprint('Data type of each column of timesData Dataframe :')\nprint(dataTypeSeries)","282db8b8":"timesData.head()","789af41e":"def linelivecharttimesData(data,tr_1,tr_2,tr_3):\n    # prepare data frame\n    df = data.iloc[:20,:]\n\n    # import graph objects as \"go\"\n    import plotly.graph_objs as go\n    from plotly.offline import iplot\n\n    # Creating trace1\n    trace1 = go.Scatter(\n                        x = df[tr_1],\n                        y = df[tr_2],\n                        mode = \"lines+markers\",\n                        name = \"teaching\",\n                        marker = dict(color = 'rgba(16, 112, 2, 0.8)'),\n                        text= df.university_name)\n    # Creating trace2\n    trace2 = go.Scatter(\n                        x = df.world_rank,\n                        y = df.research,\n                        mode = \"lines+markers\",\n                        name = \"research\",\n                        marker = dict(color = 'rgba(80, 26, 80, 0.8)'),\n                        text= df.university_name)\n    # Creating trace3\n    trace3 = go.Scatter(\n                        x = df[tr_1],\n                        y = df[tr_3],\n                        mode = \"lines+markers\",\n                        name = \"income\",\n                        marker = dict(color = 'rgba(36,120,153,.4)'),\n                        text= df.university_name)\n    data = [trace1, trace2 , trace3]\n    layout = dict(title = 'teaching, research and income vs world_rank of Top 20 Universities',\n                  xaxis= dict(title= 'World Rank',ticklen= 5,zeroline= True)\n                 )\n    fig = dict(data = data, layout = layout)\n    iplot(fig)","68e2d629":"linelivecharttimesData(timesData,'world_rank', 'teaching','income')","19003823":"def linelivecharttimesData(data,tr_1,tr_2,tr_3,tr_4):\n    # prepare data frame\n    df = data.iloc[:20,:]\n\n    # import graph objects as \"go\"\n    import plotly.graph_objs as go\n    from plotly.offline import iplot\n\n    # Creating trace1\n    trace1 = go.Scatter(\n                        x = df[tr_1],\n                        y = df[tr_2],\n                        mode = \"lines+markers\",\n                        name = \"teaching\",\n                        marker = dict(color = 'rgba(16, 112, 2, 0.8)'),\n                        text= df.university_name)\n    # Creating trace2\n    trace2 = go.Scatter(\n                        x = df.world_rank,\n                        y = df[tr_3],\n                        mode = \"lines+markers\",\n                        name = \"citations\",\n                        marker = dict(color = 'rgba(80, 26, 80, 0.8)'),\n                        text= df.university_name)\n    # Creating trace3\n    trace3 = go.Scatter(\n                        x = df[tr_1],\n                        y = df[tr_4],\n                        mode = \"lines+markers\",\n                        name = \"research\",\n                        marker = dict(color = 'rgba(36,120,153,.4)'),\n                        text= df.university_name)\n    data = [trace1, trace2 , trace3]\n    layout = dict(title = 'teaching ,citations and research vs world_rank of Top 20 Universities',\n                  xaxis= dict(title= 'World Rank',ticklen= 5,zeroline= True)\n                 )\n    fig = dict(data = data, layout = layout)\n    iplot(fig)","0620e73b":"linelivecharttimesData(timesData,'world_rank', 'teaching','citations','research')","ef6e9517":"import plotly.graph_objs as go\nfrom plotly.offline import iplot\nindex = timesData[\"country\"].value_counts().head(10).index\nvalue = timesData[\"country\"].value_counts().head(10).values\ntrace1 = go.Bar(\nx = index,\ny = value,\nmarker = {\"color\":\"rgba(131,26,93,0.4)\"}    \n)\ndata4 = [trace1]\n\niplot(data4)","aef262de":"timesData.year.unique()","98958250":"data2016 = timesData[timesData.year == 2016].iloc[:100,:]\ndata2015 = timesData[timesData.year == 2015].iloc[:100,:]\ndata2014 = timesData[timesData.year == 2014].iloc[:100,:]\ndata2013 = timesData[timesData.year == 2013].iloc[:100,:]\ndata2012 = timesData[timesData.year == 2012].iloc[:100,:]\ndata2011 = timesData[timesData.year == 2011].iloc[:100,:]","2ecab0d8":"# creating trace for year 2011\ntrace_2011 = go.Scatter(x = data2011.world_rank, y = data2011.citations, mode = \"markers\", name = \"2011\", marker = dict(color = 'rgba(255, 128, 255, 0.8)'), text= data2011.university_name)\n# creating trace for year 2012\ntrace_2012 = go.Scatter(x = data2012.world_rank, y = data2012.citations, mode = \"markers\", name = \"2012\", marker = dict(color = 'rgba(16, 112, 2, 0.8)'), text= data2012.university_name)\n# creating trace for year 2013\ntrace_2013 = go.Scatter(x = data2013.world_rank, y = data2013.citations, mode = \"markers\", name = \"2013\", marker = dict(color = 'rgba(80, 26, 80, 0.8)'), text= data2013.university_name)\n# creating trace for year 2014\ntrace_2014 = go.Scatter(x = data2014.world_rank, y = data2014.citations, mode = \"markers\", name = \"201\", marker = dict(color = 'rgba(36,120,153,.4)'), text= data2014.university_name)\n# creating trace for year 2015\ntrace_2015 = go.Scatter(x = data2015.world_rank,y = data2015.citations,mode = \"markers\",name = \"2015\",marker = dict(color = 'rgba(255, 128, 2, 0.8)'),text= data2015.university_name)\n# creating trace for year 2016\ntrace_2016 = go.Scatter(x = data2016.world_rank,y = data2016.citations, mode = \"markers\", name = \"2016\", marker = dict(color = 'rgba(0, 255, 200, 0.8)'),text= data2016.university_name)","dfa85698":"# list of traces\ndata = [trace_2011, trace_2012, trace_2013, trace_2014, trace_2015, trace_2016]\n\nlayout = dict(title = 'Citation vs world rank of top 100 universities from 2011 to 2016',\n              xaxis= dict(title= 'World Rank',ticklen= 5,zeroline= False),\n              yaxis= dict(title= 'Citation',ticklen= 5,zeroline= False))\nfigure2 = dict(data = data, layout = layout)\niplot(figure2)","c34e2b2d":"cwurData.head(10)","1d87c6d8":"cwurData.shape","cf461a76":"#Checking the datatype of the each column of the timesData DataFrame to make sure we are looking good so far ....\ndataTypeSeries = cwurData.dtypes\nprint('Data type of each column of timesData Dataframe :')\nprint(dataTypeSeries)","6442139a":"cwurData=cwurData.drop(['broad_impact'], axis = 1)","87b8f28a":"cwurData[\"Estimated_Score\"]=cwurData[\"score\"] - (cwurData[\"quality_of_education\"] * 0.35 + cwurData[\"alumni_employment\"] * 0.45 + cwurData[\"influence\"] * 0.20 )","2a9cdeeb":"cwurData.head()","85d31f1a":"cwurData.year.unique()","b4ce0a71":"fig, axs = plt.subplots(ncols=3 , figsize=(30,12))\nsns.pointplot(data=cwurData.head(3), x='institution', y='world_rank',ax=axs[0]  ,fontsize=100)\nsns.pointplot(data=cwurData.head(3), x='institution', y='score',ax=axs[1])\nsns.pointplot(data=cwurData.head(3), x='institution', y='Estimated_Score',ax=axs[2])","7d6e773c":"from wordcloud import WordCloud \ndataframe=cwurData['country'].to_string()\n# Start with one review:\ntext = dataframe\n# Create and generate a word cloud image:\nwordcloud = WordCloud().generate(text)\n# Display the generated image:\nf,ax=plt.subplots(1,1,figsize=(25,5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","e8dc1f97":"cwurData.insert(14,\"chances\",0,True)\ncwurData.head(1)","705bf9e4":"cwurData.loc[cwurData['score']> 20, ['chances']] = '1'\ncwurData.loc[cwurData['score']< 20, ['chances']] = '0'","de40ceba":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ncwurData['country']=le.fit_transform(cwurData['country'])","c9cd3459":"y = cwurData.chances\ncwurData_features = ['alumni_employment', 'publications', 'citations', 'national_rank', \n                        'quality_of_education']\nX = cwurData[cwurData_features]\n\nfrom sklearn.model_selection import train_test_split\ntrain_X, val_X, train_y, val_y = train_test_split(X, y,test_size=0.2,random_state = 7)","c79da742":"from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nran_class=RandomForestClassifier()\nran_class.fit(train_X,train_y)\nran_predict=ran_class.predict(val_X)\nprint(classification_report(val_y,ran_predict))\naccuracy=ran_class.score(val_X,val_y)\nprint(accuracy*100,'%')\ncm = confusion_matrix(val_y, ran_predict)\nsns.heatmap(cm, annot= True)","ba335164":"train_score = ran_class.score(train_X,train_y)\ntest_score = ran_class.score(val_X,val_y)\nprint(f'Training Accuracy of our model is: {train_score}')\nprint(f'Test Accuracy of our model is: {test_score}')\nprint()\n#prediction of being in top 20\nprediction = ran_class.predict(train_X.iloc[15].values.reshape(1,-1))\nactual_value = train_y.iloc[15]\nprint(f'Predicted Value \\t: {prediction[0]}')\nprint(f'Actual Value\\t\\t: {actual_value}')","6f80ae96":"**Wordcloud**","4cfedccc":"**Problem :**  \nWhen trying to split the `female to male ratio` column, I found it that there are some rows with `-` , these are just some `FAKE NANs` so best thing to do here it to replace them to NAN value then get ride of them but replacing the new NaNs with the values that comes directly after it just like what I did before.","70ee5cf2":"**Creating new Feature** based on the Forbes College rankings **check the description at the beginning of the notebook**, but with some modification ( my own prespective , just a point of view as a student) to adopt it to the dataframe  \nthe new feature **(Estimated_Score) formula**: rank for `score - (quality of education * 35% + rank for alumni employment* 45% + rank for influence * 20%)`","cec76d73":"for this data frame , I would like to see the ratio of the institue type per country and the relationship between these two and the direct expenditure.  \nAs for the rest of columns they have so much missing data ( 69%+ missing values ). In this case, dropping them would be much more usefull then processing them with no evidence of having an impact on the dataframe it self","f57a115d":"Inspired by [Trupti Mamlekar](https:\/\/www.kaggle.com\/truptimamlekar), link to his : [NoteBook](https:\/\/www.kaggle.com\/truptimamlekar\/worlduniversityranking)","3aa3c2c8":"Creating new `Score` Column that has the mean value of the rest of the scoring columns which will give a better score.","2073e883":"# cwurData","46c25df2":"**Cleaning the Data**  \nJust as before this dataFrame is already ranked as the previous one ( ShanghaiData ) so the`Female_male_ratio` column that has the most `missing` values ( `233 out of 2603 by 14` ) is already sorted.  \nwhat I mean is, if you take a close look on this missing value you will find out that they are close to each other like Rank 1, 2 and 3 universities ( NaN , 33:67, 33:67 ) so it is best ( in my opinion ) to replace the `NaNs` with the next value.\nSimirlary with the `international_students`  `num_students` and `student_staff_ratio` for the same reason mentioned before.  \n**PN**: I know it is the same approach used in the shanghaiData but i could'nt find any better, maybe because I lack experience which is True, but i m doing this to get Exp. **Please if you have a better approach drop a comment**.  \nThank You!","d3e59114":"# Times Data","5e7ed203":"**Ploting Shanghai Data**","3dfc7da0":"# Investegating the problem\n\nAfter spending some times searching on `How the Universities are ranked`.  \n\nI found several factors judging the universities rank based on different factors and visions **From wikipedia's [College and university rankings](https:\/\/en.wikipedia.org\/wiki\/College_and_university_rankings)**  \n- `Global research reputation`, `publications`, and the `number of highly cited papers`.  \n- `Human Resources & Labor Review`: measure the performance of top 300 universities' graduates, `HRLR` remains to be the `leader in university ranking` with innovative and comprehensive approaches  \n- `Nature Index`: tracks the affiliations of `high-quality scientific articles` published in 68 science journals independently chosen by the scientific community as the journals scientists would most like to publish their best research in.   \n- `G-factor`: in social network theory terminology, G-factor measures the `centrality of each university's website` in the network of university websites  \n- `Regional and national rankings`: carried out in Africa, Asia, Europe, North America, South America and Oceania.  \n- [Forbes College rankings](https:\/\/en.wikipedia.org\/wiki\/College_and_university_rankings#:~:text=Forbes%20College%20rankings): `Student satisfaction` constitutes 25% of the score, `Post-graduate success` 32.5% of the score, `Student debt loads` 25% of the score, `Graduation rate` 7.5% of the score, `Academic success` 10% of the score.  \n\nAlso... after spending some time look in the data files, I decied to eliminate the data file :  \n- **educational_attainment_supplementary_data.csv** for Not having usefull data and containing **much NaN values** according to the DataSet description\n\n\n","27f40e85":"**Count of Universities per country**  \ndisplying top 10 ranked universities's countries with most universities  \n( as example : rank 1 Harvard University ' s Country : USA ===> display number of universities of USA )  \n**Special thanks to** Mert Altunay [Notebooks Expert](https:\/\/www.kaggle.com\/nihalbey)","de735c61":"**Great!** The Data is fully cleaned and ready to be used!  \nBut.. it requires more processing","d38740bd":"**Cleaning the Data**","83b66653":"# Education Expenditure Supplementary Data\n**Detailed review**","a0f069fa":"**Ploting TimesData**","384a14ea":"**DONE!**  \nTime for ploting","06b2e1b7":"**dropping the broad_impact column** with the most missing values\n","95e2749d":"international , income ,total_score and num_students must be int or float too .......\n","b5f8e0cd":"# Prediction: prediction of country's universities rank range, on **CwurData** ","70b323c5":"Since ShanghaiData does'nt have much NaN values in most of its column ,`changing these NaNs` with `0` wont miss up the quality of the data ( except for `total_score` column it will be dropped because it has so much missing data `almost 70% of the column is missing` )","e2056c17":"**The Reason why i replaced the NaNs with the next value** is that the shanghaiData is already ranked so the scores values in the column are close to each other ( i guess, but not pretty sure i just took a look on them xD, like 99.8 is pretty close to 100 right ? ) ","0ea8562e":"# shanghai Data","8acee972":"`num_students` column is an exceptional case, because it has `','` instead of `'.'`","6b4adec1":"**Universities's ranks evoluation per year**","bd6a4d8e":"**Other small Problem .... :**  \nWe must get ride of the `%` in the `international_students` column and make it Int dType.","57cc9193":"# Investegating the Data\n**Detailed Missing Values counts**","66f9b415":"Could'nt find out how to plot the count of institue type per country tried different kind of plot but they all went wrong.\nPlease if you have any suggestion leave a comment."}}