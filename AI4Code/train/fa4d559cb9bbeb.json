{"cell_type":{"fb60af32":"code","8f3520f1":"code","196efc5e":"code","a64c15b9":"code","da546511":"code","9998e1d1":"code","443e0fe4":"code","72d5edf8":"code","a72c294f":"code","450e4bfc":"code","7e0a6336":"code","ff444912":"code","301a9afc":"code","cc79814a":"code","305666ea":"markdown","551e6ac2":"markdown","8f0b66be":"markdown","b67a793a":"markdown","18975022":"markdown","cb4d00fd":"markdown","a3332fbd":"markdown","d9337f08":"markdown","e625bb3d":"markdown","39ad1327":"markdown","f583176d":"markdown","cf33e89e":"markdown","94306d6b":"markdown"},"source":{"fb60af32":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\n\nimport jax\nimport jax.numpy as jnp\nfrom jax import random\nfrom jax import make_jaxpr\nfrom jax.config import config\nfrom jax import value_and_grad\nfrom jax import grad, vmap, pmap, jit\nfrom jax.example_libraries import stax\nfrom jax.example_libraries.stax import (\n    Conv, Dense, MaxPool, Relu, Flatten, LogSoftmax, BatchNorm\n)\nfrom jax.example_libraries import optimizers\n\nnp.random.seed(1234)\n%config IPCompleter.use_jedi = False","8f3520f1":"# The downloaded dataset consists of two tuples. The first\n# tuple represents the training data consisting of pairs of images\n# and labels. Similary, the second tuple consists of validation\/test data.\n# I will use the second tuple as the validation data for this demo\n\n(x_train, y_train), (x_valid, y_valid) = cifar10.load_data()\nprint(f\"\\nNumber of training samples: {len(x_train)} with samples shape: {x_train.shape[1:]}\")\nprint(f\"Number of validation samples: {len(x_valid)} with samples shape: {x_valid.shape[1:]}\")\n\n\n# There are 10 classes in this dataset. We will create a dictionary for\n# mapping the names of the classes represented by the integer labels\n# Labels dictionary\nlabels_dict = {\n    0: \"airplane\",\n    1: \"automobile\",\n    2: \"bird\",\n    3: \"cat\",\n    4: \"deer\",\n    5: \"dog\",\n    6: \"frog\",\n    7: \"horse\",\n    8: \"ship\",\n    9: \"truck\"\n}","196efc5e":"def plot_samples(x, y, figsize=(12, 8), num_rows=5, num_columns=3, title=None):\n    \"\"\"Plots images with labels as desrciptons.\n    \n    Args:\n        x: Batch of images represented as ndarray\n        y: Batch of correspondning labels\n        figsize: Plot size\n        num_rows: Number of rows in the plot\n        num_columns: Number of columns in the plot\n        title: Title of the plot (if any). Defaults to `None`\n    \"\"\"\n    \n    if len(x) != len(y):\n        raise ValueError(\"Number of images and number of labels don't match!\")\n    \n    _, ax = plt.subplots(num_rows, num_columns, figsize=figsize)\n    \n    for i in range(num_rows * num_columns):\n        try:\n            img = x[i]\n            label = str(y[i])\n            ax[i \/\/ num_columns, i % num_columns].imshow(img)\n            ax[i \/\/ num_columns, i % num_columns].set_title(label)\n            ax[i \/\/ num_columns, i % num_columns].axis(\"off\")\n        except:\n            pass\n    \n    if title:\n        plt.suptitle(str(title))\n    plt.show()","a64c15b9":"# Select random indices in the range [0, len(training_data) - 1]\nsample_size = 15\nindices = np.arange(len(x_train))\nrandom_idx = np.random.choice(indices, size=(sample_size,))\n\n# Get the data corresponding to the selected indices\nrandomly_selected_images = x_train[random_idx]\nrandomly_selected_labels = y_train[random_idx]\n\n# We will map the integer labels to the class names using our labels dict\nrandomly_selected_labels = [labels_dict[i[0]] for i in randomly_selected_labels]\n\n# Plot randomly selected samples to check the data\nplot_samples(\n    x=randomly_selected_images,\n    y=randomly_selected_labels,\n    title=\"Random training samples\"\n)","da546511":"def rotate_90(img):\n    \"\"\"Rotates an image by 90 degress k times.\"\"\"\n    return jnp.rot90(img, k=1, axes=(0, 1))\n\n\ndef identity(img):\n    \"\"\"Returns an image as it is.\"\"\"\n    return img\n\n\ndef flip_left_right(img):\n    \"\"\"Flips an image left\/right direction.\"\"\"\n    return jnp.fliplr(img)\n\n\ndef flip_up_down(img):\n    \"\"\"Flips an image in up\/down direction.\"\"\"\n    return jnp.flipud(img)\n\n\ndef random_rotate(img, rotate):\n    \"\"\"Randomly rotate an image by 90 degrees.\n    \n    Args:\n        img: Array representing the image\n        rotate: Boolean for rotating or not\n    Returns:\n        Rotated or an identity image\n    \"\"\"\n\n    return jax.lax.cond(rotate, rotate_90, identity, img)\n\n\ndef random_horizontal_flip(img, flip):\n    \"\"\"Randomly flip an image vertically.\n    \n    Args:\n        img: Array representing the image\n        flip: Boolean for flipping or not\n    Returns:\n        Flipped or an identity image\n    \"\"\"\n    \n    return jax.lax.cond(flip, flip_left_right, identity, img)\n    \n    \ndef random_vertical_flip(img, flip):\n    \"\"\"Randomly flip an image vertically.\n    \n    Args:\n        img: Array representing the image\n        flip: Boolean for flipping or not\n    Returns:\n        Flipped or an identity image\n    \"\"\"\n    \n    return jax.lax.cond(flip, flip_up_down, identity, img)\n\n\n\n\n\n# All the above function are written to work on a single example. \n# We will use `vmap` to get a version of these functions that can\n# operate on a batch of images. We will also add the `jit` transformation\n# on top of it so that the whole pipeline can be compiled and executed faster\nrandom_rotate_jitted = jit(vmap(random_rotate, in_axes=(0, 0)))\nrandom_horizontal_flip_jitted = jit(vmap(random_horizontal_flip, in_axes=(0, 0)))\nrandom_vertical_flip_jitted = jit(vmap(random_vertical_flip, in_axes=(0, 0)))\n\n\ndef augment_images(images, key):\n    \"\"\"Augment a batch of input images.\n    \n    Args:\n        images: Batch of input images as a jax array\n        key: Seed\/Key for random functions for generating booleans\n    Returns:\n        Augmented images with the same shape as the input images\n    \"\"\"\n    \n    batch_size = len(images)\n    \n    # 1. Rotation\n    key, subkey = random.split(key)\n    rotate = random.randint(key, shape=[batch_size], minval=0, maxval=2)\n    augmented = random_rotate_jitted(images, rotate)\n    \n    # 2. Flip horizontally\n    key, subkey = random.split(key)\n    flip = random.randint(key, shape=[batch_size], minval=0, maxval=2)\n    augmented = random_horizontal_flip_jitted(augmented, flip)\n    \n    # 3. Flip vertically\n    key, subkey = random.split(key)\n    flip = random.randint(key, shape=[batch_size], minval=0, maxval=2)\n    augmented = random_vertical_flip_jitted(augmented, flip)\n    \n    return augmented","9998e1d1":"# Let's plot the augmented version of our randomly selected samples.\n# This will help us ensure that our augmentation pipeline is working\n# as expected.\n\n# Augment the images we selected randomly\nrandomly_selected_images_augmented = augment_images(\n    randomly_selected_images, key=random.PRNGKey(0)\n)\n\n# Plot the augmeneted samples\nplot_samples(\n    x=randomly_selected_images_augmented,\n    y=randomly_selected_labels,\n    title=\"Random training samples augmneted\"\n)","443e0fe4":"# Normalize the image pixels in the range [0, 1]\nx_train_normalized = jnp.array(x_train \/ 255.)\nx_valid_normalized = jnp.array(x_valid \/ 255.)\n\n# One hot encoding applied to the labels. We have 10\n# classes in the dataset, hence the depth of OHE would be 10\ny_train_ohe = jnp.squeeze(jax.nn.one_hot(y_train, num_classes=10))\ny_valid_ohe = jnp.squeeze(jax.nn.one_hot(y_valid, num_classes=10))\n\nprint(f\"Training images shape:   {x_train_normalized.shape}  Labels shape: {y_train_ohe.shape}\")\nprint(f\"Validation images shape: {x_valid_normalized.shape}  Labels shape: {y_valid_ohe.shape}\")","72d5edf8":"def data_generator(images, labels, batch_size=128, is_valid=False, key=None):\n    \"\"\"Generates batches of data from a given dataset.\n    \n    Args:\n        images: Image data represented by a ndarray\n        labels: One-hot enocded labels\n        batch_size: Number of data points in a single batch\n        is_valid: (Boolean) If validation data, then don't shuffle and\n                    don't apply any augmentation\n        key: PRNG key needed for augmentation\n    Yields:\n        Batches of images-labels pairs\n    \"\"\"\n    \n    # 1. Calculate the total number of batches\n    num_batches = int(np.ceil(len(images) \/ batch_size))\n    \n    # 2. Get the indices and shuffle them\n    indices = np.arange(len(images))\n    \n    if not is_valid:\n        if key is None:\n             raise ValueError(\"A PRNG key is required if `aug` is set to True\")\n        else:\n            np.random.shuffle(indices)\n    \n    for batch in range(num_batches):\n        curr_idx = indices[batch * batch_size: (batch+1) * batch_size]\n        batch_images = images[curr_idx]\n        batch_labels = labels[curr_idx]\n        \n        if not is_valid: \n            batch_images = augment_images(batch_images, key=key)\n        yield batch_images, batch_labels\n        \n        \n\n# Sanity Check: To make sure that the batches generated by the data\n# generator are of correct size, we will just pull a batch of data and\n# will check the shape of the images and the labels\n\nsample_data_gen = data_generator(\n    images=x_train_normalized,\n    labels=y_train_ohe,\n    batch_size=8,\n    is_valid=False,\n    key=random.PRNGKey(0)\n)\n\nsample_batch_images, sample_batch_labels = next(sample_data_gen)\nprint(\"Batch of images is of shape: \", sample_batch_images.shape)\nprint(\"Batch of labels is of shape: \", sample_batch_labels.shape)\n\n# Clean up unnecessary objects\ndel sample_data_gen, sample_batch_images, sample_batch_labels","a72c294f":"# Use stax to set up the model\nnet_init, net_apply = stax.serial(\n    Conv(32, (3, 3), padding='SAME'),\n    Relu,\n    Conv(64, (3, 3), padding='SAME'),\n    Relu,\n    Conv(128, (3, 3), padding='SAME'),\n    Relu,\n    Conv(256, (3, 3), padding='SAME'),\n    Relu,\n    MaxPool((2, 2)),\n    Flatten,\n    Dense(128),\n    Relu,\n    Dense(10),\n    LogSoftmax,\n)\n\n\n# We have defined our model. We need to initialze the params based on the input shape.\n# The images in our dataset are of shape (32, 32, 3). Hence we will initialize the \n# network with the input shape (-1, 32, 32, 3). -1 represents the batch dimension here\nnet_out_shape, net_params = net_init(random.PRNGKey(111), input_shape=(-1, 32, 32, 3))","450e4bfc":"def loss_fn(params, batch_data):\n    \"\"\"Implements cross-entropy loss function.\n    \n    Args:\n        params: Parameters of the network\n        batch_data: A batch of data (images and labels)\n    Returns:\n        Loss calculated for the current batch\n    \"\"\"\n    inputs, targets = batch_data\n    preds = net_apply(params, inputs)\n    return -jnp.mean(jnp.sum(preds * targets, axis=1))\n\n\ndef calculate_accuracy(params, batch_data):\n    \"\"\"Implements accuracy metric.\n    \n    Args:\n        params: Parameters of the network\n        batch_data: A batch of data (images and labels)\n    Returns:\n        Accuracy for the current batch\n    \"\"\"\n    inputs, targets = batch_data\n    target_class = jnp.argmax(targets, axis=1)\n    predicted_class = jnp.argmax(net_apply(params, inputs), axis=1)\n    return jnp.mean(predicted_class == target_class)\n\n\n# We will jit the train and test steps to make them more efficient\n@jit\ndef train_step(step, opt_state, batch_data):\n    \"\"\"Implements train step.\n    \n    Args:\n        step: Integer representing the step index\n        opt_state: Current state of the optimizer\n        batch_data: A batch of data (images and labels)\n    Returns:\n        Batch loss, batch accuracy, updated optimizer state\n    \"\"\"\n    params = get_params(opt_state)\n    batch_loss, batch_gradients = value_and_grad(loss_fn)(params, batch_data)\n    batch_accuracy = calculate_accuracy(params, batch_data)\n    return batch_loss, batch_accuracy, opt_update(step, batch_gradients, opt_state)\n\n\n@jit\ndef test_step(opt_state, batch_data):\n    \"\"\"Implements train step.\n\n    Args:\n        opt_state: Current state of the optimizer\n        batch_data: A batch of data (images and labels)\n    Returns:\n        Batch loss, batch accuracy\n    \"\"\"\n    params = get_params(opt_state)\n    batch_loss = loss_fn(params, batch_data)\n    batch_accuracy = calculate_accuracy(params, batch_data)\n    return batch_loss, batch_accuracy","7e0a6336":"LEARNING_RATE = 1e-4\n\n# Get the optimizer objects\nopt_init, opt_update, get_params = optimizers.adam(step_size=LEARNING_RATE)\n\n# Initialize the state of the optimizer using the parameters\nopt_state = opt_init(net_params)","ff444912":"EPOCHS = 30\nBATCH_SIZE = 128\n\n# Initial rng key for the data generator\nkey = random.PRNGKey(0)\n\n# Lists to record loss and accuracy for each epoch\ntraining_loss = []\nvalidation_loss = []\ntraining_accuracy = []\nvalidation_accuracy = []\n\n# Training \nfor i in range(EPOCHS):\n    num_train_batches = len(x_train) \/\/ BATCH_SIZE\n    num_valid_batches = len(x_valid) \/\/ BATCH_SIZE\n    \n    # Lists to store loss and accuracy for each batch\n    train_batch_loss, train_batch_acc = [], []\n    valid_batch_loss, valid_batch_acc = [], []\n    \n    # Key to be passed to the data generator for augmenting\n    # training dataset\n    key, subkey = random.split(key)\n    \n    # Initialize data generators\n    train_data_gen = data_generator(x_train_normalized,\n                                y_train_ohe,\n                                batch_size=BATCH_SIZE,\n                                is_valid=False,\n                                key=key\n                               )\n\n    valid_data_gen = data_generator(x_valid_normalized,\n                               y_valid_ohe,\n                               batch_size=BATCH_SIZE,\n                               is_valid=True\n                               )\n    \n    print(f\"Epoch: {i+1:<3}\", end=\" \")\n    \n    # Training\n    for step in range(num_train_batches):\n        batch_data = next(train_data_gen)\n        loss_value, acc, opt_state = train_step(step, opt_state, batch_data)\n        train_batch_loss.append(loss_value)\n        train_batch_acc.append(acc)\n    \n    # Evaluation on validation data\n    for step in range(num_valid_batches):\n        batch_data = next(valid_data_gen)\n        loss_value, acc = test_step(opt_state, batch_data)\n        valid_batch_loss.append(loss_value)\n        valid_batch_acc.append(acc)\n    \n    # Loss for the current epoch\n    epoch_train_loss = np.mean(train_batch_loss)\n    epoch_valid_loss = np.mean(valid_batch_loss)\n    \n    # Accuracy for the current epoch\n    epoch_train_acc = np.mean(train_batch_acc)\n    epoch_valid_acc = np.mean(valid_batch_acc)\n    \n    training_loss.append(epoch_train_loss)\n    training_accuracy.append(epoch_train_acc)\n    validation_loss.append(epoch_valid_loss)\n    validation_accuracy.append(epoch_valid_acc)\n    \n    print(f\"loss: {epoch_train_loss:.3f}   acc: {epoch_train_acc:.3f}  valid_loss: {epoch_valid_loss:.3f}  valid_acc: {epoch_valid_acc:.3f}\")","301a9afc":"# Let's plot the training and validataion losses as well as\n# accuracies for both the dataset. \n\n_, ax = plt.subplots(1, 2, figsize=(15, 8))\nax[0].plot(range(1, EPOCHS+1), training_loss)\nax[0].plot(range(1, EPOCHS+1), validation_loss)\nax[0].set_xlabel(\"Epochs\")\nax[0].legend([\"Training loss\", \"Validation loss\"])\n\nax[1].plot(range(1, EPOCHS+1), training_accuracy)\nax[1].plot(range(1, EPOCHS+1), validation_accuracy)\nax[1].set_xlabel(\"Epochs\")\nax[1].legend([\"Training accuracy\", \"Validation accuracy\"])\n\nplt.show()","cc79814a":"# Select some samples randomly from the validation data\nnp.random.seed(0)\nrandom_idx = np.random.choice(np.arange(len(x_valid_normalized)), size=16)\nrandom_valid_samples = x_valid_normalized[random_idx], y_valid_ohe[random_idx]\n\n# Get the updated parameters from the optimizer\nparams = get_params(opt_state)\n\n# Calculate the accuracy for these samples\nacc = calculate_accuracy(params, random_valid_samples)\npredicted_class = jnp.argmax(net_apply(params, random_valid_samples[0]), axis=1)\n\n# Map the predicted class to the original class names\npredicted_class = [labels_dict[pred] for pred in predicted_class]\n\n# Plot the samples along with the predictions\nprint(f\"Accuracy on randomly selected sample of size {len(random_idx)} is {acc*100:.2f} %\\n\")\nplot_samples(x=x_valid[random_idx], y=predicted_class, num_rows=4, num_columns=4, title=\"Predictions\")","305666ea":"# Data Augmentation\n\nWe will apply image augmentation, and that too, purely in JAX. For augmentation, we will be using three different augmentation techniques:\n1. Random rotation by 90 degrees\n2. Random horizontal flips\n3. Random vertical flips\n\nFor each of these augmentations:\n1. We will define a function that will either return an augmented image or an identity image\n2. Use [**vmap**](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part-8-vmap-pmap#Data-Augmentation---Building-a-simple,-fast,-and-scalable-pipeline) to do augmentation in batches\n3. [**jit**](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part-7-jit-in-jax) the whole augmentation pipeline","551e6ac2":"# Data Generator\n\nNow that we have preprocessed our dataset, we need to define our data generator that will stream batches of data, where each batch is a pair of images and the corresponding labels. We will apply data augmentation to the training data only.","8f0b66be":"# Pros and Cons\n\nNow that we have built a classifier purely in JAX. Let's talk about the pros and cons of this approach.\n\n## Pros\n1. Everything in this approach is modeled as a function, including the layers, the models, and the optimizers\n2. Because of the above fact, it is very straightforward to code the whole thing in a single module\n3. Super flexible and provides full control to the end-user. Easy to define new layers, optimizers, etc\n\n## Cons\n1. Building a model in OOP style as done in Keras is cleaner and much better IMO compared to functional all the way\n2. Doesn't give you information on the input shape, output shape, and the connections of the layers in a nicely formatted table as provided by Keras. Also, there is no easy way to name the layers used in the model\n3. Some layers behave differently at the test stage as compared to the training stage, e.g. BatchNorm. It isn't very clear from the documentation how to enable that behavior. \n4. What if I have to add L2 regularization to the layers? \n\nTo be fair, **Stax** isn't supposed to be a full-fledged high-level API for building models in JAX because of two reasons:\n1. It is still *experimental*\n2. It is minimal yet very flexible. It can serve as a reference point if you want to develop a new high-level API for JAX\n\n\nI hope you enjoyed the tutorial! Please let me know in the comments section if you have any questions\/feedback.\n\n\n# References\n1. https:\/\/jax.readthedocs.io\/en\/latest\/\n2. https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html\n3. https:\/\/keras.io\/\n4. https:\/\/github.com\/google\/jax\/blob\/main\/jax\/example_libraries\/stax.py","b67a793a":"We have defined the model but we need a few more things before we start traninig:\n1. We need to define a loss function (cross-entropy in our case)\n2. We need to deine a metric to monitor the performance (accuracy in this case)\n3. We need to define the `train` and `test` steps","18975022":"# Introduction\n\nHello Kagglers, I hope you are doing well. As we all know that there is an ongoing [Google Open Source Expert Prize](https:\/\/www.kaggle.com\/google-oss-expert-prize?s=09) challenge live on Kaggle. Hence, I thought to contribute to the same. I am starting a whole new series of tutorials where we will learn about the existing methods of building models in JAX. In this tutorial, we are going to build an image classifier purely in JAX. Here is the list of things that we will cover in this notebook:\n\n1. Use the Cifar-10 dataset for training the classifier\n2. Build a classifier purely in JAX using no library other than JAX\n3. Data augmentation purely in JAX\n4. Create a custom training\/testing loop in the most simplified manner\n5. Discuss the pros and cons of this approach\n\nIf you don't know the fundamentals of TensorFlow\/JAX, you can use these [notebooks](https:\/\/www.kaggle.com\/general\/296640) to get a solid understanding of both the frameworks. Without any further due, let's start!","cb4d00fd":"# Training\n\nLet's train our model for a few epochs. We will record the loss and accuracy for both the training data and validation data for each epoch","a3332fbd":"# Sanity Check\n\nNow that we have our plotting utility, the first sanity check we will do is check the image data and the corresponding labels. To do so, we will perform the following steps:\n\n1. We will randomly choose `n` numbers in the range `[0, len(training data) - 1]`\n2. Based on the chosen indices, we will extract the images and the corresponding samples from the training data\n3. Plot the randomly selected samples using our plotting utility for the sanity check","d9337f08":"Perfect! The augmentation pipeline is working as expected. Let's move to the next step.\n\n# Data Preprocessing\n\nFor data preprocessing, we will apply these two things:\n1. We will normalize the image data so that the pixel values for each image is in the range `[0, 1]`\n2. We will one-hot encode our labels","e625bb3d":"# Plotting Utility\n\nWhenever we deal with image data, a few steps related to data processing are always the same. The two most common of them are:\n1. Check the raw image data and the corresponding labels to ensure that the labels are correct\n2. Plot the augmented samples to ensure that the image augmentation pipeline is correct\n\nBoth the steps require the plotting of the samples. Hence, we will define a plotting utility to reuse for these steps.","39ad1327":"# Evaluation\n\nLet's take a batch of random samples from the validation data. Check how many of them we can predict correctly, and let's plot the images in the selected batch, along with the predicted labels for the same.","f583176d":"# Model\n\nNow that we have a data streamer that yields batches of preprocessed data, the next step is to define our model (neural network in this case). For this notebook, we are going to use only JAX and no other library. We will be using the `experimental` **Stax** module that offers some commonly used NN functionalities. For documentation on stax, please check out this [page](https:\/\/github.com\/google\/jax\/blob\/main\/jax\/example_libraries\/stax.py)\n\n**Note:** Any experimental module is supposed to be changed shortly in some ways. Hence, it is not recommended to use it for any big project as the future versions may include some breaking changes.\n\n\nUsing `stax`, we can stack layers to define our model. Each layer constructor function returns an `(init_fun, apply_fun)` functions pair, where\n1. **init_fun**: Takes an rng key and an input shape and returns an `(output_shape, params)` pair\n2. **apply_fun**: Takes params, inputs, and an rng key and applies the layer (forward pass)\n\nWhen we stack layers using `stax.serial(...)`, the whole stacked module is just another layer that returns another `(init_fun, apply_fun)` pair. Let's see it in action.","cf33e89e":"# Dataset\n\nWe will use the Cifar-10 dataset for this experiment. You can download it or add it from Kaggle as well, but I am directly importing it from the available `tf.keras.datasets` for the sake of simplicity and brevity","94306d6b":"# Optimizer\nWe have implemented everything related to the model. All we need is an `optimizer` to optimize the parameters of our model. We will be using the optimizers defined in this module for [this](https:\/\/github.com\/google\/jax\/blob\/main\/jax\/example_libraries\/optimizers.py) demo. Again, it's experimental and can change shortly.\n\nThe optimizers in the [optimizer module](https:\/\/github.com\/google\/jax\/blob\/main\/jax\/example_libraries\/optimizers.py) are modeled aa a combination of three different funcations:\n\n1. **init_fun**: Initialize the optimizer state\n   - Args\n       - params: Model parameters\n   - Returns <br>\n       - Pytree representing the initial optimizer state\n \n2. **update_fun**: Updates the optimizer state\n    - Args\n        - step: Integer representing the step index.\n        - grads: Gradients to be used for updating the optimizer state\n        - opt_state: A pytree representing the optimizer state to be updated\n    - Returns\n        - Updated optimizer state as another pytree\n\n3. **get_params**: Extracts the current state of the optimizer as a pytree\n    - Args\n        - opt_state: A pytree representing the optimizer state to be updated\n    - Returns\n        Current state of the optimizer\n        \n\nIn our experiment, we will use the `Adam` optimizer. Let's initialize the same using the parameters of our model"}}