{"cell_type":{"576f90f8":"code","ea54fd11":"code","1200b6b7":"code","7fbbd711":"code","02f7a0c5":"code","d592369f":"code","7d447d04":"code","326d48b2":"code","b7c04280":"code","f3002335":"code","9f5723b7":"code","c3e9445e":"code","27aaa532":"code","402f0853":"code","78a39693":"code","6b479343":"code","4e5b3e91":"markdown","857a327b":"markdown","0176d460":"markdown","0f74b8c3":"markdown","c7ca052b":"markdown","d2af776a":"markdown","351e4d92":"markdown"},"source":{"576f90f8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ea54fd11":"import pandas as pd\ndata_csv = pd.read_csv(\"\/kaggle\/input\/temperature-and-flower-status\/hirosaki_temp_cherry_bloom.csv\")\ndf = pd.DataFrame(data_csv)\n\n# Split date into year,month,day\ndateList = df['date'].str.split('\/', expand=True)\ndf['year'], df['month'], df['day'] = dateList[0], dateList[1], dateList[2]\ndf.info()","1200b6b7":"# o:Before blooming\n# 1:Bloom\n# 2:Full bloom\n# 3:Scatter\n\nnew_df = []\nfor i in range(len(df)):\n    year, month, day = df['year'][i], df['month'][i], df['day'][i]\n    temperature = df['temperature'][i]\n    flower_status = df['flower_status'][i]\n    if month == '1' and day == '1':\n        status = 0\n    else:\n        if flower_status == 'bloom':\n            status = 1\n        elif flower_status == 'full':\n            status = 2\n        elif flower_status == 'scatter':\n            status = 3\n    innerList = {'year':year, 'month':month, 'day':day, 'temperature':temperature, 'flower_status':status}\n    new_df.append(innerList)\nnew_df = pd.DataFrame(new_df)\nnew_df","7fbbd711":"# Extract data from March 1 to May 31\nnew_df_2 = []\nfor i in range(len(new_df)):\n    month = new_df['month'][i]\n    if month == '3' or month == '4' or month == '5':\n        innerList = {'month':month, 'day':new_df['day'][i], 'temperature':new_df['temperature'][i], 'flower_status':new_df['flower_status'][i]}\n        new_df_2.append(innerList)\nnew_df_2 = pd.DataFrame(new_df_2)\nnew_df_2","02f7a0c5":"# Add the cumulative temperature to the column\nnew_df_3 = []\nfor i in range(len(new_df_2)):\n    month, day = new_df_2['month'][i], new_df_2['day'][i]\n    if month == '3' and day == '1':\n        temp_accum = 0\n    temp = new_df_2['temperature'][i]\n    temp_accum += temp\n    status = new_df_2['flower_status'][i]\n    innerList = {'month':month, 'day':day, 'temperature':temp, 'temp_accum':temp_accum, 'flower_status':status}\n    new_df_3.append(innerList)\nnew_df_3 = pd.DataFrame(new_df_3)\nnew_df_3","d592369f":"x = pd.DataFrame(new_df_3.drop('flower_status', axis = 1))\nt = pd.DataFrame(new_df_3['flower_status'])\nx = np.array(x)\nt = np.array(t)\n\nt = t.ravel()\nx = x.astype('float32')\nt = t.astype('int32')\n\n# \u4e2d\u3092\u78ba\u8a8d\nprint('x shape:', x.shape) # (n, m)\nprint(x[:10])\nprint('t shape:', t.shape) # (n,)\nprint(t[:10])","7d447d04":"# TupleDataset\nfrom chainer.datasets import TupleDataset\ndataset = TupleDataset(x, t)\nfrom chainer.datasets import split_dataset_random\ntrain_val, test = split_dataset_random(dataset, int(len(dataset) * 0.8), seed=0)\ntrain, valid = split_dataset_random(train_val, int(len(train_val) * 0.7), seed=0)\n\nfrom chainer.iterators import SerialIterator\ntrain_iter = SerialIterator(train, batch_size=32, repeat=True, shuffle=True)\n\nprint(dataset[0])","326d48b2":"import chainer\nimport chainer.links as L\nimport chainer.functions as F\n\nclass Net(chainer.Chain):\n\n    def __init__(self, n_in=4, n_hidden=100, n_out=4):\n        super().__init__()\n        with self.init_scope():\n            self.l1 = L.Linear(n_in, n_hidden)\n            self.l2 = L.Linear(n_hidden, n_hidden)\n            self.l3 = L.Linear(n_hidden, n_out)\n\n    def forward(self, x):\n        h = F.relu(self.l1(x))\n        h = F.relu(self.l2(h))\n        h = self.l3(h)\n        return h\n\nnet = Net()\n\nfrom chainer import optimizers\nfrom chainer.optimizer_hooks import WeightDecay\noptimizer = optimizers.Adam(alpha=0.0001,\n                            beta1=0.9,\n                            beta2=0.999,\n                            eps=1e-08,\n                            eta=1.0,\n                            weight_decay_rate=0.00001,\n                            amsgrad=False,\n                            adabound=False,\n                            final_lr=0.1,\n                            gamma=0.001)\noptimizer.setup(net)\n\ngpu_id = 0\nn_epoch = 2500\n\nnet.to_gpu(gpu_id)\n\nresults_train, results_valid = {}, {}\nresults_train['loss'], results_train['accuracy'] = [], []\nresults_valid['loss'], results_valid['accuracy'] = [], []\n\ntrain_iter.reset()\n\ncount = 1\n\nfor epoch in range(n_epoch):\n    while True:\n        train_batch = train_iter.next()\n        x_train, t_train = chainer.dataset.concat_examples(train_batch, gpu_id)\n        y_train = net(x_train)\n        loss_train = F.softmax_cross_entropy(y_train, t_train)\n        acc_train = F.accuracy(y_train, t_train)\n        net.cleargrads()\n        loss_train.backward()\n        optimizer.update()\n        count += 1\n\n        if train_iter.is_new_epoch:\n            with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n                x_valid, t_valid = chainer.dataset.concat_examples(valid, gpu_id)\n                y_valid = net(x_valid)\n                loss_valid = F.softmax_cross_entropy(y_valid, t_valid)\n                acc_valid = F.accuracy(y_valid, t_valid)\n            loss_train.to_cpu()\n            loss_valid.to_cpu()\n            acc_train.to_cpu()\n            acc_valid.to_cpu()\n            if epoch % 10 == 0:\n                print('epoch: {}, iteration: {}, loss(train): {:.4f}, loss(valid): {:.4f}, '\n                'acc(train): {:.4f}, acc(valid): {:.4f}'.format(\n                    epoch, count, loss_train.array.mean(),loss_valid.array.mean(),\n                    acc_train.array.mean(), acc_valid.array.mean()))\n    \n            results_train['loss'].append(loss_train.array)\n            results_train['accuracy'].append(acc_train.array)\n            results_valid['loss'].append(loss_valid.array)\n            results_valid['accuracy'].append(acc_valid.array)\n\n            break\n","b7c04280":"# Graph\nimport matplotlib.pyplot as plt\n\n# lose\nplt.plot(results_train['loss'], label='train')\nplt.plot(results_valid['loss'], label='valid')\nplt.title('Graph(loss)')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend()\nplt.show()\n\n# accuracy\nplt.plot(results_train['accuracy'], label='train')\nplt.plot(results_valid['accuracy'], label='valid')\nplt.title('Graph(accuracy)')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","f3002335":"# Calculate loss and accuracy\nx_test, t_test = chainer.dataset.concat_examples(test, device=gpu_id)\nwith chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n    y_test = net(x_test)\n    loss_test = F.softmax_cross_entropy(y_test, t_test)\n    acc_test = F.accuracy(y_test, t_test)\nprint('test loss: {:.4f}'.format(loss_test.array.get()))\nprint('test accuracy: {:.4f}'.format(acc_test.array.get()))","9f5723b7":"# Save network\nnet.to_cpu()\nchainer.serializers.save_npz('net.npz', net)\n\n# Check\n!ls net.npz","c3e9445e":"# data from Japan Meteorological Agency (Actual and 2-week forecast)\nimport pandas as pd\npre_csv = pd.read_csv('\/kaggle\/input\/hirosaki-this-year\/hirosaki_this_year.csv')\npre_df = pd.DataFrame(pre_csv)\n# Split date into year,month,day\ndateList = pre_df['date'].str.split('\/', expand=True)\npre_df['year'], pre_df['month'], pre_df['day'] = dateList[0], dateList[1], dateList[2]\npre_df.info()","27aaa532":"# Fill in missing values by predicting future temperatures from differences between past average and this year\nnew_df_4 = []\nfor i in range(len(new_df)):\n    year, month, day, temperature = new_df['year'][i], new_df['month'][i], new_df['day'][i], new_df['temperature'][i]\n    # cut Feb 29\n    if month == '2' and day == '29':\n        dummy = ''\n    else:\n        innerList = {'year':year, 'month':month, 'day':day, 'temperature':temperature}\n        new_df_4.append(innerList)\nnew_df_4 = pd.DataFrame(new_df_4)\nary_diff = []\nfor i in range(len(pre_df)):\n    m = pre_df['month'][i]\n    d = pre_df['day'][i]\n    if m == '2' and d == '29':\n        dummy = ''\n    else:\n        if pd.isnull(pre_df['temperature'][i]):\n            break\n        else:\n            # Temperature of this year\n            pre_temp = pre_df['temperature'][i]\n            # Average temperature of past year(Same month and same day)\n            df_m = new_df_4[new_df_4['month'] == m]\n            df_m_d = df_m[df_m['day'] == d]\n            temp_mean = df_m_d['temperature'].mean()\n            # Difference between this year and average\n            diff = pre_temp - temp_mean\n            ary_diff.append(diff)\nary_diff = pd.DataFrame(ary_diff)\n# Overall average of difference\ndiff_mean = ary_diff.mean()\npre_df_2 = []\nfor i in range(len(pre_df)):\n    y = pre_df['year'][i]\n    m = pre_df['month'][i]\n    d = pre_df['day'][i]\n    if pd.isnull(pre_df['temperature'][i]):\n        # Predicted temperature\n        df_m = new_df_4[new_df_4['month'] == m]\n        df_m_d = df_m[df_m['day'] == d]\n        temp_mean = df_m_d['temperature'].mean()\n\n\n#--------------------------------------------------------\n        weight = 1\n        # Change as needed\n        # Usually 1\n#--------------------------------------------------------\n\n\n        add = int(diff_mean * weight * 1000) \/ 1000\n        temperature = temp_mean + add\n    else:\n        # Actual temperature\n        temperature = pre_df['temperature'][i]\n    inner_dic = {'year':y, 'month':m, 'day':d, 'temperature':temperature}\n    pre_df_2.append(inner_dic)\npre_df_2 = pd.DataFrame(pre_df_2)\npre_df_2","402f0853":"print('Average temperature rise:', add)","78a39693":"# Add the cumulative temperature to the column\nnew_pre_df = []\ntemp_accum = 0\nfor i in range(len(pre_df)):\n    year, month, day = pre_df_2['year'][i], pre_df_2['month'][i], pre_df_2['day'][i]\n    if int(month) >= 3:\n        temperature = pre_df_2['temperature'][i]\n        temp_accum += temperature\n        innerList = [month, day, temperature, temp_accum]\n        new_pre_df.append(innerList)\nnew_pre_df = pd.DataFrame(new_pre_df)\nnew_pre_df","6b479343":"import chainer\nimport chainer.links as L\nimport chainer.functions as F\n\nclass newNet(chainer.Chain):\n    def __init__(self,n_in=4, n_hidden=100, n_out=4):\n        super().__init__()\n        with self.init_scope():\n            self.l1 = L.Linear(n_in, n_hidden)\n            self.l2 = L.Linear(n_hidden, n_hidden)\n            self.l3 = L.Linear(n_hidden, n_out)\n\n    def forward(self, x):\n        h = F.relu(self.l1(x))\n        h = F.relu(self.l2(h))\n        h = self.l3(h)\n        return h\n\nloaded_net = newNet()\n\nchainer.serializers.load_npz('net.npz', loaded_net)\n\nimport numpy as np\n\nnew_pre_df = np.array(new_pre_df)\nnew_pre_df = new_pre_df.astype('float32')\nwith chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n    result = loaded_net(new_pre_df)\n\n# If the status returns or jumps, it is judged as an error\n# If the learning rate is low, no results are displayed\ncount_bud, count_bloom, count_full, count_scatter = 0, 0, 0, 0\ndate_bloom, date_full, date_scatter = 'none', 'none', 'none'\nyear = pre_df['year'][0]\nfor i in range(len(new_pre_df)):\n    month = new_pre_df[i][0]\n    day = new_pre_df[i][1]\n    predict = np.argmax(result[i,:].array)\n    if i == 0:\n        count_bud += 1\n    else:\n        pre_predict = np.argmax(result[i - 1,:].array)\n        if predict != pre_predict:\n            if predict == 0:\n                count_bud += 1\n            elif predict == 1:\n                count_bloom += 1\n                date_bloom = '{}\/{}\/{}'.format(int(year), int(month), int(day))\n            elif predict == 2:\n                count_full += 1\n                date_full = '{}\/{}\/{}'.format(int(year), int(month), int(day))\n            elif predict == 3:\n                count_scatter += 1\n                date_scatter = '{}\/{}\/{}'.format(int(year), int(month), int(day))\n#    print(predict)\nif count_bud > 1:\n    print('ERROR !! (Over count \"Before blooming :', count_bud, '\")')\nif count_bloom > 1:\n    print('ERROR !! (Over count \"Bloom :', count_bloom, '\")')\nif count_full > 1:\n    print('ERROR !! (Over count \"Full :', count_full, '\")')\nif count_scatter > 1:\n    print('Error !! (Over count \"Scatter :', count_scatter, '\")')\nif count_bud == 1 and count_bloom == 1 and count_full == 1 and count_scatter == 1:\n    ratio_loss = loss_test.array.get()\n    ratio_acc = acc_test.array.get()\n    \n    # Set accuracy threshold\n    specified_loss = 0.1\n    specified_acc = 0.95\n    \n    if ratio_loss < specified_loss and ratio_acc > specified_acc:\n        print('Congratulations, the prediction is successful !!')\n        print('Bloom  :', date_bloom)\n        print('Full   :', date_full)\n        print('Scatter:', date_scatter)\n        # Time stamp\n        import time, datetime\n        today = datetime.datetime.fromtimestamp(time.time())\n        print(today.strftime('Time stamp: %Y\/%m\/%d %H:%M:%S (UTC)'))\n    else:\n        print('Low learning rate !!')\n        print('Accuracy rate :', ratio_acc, '(Specified rate :', specified_acc, ')')\n        print('Loss rate :', ratio_loss, '(Specified rate :', specified_loss, ')')\nelse:\n    print('ERROR !! (Missing status)')","4e5b3e91":"**1. Import training data**","857a327b":"# \"Chainer\" doesn't work, use .....\n# [\"Predict the blossoming date by scikit-learn\"](https:\/\/www.kaggle.com\/akioonodera\/predict-the-blossoming-date-by-scikit-learn)","0176d460":"**3. Shape after dividing temperature data and flowering status**","0f74b8c3":"**4. Learn with Chainer**","c7ca052b":"**2. Make up for missing 'flower_status' column**","d2af776a":"**5. Import data to predict**","351e4d92":"**6. Predict using the network**"}}