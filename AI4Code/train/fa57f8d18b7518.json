{"cell_type":{"afb45655":"code","90d001f8":"code","b28ee8cc":"code","60560a26":"code","a5498c1d":"code","e9fc5082":"code","4bb116b9":"code","fb7a811c":"code","5aa403ee":"code","a621682c":"code","f0b73e1c":"code","f5fadef5":"code","1ea08e39":"code","bae3f42a":"code","3672ac85":"code","75e5bb9e":"code","151d8c95":"code","7dd0d8b7":"code","435920f3":"code","f37f78fc":"code","f8de1a9f":"code","3dcc67cc":"code","20760320":"code","dcc9dec3":"code","510d0ead":"code","54fea127":"code","ef0fd65c":"code","056d767f":"code","fa58c703":"code","8d40ac9d":"code","e0c2491f":"code","62c506a1":"code","85a2f969":"code","fe4b7d5d":"code","3593a5d9":"code","b7cba2cd":"code","a031c144":"code","761aa989":"code","3b1ec873":"code","14f88f7b":"code","4fc456b6":"markdown","8961f59e":"markdown","56c1b1ab":"markdown","321a879c":"markdown","881a507e":"markdown","3d8c23e8":"markdown","26780642":"markdown","1e27cff3":"markdown","3a1ed849":"markdown","7a596d51":"markdown","e6f9a04a":"markdown","6da1d12d":"markdown","ab7e68eb":"markdown","ce69a270":"markdown","babd6ab1":"markdown","495670b2":"markdown","373192dd":"markdown"},"source":{"afb45655":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns #importing seaborn module \nimport warnings\nfrom collections import Counter\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler \nfrom sklearn import metrics\nfrom pandas import set_option\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score # to split the data\nfrom sklearn.metrics import explained_variance_score, median_absolute_error, r2_score, mean_squared_error, accuracy_score, confusion_matrix, classification_report, fbeta_score #To evaluate our model\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split # Model evaluation\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler # Preprocessing\nfrom sklearn.linear_model import Lasso, Ridge, ElasticNet, RANSACRegressor, SGDRegressor, HuberRegressor, BayesianRidge # Linear models\nfrom sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor  # Ensemble methods\nfrom xgboost import XGBRegressor, plot_importance # XGBoost\nfrom sklearn.svm import SVR, SVC, LinearSVC  # Support Vector Regression\nfrom sklearn.tree import DecisionTreeRegressor # Decision Tree Regression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.pipeline import Pipeline # Streaming pipelines\nfrom sklearn.decomposition import KernelPCA, PCA # Dimensionality reduction\nfrom sklearn.feature_selection import SelectFromModel # Dimensionality reduction\nfrom sklearn.model_selection import learning_curve, validation_curve, GridSearchCV # Model evaluation\nfrom sklearn.base import clone # Clone estimator\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nimport xgboost as xgb\nwarnings.filterwarnings('ignore')","90d001f8":"#Load train and test files \ndata = pd.read_csv('..\/input\/predict-the-number-of-upvotes-a-post-will-get\/train_NIR5Yl1.csv')\ntest = pd.read_csv('..\/input\/predict-the-number-of-upvotes-a-post-will-get\/test_8i3B3FC.csv')","b28ee8cc":"#creating dataframe for the required output\nsubmission = pd.DataFrame()\nsubmission['ID'] = test['ID']","60560a26":"##Step 1 : Explore train and test datasets\n\n#First look at train\ndata.sample(5)","a5498c1d":"#First look at test\ntest.sample(5)","e9fc5082":"#Shape of train and test\nprint('There are {} rows and {} columns in train'.format(data.shape[0],data.shape[1]))\nprint('There are {} rows and {} columns in train'.format(test.shape[0],test.shape[1]))","4bb116b9":"#Check Missing values in train\ndata.isna().sum()","fb7a811c":"#Check Missing values in test\ntest.isna().sum()","5aa403ee":"#Check data types in train\ndata.info()","a621682c":"#Check data types in test\ntest.info()","f0b73e1c":"#Lets describe train\ndata.describe()","f5fadef5":"#Lets describe test\ntest.describe()","1ea08e39":"#Lets concatenate train & test\ndf=pd.concat([data,test])\ndf.shape ","bae3f42a":"#Lets drop ID column\ndf.drop('ID', axis = 1, inplace = True)","3672ac85":"#Identify categorical columns \ndf_cat=df.select_dtypes(include='object')\nlist(df_cat.columns)","75e5bb9e":"#Identify numerical columns\ndf_num=df.select_dtypes(include=['int64','float64'])\nlist(df_num.columns)","151d8c95":"#Explore categorical variables - Tag\ncount = 1\nfor cols in df_cat:\n    plt.subplot(1, 2, count)\n    df[cols].value_counts().plot.pie(shadow=True,autopct='%1.1f%%',radius=1.1,textprops={'fontsize': 12} )\n    count +=1\n    plt.subplot(1, 2, count)\n    plt.tight_layout()\n    plt.style.use('seaborn-bright')\n    df[cols].value_counts().plot.bar()\n    fig=plt.gcf()\n    fig.set_size_inches(12,5)\n    plt.title('{0}'.format(cols))\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=12)\n    plt.xticks(rotation=30)\n    count+=1","7dd0d8b7":"#Explore numerical variables distribution\nsns.set(style='whitegrid', palette=\"plasma\", font_scale=1.1, rc={\"figure.figsize\": [8, 5]})\ndf[list(df_num.columns)].hist(bins=20, figsize=(15, 6), layout=(2, 3));","435920f3":"#Lets explore numerical variables : Answers\nsns.set(style='whitegrid', palette=\"Spectral\", font_scale=1.1, rc={\"figure.figsize\": [12, 5]})\nsns.distplot(\n    df['Answers'], norm_hist=False, kde=False, bins=50, hist_kws={\"alpha\": 1}\n).set(xlabel='Answers', ylabel='Frequency');\n","f37f78fc":"# Lets identify which tag is having lowest\/highest median value with respect to the numerical variables \nfor cols in df_num:\n    sorted_nb = df.groupby(['Tag'])[cols].median().sort_values()\n    print(\"Sort numerical value by\",sorted_nb)    ","f8de1a9f":"#Lets visualize above details in boxen plot\n#Numerical Data ['Reputation', 'Answers', 'Username', 'Views', 'Upvotes'] Vs Tag (i.e. categorical variable ) in ascending order of median \nplt.figure(figsize=(15, 15))\ncount = 1\nfor cols in df_num:\n    sns.set(style='darkgrid', palette=\"Set1\", font_scale=1.1, rc={\"figure.figsize\": [12, 12]})\n    plt.subplot(3, 2, count)\n    plt.tight_layout()\n    sorted_nb = df.groupby(['Tag'])[cols].median().sort_values()\n    sns.boxenplot(x=df['Tag'], y=df[cols], order=list(sorted_nb.index))\n    plt.xticks(rotation=30)\n    plt.xticks(fontsize=10)\n    plt.yticks(fontsize=9)\n    \n    count+=1","3dcc67cc":"#Correlation between Views and Upvotes across each tag\nsns.set(font_scale=1.0,style=\"ticks\")\nsns.lmplot(x=\"Views\",y=\"Upvotes\",data=data, col=\"Tag\", col_wrap=5, ci=None, palette=\"muted\", hue=\"Tag\" , height=3, scatter_kws={\"s\": 10, \"alpha\": 1})\nplt.show()","20760320":"#Correlation between Answers and Upvotes across each tag\nsns.set(font_scale=1.0,style=\"darkgrid\")\nsns.lmplot(x=\"Answers\",y=\"Upvotes\",data=data, col=\"Tag\", col_wrap=5, ci=None, palette=\"plasma\", hue=\"Tag\" , height=3, scatter_kws={\"s\": 10, \"alpha\": 1})\nplt.show()","dcc9dec3":"#Correlation between Reputation and Upvotes across each tag\nsns.set(font_scale=1.0,style=\"white\")\nsns.lmplot(x=\"Reputation\",y=\"Upvotes\",data=data, col=\"Tag\", col_wrap=5, ci=None, palette=\"Set1\", hue=\"Tag\" , height=3, scatter_kws={\"s\": 10, \"alpha\": 1})\nplt.show()","510d0ead":"#Correlation between Views and Reputation across Tag\nsns.set(font_scale=1.0,style=\"dark\")\nsns.lmplot(x=\"Views\",y=\"Reputation\",data=data, col=\"Tag\", col_wrap=5, ci=None, palette=\"rocket\", hue=\"Tag\" , height=3, scatter_kws={\"s\": 10, \"alpha\": 1})\nplt.show()","54fea127":"#Correlation between Answers and Reputation across Tag\nsns.set(font_scale=1.0,style=\"dark\")\nsns.lmplot(x=\"Answers\",y=\"Reputation\",data=data, col=\"Tag\", col_wrap=5, ci=None, palette=\"winter\", hue=\"Tag\" , height=3, scatter_kws={\"s\": 10, \"alpha\": 1})\nplt.show()","ef0fd65c":"#Correlation between Answers and Views across Tag\nsns.set(font_scale=1.0,style=\"dark\")\nsns.lmplot(x=\"Answers\",y=\"Views\",data=data, col=\"Tag\", col_wrap=5, ci=None, palette=\"summer\", hue=\"Tag\" , height=3, scatter_kws={\"s\": 10, \"alpha\": 1})\nplt.show()","056d767f":"#Lets do a correlation plot for entire dataframe\nsns.heatmap(df.corr(),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':14})\nfig=plt.gcf()\nfig.set_size_inches(9,8)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.show()","fa58c703":"df_backup = df.copy()","8d40ac9d":"#Tag -\nTag_dict = {'a':0, 'c':1,'h':2,'i':3,'j':4,'o':5,'p':6,'r':7,'s':8,'x':9}\n\n# Transform categorical variable Tag to numbers\ndata[\"Tag\"] = data[\"Tag\"].apply(lambda x: Tag_dict[x])\ntest[\"Tag\"] = test[\"Tag\"].apply(lambda x: Tag_dict[x])\n\n#Convert 'Tag' to object\ndata['Tag']  = data['Tag'].astype('object')\ntest['Tag']  = test['Tag'].astype('object')","e0c2491f":"############ Creating a Count Column for Tag & Username caetgory #################\ndata[\"Tag_Count\"] = data.groupby(['Tag'])['Tag'].transform('count')\nTag_Count_dict = data.groupby(['Tag']).size().to_dict()\ntest['Tag_Count'] = test['Tag'].apply(lambda x:Tag_Count_dict.get(x,0))\n\n\ndata[\"Username_Count\"] = data.groupby(['Username'])['Username'].transform('count')\nUsername_Count_dict = data.groupby(['Username']).size().to_dict()\ntest['Username_Count'] = test['Username'].apply(lambda x:Username_Count_dict.get(x,0))\n","62c506a1":"##### Creating 25percentile and 75percentile columns on Upvotes feature  ########################\n\n### Tag\nTag_25p_dict = data.groupby(['Tag'])['Upvotes'].apply(lambda x:np.percentile(x,25)).to_dict()\ndata['Tag_25PercPrice'] = data['Tag'].apply(lambda x:Tag_25p_dict.get(x,0))\ntest['Tag_25PercPrice'] = test['Tag'].apply(lambda x:Tag_25p_dict.get(x,0))\n\nTag_75p_dict = data.groupby(['Tag'])['Upvotes'].apply(lambda x:np.percentile(x,75)).to_dict()\ndata['Tag_75PercPrice'] = data['Tag'].apply(lambda x:Tag_75p_dict.get(x,0))\ntest['Tag_75PercPrice'] = test['Tag'].apply(lambda x:Tag_75p_dict.get(x,0))\n","85a2f969":"#Creating a Count Column for Views & Answers caetgory \ndata[\"Views_Count\"] = data.groupby(['Views'])['Views'].transform('count')\nViews_Count_dict = data.groupby(['Views']).size().to_dict()\ntest['Views_Count'] = test['Views'].apply(lambda x:Views_Count_dict.get(x,0))\n\ndata[\"Answers_Count\"] = data.groupby(['Answers'])['Answers'].transform('count')\nAnswers_Count_dict = data.groupby(['Answers']).size().to_dict()\ntest['Answers_Count'] = test['Answers'].apply(lambda x:Answers_Count_dict.get(x,0))","fe4b7d5d":"#seperating the dependant variable \ntrain_y = data[\"Upvotes\"]\ndata.drop([\"Upvotes\"], axis=1, inplace=True)\n#Lets drop ID column\ndata.drop('ID', axis = 1, inplace = True)\ntest.drop('ID', axis = 1, inplace = True)","3593a5d9":"#Create primary and secondary list of columns\nprimary_list   = ['Tag', 'Reputation', 'Answers', 'Username', 'Views','Tag_Count','Username_Count','Views_Count','Answers_Count']\nsecondary_list = ['Tag_25PercPrice', 'Tag_75PercPrice',]","b7cba2cd":"#model 1 dataframe\ntrain1 = data[primary_list+secondary_list]\ntest1  = test[primary_list+secondary_list]","a031c144":"#Shape of train and test\nprint('There are {} rows and {} columns in train'.format(train1.shape[0],train1.shape[1]))\nprint('There are {} rows and {} columns in test'.format(test1.shape[0],test1.shape[1]))\n","761aa989":"#Creating train and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train1.values, train_y.values, test_size = 0.2, random_state = 7)","3b1ec873":"#XGBoost Regressor\n# Import XGBoost Regressor\nfrom xgboost import XGBRegressor\n\n#Create a XGBoost Regressor\nreg = XGBRegressor(n_estimators=10000, learning_rate=0.05,)\n\n# Train the model using the training sets \nreg.fit(X_train, y_train,early_stopping_rounds=5,eval_set=[(X_test, y_test)], verbose=0)","14f88f7b":"predicted = reg.predict(test1.values)\n\n#print(predicted.round())\n\nsubmission['Upvotes'] = predicted.round()\nsubmission.to_csv('.\/submission_rahulpednekar.csv',index=False)\nsubmission.head()","4fc456b6":"Take backup of data","8961f59e":"* Variable : Tag\n    * c & j : Maximum count of 100000+ (21.9%)\n    * x : Minimum count of 9k+","56c1b1ab":"For username : Max frequency is from 0 to 100000","321a879c":"Identify categorical and numerical columns","881a507e":"Model building starts","3d8c23e8":"> **If you have liked my Kernel then please upvote**","26780642":"#                         **Predict No of  upvotes**\n\nAn online question and answer platform has hired you as a data scientist to identify the best question authors on the platform. This identification will bring more insight into increasing the user engagement. Given the tag of the question, number of views received, number of answers, username and reputation of the question author, the problem requires you to predict the upvote count that the question will receive.\n\nData Dictionary\n\n* Variables \n    * ID\t: Question ID\n    * Tag\t: Anonymised tags representing question category\n    * Reputation :\tReputation score of question author\n    * Answers\t: Number of times question has been answered\n    * Username :\tAnonymised user id of question author\n    * Views :\tNumber of times question has been viewed\n    * Upvotes\t(Target)  : Number of upvotes for the question\n \n\nEvaluation Metric : The evaluation metric for this competition is RMSE (root mean squared error)","1e27cff3":"Prepare submission file","3a1ed849":"> **Above prediction achieved rank 338 in analyticsVidhya hackathon on \"Predict Number of Upvotes\" **","7a596d51":"Feature Engineering","e6f9a04a":"* Reputation : r(699) is min Vs C is max (1637)\n* Answers  : Median is 2 for r&x Vs 3 for all others\n* Username : It does not make any sense \n* Views    : r has min (2888) Vs j is max (14541) i.e. j tag has max views\n* Upvotes : r has min (11) Vs j has max (42) median value","6da1d12d":"* Views are aving highest correlation of 0.44 followed by Reputation 0.27 and Answers 0.2 against Upvotes\n* Avswers and Views are having high correlation of 0.5\n* Username column has very low correation of -0.012 with Upvotes and can be dropped","ab7e68eb":"Answers: Max frequency for answer count = 1 to 2","ce69a270":"Step 1 : EDA (Exploratory Data Analysis)","babd6ab1":"Lets visualize regression plots between numerical variables Vs Target variable (i.e Upvotes)","495670b2":"No missing data in train and test","373192dd":"After several permutaion and combination, I decided to use xgbregressor to predict which gave nest results"}}