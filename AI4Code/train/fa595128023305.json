{"cell_type":{"32ea49db":"code","c82d4112":"code","4ca0fe44":"code","170e8969":"code","3861bb31":"code","52a7e7d5":"code","2180700b":"code","74b39888":"code","6a1f302b":"code","c5c9a42c":"code","62afc21c":"code","6ed56aa9":"code","c0552c56":"code","a2bb8008":"code","e0e43d5d":"code","7b24826d":"code","fbe5129c":"code","8d26172c":"code","5b61279b":"code","1257ab5e":"code","2d66ff59":"code","68ab5e6d":"code","8b95942d":"markdown","52afbe80":"markdown","70383272":"markdown","06e31602":"markdown","9c705aa1":"markdown","eb99331c":"markdown","d5aaf8a0":"markdown","14675858":"markdown","b5190b32":"markdown","3afc2dd0":"markdown","fe91f3dc":"markdown","05da4d94":"markdown","6454f2d9":"markdown","3f647d3f":"markdown","3dbabfdb":"markdown","91f91cfd":"markdown","7ccb8f86":"markdown","416bf79f":"markdown","2b110e55":"markdown","af28ae00":"markdown"},"source":{"32ea49db":"%%time\nimport pandas as pd\nimport numpy as np\nimport gc\nimport os\nimport random\nimport glob\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import LabelEncoder\nimport warnings \nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib as mpl\nfrom matplotlib_venn import venn2\n%matplotlib inline\n\ninputPath = '\/kaggle\/input\/used-car-price-forecasting\/'\ntrain = pd.read_csv(inputPath + 'train.csv')\ntest = pd.read_csv(inputPath + 'test.csv')\ntrain['flag'] = 'train'\ntest['flag'] = 'test'\n\ndf = pd.concat([train,test],axis=0)\ndel train,test\ngc.collect()","c82d4112":"%%time\n# fillna with most frequent value\ndf['year'].fillna(df['year'].mode()[0], inplace=True)\n\n# fillna with new category\ndf['model'] = df['model'].fillna('nan')\n\n# fillna with new category\ndf['condition'] = df['condition'].fillna('nan')\n\n# fillna with new value\ndf['cylinders'] = df['cylinders'].fillna('-2 cylinders')\ndf['cylinders'] = df['cylinders'].map(lambda x:x.replace('other','-1 cylinders'))\n\n# fillna with new category\ndf['fuel'] = df['fuel'].fillna('nan')\n\n# fillna with new value\ndf['odometer'] = df['odometer'].fillna('-1')\ndf['odometer'] = df['odometer'].astype(float)\n\n# fillna with new category\ndf['title_status'] = df['title_status'].fillna('nan')\n\n# fillna with new category\ndf['transmission'] = df['transmission'].fillna('nan')\n\n# fillna with new category\ndf['vin'] = df['vin'].fillna('nan')\n\n# fillna with new category\ndf['drive'] = df['drive'].fillna('nan')\n\n# fillna with new category\ndf['size'] = df['size'].fillna('nan')\n\n# fillna with new category\ndf['type'] = df['type'].fillna('nan')\n\n# fillna with new category\ndf['paint_color'] = df['paint_color'].fillna('nan')","4ca0fe44":"%%time\nprint(df['cylinders'])\ndf['cylinders'] = df['cylinders'].map(lambda x:x.split(' ')[0])\ndf['cylinders'] = df['cylinders'].astype(int)\nprint(df['cylinders'])","170e8969":"%%time\nprint(df)\ndf = pd.get_dummies(df, columns=['paint_color'])\nprint(df)","3861bb31":"%%time\nfor c in ['region','manufacturer','model','condition','fuel','title_status','transmission', 'vin', 'drive', 'size', 'type', 'state']:\n    lbl = LabelEncoder()\n    df[c] = lbl.fit_transform(df[c].astype(str))\ndf","52a7e7d5":"df.describe","2180700b":"flag_s = []\nimg_id_s = []\nfsize_s = []\n\nimage_path = '\/kaggle\/input\/used-car-price-forecasting\/images'\n\nflags = ['test','train']\nfor flag in flags:\n    for filename in os.listdir(image_path+'\/'+flag+'_images\/'):\n        flag_s.append(flag)\n        img_id_s.append(filename[:-4])\n        fsize_s.append(os.path.getsize(image_path+'\/'+flag+'_images\/'+filename))\n\nflag_s = pd.Series(flag_s)\nimg_id_s = pd.Series(img_id_s)\nfsize_s = pd.Series(fsize_s)\ndf_fsize = pd.concat([flag_s, img_id_s, fsize_s], axis=1)\ndf_fsize.columns=('flag','id','image_file_size')\ndf_fsize['id'] = df_fsize['id'].astype('int64')\n\ndf = pd.merge(df,df_fsize,on=('flag','id'))","74b39888":"%%time\nimport string\npuncs = string.punctuation\ndel_puncs = str.maketrans( '', '',puncs)\n\nbow = {}\nfor desc in tqdm(list(df['description'])):\n    desc = desc.lower()\n    for word in desc.split():\n        word = word.translate(del_puncs)\n        if word in bow:\n            bow[word] += 1\n        else:\n            bow[word] = 1\n\nlen(bow)","6a1f302b":"%%time\nbow_df = pd.DataFrame.from_dict(bow, orient='index')\nbow_df = bow_df.reset_index()\nbow_df.columns = ['word','freq']\nbow_df = bow_df.sort_values('freq',ascending=False).reset_index(drop=True)","c5c9a42c":"%%time\nfrom wordcloud import WordCloud , STOPWORDS\nstopwords = set(STOPWORDS)\nmore_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\nstopwords = stopwords.union(more_stopwords)","62afc21c":"%%time\ndef is_not_stopwords_puncs(word):\n    return not(word in stopwords or word in puncs)\nbow_df = bow_df[ bow_df['word'].apply(is_not_stopwords_puncs) ]","6ed56aa9":"%%time\nbow_checker = list(bow_df.iloc[:200,:].reset_index(drop=True)['word'])\nlen(bow_checker)","c0552c56":"%%time\n# \u5358\u8a9e\u304c\u51fa\u73fe\u3059\u308b\u304b\u3069\u3046\u304b\u3092\u7279\u5fb4\u91cf\u3068\u3057\u3066\u8ffd\u52a0\ndef word_in_str(string, word):\n    string = string.lower()\n    return int(word in string)\n\nfor word in tqdm(bow_checker):\n    df['bow_'+word] = df['description'].apply(word_in_str, args=(word,))","a2bb8008":"df.describe","e0e43d5d":"def is_ascii(s):\n    return all(ord(c) < 128 for c in s)\n\n# \uff12\u30d0\u30a4\u30c8\u6587\u5b57\u306e\u30ab\u30e9\u30e0\u540d\u3092\u78ba\u8a8d\nfor column in list(df.columns):\n    if not(is_ascii(column)):\n        print(column)","7b24826d":"# \u5909\u63db\nconvert_table = {\n    'bow_\u2705': 'bow_check-mark',\n    'bow_\ud83d\ude97': 'bow_car-mark',\n    'bow_\u2022':'bow_dot-mark',\n    'bow_we\u2019re':'bow_were-mark',\n    'bow_\u2014': 'bow_minus-mark',\n    'bow_\u2714\ufe0f': 'bow_check-mark2'\n}\n\ndf = df.rename(columns=convert_table)\ndf.columns","fbe5129c":"%%time\nfor c in ['region','manufacturer','model','condition','fuel','title_status','transmission', 'vin', 'drive', 'size', 'type', 'state']:\n    df['count_' + c] = df.groupby([c])['flag'].transform('count')","8d26172c":"%%time\ndf['mean_manufacturer_odometer'] = df.groupby(['manufacturer'])['odometer'].transform('mean')\ndf['std_manufacturer_odometer'] = df.groupby(['manufacturer'])['odometer'].transform('std')\ndf['max_manufacturer_odometer'] = df.groupby(['manufacturer'])['odometer'].transform('max')\ndf['min_manufacturer_odometer'] = df.groupby(['manufacturer'])['odometer'].transform('min')\ndf['maxmin_manufacturer_odometer'] = df['max_manufacturer_odometer'] - df['min_manufacturer_odometer']","5b61279b":"%%time\ndf['num_chars'] = df['description'].apply(len) \ndf['num_words'] = df['description'].apply(lambda x: len(x.split()))\ndf['num_unique_words'] = df['description'].apply(lambda x: len(set(w for w in x.split())))","1257ab5e":"import lightgbm as lgb\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold,GroupKFold\n\ndef rmse(y_true, y_pred):\n    return (mean_squared_error(y_true, y_pred))** .5\n\ndef run_lgb_kfold(train_df,test_df,features,target,folds,params):\n    oof_preds = np.zeros(train_df.shape[0])\n    sub_preds = np.zeros(test_df.shape[0])\n\n    cv_list = []\n    feature_imps = pd.DataFrame()\n    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[features], train_df['manufacturer'])):\n        print ('FOLD:' + str(n_fold))\n        \n        train_x, train_y = train_df[features].iloc[train_idx], train_df[target].iloc[train_idx]\n        valid_x, valid_y = train_df[features].iloc[valid_idx], train_df[target].iloc[valid_idx]\n \n        dtrain = lgb.Dataset(train_x, label=train_y)\n        dval = lgb.Dataset(valid_x, label=valid_y, reference=dtrain) \n        bst = lgb.train(params, dtrain, num_boost_round=50000, # num_boost_round\u309210000->50000\n            valid_sets=[dval,dtrain], verbose_eval=500,early_stopping_rounds=100, ) \n        \n        oof_preds[valid_idx] = bst.predict(valid_x, num_iteration=bst.best_iteration)\n        oof_cv = rmse(valid_y,  oof_preds[valid_idx])\n        cv_list.append(oof_cv)\n        print (cv_list)\n        sub_preds += bst.predict(test_df[features], num_iteration=bst.best_iteration) \/ folds.n_splits\n \n        feature_imp = pd.DataFrame(sorted(zip(bst.feature_importance('gain'),features)), columns=['Value','Feature'])\n        feature_imp['fold'] = n_fold\n        feature_imps = pd.concat([feature_imps,feature_imp],axis=0)\n        \n    cv = rmse(train_df[target],  oof_preds)\n    print('Full OOF RMSE %.6f' % cv)  \n    \n    train_df['prediction'] = oof_preds\n    test_df['prediction'] = sub_preds\n    \n    return train_df,test_df,feature_imps\n\ntrain_df = df[df['flag']=='train']\ntrain_df['price'] = np.log1p(train_df['price'])\ntest_df = df[df['flag']=='test']\n\ntarget = 'price'\ndrop_features = ['id', 'price', 'description', 'flag']\nfeatures = [f for f in train_df.columns if f not in drop_features]\nprint ('features:', len(features),features)\n\nn_splits = 5\nseed = 817\nfolds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n\nparams = {\n               \"objective\" : \"regression\", \n               \"boosting\" : \"gbdt\", \n               \"metric\" : \"rmse\",  \n               \"max_depth\": -1,\n               \"min_data_in_leaf\": 30, \n               \"reg_alpha\": 0.1, \n               \"reg_lambda\": 0.1, \n               \"num_leaves\" : 31, \n               \"max_bin\" : 256,\n               \"learning_rate\" :0.05,# 0.1 -> 0.05\n               \"bagging_fraction\" : 0.9,\n               \"feature_fraction\" : 0.9\n}\n\ntrain_lgb,test_lgb,feature_imps = run_lgb_kfold(train_df,test_df,features,target,folds,params)","2d66ff59":"feature_imp = feature_imps.groupby(['Feature'])['Value'].mean().reset_index()\nplt.figure(figsize=(20, 10))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False)[:30])\nplt.title('LightGBM Features')\nplt.tight_layout()\nplt.show()","68ab5e6d":"%%time\ntest_lgb['price'] = np.expm1(test_lgb['prediction'])\ntest_df[['id','price']].to_csv('submission.csv',index=False)","8b95942d":"# \u6982\u8981\nSenkin\u3055\u3093\u306eImprove model score step byb step\u3092\u30d5\u30a9\u30fc\u30af\u3057\u3066\u7279\u5fb4\u3092\u3044\u304f\u3064\u304b\u8ffd\u52a0\u3057\u305f\u3082\u306e\u3067\u3059\u3002\n\n\u3084\u3063\u305f\u4e8b\u306f\u57fa\u672c\u7684\u306b\u4ee5\u4e0b\u306e2\u3064\u3060\u3051\u3067\u3001\u5f8c\u5c11\u3057\u3060\u3051\u5b66\u7fd2\u306e\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u56de\u6570\u3068\u5b66\u7fd2\u7387\u3092\u3044\u3058\u308a\u307e\u3057\u305f\u3002\n\n1. description\u306b\u51fa\u73fe\u3059\u308b\u5358\u8a9e\u3092\u6d17\u3044\u51fa\u3057\u3066\u4e0a\u4f4d200\u5358\u8a9e\u306b\u3064\u3044\u3066\u305d\u308c\u305e\u308c\u51fa\u73fe\u3059\u308b\u304b\u3069\u3046\u304b\u306e\u30d5\u30e9\u30b0\u3092\u4f5c\u308a\u307e\u3057\u305f\u3002\n2. \u753b\u50cf\u306e\u30d5\u30a1\u30a4\u30eb\u30b5\u30a4\u30ba\u3092\u7279\u5fb4\u91cf\u306b\u8ffd\u52a0\u3057\u307e\u3057\u305f\u3002\n\n\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u56de\u6570\u3092\u5897\u3084\u3059\u306e\u3068\u30d5\u30a1\u30a4\u30eb\u30b5\u30a4\u30ba\u3092\u7279\u5fb4\u91cf\u306b\u6301\u3064\u306e\u306f\u30c1\u30fc\u30e0\u3067\u8b70\u8ad6\u3057\u305f\u6642\u306b\u30d2\u30f3\u30c8\u3092\u3082\u3089\u3044\u307e\u3057\u305f\u3002\n\n\u307f\u306a\u3055\u3093\u30ec\u30d9\u30eb\u304c\u9ad8\u3059\u304e\u3066\u3053\u308c\u3060\u3051\u3057\u304b\u3084\u308c\u3066\u306a\u3044\u306e\u306f\u3061\u3087\u3063\u3068\u6065\u305a\u304b\u3057\u3044\u306e\u3067\u3059\u304c\u3001\u3053\u308c\u3060\u3051\u3067Score\u304c\u4e0a\u304c\u3063\u305f\u306e\u3082\u8208\u5473\u6df1\u3044\u306a\u3068\u3082\u601d\u3044\u307e\u3057\u305f\u3002","52afbe80":"## Filling Missing Values","70383272":"## convert non ASCII features\n- Lightgbm\u306f2\u30d0\u30a4\u30c8\u6587\u5b57\u306e\u30ab\u30e9\u30e0\u3092\u8aad\u3081\u306a\u3044\u69d8\u306a\u306e\u3067\u5909\u63db","06e31602":"### \u8f9e\u66f8\u5f62\u5f0f\u3092\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u578b\u5f0f\u306b\u5909\u63db\n- \u51fa\u73fe\u983b\u5ea6\u9806\u306b\u30bd\u30fc\u30c8\u3082\u5b9f\u65bd\uff08\u306e\u3061\u306e\u3061\u4e0a\u4f4dN\u5358\u8a9e\u3092\u62bd\u51fa\u3059\u308b\u305f\u3081\uff09","9c705aa1":"# Training","eb99331c":"## Count Encoding","d5aaf8a0":"# \u753b\u50cf\u306e\u30d5\u30a1\u30a4\u30eb\u30b5\u30a4\u30ba\u3092\u7279\u5fb4\u91cf\u3068\u3057\u3066\u8ffd\u52a0","14675858":"### \u8f9e\u66f8\u5f62\u5f0f\u3067\u51fa\u73fe\u5358\u8a9e\u3068\u51fa\u73fe\u6570\u3092\u30ab\u30a6\u30f3\u30c8\n- \u305d\u306e\u969b\u3001\u5927\u6587\u5b57\u306f\u5168\u3066\u5c0f\u6587\u5b57\u306b\u5909\u63db\u3057\u3001\u8a18\u53f7\uff08,.;\u306a\u3069\uff09\u306f\u9664\u53bb\u3057\u307e\u3057\u305f\u3002","b5190b32":"### \u4e0a\u4f4d\uff12\uff10\uff10\u5358\u8a9e\u304c\u51fa\u73fe\u3059\u308b\u304b\u3044\u306a\u304b\u306e0\/1\u3067\u7279\u5fb4\u91cf\u5316","3afc2dd0":"# bag of words","fe91f3dc":"## One Hot Encoding","05da4d94":"## Text Count","6454f2d9":"## Ordinal Encoding","3f647d3f":"### \u30b9\u30c8\u30c3\u30d7\u30ef\u30fc\u30c9\u306e\u30ea\u30b9\u30c8\u3092\u4f5c\u6210\n- \u3044\u308f\u3086\u308b\u610f\u5473\u3092\u6301\u305f\u306a\u3044\u5358\u8a9e\u3092\u9664\u53bb\u3059\u308b\u305f\u3081\u306b\u4f5c\u6210","3dbabfdb":"## Label Encoding","91f91cfd":"### BoW\u304b\u3089\u30b9\u30c8\u30c3\u30d7\u30ef\u30fc\u30c9\u3001\u8a18\u53f7\u3092\u524a\u9664","7ccb8f86":"## Aggregation","416bf79f":"# Senkin\u3055\u3093\u306e\u524d\u51e6\u7406","2b110e55":"### \u51fa\u73fe\u983b\u5ea6\u4e0a\u4f4d200\u5358\u8a9e\u306e\u307f\u9078\u629e","af28ae00":"# Submission"}}