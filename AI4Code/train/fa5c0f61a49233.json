{"cell_type":{"7b198a21":"code","4af77ede":"code","a55af6c6":"code","3b297fd2":"code","d8ea1ad1":"code","4aa1d60a":"code","46049e83":"code","8215fc13":"code","247eb9e3":"code","e82c052c":"code","424b9ad8":"code","eeb047ae":"code","109ca68f":"code","03b5fc2b":"code","4c2b9c93":"markdown","1c0e4cf8":"markdown","e8eb34b8":"markdown","78867822":"markdown","a9fc9ba8":"markdown","717d01c7":"markdown","31a4ee85":"markdown","8209a76b":"markdown","e083f81e":"markdown","271036f7":"markdown","e0dc9bb5":"markdown","03bc7367":"markdown","5c552074":"markdown","fcecc1e5":"markdown","4025199e":"markdown","1ff49fea":"markdown","284cafd8":"markdown","1df52f8c":"markdown","8fbef7b5":"markdown"},"source":{"7b198a21":"#Import delle librerie\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns \nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics","4af77ede":"col_names = ['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm', 'Species']\ndata = pd.read_csv(\"..\/input\/iris-flower-dataset\/IRIS.csv\", names = col_names, header=0) \ndata.sample(5) #Stampa di alcuni elementi del dataset","a55af6c6":"data.info()","3b297fd2":"import seaborn as sns\nsns.pairplot( data=data, vars=('SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm'), hue='Species' )","d8ea1ad1":"data.describe()","4aa1d60a":"df_norm = data[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']].apply(lambda x: (x - x.min()) \/ (x.max() - x.min()))\ndf_norm.sample(n=5)","46049e83":"df_norm.describe()","8215fc13":"target = data[['Species']].replace(['Iris-setosa','Iris-versicolor','Iris-virginica'],[0,1,2])\ntarget.sample(n=5)","247eb9e3":"df = pd.concat([df_norm, target], axis=1)\ndf.sample(n=5)","e82c052c":"train, test = train_test_split(df, test_size = 0.3)\nX_train = train[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\ny_train = train.Species\nX_test = test[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\ny_test = test.Species","424b9ad8":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV\n\ngrid = {'solver': ['lbfgs', 'sgd', 'adam'], 'activation': ['identity', 'logistic', 'tanh', 'relu']}\nclf_cv = GridSearchCV(MLPClassifier(random_state=1, max_iter=5000, hidden_layer_sizes=(3,3), alpha=1e-5), grid, n_jobs=-1, cv=10)\n\nclf_cv.fit(X_train, y_train)\n\nprint(\"GridSearch():\\n\")\ncombinazioni = 1\nfor x in grid.values():\n    combinazioni *= len(x)\nprint('Per l\\'applicazione della GridSearch ci sono {} combinazioni'.format(combinazioni))\nprint(\"Migliore configurazione: \",clf_cv.best_params_)\nbest_config_gs = clf_cv.best_params_\nprint(\"Accuracy CV:\",clf_cv.best_score_)\nppn_cv = clf_cv.best_estimator_\nprint('Test accuracy: %.3f' % clf_cv.score(X_test, y_test))\n","eeb047ae":"mlp = MLPClassifier(random_state=1, max_iter=5000, hidden_layer_sizes=(3,3), alpha=1e-5, **best_config_gs)\n\nmlp.fit(X_train,y_train)\npredict_train = mlp.predict(X_train)\npredict_test = mlp.predict(X_test)","109ca68f":"#Matrice di confusione e report di classificazione per il Train\nfrom sklearn.metrics import classification_report,confusion_matrix\nprint(confusion_matrix(y_train,predict_train))\nprint(classification_report(y_train,predict_train))","03b5fc2b":"#Matrice di confusione e report di classificazione per il Test\nprint(confusion_matrix(y_test,predict_test))\nprint(classification_report(y_test,predict_test))","4c2b9c93":"<img align=\"center\" src=\"https:\/\/d1whtlypfis84e.cloudfront.net\/guides\/wp-content\/uploads\/2020\/04\/04155631\/1426878678.png\"\/>","1c0e4cf8":"Successivamente viene creata una matrice di confusione e un report di classificazione per il Train Set, individuando una serie di misure utili alla valutazione.","e8eb34b8":"Nello snippet seguente viene creato un MLPClassifier che abbia come parametri queli del miglior modello individuato dalla GridSearch.","78867822":"## GridSearch e Funzioni di Attivazione","a9fc9ba8":"## Analisi Esplorativa","717d01c7":"## Import delle librerie","31a4ee85":"## Valutazione","8209a76b":"Infine la stessa matrice e lo stesso report vengono creati per il Test Set.","e083f81e":"### Z Normalization","271036f7":"## Caricamento in memoria del dataset","e0dc9bb5":"- [Import delle librerie](#Import-delle-librerie)\n- [Caricamento in memoria del dataset](#Caricamento-in-memoria-del-dataset)\n- [Analisi Esplorativa](#Analisi-Esplorativa)\n- [Preprocessing](#Preprocessing)\n    - [Z-Normalization](#Z-Normalization)\n    - [Trasformazione della feature target da categorico a numerico](#Trasformazione-della-feature-target-da-categorico-a-numerico)\n    - [Creazione del nuovo dataframe](#Creazione-del-nuovo-dataframe)\n    - [Split dei dati in train e test set](#Split-dei-dati-in-train-e-test-set)\n- [GridSearch e Funzioni di Attivazione](#GridSearch-e-Funzioni-di-Attivazione)\n- [Valutazione](#Valutazione)","03bc7367":"La standardizzazione \u00e8 un procedimento che riconduce una variabile aleatoria distribuita secondo una media \u03bc e varianza \u03c32, ad una variabile aleatoria con distribuzione \"standard\", ossia di media zero e varianza pari a 1. \u00c8 particolarmente utile nel caso della variabile casuale normale per il calcolo della funzione di ripartizione e dei quantili con le tavole della normale standard. Infatti i valori della distribuzione normale sono tabulati per media zero e varianza unitaria.\n\nIl procedimento prevede di sottrarre alla variabile aleatoria la sua media e dividere il tutto per la deviazione standard (per \u03c3 e non per \u03c32), ovvero utilizzando la formula utile a trovare i punti zeta (Z-score o standard score):","5c552074":"## Preprocessing","fcecc1e5":"# Esercitazione MLPClassfier con GridSearch","4025199e":"### Creazione del nuovo dataframe","1ff49fea":"## Indice dei contenuti","284cafd8":"### Trasformazione della feature target da categorico a numerico","1df52f8c":"### Split dei dati in train e test set","8fbef7b5":"Di seguito vengono riportate le possibili funzioni di attivazione utilizzate per l'aggiornamento dei pesi dei neuroni.\nTali funzioni vengono valutate mediante una GridSearch, in modo da individuare la combinazione migliore di parametri.\n\n\n1. <b>relu<\/b>: La Rectifier Function \u00e8 la funzione di attivazioni pi\u00f9 utilizzata. Restituisce 0 qualora la somma pesata dei segnali in input \u00e8 minore o uguale a zero, oppure \u03a3wX negli altri casi. Il codominio della funzione spazia in questo caso da 0 ad infinito.\n2. <b>selu<\/b>: E' una variante della relu. Per valori positivi, restituisce \u03a3wX, per valori negativi, l'andamento della funzione ricorda il grafico della funzione logaritmo. Pu\u00f2 essere utilizzata quando la funzione relu crea il problema noto come \"dying relu\", ovvero quando tutti gli output assumono tutti lo stesso valore. Questo accade quando si \u00e8 in presenza di valori molto piccoli, quindi prossimi allo zero. Dato che il gradiente di zero \u00e8 zero, la rete neurale non \u00e8 in grado di aggiornare i pesi.\n3. <b>tanh<\/b>: si comporta come la sigmoide, ma il range di valori \u00e8 [-1, 1]. Il vantaggio \u00e8 che gli input saranno mappati fortemente in modo negativo, e i valori prossimi allo zero saranno mappati come zero in tanh.\n5. <b>sigmoid<\/b>: in questo caso il codominio della funzione, ovvero i valori che pu\u00f2 restituire il neurone, spazia tra 0 ed 1 in un intervallo continuo. Infatti, la caratteristica di questa funzione \u00e8 che smussata. Pu\u00f2 essere utilizzata al posto della Threshold Function considerando il valore in uscita non come Y ma come probabilit\u00e0 che Y sia uguale ad uno, ovvero Prob(Y=1)."}}