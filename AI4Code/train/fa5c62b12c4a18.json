{"cell_type":{"17ccdb2f":"code","2a8ea652":"code","f81ff34a":"code","64a6c822":"code","b94ec053":"code","8d0445a5":"code","9a2eb3ac":"code","780dba2a":"code","c0e0e9d6":"code","5f4615d5":"code","5943bbd4":"code","ddfbc520":"code","23923e51":"code","4dc24c7e":"code","567dc2fe":"code","4b8ba1bf":"code","c1c7e0cc":"code","865b55d7":"code","870c2bde":"code","dfbf5556":"code","2680b9ee":"code","9578f249":"code","accefe1b":"code","51a3fa32":"code","872dbda4":"code","1c4bdbdf":"code","b8bd9d51":"code","9a09b269":"code","d972835f":"code","5cd5431a":"code","ad3762d6":"code","9261f68d":"code","58113af9":"code","988c24bc":"code","f1fc800d":"markdown","11c887f3":"markdown","c172da08":"markdown","6b5f9f6b":"markdown","c584ca4a":"markdown","b8848e6d":"markdown","95f42bff":"markdown","73eb31a9":"markdown","9f1bf8bf":"markdown","92887334":"markdown","627d0ec7":"markdown"},"source":{"17ccdb2f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2a8ea652":"import pandas as ps\nimport numpy as ny\nimport matplotlib.pyplot as plt\nimport seaborn as sn\n\n\nspotify_set = ps.read_csv(\"\/kaggle\/input\/spotify-top-200-charts-20202021\/spotify_dataset.csv\")\nspotify_set.head(10)\n","f81ff34a":"spotify_set.describe()","64a6c822":"spotify_set.info() # Need to convert the datatypes of these columns.","b94ec053":"spotify_set.shape # Pretty small dataset.","8d0445a5":"spotify_set.isnull().sum() # No nulls. ","9a2eb3ac":"spotify_set[['Release Date','Weeks Charted','Popularity' ]] ## Screen column data to see if they are worth cleaning or better remove.","780dba2a":"# Dropping columns.\nclean_spotify = spotify_set.drop(columns = ['Index','Weeks Charted','Chord','Release Date','Week of Highest Charting','Song ID','Genre'],axis=1)\nclean_spotify.head(10)\n\n# Looks clean a bit","c0e0e9d6":"# Converting object columns to relevant float\/int\nobject_cols = ['Danceability','Energy','Loudness','Speechiness','Acousticness','Liveness','Tempo','Valence','Artist Followers','Popularity','Duration (ms)']\n","5f4615d5":"for each_col in object_cols:\n    clean_spotify[each_col] = ps.to_numeric(clean_spotify[each_col], errors='coerce')\n\nclean_spotify.isnull().sum()\nclean_spotify.info()","5943bbd4":"# Converting Loudness to postive 30 scale.\nclean_spotify['Loudness'] = 30 + clean_spotify['Loudness']\nclean_spotify['Loudness'].head(10)","ddfbc520":"# Dropping na columns as count is low.\nclean_spotify = clean_spotify.dropna()\nclean_spotify.describe()","23923e51":"# Time to clean stream column from comma format to number.\n\ndef commas_to_number(strnum):\n    strlist = str(strnum).split(',')\n    strjoined = \"\"\n    for each_literal in strlist:\n        strjoined += each_literal\n    return (int(strjoined))\n\nclean_spotify['Streams'] = clean_spotify['Streams'].apply(commas_to_number)\n\nclean_spotify['Streams'].head(10)\n","4dc24c7e":"clean_spotify.describe()","567dc2fe":"## All numbers dataframe. Time for plotting and MI scores\n\nplt.figure(figsize=(28,15))\nsn.heatmap(clean_spotify.corr(),cmap='icefire_r')\nplt.title(\"Correlation Matrix\")   # Do we get to drop a few more columns ?","4b8ba1bf":"clean_spotify.head(10)","c1c7e0cc":"# Beginning with Usecases\na_measure = clean_spotify.groupby('Artist')['Highest Charting Position'].sum()\n\n\nfigure, axes = plt.subplots(1, 2, figsize=(28, 14))#plt.subplots(1,2)\naxes[0].set_title('Top 20')\naxes[1].set_title('Bottom 20')\n\ntop20 = a_measure.sort_values(ascending=False)[:20]\nbottom20 = a_measure.sort_values(ascending=True)[:20]\n\nsn.barplot(ax=axes[0],y=top20.index,x=top20.values,palette='gist_earth')\nsn.barplot(ax=axes[1],y=bottom20.index,x=bottom20.values,palette='Accent_r')","865b55d7":"b_measure = clean_spotify.groupby('Artist')['Streams'].sum()\n\n\nfigure, axes = plt.subplots(1, 2, figsize=(28, 14))#plt.subplots(1,2)\naxes[0].set_title('Top 20')\naxes[1].set_title('Bottom 20')\n\ntop20 = b_measure.sort_values(ascending=False)[:20]\nbottom20 = b_measure.sort_values(ascending=True)[:20]\n\nsn.barplot(ax=axes[0],y=top20.index,x=top20.values,palette='gist_earth',color=clean_spotify['Artist Followers'])\nsn.barplot(ax=axes[1],y=bottom20.index,x=bottom20.values,palette='Accent_r',color=clean_spotify['Artist Followers'])","870c2bde":"c_measure = clean_spotify.groupby('Song Name')['Streams'].sum()\n\n\nfigure, axes = plt.subplots(1, 2, figsize=(28, 14))#plt.subplots(1,2)\naxes[0].set_title('Top 20')\naxes[1].set_title('Bottom 20')\n\ntop20 = c_measure.sort_values(ascending=False)[:20]\nbottom20 = c_measure.sort_values(ascending=True)[:20]\n\nsn.barplot(ax=axes[0],y=top20.index,x=top20.values,palette='gist_earth',color=clean_spotify['Artist Followers'])\nsn.barplot(ax=axes[1],y=bottom20.index,x=bottom20.values,palette='Accent_r',color=clean_spotify['Artist Followers'])","dfbf5556":"# Popularity vs Energy Vs Danceability\nfigure, axes = plt.subplots(1, 2, figsize=(28, 14))#plt.subplots(1,2)\naxes[0].set_title('Energy')\naxes[1].set_title('Danceability')\n\nsn.scatterplot(ax=axes[0],data=clean_spotify,y='Popularity',x='Energy',palette='gist_earth')\nsn.scatterplot(ax=axes[1],data=clean_spotify,y='Popularity',x='Danceability',palette='Accent_r')","2680b9ee":"clean_spotify = clean_spotify.drop(columns= [\"Artist\",\"Song Name\"])","9578f249":"#Scaling the features\n\nfrom sklearn.preprocessing import RobustScaler\n\nscalerr = RobustScaler()\nscaled_features = scalerr.fit_transform(clean_spotify)\n\nclean_spotify = ps.DataFrame(scaled_features, index=clean_spotify.index, columns=clean_spotify.columns)\n\nspotify_classify_dataset = clean_spotify.copy()\n\nclean_spotify.head(10)","accefe1b":"# Mutual Info scores with target: Popularity.\n\ny = clean_spotify['Popularity']\nX = clean_spotify.drop(columns=['Popularity'])\n\nfrom sklearn.feature_selection import mutual_info_regression\n\n#discrete_features = X.dtypes in [int,float]\ndef make_mi_scores(X, y):\n    mi_scores = mutual_info_regression(X, y, discrete_features='auto')\n    mi_scores = ps.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\nmi_scores = make_mi_scores(X, y)\nmi_scores[::]\n","51a3fa32":"# Mutual Info scores with target: Streams.\n\ny1 = clean_spotify['Streams']\nX1 = clean_spotify.drop(columns=['Streams'])\n\nfrom sklearn.feature_selection import mutual_info_regression\n\n#discrete_features = X.dtypes in [int,float]\ndef make_mi_scores(X1, y1):\n    mi_scores = mutual_info_regression(X1, y1, discrete_features='auto')\n    mi_scores = ps.Series(mi_scores, name=\"MI Scores\", index=X1.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\nmi_scores = make_mi_scores(X1, y1)\nmi_scores[::]","872dbda4":"# Mutual Info scores with target: Artist Followers.\n\ny2 = clean_spotify['Artist Followers']\nX2 = clean_spotify.drop(columns=['Artist Followers'])\n\nfrom sklearn.feature_selection import mutual_info_regression\n\n#discrete_features = X.dtypes in [int,float]\ndef make_mi_scores(X2, y2):\n    mi_scores = mutual_info_regression(X2, y2, discrete_features='auto')\n    mi_scores = ps.Series(mi_scores, name=\"MI Scores\", index=X2.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\nmi_scores = make_mi_scores(X2, y2)\nmi_scores[::]","1c4bdbdf":"# Modelling\n\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score,accuracy_score\n\n#T-T-S\nX_train,X_test,y_train,y_test = train_test_split(X1,y1,train_size=0.75)\n    \ngb_reg_model = GradientBoostingRegressor()\nrf_reg_model = RandomForestRegressor()\nxgb_reg_model = XGBRegressor()\n\nscores = {}\n\ndef get_model_scores(model,modelstr):\n    \n    \n    #Training the model\n    model.fit(X_train,y_train)\n    \n    # Predicting\n    predicted = model.predict(X_test)\n    \n    print(\"\\n \",modelstr,\" ------------\")\n    print(\"\\n R2 Score: \",r2_score(y_test, predicted))\n    print('\\n MAE:{}'.format(mean_absolute_error(y_test,predicted)))\n    print('\\n MSE:{}'.format(mean_squared_error(y_test,predicted)))\n    print('\\n RMSE:{}'.format(ny.sqrt(mean_squared_error(y_test,predicted))))\n    \n    scores.update({modelstr : (r2_score(y_test, predicted) * 100) })\n","b8bd9d51":"get_model_scores(gb_reg_model,\"GradientBoostingRegressor\")\nget_model_scores(rf_reg_model,\"RandomForestRegressor\")\nget_model_scores(xgb_reg_model,\"XGBRegressor\")\n\n# Needs hyperparam tuning to bring down the RMSE Values.","9a09b269":"# Converting 'Valence' column using a sigmoid function.\nspotify_classify_dataset.head(10)","d972835f":"# Popularity vs Energy Vs Valence\nfigure, axes = plt.subplots(1, 2, figsize=(28, 14))#plt.subplots(1,2)\naxes[0].set_title('Valence')\naxes[1].set_title('Energy')\n\nsn.scatterplot(ax=axes[0],data=spotify_classify_dataset,y='Popularity',x='Valence',palette='gist_earth')\nsn.scatterplot(ax=axes[1],data=spotify_classify_dataset,y='Energy',x='Valence',palette='Accent_r')","5cd5431a":"# defining a sigmoid\n\ndef sigmoid(value):\n    \n    if value<0.5:\n        outval = 0\n    else:\n        outval = 1\n    return outval\n\n# Transforming the Valence column.\n\nspotify_classify_dataset['Valence'] = spotify_classify_dataset['Valence'].apply(sigmoid)\n\nspotify_classify_dataset.head(10)","ad3762d6":"y11= spotify_classify_dataset['Valence']\nX11 = spotify_classify_dataset.drop(columns=['Valence'])","9261f68d":"from sklearn import tree\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\n#T-T-S\nX_train,X_test,y_train,y_test = train_test_split(X11,y11,train_size=0.7)\n\nrf_classifier_model = RandomForestClassifier()\nsvm_model = SVC(kernel = 'poly',degree=5)\ntree_model = tree.DecisionTreeClassifier()\n\nscores2 = {}\n\ndef get_model_scores(model,modelstr):\n    \n    \n    #Training the model\n    model.fit(X_train,y_train)\n    \n    # Predicting\n    predicted = model.predict(X_test)\n    \n    print(\"\\n \",modelstr,\" ------------\")\n    print(\"\\n R2 Score: \",model.score(X_test,y_test), r2_score(y_test, predicted))\n    print('\\n MAE:{}'.format(mean_absolute_error(y_test,predicted)))\n    print('\\n MSE:{}'.format(mean_squared_error(y_test,predicted)))\n    print('\\n RMSE:{}'.format(ny.sqrt(mean_squared_error(y_test,predicted))))\n    \n    scores2.update({modelstr : (r2_score(y_test, predicted) * 100) })","58113af9":"get_model_scores(rf_classifier_model,\"RandomForestClassifier\")\nget_model_scores(svm_model,\"Kernel SVM\")\nget_model_scores(tree_model,\"DecisionTreeClassifier\")","988c24bc":"# Plotting scores\n\nfigure, axes = plt.subplots(1, 2, figsize=(28, 13))#plt.subplots(1,2)\naxes[0].set_title('Regression Scores')\naxes[1].set_title('Classification Scores')\n\nkeys1 = list(scores.keys())\nvalues1 = list(scores.values())\nvalues2 = list(scores2.values())\nkeys2 = list(scores2.keys())\n\nsn.barplot(ax=axes[0],y=keys1,x=values1,palette='OrRd')\nsn.barplot(ax=axes[1],y=keys2,x=values2,palette='PuOr_r')","f1fc800d":"# 0. Introduction\nLet's take a look at the dataset for Exploratory Data Analysis.\n","11c887f3":"**Valence:** A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).","c172da08":"# 4. Classifying 'Valence' ( For a change... )","6b5f9f6b":"# 1. Primary checks and data cleaning","c584ca4a":"![](https:\/\/sm.mashable.com\/t\/mashable_in\/feature\/7\/7-hidden-s\/7-hidden-spotify-features-you-probably-didnt-know-about_fezm.1248.jpg)","b8848e6d":"# 2. Plotting observations on the numeric dataframe.","95f42bff":"**Initial thoughts :**\n\n1. To take a deep dive into dataset's variables, clean the data and visualize important use-cases.\n\n2. Consider a few independent variables and feature engineer accordingly.\n\n3. Use Mutual Information scores to get an idea of which features to select\/are of importance.\n\n4. Predict independent variables like popularity and streams.\n\n5. Classify 'Valence' ( This requires transforming the dataset's column ) - Doing this as a 'trial and error'.\n\n6. Record scores to see which Regressors and Classifiers do well.","73eb31a9":"#                                                        Top 200 Weekly (Global) charts of Spotify in 2020 & 2021","9f1bf8bf":"# Observations\n\n1. Random forest\/GB models have predicted streams well. Hyper param tuning may be needed to enhance.\n\n2. Without scaling the R2 scores were great but MAE\/MSE\/RMSEs were higher. Hence switched to RobustScaler.\n\n3. **Learning:** Just by transforming a single column and trying to classify many not be a good idea. Other feature holding correlation also should have appropriate transformation I guess. Negative R2 scores : If the chosen model fits worse than a horizontal line, then R2 is negative.\n\n4. \"Artist\",\"Song Name\" after Label Encoding brought down scores by 20%. Hence dropped these columns.\n\n5. Suggestions and comments welcome !\n\nThank You !","92887334":"Lets plot a few use-cases:\n\nA. Artist vs Highest Charting Position - Top and Bottom 20\n\nB. Artist vs Streams - Top and Bottom 20\n\nC. Song vs Streams - Top and Bottom 20\n\nD. Popularity vs Energy Vs Danceability","627d0ec7":"# 3. Data Modelling"}}