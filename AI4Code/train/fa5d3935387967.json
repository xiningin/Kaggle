{"cell_type":{"934de644":"code","10f8e830":"code","b83b97a1":"code","ce9753fd":"code","12896cb2":"code","7234b50c":"code","e86159d8":"code","6bd4c649":"code","7fc3ee5f":"code","a64a6e55":"code","47d0b71d":"code","a6246f6f":"code","99846af4":"code","8435b2f3":"code","65472890":"code","7cabf9cf":"markdown","1bbb8427":"markdown","bf7c3155":"markdown","f5b0b3b9":"markdown","fca8b0b4":"markdown","e97127ad":"markdown","61d57977":"markdown","59f3a6c9":"markdown","918fda3b":"markdown","711080eb":"markdown"},"source":{"934de644":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('display.max_rows',None)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv' , index_col = 'PassengerId')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv' , index_col = 'PassengerId')\n\nwhole_data = pd.concat([train, test] , axis = 0, sort=True)\n# Any results you write to the current directory are saved as output.","10f8e830":"whole_data.isnull().sum()\n","b83b97a1":"# Drop the features\ndata_processing= train.drop(['Cabin','Ticket'],axis=1)\n\n# Replace the NaN data from the column of Embarked as most frequent data 'S'\ndata_processing.Embarked.fillna('S',inplace=True)\n\n# Processing the test data also\ntest_processing = test.drop(['Cabin','Ticket'], axis = 'columns')\ntest_processing.Embarked = test.Embarked.fillna('S')\ntest_processing.Fare.fillna(test_processing.Fare.mean(), inplace =True)\n\ntest_processing.isnull().sum()","ce9753fd":"# Processing the feature Name\nlist =[]\nfor i in range(len(train)):\n    list.append(train.Name.iloc[i].split(',')[1].split()[0])\nhonor = pd.DataFrame(data = list, columns=['honor'], index = train.index)\nhonor.honor = np.where(honor.honor.isin(['Mr.','Miss.','Mrs.','Master.','Dr.']),\n                      honor.honor, 'Rare.')\ndata_processing.Name = honor.honor\n\n# Processing the feature Sex\ndata_processing.Sex = np.where(data_processing.Sex=='female',1,0)\n\n# Processing the test data also\nlist_test = []\nfor i in range(len(test)):\n    list_test.append(test.Name.iloc[i].split(',')[1].split()[0])\nhonor_test = pd.DataFrame(data = list_test , columns = ['honor'] , index = test.index)\nhonor_test.honor = np.where(honor_test.honor.isin(['Mr.','Miss.','Mrs.','Master.','Dr.']),\n                           honor_test.honor, 'Rare.')\n\ntest_processing.Name = honor_test.honor\n\n# Processing the feture sex of the test data\ntest_processing.Sex = np.where(test_processing.Sex=='female',1,0)\n\ndata_processing.head()","12896cb2":"# Encoding the columns of Name, Embarked into numerical data using One_hot_encoder.\nfrom sklearn.preprocessing import OneHotEncoder\none_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n\nname_enc = pd.DataFrame(one_hot_encoder.fit_transform(data_processing[['Name']]).toarray(),\n                        index = data_processing.index,\n                        columns = one_hot_encoder.get_feature_names(['']))\nembarked_enc = pd.DataFrame(one_hot_encoder.fit_transform(data_processing[['Embarked']]).toarray(),\n                           index = data_processing.index,\n                           columns = one_hot_encoder.get_feature_names(['Embarke']))\n\ndata_processed = pd.concat([data_processing,name_enc,embarked_enc], axis = 1).drop(['Name','Embarked'], axis = 'columns' )\n\n# Encoding the test data also\nname_enc_test = pd.DataFrame(one_hot_encoder.fit_transform(test_processing[['Name']]).toarray(),\n                        index = test_processing.index,\n                        columns = one_hot_encoder.get_feature_names(['']))\nembarked_enc_test = pd.DataFrame(one_hot_encoder.fit_transform(test_processing[['Embarked']]).toarray(),\n                           index = test_processing.index,\n                           columns = one_hot_encoder.get_feature_names(['Embarke']))\n\ntest_processed = pd.concat([test_processing,name_enc_test,embarked_enc_test], axis = 1).drop(['Name','Embarked'], axis = 'columns' )","7234b50c":"plt.figure(figsize=(14,10))\nsns.heatmap(data_processed.corr(),annot=True,center=0,cmap= 'coolwarm')","e86159d8":"# Plotting the histogram of Fare of Survived and Un-Survived.\nsns.set(style='darkgrid')\nplt.figure(figsize=(10,5))\nplt.xlim(-10,150)\nsns.distplot(train.groupby('Survived')[['Fare']].get_group(0), bins=300, color='blue', label = 'UnSurvived')\nsns.distplot(train.groupby('Survived')[['Fare']].get_group(1), bins=300, color='red', label='Survived')\nplt.legend(); plt.xlabel('Fare'); plt.ylabel('Survived'); plt.title('Fare-Survived',fontsize=22); plt.show()\n","6bd4c649":"# Analyze Age,Pclass and the others.\nplt.figure(figsize=(10,5))\nsns.distplot(train.groupby('Survived')[['Age']].get_group(0),\n            label = 'UnSurvivied', bins=30)\nsns.distplot(train.groupby('Survived')[['Age']].get_group(1),\n            label = 'Survivied', bins=30)\nsns.kdeplot(data = train.Age)\nplt.title('Age - Survived',fontsize = 13) ;plt.xlabel('Age',fontsize = 13)\nplt.ylabel('Survived');plt.legend()\n","7fc3ee5f":"man = train.groupby('Sex').get_group('male')\nwoman = train.groupby('Sex').get_group('female')\n\nf, axes = plt.subplots(1,2 ,figsize=(16,6), sharex = True)\nsns.despine(left=True)\n\nsns.distplot(man.groupby('Survived')['Age'].get_group(1),color = 'red', label = 'Survived', ax = axes[0], bins=20)\nsns.distplot(man.groupby('Survived')['Age'].get_group(0), label = 'UnSurvived', ax=axes[0], bins=20)\naxes[0].set_title('Man - Age'); axes[0].legend(); axes[0].set_ylabel('Ratio')\n\nsns.distplot(woman.groupby('Survived')['Age'].get_group(1),color = 'red', label = 'Survived', ax = axes[1], bins=20)\nsns.distplot(woman.groupby('Survived')['Age'].get_group(0), label = 'UnSurvived', ax=axes[1], bins=20)\naxes[1].set_title('Woman - Age'); plt.legend()","a64a6e55":"from sklearn.model_selection import train_test_split as tts\nfrom sklearn.ensemble import RandomForestRegressor\n\n\ndef Age_processing(data):\n    man_data = data.groupby('Sex').get_group(0)\n    woman_data = data.groupby('Sex').get_group(1)\n    \n    man_predicted = Age_predict(man_data)\n    woman_predicted = Age_predict(woman_data)\n    \n    man_predicted_cat= pd.cut(x = man_predicted['Age'], bins=[0,18,30,50,man_predicted.Age.max()],\n                              labels = [0,1,2,3])\n    woman_predicted_cat = pd.cut(x = woman_predicted['Age'], bins=[0,7,22,40,45,woman_predicted.Age.max()],\n                                labels = [4,5,6,7,8])\n    \n    man_predicted.Age = man_predicted_cat\n    woman_predicted.Age = woman_predicted_cat\n    \n    Age_predicted = pd.concat([woman_predicted, man_predicted] , axis = 0)\n    \n    return Age_predicted.sort_index()\n\ndef Age_predict(data):\n    Age_data = data[data.Age.isnull()==False]\n    Missing_data = data[data.Age.isnull()==True].drop(['Age'], axis = 'columns')\n    \n    x_data = Age_data.drop(['Age'], axis='columns')\n    y_data = Age_data.Age\n    \n    \n    rfr = RandomForestRegressor(n_estimators=1000 , random_state = 0)\n    rfr.fit(x_data, y_data)\n    Missing_data['Age'] = rfr.predict(Missing_data)\n    \n    data_predict = pd.concat([Missing_data, Age_data], axis = 'index', sort=True)\n    \n    return data_predict\n","47d0b71d":"# Deal with missing data from train data and also test data.\ndata_processed_ = Age_processing(data_processed)\ntest_processed_ = Age_processing(test_processed)\n\ndata_Age_enc = pd.DataFrame(one_hot_encoder.fit_transform(data_processed_[['Age']]).toarray(),\n                           index = data_processed_.index)\ntrain_data = pd.concat([data_processed_,data_Age_enc], axis=1).drop(['Age'], axis=1)\n\ntest_Age_enc = pd.DataFrame(one_hot_encoder.fit_transform(test_processed_[['Age']]).toarray(),\n                           index = test_processed_.index)\ntest_data = pd.concat([test_processed_, test_Age_enc], axis=1).drop(['Age'], axis='columns')","a6246f6f":"plt.figure(figsize=(9,7))\nsns.heatmap(train_data[['Survived',0,1,2,3,4,5,6,7,8]].corr(),\n            annot=True,center=0,cmap='BrBG_r')\n","99846af4":"drop_feature = ['Survived','SibSp','Parch']\nfrom sklearn.model_selection import train_test_split as tts\nx_train, x_test, y_train, y_test = tts(train_data.drop(drop_feature, \n                                                       axis = 'columns'),\n                                       train_data.Survived, random_state=0, test_size=0.2)\n\nfrom sklearn.linear_model import LogisticRegression\nLR = LogisticRegression()\nLR.fit(x_train,y_train)","8435b2f3":"from sklearn.model_selection import cross_validate\ncross_validate(LR, x_test, y_test, cv=5)['test_score'].mean()","65472890":"my_model = LogisticRegression()\n\nx_train_data = train_data.drop(['Survived','SibSp','Parch'], axis = 'columns')\ny_train_data = train_data.Survived\nmy_model.fit(x_train_data, y_train_data)\nprediction = my_model.predict(test_data.drop(['SibSp','Parch'], axis = 'columns'))\nmy_submission = pd.DataFrame(prediction, index=test_data.index, columns=['Survived'])\nmy_submission.to_csv('submission.csv')\n","7cabf9cf":"# What to do\n1. Preprocess the data\n2. Make an insight with heatmap\n3. Take a look at the data and find other correlation between the features.\n3. Processing\n4. Fit\n5. cross-validation","1bbb8427":"As we can see, There are not a big correlation between them after about age 30. But also, we can get some information that the survival rate from under about 18 is greater than over about age 18 and under about age 30. Now we have to figure out if there is really correlation between Age,Sex,Survived.","bf7c3155":"According to these results, I can split the column of Age from man-data into three parts.\n>1. under 18   \n2. over 18 and under 30\n3. over 30 and under 50\n4. over 50\n\nAnd from woman-data\n>1. under 25\n2. over 25 and under 50\n3. over 50\n\nWhy I'm spliting the data is the targer data dosen't go up in derect propotion with the Age data. So I believe that using the One_hot_encoder for the Age data would bring more accurate prediction. Because each specific age has to have a different weight in a model.\n\nNow What I have to do is to process the missing data from Age Not only train data, but also test data. So Writing some functions for dealing with missing data would make it more easier. ","f5b0b3b9":"Through thih heat map, I could catch some obvious clues.  \n1. The survival rates of man is so lower than woman.\n2. The survival of rich people is higher than not-rich pople.\n\nWhat I wonder is why the feature Age has not much correlation with Survived than I expected. The heat map shows comprehensive contextual information. We can think of it as a tendency.I guess the feature Age has a correlation with the target certainly. Let's take a look at the data more detaily.","fca8b0b4":"< Age >  \nThe colunms of Age is one of the most important feature to predict the target. So later, I will deal with it quit detailiy. But now, to make a heatmap to get an insight, Let me just drop the NaN data from Age.\n\n< Cabin >  \nI guess that Ticket, Cabin have a similar kind of information with Fare and Pclass. I will use Fare and Pclass as features instead of Ticket and Cabin. Beacause those are more easier to process then the others. So Let me drop the columns.\n\n< Embarked >  \nThere are a lot of cases who had embarked from the city 'S'. So I will replace NaN data to S.  ","e97127ad":"It's almost done. Now I will use one_hot_encoder to convert the column of the categorized Age into the columns of the uniques.","61d57977":"First of all. Let's figure out which data is missing.","59f3a6c9":"Second, Let's process the non-numerical data. i.e object data.\n\n< Name >  \nI'm only interested in the honorifics('Mr','Mrs',etc). I'm going to parse it and use it with one_hot_encoder.\n\n< Sex >  \nThere are two way to use this feature. One is to use one_hot_encoder and another is to replace strings as numbers. The latter is easier than the former.\n\n< Embarked >  \nOne_hot_encoder\n","918fda3b":"As I mentioned above, we could see the correlation between Survived and Fare through the plot. The greater a price of fare , The greater probability of survival.","711080eb":"Let's convert Object data into numerical data using One_hot_encoder."}}