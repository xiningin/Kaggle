{"cell_type":{"ebdd2efa":"code","5adf5d56":"code","fa096b14":"code","df3edc95":"code","bc1a1fb9":"code","e06afde3":"code","1aaa2339":"code","93574ff0":"code","b4fb68e3":"code","7892fa2a":"code","d2b0e03d":"code","f851950a":"code","08b252d0":"code","487c96f5":"code","8468a12c":"code","4d67cbe5":"markdown","46a6370d":"markdown","f3dfa17f":"markdown","1be0be7a":"markdown","27f5147b":"markdown","7c8833f9":"markdown","9f355cd0":"markdown"},"source":{"ebdd2efa":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os, glob, pickle, time, gc, copy, sys\nimport warnings\nfrom tqdm import tqdm\nfrom sklearn import metrics\n\ntqdm.pandas()\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 100)","5adf5d56":"df_train = pd.read_csv(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv\")\nprint('len(df_train): {}'.format(len(df_train)))\nprint(\"df_train['MGMT_value'].mean(): {:.6f}\".format(df_train['MGMT_value'].mean()))\ndf_train.head()","fa096b14":"df_test = pd.read_csv(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv\")\nprint('len(df_test): {}'.format(len(df_test)))\ndf_test.head()","df3edc95":"# assume that positive rate of the test data is same with the train data.\nnum_positive = int(len(df_test)*df_train['MGMT_value'].mean())\nprint(\"num_positive: {}\".format(num_positive))","bc1a1fb9":"# make true labels\ny_true = np.zeros(len(df_test))\ny_true[:num_positive] = 1\nprint(\"y_true.mean(): {:.6f}\".format(y_true.mean()))","e06afde3":"# make random prediction\ny_pred = np.random.rand(len(df_test))\ny_pred","1aaa2339":"# calculate the score\nfrom sklearn import metrics\nscore = metrics.roc_auc_score(y_true, y_pred)\nprint(\"score: {:.6f}\".format(score))","93574ff0":"from tqdm.auto import tqdm","b4fb68e3":"# try random prediction 1000 times.\nscores = []\nfor i in tqdm(range(100000)):\n    np.random.seed(i)\n    y_pred = np.random.rand(len(df_test))\n    score = metrics.roc_auc_score(y_true, y_pred)\n    scores.append(score)\ndf_score = pd.DataFrame(scores, columns=['score'])\ndf_score = df_score.sort_values('score').reset_index(drop=True)\nplt.hist(df_score['score'], bins=10)\nplt.show()\ndf_score.tail()","7892fa2a":"print(f'(1 random sub) percentile-50 : {np.percentile(scores, 50)}')\nprint(f'(1 random sub) percentile-90 : {np.percentile(scores, 90)}')\nprint(f'(1 random sub) percentile-95 : {np.percentile(scores, 95)}')\nprint(f'(1 random sub) percentile-99 : {np.percentile(scores, 99)}')\nprint(f'(1 random sub) percentile-99.9 : {np.percentile(scores, 99.9)}')\nprint(f'(1 random sub) percentile-99.99 : {np.percentile(scores, 99.99)}')","d2b0e03d":"import random\n\nscores_10 = []\nscores_20 = []\nscores_30 = []\nscores_50 = []\nscores_100 = []\n\n# pick k random scores randomly from the 1M pool\nfor i in tqdm(range(10000)):\n    random.seed(i)\n    \n    scores_10.append(np.max(random.choices(scores, k=10)))\n    scores_20.append(np.max(random.choices(scores, k=20)))\n    scores_30.append(np.max(random.choices(scores, k=30)))\n    scores_50.append(np.max(random.choices(scores, k=50)))\n    scores_100.append(np.max(random.choices(scores, k=100)))","f851950a":"print(f'(10 random subs) percentile-50 : {np.percentile(scores_10, 50)}')\nprint(f'(10 random subs) percentile-90 : {np.percentile(scores_10, 90)}')\nprint(f'(10 random subs) percentile-95 : {np.percentile(scores_10, 95)}')\nprint(f'(10 random subs) percentile-99 : {np.percentile(scores_10, 99)}')\nprint(f'(10 random subs) percentile-99.9 : {np.percentile(scores_10, 99.9)}')\nprint(f'(10 random subs) percentile-99.99 : {np.percentile(scores_10, 99.99)}')","08b252d0":"print(f'(20 random subs) percentile-50 : {np.percentile(scores_20, 50)}')\nprint(f'(20 random subs) percentile-90 : {np.percentile(scores_20, 90)}')\nprint(f'(20 random subs) percentile-95 : {np.percentile(scores_20, 95)}')\nprint(f'(20 random subs) percentile-99 : {np.percentile(scores_20, 99)}')\nprint(f'(20 random subs) percentile-99.9 : {np.percentile(scores_20, 99.9)}')\nprint(f'(20 random subs) percentile-99.99 : {np.percentile(scores_20, 99.99)}')","487c96f5":"print(f'(50 random subs) percentile50 : {np.percentile(scores_50, 50)}')\nprint(f'(50 random subs) percentile90 : {np.percentile(scores_50, 90)}')\nprint(f'(50 random subs) percentile95 : {np.percentile(scores_50, 95)}')\nprint(f'(50 random subs) percentile99 : {np.percentile(scores_50, 99)}')\nprint(f'(50 random subs) percentile99.9 : {np.percentile(scores_50, 99.9)}')\nprint(f'(50 random subs) percentile99.99 : {np.percentile(scores_50, 99.99)}')","8468a12c":"print(f'(100 random subs) percentile50 : {np.percentile(scores_100, 50)}')\nprint(f'(100 random subs) percentile90 : {np.percentile(scores_100, 90)}')\nprint(f'(100 random subs) percentile95 : {np.percentile(scores_100, 95)}')\nprint(f'(100 random subs) percentile99 : {np.percentile(scores_100, 99)}')\nprint(f'(100 random subs) percentile99.9 : {np.percentile(scores_100, 99.9)}')\nprint(f'(100 random subs) percentile99.99 : {np.percentile(scores_100, 99.99)}')","4d67cbe5":"## One submission\n\nWith one all-random submit, the median LB score is 0.5 AUC. ","46a6370d":"## Simulate LB score after multiple all-random submits\n\nLB shows the maximum score, so if you submit all-random multiple times, you are more likely to get a high scoring.","f3dfa17f":"The public test data has only 87 samples. So that, the public LB score must be unstable. I check it below.","1be0be7a":"The simulations above shows that a score of about 0.65 is almost by chance. Don't believe the public LB score too much. ","27f5147b":"This is a fork of osciiart's notebook: https:\/\/www.kaggle.com\/osciiart\/public-lb-simulation\n\nI continued the analysis to simulate LB score after multiple random-value submits.","7c8833f9":"# Public LB simulation","9f355cd0":"# Data loading"}}