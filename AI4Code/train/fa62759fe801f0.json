{"cell_type":{"9e0d3d15":"code","64abe787":"code","991c390c":"code","fb704e53":"code","c7b7dbab":"code","301fa1bc":"code","cca140ef":"code","c77a95ff":"code","4c6cc7d9":"code","c21ff0de":"code","ce7cfc45":"code","88100dce":"code","ed5c3ad8":"code","f1d5b855":"code","5b45dd2d":"code","c5ba1855":"code","927306c0":"code","81e12bc3":"code","47184383":"code","9e6c0ee9":"code","132765b2":"code","617db799":"code","129a3d8d":"code","df6efd9d":"code","d88937d1":"code","69cf0f40":"code","06e164dd":"code","c917931e":"code","3398d2b2":"code","83bdd442":"code","a70942b0":"code","f69d45ef":"code","26f702b6":"code","6e3ca27d":"code","0d78d0b4":"code","5d44c5f9":"markdown","25bbfcb8":"markdown","e91f88e3":"markdown","68bd69f4":"markdown","c912a617":"markdown","76766f93":"markdown","bec37d18":"markdown","123b0ac5":"markdown","d1c5c825":"markdown","cae29214":"markdown","d3f652ef":"markdown","dd833bd0":"markdown","de5e82ec":"markdown","527e52c9":"markdown","6f9732b9":"markdown","47726ab9":"markdown","02978280":"markdown","acf15a05":"markdown","b3f00cc3":"markdown","d04c78cf":"markdown","a34d9d3d":"markdown","c28a978e":"markdown","24b897a9":"markdown","0d312414":"markdown","1bdcad38":"markdown","51a79985":"markdown","4f739938":"markdown","923387a7":"markdown","9b2e4321":"markdown"},"source":{"9e0d3d15":"# Data Manipulation, Linear Algebra\nimport pandas as pd\nimport numpy as np\n\n# Plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\n# Machine Learning\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, precision_recall_curve, roc_curve\n\nfrom sklearn import tree, linear_model, ensemble\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\n# Ignore Warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")","64abe787":"train_data = pd.read_csv(\"..\/input\/income-adult\/adult_data.csv\")\ntest_data = pd.read_csv(\"..\/input\/income-adult\/adult_test.csv\")","991c390c":"print(\"Train Data Shape:\", train_data.shape)\nprint(\"Test Data Shape:\", test_data.shape)","fb704e53":"cols = []\nfor col in train_data.columns:\n    cols.append(col.strip())\n\ntrain_data = train_data.set_axis(cols, axis=1)\ntest_data = test_data.set_axis(cols, axis=1)\n\ntest_data[\"salary\"] = test_data[\"salary\"].apply(lambda x: x.strip(\".\"))","c7b7dbab":"obj_cols = train_data.select_dtypes(include=[np.object]).columns\n\nfor col in obj_cols:\n    train_data[col] = train_data[col].apply(lambda x: x.strip())\n    test_data[col] = test_data[col].apply(lambda x: x.strip())","301fa1bc":"train_data.sample(5)","cca140ef":"test_data.sample(5)","c77a95ff":"train_data.drop([\"race\", \"education\"], axis=1, inplace=True)\ntest_data.drop([\"race\", \"education\"], axis=1, inplace=True)","4c6cc7d9":"le = LabelEncoder()\n\ntrain_data[\"sex\"] = le.fit_transform(train_data[\"sex\"])\ntest_data[\"sex\"] = le.fit_transform(test_data[\"sex\"])","c21ff0de":"train_data[\"native-country\"] = train_data[\"native-country\"].map(lambda x: 0 if x==\"United-States\" else 1)\ntest_data[\"native-country\"] = test_data[\"native-country\"].map(lambda x: 0 if x==\"United-States\" else 1)","ce7cfc45":"plt.figure(dpi=80, figsize=(12, 6))\n\nplt.subplot(121)\nsns.countplot(x=\"sex\", data=train_data)\nplt.title(\"Train Data Gender Count\")\nplt.xticks([0, 1], [\"Male\", \"Female\"])\n\nplt.subplot(122)\nsns.countplot(x=\"salary\", hue=\"sex\", data=train_data)\nplt.title(\"Train Data Salary Values Count\")\nplt.legend([\"Male\", \"Female\"])\n\nplt.show()","88100dce":"plt.figure(figsize=(12, 6))\n\nplt.subplot(221)\nsns.distplot(train_data.age)\n\nplt.subplot(222)\nsns.distplot(train_data.fnlwgt)\n\nplt.subplot(223)\nsns.boxplot(train_data.age, width=0.3)\n\nplt.subplot(224)\nsns.boxplot(train_data.fnlwgt, width=0.3)\nplt.show()\n\n","ed5c3ad8":"plt.figure(dpi=80, figsize=(15, 8))\n\nplt.subplot(121)\nsns.countplot(y=train_data.workclass)\n\nplt.subplot(122)\nplt.pie(train_data.workclass.value_counts()[:-1], autopct='%.1f%%', labels=train_data.workclass.value_counts().index[:-1])\n\nplt.show()","f1d5b855":"train_data.loc[train_data.salary == \">50K\"].groupby(\"workclass\")[\"salary\"].value_counts()","5b45dd2d":"train_data.loc[train_data.salary != \">50K\"].groupby(\"workclass\")[\"salary\"].value_counts()","c5ba1855":"plt.figure(figsize=(10, 6))\nsns.countplot(y=\"education-num\", data=train_data)\nplt.show()","927306c0":"sns.pairplot(train_data, hue=\"salary\")\nplt.show()","81e12bc3":"X_train = train_data.drop(\"salary\", axis=1)\ny_train = train_data[\"salary\"]\n\nX_test = test_data.drop(\"salary\", axis=1)\ny_test = test_data[\"salary\"]","47184383":"X_train.head()","9e6c0ee9":"num_cols = list(X_train.select_dtypes(include=[np.number]).columns)\nnum_cols.remove(\"sex\")\nnum_cols","132765b2":"scaler = StandardScaler()\n\nscaled_train = pd.DataFrame(scaler.fit_transform(X_train[num_cols]), columns=num_cols)\nscaled_test = pd.DataFrame(scaler.transform(X_test[num_cols]), columns=num_cols)\n\nX_train.drop(num_cols, axis=1, inplace=True)\nX_test.drop(num_cols, axis=1, inplace=True)","617db799":"X_train = pd.concat([X_train, scaled_train], axis=1)\nX_test = pd.concat([X_test, scaled_test], axis=1)","129a3d8d":"X_train.head()","df6efd9d":"X_train = pd.get_dummies(X_train)\nX_test = pd.get_dummies(X_test)","d88937d1":"X_train.head()","69cf0f40":"MLA_compare = pd.DataFrame()\n\nrow_index = 0\n\ndef MLA_testing(MLA, X_train, X_test, y_train, y_test):  \n    global row_index\n    \n    # Training The Model\n    MLA.fit(X_train, y_train)\n\n    # KFold Accuracies on Training Data\n    kfold_accuracy = cross_val_score(estimator = MLA, X = X_train, y = y_train, cv = 10, n_jobs=-1)\n    print(\"K-Fold Accuracies:\\n\", kfold_accuracy, \"\\n\")\n    \n    # Prediction on Testing Data\n    y_pred = cross_val_predict(estimator = MLA, X = X_test, y = y_test, cv = 10, n_jobs=-1)\n    \n    # Accuracy for y_test and y_pred\n    classifier_accuracy_score = accuracy_score(y_test, y_pred)\n    print(\"Accuracy Score:\\n\", classifier_accuracy_score, \"\\n\")\n    \n    # Confusion Matrix\n    conf_mtx = confusion_matrix(y_test, y_pred)\n    print(\"Confusion Matrix:\\n\", conf_mtx, \"\\n\")\n    \n    # Classification Report\n    class_rep = classification_report(y_test, y_pred)\n    print(\"Classification Report:\\n\", class_rep, \"\\n\")\n    \n    # Saving Data in Dataframe\n    MLA_name = MLA.__class__.__name__\n    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n    MLA_compare.loc[row_index, 'Accuracy Score'] = classifier_accuracy_score\n    MLA_compare.loc[row_index, 'K-Fold Accuracy'] = kfold_accuracy.mean()\n\n    print(MLA_name, \"Done\")\n    \n    row_index+=1","06e164dd":"rf_clf = ensemble.RandomForestClassifier()\n\nMLA_testing(rf_clf, X_train.values, X_test.values, y_train.values, y_test.values)","c917931e":"# Feature Importance Score DataFrame\nfeature_imp = pd.DataFrame()\n\n# Getting the Feature Names and Their Importance Scores\nfeature_imp[\"Features\"] = X_train.columns\nfeature_imp[\"Features Importance Score\"] = rf_clf.feature_importances_\n\n# Sorting\nfeature_imp = feature_imp.sort_values(by=\"Features Importance Score\", ascending=False).reset_index(drop=True)[:15]\nfeature_imp","3398d2b2":"plt.figure(figsize=(10, 8), dpi=80)\nsns.barplot(x=\"Features Importance Score\", y=\"Features\", data=feature_imp)\nplt.title(\"Feature Importance Score Comparison\")\nplt.show()","83bdd442":"gb_clf = ensemble.GradientBoostingClassifier()\n\nMLA_testing(gb_clf, X_train, X_test, y_train, y_test)","a70942b0":"sgf_clf = linear_model.SGDClassifier(loss=\"log\")\n\nMLA_testing(sgf_clf, X_train, X_test, y_train, y_test)","f69d45ef":"dt_clf = tree.DecisionTreeClassifier()\n\nMLA_testing(dt_clf, X_train, X_test, y_train, y_test)","26f702b6":"xgb_clf = XGBClassifier(eval_metric=\"logloss\")\n\nMLA_testing(xgb_clf, X_train, X_test, y_train, y_test)","6e3ca27d":"cb_clf = CatBoostClassifier(silent=True)\n\nMLA_testing(cb_clf, X_train, X_test, y_train, y_test)","0d78d0b4":"MLA_compare = MLA_compare.sort_values(by=\"K-Fold Accuracy\", ascending=False).reset_index(drop=True)\nMLA_compare","5d44c5f9":"## XGBoostClassifier","25bbfcb8":"#### Most of the People have less than 50K salary\n#### Most of the People with more than 50K salary are women","e91f88e3":"## Feature Scaling Numerical Columns","68bd69f4":"# Data Cleaning","c912a617":"## DecisionTreeClassifier","76766f93":"## Dataframe to store all the accuracy scores for Comparison and Analysis","bec37d18":"#### Most of the people that have salary lower than 50K also work in Privare Sector","123b0ac5":"### Viewing Top 10 Important Features","d1c5c825":"## Striping Spaces from Column Names","cae29214":"## OneHotEncoding Categorcal Variables","d3f652ef":"## Modifying Data in \"native-country\" Column\n### 0 if United States and 1 if other","dd833bd0":"## Dropping \"race\" and \"education\" feature","de5e82ec":"## GradientBoostingClassifier","527e52c9":"## Loading Data","6f9732b9":"## Seperating Dependent Variable","47726ab9":"## CatBoostClassifier","02978280":"## RandomForestClassifier","acf15a05":"## Label Encode \"sex\"","b3f00cc3":"#### Most of the people have 9, 10 and 13 Qualifications","d04c78cf":"## Viewing Data Samples","a34d9d3d":"# Preparing Data","c28a978e":"# Comparing Models","24b897a9":"## SGDClassifier","0d312414":"## Striping Spaces from Data","1bdcad38":"# EDA","51a79985":"#### Most of the people that have higher than 50K salary work in Privare Sector","4f739938":"# Importing Libraries and Overview","923387a7":"#### The data for age and final weight is right skewed","9b2e4321":"# Modeling"}}