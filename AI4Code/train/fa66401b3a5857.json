{"cell_type":{"e523bcbe":"code","5400a3e9":"code","96fe06a6":"code","6e863794":"code","44d5c5ad":"code","9e2e543e":"code","0a06ea83":"code","20bb252d":"code","c0f2873a":"code","9c28feb2":"code","ac6d251c":"code","267a542f":"code","b2216d1e":"code","46a342b9":"code","35bf75f3":"code","b3ef4e89":"code","df0b0c3e":"code","49e8faf0":"code","e1e6b5f6":"code","05c052ff":"code","3d68c173":"code","3ed34c64":"markdown","97f8a90e":"markdown","007c3b60":"markdown","d7527121":"markdown","b5a21976":"markdown","8a5792ea":"markdown"},"source":{"e523bcbe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5400a3e9":"# Loading dataset \ndf = pd.read_csv('\/kaggle\/input\/latest-covid19-india-statewise-data\/Latest Covid-19 India Status.csv')\ndf.info()","96fe06a6":"# Getting first 5 rows \ndf.head()","6e863794":"# Checking no of states & UT .\nprint('There are {} no of states & union territories info . '.format(len(df['State\/UTs'])))\nprint('And they are: \\n {}'.format(df['State\/UTs'].unique()))","44d5c5ad":"# Checking which states or UT has the highest active cases .\nplt.figure(figsize = (10,9))\nplt.plot(df['Active'],df['State\/UTs'])\nplt.xlabel('No of Active Cases')\nplt.ylabel('States or Union Territories')","9e2e543e":"# Checking which states or UT has the highest discharged cases .\nplt.figure(figsize = (10,9))\nplt.plot(df['Discharged'],df['State\/UTs'])\nplt.xlabel('Discharged Cases')\nplt.ylabel('States or Union Territories')","0a06ea83":"# Checking which states or UT has the highest death cases .\nplt.figure(figsize = (10,9))\nplt.plot(df['Deaths'],df['State\/UTs'])\nplt.xlabel('Deaths Cases')\nplt.ylabel('States or Union Territories')","20bb252d":"ratio_df = df.iloc[:,5:]\nratio_df.head()","c0f2873a":"plt.figure(figsize = (10,9))\nplt.plot(ratio_df,df['State\/UTs'] , label = ('Active','Discharge','Death'))\nplt.xlabel(\"Ratio's of Active,Discharge and Death cases.\")\nplt.ylabel('States or Union Territories')\nplt.legend()\nplt.show()","9c28feb2":"#We have got str values in States\/UTs columns\ns = (df.dtypes == 'object')\nobject_cols = s[s].index\nprint(\"Categorical Variable :{} \".format(object_cols))","ac6d251c":"#so lets convert them into int values.\nfrom sklearn.preprocessing import OrdinalEncoder\noe = OrdinalEncoder()\ndf[object_cols] = oe.fit_transform(df[object_cols])","267a542f":"# So lets check the values which are assigned by Ordinal Encoder to object column.\n\ndf[object_cols]","b2216d1e":"# Let's one again check our dataframe .\ndf.sample(2)","46a342b9":"# Divide features and labels for train_test_split\ndf_features = df.iloc[:,:]\ndf_label = df['Deaths']","35bf75f3":"#Since We have label as Deaths so we need to drop it from the features.\ndf_features = df_features.drop('Deaths',axis =1 )\ndf_features.sample(1)","b3ef4e89":"# We don't have our features in same scale i.e some values are close to 100 and some are close to 1\n# So in order to get the best model we should scale our features.\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\ndf_features_cols = df_features.columns \n# In scaling , standard scaler will remove the columns from features.\n# So we need to add those columns back to the scaled features\ndf_features[df_features_cols] = sc.fit_transform(df_features[df_features_cols])","df0b0c3e":"# Lets check our scaled features \ndf_features.sample(2)","49e8faf0":"# We need to split our dataframe into train_test . \n\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(df_features,df_label,test_size = 0.2 )\nprint('Shape of x_train: ',x_train.shape)\nprint('Shape of y_train:',y_train.shape)\nprint('Shape of x_test:',x_test.shape)\nprint('Shape of y_test:',y_test.shape)","e1e6b5f6":"# Let's build ML model out of this data now. \n\nfrom sklearn.linear_model import LinearRegression\nlr_model = LinearRegression()\nlr_model.fit(x_train,y_train)\nlr_model.score(x_test,y_test)","05c052ff":"# We need to do predictions on x_test \ny_pred = lr_model.predict(x_test)","3d68c173":"from sklearn.metrics import mean_squared_error,r2_score\nprint(\"Mean Squared Error: {}\".format(mean_squared_error(y_test,y_pred)))\nprint(\"R2 Score: {}\".format(r2_score(y_test,y_pred)))","3ed34c64":"<h3>As we can see death ratios are very minimal campared to active ratio's<\/h3>","97f8a90e":"<h3>Manipur,Maharashtra,Madhya Pradesh has the highest discharge numbers,\nfollowed by Ladakh , Kerala , Karnataka and etc <\/h3> ","007c3b60":"<h3>We cannot analyse Deaths by No of discharge cases because we can see No of discharge cases in Maharashtra was the most but still Maharashtra has the highest death cases <.h3>","d7527121":"<h3>So,we can clearly figure out Ladakh,Kerala,Karnataka has the highest active cases.<\/h3>","b5a21976":"<h3> The less the value of Mean Squared Error the better the model is , Whereas for R2 score the closer the value gets to 100 % the better the model.<\/h3>","8a5792ea":"<h3> So let's try to predict No of deaths <\/h3>"}}