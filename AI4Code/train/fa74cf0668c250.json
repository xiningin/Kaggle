{"cell_type":{"75af448a":"code","dd3bc582":"code","079787d3":"code","063bfe31":"code","05abecc2":"code","5a85e4a2":"code","8a79bfea":"code","d22af904":"code","e3d47034":"code","df2fb5eb":"code","42d62242":"code","90010bc2":"code","02147a7c":"code","41eef312":"code","64897399":"code","7cd2fa6c":"code","77bcf58e":"code","db3e31d4":"code","16048237":"markdown","495964b4":"markdown","b5c45210":"markdown","0872c3f8":"markdown","5b696982":"markdown"},"source":{"75af448a":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport sklearn.preprocessing \nfrom sklearn.model_selection import ShuffleSplit\nimport missingno\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport seaborn as sns\nfrom scipy.stats import uniform, randint\nfrom sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\nimport xgboost as xgb\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.impute import SimpleImputer","dd3bc582":"data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ndata.head()","079787d3":"data.info()","063bfe31":"missingno.bar(data)","05abecc2":"## Percentage of missing values\nmissingVals = data.isnull().mean() * 100\nmissingVals.sort_values(ascending=False).head(20)","5a85e4a2":"# Drop 0 variance cols: Id\n# and features with more than 50% of missing values \ndata.drop(columns=['Alley','Fence','PoolQC','MiscFeature','FireplaceQu','Id'], inplace=True)\n\n# separate features from target \ny = data['SalePrice']\ndata.drop(columns = ['SalePrice'], inplace= True)","8a79bfea":"## plot corrlation \nplt.figure(figsize=(10,10))\nsns.heatmap(data.corr());","d22af904":"## Show off the features with an absolute correlation more than 0.7\ncorr = data.corr()\nkot = corr[np.abs(corr)>=0.7]\nplt.figure(figsize=(12,8))\nsns.heatmap(kot, cmap=\"Reds\")","e3d47034":"## Drop correlated features\ndata.drop(columns=['GarageArea','GrLivArea','GarageYrBlt'], inplace=True)","df2fb5eb":"def get_num_cat_features(type_features, data):\n    return data.select_dtypes(include=type_features)\n\n## Get the numerical features\nnumerics = ['int64','float64']\nnewdf_num = get_num_cat_features(numerics, data)\n\n## Get the categorical features\nnewdf_cat = data.select_dtypes(['object'])\n","42d62242":"### WORK ON THE TEST SET\n## Drop the same features dropped earlier from the trainset \ntest.drop(columns=['Id','Alley','Fence','PoolQC','MiscFeature','FireplaceQu'], inplace= True)\ntest.drop(columns=['GarageArea','GrLivArea','GarageYrBlt'], inplace=True)\n\n## fill missing data with mean \ntest.fillna(test.mean())\n\n## Get the numerical features\nnewdf_numtest = get_num_cat_features(numerics, test)\n## Get the categorical features\nnewdf_cattest = test.select_dtypes(['object'])\n\n## concat the train and test sets(the categorical features only)  with preserving the order of the rows\ntrainTest = newdf_cat.append(newdf_cattest)","90010bc2":"## encoding labels:\ndef encode_labels(data):\n    encoded_categoric_train_set = data.copy()\n    for c in data.columns:\n        data[c]= data[c].astype('category')\n        encoded_categoric_train_set[c] = data[c].cat.codes\n    return encoded_categoric_train_set\n\n# encode the categorical data\nencoded_categoric_train_set = encode_labels(trainTest)\n\n# split the trainTest set again \nnewdf_cat = encoded_categoric_train_set[:1460]\ntest = encoded_categoric_train_set[1460:] \n\n#encoded_categoric_train_set = newdf_cat # or 1094\n","02147a7c":"## Scale numerical training data\nscaler = sklearn.preprocessing.StandardScaler()\nscaled_numeric_train_set = scaler.fit_transform(newdf_num)","41eef312":"numeric_train_set_df = pd.DataFrame(scaled_numeric_train_set, columns=newdf_num.columns)\n\n# fill numeric nans\nnumCols = numeric_train_set_df.columns\nimp = SimpleImputer(missing_values=np.nan, strategy='mean')\nnumeric_train_set_df = imp.fit_transform(numeric_train_set_df)\nnumeric_train_set_df = pd.DataFrame(numeric_train_set_df, columns=numCols)\n\n# fill categoric nan\ncatCols = newdf_cat.columns\nimp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\nnewdf_cat= imp.fit_transform(newdf_cat)\n\n## Merge numercial and catgorical data\nnewdf_cat = pd.DataFrame(newdf_cat, columns=catCols)\ntrain_set = pd.DataFrame(pd.merge(numeric_train_set_df,\n                 newdf_cat[newdf_cat.columns], on= numeric_train_set_df.index))\ntrain_set= train_set.drop(columns=['key_0'])\nX = train_set","64897399":"xgb_model = xgb.XGBRegressor()\nxgb_model = xgb.XGBRegressor()\n\nparams = {\n    \"colsample_bytree\": uniform(0.7, 0.3),\n    \"importance_type\": ['weight', 'gain', 'cover'],\n    \"gamma\": uniform(0, 0.5),\n    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n    \"max_depth\": randint(2, 6), # default 3\n    \"n_estimators\": randint(100, 150), # default 100\n    \"subsample\": uniform(0.6, 0.4),\n    \"num_parallel_tree\" :  randint(1, 5),\n    \"reg_lambda\":  randint(0, 5),\n    \"reg_alpha\":  randint(0, 5),\n    \n}\n\nsearch = RandomizedSearchCV(xgb_model, param_distributions=params, random_state=42, n_iter=200, cv=3, verbose=1, n_jobs=1, return_train_score=True)\n\nsearch.fit(X, y)","7cd2fa6c":"encoded_categoric_test_set = test\n\nscaled_numeric_test_set = scaler.transform(newdf_numtest)\n\nnumeric_test_set_df = pd.DataFrame(scaled_numeric_test_set, columns=newdf_num.columns)\n## Merge numercial and catgorical data\ntest_set = pd.DataFrame(pd.merge(numeric_test_set_df,\n                 test[test.columns], on= numeric_test_set_df.index))\ntest_set.drop(columns=['key_0'], inplace=True)\ntest_set.fillna(test_set.mean(), inplace=True)\nXtest = test_set[train_set.columns]\n","77bcf58e":"y_predict = search.predict(Xtest)","db3e31d4":"sample_submission = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\noutput = pd.DataFrame({'Id': sample_submission.Id,'SalePrice': y_predict})\noutput.to_csv('submission.csv', index=False)","16048237":"## Correlation","495964b4":"## Treating Numerical\/ Categorical data","b5c45210":"## Missing data","0872c3f8":"## Prediction","5b696982":"## Model "}}