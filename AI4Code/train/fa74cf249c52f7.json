{"cell_type":{"12d100a0":"code","de52d478":"code","dc54a3c0":"code","bfe13f4e":"code","a6fa3818":"code","6b90d760":"code","edddcfbb":"code","6e0bf303":"code","5a91471a":"code","9bb5e78d":"markdown","2110c5e7":"markdown","22aff249":"markdown","c677e8b2":"markdown","77f82eb6":"markdown","33744b71":"markdown"},"source":{"12d100a0":"!pip install Pillow\n!pip install nudged","de52d478":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport copy\nfrom shapely.geometry import shape, GeometryCollection, Polygon, MultiPolygon\nfrom shapely.affinity import affine_transform\nfrom PIL import Image, ImageOps\nimport nudged\nimport numpy as np\nfrom skimage.morphology import convex_hull_image\nimport matplotlib.pyplot as plt\nimport json\nimport plotly.graph_objs as go\nimport glob\nimport random","dc54a3c0":"geojson_files = glob.glob('\/kaggle\/**\/geojson_map.json', recursive=True)\ngeojson_file = random.choice(geojson_files)\ngeojson_file\n\nsite, floor = geojson_file.split('\/')[5:7]","bfe13f4e":"site = '5cd56be4e2acfd2d33b66d0e'\nfloor = '2F'","a6fa3818":"geojson_file = '\/kaggle\/input\/indoor-location-navigation\/metadata\/%s\/%s\/geojson_map.json' % (site, floor)\ninfos_file ='\/kaggle\/input\/indoor-location-navigation\/metadata\/%s\/%s\/floor_info.json' % (site, floor)\nimage_file ='\/kaggle\/input\/indoor-location-navigation\/metadata\/%s\/%s\/floor_image.png' % (site, floor)\n\nimage = Image.open(image_file)\n\nwith open(infos_file, 'rb') as f:\n    infos = json.load(f)\n    \nwith open(geojson_file, 'rb') as f:\n    geojson = json.load(f)","6b90d760":"image","edddcfbb":"def extract_coords_from_polygon(polygon):\n    coords = []\n    if type(polygon) == MultiPolygon:\n        polygons = polygon.geoms\n    else:\n        polygons = [polygon]\n\n    for polygon in polygons:\n        x, y = polygon.exterior.xy\n        coords.append((np.array(x), np.array(y)))\n        for interior in polygon.interiors:\n            x, y = interior.xy\n            coords.append((np.array(x), np.array(y)))\n\n    return coords\n\n\ndef get_bounding_box(x, y):\n    x_min = min(x)\n    y_min = min(y)\n    x_max = max(x)\n    y_max = max(y)\n    return np.array([\n        [x_min, y_min],\n        [x_min, y_max],\n        [x_max, y_min],\n        [x_max, y_max]\n    ])\n\n\ndef plot_shape(shapes):\n    if type(shapes) == Polygon:\n        shapes = [shapes]\n    for shape in shapes:\n        for interior in shape.interiors:\n            plt.plot(*interior.xy)\n        plt.plot(*shape.exterior.xy)\n\n\ndef extract_geometries(geojson):\n    # Extract floor plan geometry (First geometry)\n    floor = copy.deepcopy(geojson)\n    floor['features'] = [floor['features'][0]]\n    floor_layout = GeometryCollection([shape(feature[\"geometry\"]).buffer(0) for feature in floor['features']])[0]\n\n    # Extract shops geometry (remaining ones)\n    shops = copy.deepcopy(geojson)\n    shops['features'] = shops['features'][1:]\n    shops_geometry = GeometryCollection([shape(feature[\"geometry\"]).buffer(0.1) for feature in shops['features']])\n\n    # Geometry differences to get corridor (floor layout - shops)\n    corridor = copy.deepcopy(floor_layout)\n    for shop in shops_geometry:\n        corridor = corridor.difference(shop)\n\n    return floor_layout, corridor\n\n\ndef extract_image_bounding_box(image):\n    # Flip and convert to black and white\n    gray_image = ImageOps.flip(image).convert('LA')\n    bw_image = np.array(gray_image.point(lambda p: p > 251 and 255)) > 0\n    bw_image = Image.fromarray(bw_image.any(axis=2) == True)\n\n    # Get convex hull\n    ch_image = convex_hull_image(np.array(bw_image))\n\n    # Transform to coordinates\n    image_y, image_x = np.where(ch_image == True)\n\n    bounding_box = get_bounding_box(image_x, image_y)\n    return bounding_box\n\n\ndef extract_geojson_bounding_box(floor_layout):\n    # Get convex hull\n    ch_geojson = floor_layout.convex_hull\n\n    coords = [coord for coord in ch_geojson.exterior.coords]\n    geojson_x = [coord[0] for coord in coords]\n    geojson_y = [coord[1] for coord in coords]\n\n    bounding_box = get_bounding_box(geojson_x, geojson_y)\n    return bounding_box\n\n\ndef find_translation(points_a, points_b):\n    \"\"\"\n    Find best translation between 2 sets of points\n    Map right coefficients for:\n    https:\/\/shapely.readthedocs.io\/en\/stable\/manual.html#shapely.affinity.affine_transform\n    \"\"\"\n    trans = nudged.estimate(points_a, points_b)\n    matrix_cooefs = np.ravel(trans.get_matrix())\n\n    trans_coeffs = [\n        matrix_cooefs[0],\n        matrix_cooefs[1],\n        matrix_cooefs[3],\n        matrix_cooefs[4],\n        matrix_cooefs[2],\n        matrix_cooefs[5],\n    ]\n\n    return trans_coeffs\n\n\ndef geo_referencing(image, geojson, info):\n    \"\"\"\n    :param image: raw PIL image object\n    :param geojson: dict, geojson format\n    :param info: dict, plan infos\n    \"\"\"\n    # Extract floor layout and corridor geometries from geojson (shapely Polygon\/MultiPolygon)\n    floor_layout, corridor = extract_geometries(geojson)\n\n    # Extract bounding boxes both from image and geojson (Using convexhull)\n    image_bounding_box = extract_image_bounding_box(image)\n    geojson_bounding_box = extract_geojson_bounding_box(floor_layout)\n\n    # Find best translation from geojson to image referential\n    translation_coeffs = find_translation(geojson_bounding_box, image_bounding_box)\n\n    # Convert to image size scale\n    translated_corridor = affine_transform(corridor, translation_coeffs)\n\n    # Convert to waypoints scale (using ratio between waypoint scale and image scale)\n    x_ratio = info[\"map_info\"][\"width\"] \/ image.size[0]\n    y_ratio = info[\"map_info\"][\"height\"] \/ image.size[1]\n    waypoint_translation_coeffs = [\n        x_ratio, 0, 0,\n        y_ratio, 0, 0\n    ]\n    translated_corridor = affine_transform(translated_corridor, waypoint_translation_coeffs)\n\n    return translated_corridor","6e0bf303":"geometry = geo_referencing(image, geojson, infos)\nplot_shape(geometry)","5a91471a":"fig = go.Figure()\n\nfig.update_layout(\n    images=[\n        go.layout.Image(\n            source=image,\n            xref=\"x\",\n            yref=\"y\",\n            x=0,\n            y=infos[\"map_info\"][\"height\"],\n            sizex=infos[\"map_info\"][\"width\"],\n            sizey=infos[\"map_info\"][\"height\"],\n            sizing=\"contain\",\n            opacity=1,\n            layer=\"below\",\n        )\n    ]\n)\n\nfor coord in extract_coords_from_polygon(geometry):\n    x, y = coord\n    fig.add_trace(\n        go.Scattergl(\n            x=x,\n            y=y,\n        ))\n\n# configure\nfig.update_xaxes(autorange=False, range=[0, infos[\"map_info\"][\"width\"]])\nfig.update_yaxes(autorange=False, range=[0, infos[\"map_info\"][\"height\"]], scaleanchor=\"x\", scaleratio=1)\nfig.update_layout(\n    title=go.layout.Title(\n        text=\"Site: %s Floor: %s\" % (site, floor),\n        xref=\"paper\",\n        x=0,\n    ),\n    autosize=True,\n    width=900,\n    height=200 + 900 * infos[\"map_info\"][\"height\"] \/ infos[\"map_info\"][\"width\"],\n    template=\"plotly_white\",\n)\n\nfig.show()","9bb5e78d":"## Motivation\n\nHi there,\n\nI have been working on this Kaggle for the last couple of weeks and I must say it's a blast. Data is huge, making possibilities endless.\n\nAt my current job I have dealt with wifi and plan data before, working with shopping malls for different use cases.\nOne thing that really mattered to us was to build a solid plan, as something we could request from, that would give us more insights about the positions.\n\nAs you may have figured it out most paths only happen in the corridor, and never in the shops. Mainly cause wifi signals in shops are way less precise, and also cause shopping mall \"Access Points fields\" usually stop at the shops' door. They normally only populate the corridors with them.\n\nWith that observation done, one could like to extract the geometry of the corridor in order to have a field of possible positions, rather that considering an infinite R2 space.\nThat's what I have been working on in the last few days.\n\n**I translated the geojson from the raw data to match the plan images and thus to match the waypoints positions.**\nI also substracted the shop geometries from the floor layout geometries so that only the corridor geometry is kept, making it easier to work with.\n\nI have published the dataset: https:\/\/www.kaggle.com\/rafaelcartenet\/indoor-location-navigation-scaled-geojson\n\nIt contains for each floor of the 204 sites, the translated geometry as **shapely Polygons (or MultiPolygons)**. (https:\/\/shapely.readthedocs.io\/en\/stable\/manual.html#polygons)\n\nHope it is easy for y'all to work with!\n\nI might also add the translated geojson, if that helps some of you.\n\nI also made an hello world notebook to use the dataset for few use cases: https:\/\/www.kaggle.com\/rafaelcartenet\/how-to-use\nIt includes:\n- Determine whether a point (x, y) belongs to the corridor geometry\n- Find the closest point to the corridor\n- Discretize corridor\n\nBelow are the explanations of how I did it, the source code, as well as an example.\n\n","2110c5e7":"## Technique\n\nThe idea is rather simple. We have a geojson with its own referential (latitude longitude) and an image with its own referential (pixels).\nBy picking a set of points from the two sources, we can find the translation (affine transformation) from one referential to the other.\nThe easiest points to extract from both the image and the geojson are the bounding box points.\nThe key point here that allows us to do that is that the angle of both sources is the same. Meaning there is no rotation in our transformation, meaning the bounding box will represent the exact same points on the two sources.\n\nGeojson bounding box extraction (Super easy):\n- Extract x_min, y_min, x_max, y_max from all possible coordinates.\n- That's it\n\nImage bouding box extraction (bit more tricky):\n- Transform image to gray scale (making sure we keep allt he image details)\n- Only keep dark enough pixes using a threshold, making sure we only keep different than white pixels\n- Extract coordinates of the non null pixels\n- Extract x_min, y_min, x_max, y_max from all possible coordinates.\n\nIn both cases I have been first using the convex hull of the extracted coordinates, in order to extract from both sources a more stable object, as I thought.\nI realised later than the bouding box of a set of coordinates is actually the same bouding box of the convex hull of these same coordinates, making it potentially uselss. I even though kept it.\n\nProvided geojsons are actually well formatted. Each contains features, and the first feature is always the global layout of the floor. The remaining ones are the shops (or else) represented as blue polygons on the images.\nIt is thus pretty easy to do the difference between the floor layout and all the shops to keep only the corridor geometry.\n\nOnce I fitted the translation between my sets of points it is pretty straight forward to translate my corridor geometry.","22aff249":"Below is an example of the result, where the geometry has been ploted over the image of one floor plan, you can tell the geometry matches the corridor layout and excludes the inside shops.","c677e8b2":"Files loading","77f82eb6":"You can pick random floor for testing purposes","33744b71":"Result![image.png](attachment:image.png)"}}