{"cell_type":{"bf04f0e7":"code","bd9553a4":"code","83ef39f9":"code","00815fc5":"code","82a28c84":"code","55775321":"code","cabeb367":"code","e2682b44":"code","dee37772":"markdown"},"source":{"bf04f0e7":"!pip install kaggle-environments -U > \/dev\/null 2>&1\n!cp -r ..\/input\/lux-ai-2021\/* .","bd9553a4":"import numpy as np\nimport json\nfrom pathlib import Path\nimport os\nimport random\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split","83ef39f9":"model = torch.jit.load(\"..\/input\/models-lux\/model_dr.pth\")\nmodel.eval()\ntraced = torch.jit.trace(model.cpu(), torch.rand(1, 20, 32, 32))\ntraced.save('model_dr.pth')","00815fc5":"model = torch.jit.load(\"..\/input\/models-lux\/model_toad.pth\")\nmodel.eval()\ntraced = torch.jit.trace(model.cpu(), torch.rand(1, 20, 32, 32))\ntraced.save('model_toad.pth')","82a28c84":"model = torch.jit.load(\"..\/input\/models-lux\/model_rl.pth\")\nmodel.eval()\ntraced = torch.jit.trace(model.cpu(), torch.rand(1, 20, 32, 32))\ntraced.save('model_rl.pth')","55775321":"%%writefile agent.py\nimport os\nimport numpy as np\nimport torch\nfrom lux.game import Game\nfrom collections import Counter\n\n\npath = '\/kaggle_simulations\/agent' if os.path.exists('\/kaggle_simulations') else '.'\nmodel = torch.jit.load(f\"{path}\/model_dr.pth\")\nmodel.eval()\n\nmodel2 = torch.jit.load(f\"{path}\/model_rl.pth\")\nmodel2.eval()\n\nmodel3 = torch.jit.load(f\"{path}\/model_toad.pth\")\nmodel3.eval()\n\ndef make_input(obs, unit_id):\n    width, height = obs['width'], obs['height']\n    x_shift = (32 - width) \/\/ 2\n    y_shift = (32 - height) \/\/ 2\n    cities = {}\n    \n    b = np.zeros((20, 32, 32), dtype=np.float32)\n    \n    for update in obs['updates']:\n        strs = update.split(' ')\n        input_identifier = strs[0]\n        \n        if input_identifier == 'u':\n            x = int(strs[4]) + x_shift\n            y = int(strs[5]) + y_shift\n            wood = int(strs[7])\n            coal = int(strs[8])\n            uranium = int(strs[9])\n            if unit_id == strs[3]:\n                # Position and Cargo\n                b[:2, x, y] = (\n                    1,\n                    (wood + coal + uranium) \/ 100\n                )\n            else:\n                # Units\n                team = int(strs[2])\n                cooldown = float(strs[6])\n                idx = 2 + (team - obs['player']) % 2 * 3\n                b[idx:idx + 3, x, y] = (\n                    1,\n                    cooldown \/ 6,\n                    (wood + coal + uranium) \/ 100\n                )\n        elif input_identifier == 'ct':\n            # CityTiles\n            team = int(strs[1])\n            city_id = strs[2]\n            x = int(strs[3]) + x_shift\n            y = int(strs[4]) + y_shift\n            idx = 8 + (team - obs['player']) % 2 * 2\n            b[idx:idx + 2, x, y] = (\n                1,\n                cities[city_id]\n            )\n        elif input_identifier == 'r':\n            # Resources\n            r_type = strs[1]\n            x = int(strs[2]) + x_shift\n            y = int(strs[3]) + y_shift\n            amt = int(float(strs[4]))\n            b[{'wood': 12, 'coal': 13, 'uranium': 14}[r_type], x, y] = amt \/ 800\n        elif input_identifier == 'rp':\n            # Research Points\n            team = int(strs[1])\n            rp = int(strs[2])\n            b[15 + (team - obs['player']) % 2, :] = min(rp, 200) \/ 200\n        elif input_identifier == 'c':\n            # Cities\n            city_id = strs[2]\n            fuel = float(strs[3])\n            lightupkeep = float(strs[4])\n            cities[city_id] = min(fuel \/ lightupkeep, 10) \/ 10\n    \n    # Day\/Night Cycle\n    b[17, :] = obs['step'] % 40 \/ 40\n    # Turns\n    b[18, :] = obs['step'] \/ 360\n    # Map Size\n    b[19, x_shift:32 - x_shift, y_shift:32 - y_shift] = 1\n\n    return b\n\n\ngame_state = None\ndef get_game_state(observation):\n    global game_state\n    \n    if observation[\"step\"] == 0:\n        game_state = Game()\n        game_state._initialize(observation[\"updates\"])\n        game_state._update(observation[\"updates\"][2:])\n        game_state.id = observation[\"player\"]\n    else:\n        game_state._update(observation[\"updates\"])\n    return game_state\n\n\ndef in_city(pos):    \n    try:\n        city = game_state.map.get_cell_by_pos(pos).citytile\n        return city is not None and city.team == game_state.id\n    except:\n        return False\n\n\ndef call_func(obj, method, args=[]):\n    return getattr(obj, method)(*args)\n\n\nunit_actions = [('move', 'n'), ('move', 's'), ('move', 'w'), ('move', 'e'), ('build_city',)]\ndef get_action(policy, unit, dest):\n    for label in np.argsort(policy)[::-1]:\n        act = unit_actions[label]\n        pos = unit.pos.translate(act[-1], 1) or unit.pos\n        if pos not in dest or in_city(pos):\n            return call_func(unit, *act), pos \n            \n    return unit.move('c'), unit.pos\n\n\ndef agent(observation, configuration):\n    global game_state\n    \n    game_state = get_game_state(observation)    \n    player = game_state.players[observation.player]\n    actions = []\n    \n    # City Actions\n    unit_count = len(player.units)\n    for city in player.cities.values():\n        for city_tile in city.citytiles:\n            if city_tile.can_act():\n                if unit_count < player.city_tile_count: \n                    actions.append(city_tile.build_worker())\n                    unit_count += 1\n                elif not player.researched_uranium():\n                    actions.append(city_tile.research())\n                    player.research_points += 1\n    \n    # Worker Actions\n    dest = []\n    for unit in player.units:\n        if unit.can_act() and (game_state.turn % 40 < 30 or not in_city(unit.pos)):\n            state = make_input(observation, unit.id)\n            with torch.no_grad():\n                p = model(torch.from_numpy(state).unsqueeze(0))\n                p2 = model2(torch.from_numpy(state).unsqueeze(0))\n                p3 = model3(torch.from_numpy(state).unsqueeze(0))\n\n            policy = p.squeeze(0).numpy()\n            policy2 = p2.squeeze(0).numpy()\n            policy3 = p3.squeeze(0).numpy()\n\n            action, pos = get_action(policy, unit, dest)\n            action2, pos = get_action(policy2, unit, dest)\n            action3, pos = get_action(policy3, unit, dest)\n            action = Counter([action,action,action2,action3,action2,action3,action3]).most_common(1)[0][0]\n            actions.append(action)\n            dest.append(pos)\n\n    return actions","cabeb367":"from kaggle_environments import make\n\nenv = make(\"lux_ai_2021\", configuration={\"width\": 24, \"height\": 24, \"loglevel\": 2, \"annotations\": True}, debug=False)\nsteps = env.run(['agent.py', 'agent.py'])\nenv.render(mode=\"ipython\", width=1200, height=800)","e2682b44":"!tar -czf submission.tar.gz *","dee37772":"# Submission"}}