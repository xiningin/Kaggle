{"cell_type":{"df9af2b0":"code","5d932bd8":"code","1f35d4f5":"code","f43a4ae2":"code","2d0a3ac1":"code","90ace7ba":"code","0e1fdabf":"code","06f53260":"code","9b29c4a5":"code","d488daa3":"code","98f9cab5":"code","aa1f2614":"code","745a3bac":"code","b0a41b6f":"code","597dbd4a":"code","2722e5d2":"code","a93129f1":"code","1bd3554f":"code","cc2639b9":"code","464ebef3":"code","70c4322c":"code","0563427b":"code","e721003e":"code","bd65940c":"code","dbe6f972":"code","856e5d51":"code","113930c4":"code","b43b3780":"code","e85563b2":"code","2207412a":"code","5d67dc06":"code","29f5a880":"code","2fbd10dc":"code","59f9cda2":"code","96d63f36":"code","3892a08f":"code","21cac8f9":"code","e0176cec":"code","9559bce2":"code","d20661a0":"code","beeb993c":"code","d957eab0":"code","5e6fc798":"code","243aec6f":"code","db0d048c":"code","a9b4b5fe":"code","044f4a17":"code","de150d2c":"markdown","46a28a7a":"markdown","5fd4dd95":"markdown","46e7771b":"markdown","8d151d2c":"markdown","1f83da0d":"markdown","ee776faa":"markdown","06b5faf7":"markdown","259011c8":"markdown","189a185c":"markdown","c65fd1eb":"markdown","299572e2":"markdown","b506d5a4":"markdown","ea440023":"markdown","18f1c8e3":"markdown","6e62127f":"markdown","300c24be":"markdown","f43301fa":"markdown","25a3895e":"markdown","a697c3e9":"markdown","232e4183":"markdown","cc236109":"markdown","603632fb":"markdown","6dede66f":"markdown","685917b6":"markdown","f1200ddc":"markdown","12c574ad":"markdown","cbae28fe":"markdown","9c37586b":"markdown","e1a4500e":"markdown"},"source":{"df9af2b0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.pyplot import plot\n\ntableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),    \n             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),    \n             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),    \n             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),    \n             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]  \n\nfor i in range(len(tableau20)):    \n    r, g, b = tableau20[i]    \n    tableau20[i] = (r \/ 255., g \/ 255., b \/ 255.) \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5d932bd8":"df = pd.read_csv('\/kaggle\/input\/h-1b-visa\/h1b_kaggle.csv')","1f35d4f5":"#  Memory saving function credit to https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    #start_mem = df.memory_usage().sum() \/ 1024**2\n    #print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    #end_mem = df.memory_usage().sum() \/ 1024**2\n    #print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    #print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n\n    return df","f43a4ae2":"df = reduce_mem_usage(df)\ndf.head()","2d0a3ac1":"df.describe()","90ace7ba":"df.info()","0e1fdabf":"print(\"The shape of the dataset is : {}\".format(df.shape))","06f53260":"print(\"There were around {} applications for H-1B Visa from 2011 to 2016.\".format(df.shape[0]))","9b29c4a5":"df.CASE_STATUS.value_counts()","d488daa3":"plt.figure(figsize=(10,7))\ndf.CASE_STATUS.value_counts().plot(kind='barh',  color=tableau20)\ndf.sort_values('CASE_STATUS')\nplt.title(\"NUMBER OF APPLICATIONS\")\nplt.show()","98f9cab5":"df.YEAR.value_counts().plot(kind = 'bar',color=tableau20)","aa1f2614":"df.columns","745a3bac":"plt.figure(figsize=(10,7))\n\nax1 = df['EMPLOYER_NAME'][df['YEAR'] == 2011].groupby(df['EMPLOYER_NAME']).count().sort_values(ascending=False).head(10).plot(kind='barh', title = \"Top 10 Applicants in 2016\",\n                                                                                                                           color=tableau20)\nax1.set_label(\"\")\nplt.show()","b0a41b6f":"plt.figure(figsize=(10,7))\n\nax2 = df['EMPLOYER_NAME'][df['YEAR'] == 2016].groupby(df['EMPLOYER_NAME']).count().sort_values(ascending=False).head(10).plot(kind='barh', title='Top 10 Applicants in 2016'\n                                                                                                                             ,color=tableau20)\nax2.set_ylabel(\"\")\nplt.show()","597dbd4a":"plt.figure(figsize=(10,7))\n\nax3 = df['EMPLOYER_NAME'].groupby([df['EMPLOYER_NAME']]).count().sort_values(ascending=False).head(10).plot(kind = 'barh', title = 'Top 10 Applicants from 2011 to 2016'\n                                                                                                           ,color=tableau20)\nax3.set_ylabel(\"\")\nplt.show()","2722e5d2":"top_emp = list(df['EMPLOYER_NAME'][df['YEAR'] >= 2015].groupby(df['EMPLOYER_NAME']).count().sort_values(ascending=False).head(10).index)\n\nbyempyear = df[['EMPLOYER_NAME', 'YEAR', 'PREVAILING_WAGE']][df['EMPLOYER_NAME'].isin(top_emp)]\n\nbyempyear = byempyear.groupby([df['EMPLOYER_NAME'], df['YEAR']])","a93129f1":"plt.figure(figsize=(12,7))\n\nmarkers=['o','v','^','<','>','d','s','p','*','h','x','D','o','v','^','<','>','d','s','p','*','h','x','D']\n\nfor company in top_emp:\n    tmp = byempyear.count().loc[company]\n    plt.plot(tmp.index.values, tmp[\"PREVAILING_WAGE\"].values, label=company, linewidth=2,marker=markers[top_emp.index(company)])\nplt.xlabel(\"Year\")\nplt.ylabel(\"Number of Applications\")\nplt.legend()\nplt.title('Number of Applications of Top 10 Applicants')\nplt.show()","1bd3554f":"plt.figure(figsize=(12,7))\n\nfor company in top_emp:\n    tmp = byempyear.mean().loc[company]\n    plt.plot(tmp.index.values, tmp[\"PREVAILING_WAGE\"].values, label=company, linewidth=2,marker=markers[top_emp.index(company)])\nplt.xlabel(\"Year\")\nplt.ylabel(\"Average Salary offered (USD)\")\nplt.legend()\nplt.title('Average Salary of Top 10 Applicants')\nplt.show()","cc2639b9":"df.head()","464ebef3":"plt.figure(figsize=(10,12))\ndf.JOB_TITLE.value_counts().nlargest(20).plot(kind = 'barh', title = \"Top 20 Job Titles\",color=tableau20)\nplt.show()","70c4322c":"plt.figure(figsize=(12,7))\nsns.set(style=\"whitegrid\")\ng = sns.countplot(x = 'FULL_TIME_POSITION', data = df)\nplt.title(\"NUMBER OF APPLICATIONS MADE FOR THE FULL TIME POSITION\")\nplt.ylabel(\"NUMBER OF PETITIONS MADE\")\nplt.show()","0563427b":"df.head()","e721003e":"df = df[df['PREVAILING_WAGE'] <= 500000]\nby_emp_year = df[['EMPLOYER_NAME', 'YEAR', 'PREVAILING_WAGE']][df['EMPLOYER_NAME'].isin(top_emp)]\nby_emp_year = by_emp_year.groupby([df['EMPLOYER_NAME'],df['YEAR']])","bd65940c":"df.PREVAILING_WAGE.max()","dbe6f972":"## Checking for null values\ndf.isnull().sum()","856e5d51":"df['SOC_NAME'] = df['SOC_NAME'].fillna(df['SOC_NAME'].mode()[0])","113930c4":"df.CASE_STATUS.value_counts()","b43b3780":"df['CASE_STATUS'] = df['CASE_STATUS'].map({'CERTIFIED' : 0, 'CERTIFIED-WITHDRAWN' : 1, 'DENIED' : 2, 'WITHDRAWN' : 3, \n                                           'PENDING QUALITY AND COMPLIANCE REVIEW - UNASSIGNED' : 4, 'REJECTED' : 5, 'INVALIDATED' : 6})","e85563b2":"df.head()","2207412a":"df.FULL_TIME_POSITION.value_counts()","5d67dc06":"df['FULL_TIME_POSITION'] = df['FULL_TIME_POSITION'].map({'N' : 0, 'Y' : 1})\ndf.head()","29f5a880":"df['SOC_NAME'].value_counts()","2fbd10dc":"import sys\ndf['SOC_NAME1'] = 'others'\ndf['SOC_NAME1'][df['SOC_NAME'].str.contains('computer','software')] = 'it'\ndf['SOC_NAME1'][df['SOC_NAME'].str.contains('chief','management')] = 'manager'\ndf['SOC_NAME1'][df['SOC_NAME'].str.contains('mechanical')] = 'mechanical'\ndf['SOC_NAME1'][df['SOC_NAME'].str.contains('database')] = 'database'\ndf['SOC_NAME1'][df['SOC_NAME'].str.contains('sales','market')] = 'scm'\ndf['SOC_NAME1'][df['SOC_NAME'].str.contains('financial')] = 'finance'\ndf['SOC_NAME1'][df['SOC_NAME'].str.contains('public','fundraising')] = 'pr'\ndf['SOC_NAME1'][df['SOC_NAME'].str.contains('education','law')] = 'administrative'\ndf['SOC_NAME1'][df['SOC_NAME'].str.contains('auditors','compliance')] = 'audit'\ndf['SOC_NAME1'][df['SOC_NAME'].str.contains('distribution','logistics')] = 'scm'\ndf['SOC_NAME1'][df['SOC_NAME'].str.contains('recruiters','human')] = 'hr'\ndf['SOC_NAME1'][df['SOC_NAME'].str.contains('agricultural','farm')] = 'agri'\ndf['SOC_NAME1'][df['SOC_NAME'].str.contains('construction','architectural')] = 'estate'\ndf['SOC_NAME1'][df['SOC_NAME'].str.contains('forencsic','health')] = 'medical'\ndf['SOC_NAME1'][df['SOC_NAME'].str.contains('teachers')] = 'education'","59f9cda2":"df.head()","96d63f36":"df.columns","3892a08f":"df = df.drop(['Unnamed: 0', 'EMPLOYER_NAME', 'SOC_NAME','JOB_TITLE','WORKSITE', 'lon','lat'], axis = 1)","21cac8f9":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(df.SOC_NAME1)\n# print list(le.classes_)\ndf['SOC_N']=le.transform(df['SOC_NAME1'])","e0176cec":"df.head()","9559bce2":"df = df.drop(['SOC_NAME1'], axis=1)","d20661a0":"sns.heatmap(df.corr(), annot=True, cmap=\"RdYlGn\", annot_kws={\"size\":15})","beeb993c":"df.columns","d957eab0":"x = df.drop(['CASE_STATUS'], axis=1) # Independent variables\ny = df['CASE_STATUS'] # Dependent variables","5e6fc798":"x.columns","243aec6f":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)","db0d048c":"from sklearn.preprocessing import OneHotEncoder\nx_train_encode = pd.get_dummies(x_train)\nx_test_encode = pd.get_dummies(x_test)","a9b4b5fe":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nLogReg = LogisticRegression()\nLogReg.fit(x_train_encode, y_train)\ny_pred = LogReg.predict(x_test_encode)","044f4a17":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","de150d2c":"* From the countplot we can see that around 85% of the total jobs are full time.","46a28a7a":"### Let's check the average salary of each company ","5fd4dd95":"## Top 10 Applicants in 2016","46e7771b":"* We can that there is an exponential increase in the number of applications as the year passes","8d151d2c":"* Dividing the data into Independent and Dependent variables.","1f83da0d":"# If you like it please consider upvoting :)","ee776faa":"# Content\n\nThis dataset contains five year's worth of H-1B petition data, with approximately 3 million records overall. The columns in the dataset include case status, employer name, worksite coordinates, job title, prevailing wage, occupation code, and year filed.","06b5faf7":"# 2. Feature Engineering","259011c8":"# 1. Exploratory Data Analysis (EDA).","189a185c":"## The meaning of the columns are as follows:\n\n* **CASE_STATUS** - status of the application\n* **EMPLOYER_NAME** - the name of the employer as registered in the H-1B Visa application\n* **SOC_NAME** - the occupation code for the employment\n* **JOB_TITLE** - the job title for the employment\n* **FULL_TIME_POSITION** - whether the application is for a full-time position of for a part-time position\n* **PREVAILING_WAGE** - the most frequent wage for the corresponding role as filled in the Visa application\n* **YEAR** - the application year\n* **WORKSITE** - the address of the employer worksite\n* **lon** - longitude of the employer worksite\n* **lat** - latitude of the employer worksite","c65fd1eb":"![H-1B Visa](https:\/\/images.techhive.com\/images\/article\/2016\/12\/h-1b-visa9-100698034-large.jpg)","299572e2":"### Removing the outliers from the dataset.","b506d5a4":"## Splitting the data into train test split","ea440023":"# What is H-1B VISA?\n\n* H-1B visas are a category of employment-based, non-immigrant visas for temporary foreign workers in the United States. For a foreign national to apply for H1-B visa, a US employer must offer them a job and submit a petition for a H-1B visa to the US immigration department. This is also the most common visa status applied for and held by international students once they complete college or higher education and begin working in a full-time position.","18f1c8e3":"* We can clearly see that there are 2 new companies which are **TECH MAHINDRA (AMERICAS),INC.** & **CAPGEMINI AMERICA**.\n* **INFOSYS** showed rapid growth between the year 2011 and 2013 where it came from 0 applications to more than 30k applications.\n* **TATA** also showed a significant growth.\n* From the above plot except the 2 new comers we can say that the number of applications receving to the top 10 employer started decreasing from the year 2015. \n* All very top applications are from India.\n* These are the companies who filed the most number of applicaions.","6e62127f":"### Analyzing more number of top 10 employees ","300c24be":"# 3. Feature Selection.\n\n**Feature Selection** is the process where you automatically or manually select those features which contribute most to your prediction variable or output in which you are interested in.","f43301fa":"## Top 10 Applicants from 2011 to 2016","25a3895e":"### Applying Logistic Regression Algorithm","a697c3e9":"## TOp job titles according to 2016.","232e4183":"## Label enconding the CASE_STATUS feature\n\n* What is **Label Encoding** ?\n     - **Label Encoding** refers to converting the labels into numeric form so as to convert it into the machine-readable form. Machine learning algorithms can then decide in a better way on how those labels must be operated. It is an important pre-processing step for the structured dataset in supervised learning.","cc236109":"* We can see that the Average Salary offered by **Infosys** was very high as compared to rest of the companies in the year 2012.\n* It's very interesting to see a huge peak in 2014 by **IBM INDIA PRIVATE LIMITED** looking like something went wrong.\n* More sudden peak's were observed by **ACCENTURE LLP** in year **2011** and by **TECH MAHINDRA** in the year 2016.\n* Now we need to further analyze the peaks.","603632fb":"(target)case_Status, full_time_pos, prewaling wage, year","6dede66f":"* Dropping the unwanted columns from the dataset.","685917b6":"# 4. Model Building ","f1200ddc":" * For the `FULL_TIME_POSITION` the variable indicates that the application is whether for Y : full-time position and N : part-time position.","12c574ad":"* Similarly performing the same operation with `FULL_TIME_POSITION` feature.","cbae28fe":"### NUmber of Applications per year","9c37586b":"### TOp 10 applicants in 2011","e1a4500e":"* From the above graph we can say that the employees who have applied for the **H-1B Visa** were more than **2500000** whose application got **certified** and there were more than 200000 whose application's were **certified and withdrawn** and there were around **90000** whose application's were **denied** and there we around **80000** were **withdrawn**"}}