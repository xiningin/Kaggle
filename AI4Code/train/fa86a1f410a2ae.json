{"cell_type":{"2f5f638e":"code","82b4e76d":"code","c6fd1467":"code","785da091":"code","cbae69ed":"markdown","eda78606":"markdown","279097bf":"markdown","0e56aa7e":"markdown"},"source":{"2f5f638e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import (\n    datasets,\n    linear_model,\n    preprocessing,\n    model_selection,\n    feature_selection,\n    metrics,\n    decomposition,\n    cluster,\n    pipeline\n)\nimport seaborn as sns\nfrom ipywidgets import interact_manual, interact","82b4e76d":"@interact_manual(\n    num_samples=(100,10000,100),\n    mic_noise=(0.0, 1.0, 0.01),\n    signal_freqs=\"0.1, 0.3, 0.5, 0.4, 0.2, 0.05\",\n    max_mic_distance=(2,5,1),\n    n_mics=(0, 10, 1),\n    )\ndef set_parameters(num_samples=8000, n_mics=0, mic_noise=0.0, signal_freqs='', max_mic_distance=5):\n    global N, noise, t, freqs, distances, phases, persons, X, Xf, Xp, n_mics_\n    N = num_samples\n    t = np.linspace(0, 100, N)\n    noise = mic_noise\n    freqs = eval(f\"[{signal_freqs}]\")\n    if not n_mics:\n        n_mics = len(freqs)\n    n_mics_ = n_mics\n    distances = np.random.uniform(0.5, max_mic_distance, size=(len(freqs), n_mics_))\n    phases = np.random.uniform(0, np.pi, size=len(freqs))\n    persons = []\n    for i in range(len(freqs)):\n        persons.append(np.sin(2 * np.pi * freqs[i] * t + phases[i]))\n    persons = np.array(persons).T\n    mic_noises = np.random.normal(0, mic_noise, size=(N, n_mics_))\n    X = persons @ (1. \/ distances**2) + mic_noises\n    plt.figure()\n    sns.heatmap(pd.DataFrame(persons, columns=[f'Person {i + 1}' for i in range(persons.shape[1])]).corr())\n    plt.title('Correlation of Actual Signals')\n    \n    fig, ax = plt.subplots(len(freqs), 2, sharey=True, sharex=True, figsize=(8, len(freqs)*2))\n    for i in range(persons.shape[1]):\n        ax[i, 0].plot(persons.T[i])\n        ax[i, 0].set_title(f\"Person {i + 1}\")\n    for i in range(min(n_mics_, persons.shape[1])):\n        ax[i, 1].plot(X.T[i])\n        ax[i, 1].set_title(f\"Microphone {i + 1}\")\n    ax[2, 0].set_xlabel('Time (s)')\n    ax[2, 1].set_xlabel('Time (s)')\n    fig.suptitle('Actual Signals vs Microphones');\n    Xf = decomposition.FastICA(max_iter=20000, random_state=98).fit_transform(X)\n    Xp = decomposition.PCA().fit_transform(X)","c6fd1467":"@interact\ndef icaviz(person=(0,persons.shape[1] - 1,1)):\n    best_score = 0\n    best_comp = 0\n    best_model = None\n    for i in range(n_mics_):\n        model = linear_model.LinearRegression().fit(Xf[:,i:i+1], persons[:,person])\n        score = model.score(Xf[:, i:i+1], persons[:,person])\n        if score >= best_score:\n            best_score = score\n            best_comp = i\n            best_model = model\n    plt.figure(figsize=(25, 4))\n    plt.plot(t, best_model.predict(Xf[:, best_comp:best_comp+1]), label='Derived IC')\n    plt.plot(t, persons[:, person], '--', label='Actual Signal')\n    plt.legend(loc=3)\n    plt.xlabel('Time (s)')\n    plt.ylabel('Amplitude')\n    plt.title(f'Person {person + 1} - Actual Signal vs Matching IC')","785da091":"@interact\ndef pcaviz(person=(0,persons.shape[1] - 1,1)):\n    best_score = 0\n    best_comp = 0\n    best_model = None\n    for i in range(len(freqs)):\n        model = linear_model.LinearRegression().fit(Xp[:,i:i+1], persons[:,person])\n        score = model.score(Xp[:, i:i+1], persons[:,person])\n        if score >= best_score:\n            best_score = score\n            best_comp = i\n            best_model = model\n    plt.figure(figsize=(25, 4))\n    plt.plot(t, best_model.predict(Xp[:, best_comp:best_comp+1]), label='Derived PC')\n    plt.plot(t, persons[:, person], label='Actual Signal')\n    plt.legend(loc=3)\n    plt.xlabel('Time (s)')\n    plt.ylabel('Amplitude')\n    plt.title(f'Person {person + 1} - Actual Signal vs Matching PC')","cbae69ed":"In the cell below, choose a person number to see matching independent component and observe the rate of recovery.\n\nCell must be re-run each time parameters are changed.","eda78606":"Use cell below to change simulation parameters.\n\n| Parameter     | Description     |\n| :------------- | :------------- |\n| num_samples       | Number of samples i.e. sampling rate for signals. To avoid aliasing, keep frequencies under 1 Hz|\n| mic_noise       | White noise scale for microphones. noise is assumed to be i.i.d. for each microphone       |\n| signal_freqs       | Comma separated speech signal frequencies. |\n| max_mic_distance       | Maximum speaker-microphone distance |\n| n_mics       | Number of microphones. Defaults to number of speakers. |\n\nAfter choosing the parameters, click `Run Interact` button to apply changes.","279097bf":"The cell below compares principal components to best matching actual signals to give a better idea of difference between ICA and PCA.\n\nCell must be re-run each time parameters are changed.","0e56aa7e":"# Blind Source Seperation (BSS) Simulator\n\nBSS, aka Cocktail Party Problem is a popular unsupervised learning problem where objective is to explore hidden variables from given observables ,i.e., recreating N original speech signals from sum of signals observed across randomly placed N different microphones in this case. Each microphone is at a random distance from each speaker.\n\nIn this simulation, we use use N sinusoidals of different frequencies and random phases to simulate N speakers (P), and place N microphones at different distances (D) from each speaker. \n\n$$P = [sin(2 \\pi f_1 t)^T, sin(2 \\pi f_2 t)^T, ..., sin(2 \\pi f_N t)^T]$$\n\nwhere $t$ denotes timesteps\n\n$$t = [t_0, t_1, ..., t_M]$$\n\nand distance matrix is stated as follows:\n\n$$D = \\begin{bmatrix}\nd(P_1, M_1) & d(P_2, M_1) & ... & d(P_N, M_1)\\\\\nd(P_1, M_2) & d(P_2, M_2) & ... & d(P_N, M_2)\\\\\n... & ... & ... & ...\\\\\nd(P_1, M_N) & d(P_2, M_N) & ... & d(P_N, M_N)\\\\\n\\end{bmatrix}$$\n\nOriginally having an amplitude of 1, attenuation of each signal is inversely proportional with the square of distance from speaker to microphone.\n\nObservables then given as\n\n$$ X = P(\\frac{1}{D^2})$$\n\nGiven below in figure is original speech signals versus observed signals at each microphone:\n\n![image.png](attachment:0a099cb2-8233-49be-a217-c2542c362f7c.png)!\n\nWe will apply ICA to observable matrix $X$ and compare resulting independent components to original speech signals to see if we were able to recover original signals from noisy observations."}}