{"cell_type":{"2d7d1e90":"code","ecfd2bf2":"code","0b344ce3":"code","1a530078":"code","a0041351":"code","ebc116d2":"code","0c78d52e":"code","a6bb26a4":"code","c73fd0ae":"code","2a541243":"code","83ca9916":"code","1b4cd578":"code","69660011":"code","6620686b":"markdown","e32bff50":"markdown","6c8d3837":"markdown","512e60c6":"markdown","a2e578dc":"markdown","8e31017a":"markdown","c5006ce9":"markdown","05f35746":"markdown","0bff684d":"markdown"},"source":{"2d7d1e90":"%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport glob\nimport itertools\nimport collections\n\nfrom PIL import Image\nimport cv2\nfrom tqdm import tqdm_notebook as tqdm\nimport pandas as pd\nimport numpy as np\nimport torch\nimport imagehash\n\nimport matplotlib.pyplot as plt","ecfd2bf2":"def run():\n\n    funcs = [\n        imagehash.average_hash,\n        imagehash.phash,\n        imagehash.dhash,\n        imagehash.whash,\n        #lambda x: imagehash.whash(x, mode='db4'),\n    ]\n\n    petids = []\n    hashes = []\n    for path in tqdm(glob.glob('..\/input\/plant-pathology-2020-fgvc7\/images\/*.jpg')):\n\n        image = Image.open(path)\n        imageid = path.split('\/')[-1].split('.')[0]\n\n        petids.append(imageid)\n        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))\n\n    return petids, np.array(hashes)\n\n%time petids, hashes_all = run()","0b344ce3":"hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()","1a530078":"%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()\/256 for i in range(hashes_all.shape[0])])","a0041351":"indices1 = np.where(sims > 0.8)\nindices2 = np.where(indices1[0] != indices1[1])\npetids1 = [petids[i] for i in indices1[0][indices2]]\npetids2 = [petids[i] for i in indices1[1][indices2]]\ndups = {tuple(sorted([petid1,petid2])):True for petid1, petid2 in zip(petids1, petids2)}\nprint('found %d duplicates' % len(dups))","ebc116d2":"train = pd.read_csv('..\/input\/plant-pathology-2020-fgvc7\/train.csv')\ntest = pd.read_csv('..\/input\/plant-pathology-2020-fgvc7\/test.csv')\n\ntrain['label'] = train.set_index('image_id').idxmax(axis=1).reset_index()[0]\ntest['label'] = 'unk'\n\ntrain.loc[:,'Category'] = 'train'\ntest.loc[:,'Category'] = 'test'\ntest.loc[:,'AdoptionSpeed'] = np.nan\n\ndf = pd.concat([train, test], sort=False)","0c78d52e":"df.head()","a6bb26a4":"detail = {petid:df[df.image_id == petid].iloc[0] for petid in itertools.chain.from_iterable(list(dups))}","c73fd0ae":"def show(row1, row2):\n\n    print('ID: %s \/ %s' % (row1.image_id, row2.image_id))\n    print('Label: %s \/ %s' % (row1.label, row2.label))\n#     print('AdoptionSpeed: %s \/ %s' % (row1.AdoptionSpeed, row2.AdoptionSpeed))\n#     print('Breed1: %d \/ %d' % (row1.Breed1, row2.Breed1))\n#     print('Age: %d \/ %d' % (row1.Age, row2.Age))\n#     print('RescuerID:\\n%s\\n%s' % (row1.RescuerID, row2.RescuerID))\n    \n    image1 = cv2.imread('..\/input\/plant-pathology-2020-fgvc7\/images\/%s.jpg' % (row1.image_id))\n    image2 = cv2.imread('..\/input\/plant-pathology-2020-fgvc7\/images\/%s.jpg' % (row2.image_id))\n    image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n    image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n    \n    fig = plt.figure(figsize=(10, 20))\n    fig.add_subplot(1,2,1)\n    plt.imshow(image1)\n    fig.add_subplot(1,2, 2)\n    plt.imshow(image2)\n    plt.show()","2a541243":"for petid1, petid2 in sorted(list(dups)):\n    row1 = detail[petid1]\n    row2 = detail[petid2]\n#     if row1.Category != row2.Category:\n#     if row1.label != row2.label:\n#         if row1.label != 'test':\n#             if row2.label != 'test':\n    show(row1, row2)","83ca9916":"counter = collections.Counter()\nfor petid1, petid2 in list(dups):\n    row1 = detail[petid1]\n    row2 = detail[petid2]\n    \n#     print(row1, row2)\n    \n    tag = f'{row1.Category}-{row2.Category}-{row1.label}-{row2.label}'\n    counter[tag] +=1\n    \n#     for attr in train.columns:\n#         if getattr(row1, attr) != getattr(row2, attr):\n#             counter[attr] += 1\n            \ncounter","1b4cd578":"import json\nout = [[petid1,petid2] for petid1,petid2 in dups.keys()]\nwith open('dups.json', 'w') as fp:\n    fp.write(json.dumps(out))","69660011":"dups","6620686b":"Convert numpy array into torch tensor to speed up similarity calculation.","e32bff50":"## Example of duplicates","6c8d3837":"- Version6: Fixed order of RGB when plotting. Added json output.\n- Version2: Description added.","512e60c6":"## Let's see how their description changes","a2e578dc":"## Calc similalities between all image pairs\nI use imagehash library to calculate hash value of image. \nhttps:\/\/github.com\/JohannesBuchner\/imagehash\n\nThere are several hash functions provided and I used 4 of them and combined the calculated hash values.\n\n  - average hashing (aHash)\n  - perception hashing (pHash)\n  - difference hashing (dHash)\n  - wavelet hashing (wHash)\n  \nI used profile image(1st image) of pet images to calculate hash values. ","8e31017a":"Calculate similarities among all image pairs. Divide the value by 256 to normalize (0-1).","c5006ce9":"## Which column info is inconsistent on duplicate pairs?","05f35746":"## Thresholding","0bff684d":"## Associate petid with csv info"}}