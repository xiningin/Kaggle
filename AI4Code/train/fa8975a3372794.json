{"cell_type":{"d6fc2b3f":"code","34e87f24":"code","ead07fdd":"code","d5fd9dfd":"code","01ab1eb1":"code","018fa6e8":"code","f17335a1":"code","e1c678b4":"code","3bcf5729":"code","55dfb8f9":"code","b857cc0e":"code","4a37c6d6":"code","78e98619":"code","af55337f":"code","718102f7":"code","40f29410":"code","eeba9cdc":"code","dfe37a0d":"code","97c98bc5":"code","2c516ce8":"code","5687c891":"code","4ee54dbb":"code","c8adf38d":"markdown","1a58773b":"markdown","2e930ab1":"markdown","6dc877dd":"markdown","d792d0c5":"markdown","6180b723":"markdown","3ce72a43":"markdown","fe79399f":"markdown","36bcdbf2":"markdown","a7a1d8ad":"markdown","db41bc4f":"markdown","90c7259a":"markdown","88fd2fe0":"markdown","d5572f1d":"markdown"},"source":{"d6fc2b3f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","34e87f24":"\nimport seaborn as sns\n\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow.keras as keras\nfrom keras.utils import to_categorical\nimport keras.layers as layers\nfrom keras.callbacks import EarlyStopping\nimport tensorflow.keras.layers.experimental.preprocessing as preprocessing\n","ead07fdd":"train_raw = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest_raw = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\ntrain_raw.head()","d5fd9dfd":"train_raw.isnull().any().describe()","01ab1eb1":"test_raw.isnull().any().describe()","018fa6e8":"sns.countplot(train_raw['label']);","f17335a1":"y = train_raw['label']\nX = train_raw.drop(labels=['label'], axis=1)\ny.value_counts()","e1c678b4":"#Normalizing the data\nX = X \/ 255.0\ntest_raw = test_raw \/ 255.0\n\n#Reshaping the data\n\nX = X.values.reshape(-1, 28, 28, 1)\ntest_raw = test_raw.values.reshape(-1, 28, 28, 1)","3bcf5729":"y = to_categorical(y, num_classes=10)","55dfb8f9":"X_train, X_valid, y_train, y_valid = train_test_split(X, y,test_size = 0.3, random_state = 42)\nprint(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape)","b857cc0e":"model = keras.Sequential([\n    \n    layers.Conv2D(filters=64, kernel_size=(5,5), activation='relu', padding='same',\n                  input_shape=(28, 28, 1)),\n    \n    # Data Augmentation\n    \n    preprocessing.RandomFlip(mode='horizontal'),\n    preprocessing.RandomRotation(factor=0.10),\n    \n    layers.MaxPool2D(pool_size=(2,2)),\n    \n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'),\n    layers.MaxPool2D(pool_size=(2,2)),\n    \n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'),\n    layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'),\n    layers.MaxPool2D(pool_size=(2,2)),\n    \n    layers.BatchNormalization(renorm=True),\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dropout(0.3),\n    layers.Dense(10, activation='sigmoid'),\n])\nmodel.summary()","4a37c6d6":"model.compile( \n    optimizer=keras.optimizers.Adam(epsilon=0.01),\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy']\n)","78e98619":"early_stopping = EarlyStopping(min_delta=0.001, patience=5, restore_best_weights=True)","af55337f":"history = model.fit(\n    X_train, y_train,\n    batch_size=128,\n    epochs=50,\n    validation_data=(X_valid, y_valid),\n    callbacks=[early_stopping]\n)","718102f7":"history_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();","40f29410":"predictions = model.predict(test_raw)","eeba9cdc":"predictions[0]","dfe37a0d":"predictions=[np.argmax(test) for test in predictions]","97c98bc5":"predictions[0]","2c516ce8":"submission_raw = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nsubmission_raw.head()","5687c891":"final_submission = pd.DataFrame({'ImageId' : [i+1 for i in range(len(predictions))] , 'Label' : predictions})\nfinal_submission.head()","4ee54dbb":"final_submission.to_csv('.\/final_submission.csv', index = False)","c8adf38d":"# **Plot for Label Count**","1a58773b":"# **Spliting data into Train and Validation data**","2e930ab1":"# **Necessary Imports**","6dc877dd":"# **Predict TEST data**","d792d0c5":"# **Checking for null values - Train Data**","6180b723":"# **Designing the model**","3ce72a43":"# **Normalizing and Reshaping**","fe79399f":"# **Reading Input Data**","36bcdbf2":"# **Model compiling by adding - Optimizer , loss and Accuracy**","a7a1d8ad":"# **Checking for null values - Test Data**","db41bc4f":"# **Model Training**","90c7259a":"# **Plot for analyzing model training **","88fd2fe0":"# **Preparing outcome for submission**","d5572f1d":"# **Including an early stopping callback to prevent overfitting.**"}}