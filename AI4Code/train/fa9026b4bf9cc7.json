{"cell_type":{"b6ad8db2":"code","4ec4e7a0":"code","5d259fc5":"code","1a72128c":"code","4bad3021":"code","7803bf30":"code","feab0e7c":"code","2cab9ba4":"code","6bec3823":"markdown","c38bfb0f":"markdown","cdafc89d":"markdown","3b3b82eb":"markdown","7e5804cf":"markdown","e6d9696d":"markdown","f163530f":"markdown"},"source":{"b6ad8db2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","4ec4e7a0":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","5d259fc5":"alldata = pd.concat([train, test],axis=0)\n\n#fillna\nalldata['Age']=alldata['Age'].fillna(np.nanmean(alldata['Age']))\nalldata['Fare']=alldata['Fare'].fillna(np.nanmean(alldata['Fare']))\nalldata['Embarked']=alldata['Embarked'].fillna(alldata['Embarked'].mode())","1a72128c":"#Select features\n\ntarget_col = 'Survived'\nexclude_cols = ['Survived','PassengerId','Name','Ticket','Cabin']\nfeature_cols = [col for col in train.columns if col not in exclude_cols]","4bad3021":"X_alldata = alldata[feature_cols]\ny_alldata = alldata[target_col]\n\nX_alldata = pd.get_dummies(X_alldata,drop_first=True)\nX_alldata.head()","7803bf30":"X_train = X_alldata.iloc[:train.shape[0],:]\nX_test  = X_alldata.iloc[train.shape[0]:,:]\ny_train = y_alldata.iloc[:train.shape[0],]","feab0e7c":"X_train.head()\nprint(\"rows of trian\",X_train.shape[0])","2cab9ba4":"%%time\n\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.ensemble import RandomForestClassifier\n\ntrain_sizes, train_scores, test_scores = learning_curve(estimator=RandomForestClassifier(random_state=42),\n                                                        X = X_train, y = y_train,\n                                                       train_sizes=np.linspace(0.1, 1.0,10),\n                                                       cv=10,\n                                                       n_jobs=-1)\n\ntrain_mean = np.mean(train_scores,axis=1)\ntest_mean = np.mean(test_scores,axis=1)\ntrain_std = np.std(train_scores,axis=1)\ntest_std = np.std(test_scores,axis=1)\n\nplt.plot(train_sizes, train_mean,color='blue', marker='o',markersize=5,label='training accuracy')\nplt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha = 0.15, color='blue')\n\nplt.plot(train_sizes, test_mean,color='green', linestyle='--',marker='o',markersize=5,label='validation accuracy')\nplt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha = 0.15, color='green')\n\n\nplt.grid()\nplt.title('Learning Curve')\nplt.xlabel('Number of training samples')\nplt.ylabel('Accuracy')\nplt.legend(loc='best')\nplt.ylim([0.6,1.1])\nplt.tight_layout()\nplt.show()","6bec3823":"## How to see there are enough amount of data\nThis is the main point of this notebook. <br>\n<br>\nWe use 90% of the data to create model and use the other 10% of the data to evaluate the accuracy of the model and I will do it 10 times.<br>\nThis is called \"KFold Cross-validation\" If you are interested in Cross-validation, please see [here](https:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html)<br>\n<br>\nThe point we would like to know now is, **\"Are there enough data to create accurate model?\"**<br>\nThis is the simple but useful methodology to answer this question.<br>\n<br>\nFirstly we use only 10 % of train data(89=891 * 10%) and create model with 90% of the data (80 = 89 * 90%) and evaluate the model with the other 10%(9 = 89 * 10%),<br>\nSince we can evaluate the accuracy of the model 10 times, we can calculate mean and standard deviation which makes us recongnize the accuarcy of the model stable.<br>\n<br>\nSecondly we use only 20 % of train data(178=891 * 20%) and create model with 90% of the data (160 = 178 * 90%) and evaluate the model with the other 10%(18 = 178 *<br> 10%). And we will see the mean and standard deviation of the accuracy of model.<br>\n<br>\nLastly, we plot these information and see the trend.<br>\n\n<br>\nIn this time, I use tree based model \"RandomForest\". However, you might need to scale data when you use the other model.","c38bfb0f":"If you find this interesting, I reccomend this [github](https:\/\/github.com\/rasbt\/python-machine-learning-book-3rd-edition\/blob\/master\/ch06\/ch06.ipynb) page.<br>\ngithub from Python-machine-learning-book-3rd-edition (by Sebastian Raschka)","cdafc89d":"## Data Preprocessing","3b3b82eb":"![learning_curve.JPG](attachment:508ebb98-c843-410f-abb9-fab4223e56e2.JPG)","7e5804cf":"## Result\nThe accuracy of training is very high. However there is a gap between training accuarcy and validation accuracy.<br>\nAlso, the validation accuracy does not go up where number of training smaples above 550. <br>\nThis shows the amount of training data is not enough to create accurate model.<br>\n<br>\nSince training data is limited, you have to find good features to create model instead of increasing the amount of training data.<br>\n\n<e.g.><br>\npick up the title of Name: Mr. ,Miss. ,Sir(Sir must be more important person than general people. must survived more)\n\n<br>\nThe graph below is learning curve for different data and the accuracy of training and validation are very close even though the amount of training data is around 400 which is almost half of Titanic training data.<br>","e6d9696d":"[](http:\/\/)","f163530f":"# Purpose of this notebook\nMachin Learning is known that large data makes accuracy of model better, and Titanic is know as it has relativily small data to train model.<br>\nIn this notebook, I would like to pick one example how we can see if there is good enough amount of data or not.\n\nIf you are familier with the idea \"data preprocessing\", please jump to **\"How to see there are enough amount of data\"** part below."}}