{"cell_type":{"c6df2d24":"code","625985e6":"code","77131b1d":"code","6ae077fb":"code","100767d0":"code","96e22a3b":"code","1f838487":"code","154f461d":"code","69b5c447":"code","0c3816a6":"code","a3129d48":"code","84929ecd":"code","ac0db4b9":"code","6614f387":"code","0a8519f3":"code","53eaf62b":"code","221bc846":"code","63d9920e":"markdown","2c7adf59":"markdown","b2faf5a2":"markdown","e4cf182a":"markdown","0a61cf89":"markdown","f0293d39":"markdown","1e5c9b29":"markdown","2a7ecd77":"markdown"},"source":{"c6df2d24":"!pip install transformers","625985e6":"import re\nimport json\nfrom sklearn.model_selection import train_test_split","77131b1d":"data_path = '\/kaggle\/input\/german-recipes-dataset\/'\n\nwith open(data_path + 'recipes.json') as f:\n    data = json.load(f)\n\ndef build_text_files(data_json, dest_path):\n    f = open(dest_path, 'w')\n    data = ''\n    for texts in data_json:\n        summary = str(texts['Instructions']).strip()\n        summary = re.sub(r\"\\s\", \" \", summary)\n        data += summary + \"  \"\n    f.write(data)","6ae077fb":"print(data[0].keys())","100767d0":"print(data[0])","96e22a3b":"train, test = train_test_split(data,test_size=0.15) \n\nbuild_text_files(train,'train_dataset.txt')\nbuild_text_files(test,'test_dataset.txt')\n\nprint(\"Train dataset length: \"+str(len(train)))\nprint(\"Test dataset length: \"+ str(len(test)))","1f838487":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"anonymous-german-nlp\/german-gpt2\")\n\ntrain_path = 'train_dataset.txt'\ntest_path = 'test_dataset.txt'","154f461d":"from transformers import TextDataset,DataCollatorForLanguageModeling\n\ndef load_dataset(train_path,test_path,tokenizer):\n    train_dataset = TextDataset(\n          tokenizer=tokenizer,\n          file_path=train_path,\n          block_size=128)\n     \n    test_dataset = TextDataset(\n          tokenizer=tokenizer,\n          file_path=test_path,\n          block_size=128)   \n    \n    data_collator = DataCollatorForLanguageModeling(\n        tokenizer=tokenizer, mlm=False,\n    )\n    return train_dataset,test_dataset,data_collator\n\ntrain_dataset,test_dataset,data_collator = load_dataset(train_path,test_path,tokenizer)","69b5c447":"from transformers import Trainer, TrainingArguments,AutoModelWithLMHead\n\nmodel = AutoModelWithLMHead.from_pretrained(\"anonymous-german-nlp\/german-gpt2\")\n\n\ntraining_args = TrainingArguments(\n    output_dir=\".\/gpt2-gerchef\", #The output directory\n    overwrite_output_dir=True, #overwrite the content of the output directory\n    num_train_epochs=3, # number of training epochs\n    per_device_train_batch_size=32, # batch size for training\n    per_device_eval_batch_size=64,  # batch size for evaluation\n    eval_steps = 400, # Number of update steps between two evaluations.\n    save_steps=800, # after # steps model is saved \n    warmup_steps=500,# number of warmup steps for learning rate scheduler\n    prediction_loss_only=True,\n    report_to=\"tensorboard\"\n    )\n\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n)","0c3816a6":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","a3129d48":"trainer.train()","84929ecd":"trainer.save_model()","ac0db4b9":"from transformers import pipeline\n\nchef = pipeline('text-generation',model='.\/gpt2-gerchef', tokenizer='anonymous-german-nlp\/german-gpt2')\n\n#result = chef('Zuerst H\u00e4hnchen')[0]['generated_text'] ","6614f387":"chef('Die Nudeln Kochen, Fleisch anbraten')","0a8519f3":"chef('Zuerst H\u00e4hnchen')","53eaf62b":"chef('Der beste Weg, um einen Schokoladenkuchen zuzubereiten, ist')","221bc846":"chef('Zuerst H\u00e4hnchen')[0]['generated_text']","63d9920e":"# GPT-2 fine tuning with German Recipes","2c7adf59":"## Train Model\n### Initialize Trainer with TrainingArguments with German-GPT2 model","b2faf5a2":"### Split Dataset","e4cf182a":"## Load Dataset","0a61cf89":"## Tokenize Input Text","f0293d39":"## Read Dataset","1e5c9b29":"## Test Model","2a7ecd77":"## Datase: [German Recipes](https:\/\/www.kaggle.com\/sterby\/german-recipes-dataset)"}}