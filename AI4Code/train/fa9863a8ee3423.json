{"cell_type":{"43890ed0":"code","937d4bf7":"code","482162cc":"code","f00e5c8a":"code","fe493556":"code","87e26680":"code","f5c730a5":"code","9e4d0252":"code","d4acfa6b":"code","26f7f376":"code","d4b9a7a1":"code","aa5e2d2d":"code","c20bdd99":"code","07b97d70":"code","0093699f":"code","e91d0648":"code","f1721b4e":"code","567d7a0a":"code","e2dfe21b":"code","da36ef1e":"code","f3477900":"code","293d4fbf":"code","fbbed455":"code","837b65b3":"code","6058925c":"markdown","49b1c129":"markdown","dcf281a7":"markdown","5e8fa55c":"markdown","2fe22cea":"markdown","024fb363":"markdown","0e93ddad":"markdown","7500233d":"markdown","1b0d689f":"markdown","36dd3e4b":"markdown","6d349309":"markdown","e9f3cca3":"markdown","772b7ab9":"markdown","d46c13ae":"markdown","29de1246":"markdown","3439250f":"markdown","63404001":"markdown","eed06dad":"markdown","e739eaee":"markdown","b05b3cf0":"markdown"},"source":{"43890ed0":"import tensorflow\ntensorflow.__version__\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.utils import to_categorical\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, MaxPooling2D, BatchNormalization\n\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras import regularizers, optimizers","937d4bf7":"# Initialize the random number generator\nimport random\nrandom.seed(0)\n\n# Ignore the warnings\nimport warnings\n\n# suppress display of warnings\nwarnings.filterwarnings('ignore')\n\n# display all dataframe columns\npd.options.display.max_columns = None\n\n# to set the limit to 3 decimals\npd.options.display.float_format = '{:.7f}'.format\n\n# display all dataframe rows\npd.options.display.max_rows = None","482162cc":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')","f00e5c8a":"# Get top 5 rows\ntrain.head()","fe493556":"test = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","87e26680":"# Get top 5 rows\ntest.head()","f5c730a5":"# Extract features\nfeatures = train.drop('label', axis=1)\n\n# Extract label\ny_train = train['label']","9e4d0252":"# Train images\nX_ = np.array(features)\nX_train = X_.reshape(X_.shape[0], 28, 28)\n\n# Test images\nX_test = np.array(test)","d4acfa6b":"print(\"Number of train images = {} and number of test images = {} in Insurance data frame\".format(X_train.shape, X_test.shape))","26f7f376":"fig = plt.figure(figsize=(10,5))\n\nfor i in range(16):\n    fig.add_subplot(4, 4, i+1)\n    \n    plt.imshow(X_train[i], cmap='gray')\n    \n    plt.xticks([])\n    plt.yticks([])\n    plt.tight_layout()\n    plt.title('Digit: ' + str(y_train[i]))","d4b9a7a1":"# Now we have to check the count of values for our output layer\ny_train.value_counts(normalize=True)","aa5e2d2d":"len(y_train.value_counts())","c20bdd99":"X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)","07b97d70":"X_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\nX_train \/= 255\nX_test \/= 255","0093699f":"print(\"X_train shape:\", X_train.shape)\nprint(\"Images in X_train:\", X_train.shape[0])\nprint(\"Images in X_test:\", X_test.shape[0])\nprint(\"Max value in X_train:\", X_train.max())\nprint(\"Min value in X_train:\", X_train.min())","e91d0648":"y_train = to_categorical(y_train, num_classes=10)\n\nprint(\"Shape of y_train:\", y_train.shape)\nprint(\"One value of y_train:\", y_train[0])","f1721b4e":"model = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\", input_shape=(28, 28, 1)))\nmodel.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\"))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dense(10, activation=\"softmax\"))","567d7a0a":"# Compile the model\nmodel.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n\n# Fit the model\nmodel.fit( x=X_train, y=y_train, batch_size=32, epochs=10, validation_split = 0.3)","e2dfe21b":"# Initialize the model\nmodel = Sequential()\n\n# Add a Convolutional Layer with 32 filters of size 3X3 and activation function as 'relu' \nmodel.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\", input_shape=(28, 28, 1)))\n\nmodel.add(BatchNormalization())\n\n# Add a Convolutional Layer with 32 filters of size 3X3 and activation function as 'relu' \nmodel.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\"))\n\nmodel.add(BatchNormalization())\n\n# Add a MaxPooling Layer of size 2X2 \nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(BatchNormalization())\n\n# Apply Dropout with 0.2 probability \nmodel.add(Dropout(rate=0.2))\n\n# Flatten the layer\nmodel.add(Flatten())\n\n# Add Fully Connected Layer with 128 units and activation function as 'relu'\nmodel.add(Dense(128, activation=\"relu\"))\n\nmodel.add(BatchNormalization())\n\n#Add Fully Connected Layer with 10 units and activation function as 'softmax'\nmodel.add(Dense(10, activation=\"softmax\"))","da36ef1e":"# Optimizer\nsgd = optimizers.SGD(lr=2e-2, decay=1e-6, momentum=0.9)\n      \n# Compile the model\nmodel.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=sgd)\n\n# Adding callbacks\nes = EarlyStopping(monitor='val_loss', mode = 'min', patience=10, min_delta=1E-4, restore_best_weights=True)\nrlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.0001, patience=10, min_delta=1E-4)\n\ncallbacks = [es, rlrp]\n\n# Fit the model\ntraining_history = model.fit(x=X_train, y=y_train, batch_size=16, epochs=100, validation_split = 0.3, callbacks=[callbacks])","f3477900":"# Predict on Test set\npreds = np.argmax(model.predict(X_test), axis=1)","293d4fbf":"submission = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')","fbbed455":"# Get the dimensions\nsubmission.shape","837b65b3":"submission['Label'] = preds\nsubmission.to_csv('submission.csv',index=False)\n\nsubmission.head()","6058925c":"<p style = \"font-size:20px; color: #007580 \"><strong> Let's visualize some numbers using matplotlib <\/strong><\/p> ","49b1c129":"<a id = '3.0'><\/a>\n<h2 style = \"font-size:35px; font-family:Garamond ; font-weight : normal; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\"> 3. Data Collection <\/h2> ","dcf281a7":"<p style = \"font-size:20px; color: #007580 \"><strong> MNIST Dataset <\/strong><\/p> \n\nThe MNIST database contains 60,000 training images and 10,000 testing images taken from American Census Bureau employees and American high school students. The MNIST dataset is one of the most common datasets used for image classification and accessible from many different sources. In fact, even Tensorflow and Keras allow us to import and download the MNIST dataset directly from their API.","5e8fa55c":"<p style = \"font-size:20px; color: #007580 \"><strong> Shape of the data <\/strong><\/p> ","2fe22cea":"<p style = \"font-size:20px; color: #007580 \"><strong> Compile and fit the model <\/strong><\/p> \n\n- let's compile our model\n    - loss: \"categorical_crossentropy\"\n    - metrics: \"accuracy\"\n    - optimizer: \"adam\"\n- Use EarlyStopping\n- then next step will be to fit model\n    - give train data - training features and labels\n    - batch size: 32\n    - epochs: 10\n    - give validation data - testing features and labels","024fb363":"<p style = \"font-size:20px; color: #007580 \"><strong> One-hot encode the class vector <\/strong><\/p> \n\n- convert class vectors (integers) to binary class matrix\n- convert y_train and y_test\n- number of classes: 10\n- we are doing this to use categorical_crossentropy as loss","0e93ddad":"<a id = '1.0'><\/a>\n<h2 style = \"font-size:35px; font-family:Garamond ; font-weight : normal; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\"> 1. Overview <\/h2> ","7500233d":"<p style = \"font-size:20px; color: #007580 \"><strong> Normalize data <\/strong><\/p> \n\n- we must normalize our data as it is always required in neural network models\n- we can achieve this by dividing the RGB codes with 255 (which is the maximum RGB code minus the minimum RGB code)\n- normalize X_train and X_test\n- make sure that the values are float so that we can get decimal points after division","1b0d689f":"<a id = '4.0'><\/a>\n<h2 style = \"font-size:35px; font-family:Garamond ; font-weight : normal; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\"> 4. Model Building and Validation <\/h2> ","36dd3e4b":"<p style = \"font-size:20px; color: #007580 \"><strong> Let's load MNIST dataset <\/strong><\/p> ","6d349309":"<br>\n<h2 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\"> Digit Recognizer<\/h2> \n<br>","e9f3cca3":"<a id = '5.0'><\/a>\n<h2 style = \"font-size:35px; font-family:Garamond ; font-weight : normal; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\"> 5. Build Submission File <\/h2> ","772b7ab9":"<a id = '2.0'><\/a>\n<h2 style = \"font-size:35px; font-family:Garamond ; font-weight : normal; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\"> 2. Import the necessary libraries <\/h2> ","d46c13ae":"<p style = \"font-size:20px; color: #007580 \"><strong> Initialize a sequential model <\/strong><\/p> \n\n- define a sequential model\n- add 2 convolutional layers\n    - no of filters: 32\n    - kernel size: 3x3\n    - activation: \"relu\"\n    - input shape: (28, 28, 1) for first layer\n- flatten the data\n    - add Flatten later\n    - flatten layers flatten 2D arrays to 1D array before building the fully connected layers\n- add 2 dense layers\n    - number of neurons in first layer: 128\n    - number of neurons in last layer: number of classes\n    - activation function in first layer: relu\n    - activation function in last layer: softmax\n    - we may experiment with any number of neurons for the first Dense layer; however, the final Dense layer must have neurons equal to the number of output classes","29de1246":"<p style = \"font-size:20px; color: #007580 \"><strong> Vanilla CNN + Pooling + Dropout <\/strong><\/p> \n\n- define a sequential model\n- add 2 convolutional layers\n    - no of filters: 32\n    - kernel size: 3x3\n    - activation: \"relu\"\n    - input shape: (28, 28, 1) for first layer\n- add a max pooling layer of size 2x2\n- add a dropout layer\n    - dropout layers fight with the overfitting by disregarding some of the neurons while training\n    - use dropout rate 0.2\n- flatten the data\n    - add Flatten later\n    - flatten layers flatten 2D arrays to 1D array before building the fully connected layers\n- add 2 dense layers\n    - number of neurons in first layer: 128\n    - number of neurons in last layer: number of classes\n    - activation function in first layer: relu\n    - activation function in last layer: softmax\n    - we may experiment with any number of neurons for the first Dense layer; however, the final Dense layer must have neurons equal to the number of output classes","3439250f":"<a id = '0'><\/a>\n<h2 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #007580; color : #fed049; border-radius: 5px 5px; text-align:center; font-weight: bold\" >Table of Contents<\/h2> \n\n1. [Overview](#1.0)\n2. [Import the necessary libraries](#2.0)\n3. [Data Collection](#3.0)\n4. [Model Building and Validation](#4.0)\n5. [Build Submission File](#5.0)\n5. [Summary](6.0)","63404001":"<p style = \"font-size:20px; color: #007580 \"><strong> Compile and fit the model <\/strong><\/p> \n\n- let's compile our model\n    - loss: \"categorical_crossentropy\"\n    - metrics: \"accuracy\"\n    - optimizer: \"adam\"\n- then next step will be to fit model\n    - give train data - training features and labels\n    - batch size: 32\n    - epochs: 10\n    - give validation data - testing features and labels","eed06dad":"<p style = \"font-size:20px; color: #007580 \"><strong> Reshape train and test sets into compatible shapes <\/strong><\/p> \n\n- Sequential model in tensorflow.keras expects data to be in the format (n_e, n_h, n_w, n_c)\n- n_e= number of examples, n_h = height, n_w = width, n_c = number of channels\n- do not reshape labels","e739eaee":"<a id = '6.0'><\/a>\n<h2 style = \"font-size:35px; font-family:Garamond ; font-weight : normal; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\"> 6. Summary <\/h2> \n<br>\n<br>\n<strong>What happend so far?<\/strong>\n\n<ol>\n<li>Loaded the MNIST dataset into dataframe.<\/li>\n<li>Visualize some numbers using matplotlib.<\/li>\n<li>Reshape train and test sets into compatible shapes.<\/li>\n<li>One-hot encode the class vector.<\/li>\n<li>Built and validated the sequential model with few Conv2D and dense layers.<\/li>\n<li>Built and validated the sequential model with Vanilla CNN, Pooling and Dropout layers.<\/li>\n<li>Built the submission file.<\/li>\n<\/ol>\n   \n<br>\n   \n<p style = \"font-size:30px; color: #007580 \"><strong> Thanks for reading. We can try to add more layers and hypertune few parameters to imrove the score, will update soon... <\/strong><\/p>","b05b3cf0":"<p style = \"font-size:20px; color: #007580 \"><strong> Print shape of data and number of images <\/strong><\/p> \n\n- print shape of X_train\n- print number of images in X_train\n- print number of images in X_test"}}