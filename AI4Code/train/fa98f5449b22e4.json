{"cell_type":{"6109df03":"code","e43cc258":"code","bf5c250a":"code","f1239598":"code","479eeeb0":"code","89b336f7":"code","0bbd561f":"code","1f7c753e":"code","4291dd2e":"code","dfe47269":"code","7585d907":"code","bbf40380":"code","bf488d19":"code","4baf343d":"code","b64d1418":"code","e837fb52":"code","d934db46":"code","3f67179d":"code","eaa70a96":"code","2da6fa80":"code","a9b2b3cf":"code","ffe18a0d":"code","49541f79":"code","eebc0201":"code","dd57ebd7":"code","c2ce40a1":"code","29316ce7":"code","0385bcff":"code","ed2105c4":"code","402c36cd":"code","8827e589":"code","79dca103":"code","7e075622":"code","290feb45":"code","3cd0877c":"code","40268731":"code","610808f1":"code","e63e705b":"code","ded352de":"code","ef710d13":"code","fd5c7049":"code","bafa0f99":"code","042755c4":"code","24fced69":"code","52633549":"code","29f4d149":"code","ed548161":"markdown","faee43fa":"markdown","cdd4124b":"markdown","7e31de4e":"markdown","7cc69d91":"markdown","a8fa5f37":"markdown"},"source":{"6109df03":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n","e43cc258":"df = pd.read_csv('..\/input\/textdb3\/fake_or_real_news.csv')    #importing the Dataset from local Machine\ndf.head()","bf5c250a":"# Check how the Lables are Distributed\n\ndf['label'].value_counts()","f1239598":"import string as st    #importing string for the function","479eeeb0":"#Remove all punctuations\n\ndef remove_punctuation(text):\n    return (\"\".join([ch for ch in text if ch not in st.punctuation]))","89b336f7":"df['New_text']=df['text'].apply(lambda x: remove_punctuation(x))     \ndf.head()","0bbd561f":"df = df.drop(['Unnamed: 0'],axis=1)    #Dropping the feature which we don't need\ndf.head()","1f7c753e":"#Convert text in lower case, Split() applied for white space\nimport re\ndef tokenize(text):\n    text = re.split('\\s+', text)\n    return [x.lower() for x in text]","4291dd2e":"df['New_text'] = df['New_text'].apply(lambda msg:tokenize(msg))\ndf.head()","dfe47269":"#Removal of tokens less than length 2\n\ndef rem_small_words(text):\n    return [x for x in text if len(x)>2]","7585d907":"df['New_text'] = df['New_text'].apply(lambda x: rem_small_words(x))\ndf.head()","bbf40380":"#Remove stopwords\nimport nltk\nfrom nltk import PorterStemmer, WordNetLemmatizer\n\ndef rem_stopword(text):\n    return[word for word in text if word not in nltk.corpus.stopwords.words('english')]","bf488d19":"df['New_text'] = df['New_text'].apply(lambda x: rem_stopword(x))\ndf.head()","4baf343d":"#Lemmetization\ndef lemmatizer(text):\n    word_net = WordNetLemmatizer()\n    return [word_net.lemmatize(word) for word in text]","b64d1418":"df['New_text'] = df['New_text'].apply(lambda x: lemmatizer(x))\ndf.head(10)","e837fb52":"# Create sentences to get clean text as input for vectors\ndef return_setances(tokens):\n    return \" \".join([word for word in tokens])","d934db46":"df['New_text'] = df['New_text'].apply(lambda x: return_setances(x))\ndf.head()","3f67179d":"df.sample(10)","eaa70a96":"from wordcloud import WordCloud\n\n# Create and generate a word cloud image FAKE_NEWS\nfake_data = df[df[\"label\"] == \"FAKE\"]\nfake_text = ' '.join([text for text in fake_data.text])\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(fake_text)\nplt.figure(figsize= [20,10])\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.title('FAKE NEWS WORDCLOUD',fontsize= 30)\nplt.show()\n\n\n","2da6fa80":"# Create and generate a word cloud image REAL_NEWS\nreal_data = df[df[\"label\"] == \"REAL\"]\nreal_text = ' '.join([text for text in real_data.text])\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(real_text)\nplt.figure(figsize= [20,10])\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.title('REAL NEWS WORDCLOUD',fontsize= 30)\nplt.show()","a9b2b3cf":"#Comparing the frequency of Fake and Real News\nimport seaborn as sns          \nprint(df.groupby(['label'])['text'].count())\nsns.countplot(df['label'])","ffe18a0d":"#Comparing the Total numbers of Characters in the Feature Title\n\nfig, (ax1,ax2)=plt.subplots(1,2,figsize=(15,8))\nfig.suptitle('Characters in News Title',fontsize=20)\nnews_len=df[df['label']=='REAL']['title'].str.len()\nax1.hist(news_len,color='orange',linewidth=2,edgecolor='black')\nax1.set_title('REAL news',fontsize=15)\nnews_len=df[df['label']=='FAKE']['title'].str.len()\nax2.hist(news_len,linewidth=2,edgecolor='black')\nax2.set_title('Fake news',fontsize=15)","49541f79":"#Comparing the Total numbers of Characters in the Feature Text\n\nfig, (ax1,ax2)=plt.subplots(1,2,figsize=(15,8))\nfig.suptitle('Characters in News Text',fontsize=20)\nnews_len=df[df['label']=='REAL']['text'].str.len()\nax1.hist(news_len,color='orange',linewidth=2,edgecolor='black')\nax1.set_title('REAL news',fontsize=15)\nnews_len=df[df['label']=='FAKE']['text'].str.len()\nax2.hist(news_len,linewidth=2,edgecolor='black')\nax2.set_title('Fake news',fontsize=15)\n","eebc0201":"#creating a bag of words with the consecutive frequency for fake text\n\nimport nltk\nimport seaborn as sns\nfake_text_vis =' '.join([str(x) for x in df[df['label']=='FAKE']['New_text']])\na = nltk.FreqDist(fake_text_vis.split())\nd = pd.DataFrame({'Word': list(a.keys()),\n                  'Count': list(a.values())})\nd.sample(10)","dd57ebd7":"# selecting top 20 most frequent hashtags     \nd = d.nlargest(columns=\"Count\", n = 20) \nplt.figure(figsize=(16,5))\nax = sns.barplot(data=d, x= \"Word\", y = \"Count\")\nax.set_xticklabels(d[\"Word\"], rotation=40, ha=\"right\")\nax.set(ylabel = 'Count')\nplt.show()","c2ce40a1":"#creating a bag of words with the consecutive frequency for Real text\nimport nltk\nimport seaborn as sns\nreal_text_vis =' '.join([str(x) for x in df[df['label']=='REAL']['New_text']])\na = nltk.FreqDist(real_text_vis.split())\nd = pd.DataFrame({'Word': list(a.keys()),\n                  'Count': list(a.values())})\nd.sample(10)","29316ce7":"d = d.nlargest(columns=\"Count\", n = 20) \nplt.figure(figsize=(16,5))\nax = sns.barplot(data=d, x= \"Word\", y = \"Count\")\nax.set_xticklabels(d[\"Word\"], rotation=40, ha=\"right\")\nax.set(ylabel = 'Count')\nplt.show()","0385bcff":"df.head()","ed2105c4":"df[\"label\"]=df[\"label\"].replace([\"FAKE\",\"REAL\"],value=[1,0]) #Label Encoding","402c36cd":"df.head()","8827e589":"df.info()","79dca103":"\nX_train,X_test,y_train,y_test = train_test_split(df['New_text'],df['label'],test_size=0.2, random_state = 10)","7e075622":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer()\nX_train = tfidf.fit_transform(X_train)\nX_test = tfidf.transform(X_test)\nprint(X_train.shape)\nprint(X_test.shape)","290feb45":"from sklearn.metrics import accuracy_score, confusion_matrix","3cd0877c":"#Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel1= RandomForestClassifier()\nmodel1.fit(X_train,y_train)\npred1 = model1.predict(X_test)\naccuracy1 = accuracy_score(y_test,pred1)\ncm1 = confusion_matrix(y_test,pred1)\nprint(\"Accuracy score : {}\".format(accuracy1))\nprint(\"Confusion matrix : \\n {}\".format(cm1))","40268731":"# Logistic Regression model\nfrom sklearn.linear_model import LogisticRegression\n\nmodel2 = LogisticRegression(max_iter = 500)\nmodel2.fit(X_train, y_train)\npred2 = model2.predict(X_test)\naccuracy2 = accuracy_score(y_test,pred2)\ncm2 = confusion_matrix(y_test,pred2)\nprint(\"Accuracy score : {}\".format(accuracy2))\nprint(\"Confusion matrix : \\n {}\".format(cm2))","610808f1":"#Passive Aggressive Classifier\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nmodel3 = PassiveAggressiveClassifier(max_iter=50)\nmodel3.fit(X_train,y_train)\n\npred3 = model3.predict(X_test)\n\naccuracy3 = accuracy_score(y_test,pred3)\ncm3 = confusion_matrix(y_test,pred3)\nprint(\"Accuracy score : {}\".format(accuracy3))\nprint(\"Confusion matrix : \\n {}\".format(cm3))","e63e705b":"#Support Vector Classification.\nfrom sklearn.svm import SVC\nmodel4=SVC()\nmodel4.fit(X_train,y_train)\n\npred4 = model4.predict(X_test)\n\naccuracy4 = accuracy_score(y_test,pred4)\ncm4 = confusion_matrix(y_test,pred4)\nprint(\"Accuracy score : {}\".format(accuracy4))\nprint(\"Confusion matrix : \\n {}\".format(cm4))","ded352de":"#Decision Tree Classifier\nfrom sklearn.tree import DecisionTreeClassifier\nmodel5=DecisionTreeClassifier()\nmodel5.fit(X_train,y_train)\n\npred5 = model5.predict(X_test)\n\naccuracy5 = accuracy_score(y_test,pred5)\ncm5 = confusion_matrix(y_test,pred5)\nprint(\"Accuracy score : {}\".format(accuracy5))\nprint(\"Confusion matrix : \\n {}\".format(cm5))","ef710d13":"#Creating the Dictionary with model name as key adn accuracy as key-value\nlabels={'RandomForestClassifier':accuracy1,'LogisticRegression':accuracy2,'PassiveAggressiveClassifier':accuracy3,\n        'SVC':accuracy4,'DecisionTreeClassifier':accuracy5}","fd5c7049":"#Plotting accuracy of all the models with Bar-Graphs\nplt.figure(figsize=(15,8))\nplt.title('Comparing Accuracy of ML Models',fontsize=20)\ncolors=['red','yellow','orange','magenta','cyan']\nplt.xticks(fontsize=10,color='black')\nplt.yticks(fontsize=20,color='black')\nplt.ylabel('Accuracy',fontsize=20)\nplt.xlabel('Models',fontsize=20)\nplt.bar(labels.keys(),labels.values(),edgecolor='black',color=colors, linewidth=2,alpha=0.5)","bafa0f99":"from mlxtend.plotting import plot_confusion_matrix\n\nprint(\"Confusion Matrix for RandomForestClassifier\")\nprint(\"Accuracy score : {}\".format(accuracy1))\nplot_confusion_matrix(conf_mat=cm1,show_absolute=True,\n                                show_normed=True,\n                                colorbar=True,class_names=['FAKE','REAL'])","042755c4":"print(\"Confusion Matrix for Logistic Regression\")\nprint(\"Accuracy score : {}\".format(accuracy2))\n\nplot_confusion_matrix(conf_mat=cm2,show_absolute=True,\n                                show_normed=True,\n                                colorbar=True,class_names=['FAKE','REAL'])","24fced69":"print(\"Confusion Matrix for PassiveAggressiveClassifier\")\nprint(\"Accuracy score : {}\".format(accuracy3))\nplot_confusion_matrix(conf_mat=cm3,show_absolute=True,\n                                show_normed=True,\n                                colorbar=True,class_names=['FAKE','REAL'])","52633549":"print(\"Confusion Matrix for SVC\")\nprint(\"Accuracy score : {}\".format(accuracy4))\nplot_confusion_matrix(conf_mat=cm4,show_absolute=True,\n                                show_normed=True,\n                                colorbar=True,class_names=['FAKE','REAL'])","29f4d149":"print(\"Confusion Matrix for DecisionTreeClassifier\")\nprint(\"Accuracy score : {}\".format(accuracy5))\nplot_confusion_matrix(conf_mat=cm5,show_absolute=True,\n                                show_normed=True,\n                                colorbar=True,class_names=['FAKE','REAL'])","ed548161":"## Generate Basic WordCloud","faee43fa":"## Importing the Libraries","cdd4124b":"# Fake News Prediction","7e31de4e":"## Splitting into training and test set","7cc69d91":"## importing the dataset","a8fa5f37":"## TF-IDF : Term Frequency - Inverse Document Frequency"}}