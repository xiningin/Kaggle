{"cell_type":{"e7596a09":"code","374ecb90":"code","a99a8e00":"code","421dff48":"code","015308e1":"code","08cdda23":"code","b570c0b2":"code","94e571ed":"code","10a2c001":"code","68bfcc0e":"code","3870c3df":"code","bf333af7":"code","cda60c10":"code","ebf18dc8":"code","3e8c3f6a":"code","2b60bcf8":"code","4da81b01":"code","112048c6":"code","835a351a":"code","195e4a8f":"code","9be3e781":"code","03853e6c":"code","adf234ce":"code","954e47c7":"code","a0244184":"code","f626d098":"code","681f9bd3":"code","20c5a6a8":"code","c7b83207":"code","4f99a5a0":"markdown","1200407e":"markdown","0744f0aa":"markdown","412dbb72":"markdown","e43600b5":"markdown","1887d93b":"markdown","01868d67":"markdown","676970ef":"markdown","2becdf0c":"markdown","bc4acc1d":"markdown","183b775a":"markdown","c6432a2f":"markdown","08ec5299":"markdown"},"source":{"e7596a09":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom warnings import simplefilter\n\nfrom scipy.stats.mstats import normaltest  # D'Agostino K^2 Test\nfrom scipy.stats import boxcox\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.preprocessing import OneHotEncoder","374ecb90":"%matplotlib inline\nplt.rcParams['font.family'] = 'consolas'\nplt.rcParams['font.size'] = 12\nplt.rcParams['figure.figsize'] = 7.8, 5.6\n# simplefilter('ignore')","a99a8e00":"data = pd.read_csv(\"yield_df.csv\", engine='c').drop(columns=['Unnamed: 0'])\ndata.head()","421dff48":"data.dtypes","015308e1":"data.info()","08cdda23":"# columns\nall_cols = data.columns.to_list()\nnum_cols = data.dtypes[data.dtypes != 'object'].index.to_list()\ncat_cols = data.dtypes[data.dtypes == 'object'].index.to_list()\nprint(all_cols)\nprint(num_cols)\nprint(\"\\n\", cat_cols)","b570c0b2":"# checking for null values\ndata.isna().sum()","94e571ed":"# Descriptive stats\ndata.describe(include='all').T","10a2c001":"# To create separate plots to visualize the distribution of data\naxList = data.hist(bins=25)\n\nfor ax in axList.flatten():\n    if ax.is_last_row():\n        ax.set_xlabel('Values')\n\n    if ax.is_first_col():\n        ax.set_ylabel('Frequency')\nplt.tight_layout()","68bfcc0e":"fig, axes_ = plt.subplots(3, 2, figsize=(8.8, 6.6))\nfor index, ax in enumerate(axes_.flatten()):\n    col = all_cols[index + 1]\n    if col in cat_cols:\n        sns.countplot(x=col, data=data, ax=ax)\n        a = ax.get_xmajorticklabels()\n        #         ax.axes.set_xticks(list(range(len(b))))\n        #         ax.axes.set_xticklabels(b)\n        continue\n\n    sns.histplot(data, x=col, ax=ax)\nplt.tight_layout()","3870c3df":"# correlation of inputs with target\nsns.set_context('talk')\nsns.pairplot(data, x_vars=num_cols, y_vars=['hg\/ha_yield'])","bf333af7":"def skewness(df, num_cols):\n    skew_limit = 0.75  # define a limit above which we will log transform\n    skew_vals = df[num_cols].skew()\n    # Showing the skewed columns\n    skew_cols = (skew_vals.sort_values(ascending=False).to_frame().rename(\n        columns={\n            0: 'Skew'\n        }).query('abs(Skew) > {}'.format(skew_limit)))\n    return skew_vals, skew_cols","cda60c10":"skew_v, skew_c = skewness(data, num_cols)\nskew_v","ebf18dc8":"skew_c","3e8c3f6a":"data_1 = data.copy()","2b60bcf8":"lambdas = []\n\nfor col in skew_c.index:\n    result = boxcox(data_1[col].values)\n    tmp = result[0]\n    lambdas.append(result[1])\n    data_1.drop(columns=[col], axis='columns', inplace=True)\n    data_1[col] = tmp\ndata_1.head()","4da81b01":"skew_v, skew_c = skewness(data_1, num_cols)\nskew_v","112048c6":"skew_c","835a351a":"sns.pairplot(data, x_vars=num_cols, y_vars=['hg\/ha_yield'])\nplt.title(\"Before transformation\")\nplt.show()\n\nax = sns.pairplot(data_1, x_vars=num_cols, y_vars=['hg\/ha_yield'])\nplt.title(\"After transformation\")\nplt.show()","195e4a8f":"# pairplot of the entier dataset\nsns.pairplot(data_1, palette='coolwarm', diag_kind='kde')\nplt.show()","9be3e781":"data_cleaned = data_1.copy()","03853e6c":"fig, axes = plt.subplots(nrows=2, ncols=2, sharey=True, figsize=(12.1, 10.6))\n\nfor index, ax in enumerate(axes.flatten()):\n    col = num_cols[index]\n    #     if col != 'hg\/ha_yield':\n    ax.scatter(data_cleaned[col], data_cleaned['hg\/ha_yield'])\n    ax.set_title(\"hg\/ha_yield and \" + col)\n    ax.set_ylabel(\"hg\/ha_yield\")\n    ax.set_xlabel(col)\n\nfig.tight_layout()\nplt.show()","adf234ce":"variables = data_cleaned[[\n    'average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp'\n]]\nvif = pd.DataFrame()\nvif[\"VIF\"] = [\n    variance_inflation_factor(variables.values, i)\n    for i in range(variables.shape[1])\n]\nvif[\"Features\"] = variables.columns","954e47c7":"vif","a0244184":"data_cleaned.describe(include='all').T","f626d098":"# Copy of the data\ndata_ohc = data_cleaned.copy()\n\nohc = OneHotEncoder(drop='first')\n\nfor col in cat_cols:\n    new_dat = ohc.fit_transform(data_ohc[[col]])\n    data_ohc = data_ohc.drop(col, axis=1)\n    categories = ohc.categories_[0][1:]\n\n    col_names = ['_'.join([col, x]) for x in categories]\n\n    # Create the new dataframe\n    new_df = pd.DataFrame(new_dat.toarray(),\n                          index=data_ohc.index,\n                          columns=col_names)\n\n    # Append the new data to the dataframe\n    data_ohc = pd.concat([data_ohc, new_df], axis=1)","681f9bd3":"data_ohc.head()","20c5a6a8":"# rearranging the columns\ncols = data_ohc.columns.to_list()\ncols.remove('hg\/ha_yield')\ncols.append('hg\/ha_yield')\n\ndata_processed = data_ohc[cols].copy()\ndata_processed.head()","c7b83207":"# saving processed data\ndata_processed.to_csv(\"ml_data.csv\", index=False, mode='+w')","4f99a5a0":"### Multicolinearity\n\n---\nFor data with no multicolinearity VIF should be less than 10","1200407e":"Alternative way for visualizing the distribution","0744f0aa":"### Exploring PDFs","412dbb72":"## Load Data","e43600b5":"## Encoding Categorical Features","1887d93b":"**Correlation between hg\/ha_yield and other features before transformation and after transformation**","01868d67":"# PERFORMING EDA ANALYSIS ON CROP YIELD PRODUCTION\n\nThus, cleaning and preprocessing the data and making it ready for further ML operations: \\[Data source: [Kaggle](https:\/\/www.kaggle.com\/patelris\/crop-yield-prediction-dataset)]\n\n---\n_Argriculture as the backbone of the economy_\n\nAgriculture is the _art and science of cultivating the soil_, growing crops and raising livestock. It includes the preparation of plant and animal products for people to use and thier distribution to markets. Agriculture provides most of the world's food and fabrics\n\n**Image of a man on the farm**\n![crop.jpeg](crop.jpeg)\n\n---\n> #### Context\nThe science of training machines to learn and produce models for future predictions is widely used, and not for nothing. Agriculture plays a critical role in the global economy. With the continuing expansion of the human population understanding worldwide crop yield is central to addressing food security challenges and reducing the impacts of climate change.\n>\n>Crop yield prediction is an important agricultural problem. The Agricultural yield primarily depends on weather conditions (rain, temperature, etc), pesticides and accurate information about history of crop yield is an important thing for making decisions related to agricultural risk management and future predictions.\n>\n> #### Acknowledgement\nAll dataset(publicly available dataset) here are taken form [FAO (Food and Agriculture Organization)](http:\/\/www.fao.org\/home\/en\/) ![Image_resized.jpeg](Image_resized.jpeg)\nand [World Data Bank](https:\/\/data.worldbank.org\/).\n![Data_bank.jpeg](Data_bank.jpeg)","676970ef":"## Preprocessing \n### Missing Values and Descriptive Statistics","2becdf0c":"Checking the skewness of the data after removing the outliers and transforming the data","bc4acc1d":"## Checking OLS Assumptions\n### Checking for Linearity","183b775a":"**All imports**","c6432a2f":"\n---\nAn empty data frame was returned because after  transforming the data there are skewed columns\n\n---","08ec5299":"## Feature Engineering\n### Checking Skewness and Dealing with Outliers"}}