{"cell_type":{"016b05ff":"code","4bbc4c7b":"code","0c458a07":"code","df7f9f7d":"code","e2c5501d":"code","1bb93efc":"code","b6026e9b":"code","27739726":"code","d1226ce9":"code","87ff2e2b":"code","170d5da2":"code","51637da0":"code","44fce3c1":"code","7c73617b":"code","e5977d13":"code","3a852509":"code","6acacf6a":"code","483b6dac":"code","1c698b40":"code","6bd2e631":"code","9a06c9bc":"code","708f7457":"code","1c7d3def":"code","6ab4b5a0":"markdown","b307bdb9":"markdown","45c3f2dd":"markdown","f2204d69":"markdown","cddf1e89":"markdown","b1ec904a":"markdown","34cc14f7":"markdown","72815e87":"markdown","cd9c643a":"markdown","681a7241":"markdown","e47dd39a":"markdown","0e39bfbc":"markdown","70d242f9":"markdown","631ed8fa":"markdown","8a88d42b":"markdown","4630b301":"markdown","2dce3087":"markdown","18398567":"markdown","c60d1593":"markdown","85d6dd28":"markdown","421bce24":"markdown","6b8402d0":"markdown","d4febaf1":"markdown","de4d84f6":"markdown","4acddce7":"markdown","52e77d2c":"markdown","5a1f53d4":"markdown","927cce7d":"markdown","5002bc0c":"markdown","a0a4c502":"markdown","1b4bcb74":"markdown","d7b4d8dc":"markdown","65ed88f4":"markdown","ca9c17ea":"markdown","9e45c96a":"markdown","1da609e4":"markdown","00450246":"markdown","8266f557":"markdown","b0a0abf9":"markdown"},"source":{"016b05ff":"from fastai.data.all import *\nfrom fastai.vision.all import *\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport torch\nimport zipfile\n\nprint(\"Libraries imported.\")","4bbc4c7b":"imgs_zip_path = \"..\/input\/hbku2019\/imgs.zip\"\nlabels_zip_path = \"..\/input\/hbku2019\/labels.zip\"\n\nsubmission_path = \".\/submission.csv\"\n\nimgs_extracted_path = \".\/\"\nlabels_extracted_path = \".\/\"\n\ntrain_img_path = \".\/imgs\/train\/\"\ntest_img_path = \".\/imgs\/test\/\"\n\ncategories_csv_path = \".\/labels\/categories.csv\"\nlabels_train_csv_path = \".\/labels\/labels_train.csv\"\n\nprint(\"Constants defined.\")","0c458a07":"def extract_folder(zip_path, dest_folder):\n    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n        namelist = zip_ref.namelist()\n        print(f'The number of files to extract: {len(namelist)}.')\n\n        # tqdm throws an error, that's why the ugly solution\n        for i, file in enumerate(namelist):\n            zip_ref.extract(member=file, path=dest_folder)\n            if i % 5000 == 0:\n                print(i)\n                \nprint(\"Extract images:\")\nextract_folder(imgs_zip_path, imgs_extracted_path)\nprint(\"DONE\")\n\nprint(\"Extract labels:\")\nextract_folder(labels_zip_path, labels_extracted_path)\nprint(\"DONE\")","df7f9f7d":"labels_train_df = pd.read_csv(labels_train_csv_path, header=None)\nlabels_train_df.head()","e2c5501d":"labels_train_df.tail()","1bb93efc":"print(labels_train_df.shape)","b6026e9b":"print(len(os.listdir(train_img_path)))","27739726":"categories_df = pd.read_csv(categories_csv_path, header=None)\ncategories_df.head()","d1226ce9":"print(categories_df.shape)","87ff2e2b":"vocab = categories_df[0].tolist()\nprint(vocab)","170d5da2":"print(len(os.listdir(test_img_path)))","51637da0":"dblock = DataBlock(\n    blocks=(ImageBlock, MultiCategoryBlock(encoded=True, vocab=vocab)),\n    get_x=lambda df: train_img_path + '\/' + df[0],\n    get_y=lambda df: df[1:].values.astype(int),\n    item_tfms=RandomResizedCrop(128, min_scale=0.35)\n)\n\nprint(\"Datablock is ready.\")","44fce3c1":"ds = dblock.datasets(labels_train_df.iloc[[1]])\n\nx, y = ds.train[0]\n\nprint(x)\nprint('--')\nprint(y)","7c73617b":"dls = dblock.dataloaders(labels_train_df)\ndls.show_batch(nrows=3, ncols=3)\n\nprint(\"Dataloaders created.\")","e5977d13":"learner = cnn_learner(dls, resnet50)\nlearner.fine_tune(5, base_lr=3e-3, freeze_epochs=6)","3a852509":"valids, targs = learner.get_preds() # predict from the validation set\n\nprint(valids)","6acacf6a":"valids.shape","483b6dac":"xs = torch.linspace(0.05,0.95,29)\naccs = [accuracy_multi(valids, targs, thresh=i, sigmoid=False) for i in xs]\nplt.plot(xs,accs);","1c698b40":"threshold = 0.5","6bd2e631":"test_imgs = get_image_files(test_img_path)\n\nprint(\"Test images loaded.\")","9a06c9bc":"test_dataloader = learner.dls.test_dl(test_imgs)\npreds, _ = learner.get_preds(dl=test_dataloader)","708f7457":"print(preds)","1c7d3def":"predicted_classes = [\"\" for i in range(len(test_imgs))]\n\n# i guess it's not the most pythonic, please advise me in the comments how to improve\nfor i, j in torch.nonzero(preds > threshold):\n    predicted_classes[i] += str(j.item())\n    predicted_classes[i] += \" \"\n\ndf = pd.DataFrame()\n\ndf[\"id\"] = [os.path.basename(test_img) for test_img in test_imgs]\ndf[\"values\"] = predicted_classes\n\ndf.info()\n\ndf.to_csv(submission_path, header=[\"id\", \"predictions\"], index=False)\n\nprint(\"Predictions saved to file.\")","6ab4b5a0":"<a id=\"intro.consts\"><\/a>\n## Constants\n[[back to top]](#toc)","b307bdb9":"Then the `DataLoaders#test_dl` method can be used to create a `dataloader` for the test images (see the [related section of my other fast.ai notebook](https:\/\/www.kaggle.com\/angyalfold\/fastai-imgclass-dog-breeds-step-by-step#Make-predictions) for further details). Once the `dataloader` is ready, predictions can be made by passing it to `learner#get_preds`.","45c3f2dd":"<a id=\"model.learner\"><\/a>\n## Learner\n[[back to top]](#toc)","f2204d69":"The number of test images is:","cddf1e89":"<a id=\"extract_input\"><\/a>\n# Extract input\n[[back to top]](#toc)","b1ec904a":"First, I examine the content of the `labels_train.csv` file. This is the file which contains the classes for each image in the training set. The first five elements:","34cc14f7":"<a id=\"save\"><\/a>\n# Save predictions\n[[back to top]](#toc)","72815e87":"<a id=\"conclusions\"><\/a>\n# Conclusions\n[[back to top]](#toc)","cd9c643a":"<a id=\"model.threshold\"><\/a>\n## Find threshold\n[[back to top]](#toc)","681a7241":"...so the model should produce 24444 predictions.","e47dd39a":"The next code snippet shows how the data looks. First, a [`DataSets` object](https:\/\/docs.fast.ai\/data.core.html#Datasets) is created from a single row of the `labels_train.csv`. Then the independent (`x`) and the dependent varaibles (`y`) are printed.","0e39bfbc":"Next, I'm checking the content of the `categories.csv` file:","70d242f9":"A convolutional neural network seems to be the appropriate choice to solve this problem. A CNN can be created by calling fast.ai's `cnn_learner` method. The`dls` parameter is the previously initialized `DataLoaders` object and [resnet50](https:\/\/www.kaggle.com\/pytorch\/resnet50) is a pretrained model. The idea is that it might be more effective to further train a model which is already capable of recognizing everyday objects, rathar than starting the whole process from scratch (transfer learning).\n\nWhen a model is based on a pretrained model it has two parts: one is the pretrained model and the other is a custom head on the top of the pretrained model. It is reasonable to assume that most of the learning takes place in the custom head and therefore it makes sense not to train the pretrained model for a couple of epochs (the pretrained part could be \"freezed\"). The `freeze_epochs` parameter determines the number of epochs in the begining of the training during which the wheights are not changed in the pretrained model. There are 11 epochs in total in the code below: 6 in which the pretrained model is freezed and then 5 other in which every weights could change.","631ed8fa":"...and plot the accuracy of the predictions using [fast.ai's `accuracy_multi`](https:\/\/docs.fast.ai\/metrics.html#accuracy_multi):","8a88d42b":"The aim of fast.ai's [datablock API](https:\/\/docs.fast.ai\/tutorial.datablock.html) is to create a blueprint which describes how to load and store the training data.\n\nThe `blocks` parameter stores a tuple which defines the type of the input data and the labels. In this case the input is an image (`ImageBlock`) and the labels are categories (`MultiCategoryBlock`). The categories are encoded (that's why `encoded=True`) which means that they are stored [one-hot-encoded](https:\/\/en.wikipedia.org\/wiki\/One-hot) (instead of actually showing the categories like \"car, hill, person\"). The possible categories are passed in the`vocab` parameter.\n\nThe `get_x` parameter defines how to fetch an image from one row of the csv file (assemble a path to the image using the first column) and the `get_y` defines how to collect the categories to the corresponding image (use the rest of the values as an integers from that row).\n\nThe `item_tfms` define the transformation which is performed on each image. As described in the documentation [RandomResizedCrop](https:\/\/docs.fast.ai\/vision.augment.html#RandomResizedCrop) \"Picks a random scaled crop of an image and resize it to size\".","4630b301":"An example of the epochs looks something like this:\n\n![epochs_and_losses.png](attachment:56bae47c-3f71-4b57-803d-8e7afab82875.png)","2dce3087":"<a id=\"links\"><\/a>\n# My other fast.ai notebooks\n[[back to top]](#toc)","18398567":"<a id=\"model\"><\/a>\n# Model\n[[back to top]](#toc)","c60d1593":"In order to make predictions, first the test images have to be loaded:","85d6dd28":"Once the [datablock](#model.datablock) is ready, the dataloaders can be created.","421bce24":"To feed the training data into the convolutional network, first wee need to have [datablock](#model.datablock), which is essentially a blueprint about how to store the data. Then the [dataloaders](#model.dataloaders) can be made based on the datablocks. Next, the [model (learner)](#model.learner) is initialized and fine tuned. The model returns a probability for each category, therefore a [threshold](#model.threshold) needs to be found above which a category is considered present on an image.","6b8402d0":"<a id=\"setup\"><\/a>\n# Setup & Imports\n[[back to top]](#toc)","d4febaf1":"<a id=\"model.datablock\"><\/a>\n## DataBlock\n[[back to top]](#toc)","de4d84f6":"<a id=\"EDA\"><\/a>\n# EDA\n[[back to top]](#toc)","4acddce7":"The number of images in the train folder is indeed 97774 so that matches.","52e77d2c":"Once the predictions are ready, they need to be saved into the `submission.csv` file. The expected format consists of two colums, one named `id` and the other `predictions`. The `id` column stores the entire file name (e.g.:`123.jpg` with the file extensions) and the predictions store the number of the categories separated with a space.","5a1f53d4":"The `learner` defined previously produces the probabilty of each category being present for a given picture. Therefore, a threshold has to be defined above which a category is considered to be present.\n\nThe way to find a threshold is to get the predictions for the validation set...","927cce7d":"In this notebook my aim was to create a simple model using fast.ai. The goal was not to build a state-of-the-art solution but to come up with a base-line model. Therefore, I didn't apply any fancy optimization technique. Still, the solution scores ~85% on the leaderboard.\n\nThe code is indeed fairly simple and consists of the following steps:\n\n1. Define a `DataBlock`:\n\n`dblock = DataBlock(\n    blocks=(ImageBlock, MultiCategoryBlock(encoded=True, vocab=vocab)),\n    get_x=lambda df: train_img_path + '\/' + df[0],\n    get_y=lambda df: df[1:].values.astype(int),\n    item_tfms=RandomResizedCrop(128, min_scale=0.35)\n)`\n\n2. Create a `Dataloaders` object based on the `DataBlock`:\n\n`dls = dblock.dataloaders(labels_train_df)`\n\n3. Define the model:\n\n`learner = cnn_learner(dls, resnet50)`\n\n4. Fine tune it:\n\n`learner.fine_tune(5, base_lr=3e-3, freeze_epochs=6)`\n\n5. Find\/double-check threshold:\n\n`valids, targs = learner.get_preds() # predict from the validation set\nxs = torch.linspace(0.05,0.95,29)\naccs = [accuracy_multi(valids, targs, thresh=i, sigmoid=False) for i in xs]\nplt.plot(xs,accs);`\n\n6. Load test data:\n\n`test_imgs = get_image_files(test_img_path)\ntest_dataloader = learner.dls.test_dl(test_imgs)`\n\n7. Make actual predictions:\n\n`preds, _ = learner.get_preds(dl=test_dataloader)`\n\nFast.ai indeed provides an easy way to implement models. It was surprising for me how similar the code is to the one which I implemented in [my previous notebook about fast.ai](https:\/\/www.kaggle.com\/angyalfold\/fastai-imgclass-dog-breeds-step-by-step\/comments) which was about finding dog breeds of images: the only difference was in the initialization of the dataloaders. In the previous notebook the target block was categorical (which was hidden in an `ImageDataLoaders` object), whereas in this case it was a `MultiCategoryBlock`. Apart from this, the two solutions are pretty much the same.","5002bc0c":"0.5 seems to be a reasonable choice for the threshold (that's also the default value). An example of the chart could look something like this:\n\n![accuracy.png](attachment:4cff150f-cc00-4301-88eb-5f0fb293f307.png)","a0a4c502":"<a id=\"introduction\"><\/a>\n# Introduction\n[[back to top]](#toc)","1b4bcb74":"<a id=\"model.dataloaders\"><\/a>\n## DataLoaders\n[[back to top]](#toc)","d7b4d8dc":"The dimensions of this file is 97774X81, so there are 97774 images and there are 80 possible classes which could appear on a picture.","65ed88f4":"... and the last five:","ca9c17ea":"There are 80 categories just like in the `labels_train.csv` file, so that matches too. The vocabulary (the names of the possible categories):","9e45c96a":"I'm going through [fast.ai's excellent book](https:\/\/course.fast.ai\/start_colab#Opening-a-chapter-of-the-book) chapter by chapter. On the way I'm solving related problems on Kaggle. These are the notebooks which I created so far:\n\n* [Image classification - dog breeds (nov. 2021)](https:\/\/www.kaggle.com\/angyalfold\/fastai-imgclass-dog-breeds-step-by-step)\n* Image multi-label classification (this notebook)","1da609e4":"In this notebook I'm solving the [DSEG660: Multi-Label Image Classification competition](https:\/\/www.kaggle.com\/c\/hbku2019\/overview) using [fast.ai](https:\/\/fast.ai). My solution is based on their [excellent tutorial](https:\/\/colab.research.google.com\/github\/fastai\/fastbook\/blob\/master\/06_multicat.ipynb). The aim of this notebook is to implement a solution which can serve as a baseline, hence there aren't any fancy optimizations in the code. My goal here is to create an easy-to-implement model.\n\nThe [first chapter](#setup) describes the basic setup which is required. The data is provided in compressed zip files, therefore the [following chapter](#extract_input) describes how to extract the data. Next, the [exploratory data analysis](#EDA) takes place.\n\nThe model is implemented in the [fourth chapter](#model), then [the predictions are made](#predictions) and then [saved](#save).","00450246":"<a id=\"toc\"><\/a>\n# Table of content\n\n* [My other fast.ai notebooks](#links)\n* [Introduction](#introduction)\n* [Setup & Imports](#setup)\n    * [Imports](#intro.imports)\n    * [Constants](#intro.consts)\n* [Extract input](#extract_input)\n* [EDA](#EDA)\n* [Model](#model)\n    * [DataBlock](#model.datablock)\n    * [DataLoaders](#model.dataloaders)\n    * [Learner](#model.learner)\n    * [Find threshold](#model.threshold)\n* [Make predictions](#predictions)\n* [Save predictions](#save)\n* [Conclusions](#conclusions)","8266f557":"<a id=\"intro.imports\"><\/a>\n## Imports\n[[back to top]](#toc)","b0a0abf9":"<a id=\"predictions\"><\/a>\n# Make predictions\n[[back to top]](#toc)"}}