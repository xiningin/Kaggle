{"cell_type":{"61a4eef3":"code","b5652ad6":"code","0c67ffa2":"code","1fd3a3cf":"code","821dc7e3":"code","8164791d":"code","3e495397":"code","9d2973c9":"code","2080da97":"code","a1daea51":"code","c65cb8f2":"code","e6e9f9bd":"code","05555423":"code","8a5bc349":"code","ab3041a4":"code","d36e59fd":"code","022c78dc":"code","43a0fc44":"code","ce969a2d":"code","898d891c":"code","7c4c4819":"code","9594bef6":"code","b0b0acf8":"code","a706c1e3":"code","c2dcfe19":"code","f48f3dc9":"code","03ba12b4":"code","89cfa87b":"code","a9780e9b":"code","5bcf7796":"code","93529a36":"code","6f49abcf":"code","6a710eaa":"code","02c98a0a":"markdown","2c80b321":"markdown","b846b4e2":"markdown","6e93a8d7":"markdown","17e15727":"markdown","6d9a93f7":"markdown","37ff0bd5":"markdown","d2a548c6":"markdown","f75810a4":"markdown"},"source":{"61a4eef3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b5652ad6":"pd.set_option('display.max_rows', 25)","0c67ffa2":"df = pd.read_csv('\/kaggle\/input\/cannabis-strains\/cannabis.csv')","1fd3a3cf":"df.head()","821dc7e3":"df.info()","8164791d":"df.sort_values(by='Rating', ascending=False).head(5)","3e495397":"df[df.isna().any(axis=1)].head()","9d2973c9":"df.dropna(inplace=True)\ndf.drop_duplicates(inplace=True)","2080da97":"df.info()","a1daea51":"effects = pd.Series(df['Effects']).str.get_dummies(',')\nflavor = pd.Series(df['Flavor']).str.get_dummies(',')\ntype_can = pd.Series(df['Type']).str.get_dummies(',')\ndf2 = df","c65cb8f2":"df2","e6e9f9bd":"df2 = df2.merge(effects, left_index=True, right_index=True)\ndf2 = df2.merge(flavor, left_index=True, right_index=True)\ndf2 = df2.merge(type_can, left_index=True, right_index=True)","05555423":"df2.drop(['Effects','Flavor', 'Type','Strain','Description'], axis=1, inplace=True)","8a5bc349":"df2.info()","ab3041a4":"df_new = df2","d36e59fd":"df_new.corr(method='pearson')","022c78dc":"df_new.corr(method='pearson')['Rating'].sort_values()","43a0fc44":"df_new.describe()","ce969a2d":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.color_palette(\"husl\", 8)\n\nmatrix = np.triu(df_new.corr())\nig = plt.figure(figsize = (20,20))\nsns.heatmap(df_new.corr(),mask=matrix)","898d891c":"fig = plt.figure(figsize=(20, 12))\nsorts = df_new[['indica','sativa', 'hybrid']]\ntips = sorts\nax = sns.barplot(data=tips)","7c4c4819":"columns = list(df_new.drop('Rating',axis=1).columns.sort_values())\ncolumns;","9594bef6":"data=df_new.drop('Rating',axis=1)\ndata = data.T\ndata = pd.DataFrame(data.sum(axis=1), columns=['Sum'])","b0b0acf8":"data = data.sort_values(by='Sum', ascending=False)","a706c1e3":"# columns = list(df_new.drop('Rating',axis=1).columns)\nfig = plt.figure(figsize=(20, 12))\nax = sns.barplot(x=data.index, y='Sum', data=data)\nax.set_xticklabels(labels=data.index, rotation = 90);\nax.set_title('Taste, smell, effect and strain of cannabis', fontdict={'fontsize': 24,\n                                                      'fontweight': 12,\n                                                      'color': '#0b57a7',\n                                                      'verticalalignment': 'baseline',\n                                                      'horizontalalignment': 'center'});","c2dcfe19":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn import preprocessing\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import roc_curve, auc","f48f3dc9":"dff = df_new.drop(['Rating'], axis=1)\n\ncols_to_use = dff.columns\n\nX = df_new[cols_to_use]\n\n# Select target\ny = df_new['Rating']\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y)","03ba12b4":"my_model = XGBRegressor(n_estimators=500)\nmy_model.fit(X_train, y_train, \n             early_stopping_rounds=5, \n             eval_set=[(X_valid, y_valid)],\n             verbose=False)","89cfa87b":"predictions = my_model.predict(X_valid)\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_valid)))","a9780e9b":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dense, BatchNormalization, Dropout, LSTM, Activation, RNN, Embedding\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop, Ftrl\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.metrics import BinaryAccuracy\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\nfrom tensorflow.keras import callbacks","5bcf7796":"#Early stopping\nearly_stopping = callbacks.EarlyStopping(\n    min_delta=0.001, # minimium amount of change to count as an improvement\n    patience=20, # how many epochs to wait before stopping\n    restore_best_weights=True,\n)\n\n# Initialising the NN\nmodel = Sequential()\n\n# layers\nmodel.add(Dense(units = 1024, activation='relu', use_bias=1, input_dim=69))\nmodel.add(Dropout(0.3))\nmodel.add(BatchNormalization())\nmodel.add(Dense(units = 16, activation='relu'))\nmodel.add(Dense(units = 1, activation='sigmoid'))\n\n# Compiling the NN\nopt = Ftrl(1e-4)\nloss = BinaryCrossentropy(from_logits=True)\nmetrics = BinaryAccuracy()\nmodel.compile(optimizer = opt, loss = loss, metrics = ['accuracy'])\n\n# Train the NN\nhistory = model.fit(X_train, y_train, batch_size = 16, epochs = 50, callbacks=[early_stopping], validation_split=0.2, verbose=1)","93529a36":"history_df = pd.DataFrame(history.history)\n\nplt.plot(history_df.loc[:, ['loss']], \"#BDE2E2\", label='Training loss')\nplt.plot(history_df.loc[:, ['val_loss']],\"#C2C4E2\", label='Validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(loc=\"best\")\n\nplt.show()","6f49abcf":"history_df = pd.DataFrame(history.history)\n\nplt.plot(history_df.loc[:, ['accuracy']], \"#BDE2E2\", label='Training accuracy')\nplt.plot(history_df.loc[:, ['val_accuracy']], \"#C2C4E2\", label='Validation accuracy')\n\nplt.title('Training and Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","6a710eaa":"# to be continued...","02c98a0a":"There is very bad result... I'll thinking what I can do.","2c80b321":"<div style=\"text-align: center;\"><font color=#0b57a7><h1>We need to clear the data.<\/h1><\/font><\/div>","b846b4e2":"<div style=\"text-align: center;\"><font color=#0b57a7><h1>We need look closer to data. Lets figure charts.<\/h1><\/font><\/div>","6e93a8d7":"<div style=\"text-align: center;\"><font color=#0b57a7><h1>We can try to compare teaching methods<\/h1><\/font><\/div>","17e15727":"<div style=\"text-align: center;\"><font color=#0b57a7><h1>We have cleaned up the data and now ready to learn something interesting from them<\/h1><\/font><\/div>","6d9a93f7":"<div style=\"text-align: center;\"><font color=#0b57a7><h1>Let's look at the cannabis data!<\/h1><\/font><\/div>","37ff0bd5":"<div style=\"text-align: center;\"><font color=#0b57a7><h1>Let's leave everything as it is for now and try to predict the 'Rating'<\/h1><\/font><\/div>","d2a548c6":"To begin with, let's build a correlation matrix to find out which features have a greater relationship.","f75810a4":"### We see a high correlation between the columns 'None_x', 'None_y' and 'Rating'.\n### There is also a high correlation between columns:\n* 'Fruit' and 'Trees'\n* 'Dry' and 'Mouth'\n\n### Which is quite logical."}}