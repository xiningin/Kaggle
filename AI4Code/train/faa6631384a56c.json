{"cell_type":{"d4911cbd":"code","b03f8b8d":"code","3ec8830f":"code","6c3b58ba":"code","f86f88db":"code","224abd2d":"code","fdd24f5c":"code","ddca7aa2":"code","81aaf2df":"code","bad9e85a":"code","d39d9ed6":"code","9ce9848a":"code","ec6b6446":"code","093af0c9":"code","ae4910a9":"code","6c0d4dc6":"code","9efcce72":"code","8f14eba5":"code","f5a43d5d":"code","5c277029":"code","7bc88163":"code","88eede2a":"code","947065ac":"code","3941d0c8":"code","17774e1c":"code","c3bd8770":"code","379b83a7":"code","65cb7cad":"code","3663f9df":"code","a5a3461e":"code","c3e92776":"code","1892c523":"code","31e96748":"markdown","d8db0d0f":"markdown","86f655eb":"markdown","c82810fc":"markdown","b3e45ac8":"markdown","3b6bf6b2":"markdown","73ff435a":"markdown","d7d0d976":"markdown","1615878e":"markdown","c6fb9fb2":"markdown","7eb9ca63":"markdown","e49b40ab":"markdown","17699cae":"markdown","e87f3839":"markdown","3a171c4b":"markdown","fe83431e":"markdown","1c8c8181":"markdown","65313ee4":"markdown","9b9fa65c":"markdown","2276c2bd":"markdown","d9575d43":"markdown","83ccd60f":"markdown","9bc5e0cf":"markdown","78e2b754":"markdown","ee988a47":"markdown","e3e78d5a":"markdown","8938e2be":"markdown","96b7fee1":"markdown","ca8e0d32":"markdown","96f15941":"markdown","dcb0745f":"markdown","1e2465e1":"markdown","9bd70218":"markdown","f5cb5175":"markdown","801cc1de":"markdown","a39f26cc":"markdown","4d4b4102":"markdown","40d84132":"markdown","a96d0379":"markdown","6db1c168":"markdown","5226e1d4":"markdown","81717db7":"markdown","1d236ecb":"markdown","20668358":"markdown","5a8f99d7":"markdown","a7d7d77e":"markdown","c409287c":"markdown","1ac7e365":"markdown","4df71260":"markdown"},"source":{"d4911cbd":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","b03f8b8d":"\ndataset = pd.read_csv('..\/input\/breast-cancer\/breast.csv')\ndataset.head()","3ec8830f":"dataset.isnull().sum()","6c3b58ba":"dataset1 = dataset.drop([\"Unnamed: 32\"], axis = 1)\ndataset1","f86f88db":"\ndataset1.isnull().values.any()","224abd2d":"dataset1.info()","fdd24f5c":"dataset1.describe()","ddca7aa2":"#plot heat map\nplt.figure(figsize=(20,20))\nsns.heatmap(dataset.iloc[:,0:31].corr(),annot=True,cmap=\"RdYlGn\")\n","81aaf2df":"X = dataset1.drop(['diagnosis'],axis = 1)\ny = dataset1['diagnosis']\nX.head()","bad9e85a":"y","d39d9ed6":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)","9ce9848a":"value_counts = pd.value_counts(y,sort = True)\nvalue_counts.plot(kind = 'bar', rot = 0)\nLabel = [' 0 - Benign', '1 - Malignant']\nplt.xticks(range(2), Label)\nvalue_counts","ec6b6446":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 1\/3, random_state = 10)","093af0c9":"\nfrom sklearn.preprocessing import StandardScaler\nsc=  StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n#print(X_train)\n","ae4910a9":"print(X_train)","6c0d4dc6":"print(X_test)","9efcce72":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression()\nclassifier.fit(X_train, y_train)","8f14eba5":"y_pred  = classifier.predict(X_test)","f5a43d5d":"print(\"training  set accuracy : {}\".format(classifier.score(X_train,y_train)*100))\nprint(\"test set accuracy : {}\".format(classifier.score(X_test,y_test)*100))","5c277029":"from sklearn.metrics import confusion_matrix, accuracy_score\n\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nprint(accuracy_score(y_test, y_pred))\n#   [TN , FP\n#    FN , TP]","7bc88163":"y_proba  = classifier.predict_proba(X_test)[:,1]","88eede2a":"y_pred_th4 = np.where(classifier.predict_proba(X_test)[:,1]>0.4,1,0) # when  threshold is 0.4\n\ny_pred_th3 = np.where(classifier.predict_proba(X_test)[:,1]>0.3,1,0) #  when threshold is 0.3\n\ny_pred_th2 = np.where(classifier.predict_proba(X_test)[:,1]>0.26,1,0) #  when threshold is 0.26\n\ny_pred_th1 = np.where(classifier.predict_proba(X_test)[:,1]>0.1,1,0) #  when threshold is 0.1\n","947065ac":"ct = pd.crosstab(y_test,y_pred_th2)\nct","3941d0c8":"\nfrom sklearn.model_selection import cross_val_score\ncross_validation = cross_val_score(estimator = classifier, X = X_train,y = y_train, cv = 10)\nprint(\"\\nCross validation mean accuracy of Logistic Regression = \", cross_validation.mean())\nprint(\"\\nCross validation std. of Logistic Regression = \", cross_validation.std())\ncross_val_res = pd.DataFrame(cross_validation*100)","17774e1c":"cross_val_res","c3bd8770":"from sklearn.metrics import roc_curve, roc_auc_score","379b83a7":"fpr,tpr, thresholds = roc_curve(y_test, y_proba)","65cb7cad":"\nfpr","3663f9df":"tpr","a5a3461e":"thresholds","c3e92776":"s = roc_auc_score(y_test, y_proba)\ns","1892c523":"import matplotlib.pyplot as plt\nplt.figure(figsize = (8,6))\nfrom sklearn.metrics import  roc_curve, roc_auc_score\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.plot(fpr,tpr, color = 'darkorange', linewidth = 5, label = 'ROC Curve (area = %0.3f)' % (s))\nplt.plot([0,1],[0,1], 'g--')\n\nplt.title('Receiver Operating Characteristic')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc = 'lower right')","31e96748":"###  2.5 Feature scaling","d8db0d0f":"### 3.2 Predict the test set results","86f655eb":"## 2. Data Preprocessing","c82810fc":"###  4.1 comparision score of  train and test set","b3e45ac8":"### 4.2 creating confusion_marix and accuracy","3b6bf6b2":"## 5 find best threshold to optimize the model","73ff435a":"## 4. Evaluate the prediction & performance ","d7d0d976":"- Thresholds values","1615878e":"### 1. Load Libraries","c6fb9fb2":"####   3.4 get correlations of each features in dataset","7eb9ca63":" ### 3.  Exploratary data analysis","e49b40ab":"- False Positive Rate:\nFalse Positive Rate is the proportion of observations that are incorrectly predicted to be positive.","17699cae":"### 5.3 evaluate the final result with tuned Threshold value","e87f3839":" !Perfect now we don't have any null value in dataset & we are going to check the datatype in dataset1","3a171c4b":"# 3. Modeling","fe83431e":"Note : here y(dependent dataset) have category (Benign, Malignant) we have to convert this into numeric data. For this we have to use LabelEncoder","1c8c8181":"###  2.1 indepenent dataset & dependent dataset","65313ee4":"## 6.  Visualizing the final result using ROC Curve","9b9fa65c":"Benign: The tumor doesn\u2019t contain cancerous cells.\n\nMalignant: The tumor contains cancerous cells","2276c2bd":"- we sucessfully achieve the desire result here FN = 0, and in the previous result was FN = 2","d9575d43":"###   3.3  Descriptive Statistical Analysis","83ccd60f":"- We have a total of non-null 569 patients\u2019 information with 31 features. All feature data types in the float. The size of the DataFrame is 142.4 KB.\n\n- Numerical distribution of data. We can know to mean, standard deviation, min, max, 25%,50% and 75% value of each feature.","9bc5e0cf":"###   2. Load dataset","78e2b754":"- Here we get good accuracy using logistic Model But here if we look at the confusion matrix here model prediced '2' person don't have cancer(Malignant) which is not good or dangerous for the person have cancerous cells but our model predicted as Bengin(not cancer cell)\n- We can solve this problem by changing the Threshold value in the Model. By default Logisitic Model thershold is 0.5, But we can tune up.","ee988a47":"# if this notebook was helpful please upvote & If you have any questions or suggestions, feel free to write them down in the comment section.","e3e78d5a":" + For AUC use roc_auc_score() python function for ROC\n","8938e2be":"As we can see, clearly the classifier has improved. Compare it with the previous Confusion Matrix given below:","96b7fee1":"here we are droping the columns 32 cause it's contain NAn values which is irrelavent","ca8e0d32":"###  3.1 applying Logistic Regression","96f15941":"###  5.4  Applying ROC Curve","dcb0745f":"### 2.4 splitting data into train and test set","1e2465e1":"###  3.2   checking the datatype &  Getting information of cancer DataFrame using \u2018.info()\u2018 method","9bd70218":"In the Confusion Matrix example, we built a logistic regression classifier to predict whether the state of breast cancer is malignant or benign. We observed the confusion matrix as shown below.\n\n","f5cb5175":"The describe function automatically computes basic statistics for all continuous variables. Any NaN values are automatically skipped in these statistics.","801cc1de":"We have clean and well formated DataFrame, so DataFrame is ready to visualize.","a39f26cc":"- True Positive Rate:\nTrue Positive Rate is the proportion of observations that are correctly predicted to be positive.\n","4d4b4102":"Note:\n- True Positive is 65\n- True Negative is 116\n- False Positive is 9\n- False Negative is 0","40d84132":"### 0. Motivation","a96d0379":"Breast cancer is the most common type of cancer in women around the world and the second highest in terms of mortality rates, and is normally detected when an abnormal lump or a tiny speck of calcium are found (from self-examination or x-ray). Early detection of this kind of cancer can greatly improve survival chances by promoding clinical treatment to patients as soon as possible. That said, the main purpose of this post is to predict wether a lump is benign or malign through data analysis.\n\nAll Information and data related to this problem can be found here: https:\/\/www.kaggle.com\/uciml\/breast-cancer-wisconsin-data\/","6db1c168":"# Breast Cancer Prediction with Logistic Regression using threshold Tuning","5226e1d4":"- here initially we build a modle with 97% accuracy using Logisitic Regression. but there are some FN(false Negative values) means patients those  have Cancer(Malignant) are predicted as non-cancer(Benign) . Which is very dangerous for the patients. we tuned the thershold value 0.5 to 0.26.and we successfully reach to desire output with FN-'0' . ","81717db7":" Here we have 'diagnosis' Column in dataset,datatype of that particular column is 'categories' & it is our target variable\n later we will convert this  into numeric data using LabelEncoder","1d236ecb":"#### 3.1checking missing values","20668358":"## 7. Conclusion:","5a8f99d7":"### 5.1 Set the threshold at different-different point and see the result at which thershold our Model improved and give us 0 - FN(Flase Negative) as result","a7d7d77e":"### 2.3  Visualizing  the size of Benign & Malignant","c409287c":"To find a correlation between each feature and target we visualize heatmap using the correlation matrix.","1ac7e365":"## 5.4 Cross validation to final result","4df71260":"### 2.2 Applying Labelencoder "}}