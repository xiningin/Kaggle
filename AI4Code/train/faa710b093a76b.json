{"cell_type":{"30af5dd6":"code","eb9a6de1":"code","28c0c90e":"code","73f36bb0":"code","2305f712":"code","81a999de":"code","45e27488":"code","e57a83fc":"code","dba1c480":"code","dd118adb":"code","e04a7a9e":"code","f842fa00":"code","35f6a7c7":"code","7feed15b":"markdown","d13839eb":"markdown","4fa23f70":"markdown","808237e0":"markdown","9660932c":"markdown","66e68ec2":"markdown","c408050c":"markdown","ef878230":"markdown","64a00799":"markdown","848acc6e":"markdown","d47d7b8d":"markdown","8b1288dd":"markdown","edcc6cd0":"markdown"},"source":{"30af5dd6":"import numpy as np\nfrom scipy.spatial import distance, Delaunay, cKDTree\nfrom scipy.sparse import csgraph, coo_matrix\nfrom sklearn.metrics.pairwise import paired_euclidean_distances\nimport networkx as nx","eb9a6de1":"all_cities = np.loadtxt(\"..\/input\/cities.csv\", delimiter=\",\", skiprows=1)\nN = all_cities.shape[0]\ncities = all_cities[0:N,1:3]","28c0c90e":"def pathDists(path):\n    pcities = cities[path]\n    return paired_euclidean_distances(pcities[1:], pcities[:-1])\n\ndef linesToDists(lines):\n    return paired_euclidean_distances(cities[lines[:,0]],cities[lines[:,1]])\n\ndef linesToMatrix(lines):\n    dists = linesToDists(lines)\n    return coo_matrix((dists, (lines[:,0],lines[:,1])), (N, N)).todok()\n\ndef linesToCountMatrix(lines):\n    return coo_matrix((np.full((lines.shape[0],), 1), (lines[:,0],lines[:,1])), (N, N)).tocsr()\n\ndef matrixToLines(matrix):\n    mTuple = np.nonzero(matrix)\n    return np.column_stack(mTuple)\n\ndef matrixNormalize(matrix):\n    mTuple = np.nonzero(matrix)\n    matrix[mTuple[::-1]] = matrix[mTuple]","73f36bb0":"tri = Delaunay(cities)\nindptr, indv2 = tri.vertex_neighbor_vertices\nindv1 = np.arange(indv2.shape[0])\nfor i in range(N):\n    indv1[indptr[i]:indptr[i+1]] = i\ntriLines = np.column_stack((indv1,indv2))\ntriMatrix = linesToMatrix(triLines)","2305f712":"mstMatrix = csgraph.minimum_spanning_tree(triMatrix, True)\nmstLines = matrixToLines(mstMatrix)\norder = mstLines.argsort(axis=1)\nmstLines = mstLines[np.arange(order.shape[0])[:,None], order]\nmstLines = np.unique(mstLines, axis=0)\nprint(\"MST\", linesToDists(mstLines).sum(), np.sum(mstMatrix))","81a999de":"mstRanks = np.bincount(mstLines.flatten())\nmstOddIndices = np.nonzero(mstRanks % 2 == 1)[0]\noddCities = cities[mstOddIndices]\nmstOddTree = cKDTree(oddCities)\nmstOddClosestDists, mstOddClosestIndices = mstOddTree.query(oddCities, 2)\nmstOddClosestLines1 = np.column_stack((mstOddIndices,mstOddIndices[mstOddClosestIndices[:, 1]]))\norder = mstOddClosestLines1.argsort(axis=1)\nmstOddClosestLines1 = mstOddClosestLines1[np.arange(order.shape[0])[:,None], order]\nmstOddClosestLines1 = np.unique(mstOddClosestLines1, axis=0)\nmstOverLines = np.concatenate((mstLines, mstOddClosestLines1), axis=0)\nmstRanks = np.bincount(mstOverLines.flatten())","45e27488":"mstUniqueLines, counts = np.unique(mstOverLines, axis=0, return_counts=True)\ngoodRepeats = mstUniqueLines[(counts > 1) * ((mstRanks[mstUniqueLines[:,0]] % 2 == 0) + (mstRanks[mstUniqueLines[:,1]] % 2 == 0))]\nmstLines = np.concatenate((mstUniqueLines, goodRepeats), axis=0)\nmstRanks = np.bincount(mstLines.flatten())\ngoodRepeats = goodRepeats[(mstRanks[goodRepeats[:,0]] == 2) + (mstRanks[goodRepeats[:,1]] == 2) + (mstRanks[goodRepeats[:,0]] % 2 == 0) * (mstRanks[goodRepeats[:,1]] % 2 == 0)]\nmstLines = np.concatenate((mstUniqueLines, goodRepeats), axis=0)\nmstRanks = np.bincount(mstLines.flatten())\ngoodRepeats = goodRepeats[(mstRanks[goodRepeats[:,0]] % 2 == 0) + (mstRanks[goodRepeats[:,1]] % 2 == 0)]\nmstLines = np.concatenate((mstUniqueLines, goodRepeats), axis=0)\nprint(\"MST odd\", linesToDists(mstLines).sum())","e57a83fc":"mstRanks = np.bincount(mstLines.flatten())\nmstOddIndices = np.nonzero(mstRanks % 2 == 1)[0]\nM = mstOddIndices.shape[0]\ninvOddIndices = np.full((N,), -1)\ninvOddIndices[mstOddIndices] = np.arange(M)\noddCities = cities[mstOddIndices]\nmstOddTree = cKDTree(oddCities)\nmstOddClosestDists, mstOddClosestIndices = mstOddTree.query(oddCities, 6)\nmstOddClosestLines1 = np.column_stack((np.arange(M),mstOddClosestIndices[:, 1]))\nmstOddClosestLines2 = np.column_stack((np.arange(M),mstOddClosestIndices[:, 2]))\nmstOddClosestLines3 = np.column_stack((np.arange(M),mstOddClosestIndices[:, 3]))\nmstOddClosestLines4 = np.column_stack((np.arange(M),mstOddClosestIndices[:, 4]))\nmstOddClosestLines5 = np.column_stack((np.arange(M),mstOddClosestIndices[:, 5]))","dba1c480":"triOddLines = triLines[(mstRanks[triLines[:,0]] % 2 == 1) * (mstRanks[triLines[:,1]] % 2 == 1)]\ntriOddLines = invOddIndices[triOddLines]\noddLines = np.concatenate((triOddLines, mstOddClosestLines1, mstOddClosestLines2, mstOddClosestLines3, mstOddClosestLines4, mstOddClosestLines5), axis=0)\noddDists = paired_euclidean_distances(oddCities[oddLines[:,0]],oddCities[oddLines[:,1]])\noddMatrix = coo_matrix((oddDists, (oddLines[:,0],oddLines[:,1])), (M, M)).todok()\nn_components, labels = csgraph.connected_components(oddMatrix, directed=False, return_labels=True)\nprint(n_components, np.bincount(labels))\nnxMatrix = nx.from_scipy_sparse_matrix(-oddMatrix)","dd118adb":"matching = nx.max_weight_matching(nxMatrix, maxcardinality=True)\nmatchingLines = np.array([[key,val] for (key,val) in list(matching)])\nmatchingLines = mstOddIndices[matchingLines]\nprint(\"Perfect\", linesToDists(matchingLines).sum())\n\n# leave only necessary edges\nmstLines = np.concatenate((mstLines, matchingLines), axis=0)\nmstRanks = np.bincount(mstLines.flatten())\nmatchingLines = mstLines[(mstRanks[mstLines[:,0]] % 2 == 1) + (mstRanks[mstLines[:,1]] % 2 == 1)]","e04a7a9e":"eulerianMatrix = nx.MultiGraph()\neulerianMatrix.add_edges_from(mstLines)\neulerianMatrix.add_edges_from(matchingLines)\ncircuit = nx.eulerian_circuit(eulerianMatrix,source=0)\ncircuitLines = np.array([[key,val] for (key,val) in list(circuit)])\nprint(\"Circuit\", linesToDists(circuitLines).sum())","f842fa00":"path, order = np.unique(circuitLines.flatten(), return_index=True)\npath = order.argsort()","35f6a7c7":"print(\"Path\", pathDists(path).sum())\nzeroIdx = np.argmin(path)\npath = np.roll(path, -zeroIdx)\npath = np.append(path, 0)\n\nnp.savetxt('submission.csv', path, fmt='%d', header='Path', comments='')\nnp.savetxt('submission_inv.csv', path[::-1], fmt='%d', header='Path', comments='')","7feed15b":"Step 2: Get list of edges of Minimum Spanning Tree","d13839eb":"Step 1: Get sparce matrix of distances only for Delaunay triangulation","4fa23f70":"Next, let's load cities data from [Traveling Santa 2018](https:\/\/www.kaggle.com\/c\/traveling-santa-2018-prime-paths\/data)","808237e0":"Step 5: And build sparse matrix only of those edges, making sure they all create single Connected Component.","9660932c":"Finally, validate and save produced path","66e68ec2":"Step 8: Shortcut Eulerian circuit to produce Path","c408050c":"Step 4: Among vertices, that still have odd rank, for each vertex find 5 closest vertices.","ef878230":"Step 7: Join found edges with edges found previously to produce Eulerian graph. Find Eulerian Circuit in that graph","64a00799":"Step 6: Find Minimum Weight Perfect Matching for matrix built on previous step","848acc6e":"Step 3.5: Remove duplicated edges added on previous step if they don't reduce number of vertices with odd rank.","d47d7b8d":"This is an attemp to implement [Christofides algorithm](https:\/\/en.wikipedia.org\/wiki\/Christofides_algorithm) using existing libraries for Python, such as scipy, sklearn, networkx.\n\nFirst let's import dependencies, that we will be using.","8b1288dd":"Then, we'll define methods to calculate distances for path and for list of edges, as well as transition methods between sparse matrices and lists of edges. ","edcc6cd0":"Step 3: Reduce number of vertices with odd rank by linking closest vertices with odd rank."}}