{"cell_type":{"36dfc80b":"code","c6d5c723":"code","df5457bb":"code","84950a59":"code","d03f41f5":"code","755089a4":"code","62cd5afc":"code","e25f8781":"code","d7014447":"code","3bd20369":"code","999e9cc3":"code","52b41fd7":"code","5e8f3757":"code","34144261":"code","f3c41c50":"code","3f33a517":"code","b304401e":"code","be5ad1b1":"code","42e5f18a":"code","dcf76192":"code","14e16b17":"code","09261303":"code","594b23dc":"code","30b8642f":"markdown","b3e57768":"markdown","008bf92a":"markdown","aafe5cda":"markdown","f39ea3d9":"markdown","e388bb45":"markdown","1a49cd27":"markdown","58cdc8a5":"markdown","15fddb20":"markdown","300de067":"markdown","27e0d69b":"markdown","a24dba8c":"markdown","96f288dc":"markdown","7773f3b2":"markdown","1c70a181":"markdown","b8515ab1":"markdown","6b7e80f4":"markdown","34a2b601":"markdown","e4513b81":"markdown","def13f9b":"markdown"},"source":{"36dfc80b":"from IPython.display import Image\nurl = 'https:\/\/bplusmovieblog.files.wordpress.com\/2016\/08\/pink-floyd-the-wall-18.png'\nImage(url=url,width=800, height=600)","c6d5c723":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nfrom keras.utils.np_utils import to_categorical # one hot encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n%matplotlib inline\nsns.set(style='white', context='notebook', palette='deep')\n\n# Set random seed to get a consistent result\nrandom_seed = 2\nnp.random.seed(random_seed)","df5457bb":"# Load the training data and review\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntrain.head(5)","84950a59":"# Load the test data and review\ntest = pd.read_csv(\"..\/input\/test.csv\")\ntest.head(5)","d03f41f5":"# Compare columns between test and train\nprint(\"Columns in training data but not in testing data\")\nprint([x for x in train.columns if x not in test.columns])\nprint(\"Columns in testing data but not in training data\")\nprint([x for x in test.columns if x not in train.columns])","755089a4":"# Split into x and y for training\nY_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1)\nX_test = test","62cd5afc":"train_null_rows = sum(X_train.isnull().sum())\nprint(\"Number of train rows with null pixels:\",train_null_rows)\n\n# Drop rows with missing values as long as it doesn't exceed 2% of the data\nif train_null_rows < len(X_train.index)*0.02:\n    X_train = X_train.dropna()\n    \ntest_null_rows = sum(X_test.isnull().sum())\nprint(\"Number of test rows with null pixels:\",train_null_rows)\n\n# Drop rows with missing values as long as it doesn't exceed 2% of the data\nif test_null_rows < len(X_test.index)*0.02:\n    X_test = X_test.dropna()","e25f8781":"fig = plt.figure(figsize=(12, 5))\nax = sns.countplot(Y_train)\nax.set_title(\"Number of training examples per digit\")","d7014447":"# Normalize the data\nX_train = X_train \/ 255.0\nX_test = X_test \/ 255.0","3bd20369":"# Reshape into 3D matrices\nX_train = X_train.values.reshape(X_train.shape[0], 28, 28 , 1).astype('float32')\nX_test = X_test.values.reshape(X_test.shape[0], 28, 28 , 1).astype('float32')","999e9cc3":"Y_num_classes = Y_train.nunique()\nprint(\"the number of classes = %i\" % Y_num_classes)\nprint(\"Dimension of images = {:d} x {:d}\".format(X_train[1].shape[0],X_train[1].shape[1]))","52b41fd7":"images_and_labels = list(zip(X_train,  Y_train))\nfor index, (image, label) in enumerate(images_and_labels[:12]):\n    plt.subplot(5, 4, index + 1)\n    plt.axis('off')\n    plt.imshow(image.squeeze(), cmap=plt.cm.gray_r, interpolation='nearest')\n    plt.title('label: %i' % label )","5e8f3757":"# Encode labels to one hot vectors\nY_train = to_categorical(Y_train, num_classes = Y_num_classes)\nprint(\"A few examples of the one hot encoding:\")\nprint(Y_train[:5,:])","34144261":"# Split the train and the validation set for the fitting\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, \n                                                  Y_train, \n                                                  test_size = 0.1, \n                                                  stratify=Y_train, #balance digits across data\n                                                  random_state=random_seed)","f3c41c50":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, \n                 kernel_size = (5,5),\n                 #strides=2,\n                 padding = 'Same', \n                 activation ='relu', \n                 input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, \n                 kernel_size = (5,5),\n                 #strides=2,\n                 padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Conv2D(filters = 64, \n                 kernel_size = (3,3),\n                 padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, \n                 kernel_size = (3,3),\n                 padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), \n                    strides=(2,2)))\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, \n                activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, \n                activation = \"softmax\"))","3f33a517":"# Define the optimizer\n#optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","b304401e":"# Compile the model\nmodel.compile(optimizer='adam', \n              #optimizer=optimizer,\n              loss = \"categorical_crossentropy\", \n              metrics=[\"accuracy\"])","be5ad1b1":"datagen = ImageDataGenerator(\n        rotation_range=10,\n        zoom_range = 0.2,\n        width_shift_range=0.1,\n        height_shift_range=0.1)\n\ndatagen.fit(X_train)","42e5f18a":"# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","dcf76192":"# 30 epochs ran in roughly 130 minutes with CPU\n# 40 epochs ran in roughly 9 minutes with GPU\nepochs = 40 # set to something around 20 to 30 to increase accuracy\nbatch_size = 86\n\nmodel.fit_generator(datagen.flow(X_train,\n                                 Y_train,\n                                 batch_size=batch_size),\n                    epochs = epochs, \n                    validation_data = (X_val,Y_val),\n                    verbose = 2, \n                    callbacks=[learning_rate_reduction],\n                    steps_per_epoch=X_train.shape[0] \/\/ batch_size)","14e16b17":"# Look at confusion matrix \n\ndef plot_confusion_matrix(cm, \n                          classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize=(12, 5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    \n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1)\n\n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n\n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(Y_num_classes))","09261303":"# predict results\nresults = model.predict(X_test)\n\n# select the index with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\nresults.head(5)","594b23dc":"results_count = len(results)\nsubmission = pd.concat([pd.Series(range(1,results_count+1),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","30b8642f":"Compare columns between training and test data to ensure only the \"label\" column is the difference between the two data sets.","b3e57768":"**2) Explore and Normalize Data**\n\nA number of data exploration steps give us more insight into how to approach this data.","008bf92a":"**3) Define and train the neural network**","aafe5cda":"Predict the results.","f39ea3d9":"General additional images that are slight alternations of the existing images in order to reduce overfitting and boost the number of examples to train on.","e388bb45":"Display a few of the images.","1a49cd27":"Split out a validation data set.","58cdc8a5":"Display a confusion matrix of the results.","15fddb20":"Take data from gray scale 0-255 to 0-1 normalized scale.","300de067":"This is my initial attempt at the Digit Recognizer challenge. The following kernels were very helpful for me to learn from:\n* [Yassine's kernel](https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6)\n* [Moghazy's kernel](https:\/\/www.kaggle.com\/moghazy\/guide-to-cnns-with-data-augmentation-keras)\n\n<br\/>\nThe thought of all of these poorly handwritten digits made me think of school children...which in turn led me to think of Pink Floyd and the image below. I'm feeling a strong appreciation for Kaggle right now because there's definitely no \"dark sarcasm in the classroom\" here which is one of the many reasons I'm learning so much.","27e0d69b":"Define the layer architecture of the neural network.","a24dba8c":"Fit the model.","96f288dc":"Confirm the number of classes as well as new shape of the training data.","7773f3b2":"**4) Predict and submit results**","1c70a181":"**1) Load and Prep Data**\n\nWe first need to load in the handwritten digits for both the train file and the test file.","b8515ab1":"Create the submission file.","6b7e80f4":"Reshape the image data from rows of 1D vectors with 784 values to 3D vectors with dimensions 28x28x1.","34a2b601":"Compile the model.","e4513b81":"Encode labels as a \"one hot\" vector - e.g. change a label of \"2\" to \"0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\"","def13f9b":"If there are only a small amount of images missing values (less than 2%) then automatically remove those images."}}