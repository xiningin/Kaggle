{"cell_type":{"609246e1":"code","0057c496":"code","4a9ed2a0":"code","d7dc802f":"code","45559d01":"code","ba64b4ba":"code","9285a8cd":"code","eacd226e":"code","544aa98e":"code","e1200b39":"code","54311ca3":"code","844b14f5":"code","734681e4":"code","1f68b8cc":"code","e523f515":"code","11de8ede":"code","dd5f5a54":"code","bd86bc22":"code","f58a4081":"code","f909748c":"code","51bc2dc1":"code","ba68522d":"code","b02ab7c8":"code","9f9ef22c":"code","b4e23801":"markdown","a0abcde6":"markdown","e4c58d2d":"markdown","7ec4a012":"markdown","c7450110":"markdown","59b7f2b9":"markdown","a0ed5def":"markdown","ebed117e":"markdown","9930ca0e":"markdown","efa63020":"markdown","f859ea69":"markdown","cad595ad":"markdown","98da3ac3":"markdown","33f01fc4":"markdown","64bf4189":"markdown","183320a5":"markdown","01281121":"markdown","6f0a2f35":"markdown","b0add495":"markdown","5b69d5cf":"markdown","1a87b651":"markdown"},"source":{"609246e1":"from IPython.display import YouTubeVideo\n\nYouTubeVideo('AdjRZnvnHF0', width=800, height=450)","0057c496":"YouTubeVideo('v-4XB2ca4uQ', width=800, height=450)","4a9ed2a0":"YouTubeVideo('dUb46Q3xZro', width=800, height=450)","d7dc802f":"!pip install scikit-allel","45559d01":"import numpy as np # data analysis\nimport pandas as pd # data analysis\nimport matplotlib.pyplot as plt # data vizualization\nimport seaborn as sns # data visualization\nfrom sklearn.model_selection import train_test_split # machine learning\nfrom sklearn.ensemble import RandomForestClassifier # machine learning\nimport shap # model explainability\nimport eli5 # model explainability\nimport allel # work with genetic data","ba64b4ba":"def plot_feature_importances(df):\n    '''\n    Adapted from https:\/\/github.com\/WillKoehrsen\/feature-selector\n    '''\n    #Sort features according to importance\n    df = df.sort_values('importance', ascending = False).reset_index()\n    #Normalise the feature importances to add up to one\n    df['importance_normalized'] = df['importance'] \/ df['importance'].sum()\n    #Make a horizontal bar chart of feature importances\n    plt.figure(figsize = (10,6))\n    ax = plt.subplot()\n    #Need to reverse the index to plot most important on top\n    ax.barh(list(reversed(list(df.index[:15]))),\n           df['importance_normalized'].head(15),\n           align = 'center', edgecolor = 'k')\n    #Set the yticks and labels\n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    #Plot labeling\n    plt.xlabel('Normalized Importance'); plt.title('Feature Importance')\n    plt.show()\n    return df","9285a8cd":"example_clinical_data_path_1 = '\/kaggle\/input\/end-als\/end-als\/clinical-data\/filtered-metadata\/metadata\/clinical\/Demographics.csv'\nexample_clinical_data_path_2 = '\/kaggle\/input\/end-als\/end-als\/clinical-data\/filtered-metadata\/metadata\/clinical\/ALSFRS_R.csv'\nexample_transcriptomics_DESEQ2_data_path_1 = '\/kaggle\/input\/end-als\/end-als\/transcriptomics-data\/DESeq2\/bulbar_vs_limb.csv'\nexample_transcriptomics_DESEQ2_data_path_2 = '\/kaggle\/input\/end-als\/end-als\/transcriptomics-data\/DESeq2\/ctrl_vs_case.csv'\nexample_transcriptomics_3counts_data_path = '\/kaggle\/input\/end-als\/end-als\/transcriptomics-data\/L3_counts\/CASE-NEUZX521TKK\/CASE-NEUZX521TKK-5793-T\/CASE-NEUZX521TKK-5793-T_P85.exon.txt'\n\ndemographics = pd.read_csv(example_clinical_data_path_1)\ndemographics.to_csv('\/kaggle\/working\/demographics.csv')\nalsfrs_scores = pd.read_csv(example_clinical_data_path_2)\nalsfrs_scores.to_csv('\/kaggle\/working\/alsfrs_scores.csv')\nbulbar_vs_limb = pd.read_csv(example_transcriptomics_DESEQ2_data_path_1)\nbulbar_vs_limb.to_csv('\/kaggle\/working\/bulbar_vs_limb.csv')\nctrl_vs_case = pd.read_csv(example_transcriptomics_DESEQ2_data_path_2)\nctrl_vs_case.to_csv('\/kaggle\/working\/ctrl_vs_case.csv')\nexample_transcriptomics_3counts_data = pd.read_csv(example_transcriptomics_3counts_data_path,delim_whitespace=True,skiprows=1,low_memory=False)\nexample_transcriptomics_3counts_data.to_csv('\/kaggle\/working\/L3_counts.csv')","eacd226e":"sns.histplot(demographics.age);","544aa98e":"print('Demographics:\\n\\n')\ndemographics.head(5)","e1200b39":"sns.histplot(alsfrs_scores.alsfrsdt);","54311ca3":"print('ALSFRS Scores:\\n\\n')\nalsfrs_scores.head(5)","844b14f5":"print('bulbar_vs_limb:\\n')\nbulbar_vs_limb.head(5)","734681e4":"print('ctrl_vs_case:\\n')\nctrl_vs_case.head(5)","1f68b8cc":"print('example_transcriptomics_3counts_data:\\n')\nexample_transcriptomics_3counts_data.head(5)","e523f515":"print('example_genomics_data:\\n')\nexample_vcf_file = \"\/kaggle\/input\/end-als\/end-als\/genomics-data\/AnswerALS_subset_annovar.hg38_anno_and_geno.no_intergenic.vcf\"\ndf = allel.vcf_to_dataframe(example_vcf_file)\ndf.to_csv('\/kaggle\/working\/vcf_converted_to_csv.csv')\ndf.head(20)","11de8ede":"data_dir = '\/kaggle\/input\/end-als\/end-als\/genomics-data'\nfilename = data_dir + '\/AnswerALS_subset_annovar.hg38_anno_and_geno.no_intergenic.vcf'\nchunksize = 2 * 10 ** 4\nnrows = 10945503\nchunks = pd.read_csv(filename, sep = '\\t', skiprows=3518, chunksize=chunksize)\ndf = pd.DataFrame()\n\ndef get_rsID(INFO):\n    return [x.split('=')[1] for x in INFO.split(';') if x.startswith('avsnp150')][0]\n\ndef get_maxMAF(INFO):\n    freq_columns = ['ExAC_nontcga_ALL', 'esp6500siv2_all']\n    freqs = []\n    for info in INFO.split(';'):\n        if info.startswith('ExAC_nontcga_ALL') or info.startswith('esp6500siv2_all'):\n            freq = info.split('=')[1]\n            freqs.append(float('0'+freq))\n    return max(freqs)\n\ndef is_exonic(INFO):\n    functions = [x.split('=')[1] for x in INFO.split(';') if x.startswith('Func.ensGene') or x.startswith('Func.refGene') or x.startswith('Func.knownGene')]\n    return 'exonic' in functions\n\nfor i,chunk in enumerate(chunks):\n    if i % 100 == 0:\n        print(f\"{i+1} out of {int(nrows\/chunksize)} chunks.\")\n    # Selecting PASSing variants (according to GATK VQSR)\n    data = chunk[chunk.FILTER == 'PASS']\n    # Selecting exonic variants only\n    data = data[data.INFO.apply(is_exonic)]\n    # Selecting variants with frequency 10% or less\n    data = data[data.INFO.apply(lambda x: get_maxMAF(x) <= 0.1)]\n    # Defining index with SNP ID\n    data.index = data[['#CHROM', 'POS', 'INFO']].apply(lambda x: get_rsID(x[2]) if get_rsID(x[2]) != '.' else x[0]+':'+str(x[1]), axis=1)\n    # Selecting genotype columns only\n    geno = data.iloc[:,9:]\n    # Replacing genotype codes with 0s and 1s\n    for col in geno.columns:\n        geno[col] = geno[col].apply(lambda x: 0 if x.split(':')[0] == '0\/0' else (np.nan if x.split(':')[0] == '.\/.' else 1))       \n    #print(geno.shape)\n    #geno.to_csv(f'{data_dir}\/geno{i+1}.csv')  \n    # Concatenating to the dataframe\n    df = pd.concat([df, geno])\n    \nmeta_dir = '\/kaggle\/input\/end-als\/end-als\/clinical-data\/filtered-metadata\/metadata\/'\nmetadata = pd.read_csv(meta_dir + 'aals_released_files.csv')\nmetadata = metadata[['Participant_ID', 'CGND_ID']].drop_duplicates()\nmetadata = metadata[-metadata.CGND_ID.isnull()]\nmetadata = metadata[-metadata.Participant_ID.isnull()]\n\nfor i,row in metadata.iterrows():\n    if row['CGND_ID'] in df.columns:\n        df = df.rename(columns = {row['CGND_ID'] : row['Participant_ID']})\n    if row['CGND_ID']+'-b38' in df.columns:\n        df = df.rename(columns = {row['CGND_ID']+'-b38' : row['Participant_ID']})\ndf.to_csv('\/kaggle\/working\/geno.csv')\n# This file is already provided for you in the following location:\n# '\/kaggle\/input\/end-als\/end-als\/genomics-data\/geno_bin.csv'","dd5f5a54":"geno_bin = pd.read_csv('\/kaggle\/input\/end-als\/end-als\/genomics-data\/geno_bin.csv')\ngeno_bin.to_csv('\/kaggle\/working\/geno_bin.csv')\ngeno_bin.head(25)","bd86bc22":"training_data = bulbar_vs_limb.drop(['SiteOnset_Class','Participant_ID'],axis=1)\nlabels = bulbar_vs_limb['SiteOnset_Class']\nX_train, X_test, y_train, y_test = train_test_split(training_data, labels, train_size=0.9, random_state=0)","f58a4081":"features = list(X_train.columns)\nrandom_forest = RandomForestClassifier(random_state=0)\nrandom_forest.fit(X_train,y_train)","f909748c":"feature_importance_values = random_forest.feature_importances_\nfeature_importances = pd.DataFrame({'feature': features, 'importance':feature_importance_values})\nfeature_importances_sorted = plot_feature_importances(feature_importances)","51bc2dc1":"explainer = shap.TreeExplainer(random_forest)\nshap_values = explainer.shap_values(X_train)\nshap.summary_plot(shap_values[1], X_train)","ba68522d":"dict_characters = {0: 'Bulbar', 1: 'Limb'} # double check this\nprint(dict_characters)\nsns.set_style(\"whitegrid\")\nplt = sns.FacetGrid(bulbar_vs_limb, hue='SiteOnset_Class',aspect=2.5)\nplt.map(sns.kdeplot,'SLC9B2',shade=True)\nplt.set(xlim=(bulbar_vs_limb['SLC9B2'].min(), bulbar_vs_limb['SLC9B2'].max()))\nplt.add_legend()\nplt.set_axis_labels('SLC9B2', 'Proportion')\nplt.fig.suptitle('SLC9B2 counts vs Diagnosis (0 = Bulbar; 1 = Limb)')","b02ab7c8":"YouTubeVideo('AdjRZnvnHF0', width=800, height=450)","9f9ef22c":"import time\nfrom datetime import datetime\nimport sklearn\nimport matplotlib\n\nprint(f'Notebook last run on {datetime.fromtimestamp(time.time()).strftime(\"%Y-%m-%d, %H:%M:%S UTC\")}\\n')\nprint('- numpy version ',np.__version__)\nprint('- pandas version ',pd.__version__)\nprint('- matplotlib version ',matplotlib.__version__)\nprint('- seaborn version ',sns.__version__)\nprint('- scikit-learn version ',sklearn.__version__)\nprint('- shap version ',shap.__version__)\nprint('- eli5 version ',eli5.__version__)\nprint('- allel version ',allel.__version__)\n\n!mkdir \/kaggle\/working\/docker\/\n!pip freeze > '..\/working\/docker\/requirements.txt'","b4e23801":"***Step 3: Load the data***","a0abcde6":"***Step 1: Import Python packages***","e4c58d2d":"For example, you can find a gene that has a very high feature importance value for your model that was used to predict bulbar vs limb for ALS patients.  And then you can research about this gene, and try to see if maybe it fits into a relevant biological pathway.  Are the genes that your machine learning model identified good targets for future laboratory researchers to investigate in more detail?  Why do you think so?  Use markdown cells and a text narrative to thoroughly explain your rationale.","7ec4a012":"***Step 2: Define helper functions***","c7450110":"For this example, we are training a machine learning model and then we are interpreting the results, within the context of predicting bulbar vs limb for ALS patients.  We are not taking the time to assess the accuracy and the performance of our model. This was done for the sake of brevity -- in your own submission you should definitely assess the accuracy and the performance of your model. For example, this dataset has a large amount of data about a small number of patients and therefore you will have to take extra special care not to overfit to the training data.","59b7f2b9":"Case vs Ctrl and Bulbar vs Limb","a0ed5def":"# Challenge Overview\nAmyotrophic Lateral Sclerosis (ALS) is a devastating neurological disease that affects 1 in 400 people. Patients suffer a progressive loss of voluntary muscle control leading to paralysis, difficulty speaking, swallowing and ultimately, breathing. Over 60% of patients with ALS die within 3 years of clinical presentation and 90% will die within 10 years. But there is reason for hope.\n\nWe stand at a very important time and place in our mission to end ALS. Biotechnologies are rapidly evolving to produce new sources of data and change the way we learn about the brain in health and disease. Answer ALS has generated an unprecedented amount of clinical and biological data from ALS patients and healthy controls. We need your help to analyze that data, increase our understanding of ALS and bring clarity to potential therapeutic targets.\n\n[Answer ALS](https:\/\/www.answerals.org), [EverythingALS](https:\/\/www.everythingals.org) and [Roche Canada's Artificial Intelligence Centre of Excellence] (https:\/\/betakit.com\/roche-launching-national-ai-digital-health-initiative-alongside-amii-mila-vector-institute\/) is requesting the collaborative effort of the AI community to fight ALS. This challenge presents a curated collection of datasets from a number of Answer ALS sources and asks you to model solutions to [key questions](https:\/\/www.kaggle.com\/alsgroup\/end-als\/discussion\/221210) that were developed and evaluated by ALS neurologists, researchers, and patient communities. See [Task Detail Pages](https:\/\/www.kaggle.com\/alsgroup\/end-als\/discussion\/221210) for more detail.","ebed117e":"* Reformat the genomics data and add ParticipantID to make the data easier to work with (thanks to @lelimat for providing the following code snippets!):","9930ca0e":"One option for explaining your models predictions is to investigate the feature importance values and the shap values.  The eli5 and shap Python packages are great for this.  It can be a challenging task if you are starting from scratch.  Best of luck!","efa63020":"***Step 4: Preview the data***","f859ea69":" For this example we will walk through one potential approach for addressing Task #1:\n \n - Task #1: Does ALS have one mechanism of action (one pathway) or is it caused by multiple independent or different mechanisms of action (multiple pathways)? For example, what is the genetic difference between people with ALS with Bulbar onset (they start the symptoms in bulbar functions) versus Limb (they start the symptoms in the limbs)?\n \nSpecifically, we will: (1) train a machine learning model to predict \"bulbar vs limb\"; (2) investigate why your machine learning model made the predictions that it did; (3) identify what genes or transcripts counts might be most predictive for developing bulbar ALS vs limb ALS; and (4) provide a logical rationale for why these genes might be worthy of future laboratory research studies.  Does it make sense if you take the time to also investigate the role of these same genes in known biological pathways?","cad595ad":"* Quick preview of the genomics data:","98da3ac3":"Demographics and ALSFRS Scores","33f01fc4":"Genomics Data","64bf4189":"I identified the gene SLC9B2 as potentially being important for predicting if a patient develops bulbar ALS vs limb ALS.  But [when I go to research about that same gene](https:\/\/www.ncbi.nlm.nih.gov\/gene?Db=gene&Cmd=DetailsSearch&Term=133308), I am not finding much that would help us to validate or increase our confidence level in that particular result.  I'll need to do a bit more research about this gene -- learn about the biological pathways that it might be relevant to -- and also I should research some of the other top candidates that we identified.  Maybe something will come up when I research about it on [genemania.org](http:\/\/apps.cytoscape.org\/apps\/genemania)?\n\n[The genemania tool](http:\/\/apps.cytoscape.org\/apps\/genemania) allows you to explore the ways different proteins interact with each other. Some of the things you will find will not be found within GeneMania because it is part of our genetics that doesn't code for a protein, or it is poorly understood. But other variables you find will be searchable. You can take collections of these genes and use GeneMania to see if they are part of a biological pathway that does indeed make sense! For those of you who are experienced at this sort of thing, I would like to recommend that you download an amazing professional level tool called [Navigator](http:\/\/navigator.ophid.utoronto.ca\/navigatorwp\/). These tools are what biologists and their computer science colleagues use to make sense of our molecular machinery. We encourage you to create a story from these tools if you are so inclined. Remember the task here: we want you to use your abilities to help us untangle which variables are driving different aspects of ALS. Good luck! Thanks to the [Bader](https:\/\/baderlab.org\/) and [Jurisica](https:\/\/www.cs.toronto.edu\/~juris\/home.html) labs. \n\nFor more detail, watch the video below:","183320a5":"***Step 6: Explain why your machine learning model made the predictions that it did***","01281121":"L3_counts data","6f0a2f35":"***Step 5: Train a machine learning model***","b0add495":"# Summary of Tasks\n - **Task #1: Does ALS have one mechanism of action (one pathway) or is it caused by multiple independent or different mechanisms of action (multiple pathways)**? For example, what is the genetic difference between people with ALS with Bulbar onset (they start the symptoms in bulbar functions) versus Limb (they start the symptoms in the limbs)?\n  - For this task you might be especially interested in the following 3 data sources: ctrl_vs_case.csv, median_low_vs_high.csv, and bulbar_vs_limb.csv.  The L3_counts data is also likely to be useful.\n - **Task #2: What are potential mechanisms of disease progression?** Are there other population sub-classifications associated to ALS progression not traditionally considered within the clinical environment within the datasets? For reference: It is estimated that 60 percent of individuals with familial ALS have an identified genetic mutation. The cause of the condition in the remaining individuals is unknown. The C9orf72, SOD1, TARDBP, and FUS genes are key to the normal functioning of motor neurons and other cells.\n  - For this task you might be especially interested in the following 3 data sources: ctrl_vs_case.csv, median_low_vs_high.csv, and bulbar_vs_limb.csv.  The L3_counts data is also likely to be useful.\n - **Task #3: What is the difference (genetic expression, transcriptomic, symptomatology) between people with ALS who progress faster versus those who develop it more slowly**? For example, what is the relationship between genetic expression and the scale ALSFRS subcategory scores?\n   - For this task you might be especially interested in the following 3 data sources: ALSFRS_R.csv, \/L3_counts\/, and \/genomics-data\/.\n\n","5b69d5cf":"***Step 7: Identify genes that might be of interest to ALS researchers and explain your rationale***","1a87b651":"There are 4 core data sources for this challenge: \/transcriptomics-data\/DESeq2\/, \/transcriptomics\/L3_counts\/, \/clinical-data\/, and \/genomics-data\/.  The field \"Participant ID\" can be used to join all of these data sources.\n\nThere are [2 core datasets](https:\/\/www.kaggle.com\/alsgroup\/end-als) containing transcriptomics data and transcript counts for ~100 ALS patients. These 2 core datasets are grouped into 2 separate folder: DESeq2 and L3_counts.  \n\nThe DESeq2 folder has the following 3 files: ctrl_vs_case.csv, median_low_vs_high.csv, and bulbar_vs_limb.csv. The first column is the Patient Name eg. NEUDE902GCT.  The second column is the classifier in numeric form Ctrl = 0, Case = 1; Bulbar = 0, Limb = 1; Mean of ALSFRS, where below Mean =0, above or equal to the Mean = 1; Median of ALSFRS, where below Median =0, above or equal to the Median = 1, etc.  \n\nL3_counts folder: Level 3 data in transcriptomic summarize the counting results by featureCounts software. For each sample, the output is a tab delimited text file that includes annotation columns (\u2018Geneid\u2019, \u2018Chr\u2019, \u2018Start\u2019, \u2018End\u2019, \u2018Strand\u2019 and \u2018Length\u2019) and a data column (i.e, read counts for genes). The annotation columns provide information about the counted feature such as ensembl gene ID, genomic location in terms of chromosome number and Start\/End coordinates as well as strand and counting length. Only the data column for read count is usually used in differential analysis.\n\nAnother core data source for this challenge is the clinical metadata that can be found at \/kaggle\/input\/end-als\/clinical-data\/filtered-metadata\/meta-data\/clinical\/aals_dataportal_datatable.csv. In addition to the common clinical features such as sex and age at disease onset, we also include in the dataset stem cell differentiation related technical features such as protein staining data for 6 markers (NEFH, NKX6.1, s100b, TUBB3, Nestin and ISL1). These staining data range between 0 and 100 and represent the % of cells in the sample that express the specific marker, thus the proportion of certain cell types. Since cell type composition affects global gene expression profile, it may be helpful to include the staining data in the modeling. For example, staining data for s100b can be included as a covariate in the DESeq analysis. For more information about sample staining, see \/kaggle\/input\/end-als\/clinical-data\/filtered-metadata\/meta-data\/clinical\/Answer ALS metadata datatable with QC Staining.csv\n\nThe genomics data is provided in full in VCF format but also there is a processed .CSV file that is easier to work with that you can find at \/genomics-data\/geno_bin.csv.  In this starter notebook, we prepare a VCF ([variant call format](https:\/\/en.wikipedia.org\/wiki\/Variant_Call_Format)) file to apply ML models. These files contain information about the changes in the genome (e.g. A>C, T>G, etc.). The whole human genome has about 3 billion positions, but we usually have between 4 and 7 million variants, as more than 99% of our genomes are the same.  The **VCF** file has a long header (all lines starting with ##) with information about the chromosomes present in the file, the programs\/parameters used to generate the file and the meaning of some fields we see in the file. After the long header, we have the column labels, which is a single line starting with #. This line has the following columns:\n1. CHROM: variant chromosome\n2. POS: variant position in the chromosome\n3. ID: variant ID (usually rsID, from [dbSNP](https:\/\/www.ncbi.nlm.nih.gov\/snp\/))\n4. REF: reference allele (A, T, C, G, ...)\n5. ALT: alternate allele (A, T, C, G, ...)\n6. QUAL: variant quality\n7. FILTER: variant quality filter (usually generated by the [GATK VQSR](https:\/\/gatk.broadinstitute.org\/hc\/en-us\/articles\/360035531612-Variant-Quality-Score-Recalibration-VQSR-) tool)\n8. INFO: variant annotation (information like the gene name, variant location in the gene, functional impact, frequency in the population, etc.)\n9. FORMAT: order of additional fields about the genotypes\n10. ... From column 10 on, we have the information about the samples. The main information we want is how many copies each sample has of the reference (always represented by 0) and alternate alleles (represented by 1, 2, 3, ...). Let's say a specific variant is a change from A to G. Then A is the reference allele and G is the alternate allele. If a patient has two copies of the reference allele, we will see the genotype as \"0\/0\". If the patient has one copy of the reference and one copy of the alternate allele, we will see the genotype as \"0\/1\", and if the patient has two copies of the alternate allele, we will see \"1\/1\". In some cases, more than one alternate alleles will be found (let's say most individuals have a T, but some can have a C and some can have a G). In these cases, we will see other combinations like \"0\/2\" (the patient has one copy of the reference and one copy of the second most frequent alternate allele).\n\nTo simplify the analysis, we coded the variants as binary data, meaning that patients with at least one copy of the alternate allele will have 1 for that variant and if the patient has only the reference allele, the value will be 0.\n\nTo filter the variants for this competition, we selected variants that passed the GATK VQSR quality control, removed variants that are outside genes (intergenic regions of the genome), and selected only variants with a frequency of 10% or less.\n\n\n\nAll four core datasets have all been collected and deposited into a central location [here](https:\/\/www.kaggle.com\/alsgroup\/end-als\/data).  For additional detail about these datasets, you can refer to https:\/\/www.kaggle.com\/alsgroup\/end-als\/discussion\/218964."}}