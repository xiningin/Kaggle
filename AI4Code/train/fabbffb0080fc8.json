{"cell_type":{"e06276cd":"code","4d388323":"code","6048b60f":"code","fa8d4a2f":"code","ce17e661":"code","8e9ec65f":"code","93e50c17":"code","86824fe3":"code","6218fa9b":"code","5e38640c":"code","37f2751a":"code","36e4576a":"code","7e5ee255":"code","691c4c4f":"code","2892aa93":"code","ec78ea5d":"code","acadc961":"code","c5418738":"code","7337d1f2":"code","e314bf33":"code","339b858d":"markdown","334ec266":"markdown","adc2f278":"markdown"},"source":{"e06276cd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4d388323":"messages = pd.read_csv(\"\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv\")","6048b60f":"messages.head()","fa8d4a2f":"messages = messages.iloc[:,:2]","ce17e661":"messages.head()","8e9ec65f":"messages.iloc[:2,1]","93e50c17":"messages.shape","86824fe3":"import nltk \nimport re\nfrom nltk.corpus import stopwords #Stop words finder\nfrom nltk.stem.porter import PorterStemmer #Stemming the words\n\n","6218fa9b":"ps = PorterStemmer()\ncorpus = []   # Saving the final sentences (step5)","5e38640c":"for i in range(0,len(messages)):\n    review = re.sub('[^a-zA-Z]',\" \", messages[\"v2\"][i])  #Removing special characters etc\n    review = review.lower()\n    review = review.split()\n    review = [ps.stem(word) for word in review if word not in stopwords.words('english')]  #Stemming words which are not stopwords\n    review = \" \".join(review)\n    corpus.append(review)\n    ","37f2751a":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features=2500)\nx = cv.fit_transform(corpus).toarray()","36e4576a":"y = pd.get_dummies(messages[\"v1\"],drop_first=True)\ny","7e5ee255":"y = np.array(y)","691c4c4f":"y","2892aa93":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=0)","ec78ea5d":"from sklearn.naive_bayes import MultinomialNB\nspam_detect_model = MultinomialNB().fit(x_train, y_train)","acadc961":"y_pred=spam_detect_model.predict(x_test)","c5418738":"from sklearn.metrics import accuracy_score\nscore = accuracy_score(y_pred,y_test)","7337d1f2":"score","e314bf33":"from sklearn.model_selection import cross_val_score\ncv_score = cross_val_score(spam_detect_model,x,y,cv=5)\nprint(\"Cross Val scoe: {}\".format(np.mean(cv_score)))","339b858d":"# Model Building","334ec266":"# Converting words to vectors (Bag of words) for model to understand","adc2f278":"# Data Cleaning and preprocessing \n1. Removing stop words(using stopwords) and ,!? etc using Regex\n2. Converting to lower case and spliting the messages into words\n3. Applying Lematization\/stemming to words (excluding stop words)\n4. Join the words back into a sentence\n5. Store in a new list"}}