{"cell_type":{"a48da587":"code","be6b7da0":"code","a90f2437":"code","aae702a6":"code","f9986dfc":"code","3fadd730":"code","94033bbd":"code","ee1ecfa4":"code","6e10208b":"code","6cc5b5e8":"code","864b5fd1":"code","f34f1eed":"code","85a1ffbd":"code","26596615":"code","178f56f0":"code","36d36e37":"code","2f9455f6":"code","84121d3c":"code","e1c80e75":"code","d5d4e6d4":"code","2dcf8466":"code","0045d428":"code","04456c49":"code","fec210fa":"code","76a48cb5":"markdown","62582b18":"markdown","c157c995":"markdown","d8c27ec4":"markdown","50241a3b":"markdown","cbbaf7c9":"markdown","dccca0a7":"markdown","15660a93":"markdown","16fac064":"markdown","3844b58e":"markdown","7d72c347":"markdown","3bddf183":"markdown","2f5b4e18":"markdown","1c9aee70":"markdown","1db65aae":"markdown","42810985":"markdown","0e33073a":"markdown","ea3d505f":"markdown","39726b8c":"markdown","c425948d":"markdown","4ed14d83":"markdown","a5d02fb7":"markdown","5a11b3f9":"markdown","2272c856":"markdown","19068fbe":"markdown"},"source":{"a48da587":"#import stuff\nimport os\nimport glob\nimport h5py\nimport shutil\nimport imgaug as aug #augment data\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt #plot stuff\/show images\nimport matplotlib.image as mimg\nimport imgaug.augmenters as iaa #augment data(data is imbalanced)\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\nfrom PIL import Image\nfrom pathlib import Path #get data\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom keras.models import Sequential, Model\nfrom keras.applications.vgg16 import VGG16, preprocess_input #transfer learning\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\n#convolutional nueral networks\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nimport cv2\nfrom keras import backend as K\ncolor = sns.color_palette()\n%matplotlib inline\nprint(os.listdir(\"..\/input\"))","be6b7da0":"import tensorflow as tf\n\ndevice_name = tf.test.gpu_device_name()\nif device_name != '\/device:GPU:0':\n  raise SystemError('GPU device not found')\nprint('Found GPU at: {}'.format(device_name))\ntf.config.experimental.list_physical_devices('GPU')","a90f2437":"#get data\ndata_dir1 = Path('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray')\ndata_dir2 = Path('..\/input\/covid19-detection-xray-dataset')\ndata_dir3 = Path('..\/input\/covid19-radiography-database\/COVID-19 Radiography Database')\ndata_dir4 = Path('..\/input\/pneumonia-virus-vs-covid19\/Pneumonia_and_COVID19')","aae702a6":"data = []\nnormal_data = []\nbacterial_data = []\nviral_data = []","f9986dfc":"loop_dir1 = ['test', 'train', 'val']\nfor i in loop_dir1:\n    normal_dir1 = data_dir1 \/ i \/ 'NORMAL'\n    pneumonia_dir1 = data_dir1 \/ i \/ 'PNEUMONIA'\n    normal_cases1 = normal_dir1.glob('*.jpeg')\n    pneumonia_cases1 = pneumonia_dir1.glob('*.jpeg')\n    for img in normal_cases1:\n        normal_data.append((img,0))\n    for img in pneumonia_cases1:\n        if \"bacteria\" in str(img):\n            bacterial_data.append((img,1))\n        elif \"virus\" in str(img):\n            viral_data.append((img,2))\n    ","3fadd730":"loop_dir2 = ['NonAugmentedTrain', 'ValData']\nfor i in loop_dir2:\n    normal_dir2 = data_dir2 \/ i \/ 'Normal'\n    bacterial_dir2 = data_dir2 \/ i \/ 'BacterialPneumonia'\n    viral_dir2 = data_dir2 \/ i \/ 'ViralPneumonia'\n    normal_cases2 = normal_dir2.glob('*.jpeg')\n    bacterial_cases2 = bacterial_dir2.glob('*.jpeg')\n    viral_cases2 = viral_dir2.glob('*.jpeg')\n    for img in normal_cases2:\n        normal_data.append((img,0))\n    for img in bacterial_cases2:\n        bacterial_data.append((img,1))\n    for img in viral_cases2:\n        viral_data.append((img,2))","94033bbd":"# normal_dir3 = data_dir3 \/ 'NORMAL'\n# viral_dir3 = data_dir3 \/ 'Viral Pneumonia'\n# normal_cases3 = normal_dir3.glob('*.png')\n# viral_cases3 = viral_dir3.glob('*.png')\n# for i, img in enumerate(normal_cases3):\n#     im = Image.open(img)\n#     rgb_img = im.convert('RGB')\n#     rgb_img.save('normal('+str(i)+').jpeg', quality=100, subsampling = 0)\n#     data.append((rgb_img,0))\n# for i, img in enumerate(viral_cases3):\n#     im = Image.open(img)\n#     rgb_img = im.convert('RGB')\n#     rgb_img.save('viral('+str(i)+').jpeg', quality=100, subsampling = 0)\n#     data.append((rgb_img,2))\n    \n    \n# for img in normal_cases2:\n#     rgb_img = cv2.imread(img)\n#     cv2.imwrite(img[:-3] + 'jpeg', rgb_img)\n#     data.append((img,0))\n# for img in viral_cases2:\n#     rgb_img = cv2.imread(img)\n#     cv2.imwrite(img[:-3] + 'jpeg', rgb_img)\n#     data.append((img,2))","ee1ecfa4":"loop_dir4 = ['TEST', 'TRAIN']\nfor i in loop_dir4:\n    viral_dir4 = data_dir4 \/ i \/ 'PNEUMONIA (VIRUS)'\n    viral_cases4 = viral_dir4.glob('*.jpeg')\n    for img in viral_cases4:\n        viral_data.append((img,2))","6e10208b":"print('number of normal cases: ' + str(len(normal_data)))\nprint('number of bacterial cases: ' + str(len(bacterial_data)))\nprint('number of viral cases: ' + str(len(viral_data)))","6cc5b5e8":"data = normal_data + bacterial_data + viral_data\ndel normal_data, bacterial_data, viral_data, data_dir1, data_dir2, data_dir3, data_dir4","864b5fd1":"data = pd.DataFrame(data, columns=['image', 'label'],index=None)\n#shuffle\ndata = data.sample(frac=1.).reset_index(drop=True)\n#print\ndata.head()        ","f34f1eed":"# Get the counts for each class\ncases_count = data['label'].value_counts()\nprint(cases_count)\n\n# Plot the results \nplt.figure(figsize=(10,8))\nsns.barplot(x=cases_count.index, y= cases_count.values)\nplt.title('Number of cases', fontsize=14)\nplt.xlabel('Case type', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Bacterial(1)', 'Viral(2)'])\nplt.show()\ndel cases_count","85a1ffbd":"#show sample\nviral_samples = (data[data['label']==2]['image'].iloc[:5]).tolist()\nbacterial_samples = (data[data['label']==1]['image'].iloc[:5]).tolist()\nnormal_samples = (data[data['label']==0]['image'].iloc[:5]).tolist()\n\n# Concat the data in a single list and del the above 3 lists\nsamples = viral_samples + bacterial_samples + normal_samples\ndel viral_samples, normal_samples, bacterial_samples\n\n# Plot the data \nf, ax = plt.subplots(3,5, figsize=(30,15))\nfor i in range(15):\n    img = imread(samples[i])\n    ax[i\/\/5, i%5].imshow(img, cmap='gray')\n    if i<5:\n        ax[i\/\/5, i%5].set_title(\"Viral\")\n    elif i>=5 and i<10:\n        ax[i\/\/5, i%5].set_title(\"Bacterial\")\n    else:\n        ax[i\/\/5, i%5].set_title(\"Normal\")\n    ax[i\/\/5, i%5].axis('off')\n    ax[i\/\/5, i%5].set_aspect('auto')\nplt.show()","26596615":"data = data.iloc[: int(data.shape[0]\/2)]\nprint(data.shape)","178f56f0":"image_data = []\nlabel_data = []\nfor index, d in data.iterrows():\n    img = d['image']\n    l = d['label']\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (224,224))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)\/255.\n    label = to_categorical(l, num_classes=3)\n    image_data.append(img)\n    label_data.append(label)\nimage_data = np.array(image_data)\nlabel_data = np.array(label_data)\ndel data","36d36e37":"image_train, image_validate, image_test = np.split(image_data, [int(.7*len(image_data)), int(.85*len(image_data))])\nlabel_train, label_validate, label_test = np.split(label_data, [int(.7*len(label_data)), int(.85*len(label_data))])\nprint('number of training images and labels: ' + str(len(image_train)) + ' and ' + str(len(label_train)))\nprint('number of validation images and labels: ' + str(len(image_validate)) + ' and ' + str(len(label_validate)))\nprint('number of test images and labels: ' + str(len(image_test)) + ' and ' + str(len(label_test)))\ndel image_data, label_data","2f9455f6":"from keras.applications.vgg16 import VGG16\nvgg16_weights = '..\/input\/vgg16\/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\nvgg16_model = VGG16(weights=vgg16_weights)\nnew_vgg16 = Sequential()\nfor layer in vgg16_model.layers[:-1]:\n    new_vgg16.add(layer)\nnew_vgg16.add(Dense(3, activation='softmax'))\ndel vgg16_model, vgg16_weights\n#new_vgg16.summary()\n","84121d3c":"new_vgg16.compile(loss='categorical_crossentropy',\n              optimizer= Adam(lr=0.0001, decay=1e-5),\n              metrics=['accuracy'])","e1c80e75":"early_stopping_monitor = EarlyStopping(\n    monitor='val_acc',\n    min_delta=0,\n    patience=4,\n    verbose=0,\n    mode='max',\n    baseline=None,\n    restore_best_weights=True\n)","d5d4e6d4":"batch_size = 16\nwith tf.device('\/gpu:0'):\n    new_vgg16.fit(image_train, label_train, \\\n                    validation_data=(image_validate, label_validate), \\\n                    epochs=20, callbacks=[early_stopping_monitor], batch_size=batch_size, verbose = 0)\n","2dcf8466":"test_loss, test_score = new_vgg16.evaluate(image_test, label_test, batch_size=16)\nprint(\"Loss on test set: \", test_loss)\nprint(\"Accuracy on test set: \", test_score)","0045d428":"# Get predictions\npreds = new_vgg16.predict(image_test, batch_size=16)\npreds = np.argmax(preds, axis=-1)\n\n# Original labels\norig_test_labels = np.argmax(label_test, axis=-1)\n\nprint(orig_test_labels.shape)\nprint(preds.shape)","04456c49":"# Get the confusion matrix\ncm  = confusion_matrix(orig_test_labels, preds)\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\nplt.xticks(range(3), ['Normal', 'Bacterial', 'Viral'], fontsize=16)\nplt.yticks(range(3), ['Normal', 'Bacterial', 'Viral'], fontsize=16)\nplt.show()","fec210fa":"nn, nb, nv, bn, bb, bv, vn, vb, vv = cm.ravel()\nnormal_precision = nn\/(nn+bn+vn)\nnormal_recall = nn\/(nn+nb+nv)\nbacterial_precision = bb\/(nb+bb+vb)\nbacterial_recall = nn\/(bn+bb+bv)\nviral_precision = nn\/(nv+bv+vv)\nviral_recall = nn\/(vn+vb+vv)\nprint(\"Recall of the model when dealing with heathly lungs is {:.2f}\".format(normal_recall))\nprint(\"Precision of the model when dealing with heathly lungs is {:.2f}\".format(normal_precision))\nprint(\"Recall of the model when dealing with bacterial pneumonia is {:.2f}\".format(bacterial_recall))\nprint(\"Precision of the model when dealing with bacterial pneumonia is {:.2f}\".format(bacterial_precision))\nprint(\"Recall of the model when dealing with viral pneumonia is {:.2f}\".format(viral_recall))\nprint(\"Precision of the model when dealing with viral pneumonia is {:.2f}\".format(viral_precision))","76a48cb5":"This pits our algorithim against the test data. You should hopefully get an accuracy of around 85% and a loss of around .7.","62582b18":"**Model Time**\n\nAs stated earlier, we will be using transfer learning. For a quick recap of what transfer learing is, we basically take a pre-trained model and repurpose it to do our task. Said model would have already aquired a wealth of information, which would make it better than an entirely new model. It's like how teaching a adult to do something is usually easier than teaching a baby to do the same thing. More info: https:\/\/machinelearningmastery.com\/transfer-learning-for-deep-learning\/\n\nIn this case, we will be using \"vgg16\", a model that has been trained to do image classification. More info: https:\/\/neurohive.io\/en\/popular-networks\/vgg16\/\n\nIn order to do this, I imported the model and replaced the output layer with on of my own (3 classes instead of the original 1k). You can uncomment the last line to output the structure of the model but I was afraid of memory issues.","c157c995":"Up until now, the data has just been the path to the image instead of the image itself. This code actually gets us the image itself and loads the images and labels into seperate arrays. vgg16 takes colored images that have the dimensions of (224, 224, 3) with the numbers representing each pixel ranging from 0 to 1. This code takes care of that by resizing the images, turning grayscale images(they only have 1 layer so we need to convert them) into colored ones (which have 3 layers), and setting all images to the same color so color won't be a confounding variable.","d8c27ec4":"Here we will initialize the lists that we will store our data in.","50241a3b":"This is where I train the model. A batch size of 16 means the model only updates its weights every 16 images. This helps prevent overfitting which is bad: https:\/\/elitedatascience.com\/overfitting-in-machine-learning\n\nEpochs are the number of times the model goes through the data and the validation data is there to test the effectiveness of the model. You can also see here that I set verbose to 0. It is 1 by defult and prints out progress bars and metrics for each iteration of the model. I silenced it because it caused memory issues.","cbbaf7c9":"You should probably google this. It's a lot of math that I don't have the space to explain.\n\nloss: https:\/\/gombru.github.io\/2018\/05\/23\/cross_entropy_loss\/\n\noptimizer: https:\/\/algorithmia.com\/blog\/introduction-to-optimizers\n\nmetrics: https:\/\/towardsdatascience.com\/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234\n\nIf you want my TLDR explanation of this: \n\nLoss is basically error. You want this as low as possible. You use categorical crossentropy to calculate it when dealing with multiple labels and binary crossentropy for only 2. \n\nAn optimizer is kind of like the pilot. It decides when to change the weights, by how much, etc. Diffrent optimizers will be suited for diffrent tasks. We will be using Adam.\n\nMetrics are what you measure your model by. This is usually accuracy but might change depending on your task.","dccca0a7":"This is a work in progress. In order to use it I need to convert all the .png images into .jpeg (or maybe I don't? Please comment if you know). These images are higher quality than the last dataset, but maybe introducing some poorer images into the dataset isn't a bad idea.","15660a93":"Load data from the last dataset. It only has viral pneumonia because that was the only data we were lacking enough of.","16fac064":"That's about it from me. Thanks for sticking to the end and I hope you enjoyed or found my first notebook helpful. Have a great day :)","3844b58e":"**Future Steps**\n\nI have a couple ideas for future steps. The most obvious of which is to fiddle with the optimizer (including learning rates and decay) to see what would give us the best results. I could also try using vgg19 which is basically vgg16 but with more layers. There is also what I mentioned while loading in the data about figuring out how to use the dataset with .png. Maybe the poorer images is what caused a drop in the precision and recall for viral pneumonia compared to bacterial pneumonia. The last one I can think of is using image augmentation like NAIN, but since my data is balanced, all that would do is allow the model to work on X-rays of diffrent angles, though I doubt that would be needed for any of it's possible applications. It's not like any doctors would take an X-ray upsidown or at some random angle. \n\nI likely won't be able to get to these steps for a while, since I have to focus on college apps, but I'll be excited to see what you guys come up with, assuming anyone sees this notebook.","7d72c347":"Combine all data into one list. You might think this is redundent and we should have just loaded them into one list in the first place. You would be correct. However, loading them into seperate lists would have allowed us to trim off execess data if the data was imbalanced. For example, if we had far too many bacterial pneumonia cases we could just only use an amount that is equal to the other 2 cases.","3bddf183":"Load data from the second dataset. You will notice the code is diffrent. This is due to the fact that each dataset is formated diffrently so we have to navigate through diffrent folders.","2f5b4e18":"This will allow use to see some of the images with their respective labels. Here you might notice that sometimes it is nearly impossible to tell the difference between a healthy lung and a pneumonia striken one, not to mention the difference between the types of pneumonia.","1c9aee70":"Unfortunately, when I tried to train the AI, the notebook ran out of memory. Therefore, I am forced to only use half the data. The circumstances might be different for you though, so good luck. This is also why I kept deleteing every variable I wasn't using again.","1db65aae":"You must use your GPU or else training will take a year. In order to do that, at the top right of your notebook, you will see bars that show your HDD, CPU, and RAM usage. To the right of that you will see 3 vertical darts. Click on that, click on \"Accelerator\", and select \"GPU\". Then run the code below. It will error if it can't find your GPU. If so, good luck.","42810985":"The code below will get the directories to the data. The data we will be using consists of .jpeg images of chest X-rays taken from the front.","0e33073a":"Here we finally split the data into training, validation, and test.","ea3d505f":"Some data visualization.","39726b8c":"However, 84% accuracy is kind of low for something that used transfer learing for a relatively basic task. The next two blocks will allow us to see the predictions that were made.","c425948d":"This checks the numbers of each label.","4ed14d83":"As some of you might have suspected, it turns out that bacterial pneumonia and viral pneumonia are relatively similar, even to an AI. However, our predictions on which lungs were healthy were phenominal.\n\nBelow is some more data analysis. Here is an explaination on recall and precision: https:\/\/developers.google.com\/machine-learning\/crash-course\/classification\/precision-and-recall","a5d02fb7":"Convert to dataframe and shuffle.","5a11b3f9":"**Intro**\n\nHello everyone. This notebook goes through how to train an AI to differentiate between healthy lungs, bacterial pneumonia, and viral pneumonia using transfer learning with vgg16, a neural network which was trained on millions of images and excels at classification. As you might have already guessed if you saw the date of this notebook, my selection of this topic was largely influced by the ongoing pandemic at the time I'm writing this. The original plan was to train one to diagnose Covid19, but due to the lack of data, I decided to use viral pneumonia instead, seeing that Covid19 is a virus that causes pneumonia. Even without the context of this pandemic AI will become essential in the medical field, as some diseases that are almost impossible to distinguish with the naked eye can be rather easily diagonsed with a well trained AI. Therefore, every step of progress we make, no matter how small, could lead to a huge diffrence in lives saved. However, my personal reason for creating this notebook was to learn and hopefully teach others what I gained from creating this.\n\nFor some context, you likely will need to have some basic knowledge about AI in order to follow along. I'm not a teacher or any sort of professional that is qualified to teach you that stuff, so google it or go take a class online if you don't understand the context. In fact, I'm just a highschooler that took one class about AI over the summer and decided to try my hand at it. That being said, I would credit NAIN and his notebook (https:\/\/www.kaggle.com\/aakashnain\/beating-everything-with-depthwise-convolution). Due to my lack of experience, I used this as a basis for my notebook. The main difference is that he is distinguishing between health and pneumonia striken lungs while mine also deals with bacterial vs viral pneumonia. He did a great job with his notebook so you should go check him out later.","2272c856":"Load data in from the first dataset. As of now, we are not sperating the data into training, test, and validation, but into different lists based on the diagnosis. We will also be assigning a number to each label: 0 for health, 1 for bacterial pneumonia, and 2 for viral pneumonia.","19068fbe":"This code will basically stop the training if the model starts getting worse. That never happened, but the important part is \"restore_best_weights=True\". This means that it will return us the best version of the model, as graded by validation accuracy."}}