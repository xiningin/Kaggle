{"cell_type":{"1451e353":"code","01efc8b2":"code","91c4bcbb":"code","f37a871e":"code","c1fb3b08":"code","93df26a3":"code","f2178fde":"code","595d402f":"code","5bfd3529":"code","340054ec":"code","3b8f256c":"code","e1984673":"code","424946fd":"code","310e1b02":"code","c61757df":"code","743d07cc":"code","e81ae169":"code","db46b58c":"code","7801e249":"code","2a7ea45f":"code","b3ef3577":"code","05007e60":"code","ef613f74":"code","dcb960f9":"code","6d2594ec":"code","213e71db":"code","2d729c34":"code","d5404566":"code","b68d8b77":"code","7c68ed33":"code","6a1c91ea":"code","7725b668":"code","749b7140":"code","3c31155b":"code","d9adfd97":"code","03235792":"code","6203abeb":"code","9125870f":"code","2f043153":"code","ddd3a3b1":"code","b4cc2684":"code","a7b0909e":"code","0aa6d2c9":"code","5bba2a34":"code","d5a59a91":"markdown","5ea88fd1":"markdown","cfec2673":"markdown","ae3eea23":"markdown","fe7551ea":"markdown","3ca545e1":"markdown","3a998b6a":"markdown","22171c34":"markdown"},"source":{"1451e353":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules\nfrom sklearn.cluster import KMeans\nimport seaborn as sns; sns.set(style=\"ticks\", color_codes=True, font_scale=2, rc={'figure.figsize':(15,9)})\nimport networkx as nx\n\nfrom sklearn.cluster import KMeans\nimport random\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","01efc8b2":"heroes_info = pd.read_csv('..\/input\/heroes_information.csv')\nheroes_info = heroes_info.drop(columns=heroes_info.columns[0])\npowers = pd.read_csv('..\/input\/super_hero_powers.csv')","91c4bcbb":"heroes_info.replace('-', np.nan).info()","f37a871e":"powers.replace('-', np.nan).info()","c1fb3b08":"heroes_info = heroes_info.dropna()","93df26a3":"heroes_info['Hair color'] = heroes_info['Hair color'].str.title()\nheroes_info['Skin color'] = heroes_info['Skin color'].str.title()\nheroes_info['Eye color'] = heroes_info['Eye color'].str.title()\nheroes_info['Race'] = heroes_info['Race'].str.title()\nheroes_info['Alignment'] = heroes_info['Alignment'].str.title()","f2178fde":"heroes_info['Race'].sort_values().unique()","595d402f":"table = heroes_info['Race'].str.extract('(?P<Race>\\w+)(.{1}[\\-\\\/].{1}(?P<Race2>\\w+))?', expand=True)[['Race', 'Race2']]\ntable['Race'] = table['Race'].fillna('no_race')\ntable['Race2'] = table['Race2'].fillna('no_race')\nrace_df = pd.concat([pd.get_dummies(table['Race']), pd.get_dummies(table['Race2']) ], axis=1).drop(columns='no_race')\nheroes_info = heroes_info.drop(columns='Race')\nheroes_info = pd.concat([heroes_info, race_df], axis=1)","5bfd3529":"heroes_info","340054ec":"heroes_info.loc[heroes_info['Gender'] != '-']['Gender'].value_counts().plot(kind='bar')\nplt.title('Super heroes gender distribution')\nplt.xticks(rotation=45)","3b8f256c":"heroes_info.loc[:, 'Alien':'Radiation'].sum().sort_values(ascending=False).head(20)","e1984673":"heroes_info.loc[:, 'Alien':'Radiation'].sum().sort_values(ascending=False).head(10).plot(kind='bar')\nplt.title('Super heroes race distribution')\nplt.xticks(rotation=45, ha='right')","424946fd":"sns.jointplot(x='Weight',y='Height',data=heroes_info,kind='kde',size=12)\n# plt.title('Super heroes Height x Weight distribution')","310e1b02":"heroes_info.loc[heroes_info['Eye color'] != '-']['Eye color'].value_counts().head(10).plot(kind='bar')\nplt.title('Super heroes Eye Color distribution')\nplt.xticks(rotation=45, ha='right')","c61757df":"heroes_info['Publisher'].value_counts().head(10).plot(kind='bar')\nplt.title('Super heroes Publishers distribution')\nplt.xticks(rotation=45, ha='right')","743d07cc":"data = heroes_info.loc[heroes_info['Alignment'] != '-']\ndata['Alignment'].value_counts().plot(kind='bar')\nplt.title('Super heroes Alignment distribution')\nplt.xticks(rotation=45)","e81ae169":"temp_series = heroes_info['Publisher'].value_counts().head(10)\nlabels = (np.array(temp_series.index))\nsizes = (np.array((temp_series \/ temp_series.sum())*100))\n\ntemp_series.plot(kind='pie')\nplt.title('Top 10 publishers with most heroes')","db46b58c":"data = heroes_info.loc[heroes_info['Gender'] != '-']\ndata.groupby(['Publisher', 'Gender'])['Gender'].count().unstack('Gender').sort_values(by=['Male', 'Female'], ascending=False).head(10).plot(kind='bar', stacked=True)\nplt.title('Super heroes Gender by Publisher')\nplt.xticks(rotation=45, ha='right')","7801e249":"data = heroes_info.loc[heroes_info['Gender'] != '-']\npercentual_data = data.groupby(['Publisher', 'Gender'])['Gender'].count() \/ data.groupby(['Publisher'])['Gender'].count()\npercentual_data.unstack('Gender').sort_values(by=['Female', 'Male'], ascending=False).head(13).plot(kind='bar', stacked=True)\nplt.title('Super heroes Gender percentual by Publisher')\nplt.xticks(rotation=45, ha='right')","2a7ea45f":"data = heroes_info.loc[(heroes_info['Gender'] != '-') & (heroes_info['Alignment'] != '-')]\npercentual_data = data.groupby(['Alignment', 'Gender'])['Alignment'].count() \/ data.groupby(['Gender'])['Alignment'].count()\npercentual_data.unstack('Alignment').plot(kind='bar', stacked=True)\nplt.title('Super heroes Gender percentual by Alignment')\nplt.xticks(rotation=45, ha='right')","b3ef3577":"data = heroes_info.loc[(heroes_info['Hair color'] != '-') & (heroes_info['Alignment'] != '-')]\ndata = data.groupby(['Alignment', 'Hair color'])['Alignment'].count()\ndata.unstack('Alignment').sort_values(by=['Good', 'Bad', 'Neutral'], ascending=False).head(12).plot(kind='bar')\nplt.title('Super heroes Hair Color by Alignment')\nplt.xticks(rotation=45, ha='right')","05007e60":"def function(group):\n    return group.loc[:, 'Alien':'Radiation'].sum()\n    \ndata = heroes_info.loc[heroes_info['Alignment'] != '-']\ndata = data.groupby('Alignment').apply(lambda group: function(group))\ndata.columns.name = 'Race'\n#data_sort = data[\"Bad\"] \/ data.sum(axis=0)\ndata_sort = data.loc[\"Bad\"].divide(data.loc[\"Good\"] + data.loc[\"Neutral\"], fill_value=0).fillna(0).replace(np.inf, 0)\ndata = data.T\ndata['sort'] = data_sort\ndata.sort_values(by=['sort'], ascending=False).drop(columns='sort').head(15).plot(kind='bar')\nplt.title('Super heroes Race by Alignment - sorted by higher Bad')\nplt.xticks(rotation=45, ha='right')","ef613f74":"powers","dcb960f9":"df_total_power = pd.concat([powers['hero_names'], pd.Series(powers.sum(axis=1), name='power')], axis=1)\ndf_total_power = df_total_power.sort_values('power', ascending=False)\ndf_total_power = df_total_power.merge(heroes_info, left_on='hero_names', right_on='name', how='inner').drop(columns='hero_names').set_index(['name', 'Publisher'])\ndf_total_power","6d2594ec":"df_total_power['power'].head(20).plot(kind='bar', figsize=(22,9))\nplt.title('Most powerfull Superheroes')\nplt.xticks(rotation=45, ha='right')","213e71db":"df_total_power.loc[df_total_power['Gender'] == 'Female']['power'].head(20).plot(kind='bar', figsize=(22,9))\nplt.title('Most powerfull Female Superheroes')\nplt.xticks(rotation=45, ha='right')","2d729c34":"df_total_power.loc[df_total_power['Gender'] == 'Male']['power'].head(20).plot(kind='bar', figsize=(22,9))\nplt.title('Most powerfull Male Superheroes')\nplt.xticks(rotation=45, ha='right')","d5404566":"df_total_power.groupby('Publisher')['power'].sum().sort_values(ascending=False).head(8).plot(kind='bar')\nplt.title('Combined Superheroes powers for each Publisher')\nplt.xticks(rotation=45, ha='right')","b68d8b77":"data = df_total_power.loc[df_total_power['Gender'] != '-']\n\nfig, ax1 = plt.subplots()\ntotal = data.groupby('Gender')['power'].sum()\ntotal.plot(kind='bar', ax=ax1)\nax1.set_ylabel('Total power')\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\npercentual = data.groupby('Gender')['power'].mean()\npercentual.plot(kind='line', color='black', ax=ax2)\nax2.grid(False)\nax2.set_ylabel('Mean power')\nfig.tight_layout()  # otherwise the right y-label is slightly clipped\nplt.title('Combined and mean power for each Gender Superheroes')\nplt.xticks(rotation=45, ha='right')","7c68ed33":"heroes_info","6a1c91ea":"s_info = heroes_info[['Gender', 'Eye color', 'Hair color', 'Publisher', 'Alignment']]\ns_array = s_info.values.tolist()\ns_array","7725b668":"oht = TransactionEncoder()\noht_ary = oht.fit(s_array).transform(s_array)\ndf = pd.DataFrame(oht_ary, columns=oht.columns_, index=s_info.index)\ndf = pd.concat([df, race_df == 1], axis=1)\ndf","749b7140":"frequent_itemsets = apriori(df, min_support=0.2, use_colnames=True)\nfrequent_itemsets.sort_values(by=['support'], ascending=False)","3c31155b":"rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.6)\n#association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\nrules = rules.loc[~rules['antecedents'].astype(str).str.contains('-')]\nrules = rules.loc[~rules['consequents'].astype(str).str.contains('-')]\nrules = rules.reset_index(drop=True)\nrules","d9adfd97":"G=nx.from_pandas_edgelist(rules, 'antecedents', 'consequents', edge_attr=['antecedents', 'consequents'] )\nplt.figure(1,figsize=(20,15))\nplt.margins(0.2)\nnx.draw(G, with_labels=True,node_size=1500, node_color=\"skyblue\", node_shape=\"o\", alpha=0.8, linewidths=6, font_size=23, font_color=\"black\", font_weight=\"bold\", width=1, edge_color=\"grey\")","03235792":"hero_power = powers.merge(heroes_info[['name', 'Alignment']], left_on='hero_names', right_on='name', how='inner').drop(columns=['hero_names'])\nhero_power","6203abeb":"hero_power = hero_power.loc[hero_power['Alignment'] != '-']\nhero_names = hero_power['name']\nhero_power = hero_power.drop(columns='name')\nhero_power = pd.get_dummies(hero_power, columns=['Alignment'], prefix='', prefix_sep='')\nhero_power = hero_power == 1\nhero_power","9125870f":"frequent_itemsets = apriori(hero_power, min_support=0.25, use_colnames=True)\nfrequent_itemsets.sort_values(by=['support'], ascending=False)","2f043153":"rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n#rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.4)\nrules = rules.loc[~rules['antecedents'].astype(str).str.contains('-')]\nrules = rules.loc[~rules['consequents'].astype(str).str.contains('-')]\nrules = rules.reset_index(drop=True)\nrules","ddd3a3b1":"G=nx.from_pandas_edgelist(rules, 'antecedents', 'consequents', edge_attr=['antecedents', 'consequents'] )\nplt.figure(1,figsize=(40,20))\nplt.margins(0.4)\nnx.draw(G, with_labels=True,node_size=1500, node_color=\"skyblue\", node_shape=\"o\", alpha=0.8, linewidths=6, font_size=23, font_color=\"black\", font_weight=\"bold\", width=1, edge_color=\"grey\")","b4cc2684":"number_clusters = range(1, 10)\nsum_of_squared_distances = []\ndf = hero_power\nfor k in number_clusters:\n    kmeans = KMeans(n_clusters=k).fit(df)\n    sum_of_squared_distances.append(kmeans.inertia_)","a7b0909e":"sns.set(font_scale=2)\nplt.figure(1,figsize=(15,9))\nplt.plot(number_clusters, sum_of_squared_distances, 'bx-')\nplt.xlabel('number of clusters')\nplt.ylabel('score')\nplt.title('Elbow Method For Optimal k')","0aa6d2c9":"kmeans = KMeans(n_clusters=6).fit(df)\nhero_power['cluster'] = kmeans.labels_\nhero_power['name'] = hero_names\nhero_clusters = hero_power[['name', 'cluster']].sort_values(by=['cluster'])","5bba2a34":"hero_clusters.to_csv('output.csv', index=False)","d5a59a91":"# Fix some columns","5ea88fd1":"# Clustering","cfec2673":"## By Alignment","ae3eea23":"# Associative in infos","fe7551ea":"# Associative in powers","3ca545e1":"## By Publisher","3a998b6a":"# Power analysis","22171c34":"# Analysis super heroes characteristics"}}