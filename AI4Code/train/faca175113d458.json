{"cell_type":{"e09b2938":"code","5cbc2ef8":"code","a8f4c338":"code","7b057e41":"code","af881170":"code","00159c4d":"code","d26ffc3b":"code","dbc7d113":"code","a9986670":"code","6001b331":"code","08b3136b":"code","763f4308":"code","adaa13ee":"code","60380bca":"code","c0309ec4":"code","db8aea86":"code","f0ad5dfe":"code","4f7c32eb":"code","514d924f":"code","a4231aae":"code","db7bb326":"code","8e4d663d":"code","cf1e0e41":"code","368aae07":"code","ce17b726":"markdown","6d4a7584":"markdown"},"source":{"e09b2938":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os, cv2, random, time, shutil, csv\nimport tensorflow as tf\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom tqdm import tqdm\nnp.random.seed(42)\n%matplotlib inline \n\nimport keras\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras.layers import BatchNormalization, Dense, GlobalAveragePooling2D, Lambda, Dropout, InputLayer, Input\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","5cbc2ef8":"#\u83b7\u53d6\u7167\u7247\u603b\u6570\ndef get_num_files(path):\n    '''\n    Counts the number of files in a folder.\n    '''\n    if not os.path.exists(path):\n        return 0\n    return sum([len(files) for r, d, files in os.walk(path)])","a8f4c338":"#Data Paths\ntrain_dir = '.\/data\/train'\ntest_dir = '.\/data\/test_dogs'\n#Count\/Print train and test samples.\ndata_size = get_num_files(train_dir)\ntest_size = get_num_files(test_dir)\nprint('Data samples size: ', data_size)\nprint('Test samples size: ', test_size)","7b057e41":"#\u83b7\u53d6\u7167\u7247\ndef dir_to_gen(data_dir = '.\/data\/train',img_size = (331,331,3),shuffle=True):\n    batch_size = 16\n    datagen = ImageDataGenerator()\n    generator = datagen.flow_from_directory(\n        data_dir,\n        target_size=(img_size[0],img_size[1]),\n        batch_size=batch_size,\n        class_mode=None,\n        shuffle=shuffle)\n    \n    return generator\n\ntrain_generator=dir_to_gen(data_dir = train_dir)","af881170":"#\u6807\u7b7e\u548c\u53d8\u6362\nclass_idx=train_generator.class_indices\nidx_class={class_idx[x]:x for x in class_idx.keys()}","00159c4d":"#\u770b\u4e00\u773c\nprint(train_generator.filepaths[:3])\nprint(train_generator.filenames[:3])\nprint(train_generator.labels[200:210])","d26ffc3b":"#\u56fe\u50cf\u8f6c\u6362\u6210numpy\u6570\u7ec4\uff0c\u5e76\u8c03\u6574\u5927\u5c0f\n#X\u4e3a16580*331*331*3\n#\u6807\u7b7e\u72ec\u70ed\u7f16\u780116580*120\ndef images_to_array(generator,img_size = (331,331,3)):\n    '''\n    1- Read image samples from certain directory.\n    2- Risize it, then stack them into one big numpy array.\n    3- Read sample's label form the labels dataframe.\n    4- One hot encode labels array.\n    5- Shuffle Data and label arrays.\n    '''\n    images_path = generator.filepaths\n    images_labels = generator.labels\n\n    data_size = len(images_labels)\n    #initailize output arrays.\n    X = np.zeros([data_size, img_size[0], img_size[1], img_size[2]], dtype=np.uint8)\n    y = np.zeros([data_size,1], dtype=np.uint8)\n    #read data and lables.\n    for i in tqdm(range(data_size)):\n        img_dir = images_path[i]\n        img_pixels = load_img(img_dir, target_size=img_size)\n        X[i] = img_pixels       \n        y[i] = images_labels[i]\n    \n    #One hot encoder\n    y = to_categorical(y)\n    #shuffle    \n    ind = np.random.permutation(data_size)\n    X = X[ind]\n    y = y[ind]\n    print('Ouptut Data Size: ', X.shape)\n    print('Ouptut Label Size: ', y.shape)\n    return X, y","dbc7d113":"\nimg_size = (331,331,3)\nX, y = images_to_array(train_generator,img_size = (331,331,3))\n\n\n","a9986670":"#\u4e0b\u8fb9\u7528\u4e86\u56db\u4e2a\u4e0d\u540c\u7684\u6a21\u578b\u83b7\u53d6\u7279\u5f81\uff0c\u7136\u540e\u62fc\u63a5\u8d77\u6765\u8bad\u7ec3\u4e00\u4e2a\u5c0f\u7684\u5168\u8fde\u63a5wangluo\ndef get_features(model_name, data_preprocessor, input_size, data):\n    '''\n    1- Create a feature extractor to extract features from the data.\n    2- Returns the extracted features and the feature extractor.\n    '''\n    #Prepare pipeline.\n    input_layer = Input(input_size)\n    preprocessor = Lambda(data_preprocessor)(input_layer)\n    base_model = model_name(weights='imagenet', include_top=False,\n                            input_shape=input_size)(preprocessor)\n    avg = GlobalAveragePooling2D()(base_model)\n    feature_extractor = Model(inputs = input_layer, outputs = avg)\n    #Extract feature.\n    feature_maps = feature_extractor.predict(data, batch_size=64, verbose=1)\n    print('Feature maps shape: ', feature_maps.shape)\n    return feature_maps","6001b331":"# Extract features using InceptionV3 as extractor.\nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\ninception_preprocessor = preprocess_input\ninception_features = get_features(InceptionV3,\n                                  inception_preprocessor,\n                                  img_size, X)","08b3136b":"# Extract features using Xception as extractor.\nfrom keras.applications.xception import Xception, preprocess_input\nxception_preprocessor = preprocess_input\nxception_features = get_features(Xception,\n                                 xception_preprocessor,\n                                 img_size, X)","763f4308":"# Extract features using NASNetLarge as extractor.\nfrom keras.applications.nasnet import NASNetLarge, preprocess_input\nnasnet_preprocessor = preprocess_input\nnasnet_features = get_features(NASNetLarge,\n                               nasnet_preprocessor,\n                               img_size, X)","adaa13ee":"# Extract features using InceptionResNetV2 as extractor.\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\ninc_resnet_preprocessor = preprocess_input\ninc_resnet_features = get_features(InceptionResNetV2,\n                                   inc_resnet_preprocessor,\n                                   img_size, X)","60380bca":"#s\u5220\u9664X\u91ca\u653e\u5185\u5b58\ndel X","c0309ec4":"#\u62fc\u63a5\u7279\u5f81\nfinal_features = np.concatenate([inception_features,\n                                 xception_features,\n                                 nasnet_features,\n                                 inc_resnet_features,], axis=-1)\nprint('Final feature maps shape', final_features.shape)","db8aea86":"from keras.callbacks import EarlyStopping\n#Prepare call backs\nEarlyStop_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nmy_callback=[EarlyStop_callback]","f0ad5dfe":"#Prepare DNN model\ndnn = keras.models.Sequential([\n    InputLayer(final_features.shape[1:]),\n    Dropout(0.7),\n    Dense(n_classes, activation='softmax')\n])\n\ndnn.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n#Train simple DNN on extracted features.\nh = dnn.fit(final_features, y,\n            batch_size=128,\n            epochs=60,\n            validation_split=0.1,\n            callbacks=my_callback)","4f7c32eb":"test_generator=dir_to_gen(data_dir =test_dir,shuffle=False)","514d924f":"print(test_generator.filenames[:10])","a4231aae":"\ndef images_to_array2(generator,img_size = (224,224,3)):\n    '''\n    Do same as images_to_array but omit some unnecessary steps for test data.\n    '''\n    images_path = generator.filepaths\n    data_size = len(images_path)\n    X = np.zeros([data_size, img_size[0], img_size[1], 3], dtype=np.uint8)\n    \n    for i in tqdm(range(data_size)):\n        img_dir = images_path[i]\n        img_pixels = tf.keras.preprocessing.image.load_img(img_dir, target_size=img_size)\n        X[i] = img_pixels\n        \n    print('Ouptut Data Size: ', X.shape)\n    return X\n\ntest_data = images_to_array2(test_generator,img_size)","db7bb326":"#Extract test data features.\ninception_features = get_features(InceptionV3, inception_preprocessor, img_size, test_data)\nxception_features = get_features(Xception, xception_preprocessor, img_size, test_data)\nnasnet_features = get_features(NASNetLarge, nasnet_preprocessor, img_size, test_data)\ninc_resnet_features = get_features(InceptionResNetV2, inc_resnet_preprocessor, img_size, test_data)\n\ntest_features = np.concatenate([inception_features,\n                                 xception_features,\n                                 nasnet_features,\n                                 inc_resnet_features],axis=-1)\nprint('Final feature maps shape', test_features.shape)","8e4d663d":"#Free up some space.\ndel test_data","cf1e0e41":"#Predict test labels given test data features.\ny_pred = dnn.predict(test_features, batch_size=128)","368aae07":"# y=model.predict(test_generator, verbose=True)\ny_cls=np.argmax(y_pred,1)\n# y_cls=np.argmax(y)\nfilenames=test_generator.filenames\nresult={'Id':[],'Category':[]}\nfor file, cls_id in zip(filenames, y_cls):\n    name=file.split('\/')[1]\n    name=name.split('.')[0]\n    category=idx_class[cls_id]\n    result['Id'].append(name)\n    result['Category'].append(category)\n    \nresult_dataframe=pd.DataFrame(result)\nresult_dataframe.to_csv('.\/imnet\/loss018.csv',index=False)","ce17b726":"# \u672c\u4ee3\u7801\u53c2\u8003kaggle\u7f51\u7ad9loss018\u65b9\u6848","6d4a7584":"# \u540c\u6837\uff0c\u4e0b\u9762\u6d4b\u8bd5\u56fe\u7247\u4e5f\u7528\u8fd9\u56db\u4e2a\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\u4e4b\u540e\u653e\u5165\u8bad\u7ec3\u597d\u7684\u7f51\u7edc\u6d4b\u8bd5"}}