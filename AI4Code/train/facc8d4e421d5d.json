{"cell_type":{"088d6422":"code","d2afca71":"code","ba8a3d79":"code","cfccb268":"code","1a2fd0f5":"code","0652bb3f":"code","27a2dc01":"code","b8934964":"code","9d53ae52":"code","43aee75f":"code","d50ec3d3":"code","b85b6609":"code","b8b30286":"code","1bd4768f":"code","9e451eea":"code","05b2b038":"code","7f16ef7b":"code","3560c149":"code","f6d2c3ed":"code","2ffc9037":"code","b8f5a23f":"code","67764a6a":"code","a0fa5baa":"code","a13a9d47":"code","3b7fe8dc":"code","f0e6422b":"code","17c8147e":"code","7e6c9ba3":"code","bc87a786":"code","17fd22fd":"code","cb75ca2f":"code","a4232a06":"code","44725d56":"code","00d7cd44":"code","d5644d66":"code","da2b06b6":"code","2b9c2134":"code","3a9d4fc6":"code","eac05943":"code","40a79a75":"code","2efa44a3":"code","e6748ec8":"code","75a95d09":"code","499a3451":"code","8a63ae3c":"code","6ff7783f":"code","bf72fd38":"code","7168058a":"code","96b69da3":"code","81f6f45b":"code","80f9bdeb":"code","564af72a":"markdown","09c815c8":"markdown","629b0090":"markdown","3ea12761":"markdown","fa070ddc":"markdown","61d0aacf":"markdown","ba9bb9eb":"markdown","7d207bdb":"markdown","6fe597c2":"markdown","e49f7a10":"markdown","57baca9d":"markdown","f4a9981d":"markdown","97c0b2aa":"markdown","a2ffde3a":"markdown","347a6572":"markdown","9bdfdd11":"markdown","064ffa45":"markdown"},"source":{"088d6422":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d2afca71":"# load libraries \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas_profiling\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import show\nimport plotly.express as px\n\n","ba8a3d79":"# combine and create single dataframe\nchicago_df_1 = pd.read_csv('\/kaggle\/input\/crimes-in-chicago\/Chicago_Crimes_2001_to_2004.csv', error_bad_lines=False)\nchicago_df_2 = pd.read_csv('\/kaggle\/input\/crimes-in-chicago\/Chicago_Crimes_2005_to_2007.csv', error_bad_lines=False)\nchicago_df_3 = pd.read_csv('\/kaggle\/input\/crimes-in-chicago\/Chicago_Crimes_2008_to_2011.csv', error_bad_lines=False)\nchicago_df_4 = pd.read_csv('\/kaggle\/input\/crimes-in-chicago\/Chicago_Crimes_2012_to_2017.csv', error_bad_lines=False)","cfccb268":"# combining the datasets\ndf = pd.concat([chicago_df_1,chicago_df_2,chicago_df_3,chicago_df_4],ignore_index=False,axis=0)","1a2fd0f5":"df.shape","0652bb3f":"# let's view the head of the training dataset\ndf.head()","27a2dc01":"# select only the necessary columns\ndf = df[['ID','Date','Primary Type','Location Description','Arrest','Domestic']]","b8934964":"df.head()","9d53ae52":"df.info()","43aee75f":"# change the column date dtype from object to date\ndf.Date = pd.to_datetime(df.Date, format='%m\/%d\/%Y %I:%M:%S %p')","d50ec3d3":"# setting the index to be the date \ndf.index = pd.DatetimeIndex(df.Date)","b85b6609":"# verify the change\ndf.head()","b8b30286":"# get the summary\nprint (\"Rows     : \" ,df.shape[0])\nprint (\"Columns  : \" ,df.shape[1])\nprint (\"\\nFeatures : \\n\\n\" ,df.columns.tolist())\nprint (\"\\nMissing values : \\n\\n\", df.isnull().any())\nprint (\"\\nUnique values :  \\n\\n\",df.nunique())","1bd4768f":"# Examine the null records of Location Description\ndf[df[\"Location Description\"].isnull()]\n","9e451eea":"# drop these records\ndf = df.dropna()\n# print the count of Null records in each column\ndf.isnull().sum()","05b2b038":"# set figure size\nplt.figure(figsize = (15, 10))\n\n# plot the records\nax=sns.countplot(x= 'Primary Type', data = df, order = df['Primary Type'].value_counts().iloc[:10].index, palette = 'RdBu_r')\n\n# set individual bar lables using above list\nfor i in ax.patches:\n    # get_x pulls left or right; get_height pushes up or down\n    ax.text(i.get_x(), i.get_height(),\n            str(i.get_height()), fontsize=15,\ncolor='dimgrey')\nshow()\n","7f16ef7b":"# set the figure size\nplt.figure(figsize = (15, 10))\n\n# plot the values\nax = sns.countplot(y= 'Location Description', data = df, order = df['Location Description'].value_counts().iloc[:15].index,palette = 'RdBu_r')\n\n# set individual bar lables using above list\nfor i in ax.patches:\n    # get_width pulls left or right; get_y pushes up or down\n    ax.text(i.get_width()+.3, i.get_y()+.5, \n            str(i.get_width()), fontsize=15,\ncolor='dimgrey')\nshow()\n","3560c149":"# Resample is a Convenience method for frequency conversion and resampling of time series.\n\n# resample into Years\n\nplt.plot(df.resample('Y').size())\nplt.title('Crimes Count Per Year')\nplt.xlabel('Years')\nplt.ylabel('Number of Crimes')","f6d2c3ed":"# resample into Months\n\nplt.plot(df.resample('M').size())\nplt.title('Crimes Count Per Month')\nplt.xlabel('Months')\nplt.ylabel('Number of Crimes')","2ffc9037":"# aggregating the number of cases per month for all years\nts_df = pd.DataFrame(df.resample('M').size().reset_index())\nts_df.columns = ['Date', 'Crime Count'] # renaming the columns","b8f5a23f":"ts_df.head()","67764a6a":"# plot interactive slider chart\nfig = px.line(ts_df, x='Date',y='Crime Count', title= 'Crime count')\n\nfig.update_xaxes(\nrangeslider_visible =True,\nrangeselector=dict(\n        buttons=list([\n                dict(count=1,label=\"1y\",step=\"year\",stepmode=\"backward\"),\n                dict(count=2,label=\"3y\",step=\"year\",stepmode=\"backward\"),\n                dict(count=3,label=\"5y\",step=\"year\",stepmode=\"backward\"),\n                dict(step=\"all\")\n                    ])\n                )\n                )\nfig.show()","a0fa5baa":"ts_df = ts_df.set_index('Date')","a13a9d47":"# splitting into train and test set\ntrain = ts_df[:181]\ntest = ts_df[181:]\nprint(train.shape)\nprint(test.shape)","3b7fe8dc":"plt.plot(train)\nplt.plot(test)","f0e6422b":"from fbprophet import Prophet","17c8147e":"# creating the dataframe\nprophet_df = train.reset_index()\nprophet_df .head()","7e6c9ba3":"prophet_df = prophet_df.rename(columns= {'Date':'ds','Crime Count':'y'})\nprophet_df.head()","bc87a786":"m = Prophet()\nm.fit(prophet_df)\n","17fd22fd":"# Forcasting into the future\nfuture = m.make_future_dataframe(periods=12, freq='M')\nforecast = m.predict(future)","cb75ca2f":"forecast.head()","a4232a06":"figure = m.plot(forecast, xlabel='Date', ylabel='Crime Rate')","44725d56":"plot = m.plot_components(forecast)","00d7cd44":"forecast_df = pd.DataFrame(forecast)\nforecast_df.head()","d5644d66":"# preparing the dataframe with date and forecast\nforecast_df=forecast_df[['ds','yhat']]\nforecast_df=forecast_df.set_index('ds')\nforecast_df.head()","da2b06b6":"# plot the predictions\nplt.figure(figsize=(20,10))\nplt.plot(train, label ='Train')\nplt.plot(test, label='Test')\nplt.plot(forecast_df, label='Forecast')\nplt.xlabel('Year')\nplt.ylabel('Count')\nplt.title('Plotting Train vs Test vs Predicted Crime rate')\nplt.legend()\nplt.show()","2b9c2134":"test['Crime Count']","3a9d4fc6":"forecast_df['yhat'][181:]","eac05943":"# calculate error\ntest['fbprophet_error'] = test['Crime Count'] - forecast_df['yhat'][181:]\n\nrmse = np.sqrt(np.mean(test.fbprophet_error**2)).round(2)\nmape = np.round(np.mean(np.abs(100*(test.fbprophet_error\/test['Crime Count'])), 0))\n\nprint('RMSE = $', rmse)\nprint('MAPE =', mape, '%')","40a79a75":"!pip install pmdarima","2efa44a3":"import pmdarima as pm","e6748ec8":"from pandas.plotting import autocorrelation_plot\nautocorrelation_plot(train)","75a95d09":"from statsmodels.graphics.tsaplots import plot_pacf\nplot_pacf(train,lags=20)","499a3451":"model = pm.auto_arima(train,m=12,start_p=0,start_q=3, max_order=5, \n                      error_action='ignore',test='adf',seasonal=True,\n                      trace=True,stepwise=True)","8a63ae3c":"model.summary()","6ff7783f":"# create a dataframe with test date index\nprediction = pd.DataFrame(model.predict(n_periods=12),index = test.index,columns =['Predicted Crime Count'])","bf72fd38":"# print predictions\nprediction","7168058a":"test","96b69da3":"# plot the predictions\nplt.plot(train, label ='Train')\nplt.plot(test['Crime Count'], label='Test')\nplt.plot(prediction, label='Prediction')\nplt.xlabel('Year')\nplt.ylabel('Count')\nplt.title('Plotting Train vs Test vs Predicted Crime rate')\nplt.legend()\nplt.show()","81f6f45b":"# calculate error\ntest['arima_error'] = test['Crime Count'] - prediction['Predicted Crime Count']\n\nrmse = np.sqrt(np.mean(test.arima_error**2)).round(2)\nmape = np.round(np.mean(np.abs(100*(test.arima_error\/test['Crime Count'])), 0))\n\nprint('RMSE = $', rmse)\nprint('MAPE =', mape, '%')","80f9bdeb":"out = model.plot_diagnostics()","564af72a":"* Rename the columns as ds and y for the model","09c815c8":"Exploring the dataset","629b0090":"Load and combine the data","3ea12761":"Here, we are trying with the p, d, q values ranging from 0 to 5 to get better optimal values from the model. There are many other parameters in this model and to know more about the functionality, visit this link [[here]](https:\/\/alkaline-ml.com\/pmdarima\/modules\/generated\/pmdarima.arima.auto_arima.html)","fa070ddc":"![](https:\/\/miro.medium.com\/max\/1148\/1*64ZOjhR_jsZ9D-E51MKvBQ.png)\n* Auto-Regressive (p) -> Number of autoregressive terms.\n* Integrated (d) -> Number of nonseasonal differences needed for stationarity.\n* Moving Average (q) -> Number of lagged forecast errors in the prediction equation.","61d0aacf":"# Data Analysis & Visualization","ba9bb9eb":"Plot the top 10 primary types","7d207bdb":"# Build Auto Arima Model","6fe597c2":"Preparing the data for the model","e49f7a10":"# Build Fb prophet model","57baca9d":"ARIMA is an acronym for Auto Regressive (AR) Integrated (I) Moving Average (MA) which indicates that an ARIMA model has three components to it.","f4a9981d":"Plot the top 10 Location descriptions","97c0b2aa":"# **Hello! I Hope you are well, if you find this notebook helpful\u00a0please upvote and support my work.**","a2ffde3a":"Split into train and test datasets to build the model on the training dataset and forecast using the test dataset.","347a6572":"Prophet is open source software released by Facebook\u2019s Core Data Science team.\n\nProphet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects.\n\nProphet works best with time series that have strong seasonal effects and several seasons of historical data.\n\nFor more information, please check this out: https:\/\/research.fb.com\/prophet-forecasting-at-scale\/ https:\/\/facebook.github.io\/prophet\/docs\/quick_start.html#python-api","9bdfdd11":"# Time series\n\nA time series is simply a series of data points ordered in time. As continuous monitoring and data collection become more common, the need for competent time series analysis with both statistical and machine learning techniques will increase.\n\nNow, datasets where only one variable is observed at each time is called \u2018Univariate Time Series\u2019 and if two or more variables are observed at each time is called \u2018Multivariate Time Series\u2019.\n\nIn this notebook, we will focus on the univariate time series for forecasting the sales with Facebook Prophet and Auto ARIMA functionality in python","064ffa45":"The output above shows that the final model fitted was an ARIMA(0,1,3) estimator, where the values of the parameters p, d, and q were zero, one, and three, respectively. "}}