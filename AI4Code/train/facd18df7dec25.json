{"cell_type":{"17efa607":"code","ca0c08ea":"code","f351eab4":"code","24467722":"code","b5c49abf":"code","bf0b3fc9":"code","c31130e0":"code","957a46b4":"code","232cb62f":"code","eb93e2bc":"code","a0013809":"code","39462b1f":"code","27eef848":"code","bafe366a":"code","78117a5d":"code","716f5d62":"code","d3c87c39":"code","1c497e22":"code","c59c56bb":"code","c82b51c3":"code","a73412b0":"code","f13a7921":"code","2d806b58":"code","83925989":"code","619a1a27":"code","de8aada2":"code","11c2e07d":"code","4635b99d":"code","6c4cddff":"code","46d0eb85":"code","7ed6922c":"code","7a00a2e8":"code","cf293c78":"code","884acc7d":"code","536e4535":"code","1aea29b5":"code","f2cfba70":"code","4281621a":"code","e7390853":"code","c3097e11":"code","e319749d":"code","d2270587":"code","c257d6d8":"code","f6c4ef17":"code","a13338a6":"code","656871da":"code","f87bc157":"code","812bdc49":"code","54e6ee64":"code","c535356e":"code","6b9d92d5":"code","98e8ae0a":"code","2c80faa7":"code","d0579d95":"code","d04386d7":"code","87a294d1":"code","4d9bdaa7":"code","f1f6ef2e":"code","f5ace01c":"code","e7038df3":"code","a0fe5b9e":"code","58a90f84":"code","a91f585a":"code","8269fc3f":"code","61c5b963":"code","97b1cdd4":"code","06c32953":"code","045032ad":"code","f1ba8877":"code","88dcd9ae":"code","e3e2a410":"code","93542d39":"code","632753d9":"code","c9ea9f00":"markdown","18cd60d1":"markdown","346e2788":"markdown","5af3ee5c":"markdown","8af7bf0e":"markdown","996efe3f":"markdown","f495807f":"markdown","a34b901b":"markdown","65e89a79":"markdown"},"source":{"17efa607":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ca0c08ea":"import os\nimport os.path as osp\nimport sys\nfrom tqdm import tqdm_notebook as tqdm\nfrom IPython.display import display, clear_output","f351eab4":"%%time\npath = '\/kaggle\/input\/data-science-bowl-2019\/'\ntrain_df = pd.read_csv(osp.join(path, 'train.csv'))\ntest_df = pd.read_csv(osp.join(path, 'test.csv'))\ntrain_labels_df = pd.read_csv(osp.join(path, 'train_labels.csv'))\nspecs_df = pd.read_csv(osp.join(path, 'specs.csv'))\nsub_df = pd.read_csv(osp.join(path, 'sample_submission.csv'))","24467722":"def show_df_info(df):\n    display(df.head(2), df.columns, df.shape)","b5c49abf":"show_df_info(train_df)","bf0b3fc9":"show_df_info(train_labels_df)","c31130e0":"def get_shared_columns(df_1, df_2):\n    return [x for x in df_1.columns if x in df_1.columns and x in df_2.columns]\n    \nshares_column_names = get_shared_columns(train_labels_df, train_df)\ndisplay(shares_column_names)","957a46b4":"show_df_info(test_df)","232cb62f":"get_shared_columns(train_labels_df, test_df)","eb93e2bc":"get_shared_columns(train_df, test_df)","a0013809":"show_df_info(specs_df)","39462b1f":"display(get_shared_columns(specs_df, train_df),\n        get_shared_columns(specs_df, train_labels_df),\n        get_shared_columns(specs_df, test_df))","27eef848":"show_df_info(sub_df)","bafe366a":"accuracy_group = np.array(train_labels_df['accuracy_group'])\ndisplay(set(accuracy_group))","78117a5d":"%%time\ntrain = pd.merge(train_df, train_labels_df, on = ['game_session', 'installation_id', 'title'])\nshow_df_info(train)","716f5d62":"%%time\ntrain = pd.merge(train, specs_df, on = ['event_id'])\nshow_df_info(train)","d3c87c39":"%%time\ntest = pd.merge(test_df, sub_df, on=['installation_id'])\nshow_df_info(test)","1c497e22":"%%time\ntest = pd.merge(test, specs_df, on=['event_id'])\nshow_df_info(test)","c59c56bb":"columns = get_shared_columns(train, test)\nid_str = 'installation_id'\ntarget_str = 'accuracy_group'\nfeatures = [column for column in columns if column not in [id_str, target_str]]\n\ndisplay(columns, len(columns), features, len(features))","c82b51c3":"%%time\nfeatures_numbers = [len(set(train[feature])) for feature in features]\ndisplay(features, features_numbers)","a73412b0":" train[\"title\"].value_counts()","f13a7921":"train.info()","2d806b58":"train.describe()","83925989":"\nimport matplotlib.pyplot as plt \ntrain.hist(bins=50, figsize=(20,15)) \nplt.show()\n","619a1a27":"show_df_info(train)","de8aada2":"corr_matrix = train.corr() ","11c2e07d":" corr_matrix[\"accuracy_group\"].sort_values(ascending=False) ","4635b99d":"train_try=train","6c4cddff":"train_try[\"event_count*event_code\"] = train[\"event_count\"]*train[\"event_code\"]\n","46d0eb85":"corr_matrix = train_try.corr() ","7ed6922c":" corr_matrix[\"accuracy_group\"].sort_values(ascending=False) ","7a00a2e8":"train[\"event_count*event_code\"]=train_try[\"event_count*event_code\"]\n\n","cf293c78":"corr_matrix = train.corr() \ncorr_matrix[\"accuracy_group\"].sort_values(ascending=False) ","884acc7d":"train.head(2)","536e4535":"cat =[\"args\",\"info\",\"accuracy_group\",\"world\",\"type\",\"title\",\"installation_id\",\"event_data\",\"timestamp\",\"game_session\",\"event_id\"]","1aea29b5":"train_cat=train[cat]","f2cfba70":"train_args=train[\"args\"]\ntrain_info=train[\"info\"]\ntrain_accuracy_group=train[\"accuracy_group\"]\ntrain_world=train[\"world\"]\ntrain_title=train[\"title\"]\ntrain_installation_id=train[\"installation_id\"]\ntrain_event_data=train[\"event_data\"]\ntrain_timestamp=train[\"timestamp\"]\ntrain_game_session=train[\"game_session\"]\ntrain_event_id=train[\"event_id\"]\n","4281621a":"try:\n    from sklearn.preprocessing import OrdinalEncoder # just to raise an ImportError if Scikit-Learn < 0.20\n    from sklearn.preprocessing import OneHotEncoder\nexcept ImportError:\n    from future_encoders import OneHotEncoder # Scikit-Learn < 0.20\n","e7390853":"cat_encoder = OneHotEncoder()\ntrain_cat_1hot = cat_encoder.fit_transform(train_cat)\ntrain_cat_1hot","c3097e11":"\nfrom sklearn.preprocessing import LabelBinarizer\nencoder = LabelBinarizer() \nworld= encoder.fit_transform(train_world)\nencoder.classes_\nworld = pd.DataFrame(world, columns = ['CRYSTALCAVES', 'MAGMAPEAK', 'TREETOPCITY']) \n","e319749d":"world","d2270587":"\nfrom sklearn.preprocessing import LabelBinarizer\nencoder = LabelBinarizer() \nevent_id= encoder.fit_transform(train_event_id)\nevent_id","c257d6d8":"train_title=train[\"title\"]\nfrom sklearn.preprocessing import LabelBinarizer\nencoder = LabelBinarizer() \ntitle= encoder.fit_transform(train_title)\ntitle= pd.DataFrame(title, columns = (['Bird Measurer (Assessment)', 'Cart Balancer (Assessment)','Cauldron Filler (Assessment)', 'Chest Sorter (Assessment)','Mushroom Sorter (Assessment)']))\n                     \n","f6c4ef17":"title","a13338a6":"\nfrom sklearn.preprocessing import LabelBinarizer\nencoder = LabelBinarizer() \nargs= encoder.fit_transform(train_args)\n\nencoder.classes_","656871da":"from sklearn.preprocessing import LabelBinarizer\nencoder = LabelBinarizer() \ninfo= encoder.fit_transform(train_info)\nencoder.classes_\n\n\n\n","f87bc157":"encoder.classes_","812bdc49":"train_num=train_try[[\"event_count*event_code\",\"accuracy\",\"num_incorrect\",\"num_correct\"]]","54e6ee64":"train_try.head(2)","c535356e":"from sklearn.preprocessing import StandardScaler\n\ntrain_num[[\"event_count*event_code\",\"accuracy\",\"num_incorrect\",\"num_correct\"]]=StandardScaler().fit_transform(train_num[[\"event_count*event_code\",\"accuracy\",\"num_incorrect\",\"num_correct\"]])\n","6b9d92d5":"train_num","98e8ae0a":"title\n","2c80faa7":"Final_train=train_num","d0579d95":"\nFinal_train=train_num\nFinal_train[['CRYSTALCAVES', 'MAGMAPEAK', 'TREETOPCITY']]=world[['CRYSTALCAVES', 'MAGMAPEAK', 'TREETOPCITY']]","d04386d7":"Final_train","87a294d1":"Final_train[['Bird Measurer (Assessment)', 'Cart Balancer (Assessment)','Cauldron Filler (Assessment)', 'Chest Sorter (Assessment)','Mushroom Sorter (Assessment)']]=title[['Bird Measurer (Assessment)', 'Cart Balancer (Assessment)','Cauldron Filler (Assessment)', 'Chest Sorter (Assessment)','Mushroom Sorter (Assessment)']]","4d9bdaa7":"Final_training_set=Final_train\nFinal_train['accuracy_group']=train['accuracy_group']","f1f6ef2e":"label=train['accuracy_group']","f5ace01c":"corr_matrix = Final_train.corr() \n","e7038df3":"corr_matrix[\"accuracy_group\"].sort_values(ascending=False) ","a0fe5b9e":"del Final_train[\"TREETOPCITY\"]","58a90f84":"del Final_train[\"accuracy_group\"]\n","a91f585a":"Final_training_set=Final_train","8269fc3f":"from sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier(max_iter=5, tol=-np.infty, random_state=42)\nsgd_clf.fit(Final_training_set, label)\n\n","61c5b963":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix\n","97b1cdd4":"train          \n\n \n","06c32953":"del train[\"event_count*event_code\"]\ndel train[\"num_incorrect\"]\ndel train[\"type\"]\ndel train[\"event_code\"]\ndel train[\"installation_id\"]","045032ad":"del train[\"installation_id\"]","f1ba8877":"train","88dcd9ae":"\n\naccuracy_group_list =train\n\naccuracy_group_list","e3e2a410":"label","93542d39":"\nsub_df['accuracy_group'] = accuracy_group_list\nsub_df.head()","632753d9":"sub_df.to_csv('submission.csv', index=False)","c9ea9f00":"# 4 submission","18cd60d1":"# 3 Model","346e2788":"```python\nIndex(['event_id', 'game_session', 'timestamp', 'event_data',\n       'installation_id', 'event_count', 'event_code', 'game_time', 'title',\n       'type', 'world'],\n      dtype='object')\n```\n\n```python\nIndex(['game_session', 'installation_id', 'title', 'num_correct',\n       'num_incorrect', 'accuracy', 'accuracy_group'],\n      dtype='object')\n```","5af3ee5c":"There are no missing values","8af7bf0e":"**What is the classes?**\n","996efe3f":"**Almost columns are categorical feature, oh my god!**","f495807f":"# 2 Feature engineering","a34b901b":"# 1 EDA","65e89a79":"So, we have a problem with 4 classes\n\nNow, we join some table for getting the training dataset."}}