{"cell_type":{"e654f333":"code","c203023f":"code","828d08b1":"code","05f8e4ff":"code","2ee612ce":"code","3028b163":"code","00d0e8ba":"code","ed0b8777":"code","04636284":"code","204d4dea":"code","ddd0d260":"code","e40d5865":"code","8027a72d":"code","98ac6d0e":"code","981bca9d":"code","1a80788d":"code","69cd054e":"code","58c5c504":"code","806092fc":"code","08eed5b1":"code","38b4aec7":"code","13b972aa":"code","c21c9d00":"code","9f7fcc26":"code","93f7820a":"code","5da27656":"code","ae523353":"code","6737f4d8":"code","ff0d3bce":"code","be8749b7":"code","e20f4094":"code","a81ab6e7":"code","fda18058":"code","26ca7848":"code","5d4034f5":"code","3c65e159":"code","a1459e7e":"code","92529bee":"code","7ae8bcd1":"code","eba36be5":"code","841772bf":"code","7f35a37d":"code","aae52a24":"code","03e87ddc":"code","a90c26a0":"code","0f9dc48e":"code","4ee0765b":"code","2f7f80c1":"code","2e045c81":"code","12e8ed5c":"code","44b0bdfc":"code","11672131":"code","1d020dcc":"code","17c412e6":"code","3fcf6381":"code","3e4703a3":"code","ee00531e":"code","cb758741":"code","2fef2fbc":"code","ff1fe987":"markdown","6f01486a":"markdown","87019427":"markdown","e4b94ca4":"markdown","d9ccda68":"markdown","9cff86d3":"markdown","2283993a":"markdown","3656553c":"markdown"},"source":{"e654f333":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c203023f":"#First import the train dataset\n\ndf_train = pd.read_csv('..\/input\/titanic\/train.csv')\ndf_train.head()","828d08b1":"#find out the shape of the train dataset\ndf_train.shape","05f8e4ff":"#now import the test dataset\n\ndf_test = pd.read_csv('..\/input\/titanic\/test.csv')\ndf_test.head()","2ee612ce":"df_test.shape","3028b163":"df_train.head()","00d0e8ba":"#check if there is any null value in the train data\n\ndf_train.isnull().sum()","ed0b8777":"sns.heatmap(df_train.isnull())","04636284":"#Drop the column \"Cabin\" from the train dataset\ndf_train.drop('Cabin', axis=1, inplace=True)","204d4dea":"df_train.head()","ddd0d260":"sns.boxplot(x='Pclass', y=\"Age\", data=df_train, palette='winter')","e40d5865":"#fill the nan value of Age column\ndef impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass==1:\n            return 37\n        elif Pclass==2:\n            return 24\n        else:\n            return 22\n    else:\n        return Age\n    \ndf_train['Age'] = df_train[['Age','Pclass']].apply(impute_age, axis=1)","8027a72d":"# fill the embarked column by the mode value\ndf_train['Embarked'] = df_train['Embarked'].fillna(df_train['Embarked'].value_counts().index[0])\ndf_train.isnull().sum()","98ac6d0e":"df_train.head()","981bca9d":"# Drop the Ticket and Name columns from the dataset also\ndf_train.drop(['Name','Ticket'], axis=1, inplace=True)\ndf_train.head()","1a80788d":"#Drop the passenger ID Column from the dataset\ndf_train.drop('PassengerId', axis=1, inplace=True)\ndf_train.head()","69cd054e":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(10,6))\nsns.countplot(x='Sex',data=df_train, hue='Survived')\nplt.show()","58c5c504":"#now lets get the ration of male and female survived from Titanic\na = df_train.Sex.eq('male').groupby(df_train['Survived']).sum()\nprint(a[1]\/(a[0]+a[1]))\n\n# 18.8% men were survived\n\nb = df_train.Sex.eq('female').groupby(df_train['Survived']).sum()\nprint(b[1]\/(b[0]+b[1]))\n\n# 74.2% female were survived","806092fc":"df_train.head()","08eed5b1":"# Lets do the same thing for Pclass column\nsns.countplot(x='Pclass', data=df_train, hue='Survived')\nplt.show()","38b4aec7":"a = df_train.Pclass.eq(1).groupby(df_train['Survived']).sum()\nprint(a[1]\/(a[1]+a[0]))\n\n# 62% 1st class passengers were survived\n\nb = df_train.Pclass.eq(2).groupby(df_train['Survived']).sum()\nprint(b[1]\/(b[1]+b[0]))\n\n# 47% 1st class passengers were survived\n\nc = df_train.Pclass.eq(3).groupby(df_train['Survived']).sum()\nprint(c[1]\/(c[1]+c[0]))\n\n# 24% 1st class passengers were survived","13b972aa":"# Lets do the same thing for Pclass column\nsns.countplot(x='Embarked', data=df_train, hue='Survived')\nplt.show()","c21c9d00":"a = df_train.Embarked.eq('S').groupby(df_train['Survived']).sum()\nprint(a[1]\/(a[1]+a[0]))\n\n# 34% 1st class passengers were survived\n\nb = df_train.Embarked.eq('C').groupby(df_train['Survived']).sum()\nprint(b[1]\/(b[1]+b[0]))\n\n# 55% 1st class passengers were survived\n\nc = df_train.Embarked.eq('Q').groupby(df_train['Survived']).sum()\nprint(c[1]\/(c[1]+c[0]))\n\n# 39% 1st class passengers were survived","9f7fcc26":"df_train.head()","93f7820a":"plt.scatter(df_train['Fare'], df_train['Survived'])\nplt.show()","5da27656":"df_train.head()","ae523353":"X = df_train.drop('Survived', axis=1)\nX.head(), X.shape","6737f4d8":"from sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\ncol_trans = make_column_transformer((OneHotEncoder(),['Embarked','Sex']), remainder='passthrough')\nfinal = col_trans.fit_transform(X)\nprint(final[0])\nX_train = pd.DataFrame(final, columns=['Embarked_C','Embarked_Q','Embarked_S','Sex_f','Sex_m','Pclass','Age','SibSp','Parch','Fare'])\nX_train.head()","ff0d3bce":"X_train.head(10)","be8749b7":"X_train.shape","e20f4094":"y_train=df_train['Survived']\ny_train.shape","a81ab6e7":"# Now do the same for test dataset","fda18058":"df_test.head()","26ca7848":"df_test.drop(['PassengerId','Name','Ticket','Cabin'], axis=1, inplace=True)\ndf_test.shape","5d4034f5":"df_test.head()","3c65e159":"X_test = df_test","a1459e7e":"col_trans = make_column_transformer((OneHotEncoder(),['Embarked','Sex']), remainder='passthrough')\nfinal = col_trans.fit_transform(X_test)\nprint(final[0])\nX_test = pd.DataFrame(final, columns=['Embarked_C','Embarked_Q','Embarked_S','Sex_f','Sex_m','Pclass','Age','SibSp','Parch','Fare'])\nX_test.head()","92529bee":"X_test.shape","7ae8bcd1":"X_test.isnull().sum()","eba36be5":"sns.boxplot(x='Pclass',y='Age', data=X_test, palette='winter')","841772bf":"# Fill the age column\n\ndef impute_Age(cols):\n    Age=cols[0]\n    Pclass=cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass==1:\n            return 39\n        elif Pclass==2:\n            return 24\n        else:\n            return 24\n    else:\n        return Age\n    \nX_test['Age'] = df_train[['Age','Pclass']].apply(impute_Age, axis=1)\nX_test.isnull().sum()","7f35a37d":"X_test['Fare'].fillna(X_test['Fare'].mean(), inplace=True)","aae52a24":"X_test.isnull().sum()","03e87ddc":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nlogreg = LogisticRegression()\nlogreg.fit(X_train,y_train)","a90c26a0":"X_test.shape","0f9dc48e":"y_pred_logreg = logreg.predict(X_test)\ny_pred_logreg.shape","4ee0765b":"submission_df = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nfinal_df_logreg = pd.DataFrame(submission_df['PassengerId'], columns=['PassengerId'])\nfinal_df_logreg['Survived'] = y_pred_logreg\nfinal_df_logreg.to_csv('Logistic_result.csv', index=False)\nfinal_df_logreg.head()","2f7f80c1":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\n\nmax_depth = [2,4,6,8,10]\nmin_samples_split = [5,10,15,20,25]\nmin_samples_leaf = [5,10,15,20,25]\nmax_leaf_nodes = [10,15,20,25,30]\ncriterion = ['gini','entropy','chi2']\nparam_grid = dict(\n                    max_depth=max_depth,\n                    min_samples_split=min_samples_split,\n                    min_samples_leaf=min_samples_leaf,\n                    max_leaf_nodes=max_leaf_nodes,\n                    criterion=criterion\n                 )\nfrom sklearn.model_selection import GridSearchCV\ngrid = GridSearchCV(dt, param_grid, cv=10, n_jobs=-1, scoring='accuracy')\ngrid.fit(X_train,y_train)","2e045c81":"grid.best_score_","12e8ed5c":"grid.best_params_","44b0bdfc":"grid.best_estimator_","11672131":"dt = DecisionTreeClassifier(criterion='entropy', max_depth=8, max_leaf_nodes=25,\n                       min_samples_leaf=5, min_samples_split=15)\ndt.fit(X_train,y_train)\ny_pred_dt = dt.predict(X_test)\n\n\nfinal_df_dt = pd.DataFrame(submission_df['PassengerId'], columns=['PassengerId'])\nfinal_df_dt['Survived'] = y_pred_dt\nfinal_df_dt.to_csv('Decisiontree_result.csv', index=False)\nfinal_df_dt.head()","1d020dcc":"from sklearn.ensemble import RandomForestClassifier\nran = RandomForestClassifier()\n\nmax_depth = [2,4,6,8,10]\nmin_samples_split = [5,10,15,20,25]\nmin_samples_leaf = [5,10,15,20,25]\nmax_leaf_nodes = [10,15,20,25,30]\ncriterion = ['gini','entropy','chi2']\nmax_features = np.linspace(0.1,.5,5)\nparam_grid = dict(\n                    max_depth=max_depth,\n                    min_samples_split=min_samples_split,\n                    min_samples_leaf=min_samples_leaf,\n                    max_leaf_nodes=max_leaf_nodes,\n                    criterion=criterion,\n                    max_features=max_features\n                 )\nfrom sklearn.model_selection import RandomizedSearchCV\ngrid = RandomizedSearchCV(ran, param_grid, cv=10, n_jobs=-1, scoring='accuracy', n_iter=50)\ngrid.fit(X_train,y_train)","17c412e6":"grid.best_score_","3fcf6381":"grid.best_params_","3e4703a3":"grid.best_estimator_","ee00531e":"ran = RandomForestClassifier(max_depth=10, max_features=0.4, max_leaf_nodes=20,\n                       min_samples_leaf=5, min_samples_split=5)\nran.fit(X_train,y_train)","cb758741":"y_pred_ran = ran.predict(X_test)\ny_pred_ran\n\nfinal_df_ran = pd.DataFrame(submission_df['PassengerId'], columns=['PassengerId'])\nfinal_df_ran['Survived'] = y_pred_ran\nfinal_df_ran.to_csv('Randomforest_result.csv', index=False)\nfinal_df_ran.head()","2fef2fbc":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.svm import SVC\nabc = AdaBoostClassifier(n_estimators=150, learning_rate=.5, random_state=0)\nabc.fit(X_train,y_train)\ny_pred_ada = abc.predict(X_test)\n\nsubmission_df = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nfinal_df_ada = pd.DataFrame(submission_df['PassengerId'], columns=['PassengerId'])\nfinal_df_ada['Survived'] = y_pred_ada\nfinal_df_ada.to_csv('Adaboost_result.csv', index=False)\nfinal_df_ada.head()","ff1fe987":"## Lets Visualize the dataset","6f01486a":"## Decision Tree Classification","87019427":"## Random Forest Classifier","e4b94ca4":"## Data Preprocessing","d9ccda68":"## LogisticRegression","9cff86d3":"**The test dataset doesn't hold the \"Survived\" column because we have to predict it**","2283993a":"## Adaboost Algorithm","3656553c":"**Now first work with the train data for exploratory data analysis and visualization**"}}