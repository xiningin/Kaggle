{"cell_type":{"e37ec0e5":"code","47ef3397":"code","4fc7e85c":"code","3e0f7aec":"code","e6dee584":"code","1cb27c0b":"code","8dc48cb1":"code","1bba2c18":"code","dc699360":"code","4a672e24":"code","92546a5d":"code","ddf2131a":"code","2adfdeef":"code","1b34b0f5":"code","50e94421":"code","12ae0f28":"code","43994306":"code","7167605d":"code","5cc0ac8c":"code","5d4e70bd":"markdown","f2598f18":"markdown","fa167912":"markdown","d9ed47ae":"markdown","590c2853":"markdown","1e7b9a3b":"markdown","02d077e3":"markdown","330d6b82":"markdown","d26718a0":"markdown","67d7a497":"markdown","c48ba609":"markdown","56ace47b":"markdown","b1dea461":"markdown"},"source":{"e37ec0e5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","47ef3397":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Flatten\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n!pip install yfinance \nimport yfinance as yf","4fc7e85c":"df= yf.Ticker(\"^NSEBANK\").history(period='3y').reset_index()\ndf_axis= yf.Ticker(\"AXISBANK.NS\").history(period='3y').reset_index()\ndf_sbi= yf.Ticker(\"SBIN.NS\").history(period='3y').reset_index()\ndf_rbl= yf.Ticker(\"RBLBANK.NS\").history(period='3y').reset_index()\ndf_pnb= yf.Ticker(\"PNB.NS\").history(period='3y').reset_index()\ndf_kot= yf.Ticker(\"KOTAKBANK.NS\").history(period='3y').reset_index()\ndf_ind= yf.Ticker(\"INDUSINDBK.NS\").history(period='3y').reset_index()\ndf_idfc= yf.Ticker(\"IDFCFIRSTB.NS\").history(period='3y').reset_index()\ndf_icic= yf.Ticker(\"ICICIBANK.NS\").history(period='3y').reset_index()\ndf_band= yf.Ticker(\"BANDHANBNK.NS\").history(period='3y').reset_index()\ndf_hdfc= yf.Ticker(\"HDFC.NS\").history(period='3y').reset_index()\ndf_fed= yf.Ticker(\"FEDERALBNK.NS\").history(period='3y').reset_index()\ndf_au= yf.Ticker(\"AUBANK.NS\").history(period='3y').reset_index()","3e0f7aec":"df.head()","e6dee584":"# df=pd.read_csv('..\/input\/nifty-bank-stock-prices\/NSEBANK (1).csv')\n# df_axis=pd.read_csv('..\/input\/nifty-bank-stock-prices\/AXISBANK.NS.csv')\n# df_sbi=pd.read_csv('..\/input\/nifty-bank-stock-prices\/SBIN.NS.csv')\n# df_rbl=pd.read_csv('..\/input\/nifty-bank-stock-prices\/RBLBANK.NS.csv')\n# df_pnb=pd.read_csv('..\/input\/nifty-bank-stock-prices\/PNB.NS.csv')\n# df_kot=pd.read_csv('..\/input\/nifty-bank-stock-prices\/KOTAKBANK.NS.csv')\n# df_ind=pd.read_csv('..\/input\/nifty-bank-stock-prices\/INDUSINDBK.NS.csv')\n# df_idfc=pd.read_csv('..\/input\/nifty-bank-stock-prices\/IDFCFIRSTB.NS.csv')\n# df_icic=pd.read_csv('..\/input\/nifty-bank-stock-prices\/ICICIBANK.NS.csv')\n# df_band=pd.read_csv('..\/input\/nifty-bank-stock-prices\/BANDHANBNK.NS.csv')\n# df_hdfc=pd.read_csv('..\/input\/nifty-bank-stock-prices\/HDFC.NS.csv')\n# df_fed=pd.read_csv('..\/input\/nifty-bank-stock-prices\/FEDERALBNK.NS.csv')\n# df_au=pd.read_csv('..\/input\/nifty-bank-stock-prices\/AUBANK.NS.csv')","1cb27c0b":"import plotly.express as px\nfig = px.line(df, x='Date', y=\"Open\")\nfig.show()","8dc48cb1":"print(df_rbl.Date.max())\nprint(df_rbl.Date.min())","1bba2c18":"fig, axes = plt.subplots(6, 2, sharex=True, figsize=(20,32))\nplt.grid(True)\nsns.lineplot(ax=axes[0, 0], data=df_axis, x='Date', y='Open')\naxes[0,0].set_title('axis')\nsns.lineplot(ax=axes[0, 1], data=df_sbi, x='Date', y='Open')\naxes[0,1].set_title('sbi')\nsns.lineplot(ax=axes[1, 0], data=df_rbl, x='Date', y='Open')\naxes[1,0].set_title('rbl')\nsns.lineplot(ax=axes[1, 1], data=df_pnb, x='Date', y='Open')\naxes[1,1].set_title('pnb')\nsns.lineplot(ax=axes[2, 0], data=df_kot, x='Date', y='Open')\naxes[2,0].set_title('kot')\nsns.lineplot(ax=axes[2, 1], data=df_ind, x='Date', y='Open')\naxes[2,1].set_title('ind')\nsns.lineplot(ax=axes[3, 0], data=df_idfc, x='Date', y='Open')\naxes[3,0].set_title('idfc')\nsns.lineplot(ax=axes[3, 1], data=df_icic, x='Date', y='Open')\naxes[3,1].set_title('icic')\nsns.lineplot(ax=axes[4, 0], data=df_band, x='Date', y='Open')\naxes[4,0].set_title('band')\nsns.lineplot(ax=axes[4, 1], data=df_hdfc, x='Date', y='Open')\naxes[4,1].set_title('hdfc')\nsns.lineplot(ax=axes[5, 0], data=df_fed, x='Date', y='Open')\naxes[5,0].set_title('fed')\nsns.lineplot(ax=axes[5,1], data=df_au, x='Date', y='Open')\naxes[5,1].set_title('au')","dc699360":"print(df.shape)\ndate_train=pd.to_datetime(df['Date'])\ndate_train","4a672e24":"Scale=StandardScaler()\ndef data_prep(df, lookback, future, Scale):\n    date_train=pd.to_datetime(df['Date'])\n    df_train=df[['Open','High','Low','Close','Volume','Dividends','Stock Splits']]\n    df_train=df_train.astype(float)\n    \n    df_train_scaled=Scale.fit_transform(df_train)\n\n    X, y =[],[]\n    for i in range(lookback, len(df_train_scaled)-future+1):\n        X.append(df_train_scaled[i-lookback:i, 0:df_train.shape[1]])\n        y.append(df_train_scaled[i+future-1:i+future, 0])\n        \n    return np.array(X), np.array(y), df_train, date_train\n\nLstm_x, Lstm_y, df_train, date_train = data_prep(df, 30, 1, Scale)","92546a5d":"def Lstm_fallback(X,y):\n    model = Sequential()\n    \n    model.add(LSTM(64, activation='relu',input_shape=(X.shape[1], X.shape[2]),  return_sequences=True))\n    model.add(Dropout(0.2))\n    model.add(BatchNormalization())\n    model.add(LSTM(32, activation='relu', return_sequences=False))\n    model.add(Dropout(0.2))\n    model.add(BatchNormalization())\n    model.add(Dense(32, activation='relu'))\n    model.add(Dense(y.shape[1], activation='relu'))\n\n    opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)  \n    model.compile(\n            loss='mse',\n            optimizer=opt,\n        )\n    \n    es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15, restore_best_weights=True)\n    model.fit(X, y, epochs=100, verbose=1, callbacks=[es], validation_split=0.1, batch_size=16)\n    return model\n\n","ddf2131a":"def Lstm_model1(X, y):\n    regressor = Sequential()\n\n    regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X.shape[1], X.shape[2])))\n    regressor.add(Dropout(0.2))\n    regressor.add(LSTM(units = 50, return_sequences = True))\n    regressor.add(Dropout(0.2))\n    regressor.add(LSTM(units = 50, return_sequences = True))\n    regressor.add(Dropout(0.2))\n    regressor.add(LSTM(units = 50))\n    regressor.add(Dropout(0.2))\n    regressor.add(Dense(units = 1))\n\n    regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n    \n    es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15, restore_best_weights=True)\n    regressor.fit(X, y, epochs = 100, validation_split=0.1, batch_size = 64, verbose=1, callbacks=[es])\n    return regressor","2adfdeef":"def Lstm_model2(X,y):\n    model=Sequential()\n    \n    model.add(LSTM(20,return_sequences=True,input_shape=(X.shape[1], X.shape[2])))\n    model.add(Dropout(0.2))\n    model.add(BatchNormalization())\n    #model.add(LSTM(15,return_sequences=True))\n    #model.add(Dropout(0.2))\n    #model.add(BatchNormalization())\n    model.add(LSTM(15))\n    model.add(Dropout(0.2))\n    model.add(BatchNormalization())\n    model.add(Dense(16, activation='relu'))\n    model.add(Dense(1))\n    \n    adam = optimizers.Adam(0.001)\n    model.compile(loss='mean_squared_error',optimizer=adam)\n    \n    es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15, restore_best_weights=True)\n    model.fit(X, y,validation_split=0.2,epochs=100,batch_size=64,verbose=1, callbacks=[es])\n    return model","1b34b0f5":"def predict_open(model,date_train,Lstm_x,df_train, future, Scale):\n    forecasting_dates=pd.date_range(list(date_train)[-1], periods=future, freq='1d').tolist()\n    predicted=model.predict(Lstm_x[-future:])\n    predicted1=np.repeat(predicted, df_train.shape[1], axis=-1)\n    predicted_descaled=Scale.inverse_transform(predicted1)[:,0]\n    return predicted_descaled,forecasting_dates\n\ndef output_prep(forecasting_dates,predicted_descaled):\n    dates=[]\n    for i in forecasting_dates:\n        dates.append(i.date())\n    df_final=pd.DataFrame(columns=['Date','Open'])\n    df_final['Date']=pd.to_datetime(dates)\n    df_final['Open']=predicted_descaled\n    return df_final","50e94421":"def results(df, lookback, future, Scale, x):\n    Lstm_x, Lstm_y, df_train, date_train = data_prep(df, lookback, future, Scale)\n    model=Lstm_model1(Lstm_x,Lstm_y)\n    loss=pd.DataFrame(model.history.history)\n    loss.plot()\n    future=30\n    predicted_descaled,forecasting_dates=predict_open(model,date_train,Lstm_x,df_train,future, Scale)\n    results=output_prep(forecasting_dates,predicted_descaled)   \n    print(results.head())\n    plt.show()\n    fig = px.area(results, x=\"Date\", y=\"Open\", title=x)\n    fig.update_yaxes(range=[results.Open.min()-10, results.Open.max()+10])\n    fig.show()","12ae0f28":"def results1(df, lookback, future, Scale, x):\n    Lstm_x, Lstm_y, df_train, date_train = data_prep(df, lookback, future, Scale)\n    model=Lstm_model2(Lstm_x,Lstm_y)\n    loss=pd.DataFrame(model.history.history)\n    loss.plot()\n    future=30\n    predicted_descaled,forecasting_dates=predict_open(model,date_train,Lstm_x,df_train,future, Scale)\n    results=output_prep(forecasting_dates,predicted_descaled)   \n    print(results.head())\n    plt.show()\n    fig = px.area(results, x=\"Date\", y=\"Open\", title=x)\n    fig.update_yaxes(range=[results.Open.min()-10, results.Open.max()+10])\n    fig.show()\n","43994306":"results(df, 30, 1, Scale, 'NSEBANK')","7167605d":"results1(df, 30, 1, Scale, 'NSEBANK')","5cc0ac8c":"d={'AXIS':df_axis, 'SBI':df_sbi, 'RBL': df_rbl ,'PNB': df_pnb ,'KOTAK': df_kot, \n   'INDUSIND':df_ind, 'IDFC': df_idfc, 'ICIC': df_icic , 'BANDHAN': df_band, 'HDFC': df_hdfc, 'FEDERAL': df_fed,\n   'AU FIN':df_au}\n\nfor x in d.keys():\n    results1(d[x], 30, 1, Scale, x)\n    ","5d4e70bd":"LSTMs are very powerful in sequence prediction problems because they\u2019re able to store past information. This is important in our case because the previous price of a stock is crucial in predicting its future price.\n\nLong-Short-Term Memory Recurrent Neural Network belongs to the family of deep learning algorithms. It is a recurrent network because of the feedback connections in its architecture. It has an advantage over traditional neural networks due to its capability to process the entire sequence of data. Its architecture comprises the cell, input gate, output gate and forget gate.\n\nThe input gate: The input gate adds information to the cell state,\nThe forget gate: It removes the information that is no longer required by the model,\nThe output gate: Output Gate at LSTM selects the information to be shown as output.\n\nWhile Implementing any LSTM, we should always reshape our X train in 3-D, add 1 the reason behind is the time step and the 1 is given to the LSTM.","f2598f18":"# Data Preprocessing","fa167912":"Historical data for Bank Nifty (NSEBANK)","d9ed47ae":"Last 6 months","590c2853":"# Prediction","1e7b9a3b":"# Time Series Forecasting\nTime series data is recorded at regular time intervals, and the order of these data points is important. Therefore, any predictive model based on time series data will have time as an independent variable. The output of a model would be the predicted value or classification at a specific time. We use stock price data over a period of three years as a time series to predict the future price of those shares. \n","02d077e3":"# Overview \nThe stock market is very unpredictable, any geopolitical change can impact the share trend of stocks in the share market, recently we have seen how covid-19 has impacted the stock prices, which is why on financial data doing a  reliable trend analysis is very difficult. The most efficient way to solve this kind of issue is with the help of Machine learning and Deep learning. We use Recurrent Neural Networks for time series forecasting of all the banks under Bank Nifty. \n","330d6b82":"# Visualizations","d26718a0":"Historical data for all the banks under Bank Nifty (NSEBANK)","67d7a497":"# LSTM","c48ba609":"# Result Visualization","56ace47b":"# Data Loading\n\nWe use ticker method to retrieve the data from Yahoo Finance website. \nIn another approach we use the existing dataset that contains stock prices for over a period of 6 months for all the banks under Bank Nifty. ","b1dea461":"Entire data"}}