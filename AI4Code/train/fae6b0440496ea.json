{"cell_type":{"6c8ebb45":"code","058302ef":"code","f79e8d43":"code","62bcd8b2":"code","1e961104":"code","40f969b3":"code","8b33064b":"code","4cf27f64":"code","dba63f8b":"code","4e7ce327":"code","e8836ef9":"code","c58467aa":"code","902af61b":"code","a4cc4356":"code","680880f7":"code","f742d88e":"markdown","d00c8eeb":"markdown","874e2576":"markdown","dc123931":"markdown","8cc40c00":"markdown","c03efca5":"markdown","d241ec72":"markdown","d4629995":"markdown","8abc5b40":"markdown"},"source":{"6c8ebb45":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","058302ef":"pd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport datetime\nprint(\"Setup Complete\")","f79e8d43":"df = pd.read_csv('..\/input\/dataatp\/data_atp.csv')\ndf.head()","62bcd8b2":"df.info()","1e961104":"df['Date'] = pd.to_datetime(df['Date'], format=\"%m\/%d\/%y\")","40f969b3":"df = df.drop(columns=df.iloc[:,28:36])","8b33064b":"df.fillna(value=0, inplace=True)","4cf27f64":"for i in range(1,6):\n  df['GpS'+str(i)] = df.apply(lambda x: x['W'+str(i)] + x['L'+str(i)], axis = 1)\n\ndf['Total'] = 0\n\nfor i in range(1,6):\n  df['Total'] += df['GpS'+str(i)]\n\ndf['Sets'] = df.apply(lambda x: x['Wsets'] + x['Lsets'] if x['Comment']=='Completed' else 0, axis=1)","dba63f8b":"df.head()","4e7ce327":"player1, player2 = 'Nadal R.','Djokovic N.'\n\nprint(player1, player2)","e8836ef9":"df1 = df.loc[(df['Series']!='Grand Slam') & (df['Sets'] > 1) & (df['Total'] > 0) & (df['Surface']!='Carpet') & (df['Comment'] == 'Completed')]","c58467aa":"print(df1.groupby(['Winner','Sets'])[['Total']].describe().loc[[player1, player2]])\nprint(df1.groupby(['Loser','Sets'])[['Total']].describe().loc[[player1, player2]])","902af61b":"df2 =df1[['Total','Sets']].loc[(df1['Winner']==player1) | (df1['Loser']==player1) | (df1['Winner']==player2) | (df1['Loser']==player2)]\nprint(df2.groupby(['Sets'])[['Total']].describe())","a4cc4356":"plt.figure(figsize=(16,6))\nsns.kdeplot(data=df2, x ='Total', shade=False, bw_adjust=3)\nsns.kdeplot(data=df2, x ='Total', hue = 'Sets', shade=True, bw_adjust=2)\nplt.show()","680880f7":"plt.figure(figsize=(16,6))\nsns.kdeplot(data=df1, x ='Total', hue = 'Series', shade=True)\nplt.show()","f742d88e":"Create a sub-Dataframe containing the required data for the specific match. Find winning and losing matches for given players.","d00c8eeb":"# **Missing Values and Cleaning Data**\n\n> The first thing after after we download the file is to check for any missing values, which will be reprsented with \"NaN\" or \"None\".","874e2576":"Eleiminate the last 8 columns, since they contain no values.","dc123931":"Fill \"NaN\" values with \"0\".","8cc40c00":"To print a concise summary of a Tennis DataFrame and also to check the data type of our date column","c03efca5":"Creating additional columns for number of Games per Set (GpS), and calculating Total number of games (Total) and a number of Sets played per match (Sets).","d241ec72":"Combining the winning and losing data of two players and generating a kde smoothed distribution.","d4629995":"# **Data Visualization**","8abc5b40":"Convert our date columns to datetime."}}