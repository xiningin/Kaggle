{"cell_type":{"4beb1e66":"code","8485d4bd":"code","4715f6f0":"code","f0ac8116":"code","bebbd8c2":"code","b5f92c43":"code","853d72d4":"code","5af75b22":"markdown","183b5d8b":"markdown","edc6da60":"markdown","3c8db275":"markdown","4cfb43b3":"markdown","bd5226e4":"markdown"},"source":{"4beb1e66":"#\n# Setting for obtaining reproducible results\n#\n\nimport numpy as np\nimport tensorflow as tf\nimport random as rn\n\n# The below is necessary in Python 3.2.3 onwards to\n# have reproducible behavior for certain hash-based operations.\n# See these references for further details:\n# https:\/\/docs.python.org\/3.4\/using\/cmdline.html#envvar-PYTHONHASHSEED\n# https:\/\/github.com\/keras-team\/keras\/issues\/2280#issuecomment-306959926\n\nimport os\nos.environ['PYTHONHASHSEED'] = '0'\n\n# The below is necessary for starting Numpy generated random numbers\n# in a well-defined initial state.\n\nnp.random.seed(1234)\n\n# The below is necessary for starting core Python generated random numbers\n# in a well-defined state.\n\n#rn.seed(12345)\n\n# Force TensorFlow to use single thread.\n# Multiple threads are a potential source of\n# non-reproducible results.\n\nsession_conf = tf.ConfigProto(intra_op_parallelism_threads=1, \n                              inter_op_parallelism_threads=1)\n\nfrom keras import backend as K\n\n# The below tf.set_random_seed() will make random number generation\n# in the TensorFlow backend have a well-defined initial state.\n# For further details, \n# see: https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/set_random_seed\n\ntf.set_random_seed(1234)\n\nsess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\nK.set_session(sess)","8485d4bd":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport keras","4715f6f0":"df_train = pd.read_csv('..\/input\/X_train.csv', encoding='cp949')\ndf_test = pd.read_csv('..\/input\/X_test.csv', encoding='cp949')\ny_train = pd.read_csv('..\/input\/y_train.csv').gender\nIDtest = df_test.cust_id.unique()\ndf_test.head()","f0ac8116":"level = 'gds_grp_nm'\nitems = list(set(df_train[level]) | set(df_test[level]))\nncol = len(items)\n\ndef make_image(df):\n    x = pd.DataFrame({'cust_id': df.cust_id.unique()})\n    y = pd.DataFrame({level: items})\n    z = pd.DataFrame({'week_day': np.arange(7)})\n    df_pad = (\n        x.assign(key=1)\n        .merge(y.assign(key=1), on=\"key\")\n        .merge(z.assign(key=1), on=\"key\")\n        .drop(\"key\", axis=1)\n        .assign(amount=0)\n    )\n    df['week_day'] = pd.to_datetime(df.tran_date).dt.weekday\n    df_all = pd.concat([df, df_pad], sort=False, axis=0)\n    x = pd.pivot_table(df_all.query('amount >= 0'), \n                       index=['cust_id','week_day'], columns=level, \n                       values='amount', aggfunc=np.size, fill_value=0)\n    x = np.array(x).reshape(-1,7*ncol) - 1\n    return x.reshape(-1,7,ncol,1)\n#    x = np.array(x).reshape(-1,7*ncol) - 1\n#    return (x \/ x.max(1).reshape(-1,1)).reshape(-1,7,ncol,1)\n\nX_train = make_image(df_train)\nX_test = make_image(df_test)\n\nX_train.shape, X_test.shape","bebbd8c2":"import seaborn as sns\nfig, ax = plt.subplots(figsize=(20,10))\nsns.heatmap(X_train.reshape(-1,7,ncol)[300], ax=ax)\nplt.show()","b5f92c43":"from keras.models import Sequential\nfrom keras import layers\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import EarlyStopping\n\nmodel = Sequential()\nmodel.add(layers.Conv2D(1, kernel_size=(1, 1),strides=(1,1), activation='tanh', input_shape=(7,ncol,1)))\n#model.add(layers.MaxPooling2D(pool_size=(2, 1)))\n#model.add(layers.Conv2D(1, kernel_size=(1, 1),strides=(1,1), activation='tanh'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.2))\n#model.add(layers.Dense(16, activation='tanh'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\nmodel.summary()\n\nmodel.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['acc'])\n#model.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\nhistory = model.fit(X_train, y_train, \n                    epochs=50, batch_size=128, \n                    validation_split=0.2, callbacks=[EarlyStopping(patience=5)])\n\nplt.plot(history.history[\"loss\"], label=\"train loss\")\nplt.plot(history.history[\"val_loss\"], label=\"validation loss\")\nplt.legend()\nplt.title(\"Loss\")\nplt.show()","853d72d4":"pred = model.predict(X_test)[:,0]\nfname = 'submissions.csv'\nsubmissions = pd.concat([pd.Series(IDtest, name=\"cust_id\"), pd.Series(pred, name=\"gender\")] ,axis=1)\nsubmissions.to_csv(fname, index=False)\nprint(\"'{}' is ready to submit.\" .format(fname))","5af75b22":"### Build Models","183b5d8b":"### Make Submissions","edc6da60":"### Read Data","3c8db275":"## End","4cfb43b3":"## This model has the following characteristics:\n* No feature engineering\n* Applying Conv2D to raw transactions","bd5226e4":"### Transform Data"}}