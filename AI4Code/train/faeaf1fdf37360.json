{"cell_type":{"60ff05f0":"code","24732a07":"code","85fde423":"code","fef92acd":"code","c1516f0b":"code","7247010c":"code","9f133bb0":"code","f9b36003":"code","d2f4f067":"code","1be99c7d":"code","491a0c89":"code","9d1316a9":"code","365b1d9d":"code","679fc012":"code","9489ffa4":"code","e2f1da4c":"code","850e39b4":"code","44fc8416":"code","2e9f0e8a":"code","a808c0e1":"code","013cb2da":"code","9b964675":"code","ef81268a":"code","ddeb06cb":"code","787d6b5a":"code","98f2a7ed":"code","e5e4f476":"code","1834dd85":"code","9084cb89":"code","eff7cd93":"code","c587634e":"code","e5b57017":"code","2daf50fa":"code","3d6f90ce":"code","3c4e526c":"code","89046cf0":"code","72ca4870":"code","faac523c":"code","5cff8eeb":"code","8d6f4276":"code","51f788a2":"code","c323781c":"code","393c58eb":"code","06131c96":"code","743aeef0":"code","1f114b3b":"code","5c7c4535":"code","69abf2dc":"code","696e5a86":"markdown","61776d83":"markdown","17c8f81e":"markdown","7798567e":"markdown","d6fd5a76":"markdown","1006e595":"markdown","fbe1b938":"markdown","2b9e1a36":"markdown","cff9a4c4":"markdown"},"source":{"60ff05f0":"#Importing required libraries\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import MultinomialNB,GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score,GridSearchCV\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport xgboost\nfrom xgboost import XGBClassifier\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")","24732a07":"#reading Dataset\ndf=pd.read_csv(\"..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv\")\ndf","85fde423":"print(df.shape)\ndf.info()\n#data is numeric","fef92acd":"df.describe()","c1516f0b":"#cheking null values\nprint(df.isnull().values.any())\ndf.isnull().sum()\n#no null values present in the data set","7247010c":"plt.tight_layout()\n#univariate analysis\nfor i in df.columns:\n    plt.figure(figsize=(10,5))\n    sns.countplot(df[i])\n    print(i,df[i].unique())\n    print(df[i].value_counts().sort_index())\n    print(\"----------------------------------------------------------------------\")","9f133bb0":"#lets check coorelation matrix\ndf.corr()","f9b36003":"#visulaising the correlation matrix\nplt.tight_layout()\nplt.figure(figsize=(15,5))\nsns.heatmap(df.corr(),cbar=\"viridius\",annot=True)\n#it is observed that attributes are not so highly correlated ","d2f4f067":"#Bivariate Analysis\n#lets divide the age group and see tha chances of heart attack among age<45,45>and<=60 , >60\nplt.figure(figsize=(10,5))\nage_less_45=df[df[\"age\"]<45]\nsns.countplot(x=\"output\",hue=\"sex\",data=age_less_45)","1be99c7d":"plt.figure(figsize=(10,5))\nage_bw_45_60=df[(df[\"age\"]>=45) & (df[\"age\"]<=60)]\nsns.countplot(x=\"output\",hue=\"sex\",data=age_bw_45_60)","491a0c89":"plt.figure(figsize=(10,5))\nage_grtr_60=df[df[\"age\"]>60]\nsns.countplot(x=\"output\",hue=\"sex\",data=age_grtr_60)","9d1316a9":"#lets divide on the basis of cholestoral  level\nchol_1=df[df[\"chol\"]<200]\nchol_3=df[df[\"chol\"]>=240]\nchol_2=df[(df[\"chol\"]>=200) & (df[\"chol\"]<=239)]\ncol=[chol_1,chol_2,chol_3]\nfor i in col:\n    plt.figure(figsize=(10,5))\n    sns.countplot(x=\"output\",hue=\"sex\",data=i)\n  ","365b1d9d":"df.describe(percentiles=[.25,.50,.75,.98,.99])#checking for outliers,looking good ","679fc012":"#scaling the data using Standardscalar\nscaled=StandardScaler().fit_transform(df.drop(\"output\",axis=1))\nscaled\nscaled=pd.DataFrame(scaled,columns=['age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh',\n       'exng', 'oldpeak', 'slp', 'caa', 'thall'])\nscaled.head()","9489ffa4":"X=scaled\ny=df[[\"output\"]]\n#dividing the dataset intto input and output variables ","e2f1da4c":"#spliting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","850e39b4":"gc.collect()#memory clearing ","44fc8416":"print(y_train.value_counts()[0]\/len(y_train),\"% of label 0 in train data\")\nprint(y_train.value_counts()[1]\/len(y_train),\"% of label 1 in train data\")\nprint(y_test.value_counts()[0]\/len(y_test),\"% of label 0 in train data\")\nprint(y_test.value_counts()[1]\/len(y_test),\"% of label 1 in train data\")\n\n#we can see that almost good amount of data is distributed in train and test","2e9f0e8a":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)\n\n#shape of train and test data\n","a808c0e1":"#fitting the models and predicting the accuracy scores of default models and cross validation scores as well\nmodel=[LogisticRegression(),DecisionTreeClassifier(),GaussianNB(),SVC(),KNeighborsClassifier(),\n      RandomForestClassifier(),AdaBoostClassifier(),GradientBoostingClassifier()]\nmodel_score=pd.DataFrame(columns=[\"Model\",\"Accuracy\",\"CV_Mean_Accuracy\"])\nfor m in model:\n    m.fit(X_train,y_train)\n    pred=m.predict(X_test)\n    print(\"Accuracy score of {} model is\".format(m),accuracy_score(y_test,pred),\"\\n\")\n    cv=cross_val_score(estimator=m,X=X,y=y,scoring=\"accuracy\",cv=10)\n    print(\"Cross validation score of {} model is \".format(m),list(cv),\"\\n\")\n    print(\"Mean score of cross validation of {} model is \".format(m),cv.mean(),\"\\n\")\n    print(\"confusion matrix for{} model\".format(m),\"\\n\",confusion_matrix(y_test,pred))\n    print(\"\\n\",classification_report(y_test,pred))\n    print(\"------------------------------------------------------------------------------------\")\n    print(\"\\n\")\n    model_score=model_score.append([{\"Model\":m,\"Accuracy\":accuracy_score(y_test,pred),\"CV_Mean_Accuracy\":cv.mean()}],ignore_index=True)","013cb2da":"model_score\n#observations:best model is random forest in terms of cv scores and worst model is DT","9b964675":"gc.collect()#clearing memory","ef81268a":"#LogisticRegression model\nlog=LogisticRegression()\nparam_grid={\"C\":[0.001,0.01,0.1,0.5,1,2,10], \"penalty\":['l1', 'l2'],\"max_iter\":[50,100,200,300] }\ngrid_lr=GridSearchCV(estimator=log,param_grid=param_grid,\n                     scoring=\"accuracy\",cv=10,return_train_score=True)\ngrid_lr.fit(X_train,y_train)\n","ddeb06cb":"print(grid_lr.best_params_)#best params obtained by grid search \n                 ","787d6b5a":"#lest fit the LR model with best parameters and check the accuracy\nlr=LogisticRegression(C=0.5,max_iter=50,penalty='l2',random_state=100)\nlr.fit(X_train,y_train)\npred=lr.predict(X_test)\nacclr=accuracy_score(y_test,pred)\nprint(accuracy_score(y_test,pred),\"accuracy score\")\ncv_lr=cross_val_score(estimator=lr,X=X,y=y,cv=10)\nprint(cv_lr.mean(),\"mean_cv_accuracy score\")\n#we can observe cv accuracy score has been is quite decreased","98f2a7ed":"#svm model\nsvm=SVC()\nparam_grid={\"C\":[0.001,0.01,0.1,0.5,1,2,10,20],\"kernel\":['linear', 'poly', 'rbf',],\"gamma\":[1e-1,1e-2,1e-4,1,2]}\ngrid_svm=GridSearchCV(estimator=svm,cv=10,param_grid=param_grid,scoring=\"accuracy\",\n                     return_train_score=True)\ngrid_svm.fit(X_train,y_train)","e5e4f476":"print(grid_svm.best_params_)#best prams for svc","1834dd85":"#lest fit the svc model with best model and check the accuracy\nsvm=SVC(C=10,gamma=0.1,kernel=\"linear\",random_state=100)\nsvm.fit(X_train,y_train)\npred=svm.predict(X_test)\naccsvm=accuracy_score(y_test,pred)\nprint(accuracy_score(y_test,pred),\"accuracy score\")\ncv_svm=cross_val_score(estimator=svm,X=X,y=y,cv=10)\nprint(cv_svm.mean(),\"mean_cv_accuracy score\")\n#cv accuracy is increased","9084cb89":"#KNN model\nknn=KNeighborsClassifier()\nparam_grid={\"n_neighbors\":range(1,50,5),\"leaf_size\":range(1,50,5)}\ngrid_knn=GridSearchCV(estimator=knn,cv=10,param_grid=param_grid,scoring=\"accuracy\",\n                     return_train_score=True)\ngrid_knn.fit(X_train,y_train)","eff7cd93":"print(grid_knn.best_params_)#best prams for knn","c587634e":"#fitting the model with best parameter\nknn=KNeighborsClassifier(leaf_size=1,n_neighbors=16)\nknn.fit(X_train,y_train)\npred=knn.predict(X_test)\naccknn=accuracy_score(y_test,pred)\nprint(accuracy_score(y_test,pred),\"accuracy score\")\ncv_knn=cross_val_score(estimator=knn,X=X,y=y,cv=10)\nprint(cv_knn.mean(),\"mean_cv_accuracy score\")\n#cv accuracy is increased ","e5b57017":"#Random Forest Model\nrf=RandomForestClassifier()\nparam_grid={\"n_estimators\":[500,1000,2000],\"max_depth\":[2,3,5]}\ngrid_rf=GridSearchCV(estimator=rf,cv=10,param_grid=param_grid,scoring=\"accuracy\",\n                     return_train_score=True)\ngrid_rf.fit(X_train,y_train)\nprint(grid_rf.best_params_)","2daf50fa":"rf=RandomForestClassifier()\nparam_grid={\"min_samples_split\":[20,30,50],\n           \"min_samples_leaf\" : [20,30,50]}\ngrid_rf=GridSearchCV(estimator=rf,cv=10,param_grid=param_grid,scoring=\"accuracy\",\n                     return_train_score=True)\ngrid_rf.fit(X_train,y_train)\nprint(grid_rf.best_params_)","3d6f90ce":"#fitting the model with best parametres\nrf=RandomForestClassifier(n_estimators=500,max_depth=3,min_samples_split=50,min_samples_leaf=20,random_state=42)\nrf.fit(X_train,y_train)\npred=rf.predict(X_test)\naccrf=accuracy_score(y_test,pred)\nprint(accuracy_score(y_test,pred),\"accuracy score\")\ncv_rf=cross_val_score(estimator=rf,X=X,y=y,cv=10)\nprint(cv_rf.mean(),\"mean_cv_accuracy score\")\n","3c4e526c":"#lets use xgboost model\nxgb=XGBClassifier()\nxgb.fit(X_train,y_train)\npred=xgb.predict(X_test)\naccxgb=accuracy_score(y_test,pred)\nprint(accuracy_score(y_test,pred))\ncv_xgb=cross_val_score(estimator=xgb,X=X,y=y,cv=10)\nprint(cv_xgb.mean(),\"mean_cv_accuracy score\")\n\n","89046cf0":"#finding best parameters for xgboost model\nparams = {'learning_rate': [0.2,.6,.8,1],\n          'max_depth': [2,5,8]\n         }\ngrid_xgb=GridSearchCV(estimator=xgb,param_grid=params,cv=10,scoring=\"accuracy\")\ngrid_xgb.fit(X_train,y_train)\nprint(grid_xgb.best_params_)\n","72ca4870":"params = {'n_estimators': [200,400,600,1000],\n          \"subsample\": [0.3, 0.6, 0.9],\n         }\ngrid_xgb=GridSearchCV(estimator=xgb,param_grid=params,cv=10,scoring=\"accuracy\")\ngrid_xgb.fit(X_train,y_train)\nprint(grid_xgb.best_params_)","faac523c":"xgb=XGBClassifier()\nparams = {'n_estimators': [100,200],\n          \"subsample\": [0.3,0.4,],\n          \"learning_rate\":[0.2,0.3],\"max_depth\":[2,3]}\ngrid_xgb=GridSearchCV(estimator=xgb,param_grid=params,cv=10,scoring=\"accuracy\")\ngrid_xgb.fit(X_train,y_train)\nprint(grid_xgb.best_params_)\n#finding the best parametres","5cff8eeb":"#fitting model with best params\nxgb=XGBClassifier(n_estimators =100,subsample=0.3,learning_rate=0.2,max_depth=3)\nxgb.fit(X_train,y_train)\npred=xgb.predict(X_test)\naccxgbf=accuracy_score(y_test,pred)\nprint(accuracy_score(y_test,pred))\ncv_xgb=cross_val_score(estimator=xgb,X=X,y=y,scoring=\"accuracy\",cv=10)\nprint(cv_xgb.mean(),\"mean_cv_accuracy score\")","8d6f4276":"abc=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2))\nparam_grid=[{'n_estimators':[50,100,150],\"learning_rate\":[0.01,0.1,0.2],\n            \"algorithm\":['SAMME'],\"random_state\":[40,100]}]\nabc_grid=GridSearchCV(estimator=abc,param_grid=param_grid,scoring=\"accuracy\",cv=10,return_train_score=True)\nabc_grid.fit(X_train,y_train)\nprint(abc_grid.best_params_)","51f788a2":"abc=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2),algorithm=\"SAMME\",\n                      learning_rate=0.1,n_estimators=100,random_state=40)\nabc.fit(X_train,y_train)\npred=abc.predict(X_test)\naccabc=accuracy_score(y_test,pred)\nprint(accuracy_score(y_test,pred))\ncv_abc=cross_val_score(estimator=abc,X=X,y=y,scoring=\"accuracy\",cv=10)\nprint(cv_abc.mean(),\"mean_cv_accuracy score\")","c323781c":"#model scores after hyper parametre tuning\nmodel_score=pd.DataFrame(columns=[\"Model\",\"Accuracy\",\"CV_Mean_Accuracy\"])\nmodel_score=model_score.append([{\"Model\":\"LR\",\"Accuracy\":acclr,\"CV_Mean_Accuracy\":cv_lr.mean()}],ignore_index=True)\nmodel_score=model_score.append([{\"Model\":\"SVC\",\"Accuracy\":accsvm,\"CV_Mean_Accuracy\":cv_svm.mean()}],ignore_index=True)\nmodel_score=model_score.append([{\"Model\":\"knn\",\"Accuracy\":accknn,\"CV_Mean_Accuracy\":cv_knn.mean()}],ignore_index=True)\nmodel_score=model_score.append([{\"Model\":\"RF\",\"Accuracy\":accrf,\"CV_Mean_Accuracy\":cv_rf.mean()}],ignore_index=True)\nmodel_score=model_score.append([{\"Model\":\"XGBoost\",\"Accuracy\":accxgbf,\"CV_Mean_Accuracy\":cv_xgb.mean()}],ignore_index=True)\nmodel_score=model_score.append([{\"Model\":\"AdaBoost\",\"Accuracy\":accabc,\"CV_Mean_Accuracy\":cv_abc.mean()}],ignore_index=True)","393c58eb":"model_score","06131c96":"#Choosing Random Forest \nrf=RandomForestClassifier(n_estimators=500,max_depth=3,min_samples_split=50,min_samples_leaf=20,random_state=42)\nrf.fit(X_train,y_train)\npred=rf.predict(X_test)\naccrf=accuracy_score(y_test,pred)\nprint(\"Accuracy score of final model is\",round(accuracy_score(y_test,pred)*100,2),\"%\")\nprint(\"\\nConfusion Matrix\")\nprint(confusion_matrix(y_test,pred),\"\\n\")\nprint(\"Classifiaction Report:\",\"\\n\",classification_report(y_test,pred))\ncv_rf=cross_val_score(estimator=rf,X=X,y=y,cv=10)\nprint(\"Cross Validation Scores are:\",cv_rf)\nprint(\"\\n\")\nprint(\"Mean_Accuracy_Score of final model is\",round(cv_rf.mean()*100,2),\"%\")\n","743aeef0":"#visualizing the confusion matrix of final model\nmatrix=confusion_matrix(y_test,pred)\nsns.heatmap(matrix,annot=True)\nplt.title(\"Confusion matrix of Random Forest\")\n","1f114b3b":"print(\"\\t\\t\\t\\t\",\"Important features of RandomForest Model\")\nplt.figure(figsize=(15,6),dpi=100)\npd.Series(rf.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8)\nprint('\\t\\t\\t\\t******************************************')\nprint(\"\\t\\t\\t\\t    Accuracy of the Model is \",round(cv_rf.mean()*100,2),\"%\")","5c7c4535":"import joblib","69abf2dc":"joblib.dump(rf,\"RF_Heartattack_Classification.pkl\")","696e5a86":"  ****Visualising the important features of the final model to predict Heart Attack****    ","61776d83":"**Observation:**\nIt is observed that random forest model performed quite well among all models and aroud 84% percentage of accuracy is predicted in terms of cross validation accuracy which is pretty much good.","17c8f81e":"**Understanding the data by visualizing**\n\n","7798567e":"**Observation:**\nwe can observe that male who have moderate cholestoral level are more prone to  heart attack i.e cholestoral level b\/w 200 and 239**\n     ","d6fd5a76":"**Observations:**\n* It is observed that among above models Random Forrest model is performed very well in terms of cross validation accuracy and DecsionTree classifier came to be worst performer.\n* Cosndering -Logistic Regression ,Support Vector Machines ,Random Forest Classifier,KNN,AdaBoost models and finding the best hyperparameters\n","1006e595":"*****Observations:*****\n* Different age group people are there in given data set\n* Assuming 0 as female and 1 as male and fact says that males do have more chances       of heartattack,so in this data set label 1 is considered as males and vice versa.\n* More count of people with type 1 Chest pain and very few with type 4 can be observed in the above visualization\n* As per my research,normal bp is considered to be upto 80\/120 mm Hg but there are many people who have bp more than 140 mm Hg and one person even have bp upto 200 mm Hg which is too high \n* As per my research,Cholestrol level below 200 mg\/dl  is considered to be normal and between 200 and 239  is considered to be borderline and more than 240  mg\/dl is considered to be high cholestrol level,we can observe in above visulaization one person is having as high 564 mg\/dl.\n* Very few people have diabetes ,it is clear from above visulization\n* We can observe that among people who have done ECG,more of them were having ST-T wave abnormality \n* Normal Heart rate or pulse rate is b\/w 50-100 but in visualization above we can observe a person was having pulse rate as high as 202\n* In above visulisation ,it is observed that less people had angima(chest pain caused by reduced blood flow to heart)\n* oldpeak is measure of ST depression induced by exercise relative to rest\n* sip here is the slope of the peak exercise ST segment(as per my research)\n* thal is also a heart disease ,may be its are given,and we can observe that more count of people have type 2 thal.\n\n","fbe1b938":"**Observation:**\ncomparing above age group results-it is observed that  people b\/w age group of 45-60 are having  more heartattack chances and among them majority  are males.","2b9e1a36":"**Lets tune the hyperparameters and see whether accuracy score is improved**","cff9a4c4":"**Preparing the model**"}}