{"cell_type":{"2212c718":"code","417ba9f1":"code","76e88270":"code","bd94d295":"code","582c0070":"code","b50bebfc":"code","bfb52a26":"code","96be43dc":"code","6aca4ada":"code","b34d3c79":"code","d98b04db":"code","1b2b9245":"code","078045c6":"code","3a259dab":"code","cb53cbb1":"code","3834c6c6":"code","10a2fb36":"code","a947bd8e":"code","6e8f153d":"code","0c2e66dd":"code","d13ed1ca":"code","5f4cba88":"code","6c94a947":"code","e5c88f8d":"code","eae09628":"code","e2f04b54":"code","8ec17677":"code","8a6685b2":"code","5ec1f4b7":"code","bc96acea":"code","4e20e4c7":"code","2b2476cc":"code","18279f94":"markdown","3d803061":"markdown","66a34a3d":"markdown","158c7362":"markdown","b3000199":"markdown","f0d544fb":"markdown","df0c31f4":"markdown","07e8e333":"markdown","ff79a7ae":"markdown","c90d1b64":"markdown","8b13b422":"markdown","cfdf62f3":"markdown","74f93939":"markdown","fa1939b1":"markdown","5f83880f":"markdown","c6d4287b":"markdown","6ea19d92":"markdown","12c22fc4":"markdown","2275ec20":"markdown","8e815292":"markdown","6660ee06":"markdown","b93fc543":"markdown","96b279b2":"markdown","22a7c756":"markdown","13448d51":"markdown","cf1935d1":"markdown","6dac2d46":"markdown","8d70d732":"markdown"},"source":{"2212c718":"import tensorflow as tf\nfrom tensorflow.keras.datasets import fashion_mnist\n\n# The data has already been sorted into training and test sets for us\n(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()","417ba9f1":"# Show the first training example\nprint(f\"Training sample:\\n{train_data[0]}\\n\") \nprint(f\"Training label: {train_labels[0]}\")","76e88270":"# Check the shape of our data\ntrain_data.shape, train_labels.shape, test_data.shape, test_labels.shape","bd94d295":"# Check shape of a single example\ntrain_data[0].shape, train_labels[0].shape","582c0070":"# Plot a single example\nimport matplotlib.pyplot as plt\nplt.imshow(train_data[7]);","b50bebfc":"# Check our samples label\ntrain_labels[7]","bfb52a26":"class_names = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\n# How many classes are there (this'll be our output shape)?\nlen(class_names)","96be43dc":"# Plot an example image and its label\nplt.imshow(train_data[17], cmap=plt.cm.binary) # change the colours to black & white\nplt.title(class_names[train_labels[17]]);","6aca4ada":"# Plot multiple random images of fashion MNIST\nimport random\nplt.figure(figsize=(7, 7))\nfor i in range(4):\n  ax = plt.subplot(2, 2, i + 1)\n  rand_index = random.choice(range(len(train_data)))\n  plt.imshow(train_data[rand_index], cmap=plt.cm.binary)\n  plt.title(class_names[train_labels[rand_index]])\n  plt.axis(False)","b34d3c79":"# Set random seed\ntf.random.set_seed(42)\n\n# Create the model\nmodel_11 = tf.keras.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)), # input layer (we had to reshape 28x28 to 784, the Flatten layer does this for us)\n  tf.keras.layers.Dense(4, activation=\"relu\"),\n  tf.keras.layers.Dense(4, activation=\"relu\"),\n  tf.keras.layers.Dense(10, activation=\"softmax\") # output shape is 10, activation is softmax\n])\n\n# Compile the model\nmodel_11.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), # different loss function for multiclass classifcation\n                 optimizer=tf.keras.optimizers.Adam(),\n                 metrics=[\"accuracy\"])\n\n# Fit the model\nnon_norm_history = model_11.fit(train_data,\n                                train_labels,\n                                epochs=10,\n                                validation_data=(test_data, test_labels)) # see how the model performs on the test set during training","d98b04db":"# Check the shapes of our model\n# Note: the \"None\" in (None, 784) is for batch_size, we'll cover this in a later module\nmodel_11.summary()","1b2b9245":"# Check the min and max values of the training data\ntrain_data.min(), train_data.max()","078045c6":"# Divide train and test images by the maximum value (normalize it)\ntrain_data = train_data \/ 255.0\ntest_data = test_data \/ 255.0\n\n# Check the min and max values of the training data\ntrain_data.min(), train_data.max()","3a259dab":"# Set random seed\ntf.random.set_seed(42)\n\n# Create the model\nmodel_12 = tf.keras.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)), # input layer (we had to reshape 28x28 to 784)\n  tf.keras.layers.Dense(4, activation=\"relu\"),\n  tf.keras.layers.Dense(4, activation=\"relu\"),\n  tf.keras.layers.Dense(10, activation=\"softmax\") # output shape is 10, activation is softmax\n])\n\n# Compile the model\nmodel_12.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                 optimizer=tf.keras.optimizers.Adam(),\n                 metrics=[\"accuracy\"])\n\n# Fit the model (to the normalized data)\nnorm_history = model_12.fit(train_data,\n                            train_labels,\n                            epochs=10,\n                            validation_data=(test_data, test_labels))","cb53cbb1":"import pandas as pd\n# Plot non-normalized data loss curves\npd.DataFrame(non_norm_history.history).plot(title=\"Non-normalized Data\")\n# Plot normalized data loss curves\npd.DataFrame(norm_history.history).plot(title=\"Normalized data\");","3834c6c6":"# Set random seed\ntf.random.set_seed(42)\n\n# Create the model\nmodel_13 = tf.keras.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)), # input layer (we had to reshape 28x28 to 784)\n  tf.keras.layers.Dense(4, activation=\"relu\"),\n  tf.keras.layers.Dense(4, activation=\"relu\"),\n  tf.keras.layers.Dense(10, activation=\"softmax\") # output shape is 10, activation is softmax\n])\n\n# Compile the model\nmodel_13.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                 optimizer=tf.keras.optimizers.Adam(),\n                 metrics=[\"accuracy\"])\n\n# Create the learning rate callback\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-3 * 10**(epoch\/20))\n\n# Fit the model\nfind_lr_history = model_13.fit(train_data,\n                               train_labels,\n                               epochs=40, # model already doing pretty good with current LR, probably don't need 100 epochs\n                               validation_data=(test_data, test_labels),\n                               callbacks=[lr_scheduler])","10a2fb36":"# Plot the learning rate decay curve\nimport numpy as np\nimport matplotlib.pyplot as plt\nlrs = 1e-3 * (10**(np.arange(40)\/20))\nplt.semilogx(lrs, find_lr_history.history[\"loss\"]) # want the x-axis to be log-scale\nplt.xlabel(\"Learning rate\")\nplt.ylabel(\"Loss\")\nplt.title(\"Finding the ideal learning rate\");","a947bd8e":"# Set random seed\ntf.random.set_seed(42)\n\n# Create the model\nmodel_14 = tf.keras.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)), # input layer (we had to reshape 28x28 to 784)\n  tf.keras.layers.Dense(4, activation=\"relu\"),\n  tf.keras.layers.Dense(4, activation=\"relu\"),\n  tf.keras.layers.Dense(10, activation=\"softmax\") # output shape is 10, activation is softmax\n])\n\n# Compile the model\nmodel_14.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), # ideal learning rate (same as default)\n                 metrics=[\"accuracy\"])\n\n# Fit the model\nhistory = model_14.fit(train_data,\n                       train_labels,\n                       epochs=20,\n                       validation_data=(test_data, test_labels))","6e8f153d":"# Note: The following confusion matrix code is a remix of Scikit-Learn's \n# plot_confusion_matrix function - https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.plot_confusion_matrix.html\n# and Made with ML's introductory notebook - https:\/\/github.com\/GokuMohandas\/MadeWithML\/blob\/main\/notebooks\/08_Neural_Networks.ipynb\nimport itertools\nfrom sklearn.metrics import confusion_matrix\n\n# Our function needs a different name to sklearn's plot_confusion_matrix\ndef make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15): \n  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n\n  If classes is passed, confusion matrix will be labelled, if not, integer class values\n  will be used.\n\n  Args:\n    y_true: Array of truth labels (must be same shape as y_pred).\n    y_pred: Array of predicted labels (must be same shape as y_true).\n    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n    figsize: Size of output figure (default=(10, 10)).\n    text_size: Size of output figure text (default=15).\n  \n  Returns:\n    A labelled confusion matrix plot comparing y_true and y_pred.\n\n  Example usage:\n    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n                          y_pred=y_preds, # predicted labels\n                          classes=class_names, # array of class label names\n                          figsize=(15, 15),\n                          text_size=10)\n  \"\"\"  \n  # Create the confustion matrix\n  cm = confusion_matrix(y_true, y_pred)\n  cm_norm = cm.astype(\"float\") \/ cm.sum(axis=1)[:, np.newaxis] # normalize it\n  n_classes = cm.shape[0] # find the number of classes we're dealing with\n\n  # Plot the figure and make it pretty\n  fig, ax = plt.subplots(figsize=figsize)\n  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n  fig.colorbar(cax)\n\n  # Are there a list of classes?\n  if classes:\n    labels = classes\n  else:\n    labels = np.arange(cm.shape[0])\n  \n  # Label the axes\n  ax.set(title=\"Confusion Matrix\",\n         xlabel=\"Predicted label\",\n         ylabel=\"True label\",\n         xticks=np.arange(n_classes), # create enough axis slots for each class\n         yticks=np.arange(n_classes), \n         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n         yticklabels=labels)\n  \n  # Make x-axis labels appear on bottom\n  ax.xaxis.set_label_position(\"bottom\")\n  ax.xaxis.tick_bottom()\n\n  # Set the threshold for different colors\n  threshold = (cm.max() + cm.min()) \/ 2.\n\n  # Plot the text on each cell\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n             horizontalalignment=\"center\",\n             color=\"white\" if cm[i, j] > threshold else \"black\",\n             size=text_size)","0c2e66dd":"# Make predictions with the most recent model\ny_probs = model_14.predict(test_data) # \"probs\" is short for probabilities\n\n# View the first 5 predictions\ny_probs[:5]","d13ed1ca":"# See the predicted class number and label for the first example\ny_probs[0].argmax(), class_names[y_probs[0].argmax()]","5f4cba88":"# Convert all of the predictions from probabilities to labels\ny_preds = y_probs.argmax(axis=1)\n\n# View the first 10 prediction labels\ny_preds[:10]","6c94a947":"# Check out the non-prettified confusion matrix\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_true=test_labels, \n                 y_pred=y_preds)","e5c88f8d":"# Make a prettier confusion matrix\nmake_confusion_matrix(y_true=test_labels, \n                      y_pred=y_preds,\n                      classes=class_names,\n                      figsize=(15, 15),\n                      text_size=10)","eae09628":"import random\n\n# Create a function for plotting a random image along with its prediction\ndef plot_random_image(model, images, true_labels, classes):\n  \"\"\"Picks a random image, plots it and labels it with a predicted and truth label.\n\n  Args:\n    model: a trained model (trained on data similar to what's in images).\n    images: a set of random images (in tensor form).\n    true_labels: array of ground truth labels for images.\n    classes: array of class names for images.\n  \n  Returns:\n    A plot of a random image from `images` with a predicted class label from `model`\n    as well as the truth class label from `true_labels`.\n  \"\"\" \n  # Setup random integer\n  i = random.randint(0, len(images))\n  \n  # Create predictions and targets\n  target_image = images[i]\n  pred_probs = model.predict(target_image.reshape(1, 28, 28)) # have to reshape to get into right size for model\n  pred_label = classes[pred_probs.argmax()]\n  true_label = classes[true_labels[i]]\n\n  # Plot the target image\n  plt.imshow(target_image, cmap=plt.cm.binary)\n\n  # Change the color of the titles depending on if the prediction is right or wrong\n  if pred_label == true_label:\n    color = \"green\"\n  else:\n    color = \"red\"\n\n  # Add xlabel information (prediction\/true label)\n  plt.xlabel(\"Pred: {} {:2.0f}% (True: {})\".format(pred_label,\n                                                   100*tf.reduce_max(pred_probs),\n                                                   true_label),\n             color=color) # set the color to green or red","e2f04b54":"# Check out a random image as well as its prediction\nplot_random_image(model=model_14, \n                  images=test_data, \n                  true_labels=test_labels, \n                  classes=class_names)","8ec17677":"# Find the layers of our most recent model\nmodel_14.layers","8a6685b2":"# Extract a particular layer\nmodel_14.layers[1]","5ec1f4b7":"# Get the patterns of a layer in our network\nweights, biases = model_14.layers[1].get_weights()\n\n# Shape = 1 weight matrix the size of our input data (28x28) per neuron (4)\nweights, weights.shape","bc96acea":"# Shape = 1 bias per neuron (we use 4 neurons in the first layer)\nbiases, biases.shape","4e20e4c7":"# Can now calculate the number of paramters in our model\nmodel_14.summary()","2b2476cc":"from tensorflow.keras.utils import plot_model\n\n# See the inputs and outputs of each layer\nplot_model(model_14, show_shapes=True)","18279f94":"Alright, our model gets to about ~35% accuracy after 10 epochs using a similar style model to what we used on our binary classification problem.\n\nWhich is better than guessing (guessing with 10 classes would result in about 10% accuracy) but we can do better.\n\nDo you remember when we talked about neural networks preferring numbers between 0 and 1? (if not, treat this as a reminder)\n\nWell, right now, the data we have isn't between 0 and 1, in other words, it's not normalized (hence why we used the non_norm_history variable when calling fit()). It's pixel values are between 0 and 255.\n\nLet's see.","3d803061":"Woah, we used the exact same model as before but we with normalized data we're now seeing a much higher accuracy value!\n\nLet's plot each model's history (their loss curves).","66a34a3d":"We can get these values between 0 and 1 by dividing the entire array by the maximum: 255.0 (dividing by a float also converts to a float).\n\nDoing so will result in all of our data being between 0 and 1 (known as **scaling** or **normalization**).","158c7362":"Hmm, but what about its label?","b3000199":"And we can find the patterns learned by a particular layer using the get_weights() method.\n\nThe get_weights() method returns the **weights** (also known as a weights matrix) and biases (also known as a bias vector) of a particular layer.","f0d544fb":"Every neuron has a bias vector. Each of these is paired with a weight matrix.\n\nThe bias values get initialized as zeroes by default (using the bias_initializer parameter).\n\nThe bias vector dictates how much the patterns within the corresponding weights matrix should influence the next layer.","df0c31f4":"That looks much better! (one of my favourites sights in the world is a confusion matrix with dark squares down the diagonal)\n\nExcept the results aren't as good as they could be...\n\nIt looks like our model is getting confused between the Shirt and T-shirt\/top classes (e.g. predicting Shirt when it's actually a T-shirt\/top).\n\n> \ud83e\udd14 Question: Does it make sense that our model is getting confused between the Shirt and T-shirt\/top classes? Why do you think this might be? What's one way you could investigate?\n\nWe've seen how our models predictions line up to the truth labels using a confusion matrix, but how about we visualize some?\n\nLet's create a function to plot a random image along with its prediction.\n\n> \ud83d\udd11 Note: Often when working with images and other forms of visual data, it's a good idea to visualize as much as possible to develop a further understanding of the data and the outputs of your model.","07e8e333":"Now we've got a model trained with a close-to-ideal learning rate and performing pretty well, we've got a couple of options.\n\nWe could:\n\n* Evaluate its performance using other classification metrics (such as a confusion matrix or classification report).\n* Assess some of its predictions (through visualizations).\n* Improve its accuracy (by training it for longer or changing the architecture).\n* Save and export it for use in an application.\n\nLet's go through the first two options.\n\nFirst we'll create a classification matrix to visualize its predictions across the different classes","ff79a7ae":"Beautiful! Now our data is between 0 and 1. Let's see what happens when we model it.\n\nWe'll use the same model as before (model_11) except this time the data will be normalized","c90d1b64":"The weights matrix is the same shape as the input data, which in our case is 784 (28x28 pixels). And there's a copy of the weights matrix for each neuron the in the selected layer (our selected layer has 4 neurons).\n\nEach value in the weights matrix corresponds to how a particular value in the input data influences the network's decisions.\n\nThese values start out as random numbers (they're set by the kernel_initializer parameter when creating a layer, the default is \"glorot_uniform\") and are then updated to better representative values of the data (non-random) by the neural network during training.\n\n![image.png](attachment:f3adefbe-5fcc-4928-b466-93793d5d112c.png)\n\nExample workflow of how a supervised neural network starts with random weights and updates them to better represent the data by looking at examples of ideal outputs.\n\nNow let's check out the bias vector.","8b13b422":"Alright, let's build a model to figure out the relationship between the pixel values and their labels.\n\nSince this is a multiclass classification problem, we'll need to make a few changes to our architecture (inline with Table 1 above):\n\n* The input shape will have to deal with 28x28 tensors (the height and width of our images).\n    * We're actually going to squash the input into a tensor (vector) of shape (784).\n* The output shape will have to be 10 because we need our model to predict for 10 different classes.\n    * We'll also change the activation parameter of our output layer to be \"softmax\" instead of 'sigmoid'. As we'll see the \"softmax\" activation function outputs a series of values between 0 & 1 (the same shape as output shape, which together add up to ~1. The index with the highest value is predicted by the model to be the most likely class.\n* We'll need to change our loss function from a binary loss function to a multiclass loss function.\n    * More specifically, since our labels are in integer form, we'll use tf.keras.losses.SparseCategoricalCrossentropy(), if our labels were one-hot encoded (e.g. they looked something like [0, 0, 1, 0, 0...]), we'd use tf.keras.losses.CategoricalCrossentropy().\n* We'll also use the validation_data parameter when calling the fit() function. This will give us an idea of how the model performs on the test set during training.\n\nYou ready? Let's go.","cfdf62f3":"After running the cell above a few times you'll start to get a visual understanding of the relationship between the model's predictions and the true labels.\n\nDid you figure out which predictions the model gets confused on?\n\nIt seems to mix up classes which are similar, for example, Sneaker with Ankle boot.\n\nLooking at the images, you can see how this might be the case.\n\nThe overall shape of a Sneaker and an Ankle Boot are similar.\n\nThe overall shape might be one of the patterns the model has learned and so therefore when two images have a similar shape, their predictions get mixed up.\n# **What patterns is our model learning?**\nWe've been talking a lot about how a neural network finds patterns in numbers, but what exactly do these patterns look like?\n\nLet's crack open one of our models and find out.\n\nFirst, we'll get a list of layers in our most recent model (model_14) using the layers attribute.","74f93939":"That confusion matrix is hard to comprehend, let's make it prettier using the function we created before.","fa1939b1":"Wow. From these two plots, we can see how much quicker our model with the normalized data (model_12) improved than the model with the non-normalized data (model_11).\n\n> \ud83d\udd11 Note: The same model with even slightly different data can produce dramatically different results. So when you're comparing models, it's important to make sure you're comparing them on the same criteria (e.g. same architecture but different data or same data but different architecture).\n\nHow about we find the ideal learning rate and see what happens?\n\nWe'll use the same architecture we've been using.","5f83880f":"Now let's do the same for all of the predictions.","c6d4287b":"In this case, it looks like somewhere close to the default learning rate of the [Adam optimizer](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/optimizers\/Adam) (0.001) is the ideal learning rate.\n\nLet's refit a model using the ideal learning rate.","6ea19d92":"Now let's check out an example.","12c22fc4":"Woah, we get a large list of numbers, followed (the data) by a single number (the class label).\n\nWhat about the shapes?","2275ec20":"Now we've built a few deep learning models, it's a good time to point out the whole concept of inputs and outputs not only relates to a model as a whole but to every layer within a model.\n\nYou might've already guessed this, but starting from the input layer, each subsequent layer's input is the output of the previous layer.\n\nWe can see this clearly using the utility plot_model().","8e815292":"Okay, 60,000 training examples each with shape (28, 28) and a label each as well as 10,000 test examples of shape (28, 28).\n\nBut these are just numbers, let's visualize.","6660ee06":"# **Working with a larger example (multiclass classification)**\nWe've seen a binary classification example (predicting if a data point is part of a red circle or blue circle) but what if you had multiple different classes of things?\n\nFor example, say you were a fashion company and you wanted to build a neural network to predict whether a piece of clothing was a shoe, a shirt or a jacket (3 different options).\n\nWhen you have more than two classes as an option, this is known as** multiclass classification**.\n\nThe good news is, the things we've learned so far (with a few tweaks) can be applied to multiclass classification problems as well.\n\nLet's see it in action.\n\nTo start, we'll need some data. The good thing for us is TensorFlow has a multiclass classication dataset known as Fashion MNIST built-in. Meaning we can get started straight away.\n\nWe can import it using the tf.keras.datasets module.\n\n> \ud83d\udcd6 Resource: The following multiclass classification problem has been adapted from the TensorFlow classification guide. A good exercise would be to once you've gone through the following example, replicate the TensorFlow guide.","b93fc543":"We can access a target layer using indexing.","96b279b2":"Wonderful, now we've got our model's predictions in label form, let's create a confusion matrix to view them against the truth labels.","22a7c756":"Our model outputs a list of prediction probabilities, meaning, it outputs a number for how likely it thinks a particular class is to be the label.\n\nThe higher the number in the prediction probabilities list, the more likely the model believes that is the right class.\n\nTo find the highest value we can use the argmax() method.","13448d51":"# **How a model learns (in brief)**\nAlright, we've trained a bunch of models, but we've never really discussed what's going on under the hood. So how exactly does a model learn?\n\nA model learns by updating and improving its weight matrices and biases values every epoch (in our case, when we call the fit() fucntion).\n\nIt does so by comparing the patterns its learned between the data and labels to the actual labels.\n\nIf the current patterns (weight matrices and bias values) don't result in a desirable decrease in the loss function (higher loss means worse predictions), the optimizer tries to steer the model to update its patterns in the right way (using the real labels as a reference).\n\nThis process of using the real labels as a reference to improve the model's predictions is called backpropagation.\n\nIn other words, data and labels pass through a model (forward pass) and it attempts to learn the relationship between the data and labels.\n\nAnd if this learned relationship isn't close to the actual relationship or it could be improved, the model does so by going back through itself (backward pass) and tweaking its weights matrices and bias values to better represent the data.\n\nIf all of this sounds confusing (and it's fine if it does, the above is a very succinct description), check out the resources in the extra-curriculum section for more.","cf1935d1":"Since a confusion matrix compares the truth labels (test_labels) to the predicted labels, we have to make some predictions with our model.","6dac2d46":"It looks like our labels are in numerical form. And while this is fine for a neural network, you might want to have them in human readable form.\n\nLet's create a small list of the class names (we can find them on the dataset's GitHub page).\n\n> \ud83d\udd11 Note: Whilst this dataset has been prepared for us and ready to go, it's important to remember many datasets won't be ready to go like this one. Often you'll have to do a few preprocessing steps to have it ready to use with a neural network (we'll see more of this when we work with our own data later).","8d70d732":"Now we have these, let's plot another example.\n\n> \ud83e\udd14 Question: Pay particular attention to what the data we're working with looks like. Is it only straight lines? Or does it have non-straight lines as well? Do you think if we wanted to find patterns in the photos of clothes (which are actually collections of pixels), will our model need non-linearities (non-straight lines) or not?"}}