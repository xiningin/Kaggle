{"cell_type":{"b6dc024c":"code","ba95e4f5":"code","506b97b9":"code","df21d5f5":"code","f912f105":"code","cac4c709":"code","31c02ab1":"code","d4608f40":"code","b8a835c3":"code","ff14a0e5":"code","abb2be52":"code","cd3ef3c0":"code","d51d2207":"code","b264797f":"code","b88f05f7":"code","7f3e19c2":"code","b62bca2c":"code","47512697":"code","57b3235f":"code","6c4cf082":"code","79c30cb3":"code","75977704":"code","541bd3ba":"code","009c1bd9":"code","dc3c724e":"code","054f4138":"code","5d58b987":"code","8acb6b44":"code","8efe44b2":"code","f8e1bf77":"code","919c7c63":"code","f0c234b2":"code","55ecba6b":"code","a2bed714":"code","5e5837db":"code","80053281":"code","cb9c5456":"markdown","ccdc81c7":"markdown","7e8046f4":"markdown","b8c94544":"markdown"},"source":{"b6dc024c":"import os\nimport zipfile\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nimport shutil\nimport matplotlib.pyplot as plt\n%matplotlib inline","ba95e4f5":"train_data_dir = '\/kaggle\/input\/gender-classification-dataset\/Training'\nval_data_dir = '\/kaggle\/input\/gender-classification-dataset\/Validation'","506b97b9":"paths_dict = {\n    'female': [],\n    'male': []\n}","df21d5f5":"for key in paths_dict.keys():\n    for dirname, _, filenames in os.walk(os.path.join(train_data_dir, key)):\n        for filename in filenames:\n            paths_dict[key].append(os.path.join(dirname, filename))","f912f105":"groups = [key + '\\n' + str(len(paths_dict[key])) \n          for key in paths_dict.keys()]\ncount_data = [len(paths_dict[key])\n          for key in paths_dict.keys()]\ncolors = ['b', 'r']","cac4c709":"plt.title('Amount of train data')\n\nwidth = len(count_data) * 0.3\nplt.bar(groups, count_data, width=width, color=colors, alpha=0.6, bottom=2, linewidth=2)","31c02ab1":"train_dir = '\/kaggle\/working\/train_dir'\ntest_dir = '\/kaggle\/working\/test_dir'","d4608f40":"def create_directory(dir_name):\n    if os.path.exists(dir_name):\n        shutil.rmtree(dir_name)\n    os.makedirs(dir_name)\n    \n    for key in paths_dict.keys():\n        os.makedirs(os.path.join(dir_name, key))","b8a835c3":"create_directory(train_dir)\ncreate_directory(test_dir)","ff14a0e5":"def copy_images(start_index, end_index, paths, dest_dir):\n    for i in range(start_index, end_index):\n        dest_path = os.path.join(dest_dir, paths[i].split('\/')[5])\n        shutil.copy2(paths[i], dest_path)","abb2be52":"# Part of the test data set\ntest_data_proportion = 0.2","cd3ef3c0":"for key in paths_dict.keys():\n    test_index = len(paths_dict[key]) - int(len(paths_dict[key]) * test_data_proportion)\n    \n    copy_images(0, test_index, paths_dict[key], train_dir)\n    copy_images(test_index, len(paths_dict[key]), paths_dict[key], test_dir)","d51d2207":"# Import the inception model  \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3","b264797f":"pre_trained_model = InceptionV3(input_shape = (150, 150, 3), # Shape of our images\n                                include_top = False, # Leave out the last fully connected layer\n                                weights = 'imagenet')","b88f05f7":"for layer in pre_trained_model.layers:\n  layer.trainable = False","7f3e19c2":"class myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('acc')>0.959):\n      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n      self.model.stop_training = True","b62bca2c":"from keras import backend as K\n\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives =K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))\n","47512697":"from tensorflow.keras.optimizers import RMSprop\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(pre_trained_model.output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)                  \n# Add a final sigmoid layer for classification\nx = layers.Dense  (1, activation='sigmoid')(x)           \n\nmodel = Model( pre_trained_model.input, x) \n\nmodel.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'binary_crossentropy', \n              metrics = ['acc', f1_m, precision_m, recall_m])","57b3235f":"# Rescale Train & Test Image\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255.,\n                                   rotation_range = 40,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\n\n# No augmentation needed\ntest_datagen = ImageDataGenerator( rescale = 1.0\/255. )","6c4cf082":"# Flow validation images in batches 20 using train_datagen and test_datagen\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size = 20,\n                                                    class_mode = 'binary', \n                                                    target_size = (150, 150))\nvalidation_generator =  test_datagen.flow_from_directory( val_data_dir,\n                                                          batch_size  = 20,\n                                                          class_mode  = 'binary', \n                                                          target_size = (150, 150))","79c30cb3":"callbacks = myCallback()\nhistory = model.fit_generator(\n            train_generator,\n            validation_data = validation_generator,\n            steps_per_epoch = 100,\n            epochs = 100,\n            validation_steps = 50,\n            verbose = 2,\n            callbacks=[callbacks])","75977704":"print(\"F1-score: \",history.history['f1_m'])\nprint(\"F1-score val: \",history.history['val_f1_m'])\nprint(\"Precision: \",history.history['precision_m'])\nprint(\"Precision val: \",history.history['val_precision_m'])\nprint(\"Recall: \",history.history['recall_m'])\nprint(\"Recall: \",history.history['val_recall_m'])\n","541bd3ba":"import matplotlib.pyplot as plt\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","009c1bd9":"last_layer = pre_trained_model.get_layer('mixed7') #Only use layers including and above 'mixed7'\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output","dc3c724e":"last_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)                  \n# Add a final sigmoid layer for classification\nx = layers.Dense  (1, activation='sigmoid')(x)           \n\nmodel = Model( pre_trained_model.input, x) \n\nmodel.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'binary_crossentropy', \n              metrics = ['acc', f1_m, precision_m, recall_m])\n\n# Add our data-augmentation parameters to ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255.,\n                                   rotation_range = 40,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\n# Note that the validation data should not be augmented!\ntest_datagen = ImageDataGenerator( rescale = 1.0\/255. )\n\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size = 20,\n                                                    class_mode = 'binary', \n                                                    target_size = (150, 150))     \n\n# Flow validation images in batches of 20 using test_datagen generator\nvalidation_generator =  test_datagen.flow_from_directory( val_data_dir,\n                                                          batch_size  = 20,\n                                                          class_mode  = 'binary', \n                                                          target_size = (150, 150))\n\ncallbacks = myCallback()\nhistory = model.fit_generator(\n            train_generator,\n            validation_data = validation_generator,\n            steps_per_epoch = 100,\n            epochs = 100,\n            validation_steps = 50,\n            verbose = 2,\n            callbacks=[callbacks])","054f4138":"print(\"F1-score: \",history.history['f1_m'])\nprint(\"F1-score val: \",history.history['val_f1_m'])\nprint(\"Precision: \",history.history['precision_m'])\nprint(\"Precision val: \",history.history['val_precision_m'])\nprint(\"Recall: \",history.history['recall_m'])\nprint(\"Recall: \",history.history['val_recall_m'])","5d58b987":"len_train_data = len(train_generator.filenames)\nlen_test_data = len(validation_generator.filenames)\n#batch_size = 20\n\nresult = model.evaluate_generator(validation_generator,\n                                  len_test_data \/\/ 20,\n                                  verbose=1)","8acb6b44":"model.summary()","8efe44b2":"import matplotlib.pyplot as plt\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","f8e1bf77":"last_layer = pre_trained_model.get_layer('mixed7') #Only use layers including and above 'mixed7'\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output","919c7c63":"last_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)                  \n# Add a final sigmoid layer for classification\nx = layers.Dense  (1, activation='sigmoid')(x)           \n\nmodel = Model( pre_trained_model.input, x) \n\nmodel.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'binary_crossentropy', \n              metrics = ['acc', f1_m, precision_m, recall_m])\n\n# Add our data-augmentation parameters to ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255.,\n                                   rotation_range = 40,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\n# Note that the validation data should not be augmented!\ntest_datagen = ImageDataGenerator( rescale = 1.0\/255. )\n\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size = 20,\n                                                    class_mode = 'binary', \n                                                    target_size = (150, 150))     \n\n# Flow validation images in batches of 20 using test_datagen generator\nvalidation_generator =  test_datagen.flow_from_directory( val_data_dir,\n                                                          batch_size  = 20,\n                                                          class_mode  = 'binary', \n                                                          target_size = (150, 150))\n\ncallbacks = myCallback()\nhistory = model.fit_generator(\n            train_generator,\n            validation_data = validation_generator,\n            steps_per_epoch = 100,\n            epochs = 100,\n            validation_steps = 50,\n            verbose = 2,\n            callbacks=[callbacks])","f0c234b2":"print(\"F1-score: \",history.history['f1_m'])\nprint(\"F1-score val: \",history.history['val_f1_m'])\nprint(\"Precision: \",history.history['precision_m'])\nprint(\"Precision val: \",history.history['val_precision_m'])\nprint(\"Recall: \",history.history['recall_m'])\nprint(\"Recall: \",history.history['val_recall_m'])","55ecba6b":"import matplotlib.pyplot as plt\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","a2bed714":"#batch_size = 20\n\nresult = model.evaluate_generator(validation_generator,\n                                  len_test_data \/\/ 20,\n                                  verbose=1)","5e5837db":"model.summary()","80053281":"model.evaluate(test_gen)","cb9c5456":"## Generating Inception-V3 Model","ccdc81c7":"Creation of directories for generators","7e8046f4":"# Data preparation","b8c94544":"Visualization of the amount of train data in classes"}}