{"cell_type":{"f3fe2eb8":"code","97206bf2":"code","4eefb2fa":"code","45a4b5e1":"code","f27f0351":"code","fbf6affe":"code","cafd6a7c":"code","16ffa277":"code","edade97e":"code","c19dd20a":"code","251719cf":"code","2905b089":"code","bd129ebe":"code","55e55907":"code","4b10bbaf":"code","fbbe0421":"code","a391faa4":"code","c94ba46f":"code","366d909e":"code","5171a9b1":"markdown"},"source":{"f3fe2eb8":"from __future__ import print_function, division\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torch import nn, optim\nfrom torch.autograd import Variable\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nimport os\nimport shutil\nimport pandas as pd\nfrom torch.optim import lr_scheduler\nimport torchvision\nimport time\nimport os\nimport copy\nimport cv2\nfrom sklearn.metrics import roc_auc_score\nprint(\"Imports done\")","97206bf2":"#Creating a training and a validation set folder\nos.makedirs(\"..\/val\")\nos.makedirs(\"..\/train\")\nprint(\"Validation set directory created\")\nprint(\"Training set directory created\")","4eefb2fa":"#Creating the training and the validation set directories\nfull_dir = '..\/input\/virtual-hack\/car_data\/car_data\/train\/'\ntrain_dir = '..\/train\/'\nvalid_dir = '..\/val\/'\nfor dir in os.listdir(full_dir):\n    os.makedirs(train_dir+dir)\n    os.makedirs(valid_dir+dir)\nprint(\"Sub-Directories created\")","45a4b5e1":"#Deciding the split between validation and test data\nsplit_factor = 0.9","f27f0351":"#Initializing some directory variables\nfull_dir = '..\/input\/virtual-hack\/car_data\/car_data\/train\/'\nvalid_dir = '..\/val\/'\ntrain_dir = '..\/train\/'","fbf6affe":"#Making the appropriate directories for training and validation\nfor dir in os.listdir(full_dir):\n    list = os.listdir(full_dir+dir) # dir is your directory path\n    number_files = len(list)\n    train_size = int(split_factor*number_files)\n    valid_size = number_files - train_size\n    for i in range(number_files):\n        if (i < train_size):\n            shutil.copy(full_dir+dir+'\/'+list[i],train_dir+dir)\n        else:\n            shutil.copy(full_dir+dir+'\/'+list[i],valid_dir+dir)\nprint(\"Data transfer done\")","cafd6a7c":"#Initializing the training and testing data loaders\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomVerticalFlip(p=0.5),\n        transforms.RandomAffine(360,translate = (0.125,0.125)),\n        transforms.ColorJitter(0.2),\n        transforms.ToTensor(),\n        transforms.Normalize([0.388, 0.394, 0.401], [0.293, 0.285, 0.292])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.388, 0.394, 0.401], [0.293, 0.285, 0.292])\n    ]),\n}\n\ndata_dir = '..\/'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","16ffa277":"#defining imshow for visualizing the data\ndef imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.388, 0.394, 0.401])\n    std = np.array([0.293, 0.285, 0.292])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])","edade97e":"#Defining the classifier and the relevant parameters\n# Use GPU if it's available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = models.resnet101(pretrained=True)\n\n# Freeze parameters so we don't backprop through them\nfor param in model.parameters():\n    param.requires_grad = False\n    \nmodel.fc = nn.Sequential(nn.Linear(2048, 512),\n                                 nn.ReLU(),\n                                 nn.Dropout(0.2),\n                                 nn.Linear(512, 196),\n                                 nn.LogSoftmax(dim=1))\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\nmodel.to(device);","c19dd20a":"#defining the method which is used for training the model\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","251719cf":"#Helper method for visualizing the peformance of the model\ndef visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images\/\/2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","2905b089":"#Training the model\nmodel_ft = train_model(model, criterion, optimizer, exp_lr_scheduler,\n                       num_epochs=40)","bd129ebe":"#Visualizing the performance of the model\nvisualize_model(model_ft)","55e55907":"#Generating the list of images\ntest_dir = '..\/input\/virtual-hack\/car_data\/car_data\/test\/'\nfolder_list = []\nfor folder in os.listdir(test_dir):\n    folder_list.append(folder)\nfolder_list.sort()\nname_list = []\ntrue_label_list = []\nfor i in range(len(folder_list)):\n    current_list = []\n    current_label_list = []\n    for j in os.listdir(test_dir+folder_list[i]):\n        current_list.append(j)\n        current_label_list.append(i)\n    current_list.sort()\n    name_list.extend(current_list)\n    true_label_list.extend(current_label_list)\nprint('Name list generated')\nprint('True label list generated')","4b10bbaf":"#Generating the test predictions\ntest_transforms = transforms.Compose([transforms.Resize((224,224)),\n                                transforms.ToTensor(),\n                                transforms.Normalize([0.388, 0.394, 0.401], [0.293, 0.285, 0.292])])\npredict = []\nvalues = []\nmodel.eval()\ntest_data = datasets.ImageFolder('..\/input\/virtual-hack\/car_data\/car_data\/test', transform = test_transforms)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=32)\nwith torch.no_grad():\n        for i, (inputs, labels) in enumerate(test_loader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            vals, preds = torch.max(outputs, 1)\n            predict.extend(preds.tolist())\n            values.extend(vals.tolist())\nprint('Predictions generated')\nprint('Values generated')","fbbe0421":"#Printing id and predictions\nfinal_result = []\nfor i in range (len(predict)):\n    filename = str(name_list[i])[0:5]\n    pred_category  = predict[i]\n    final_result.append((filename, pred_category))\nfinal_result","a391faa4":"#Saving the prediction in a csv\nfinal_output = pd.DataFrame(final_result, columns=[\"Id\", \"Predicted\"])\nfinal_output.to_csv('final_output.csv', index=False)","c94ba46f":"#Checking whether the CSV is generated properly or not\ntest_csv = pd.read_csv(\"final_output.csv\")\ntest_csv","366d909e":"#Getting the auc score\nfrom sklearn.preprocessing import LabelBinarizer\ndef multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n    return roc_auc_score(y_test, y_pred, average=average)\nmulticlass_roc_auc_score(true_label_list, predict)","5171a9b1":"My overall approach involves using transfer learning with Resnet101, while defining a custom classifier which works on top of the Resnet Architecture. I chose resnet for it's efficiency.\nInput size (224,224) is what is recommended for resnet.\nTransforms of all varieties have been tried out while keeping in mind the input requirements.\nI started with Learning rate = 0.001 but decided to increase it given the low starting accuracy which was gradually increasing.\nMean and std were calculated for one random batch of training data.\nSplit factor was kept as 0.9 to make the most out of training data while keeping in mind the possibility of over-fitting.\nCross-Entropy loss is used keeping in mind the multiple labels of classification.\nMomentum is also used for better optimization.\n"}}