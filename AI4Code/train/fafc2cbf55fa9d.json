{"cell_type":{"6272d9f3":"code","98df2184":"code","bd92b995":"code","988c51e0":"code","f79260ba":"code","125bb7aa":"code","bd3a527c":"code","13d42f61":"code","e07b9007":"code","78bc7b4c":"code","6ba825c5":"code","01806283":"code","a8f92d5a":"code","15e1be9d":"code","d6322f72":"code","a955ed71":"code","2c9157ef":"code","f4eb1c10":"code","37e563f8":"code","f6e09387":"code","0d125417":"code","8b095b1b":"code","618ba64f":"code","8a0a86b8":"code","3aa5db19":"code","d2dcaf5e":"code","12cfaca8":"code","b972aa18":"code","0a729ddd":"code","998293ec":"code","36db8c80":"code","4a175c80":"code","f25d661d":"code","70a62c7a":"code","c2b43331":"code","0a3d6801":"code","a705eb3b":"code","16f88d7f":"code","5b8fac59":"code","3f677210":"code","208f6443":"code","4bf011a2":"code","50ed9f8b":"code","4142e725":"code","80b7403f":"code","b195fde9":"code","07a95e09":"code","800ceff2":"code","8d03e8d1":"code","df936bc6":"code","e15de216":"code","d4053b13":"code","3e13ca4b":"code","2dcd08cf":"code","d9dca40c":"code","7170137c":"code","1689b15b":"code","e863ce0d":"code","0932fb09":"code","ec28b0db":"code","f0e54449":"code","0a091935":"code","d54d7c9c":"code","acc7c795":"code","ddb9566a":"code","84afb658":"code","e51ed03e":"code","378526bb":"code","96d29629":"markdown","bfeab950":"markdown","6fe94f76":"markdown","9ca24edb":"markdown","35e50035":"markdown","4d90665c":"markdown","6dae5834":"markdown","4fdb43a5":"markdown","74b0d702":"markdown","f47b619c":"markdown","3dd285e8":"markdown","915b3b8a":"markdown","54257575":"markdown","27ec8c46":"markdown","b16c56b3":"markdown","cb7d333b":"markdown","f8a0a247":"markdown","9784ed0d":"markdown","22fe0ff2":"markdown","1299949c":"markdown","cb239f74":"markdown","eb4fb774":"markdown","5df7e210":"markdown","cf96c70d":"markdown","a3b27984":"markdown","7b166464":"markdown","7e5eda1f":"markdown","351983e4":"markdown","9aa5e450":"markdown","09a8b68a":"markdown","593653c7":"markdown","64ab0c31":"markdown","29aa0809":"markdown","80917647":"markdown","d90425dc":"markdown","78ed8e5f":"markdown","b53551e3":"markdown","5c71fb4d":"markdown","40c0da0c":"markdown","76734bbe":"markdown","7d6306f5":"markdown","569de76a":"markdown","4056b9b2":"markdown","f4c11545":"markdown","b1d23734":"markdown","15c00d79":"markdown","2ef2c81d":"markdown","b3febdad":"markdown","61deebcf":"markdown","e4ccafea":"markdown","6affe96a":"markdown","4bd56063":"markdown","c9906eda":"markdown","4632f41e":"markdown","91d129ca":"markdown","06ccad27":"markdown"},"source":{"6272d9f3":"# load libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nimport sklearn\nsns.set()","98df2184":"# load dataset\n\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\n","bd92b995":"train_df.shape","988c51e0":"test_df.shape","f79260ba":"train_df.columns.values","125bb7aa":"train_df.head()","bd3a527c":"train_df.isnull().sum()[train_df.isnull().sum() > 0]","13d42f61":"import missingno as msno","e07b9007":"msno.matrix(train_df[['v2a1', 'v18q1', 'rez_esc', 'meaneduc', 'SQBmeaned']], color = (0.211, 0.215, 0.274))\nplt.show()","78bc7b4c":"sns.countplot(train_df.loc[(pd.isnull(train_df['v2a1'])), 'tipovivi1'])\nplt.title(\"Ownership\")\nplt.show()","6ba825c5":"train_df.loc[(pd.isnull(train_df['v2a1']) & train_df['tipovivi1'] == 1), 'v2a1'] = 0","01806283":"train_df = train_df.loc[pd.notnull(train_df['v2a1'])]","a8f92d5a":"train_df['v18q1'].dropna().value_counts()","15e1be9d":"train_df.loc[(pd.isnull(train_df['v18q1'])), 'v18q1'] = 0","d6322f72":"train_df['rez_esc'].dropna().value_counts()","a955ed71":"# statistical measures of those with rez_esc\n\ntrain_df.loc[pd.notnull(train_df['rez_esc']),('age')].describe()","2c9157ef":"# statistical measures of those with missing rez_esc\n\ntrain_df.loc[pd.isnull(train_df['rez_esc']),('age')].describe()","f4eb1c10":"train_df.drop(columns='rez_esc', inplace = True)","37e563f8":"train_df.loc[pd.isnull(train_df['meaneduc']), ('edjefa', 'edjefe', 'escolari', 'meaneduc')]","f6e09387":"train_df.loc[pd.isnull(train_df['meaneduc']), 'meaneduc'] = train_df.loc[pd.isnull(train_df['meaneduc']), 'escolari']","0d125417":"train_df.loc[pd.isnull(train_df['SQBmeaned']), 'SQBmeaned'] = train_df.loc[pd.isnull(train_df['SQBmeaned']), 'meaneduc']**2","8b095b1b":"len(train_df.loc[train_df['age'] == 0].index)","618ba64f":"train_df = train_df.loc[train_df['age']!=0]","8a0a86b8":"msno.matrix(train_df[['v2a1', 'v18q1', 'meaneduc', 'SQBmeaned']], color = (0.211, 0.215, 0.274))\nplt.show()","3aa5db19":"train_df.groupby('dependency').size()","d2dcaf5e":"mode = train_df.loc[(train_df['dependency'] != 'yes') & (train_df['dependency'] != 'no'), 'dependency'].astype(float).mode()\nmode","12cfaca8":"def mutate_columns(df):\n    df.loc[df['dependency']=='no', 'dependency'] = 0\n    df.loc[df['dependency']=='yes', 'dependency'] = 0.5 # TODO computation of dependency\n    df['dependency'] = df['dependency'].astype('float16')\n    \n    #The same applies with edjefe and edjefa EXCEPT that the 'yes' value doesn't make any sense? Does it to you? \n    #Anyway, let's just impute meaneduc for 'yes' values\n    \n    df.loc[df['edjefe']=='no', 'edjefe'] = 0\n    df.loc[df['edjefe']=='yes', 'edjefe'] = df['meaneduc']\n    df['edjefe'] = df['edjefe'].astype('uint8')\n    \n    df.loc[df['edjefa']=='no', 'edjefa'] = 0\n    df.loc[df['edjefa']=='yes', 'edjefa'] = df['meaneduc']\n    df['edjefa'] = df['edjefa'].astype('uint8')","b972aa18":"mutate_columns(train_df)\nmutate_columns(test_df)","0a729ddd":"plt.figure(figsize = (10,5))\nsns.countplot(x='Target', data=train_df, palette=\"OrRd_r\")\nplt.xticks([0,1,2,3],['extreme poverty','moderate poverty','vulnerable households','non vulnerable households'])\nplt.xlabel('')\nplt.ylabel('')\nplt.title(\"Poverty Levels\", fontsize = 14)\n\nplt.show()","998293ec":"tdf = train_df[['Target']]\nn_train_df = train_df\nfor col in ['v18q', 'refrig', 'computer', 'television', 'mobilephone', 'v14a']:\n    n_train_df[col] = n_train_df[col].astype('category')\ndfcat = pd.get_dummies(n_train_df[[ 'v18q', 'refrig', 'computer', 'television', 'mobilephone', 'v14a']])\ndf_ = pd.concat([dfcat, tdf], axis=1)","36db8c80":"df_ = df_.groupby(['Target']).sum()\ndf_.reset_index(inplace = True)","4a175c80":"plt.figure(figsize=(12,4))\ngroups = ['extreme','moderate','vulnerable','non-vulnerable']\n\nordered_df = df_.sort_values(by='Target')\nmy_range=range(1,len(df_.index)+1)\n\n\nplt.scatter(ordered_df['v18q_1'], my_range, color='#0055a4', label='Present', s=200)\nplt.scatter(ordered_df['v18q_0'], my_range, color='#9b1d20' , label='Not present', s=200)\nplt.legend(loc = 4, prop={'size': 10})\nplt.hlines(y=my_range, xmin=ordered_df['v18q_1'], xmax=ordered_df['v18q_0'], alpha=0.5)\nplt.yticks(np.arange(1,5),groups)\nplt.xlabel(\"Number of household\")\nplt.title(\"Tablet ownership\", fontsize = 14)\nplt.show()\n\nplt.figure(figsize=(12, 4))\n\nplt.scatter(ordered_df['refrig_1'], my_range, color='#0055a4', label='Present', s=200)\nplt.scatter(ordered_df['refrig_0'], my_range, color='#9b1d20' , label='Not present', s=200)\nplt.legend(loc = 4, prop={'size': 10})\nplt.hlines(y=my_range, xmin=ordered_df['refrig_1'], xmax=ordered_df['refrig_0'], alpha=0.5)\nplt.yticks(np.arange(1,5),groups)\nplt.xlabel(\"Number of household\")\nplt.title(\"Refrigerator ownership\", fontsize = 14)\nplt.show()\n\nplt.figure(figsize=(12, 4))\n\nplt.scatter(ordered_df['computer_1'], my_range, color='#0055a4', label='Present', s=200)\nplt.scatter(ordered_df['computer_0'], my_range, color='#9b1d20' , label='Not present', s=200)\nplt.legend(loc = 4, prop={'size': 10})\nplt.hlines(y=my_range, xmin=ordered_df['computer_1'], xmax=ordered_df['computer_0'], alpha=0.5)\nplt.yticks(np.arange(1,5),groups)\nplt.xlabel(\"Number of household\")\nplt.title(\"Computer ownership\", fontsize = 14)\nplt.show()\n\nplt.figure(figsize=(12, 4))\n\nplt.scatter(ordered_df['television_1'], my_range, color='#0055a4', label='Present', s=200)\nplt.scatter(ordered_df['television_0'], my_range, color='#9b1d20' , label='Not present', s=200)\nplt.legend(loc = 4, prop={'size': 10})\nplt.hlines(y=my_range, xmin=ordered_df['television_1'], xmax=ordered_df['television_0'], alpha=0.5)\nplt.yticks(np.arange(1,5),groups)\nplt.xlabel(\"Number of household\")\nplt.title(\"Television ownership\", fontsize = 14)\nplt.show()\n\nplt.figure(figsize=(12, 4))\n\nplt.scatter(ordered_df['mobilephone_1'], my_range, color='#0055a4', label='Present', s=200)\nplt.scatter(ordered_df['mobilephone_0'], my_range, color='#9b1d20' , label='Not present', s=200)\nplt.legend(loc = 4, prop={'size': 10})\nplt.hlines(y=my_range, xmin=ordered_df['mobilephone_1'], xmax=ordered_df['mobilephone_0'], alpha=0.5)\nplt.yticks(np.arange(1,5),groups)\nplt.xlabel(\"Number of household\")\nplt.title(\"Mobile phone ownership\", fontsize = 14)\nplt.show()\n","f25d661d":"df_ = train_df[['Target', 'male', 'female', 'age']]\ndf_.loc[(train_df['male'] == 1), 'sex'] = 'male'\ndf_.loc[(train_df['female'] == 1), 'sex'] = 'female'\n\nplt.figure(figsize = (10,8))\nsns.violinplot(x='Target',y='age', data=df_, hue='sex', split=True)\nplt.xticks(np.arange(0,5),groups)\nplt.show()\n","70a62c7a":"plt.figure(figsize = (15,15))\ngs = gridspec.GridSpec(4, 2, hspace=0.3)\n\nplt.subplot(gs[0,0])\ng = sns.countplot(train_df['r4h3'], hue=train_df['Target'], color=\"#3274a1\")\nplt.title(\"Total males in a household\", fontsize = 14)\nplt.xlabel('')\nplt.ylabel('')\nlegend = g.get_legend()\nlegend.set_title(\"Income group\")\nnew_labels = ['extreme', 'moderate', 'vulnerable', 'non-vulnerable']\nfor t, l in zip(legend.texts, new_labels): t.set_text(l)\n\nplt.subplot(gs[0,1])\ng = sns.countplot(train_df['r4m3'], hue=train_df['Target'], color=\"#d32d41\")\nplt.title(\"Total females in a household\", fontsize = 14)\nplt.xlabel('')\nplt.ylabel('')\nlegend = g.get_legend()\nlegend.set_title(\"Income group\")\nnew_labels = ['extreme', 'moderate', 'vulnerable', 'non-vulnerable']\nfor t, l in zip(legend.texts, new_labels): t.set_text(l)\n\nplt.subplot(gs[1,0]) \nsns.countplot(train_df['r4h1'], hue=train_df['Target'], color=\"#3274a1\")\nplt.title(\"Males < 12 years old\", fontsize = 14)\nplt.xlabel('')\nplt.ylabel('')\nplt.legend('')\n\n\nplt.subplot(gs[1,1]) \nsns.countplot(train_df['r4m1'], hue=train_df['Target'], color=\"#d32d41\")\nplt.title(\"Females < 12 years old\", fontsize = 14)\nplt.xlabel('')\nplt.legend('')\n\nplt.subplot(gs[2,0]) \nsns.countplot(train_df['r4h2'], hue=train_df['Target'], color=\"#3274a1\")\nplt.title(\"Males >= 12 years old\", fontsize = 14)\nplt.xlabel('')\nplt.ylabel('')\nplt.legend('')\n\nplt.subplot(gs[2,1]) \nsns.countplot(train_df['r4m2'], hue=train_df['Target'], color=\"#d32d41\")\nplt.title(\"Females >= 12 years old\", fontsize = 14)\nplt.xlabel('')\nplt.ylabel('')\nplt.legend('')\n\nplt.show()","c2b43331":"df_q = train_df[['Target', 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3']]\ndf_q.loc[df_q['epared1'] == 1, 'wall'] = 'Bad'\ndf_q.loc[df_q['epared2'] == 1, 'wall'] = 'Regular'\ndf_q.loc[df_q['epared3'] == 1, 'wall'] = 'Good'\n\ndf_q.loc[df_q['etecho1'] == 1, 'roof'] = 'Bad'\ndf_q.loc[df_q['etecho2'] == 1, 'roof'] = 'Regular'\ndf_q.loc[df_q['etecho3'] == 1, 'roof'] = 'Good'\n\ndf_q.loc[df_q['eviv1'] == 1, 'floor'] = 'Bad'\ndf_q.loc[df_q['eviv2'] == 1, 'floor'] = 'Regular'\ndf_q.loc[df_q['eviv3'] == 1, 'floor'] = 'Good'\n\ndf_q = df_q[['Target', 'wall', 'roof', 'floor']]","0a3d6801":"print(\"Roof quality\")\nprint(\"==============================================================================================================================\")\ndf_q.loc[df_q['Target'] == 1, 'Target'] = 'Extreme'\ndf_q.loc[df_q['Target'] == 2,'Target'] = 'Moderate'\ndf_q.loc[df_q['Target'] == 3,'Target'] = 'Vulnerable'\ndf_q.loc[df_q['Target'] == 4,'Target'] = 'Non-Vulnerable'\nax = sns.catplot(x = 'roof', col = 'Target', data = df_q, kind=\"count\", col_order=['Extreme', 'Moderate', 'Vulnerable', 'Non-Vulnerable']).set_titles(\"{col_name}\")\nax.fig.set_size_inches(15,4)\nax.set(ylabel = '')\nplt.show()\n\nprint(\"Wall quality\")\nprint(\"==============================================================================================================================\")\n\nax = sns.catplot(x = 'wall', col = 'Target', data = df_q, kind=\"count\" ,col_order=['Extreme', 'Moderate', 'Vulnerable', 'Non-Vulnerable'], order = ['Bad', 'Regular', 'Good']).set_titles(\"{col_name}\")\nax.fig.set_size_inches(15,4)\nax.set(ylabel = '')\nplt.show()\n\nprint(\"Floor quality\")\nprint(\"==============================================================================================================================\")\n\nax = sns.catplot(x = 'floor', col = 'Target', data = df_q, kind=\"count\", col_order=['Extreme', 'Moderate', 'Vulnerable', 'Non-Vulnerable']).set_titles(\"{col_name}\")\nax.fig.set_size_inches(15,4)\nax.set(ylabel = '')\nplt.show()","a705eb3b":"# bars1 = [12, 28, 1, 8, 22]\n# bars2 = [28, 7, 16, 4, 10]\n# bars3 = [25, 3, 23, 25, 17]\n \n# # Heights of bars1 + bars2 (TO DO better)\n# bars = [40, 35, 17, 12, 32]\n \n# # The position of the bars on the x-axis\n# r = [0,1,2,3,4]\n \n# # Names of group and bar width\n# names = ['A','B','C','D','E']\n# barWidth = 1\n \n# # Create brown bars\n# plt.bar(r, bars1, color='#7f6d5f', edgecolor='white', width=barWidth)\n# # Create green bars (middle), on top of the firs ones\n# plt.bar(r, bars2, bottom=bars1, color='#557f2d', edgecolor='white', width=barWidth)\n# # Create green bars (top)\n# plt.bar(r, bars3, bottom=bars, color='#2d7f5e', edgecolor='white', width=barWidth)\n \n# # Custom X axis\n# plt.xticks(r, names, fontweight='bold')\n# plt.xlabel(\"group\")\n","16f88d7f":"plt.figure(figsize = (10,6))\nplt.subplot(111)\nsns.boxplot(x = 'Target', y = 'overcrowding', data = train_df)\nplt.title('Person per room')\nplt.xlabel('')\nplt.ylabel('')\nplt.xticks(np.arange(0,4), ['extreme','moderate','vulnerable','non-vulnerable'])\nplt.show()","5b8fac59":"temp_train = train_df\ntemp_test = test_df","3f677210":"train_df = temp_train\ntest_df = temp_test","208f6443":"def feature_engineer(x):\n    \n    x['refrig'] = x['refrig'].astype(int)\n    x['computer'] = x['computer'].astype(int)\n    x['television'] = x['television'].astype(int)\n    x['mobilephone'] = x['mobilephone'].astype(int)\n    x['v18q'] = x['v18q'].astype(int)\n    x['epared1'] = x['epared1'].astype(int)\n    x['epared2'] = x['epared2'].astype(int)\n    x['epared3'] = x['epared3'].astype(int)\n    x['etecho1'] = x['etecho1'].astype(int)\n    x['etecho2'] = x['etecho2'].astype(int)\n    x['etecho3'] = x['etecho3'].astype(int)\n    x['eviv1'] = x['eviv1'].astype(int)\n    x['eviv2'] = x['eviv2'].astype(int)\n    x['eviv3'] = x['eviv3'].astype(int)\n    x['abastaguadentro'] = x['abastaguadentro'].astype(int)\n    x['abastaguafuera'] = x['abastaguafuera'].astype(int)\n    x['abastaguano'] = x['abastaguano'].astype(int)\n    x['abastaguano'] = x['abastaguano'].astype(int)\n    x[['instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9']] = x[['instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9']].apply(pd.to_numeric)\n    \n    x['appliances'] = (x['refrig'] + x['computer'] + x['television'])\n\n    x['rent_by_hhsize'] = x['v2a1'] \/ x['hhsize'] # rent by household size\n    x['rent_by_people'] = x['v2a1'] \/ x['r4t3'] # rent by people in household\n    x['rent_by_rooms'] = x['v2a1'] \/ x['rooms'] # rent by number of rooms\n    x['rent_by_living'] = x['v2a1'] \/ x['tamviv'] # rent by number of persons living in the household\n    x['rent_by_minor'] = x['v2a1'] \/ x['hogar_nin']\n    x['rent_by_adult'] = x['v2a1'] \/ x['hogar_adul']\n    x['rent_by_dep'] = x['v2a1'] \/ x['dependency']\n    x['rent_by_head_educ'] = x['v2a1'] \/ (x['edjefe'] + x['edjefa'])\n    x['rent_by_educ'] = x['v2a1'] \/ x['meaneduc']\n    x['rent_by_numPhone'] = x['v2a1'] \/ x['qmobilephone']\n    x['rent_by_gadgets'] = x['v2a1'] \/ (x['computer'] + x['mobilephone'] + x['v18q'])\n    x['rent_by_num_gadgets'] = x['v2a1'] \/ (x['v18q1'] + x['qmobilephone'])\n    x['rent_by_appliances'] = x['v2a1'] \/ x['appliances']\n    \n    x['tablet_density'] = x['v18q1'] \/ x['r4t3']\n    x['phone_density'] = x['qmobilephone'] \/ x['r4t3']\n    \n    x['wall_qual'] = x['epared3'] - x['epared1']\n    x['roof_qual'] = x['etecho3'] - x['etecho1']\n    x['floor_qual'] = x['eviv3'] - x['eviv1']\n    x['water_qual'] = x['abastaguadentro'] - x['abastaguano']\n    \n    x['house_qual'] = x['wall_qual'] + x['roof_qual'] + x['floor_qual']\n    \n    x['person_per_room'] = x['hhsize'] \/ x['rooms']\n    x['person_per_appliances'] = x['hhsize'] \/ x['appliances']\n    \n    x['educ_qual'] = (1 * x['instlevel1']) + (2 * x['instlevel2']) + (3 * x['instlevel3']) + (4 * x['instlevel4']) + (5 * x['instlevel5']) + (6 * x['instlevel6']) + ( 7 * x['instlevel7']) + (8 * x['instlevel8']) + (9 * x['instlevel9'])\n    \n    def reverse_label_encoding(row, df):\n        for c in df.columns:\n            if row[c] == 1:\n                return int(c[-1])\n            \n    def rate_sanitary(row, df):\n        c = df.columns.tolist()[0]\n        \n        if row[c] == 'sanitario2':\n            return 3\n        elif row[c] == 'sanitario3':\n            return 2\n        elif row[c] == 'sanitario5':\n            return 1\n        else:\n            return 0\n        \n    def rate_cooking(row, df):\n        c = df.columns.tolist()[0]\n        \n        if row[c] == 'energcocinar2':\n            return 3\n        elif row[c] == 'energcocinar3':\n            return 2\n        elif row[c] == 'energcocinar4':\n            return 1\n        else:\n            return 0\n        \n    def rate_rubbish(row, df):\n        c = df.columns.tolist()[0]\n        \n        if row[c] == 'elimbasu1':\n            return 1\n        elif row[c] == 'elimbasu2':\n            return 2\n        else:\n            return 0\n            \n    x['sanitary'] = x.apply(lambda q: reverse_label_encoding(q, x[['sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6']]), axis=1)\n    x['cooking'] =  x.apply(lambda q: reverse_label_encoding(q, x[['energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4']]), axis=1)\n    x['rubbish'] = x.apply(lambda q: reverse_label_encoding(q, x[['elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6']]), axis=1)\n    x['region'] = x.apply(lambda q: reverse_label_encoding(q, x[['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']]), axis=1)\n    \n    x['sanitary_i'] = x.apply(lambda q: rate_sanitary(q, x[['sanitary']]), axis = 1)\n    x['cooking_i'] = x.apply(lambda q: rate_cooking(q, x[['cooking']]), axis = 1)\n    x['rubbish_i'] = x.apply(lambda q: rate_rubbish(q, x[['rubbish']]), axis = 1)\n    \n    x['zone'] = x['area1'] - x['area2']\n\n    x.replace([np.inf, -np.inf], 0, inplace = True)\n    x.fillna(0, inplace = True)","4bf011a2":"feature_engineer(train_df)\nfeature_engineer(test_df)","50ed9f8b":"# def agg_features(y):\n#     agg_feat = ['hacdor', 'v18q1', 'dis', 'r4h3', 'r4m3', 'age', 'hogar_nin', 'hogar_adul', 'hogar_total', 'dependency',\n#                 'appliances', 'phone_density', 'tablet_density', 'house_qual', 'person_per_appliances', 'educ_qual'\n#                ]\n#     # https:\/\/www.kaggle.com\/gaxxxx\/exploratory-data-analysis-lightgbm\n#     for group in ['idhogar', 'zone', 'region']:\n#         for feat in agg_feat:\n#             for agg_m in ['mean','sum']:\n#                 id_agg = y[feat].groupby(y[group]).agg(agg_m).reset_index()[[feat, group]]\n# #                 id_agg = y[feat].groupby(y[group]).agg(agg_m).reset_index()\n#                 new_col = feat + '_' + agg_m + '_' + group \n#                 id_agg.rename(columns = {feat : new_col} , inplace = True)\n#                 y = y.merge(id_agg, how = 'left', on = group)\n\n    \n#     drop_ = ['sanitary', 'cooking', 'rubbish', 'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n#             'sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6', 'elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6',\n#             'lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']\n    \n#     y.drop((drop_), inplace = True, axis = 1)\n#     y.replace([np.inf, -np.inf], 0, inplace = True)\n#     y.fillna(0, inplace = True)\n#     return y","4142e725":"def agg_features(y):\n    mean_list = ['rez_esc', 'dis', 'male', 'female', 'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', 'parentesco2',\n             'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', 'parentesco11', 'parentesco12']\n    o_list = ['escolari', 'age', 'escolari_age']\n        \n    for group in ['idhogar', 'zone', 'region']:\n        for feat in mean_list:\n            for agg_m in ['mean']:\n                id_agg = y[feat].groupby(y[group]).agg(agg_m)#.reset_index()[[feat, group]]\n#                 id_agg = y[feat].groupby(y[group]).agg(agg_m).reset_index()\n                new_col = feat + '_' + agg_m + '_' + group \n                #id_agg.rename(columns = {feat : new_col} , inplace = True)\n                #y = y.merge(id_agg, how = 'left', on = group)\n                y[new_col] = id_agg\n                \n    for item in o_list:\n        for agg_m in ['mean','std','min','max','sum']:\n            id_agg = y[feat].groupby(y[group]).agg(agg_m)#.reset_index()[[feat, group]]\n#                 id_agg = y[feat].groupby(y[group]).agg(agg_m).reset_index()\n            new_col = feat + '_' + agg_m + '_' + group \n                #id_agg.rename(columns = {feat : new_col} , inplace = True)\n                #y = y.merge(id_agg, how = 'left', on = group)\n            y[new_col] = id_agg\n                \n                \n    return y","80b7403f":"train_df = agg_features(train_df)\ntest_df = agg_features(test_df)\ntrain_df.fillna(value=0, inplace=True)","b195fde9":"train_df = train_df.loc[train_df['parentesco1'] == 1]","07a95e09":"y = train_df[['Target']]\nx = train_df.drop(['Target','Id','idhogar'], axis = 1)","800ceff2":"from sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb","8d03e8d1":"clf = RandomForestClassifier()\nclf.fit(x, y)\n\nimp = clf.feature_importances_\nname = np.array(x.columns.values.tolist())\n\n\ndf_imp = pd.DataFrame({'feature':name, 'importance':imp})\ndf_imp = df_imp.sort_values(by='importance', ascending=False)","df936bc6":"plt.figure(figsize=(8,20))\nsns.barplot(df_imp.loc[(df_imp['importance'] > 0.01),'importance'], y = df_imp.loc[(df_imp['importance'] > 0.01),'feature'])\nplt.title('Important features')\nplt.show()","e15de216":"important_cols = df_imp['feature']","d4053b13":"x_ = x[important_cols]\n# plt.figure(figsize = (20,16))\n# sns.heatmap(x_.corr(), cmap='YlOrRd')\n# plt.show()","3e13ca4b":"# x_ = x[['meaneduc', 'dependency', 'person_per_room', 'qmobilephone', 'overcrowding', 'hogar_nin', 'age', 'r4t2', 'rooms', 'cielorazo', 'r4h3', 'r4h2', 'r4m3', 'v2a1', 'rent_by_hhsize', 'r4t1', 'escolari', 'v18q', 'r4m1', 'bedrooms', 'edjefe', 'eviv3', 'epared3', 'hogar_adul', 'etecho3', 'r4m2', 'tamviv']]","2dcd08cf":"from sklearn.preprocessing import StandardScaler","d9dca40c":"# scaler = StandardScaler()\n# x_ = scaler.fit_transform(x_)","7170137c":"from sklearn.model_selection import train_test_split\n\nfeatures = [c for c in x_.columns if c not in ['Target']]\ntarget = train_df[['Target']]","1689b15b":"from imblearn.combine import SMOTETomek\nsmote_tomek = SMOTETomek(random_state=0)\nX_resampled, y_resampled = smote_tomek.fit_sample(x_, target)","e863ce0d":"sns.countplot(y_resampled)\nplt.show()","0932fb09":"X_train, X_valid, y_train, y_valid = train_test_split(X_resampled,  y_resampled, test_size=0.1, random_state=1)","ec28b0db":"print(\"foo\")","f0e54449":"import xgboost as xgb","0a091935":"model = xgb.XGBClassifier( objective='multiclass', n_jobs=4, n_estimators=5000, class_weight='balanced', learning_rate=0.1, scale_pos_weight = 1).fit(X_resampled, y_resampled.ravel())\ny_trainpred_xg = model.predict(X_train)\ny_testpred_xg = model.predict(X_valid)","d54d7c9c":"def evaluate(y_train, y_valid, y_trainpred, y_testpred):\n    from sklearn.metrics import mean_absolute_error\n    from sklearn.metrics import accuracy_score\n    from sklearn.metrics import confusion_matrix\n    from sklearn.metrics import f1_score\n\n    print(\"MAE :: \", mean_absolute_error(y_train, y_trainpred))\n    print(\"Train Accuracy :: \", accuracy_score(y_train, y_trainpred)*100) \n    print(\"Test Accuracy  :: \", accuracy_score(y_valid, y_testpred) * 100)\n    print(\"Confusion matrix :: \\n\", confusion_matrix(y_valid, y_testpred))","acc7c795":"evaluate(y_train, y_valid, y_trainpred_xg, y_testpred_xg)","ddb9566a":"predict = model.predict(test_df[features].values)","84afb658":"predict.shape","e51ed03e":"submission = pd.DataFrame()\nsubmission['Id'] = test_df['Id']\nsubmission['Target'] = predict","378526bb":"submission.to_csv('submissions.csv', index=False)","96d29629":"### Feature Scaling","bfeab950":"For meaneduc let's just copy escolari (years of education) to the meaneduc","6fe94f76":"We could predict the age of this rows, but that would be on a different Kernel. Let's delete these rows for the meantime","9ca24edb":"You could see above that dependency column contains numerical values and 'no' and 'yes'. <br>\nFor the 'no' values let's impute zero, while for 'yes' let's impute the mode or the most frequent value.","35e50035":"#### House quality","4d90665c":"## Data Exploration","6dae5834":"## Modelling","4fdb43a5":"### Sampling and splitting","74b0d702":"We could infer from the table above that those with 'Years behind school' data are teenagers and kids with ages 7-17 and those with missing values are much older. This may be due to older people can't remember how many years they are behind already. Unfortunately, we may not be able to perform proper treatment on the missing values of this column, so let's drop this column.\n<hr>\nAlso, the minimum value of age for those with missing rez_esc is zero. I'll have to deal with that later","f47b619c":"First thing that we would like to do is to apply proper treatment on these missing values.","3dd285e8":"### Feature selection","915b3b8a":"#### rez_esc column","54257575":"meaneduc is defined as average years of education for adults (18+)","27ec8c46":"#### v18q1 column","b16c56b3":"SQBmeaned is just square of meaneduc","cb7d333b":"**Unfortunatelly for some reason, I cannot install the latest version of seaborn in this kernel which has the catplot. Please leave a comment if you know the answer to this problem of mine.**","f8a0a247":"#### Overcrowding problem ","9784ed0d":"--# This is a BEGINNER'S kernel, please go easy on me. Your comments, suggestions and tips will be highly appreciated and if you liked this kernel please upvote. Thank you very much.","22fe0ff2":"### Feature engineering","1299949c":"### Uniform values","cb239f74":"### Training and validation","eb4fb774":"Yikes! There are zero values already. Let's investigate further","5df7e210":"#### v2a1 column <a id = 'v2a1_c'><\/a>","cf96c70d":"#  Costa Rican Household : EDA - Feature Selection - Prediction","a3b27984":"#### XGboost","7b166464":"#### meaneduc column","7e5eda1f":"#### The target!","351983e4":"We wan't our variables to be in uniform, meaning if it's numeric, then keep it numeric afterall predictive models only understand numeric values.","9aa5e450":"v18q1 is defined as the number of tablets household owns. It looks too easy that these missing values are 'zeros', hmmmm just to make sure I will check the value counts for v18q1","09a8b68a":"### Missing values","593653c7":"As your income group goes up, so is your age. <br>\nA lot of data under age 20 for the extreme, moderate, and vulnerable income groups. Non-vulnerable on the other hand contains a lot of data with over 20 years of age.","64ab0c31":"Let's do an investigation regarding the missing values from these columns","29aa0809":"Let us remove the remaining missing values for now. ","80917647":"We're done imputing missing values here is the summary:\n<ol>\n    <li>We've imputed zero values for v2a1 pertaining that a household does not have a monthly rent because they own the house.<\/li>\n    <li>We've also imputed zero values for v18q1. Not everyone owns a tablet at their homes.<\/li>\n    <li>Unfortunately, we've removed rez_vec because it has too much missing values and imputation is not ideal even more so deletion of rows.<\/li>\n    <li>While exploring rez_vec, we've noticed zero values on the age column, this is not possible so for the meantime we've removed those rows.<\/li>\n    <li>meaneduc column is imputed by the value of escolari (years of education). And SQBmeaned is computed <\/li>\n<\/ol>","d90425dc":"----- TO be continued","78ed8e5f":"#### Age column","b53551e3":"#### Services","5c71fb4d":"#### SQBmeaned column","40c0da0c":"Most of the missing monthly rent payment already owns the house, let's impute zero on these rows","76734bbe":"#### Ownership by income group","7d6306f5":"Our target variable is named Target, duhh. Let's explore our target variable","569de76a":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-Exploration\" data-toc-modified-id=\"Data-Exploration-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Data Exploration<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Missing-values\" data-toc-modified-id=\"Missing-values-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;<\/span>Missing values<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#v2a1-column-\" data-toc-modified-id=\"v2a1-column--1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;<\/span>v2a1 column <a id=\"v2a1_c\"><\/a><\/a><\/span><\/li><li><span><a href=\"#v18q1-column\" data-toc-modified-id=\"v18q1-column-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;<\/span>v18q1 column<\/a><\/span><\/li><li><span><a href=\"#rez_esc-column\" data-toc-modified-id=\"rez_esc-column-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;<\/span>rez_esc column<\/a><\/span><\/li><li><span><a href=\"#meaneduc-column\" data-toc-modified-id=\"meaneduc-column-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;<\/span>meaneduc column<\/a><\/span><\/li><li><span><a href=\"#SQBmeaned-column\" data-toc-modified-id=\"SQBmeaned-column-1.1.5\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;<\/span>SQBmeaned column<\/a><\/span><\/li><li><span><a href=\"#Age-column\" data-toc-modified-id=\"Age-column-1.1.6\"><span class=\"toc-item-num\">1.1.6&nbsp;&nbsp;<\/span>Age column<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Uniform-values\" data-toc-modified-id=\"Uniform-values-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;<\/span>Uniform values<\/a><\/span><\/li><li><span><a href=\"#Variable-analysis\" data-toc-modified-id=\"Variable-analysis-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;<\/span>Variable analysis<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#The-target!\" data-toc-modified-id=\"The-target!-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;<\/span>The target!<\/a><\/span><\/li><li><span><a href=\"#Ownership-by-income-group\" data-toc-modified-id=\"Ownership-by-income-group-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;<\/span>Ownership by income group<\/a><\/span><\/li><li><span><a href=\"#Sex-(the-gender)-and-age-by-income-group\" data-toc-modified-id=\"Sex-(the-gender)-and-age-by-income-group-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;<\/span>Sex (the gender) and age by income group<\/a><\/span><\/li><li><span><a href=\"#House-quality\" data-toc-modified-id=\"House-quality-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;<\/span>House quality<\/a><\/span><\/li><li><span><a href=\"#Services\" data-toc-modified-id=\"Services-1.3.5\"><span class=\"toc-item-num\">1.3.5&nbsp;&nbsp;<\/span>Services<\/a><\/span><\/li><li><span><a href=\"#Overcrowding-problem\" data-toc-modified-id=\"Overcrowding-problem-1.3.6\"><span class=\"toc-item-num\">1.3.6&nbsp;&nbsp;<\/span>Overcrowding problem<\/a><\/span><\/li><\/ul><\/li><\/ul><\/li><li><span><a href=\"#Modelling\" data-toc-modified-id=\"Modelling-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Modelling<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Feature-engineering\" data-toc-modified-id=\"Feature-engineering-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;<\/span>Feature engineering<\/a><\/span><\/li><li><span><a href=\"#Feature-selection\" data-toc-modified-id=\"Feature-selection-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;<\/span>Feature selection<\/a><\/span><\/li><li><span><a href=\"#Feature-Scaling\" data-toc-modified-id=\"Feature-Scaling-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;<\/span>Feature Scaling<\/a><\/span><\/li><li><span><a href=\"#Sampling-and-splitting\" data-toc-modified-id=\"Sampling-and-splitting-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;<\/span>Sampling and splitting<\/a><\/span><\/li><li><span><a href=\"#Training-and-validation\" data-toc-modified-id=\"Training-and-validation-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;<\/span>Training and validation<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#XGboost\" data-toc-modified-id=\"XGboost-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;<\/span>XGboost<\/a><\/span><\/li><\/ul><\/li><\/ul><\/li><li><span><a href=\"#Submission\" data-toc-modified-id=\"Submission-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Submission<\/a><\/span><\/li><li><span><a href=\"#Summary,-conclusion-and-recommendation\" data-toc-modified-id=\"Summary,-conclusion-and-recommendation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>Summary, conclusion and recommendation<\/a><\/span><\/li><\/ul><\/div>","4056b9b2":"SQBmeaned and meaneduc are highly correlated with each other, so we will just use meaneduc. The same with SQBovercrowding and overcrowding, just use overcrowding. hogar_nin is selected ahead of SQBhogar_nin, age ahead of SQBage and agesq, escolari ahead of SQBescolari, v2a1 ahead of rent_by_rooms. tamhog, tamviv, r4t3 and SQBhogar_total, hhsize are highly correlated with each other let's use tamviv because it has higher importance.\n<hr>\nActually, just kidding XGBosst is immune to multicollinearity.","f4c11545":"https:\/\/www.kaggle.com\/grfiv4\/plotting-feature-importances","b1d23734":"For selecting the most appopriate columns for our model we will perform two operations. <br>\n<ol>\n    <li>Random Forest for feature importance<\/li>\n    <li>Eliminate highly correlated values<\/li>\n<\/ol>","15c00d79":"<b>Background:<\/b>\n\nMany social programs have a hard time making sure the right people are given enough aid. It\u2019s especially tricky when a program focuses on the poorest segment of the population. The world\u2019s poorest typically can\u2019t provide the necessary income and expense records to prove that they qualify.\n \nBeyond Costa Rica, many countries face this same problem of inaccurately assessing social need. If Kagglers can generate an improvement, the new algorithm could be implemented in other countries around the world.\n\nTo address this problem we will try to find an optimal solution to classify the income group of families based on household attributes attributes like the material of their walls and ceiling, or the assets found in the home to classify them and predict their level of need. ","2ef2c81d":"No zero value, which means the missing values really means zero tablets owned.","b3febdad":"There seems to be a big imbalance in our data, we may want to apply sampling later on.","61deebcf":"rez_esc is defined as the Years behind in school. As usual let's check for the value count","e4ccafea":"## Summary, conclusion and recommendation","6affe96a":"v2a1 is defined as the monthly rent payment of the household. I will assume that those with missing values of v2a1 already owns the house, let's investigate how many of those missing values already owns the house using the tipovivi1 column.","4bd56063":"### Variable analysis","c9906eda":"For now let us focus on the training data.","4632f41e":"That's a lot of column, we may want to remove some of them later","91d129ca":"#### Sex (the gender) and age by income group","06ccad27":"## Submission"}}