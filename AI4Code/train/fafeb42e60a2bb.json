{"cell_type":{"842a6c52":"code","1a3832d4":"code","59ec7b41":"code","9e2a2b19":"code","d43a4f81":"code","eb25b292":"code","1da27362":"code","5bbb7143":"code","b8962b59":"code","7839e040":"code","b86a950b":"code","aa23bc96":"code","418690ad":"code","c9efa889":"code","87b69c15":"code","d8a7d89d":"code","3cb91ceb":"code","d46b77d1":"code","f7f05280":"code","487fe9d8":"code","27d58297":"code","847d9f8d":"code","d0425ec0":"code","48005726":"code","abd76044":"code","17c1ebea":"code","c6830caf":"code","d08bcb30":"code","b01ce1b1":"code","d8a47d11":"code","525747cf":"code","97be2b57":"code","702b3fb0":"code","a369010c":"code","adc31fa4":"code","a99d5288":"code","cc9f1c59":"code","88e03197":"code","2b26db03":"code","21861cdc":"code","26f40872":"code","c06b2821":"code","f367b07e":"markdown","522a1e04":"markdown","c9728881":"markdown","f17a5704":"markdown","2f2348da":"markdown","4622233a":"markdown","263b8468":"markdown","bdb8da94":"markdown","96bb3eec":"markdown","adb7c221":"markdown","7eeebe49":"markdown","29505c57":"markdown","5b573d3b":"markdown","c999e90e":"markdown","8c13cc89":"markdown","a7354953":"markdown","f3e1252c":"markdown","f190af02":"markdown","5b03f8a8":"markdown","6c766e1c":"markdown","b011b8ab":"markdown","4197ddf0":"markdown","ccba970e":"markdown","8fb20b51":"markdown","197ed554":"markdown","7759c506":"markdown","a28cf6bc":"markdown","3b690d1f":"markdown","abe6b60b":"markdown","fe395c65":"markdown","4ca06884":"markdown","c1241e84":"markdown","7c1abdb7":"markdown","9e8ff97d":"markdown","04cd2092":"markdown","ac544b9e":"markdown","91134bd7":"markdown","0dd7aff5":"markdown","5a3b5fe3":"markdown","d7edb031":"markdown","b2b04a5b":"markdown","76bf8760":"markdown","e052bf71":"markdown","ac2406e5":"markdown"},"source":{"842a6c52":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nfrom sklearn.metrics import mean_squared_error","1a3832d4":"#Import the data set\ndf = pd.read_csv('ratings_Electronics.csv', header=None) #There are no headers in the data file\n\ndf.columns = ['user_id', 'prod_id', 'rating', 'timestamp'] #Adding column names\n\ndf = df.drop('timestamp', axis=1) #Dropping timestamp\n\ndf_copy = df.copy(deep=True) #Copying the data to another dataframe","59ec7b41":"# see few rows of the imported dataset\ndf.head()","9e2a2b19":"# Check the number of rows and columns\nrows, columns = df.shape\nprint(\"No of rows: \", rows) \nprint(\"No of columns: \", columns) ","d43a4f81":"#Check Data types\ndf.info()","eb25b292":"# Find number of missing values in each column\ndf.isna().sum()","1da27362":"# Summary statistics of 'rating' variable\ndf.describe()","5bbb7143":"#Create the plot and provide observations\n\nplt.figure(figsize = (12,6))\ndf['rating'].value_counts(1).plot(kind='bar')\nplt.xlabel('Rating')\n\nplt.ylabel('provide observations')\nplt.show()","b8962b59":"# Number of unique user id and product id in the data\nprint('Number of unique USERS in Raw data = ', df['user_id'].nunique())\nprint('Number of unique ITEMS in Raw data = ', df['prod_id'].nunique())","7839e040":"# Top 10 users based on rating\nmost_rated = df.groupby('user_id').size().sort_values(ascending=False)[:10]\nmost_rated","b86a950b":"counts = df['user_id'].value_counts()\ndf_final = df[df['user_id'].isin(counts[counts >= 50].index)]","aa23bc96":"print('The number of observations in the final data =', len(df_final))\nprint('Number of unique USERS in the final data = ', df_final['user_id'].nunique())\nprint('Number of unique PRODUCTS in the final data = ', df_final['prod_id'].nunique())","418690ad":"#Creating the interaction matrix of products and users based on ratings and replacing NaN value with 0\nfinal_ratings_matrix = df_final.pivot(index = 'user_id', columns ='prod_id', values = 'rating').fillna(0)\nprint('Shape of final_ratings_matrix: ', final_ratings_matrix.shape)\n\n#Finding the number of non-zero entries in the interaction matrix \ngiven_num_of_ratings = np.count_nonzero(final_ratings_matrix)\nprint('given_num_of_ratings = ', given_num_of_ratings)\n\n#Finding the possible number of ratings as per the number of users and products\npossible_num_of_ratings = final_ratings_matrix.shape[0] * final_ratings_matrix.shape[1]\nprint('possible_num_of_ratings = ', possible_num_of_ratings)\n\n#Density of ratings\ndensity = (given_num_of_ratings\/possible_num_of_ratings)\ndensity *= 100\nprint ('density: {:4.2f}%'.format(density))\n\nfinal_ratings_matrix.head()","c9efa889":"#Calculate the average rating for each product \naverage_rating = df_final.groupby('prod_id').mean()['rating']\n\n#Calculate the count of ratings for each product\ncount_rating = df_final.groupby('prod_id').count()['rating']\n\n#Create a dataframe with calculated average and count of ratings\nfinal_rating = pd.DataFrame({'avg_rating':average_rating, 'rating_count':count_rating})\n\n#Sort the dataframe by average of ratings\nfinal_rating = final_rating.sort_values(by='avg_rating', ascending=False)\n\nfinal_rating.head()","87b69c15":"#defining a function to get the top n products based on highest average rating and minimum interactions\ndef top_n_products(final_rating, n, min_interaction):\n    \n    #Finding movies with minimum number of interactions\n    recommendations = final_rating[final_rating['rating_count'] > min_interaction]\n    \n    #Sorting values w.r.t average rating \n    recommendations = recommendations.sort_values(by='avg_rating', ascending=False)\n    \n    return recommendations.index[:n]","d8a7d89d":"list(top_n_products(final_rating, 5, 50))","3cb91ceb":"list(top_n_products(final_rating, 5, 100))","d46b77d1":"final_ratings_matrix.head()","f7f05280":"final_ratings_matrix['user_index'] = np.arange(0, final_ratings_matrix.shape[0])\nfinal_ratings_matrix.set_index(['user_index'], inplace=True)\n\n# Actual ratings given by users\nfinal_ratings_matrix.head()","487fe9d8":"# defining a function to get similar users\ndef similar_users(user_index, interactions_matrix):\n    similarity = []\n    for user in range(0, interactions_matrix.shape[0]):\n        \n        #finding cosine similarity between the user_id and each user\n        sim = cosine_similarity([interactions_matrix.loc[user_index]], [interactions_matrix.loc[user]])\n        \n        #Appending the user and the corresponding similarity score with user_id as a tuple\n        similarity.append((user, sim))\n        \n    similarity.sort(key=lambda x: x[1], reverse=True)\n    most_similar_users = [tup[0] for tup in similarity] #Extract the user from each tuple in the sorted list\n    similarity_score = [tup[1] for tup in similarity]  ##Extracting the similarity score from each tuple in the sorted list\n   \n    #Remove the original user and its similarity score and keep only other similar users \n    most_similar_users.remove(user_index) \n    similarity_score.remove(similarity_score[0])\n       \n    return most_similar_users, similarity_score","27d58297":"similar = similar_users(3, final_ratings_matrix)[0][0:10]\nsimilar","847d9f8d":"#Print the similarity score\nsimilar_users(3, final_ratings_matrix)[1][0:10]","d0425ec0":"similar = similar_users(1521, final_ratings_matrix)[0][0:10]\nsimilar","48005726":"#Print the similarity score\nsimilar_users(1521, final_ratings_matrix)[1][0:10]","abd76044":"# defining the recommendations function to get recommendations by using the similar users' preferences\ndef recommendations(user_index, num_of_products, interactions_matrix):\n    \n    #Saving similar users using the function similar_users defined above\n    most_similar_users = similar_users(user_index, interactions_matrix)[0]\n    \n    #Finding product IDs with which the user_id has interacted\n    prod_ids = set(list(interactions_matrix.columns[np.where(interactions_matrix.loc[user_index] > 0)]))\n    recommendations = []\n    \n    observed_interactions = prod_ids.copy()\n    for similar_user in most_similar_users:\n        if len(recommendations) < num_of_products:\n            \n            #Finding 'n' products which have been rated by similar users but not by the user_id\n            similar_user_prod_ids = set(list(interactions_matrix.columns[np.where(interactions_matrix.loc[similar_user] > 0)]))\n            recommendations.extend(list(similar_user_prod_ids.difference(observed_interactions)))\n            observed_interactions = observed_interactions.union(similar_user_prod_ids)\n        else:\n            break\n    \n    return recommendations[:num_of_products]","17c1ebea":"recommendations(3, 5, final_ratings_matrix)","c6830caf":"recommendations(1521, 5, final_ratings_matrix)","d08bcb30":"from scipy.sparse.linalg import svds # for sparse matrices\n\n# Singular Value Decomposition\nU, s, Vt = svds(final_ratings_matrix, k = 50) # here k is the number of latent features\n\n# Construct diagonal array in SVD\nsigma = np.diag(s)","b01ce1b1":"U.shape #checking the shape of the U matrix","d8a47d11":"sigma.shape #checking the shape of the sigma matrix","525747cf":"Vt.shape #checking the shape of the Vt matrix","97be2b57":"all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \n\n# Predicted ratings\npreds_df = pd.DataFrame(abs(all_user_predicted_ratings), columns = final_ratings_matrix.columns)\npreds_df.head()","702b3fb0":"# Recommend the items with the highest predicted ratings\n\ndef recommend_items(user_index, interactions_matrix, preds_df, num_recommendations):\n    \n    # Get and sort the user's ratings from the actual and predicted interaction matrix\n    sorted_user_ratings = interactions_matrix.loc[user_index].sort_values(ascending=False)\n    sorted_user_predictions = preds_df.loc[user_index].sort_values(ascending=False)\n\n    #Creating a dataframe with actual and predicted ratings columns\n    temp = pd.concat([sorted_user_ratings, sorted_user_predictions], axis=1)\n    temp.index.name = 'Recommended Products'\n    temp.columns = ['user_ratings', 'user_predictions']\n    \n    #Filtering the dataframe where actual ratings are 0 which implies that the user has not interacted with that product\n    temp = temp.loc[temp.user_ratings == 0]   \n    \n    #Recommending products with top predicted ratings\n    temp = temp.sort_values('user_predictions', ascending=False) #Sort the dataframe by user_predictions in descending order\n    print('\\nBelow are the recommended products for user(user_id = {}):\\n'.format(user_index))\n    print(temp['user_predictions'].head(num_recommendations))","a369010c":"#Enter 'user index' and 'num_recommendations' for the user\nrecommend_items(121, final_ratings_matrix, preds_df, 5)","adc31fa4":"#Enter 'user_index' and 'num_recommendations' for the user #\nrecommend_items(465, final_ratings_matrix, preds_df, 5)","a99d5288":"# Actual ratings given by the users\nfinal_ratings_matrix.head()","cc9f1c59":"# Find average actual rating for each item\naverage_actual_rating=final_ratings_matrix.mean(axis=0)\naverage_actual_rating","88e03197":"# Predicted ratings \npreds_df.head()","2b26db03":"# Find average predicted rating for each item\naverage_predicted_rating=preds_df.mean(axis=0)\naverage_predicted_rating","21861cdc":"#create a dataframe containing average actual ratings and avearge predicted ratings for each product\nrmse_df = pd.concat([average_actual_rating, average_predicted_rating], axis=1)\n\nrmse_df.columns = ['Avg_actual_ratings', 'Avg_predicted_ratings']\n\nrmse_df.head()","26f40872":"#Calculate and print RMSE using the mean_square_error function\nRMSE = mean_squared_error(rmse_df['Avg_actual_ratings'], rmse_df['Avg_predicted_ratings'], squared=False)\nprint('\\nRMSE SVD Model = {} \\n'.format(RMSE))","c06b2821":"# Enter 'user_index' and 'num_recommendations' for the user #\nrecommend_items(100, final_ratings_matrix, preds_df, 10)","f367b07e":"We have found similar users for a given user. Now, let's create **a function to recommend products** to the user using the ratings given by similar users.","522a1e04":"#### Checking the rating distribution\n\nCheck the distribution of ratings and **provide observations** from the plot ","c9728881":"### Data preparation  (1 mark)","f17a5704":"#### Recommending top 5 products with 50 minimum interactions based on popularity","2f2348da":"- The highest number of ratings by a user is 520 which is far from the actual number of products present in the data. We can build a recommendation system to recommend products to users which they have not interacted with.","4622233a":"#### Checking the number of unique users and items in the dataset","263b8468":"**We have seen above that the interaction matrix is highly sparse. SVD is best to apply on a large sparse matrix. Note that for sparse matrices, we can use the sparse.linalg.svds() function to perform the decomposition**\n\nAlso, we will use **k=50 latent features** to predict rating of products","bdb8da94":"### Evaluate the model (10 marks)","96bb3eec":"#### Recommending top 5 products with 100 minimum interactions based on popularity","adb7c221":"#### Data types","7eeebe49":"#### Evaluation of the Model based Collaborative Filtering (SVD)","29505c57":"#### Recommend top 10 products to the user id 100","5b573d3b":"### Recommendation (2 marks)","c999e90e":"#### Shape of the data","8c13cc89":"**Conclusion: - The **RMSE is low** which implies that the majority of **predicted ratings are close to the actual ratings**.**","a7354953":"We have the prediction of ratings but we need to create a **function to recommend products** to the users on the basis of predicted ratings for each product","f3e1252c":"### Exploratory Data Analysis (5 marks)","f190af02":"#### Checking for missing values","5b03f8a8":"### Model based Collaborative Filtering: Singular Value Decomposition  (15 marks)","6c766e1c":"#### Finding out top 10 similar users to the user index 1521 and their similarity score","b011b8ab":"We have recommended the top 5 products by using popularity recommendation system. Now, let's build a recommendation system using collaborative filtering","4197ddf0":"**Recommending the 5 products to user index 465**","ccba970e":"**Let's take a subset of the dataset (by only keeping the users who have given 50 or more ratings) to make the dataset less sparse and easy to work with.**","8fb20b51":"We have applied two technique to recommend products to users. Now, let's build one more recommendation system using matrix factorization (SVD).","197ed554":"- The dataframe **df_final has users who have rated 50 or more items**\n- **We will use df_final to build recommendation systems**","7759c506":"### Conclusion (2 marks)","a28cf6bc":"#### Recommend 5 products to user index 3 based on similarity based collaborative filtering","3b690d1f":"#### Recommend 5 products to user index 1521 based on similarity based collaborative filtering","abe6b60b":"### Collaborative Filtering based Recommendation System (15 marks)","fe395c65":"**Here, user_id (index) is of the object data type. We will replace the user_id by numbers starting from 0 to 1539 (for all user ids) so that the index is of integer type and represents a user id in the same format**","4ca06884":"### Importing Libraries","c1241e84":"# Project- Recommendation Systems: Amazon product reviews\n\nOnline E-commerce websites like Amazon, Flipkart uses different recommendation models to provide personalized suggestions to different users. Amazon currently uses item-to-item collaborative filtering, which scales to massive data sets and produces high-quality recommendations in real-time.\n\n----------------\n### Objective:\n----------------\n\nBuild a recommendation system to recommend products to customers based on their previous ratings for other products.\n\n--------------\n### Dataset:\n--------------\n\nThe Amazon dataset contains the following attributes:\n\n- **userId:** Every user identified with a unique id\n- **productId:** Every product identified with a unique id\n- **Rating:** Rating of the corresponding product by the corresponding user\n- **timestamp:** Time of the rating (ignore this column for this exercise)","7c1abdb7":"Now that we have explored and preprocessed the data, let's build the first recommendation system","9e8ff97d":"**Recommending top 5 products to user id 121**","04cd2092":"### Loading data","ac544b9e":"#### Checking the density of the rating matrix","91134bd7":"Now, let's regenerate the original matrix using U, Sigma, and Vt matrices. The resulting matrix would be the predicted ratings for all users and products","0dd7aff5":"Now, let's define a **function to get similar users** for a particular user","5a3b5fe3":"- Even with the subset of users and products, the current number of ratings is just **0.17%** of the possible number of ratings. This implies that the data is **highly sparse**.\n- We will build recommendation systems to recommend products to users with which they have not interacted.","d7edb031":"#### Summary Statistics","b2b04a5b":"#### Users with most number of ratings","76bf8760":"#### Finding out top 10 similar users to the user index 3 and their similarity score","e052bf71":"### Rank Based Recommendation System (10 marks)","ac2406e5":"- There are **42,01,696 users and 4,76,002 products** in the dataset"}}