{"cell_type":{"d66d8c27":"code","84caa877":"code","265af74a":"code","f122aa31":"code","2e104847":"code","2f66cb60":"code","c558e547":"code","f8222bb0":"code","389a76ef":"code","d4a807c4":"code","0a6c21d2":"code","005a8cd2":"code","c6112265":"code","40c9b60f":"code","eb55e8c7":"code","b0bfac2c":"code","0f433da9":"code","7a4ee349":"code","325c66b4":"code","b31bf7c1":"markdown","33246a29":"markdown","530a41c9":"markdown","7b08fdf8":"markdown","4c760698":"markdown","d7dfbfb3":"markdown","4f96b950":"markdown","9a41a5ba":"markdown","35548161":"markdown","ba40670b":"markdown","f0ec67cf":"markdown","444237eb":"markdown","8538319a":"markdown","56a29ecc":"markdown"},"source":{"d66d8c27":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import rcParams","84caa877":"plt.rcParams['figure.figsize'] = (15,16)\nsns.set_theme(style=\"darkgrid\")","265af74a":"df = pd.read_csv('..\/input\/house-price-dataset-with-other-information\/kc_house_data.csv')\ndf","f122aa31":"df.isnull().values.any()","2e104847":"df  = df.drop('date', 1)\ndf","2f66cb60":"sns.heatmap(df.corr(), annot=True, fmt=\".2f\")\nplt.show()","c558e547":"from sklearn import  linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nimport xgboost","f8222bb0":"X = df.loc[:, df.columns != 'price']\ny = df[['price']]","389a76ef":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)","d4a807c4":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)","0a6c21d2":"scaler.fit(X_test)\nX_test = scaler.transform(X_test)","005a8cd2":"regression = linear_model.LinearRegression()\nregression.fit(X_train, y_train)\n","c6112265":"y_pred = regression.predict(X_test)\nprint('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))","40c9b60f":"import torch\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport torch.utils.data as Data","eb55e8c7":"class Net(torch.nn.Module):\n    def __init__(self, n_feature, n_hidden, n_output):\n        super(Net, self).__init__()\n        self.fc1 = torch.nn.Linear(n_feature, n_hidden)\n        self.fc2 = torch.nn.Linear(n_hidden, n_hidden)\n        self.fc3 = torch.nn.Linear(n_hidden, n_hidden)\n        self.fc4 = torch.nn.Linear(n_hidden, n_output)   \n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)     \n        return x","b0bfac2c":"net = Net(n_feature=len(df.columns)-1, n_hidden=32, n_output=1)    \nprint(net)  # net architecture\noptimizer = torch.optim.Adam(net.parameters(), lr=0.01)\nloss_func = torch.nn.MSELoss()  ","0f433da9":"X_train, X_test = torch.tensor(X_train).float(), torch.tensor(X_test).float()\ny_train, y_test = torch.tensor(y_train.values).float(), torch.tensor(y_test.values).float()","7a4ee349":"running_loss = 0\n\nfor epoch in range(10):\n    for i in range(len(X_train)):\n        prediction = net(X_train[i])     # input x and predict based on x\n        loss = loss_func(prediction, y_train[i])     # must be (1. nn output, 2. target)\n\n        optimizer.zero_grad()   # clear gradients for next train\n        loss.backward()         # backpropagation, compute gradients\n        optimizer.step()        # apply gradients\n\n        running_loss += loss.item()\n        if i % 15000 == 14999:    # print every 15000 items\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss \/ 15000))\n            running_loss = 0","325c66b4":"print('Coefficient of determination: %.2f' % r2_score(y_test, net(X_test).data.numpy()))","b31bf7c1":"We'll use MSELoss to calculate the loss and Adam as the optimizer","33246a29":"To measure the accuracy, we'll use r2 score. For more info about how it is calculated, check https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.r2_score.html","530a41c9":"Split the data, with 30% test set.","7b08fdf8":"We can try something a little more robust.\n# Neural Network\n\nNow we'll use pytorch to create a neural network to predict the housing prices.","4c760698":"Now the training. We'll have 10 epochs. The code below has some comments to indicate what it is doing.","d7dfbfb3":"The results are better, but there is definitely some room for improvements","4f96b950":"Converting the data to tensors, so pytorch can use it.","9a41a5ba":"Let's check how correlated the features are:","35548161":"# EDA, Linear and Neural Network\n\nIn this notebook we will explore the data, run a linear regression and use a neural network to do a more robust regression.","ba40670b":"There is definitely some correlation, especially with the 'squarefeet' features.\n\n# Linear Regression\n\nOur first try to predict the house prices will be a simple Linear Regression. For this, we'll use sklearn.","f0ec67cf":"Now we fit the data to the Linear model.","444237eb":"Here, we define our neural net. It has 4 layers, with 32 neurouns in each hidden layer. The activation used was Relu.","8538319a":"Checking if there is any null value, and dropping the date column, because we will not use it.","56a29ecc":"Now we will normalize the data"}}