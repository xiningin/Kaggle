{"cell_type":{"cdd00171":"code","abeb2d68":"code","ab779904":"code","62baca74":"code","34aa78b9":"code","af57db5b":"code","713ff6f5":"code","159a4977":"code","6bcb769b":"code","6643418b":"code","269eea49":"code","a0b012f4":"code","122bd759":"code","54f2cef1":"code","2eff25ec":"code","45b6a4ad":"code","33232222":"code","b76f6c2f":"code","b0e9c069":"code","c8012627":"code","ea4740a2":"code","4c9acb94":"code","be591d97":"code","fd3573f8":"code","7aa8bae4":"code","12250bac":"code","d2a0a210":"code","348e183a":"code","135aa50d":"code","185132e5":"markdown","5d5e397b":"markdown","1a6eca19":"markdown","8e13f190":"markdown","8dd28507":"markdown","8ba00065":"markdown","b1897d32":"markdown","32049248":"markdown","eb768e1e":"markdown","76c7a04f":"markdown","1114e246":"markdown"},"source":{"cdd00171":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","abeb2d68":"df = pd.read_csv('\/kaggle\/input\/statcast-mlb-pitcher-stats\/stats.csv')\ndf['IP\/G'] = df['p_formatted_ip'] \/ df['p_game']\ndel df['Unnamed: 20']\ndf.head()","ab779904":"corr = df.corr()\ncorr.style.background_gradient(cmap='coolwarm').set_precision(2)","62baca74":"'''fig = plt.figure(figsize=(20,3)) \nfig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05) \n\nax = fig.add_subplot(1, 6, 1, xticks=[], yticks=[]) \nsns.kdeplot(data=df, x=\"fastball_avg_speed\", y=\"breaking_avg_speed\", fill=True, bw_adjust=.75)\n\nax = fig.add_subplot(1, 6, 2, xticks=[], yticks=[]) \nsns.kdeplot(data=df, x=\"fastball_avg_speed\", y=\"offspeed_avg_speed\", fill=True, bw_adjust=.75)\n\nax = fig.add_subplot(1, 6, 3, xticks=[], yticks=[]) \nsns.kdeplot(data=df, x=\"breaking_avg_speed\", y=\"offspeed_avg_speed\", fill=True, bw_adjust=.75)\n'''\nfig = plt.figure(figsize=(20,3))\nax = fig.add_subplot(1, 6, 1, xticks=[], yticks=[]) \nsns.kdeplot(data=df, x=\"fastball_avg_speed\", y=\"breaking_avg_speed\", fill=True, bw_adjust=.75)","34aa78b9":"sns.histplot(data=df, x='p_era')","af57db5b":"ax = sns.violinplot(x=df[\"p_era\"])","713ff6f5":"for year in pd.unique(df['year']):\n    count = len(df[df['year'] == year])\n    print(f'Year {year} had {count} players')","159a4977":"def report_missing_vals(df):\n    col=[]\n    for column in df.columns:\n        if len(df[df[column] == 0]) > 0:\n            print(f'{column}:\\t Zero values: {len(df[df[column] == 0])}')\n        if len(df[pd.isna(df[column])]) > 0:\n            print(f'{column}:\\t Null values: {len(df[pd.isna(df[column])])}')\n            col.append(column)\n    return col\n    \nimputelist=report_missing_vals(df)","6bcb769b":"#impute missing n_ values to be 0\n#impute avg values to be avg of the rest of the data set  (weak R^2 between n and avg)\ndef impute_vals(df, imputelist):\n    new_df = df.copy()\n    for column in imputelist:\n        if \"n_\" in column:\n            new_df.loc[new_df[pd.isna(new_df[column])].index, column] = 0.0\n        else:\n            new_df.loc[new_df[pd.isna(new_df[column])].index, column] = new_df[column].mean()\n\n    return new_df\n\n#test function        \n#a = pd.Series([1, 1, 0])\n#b = pd.Series([2, None, 2])\n#c = pd.Series([None, None, 3])\n#test_df = pd.concat([a,b,c], axis=1).rename(columns={0: \"a\", 1: \"b\", 2: 'c'})\n#display(test_df)\n\n#print('\\nimpute_zeros = 0')\n#display(impute_vals(test_df, impute_zeros=0))\n\n#\ndf = impute_vals(df, imputelist)\nreport_missing_vals(df)","6643418b":"pitching_only = 1\n\n# Case 1 using K%\/BB%\/Hardhit\/Softhit and only pitching data \nif pitching_only == 1:\n    #    X = df[[\"p_k_percent\", \"p_bb_percent\",\"hard_hit_percent\",\"poorlyweak_percent\"]]\n    X = df[[\"n_fastball_formatted\",\"fastball_avg_speed\",\"fastball_avg_spin\",\"n_breaking_formatted\",\"breaking_avg_speed\",\"breaking_avg_spin\",\"n_offspeed_formatted\",\"offspeed_avg_speed\",\"offspeed_avg_spin\",\"IP\/G\"]]\n\n    # Case 2 using Earned Run Average as the target w\/ all other variables (including BB%\/K%\/etc.) as explanatory variables since its the most commonly accepted perf measure    \nelse:\n    X = df.iloc[:, 4:] # Filter name, ID, year\n    X = X.drop('p_era', axis=1)\n#X = impute_vals(X, impute_zeros=0)\nscaler = StandardScaler()\nscaler.fit(X)\nscaled_X = scaler.transform(X)\n\n\ny = df['p_era']","269eea49":"pca = PCA()\npca.fit_transform(scaled_X)\n# pca.explained_variance_ratio_[:2].sum()\n# pca.explained_variance_\n\nPC_values = np.arange(pca.n_components_) + 1\nplt.plot(PC_values, pca.explained_variance_ratio_, 'ro-', linewidth=2)\nplt.title('Scree Plot')\nplt.xlabel('Principal Component')\nplt.ylabel('Variance Explained')\nplt.show()\n\nprint(f'Cumulative sum of variance explained {np.cumsum(pca.explained_variance_ratio_)}')\n#kmeans = KMeans(n_clusters=5, random_state=0).fit(reduced_data)","a0b012f4":"np.round(pca.components_,3)\n\n#\"n_fastball_formatted\",\"fastball_avg_speed\",\"fastball_avg_spin\",\"n_breaking_formatted\",\"breaking_avg_speed\",\"breaking_avg_spin\",\"n_offspeed_formatted\",\"offspeed_avg_speed\",\"offspeed_avg_spin\",\"IP\/G\"\n\npca_df=pd.DataFrame(np.round(pca.components_,3),columns=[\"n_fastball_formatted\",\"fastball_avg_speed\",\"fastball_avg_spin\",\"n_breaking_formatted\",\"breaking_avg_speed\",\"breaking_avg_spin\",\"n_offspeed_formatted\",\"offspeed_avg_speed\",\"offspeed_avg_spin\",\"IP\/G\"])\npca_df\n","122bd759":"pca = PCA(n_components=6)\npca_X = pca.fit_transform(scaled_X)","54f2cef1":"SSE=[]\nfor k in range(2,50):\n    kmeans = KMeans(n_clusters=k, random_state=0).fit(pca_X)\n    SSE.append(kmeans.inertia_)\n\nplt.figure(1)\nplt.plot(range(2,50),SSE, 'o')\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"Sum of Squared Distances\")\n    ","2eff25ec":"#Best K = 12    \nbestk=20\n\n# Source\n# https:\/\/scikit-learn.org\/stable\/auto_examples\/cluster\/plot_kmeans_digits.html#sphx-glr-auto-examples-cluster-plot-kmeans-digits-py\ndef plot_kmeans(kmeans, X):\n\n    fig, ax = plt.subplots()\n\n    # Step size of the mesh. Decrease to increase the quality of the VQ.\n    h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\n\n    # Plot the decision boundary. For that, we will assign a color to each\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n\n    # Obtain labels for each point in mesh. Use last trained model.\n    Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n\n    # Put the result into a color plot\n    Z = Z.reshape(xx.shape)\n    #print(Z)\n    #plt.figure(1)\n    #plt.clf()\n    plt.imshow(Z, interpolation=\"nearest\",\n               extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n               cmap=plt.cm.Paired, aspect=\"auto\", origin=\"lower\")\n\n    plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)\n    # Plot the centroids as a white X\n    centroids = kmeans.cluster_centers_\n    #plt.scatter(centroids[:, 0], centroids[:, 1], marker=\"x\", s=169, linewidths=3, color=\"w\", zorder=10)\n    for i in range(len(centroids)):\n      ax.annotate(str(i), (centroids[i, 0], centroids[i, 1]),  bbox=dict(boxstyle=\"round4\", fc=\"w\"))\n    #plt.title(\"K-means clustering on baseball stats (PCA-reduced data)\\n\"\n    #          \"Centroids are marked with white cross\")\n    plt.xlim(x_min, x_max)\n    plt.ylim(y_min, y_max)\n    #plt.xticks(())\n    #plt.yticks(())\n    plt.xlabel(\"PCA 1\")\n    plt.ylabel(\"PCA 2\")\n    plt.show()\n\n\nplot_pca = PCA(n_components=2)\nplot_pca_X = plot_pca.fit_transform(scaled_X)\n\nkmeans = KMeans(n_clusters=bestk, random_state=0).fit(plot_pca_X)\nplot_kmeans(kmeans, pca_X)\n","45b6a4ad":"kmeans = KMeans(n_clusters=bestk, random_state=0).fit(pca_X)\n","33232222":"# Assign cluster labels to the player names\n#players = df.reset_index().iloc[:,:4].drop(columns=['index'])\nlabels_df = pd.DataFrame(kmeans.labels_, columns = ['cluster'])\n#labeled_df = df.copy()\n#labeled_df.append(labels_df, ignore_index=True)\nlabeled_df = pd.concat([df, labels_df], axis=1, join=\"inner\")\nlabeled_df\n#temp =\n#labeled_df[['player_id','cluster']] .rename(columns={'player_id':'Count of Players in Cluster'}).groupby(\"cluster\").count()\n#display(clustered_players.drop(['last_name', ' first_name'], axis=1).rename(columns={'player_id':'Count of Players in Cluster'}).groupby(\"cluster\").count())\n\n#Add columns for mean ERA\/SD ERA.\nagg_df = labeled_df[['player_id','cluster','p_era','p_k_percent','p_bb_percent','hard_hit_percent','poorlyweak_percent']].groupby(\"cluster\").agg({'player_id':['count'],'p_era':['mean'], 'p_k_percent':['mean'] ,'p_bb_percent':['mean'],'hard_hit_percent':['mean'], 'poorlyweak_percent':['mean']})\nagg_df.columns = agg_df.columns.map('_'.join)\n#agg_df\n\n#Add columns for all Data \n#all_agg_df = labeled_df.groupby(\"cluster\").agg({'player_id':['count'],'p_era':['mean', 'std'],'p_k_percent':['mean', 'std'],'p_bb_percent':['mean', 'std'],'hard_hit_percent':['mean', 'std'], 'poorlyweak_percent':['mean', 'std'] })\nall_agg_df = labeled_df.groupby(\"cluster\").agg([\"mean\"])\nall_agg_df.columns = all_agg_df.columns.map('_'.join)\nall_agg_df.drop(['player_id_mean','p_game_mean','p_formatted_ip_mean','year_mean'], axis=1, inplace=True)\n\ncentroids = pd.DataFrame(kmeans.cluster_centers_)\nagg_df['centroids_x'] = centroids[0]\nagg_df['centroids_y'] = centroids[1]\nagg_df\n\n\nall_agg_df['centroids_x'] = centroids[0]\nall_agg_df['centroids_y'] = centroids[1]\nall_agg_df['centroids_z'] = centroids[2]\nall_agg_df.sort_values('p_era_mean')\nall_agg_df.sort_values('p_era_mean').style.background_gradient(cmap='coolwarm').set_precision(2)\nall_agg_df.drop(17,inplace=True)\nall_agg_df.sort_values('p_era_mean').style.background_gradient(cmap='coolwarm').set_precision(2)","b76f6c2f":"#Add columns for mean ERA\/SD ERA.\nagg_df = labeled_df[['cluster','p_era','p_k_percent','p_bb_percent','hard_hit_percent','poorlyweak_percent']].groupby(\"cluster\").agg({'p_era':['mean'], 'p_k_percent':['mean'] ,'p_bb_percent':['mean'],'hard_hit_percent':['mean'], 'poorlyweak_percent':['mean']})\nagg_df.columns = agg_df.columns.map('_'.join)\n#agg_df\nagg_df.drop(17,inplace=True)\nagg_df.rename({'p_era_mean': 'Mean ERA', 'p_k_percent_mean': 'Mean K%', 'p_bb_percent_mean': 'Mean BB%', 'hard_hit_percent_mean': 'Mean Hard hit%', 'poorlyweak_percent_mean': 'Mean Poor\/Weak%' }, axis=1, inplace=True)\nagg_df.sort_values('Mean ERA').style.background_gradient(cmap='coolwarm').set_precision(2)","b0e9c069":"IPG_df = labeled_df[['player_id','cluster','IP\/G']].groupby(\"cluster\").agg({'player_id':['count'],'IP\/G':['min', 'max','std']})\nIPG_df.columns = IPG_df.columns.map('_'.join)\nIPG_df","c8012627":"figure = plt.figure(figsize=(18, 18))\nax = plt.subplot(2, 3, 1)\n\nplt.figure(1)\nx=all_agg_df['fastball_avg_speed_mean']\ny=all_agg_df['p_era_mean']\nplt.plot(all_agg_df['fastball_avg_speed_mean'],all_agg_df['p_era_mean'],'bo')\nplt.xlabel(\"Mean Fastball Speed\")\nplt.ylabel(\"Mean ERA\")\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\nplt.plot(x,p(x),'--', dashes=(5, 50))\n\n\n#plt.show()\nax = plt.subplot(2, 3, 2)\nplt.figure(1)\nx=all_agg_df['breaking_avg_speed_mean']\ny=all_agg_df['p_era_mean']\nplt.plot(all_agg_df['breaking_avg_speed_mean'],all_agg_df['p_era_mean'],'ro')\nplt.xlabel(\"Mean Breaking Speed\")\nplt.ylabel(\"Mean ERA\")\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\nplt.plot(x,p(x),'r--', dashes=(5, 50))\n\n#plt.show()\nax = plt.subplot(2, 3, 3)\n\nplt.figure(1)\nx=all_agg_df['offspeed_avg_speed_mean']\ny=all_agg_df['p_era_mean']\nplt.plot(all_agg_df['offspeed_avg_speed_mean'],all_agg_df['p_era_mean'],'go')\nplt.xlabel(\"Mean Offspeed Speed\")\nplt.ylabel(\"Mean ERA\")\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\nplt.plot(x,p(x),'g--', dashes=(5, 50))\n\nplt.show()","ea4740a2":"figure = plt.figure(figsize=(18, 12))\nax = plt.subplot(2, 3, 1)\n\nplt.figure(1)\nx=all_agg_df['fastball_avg_speed_mean']\ny=all_agg_df['p_era_mean']\nplt.plot(all_agg_df['fastball_avg_speed_mean'],all_agg_df['p_era_mean'],'bo')\nplt.xlabel(\"Mean Fastball Speed\")\nplt.ylabel(\"Mean ERA\")\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\nplt.plot(x,p(x),'--', dashes=(5, 50))\n\n\n#plt.show()\nax = plt.subplot(2, 3, 2)\nplt.figure(1)\nx=all_agg_df['breaking_avg_speed_mean']\ny=all_agg_df['p_era_mean']\nplt.plot(all_agg_df['breaking_avg_speed_mean'],all_agg_df['p_era_mean'],'ro')\nplt.xlabel(\"Mean Breaking Speed\")\nplt.ylabel(\"Mean ERA\")\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\nplt.plot(x,p(x),'r--', dashes=(5, 50))\n\n#plt.show()\nax = plt.subplot(2, 3, 3)\n\nplt.figure(1)\nx=all_agg_df['offspeed_avg_speed_mean']\ny=all_agg_df['p_era_mean']\nplt.plot(all_agg_df['offspeed_avg_speed_mean'],all_agg_df['p_era_mean'],'go')\nplt.xlabel(\"Mean Offspeed Speed\")\nplt.ylabel(\"Mean ERA\")\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\nplt.plot(x,p(x),'g--', dashes=(5, 50))\n\nax = plt.subplot(2, 3, 4)\nplt.figure(1)\nx=all_agg_df['fastball_avg_spin_mean']\ny=all_agg_df['p_era_mean']\nplt.plot(all_agg_df['fastball_avg_spin_mean'],all_agg_df['p_era_mean'],'bo')\nplt.xlabel(\"Mean Fastball Spin\")\nplt.ylabel(\"Mean ERA\")\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\nplt.plot(x,p(x),'-', dashes=(5, 50))\n\n\n#plt.show()\nax = plt.subplot(2, 3, 5)\nplt.figure(1)\nx=all_agg_df['breaking_avg_spin_mean']\ny=all_agg_df['p_era_mean']\nplt.plot(all_agg_df['breaking_avg_spin_mean'],all_agg_df['p_era_mean'],'ro')\nplt.xlabel(\"Mean Breaking Spin\")\nplt.ylabel(\"Mean ERA\")\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\nplt.plot(x,p(x),'r-', dashes=(5, 50))\n\n#plt.show()\nax = plt.subplot(2, 3, 6)\n\nplt.figure(1)\nx=all_agg_df['offspeed_avg_spin_mean']\ny=all_agg_df['p_era_mean']\nplt.plot(all_agg_df['offspeed_avg_spin_mean'],all_agg_df['p_era_mean'],'go')\nplt.xlabel(\"Mean Offspeed Spin\")\nplt.ylabel(\"Mean ERA\")\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\nplt.plot(x,p(x),'g-', dashes=(5, 50))\n\nplt.show()\n\n#plt.plot(all_agg_df['breaking_avg_speed_mean'],all_agg_df['p_era_mean'],'o')\n#plt.plot(all_agg_df['offspeed_avg_speed_mean'],all_agg_df['p_era_mean'],'o')\n","4c9acb94":"plt.figure(1)\nx=all_agg_df['n_fastball_formatted_mean']\ny=all_agg_df['p_era_mean']\nplt.plot(all_agg_df['n_fastball_formatted_mean'],all_agg_df['p_era_mean'],'bo')\nplt.xlabel(\"% Fastballs Thrown\")\nplt.ylabel(\"Mean ERA\")\nz = np.polyfit(x, y, 1)\nx1=all_agg_df['n_fastball_formatted_mean'].drop(15)\ny1=all_agg_df['p_era_mean'].drop(15)\nz1= np.polyfit(x1, y1, 1)\np = np.poly1d(z)\np1= np.poly1d(z1)\nplt.plot(x,p(x),'-', dashes=(5, 50))\nplt.plot(x1,p1(x1),'-', dashes=(5, 50))\nplt.show()\n\nplt.figure(1)\nx=all_agg_df['n_breaking_formatted_mean']\ny=all_agg_df['p_era_mean']\nplt.plot(all_agg_df['n_breaking_formatted_mean'],all_agg_df['p_era_mean'],'bo')\nplt.xlabel(\"% Breaking Thrown\")\nplt.ylabel(\"Mean ERA\")\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\nplt.plot(x,p(x),'-', dashes=(5, 50))\nplt.show()","be591d97":"#agg_df.sort_values('p_era_mean')","fd3573f8":"count_df = labeled_df.groupby(\"cluster\").agg({'player_id':['count']})\ncount_df.rename({'player_id': ''}, axis=1, inplace=True)\ncount_df","7aa8bae4":"# Cluster 7 stands out significantly from the rest\nlabeled_df[labeled_df['cluster'] == 17].sort_values('player_id').head()","12250bac":"player='Dallas Keuchel'\nc = labeled_df[ (labeled_df['player_id'] == 572971) & (labeled_df['year'] == 2015)]['cluster'].iloc[0]\nprint(f'{player}s 2015 cluster: {c}')\n\nprint()\nplayer='Rick Porcello'\nc = labeled_df[ (labeled_df['player_id'] == 519144) & (labeled_df['year'] == 2016)]['cluster'].iloc[0]\nprint(f'{player}s 2016 cluster: {c}')\n\nprint()\nplayer='Corey Kluber'\nc = labeled_df[ (labeled_df['player_id'] == 446372) & (labeled_df['year'] == 2017)]['cluster'].iloc[0]\nprint(f'{player}s 2017 cluster: {c}')\n\nprint()\nplayer='Blake Snell'\nc = labeled_df[ (labeled_df['player_id'] == 605483) & (labeled_df['year'] == 2018)]['cluster'].iloc[0]\nprint(f'{player}s 2018 cluster: {c}')\n\nprint()\nplayer='Justin Verlander'\nc = labeled_df[ (labeled_df['player_id'] == 434378) & (labeled_df['year'] == 2019)]['cluster'].iloc[0]\nprint(f'{player}s 2019 cluster: {c}')\n\nprint()\nplayer='Jack Arrieta'\nc = labeled_df[ (labeled_df['player_id'] == 453562) & (labeled_df['year'] == 2015)]['cluster'].iloc[0]\nprint(f'{player}s 2015 cluster: {c}')\n\nprint()\nplayer='Max Scherzer'\nc = labeled_df[ (labeled_df['player_id'] == 453286) & (labeled_df['year'] == 2016)]['cluster'].iloc[0]\nprint(f'{player}s 2016 cluster: {c}')\nc = labeled_df[ (labeled_df['player_id'] == 453286) & (labeled_df['year'] == 2017)]['cluster'].iloc[0]\nprint(f'{player}s 2017 cluster: {c}')\n\nprint()\nplayer='Jacob deGrom'\nc = labeled_df[ (labeled_df['player_id'] == 594798) & (labeled_df['year'] == 2018)]['cluster'].iloc[0]\nprint(f'{player}s 2018 cluster: {c}')\nc = labeled_df[ (labeled_df['player_id'] == 594798) & (labeled_df['year'] == 2019)]['cluster'].iloc[0]\nprint(f'{player}s 2019 cluster: {c}')\n\n#labeled_df[ (labeled_df['player_id'] == 453286) & (labeled_df['year'] == 2016)]['cluster']\n#labeled_df[ (labeled_df['player_id'] == 453286) & (labeled_df['year'] == 2017)]['cluster']","d2a0a210":"player='Mark Melancon'\nyear = 2015\nc = labeled_df[ (labeled_df['player_id'] == 453343) & (labeled_df['year'] == year)]['cluster'].iloc[0]\nprint(f'{player}s {year} cluster: {c}')\n\n\nplayer='Kenley Jansen'\nyear = 2016\nc = labeled_df[ (labeled_df['player_id'] == 445276) & (labeled_df['year'] == year)]['cluster'].iloc[0]\nprint(f'{player}s {year} cluster: {c}')\nyear = 2017\nc = labeled_df[ (labeled_df['player_id'] == 445276) & (labeled_df['year'] == year)]['cluster'].iloc[0]\nprint(f'{player}s {year} cluster: {c}')\n\nplayer='Josh Hader'\nyear = 2018\nc = labeled_df[ (labeled_df['player_id'] == 623352) & (labeled_df['year'] == year)]['cluster'].iloc[0]\nprint(f'{player}s {year} cluster: {c}')\nyear = 2019\nc = labeled_df[ (labeled_df['player_id'] == 623352) & (labeled_df['year'] == year)]['cluster'].iloc[0]\nprint(f'{player}s {year} cluster: {c}')\n\n\nplayer='Andrew Miller '\nyear = 2015\nc = labeled_df[ (labeled_df['player_id'] == 453192) & (labeled_df['year'] == year)]['cluster'].iloc[0]\nprint(f'{player}s {year} cluster: {c}')\n\nplayer='Zack Britton'\nyear = 2016\nc = labeled_df[ (labeled_df['player_id'] == 502154) & (labeled_df['year'] == year)]['cluster'].iloc[0]\nprint(f'{player}s {year} cluster: {c}')\n\nplayer='Craig Kimbrel'\nyear = 2017\nc = labeled_df[ (labeled_df['player_id'] == 518886) & (labeled_df['year'] == year)]['cluster'].iloc[0]\nprint(f'{player}s {year} cluster: {c}')\n\nplayer='Edwin D\u00edaz'\nyear = 2018\nc = labeled_df[ (labeled_df['player_id'] == 621242) & (labeled_df['year'] == year)]['cluster'].iloc[0]\nprint(f'{player}s {year} cluster: {c}')\n\nplayer='Aroldis Chapman'\nyear = 2019\nc = labeled_df[ (labeled_df['player_id'] == 547973) & (labeled_df['year'] == year)]['cluster'].iloc[0]\nprint(f'{player}s {year} cluster: {c}')\n\n","348e183a":"#https:\/\/scikit-learn.org\/stable\/auto_examples\/exercises\/plot_cv_diabetes.html#sphx-glr-auto-examples-exercises-plot-cv-diabetes-py\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import Ridge\n\nridge = Ridge()\nalphas = np.linspace(.0000000001, 10, 100)\n\ntuned_parameters = [{'alpha': alphas}]\nn_folds = 5\n\nclf = GridSearchCV(ridge, tuned_parameters, cv=n_folds, refit=False)\nclf.fit(X, y)\nscores = clf.cv_results_['mean_test_score']\nscores_std = clf.cv_results_['std_test_score']\nplt.figure().set_size_inches(8, 6)\nplt.plot(alphas, scores)\n\n# plot error lines showing +\/- std. errors of the scores\nstd_error = scores_std \/ np.sqrt(n_folds)\n\nplt.plot(alphas, scores + std_error, 'b--')\nplt.plot(alphas, scores - std_error, 'b--')\n\n# alpha=0.2 controls the translucency of the fill color\nplt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n\nplt.ylabel('CV score +\/- std error')\nplt.xlabel('alpha')\nplt.axhline(np.max(scores), linestyle='--', color='.5')\nplt.axvline(alphas[np.argmax(scores)], linestyle='--', color='.5')\nplt.xlim( [alphas[0], alphas[-1]])\n\nplt.show()\n\nprint(f\"Best alpha: {alphas[np.argmax(scores)]}\")\n\nclf = Ridge(alpha=alphas[np.argmax(scores)])\nclf.fit(X, y)\n\nresults = pd.DataFrame(columns=['Column','Coefficient'])\nfor col, coef in zip(X.columns, clf.coef_):\n    result = pd.DataFrame([[col, coef]], columns=['Column','Coefficient'])\n    results = results.append(result)\nresults.sort_values(by='Coefficient', ascending=True).set_index('Column')","135aa50d":"#https:\/\/scikit-learn.org\/stable\/auto_examples\/exercises\/plot_cv_diabetes.html#sphx-glr-auto-examples-exercises-plot-cv-diabetes-py\nfrom sklearn.model_selection import GridSearchCV\n\n\nridge = Ridge()\nalphas = np.linspace(.0000000001, 10, 100)\n\ntuned_parameters = [{'alpha': alphas}]\nn_folds = 5\n\nclf = GridSearchCV(ridge, tuned_parameters, cv=n_folds, refit=False)\nclf.fit(scaled_X, y)\nscores = clf.cv_results_['mean_test_score']\nscores_std = clf.cv_results_['std_test_score']\nplt.figure().set_size_inches(8, 6)\nplt.plot(alphas, scores)\n\n# plot error lines showing +\/- std. errors of the scores\nstd_error = scores_std \/ np.sqrt(n_folds)\n\nplt.plot(alphas, scores + std_error, 'b--')\nplt.plot(alphas, scores - std_error, 'b--')\n\n# alpha=0.2 controls the translucency of the fill color\nplt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n\nplt.ylabel('CV score +\/- std error')\nplt.xlabel('alpha')\nplt.axhline(np.max(scores), linestyle='--', color='.5')\nplt.axvline(alphas[np.argmax(scores)], linestyle='--', color='.5')\nplt.xlim( [alphas[0], alphas[-1]])\n\nplt.show()\n\nprint(f\"Best alpha: {alphas[np.argmax(scores)]}\")\n\nclf = Ridge(alpha=alphas[np.argmax(scores)])\nclf.fit(X, y)\n\nresults = pd.DataFrame(columns=['Column','Coefficient'])\nfor col, coef in zip(X.columns, clf.coef_):\n    result = pd.DataFrame([[col, coef]], columns=['Column','Coefficient'])\n    results = results.append(result)\nresults.sort_values(by='Coefficient', ascending=True).set_index('Column')","185132e5":"<a id=\"clustering\"><\/a>\n# Clustering","5d5e397b":"https:\/\/en.wikipedia.org\/wiki\/Major_League_Baseball_Reliever_of_the_Year_Award\n\n**Trevor Hoffman NL Reliever of the Year** <br>\n> Mark Melancon\t- 15 player_id == 453343 <br>\n> Kenley Jansen - 16, 17 player_id == 445276 <br>\n> Josh Hader - 18, 19 player_id == 623352 <br>\n\n**Mariano Rivera AL Reliever of the Year** <br>\n>    Andrew Miller - 15 player_id == 453192 <br>\n>    Zack Britton - 16 player_id == 502154 <br>\n>     Craig Kimbrel - 17 player_id == 518886 <br>\n>     Edwin D\u00edaz - 18 player_id == 621242<br>\n>     Aroldis Chapman - 19 player_id == 547973 <br>","1a6eca19":"<a id=\"clusteranalysis\"><\/a>\n# Cluster Analysis","8e13f190":"https:\/\/en.wikipedia.org\/wiki\/Cy_Young_Award <br>\n**American League** <br>\n*   Dallas Keuchel - 2015 player_id == 572971 <br>\n*    Rick Porcello - 2016 player_id == 519144 <br>\n*    Corey Kluber - 2017 player_id == 446372 <br>\n*   Blake Snell\t- 2018 player_id == 605483 <br>\n*   Justin Verlander - 2019 player_id == 434378 <br>\n\n<br>\n\n**National League** <br>\n* Jake Arrieta - 2015  player_id == 453562\n* Max Scherzer - 2016, 2017 player_id == 453286 <br>\n* Jacob deGrom - 2018, 2019 player_id == 594798 <br>","8dd28507":"![image.png](attachment:0150dc8e-5fa6-460d-85db-27b0dcf556f5.png)","8ba00065":"### Table of Contents\n1. [Data Introduction](#data)\n - Preview\n - Data Descriptions\n2. [Brief Analysis](#analysis)\n - Correlations\n - Yearly Players\n - Missing Data\n3. [Cleaning](#Cleaning)\n4. [PCA](#pca)\n5. [Clustering](#clustering)\n6. [Cluster Analysis](#clusteranalysis)","b1897d32":"<a id=\"cleaning\"><\/a>\n# Cleaning","32049248":"<a id=\"analysis\"><\/a>\n# Brief Analysis","eb768e1e":"| Column | Short Description | Long Description |\n| :---   | ----------- | ----------- |\n| p_game | Games Played (G) |\n| p_formatted_ip\t| Innings Pitched (IP) |\n| IP\/G\t| Innings Pitched Per Game |\n|p_k_percent\t| Strikeout Rate (K%) | Total strikeouts divided by total batters faced.\n|p_bb_percent\t| Walk Rate |  Frequency with which a pitcher walks hitters, as determined by total walks divided by total batters faced. \n|p_era\t| Earned Run Average | Number of earned runs a pitcher allows per nine innings -- with earned runs being any runs that scored without the aid of an error or a passed ball. ERA is the most commonly accepted statistical tool for evaluating pitchers.\n|n_fastball_formatted | Fastball | Pitch thrown very fast, generally as hard as a given pitcher can throw while maintaining control.\n|fastball_avg_speed\t\n|fastball_avg_spin\t\n|n_breaking_formatted | Breaking Ball | Pitch that does not travel straight as it approaches the batter; it will have sideways or downward motion on it, sometimes both\n|breaking_avg_speed\t\n|breaking_avg_spin\t\n|n_offspeed_formatted\t| Offspeed | Pitch thrown at a slower speed than a fastball. Breaking balls and changeups are the two most common types of off-speed pitches.\n|offspeed_avg_speed\t\n|offspeed_avg_spin\n\nn_fastball_formatted + n_breaking_formatted + n_offspeed_formatted = 100","76c7a04f":"<a id=\"data\"><\/a>\n# Data Introduction\n\nThis data was collected from https:\/\/baseballsavant.mlb.com\/ with the intent to use it to group pitchers together based on a range of statistics on them. Some descriptions are given below:","1114e246":"<a id=\"pca\"><\/a>\n# PCA"}}