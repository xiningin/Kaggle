{"cell_type":{"71eaa9a0":"code","16f7b584":"code","b546e52c":"code","56206089":"code","84ad7b81":"code","7e42911c":"code","e45e6a79":"code","b678f988":"code","d08bb784":"code","c72015c1":"code","4850bfe4":"code","cc578de1":"code","2c72e0a6":"code","228807f0":"code","cbd38d6f":"code","eb970661":"code","b9168969":"code","ff68deee":"code","1b1089ef":"code","b4ce8950":"code","5d7817e0":"code","f6ce0705":"code","ab63257a":"code","a92e7019":"code","bd134d83":"code","aafbe815":"code","43431749":"code","382ebf19":"code","0d64e030":"code","4d5c9070":"code","ecfd7364":"code","420003aa":"code","a3c3f1e2":"code","68ffff58":"markdown","141b141b":"markdown","e9ee44c8":"markdown","fc571584":"markdown","8d86cbf1":"markdown","105b558e":"markdown","2f2ecf1e":"markdown","3f889d9a":"markdown","fc18dbe2":"markdown","a8bbea0b":"markdown","f852439b":"markdown"},"source":{"71eaa9a0":"!pip install pyenchant pysastrawi","16f7b584":"!wget http:\/\/archive.ubuntu.com\/ubuntu\/pool\/main\/libr\/libreoffice-dictionaries\/hunspell-id_6.4.3-1_all.deb\n!dpkg -i hunspell-id_6.4.3-1_all.deb","b546e52c":"!apt update && apt install -y enchant libenchant1c2a hunspell hunspell-en-us libhunspell-1.6-0","56206089":"import re\nimport os\nimport gc\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport sklearn\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nimport enchant","84ad7b81":"!pip freeze > requirements.txt","7e42911c":"print('Numpy version:', np.__version__)\nprint('Pandas version:', pd.__version__)\nprint('Scikit-Learn version:', sklearn.__version__)\nprint('Matplotlib version:', matplotlib.__version__)\nprint('Seaborn version:', sns.__version__)\nprint('NLTK version:', nltk.__version__)","e45e6a79":"SEED = 42\n\nos.environ['PYTHONHASHSEED']=str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)","b678f988":"nltk.download('wordnet')","d08bb784":"!ls -lha \/kaggle\/input\n!ls -lha \/kaggle\/input\/student-shopee-code-league-sentiment-analysis","c72015c1":"df_train = pd.read_csv('\/kaggle\/input\/student-shopee-code-league-sentiment-analysis\/train.csv')\ndf_train.sample(10)","4850bfe4":"df_train2 = pd.read_csv('\/kaggle\/input\/shopee-reviews\/shopee_reviews.csv')\n\ndef to_int(r):\n    try:\n        return np.int32(r)\n    except:\n        return np.nan\n\ndf_train2['label'] = df_train2['label'].apply(to_int)\ndf_train2 = df_train2.dropna()\ndf_train2['label'] = df_train2['label'].astype(np.int32)\ndf_train2","cc578de1":"df_test = pd.read_csv('\/kaggle\/input\/student-shopee-code-league-sentiment-analysis\/test.csv')\ndf_test.sample(10)","2c72e0a6":"X_train = pd.concat([df_train['review'], df_train2['text']], axis=0)\nX_train = X_train.reset_index(drop=True)\ny_train = pd.concat([df_train['rating'], df_train2['label']], axis=0)\ny_train = y_train.reset_index(drop=True)\n\nX_test = df_test['review']","228807f0":"rating_count = y_train.value_counts().sort_index().to_list()\ntotal_rating = sum(rating_count)\nlowest_rating_count = min(rating_count)\nrating_weight = [lowest_rating_count\/rc for rc in rating_count]\n\nprint(rating_count)\nprint(total_rating)\nprint(rating_weight)","cbd38d6f":"class_weight = np.empty((total_rating,))\nfor i in range(total_rating):\n    class_weight[i] = rating_weight[y_train[i] - 1]","eb970661":"from nltk.stem import WordNetLemmatizer\nfrom Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n\nlemmatizer = WordNetLemmatizer() # for en\nfactory = StemmerFactory() # for id\nstemmer = factory.create_stemmer() # for id\n\ntweet_tokenizer = nltk.tokenize.TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n\neng_dict = enchant.Dict('en')\nind_dict = enchant.Dict('id_ID')\n\ndef remove_char(text):\n    text = re.sub(r'[^a-z ]', ' ', text)\n    return text\n\n\ndef stem_lemma(tokens):\n    new_token = []\n    for token in tokens:\n        if eng_dict.check(token):\n            new_token.append(lemmatizer.lemmatize(token))\n        elif ind_dict.check(token):\n            new_token.append(stemmer.stem(token))\n        else:\n            new_token.append(token)\n    return new_token\n\ndef upper_or_lower(tokens):\n    new_token = []\n    for token in tokens:\n        total_lower = len(re.findall(r'[a-z]',token))\n        total_upper = len(re.findall(r'[A-Z]',token))\n        if total_lower == 0 or total_upper == 0:\n            new_token.append(token)\n        elif total_lower > total_upper:\n            new_token.append(token.lower())\n        else:\n            new_token.append(token.upper())\n    return new_token\n    \n\ndef preprocess(X):\n    X = X.apply(tweet_tokenizer.tokenize)\n    X = X.apply(lambda token: [t for t in token if t != ''])\n    X = X.apply(upper_or_lower)\n    X = X.apply(stem_lemma)\n#     X = X.apply(lambda token: ' '.join(token)) # need to join token because sklearn tf-idf only accept string, not list of string\n    \n#     X = X.apply(remove_char)\n    return X","b9168969":"X_train = preprocess(X_train)\nX_test = preprocess(X_test)","ff68deee":"X_train.sample(10)","1b1089ef":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nbow_vectorizer = TfidfVectorizer(lowercase=False, ngram_range=(1,2), analyzer=lambda t:t, min_df=5, sublinear_tf=True)\n\nX_train = bow_vectorizer.fit_transform(X_train)\nX_test = bow_vectorizer.transform(X_test)\n","b4ce8950":"print(X_train.shape)\nprint(X_test.shape)","5d7817e0":"from sklearn.metrics import classification_report, f1_score, confusion_matrix\n\ndef predict(model, X):\n    y = model.predict(X)\n    return y\n\ndef metrics(y_true, y_pred):\n    print('F1 Score :', f1_score(y_true, y_pred, average='macro'))\n    print(classification_report(y_true, y_pred))\n\n    cm = confusion_matrix(y_true, y_pred)\n    cm = pd.DataFrame(cm, [1,2,3,4,5], [1,2,3,4,5])\n\n    sns.heatmap(cm, annot=True, cmap=\"YlGnBu\", fmt=\"d\")\n    plt.show()","f6ce0705":"from sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB()\nclf.fit(X_train, y_train, class_weight)","ab63257a":"y_train_pred = predict(clf, X_train)\nmetrics(y_train, y_train_pred)","a92e7019":"y_test_pred = predict(clf, X_test)\n\ndf_submission = pd.concat([df_test['review_id'], pd.Series(y_test_pred, name='rating')], axis=1)\ndf_submission.to_csv('submission_MultinomialNB.csv', index=False)\n\ndf_submission","bd134d83":"from sklearn.naive_bayes import ComplementNB\nclf = ComplementNB()\nclf.fit(X_train, y_train, class_weight)","aafbe815":"y_train_pred = predict(clf, X_train)\nmetrics(y_train, y_train_pred)","43431749":"y_test_pred = predict(clf, X_test)\n\ndf_submission = pd.concat([df_test['review_id'], pd.Series(y_test_pred, name='rating')], axis=1)\ndf_submission.to_csv('submission_ComplementNB.csv', index=False)\n\ndf_submission","382ebf19":"# from sklearn.ensemble import RandomForestClassifier\n\n# clf = RandomForestClassifier(random_state=SEED)\n# clf.fit(X_train, y_train)","0d64e030":"# y_train_pred = predict(clf, X_train)\n# metrics(y_train, y_train_pred)","4d5c9070":"# y_test_pred = predict(clf, X_test)\n\n# df_submission = pd.concat([df_test['review_id'], pd.Series(y_test_pred, name='rating')], axis=1)\n# df_submission.to_csv('submission.csv', index=False)\n\n# df_submission","ecfd7364":"# from sklearn.svm import SVC\n\n# clf = SVC(kernel='rbf', C=1, cache_size=10240)\n# clf.fit(X_train, y_train)","420003aa":"# y_train_pred = predict(clf, X_train)\n# metrics(y_train, y_train_pred)","a3c3f1e2":"# y_test_pred = predict(clf, X_test)\n\n# df_submission = pd.concat([df_test['review_id'], pd.Series(y_test_pred, name='rating')], axis=1)\n# df_submission.to_csv('submission.csv', index=False)\n\n# df_submission","68ffff58":"# Library","141b141b":"# Class weight","e9ee44c8":"# MultinomialNB","fc571584":"# Changelog\n\n### Version 18\n\n* Use additional dataset from https:\/\/www.kaggle.com\/shymammoth\/shopee-reviews\n* No longer modify y_train\n\n### Version 14\n\n* Replace Bag of Words (BoW) with TF-IDF\n\n### Version 13\n\n* Use NaiveBayes\n* Use Bigram\n* Change all y_train rating 4->5\n\n### Version 12\n\n* Replace TF-IDF with Bag of Words (BoW)\n\n### Version 11\n\n* Change replace char & delete remove char\n* Set `min_df=20` for TF-IDF\n* Use SVM (with GridSearchCV)\n* Enable replace\/remove char\n\n### Version 6\n\n* Add Confusion Matrix\n* Set `min_df=5` for TF-IDF\n* Import library used to set SEED\n* Lemmatization for EN & Stemming for ID\n* Disable replace\/remove char\n* Revert RandomForestClassifier parameter\n\n### Version 5\n\n* Change RandomForestClassifier parameter\n* Set SEED\n\n### Version 4\n\n* Use RandomForestClassifier\n* `min_df=20` for TF-IDF\n* Change generic model function position\n\n### Version 3\n\n* Fix submission.csv column name\n\n### Version 2\n\n* Use MultinomialNB\n\n### Version 1\n\n* Initialize code","8d86cbf1":"# Model functions","105b558e":"# Word representation","2f2ecf1e":"# RandomForestClassifier","3f889d9a":"# Dataset","fc18dbe2":"# SVM","a8bbea0b":"# ComplementNB","f852439b":"# Preprocess"}}