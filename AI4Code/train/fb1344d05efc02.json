{"cell_type":{"bafd3d9f":"code","b49ec969":"code","289d8137":"code","d0ef9829":"code","a8f566a7":"code","d67881ce":"code","9a6e3a36":"code","a6e3df12":"code","76709c09":"code","98f9b364":"code","283bfa31":"code","ddfe0a60":"code","5ada178d":"code","bae7e13f":"code","3fcfab76":"code","13b307e1":"code","4e69b616":"code","d2a347dc":"code","84be0c2e":"code","81d0e868":"code","f0b3ffc8":"code","58c689b1":"code","e9d54597":"code","f51fcd7f":"code","fd2099b9":"code","ff8df4ef":"code","cf941228":"code","bf530bc0":"code","fb7941db":"code","b8ede151":"code","98d7c2a4":"code","7ce11c7b":"code","dad5b7f7":"code","92c7d16a":"code","a5061cc0":"markdown","451a0f31":"markdown","560d8f45":"markdown","470f0a6f":"markdown","24f1da20":"markdown","36af571e":"markdown","4789692d":"markdown","04aaf0bf":"markdown","469000b0":"markdown","afd4b1d3":"markdown","220babaf":"markdown","7644c2e0":"markdown","a2a06af1":"markdown","219718ca":"markdown","44f8d2cb":"markdown","6da11e39":"markdown"},"source":{"bafd3d9f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.pipeline import Pipeline\nplt.style.use('ggplot')\n%matplotlib inline","b49ec969":"df = pd.read_csv('..\/input\/sms-spam-collection-dataset\/spam.csv',encoding='latin-1')\ndf","289d8137":"df.isna().sum()","d0ef9829":"not_null = df[df['Unnamed: 2'].notnull()].head()\nnot_null","a8f566a7":"for index, rows in df.iterrows():\n    for r in rows[2:]:\n        if type(r) is str:\n            df.loc[index,'v2'] = df.loc[index,'v2'] + ' ' + r\n\n  ","d67881ce":"not_null","9a6e3a36":"df.loc[281,'v2']","a6e3df12":"df[df['Unnamed: 2'] != 0].head()","76709c09":"cols = df.columns\ncols","98f9b364":"df = df.drop(cols[2:],axis=1)","283bfa31":"df = df.rename(columns={'v1': 'class','v2': 'text'})","ddfe0a60":"df = df.replace('ham',0) \ndf = df.replace('spam',1)","5ada178d":"df['class'].astype('int')","bae7e13f":"percentage_spam = df['class'].mean()\npercentage_spam","3fcfab76":"df['text_length'] = df['text'].apply(len)\ndf","13b307e1":"df[df['class']==0]['text_length']","4e69b616":"df.groupby('class').describe()","d2a347dc":"plt.figure(figsize=(10,8))\nsns.histplot(data=df, x='text_length',hue='class',stat=\"density\", common_norm=False)\nplt.xlim(-1,250)\nplt.title('Distribution of spam(1) vs ham(0)')\nplt.ylabel('Normalized Frequency')\nplt.xlabel('Length of Text')","84be0c2e":"X = df.drop('class',axis=1)\ny = df['class']","81d0e868":"#count_vectorizer class requires 1d X values\nX_train, X_test, y_train, y_test = train_test_split(X['text'],y,test_size=0.2,random_state=42)","f0b3ffc8":"count_vectorizer = CountVectorizer(stop_words='english')","58c689b1":"count_train = count_vectorizer.fit_transform(X_train.values)\ncount_test = count_vectorizer.transform(X_test.values)","e9d54597":"multi_nb = MultinomialNB()","f51fcd7f":"multi_nb.fit(count_train,y_train)","fd2099b9":"y_pred = multi_nb.predict(count_test)","ff8df4ef":"metrics.accuracy_score(y_test,y_pred)","cf941228":"print(classification_report(y_test,y_pred))","bf530bc0":"sns.heatmap(confusion_matrix(y_test,y_pred),annot=True)","fb7941db":"alpha_list = np.logspace(0,200,20)\nalpha_list","b8ede151":"nb_params = {'alpha': alpha_list}","98d7c2a4":"multi_nb.get_params()","7ce11c7b":"nb_grid = GridSearchCV(multi_nb,nb_params,n_jobs=-1)","dad5b7f7":"nb_grid.fit(count_train,y_train)","92c7d16a":"nb_grid.best_params_","a5061cc0":"The columns have combined, now we can do our analysis and not miss out on any data!","451a0f31":"First we read the csv file.","560d8f45":"This is a pretty good result as it is more then just predicting everything as spam (87%).","470f0a6f":"Let's look at the length of text to see whether it can predict for spam.","24f1da20":"Thanks for reading this beginner's notebook, if you have any suggestions on how to improve my model please let me know!","36af571e":"Let's rename the columns for readability.","4789692d":"Let's check the data.","04aaf0bf":"Let's start building our NLP model.","469000b0":"Let's try to optimize the model's hyperparamters even further.","afd4b1d3":"They seem to be multiple lines of text, lets add them to the same column.","220babaf":"Hi all, this is my attempt at building a spam filter from the `sms-spam-collection-dataset`.","7644c2e0":"Looks like the model was already using `alpha = 1.0`, this best parameter.","a2a06af1":"About 13.4% of the text messages are spam.","219718ca":"And we can encode our predictor variable.","44f8d2cb":"It looks like the mean character length for spam is higher, we should visualize this.","6da11e39":"Let's examine the columns to see what is going on."}}