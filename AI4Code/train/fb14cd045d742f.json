{"cell_type":{"815daee6":"code","ddbb0b00":"code","eb3100b1":"code","9c8a98c1":"code","a315ca5b":"code","784488b6":"code","4f8ee033":"code","ef6c8e42":"markdown"},"source":{"815daee6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ddbb0b00":"\"\"\"\nreference from \nhttps:\/\/tfhub.dev\/google\/openimages_v4\/ssd\/mobilenet_v2\/1\nhttps:\/\/colab.research.google.com\/github\/tensorflow\/hub\/blob\/master\/examples\/colab\/object_detection.ipynb\nhttps:\/\/www.kaggle.com\/xhlulu\/intro-to-tf-hub-for-object-detection\nhttps:\/\/www.kaggle.com\/vikramtiwari\/baseline-predictions-using-inception-resnet-v2\n\"\"\"\n\nimport os\nimport gc\ngc.enable()\nfrom multiprocessing import Pool, cpu_count\n\nimport matplotlib.pyplot as plt\nfrom six import BytesIO\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom pprint import pprint\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom PIL import Image, ImageColor, ImageDraw, ImageFont, ImageOps\n\n\n","eb3100b1":"def form_one_prediction_strings(result, i):\n    class_name = result['detection_class_names'][i].decode(\"utf-8\")\n    boxes = result['detection_boxes'][i]\n    score = result['detection_scores'][i]\n    return f\"{class_name} {score} \" + \" \".join(map(str, boxes))\n\n\n","9c8a98c1":"def format_prediction_string(detected):\n    image_id, result = detected\n    prediction_strings = [form_one_prediction_strings(result, i) for i in range(len(result['detection_scores']))]\n    return {\n        \"ImageID\": image_id,\n        \"PredictionString\": \" \".join(prediction_strings)\n    }\n\n\n","a315ca5b":"def inference_one_chunk(data_path, list_image_ids, session, result, image_string_placeholder, predictions):\n    img_files = {\n        i: tf.gfile.Open(\n            os.sep.join([data_path, 'test', f'{i}.jpg']), \"rb\").read() for i in list_image_ids}\n    \n    for image_id in tqdm(list_image_ids):\n        result_out = session.run(\n            result, feed_dict={image_string_placeholder: img_files[image_id]})\n\n        predictions.append((image_id, result_out))\n        \n    del img_files\n    gc.collect()\n    return\n\n\n","784488b6":"def inference():\n    \n    # load model\n    #module_handle = \"https:\/\/tfhub.dev\/google\/openimages_v4\/ssd\/mobilenet_v2\/1\"\n    module_handle = \"https:\/\/tfhub.dev\/google\/faster_rcnn\/openimages_v4\/inception_resnet_v2\/1\"\n    #@param [\"https:\/\/tfhub.dev\/google\/openimages_v4\/ssd\/mobilenet_v2\/1\", \"https:\/\/tfhub.dev\/google\/faster_rcnn\/openimages_v4\/inception_resnet_v2\/1\"]\n    with tf.device('\/device:GPU:0'):\n        with tf.Graph().as_default():\n            detector = hub.Module(module_handle)\n            image_string_placeholder = tf.placeholder(tf.string)\n            decoded_image = tf.image.decode_jpeg(image_string_placeholder)\n            # Module accepts as input tensors of shape [1, height, width, 3], i.e. batch\n            # of size 1 and type tf.float32.\n            decoded_image_float = tf.image.convert_image_dtype(image=decoded_image, dtype=tf.float32)\n            module_input = tf.expand_dims(decoded_image_float, 0)\n            result = detector(module_input, as_dict=True)\n            init_ops = [tf.global_variables_initializer(), tf.tables_initializer()]\n\n            session = tf.Session()\n            session.run(init_ops)\n\n    # load test tset index\n    data_path = \"..\/input\"\n    sample_submission_df = pd.read_csv(f'{data_path}\/sample_submission.csv')\n    image_ids = sample_submission_df['ImageId']\n    image_ids=image_ids[0:25]\n    predictions = []\n    with tf.device('\/device:GPU:0'):\n        step = 2000\n        for ii in range(0, len(image_ids), step):\n            list_image_ids = image_ids.tolist()[ii: ii+step]\n            inference_one_chunk(data_path, list_image_ids, session, result, image_string_placeholder, predictions)\n    \n    # post processing and save\n    predictions_df = pd.DataFrame(list(map(format_prediction_string, predictions)))\n    predictions_df.to_csv('submission_25k.csv', index=False)\n    session.close()\n\n\n","4f8ee033":"if \"__main__\" == __name__:\n    inference()","ef6c8e42":"This kernel is based on pre-trained TF model from the Tensorflow Hub.\n\nThe kernel was inspired by [Vikram's Kernel](https:\/\/www.kaggle.com\/vikramtiwari\/baseline-predictions-using-inception-resnet-v2) and [xhlulu Kernel](https:\/\/www.kaggle.com\/xhlulu\/intro-to-tf-hub-for-object-detection).\n\n# How to get predictions ?\n\nI have used Inception-ResNet. This means that the inference will be slower, but the accuracy is better as compared to MobileNet v2.\n\nIf you are using Kaggle Kernels split the image id's into bunch of 25000 and run the kernels 4 times if you get error code 137."}}