{"cell_type":{"8940fee8":"code","9d0ac9d8":"code","cd613dc2":"code","e781b81d":"code","5825e29b":"code","cbeee563":"code","8ff781d8":"code","c0a8ec91":"code","a425e000":"code","89e40847":"code","270fd9d3":"code","d1337ab5":"code","bfca9b04":"code","8a9d9da1":"code","05a51e1e":"code","cb4a6e19":"markdown","e2dab0cd":"markdown","4d9ce8b8":"markdown","196d7741":"markdown","3b5243aa":"markdown","02e2ff76":"markdown","463fba52":"markdown","fa904e33":"markdown","939950e7":"markdown","f7c15dff":"markdown","8669b7ad":"markdown","c15e77d1":"markdown","f8d269fb":"markdown","5a99c4a4":"markdown","b08b337f":"markdown","0fa1434b":"markdown","c77ef323":"markdown","e1707205":"markdown","ddf0aaee":"markdown","f8e55bfe":"markdown","2571207c":"markdown","82e76074":"markdown","825a75f2":"markdown","91794682":"markdown","31c1ab68":"markdown","070e446e":"markdown","6a5db4cd":"markdown"},"source":{"8940fee8":"# import libraries\nfrom keras.models import Sequential\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nimport numpy as np\nfrom numpy import split\nfrom numpy import array\nfrom numpy import isnan\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom math import sqrt\nfrom datetime import timedelta\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import RepeatVector\nfrom keras.layers import TimeDistributed","9d0ac9d8":"hist = pd.read_csv(\"..\/input\/diamond-prices\/diamond_data_merged_with_other_variables.csv\")","cd613dc2":"# plot diamond price development\ndef line_plot(line1, label1=None, title='', lw=2):\n    fig, ax = plt.subplots(1, figsize=(14, 6))\n    ax.plot(line1, label=label1, linewidth=lw)\n    ax.set_xlabel('date', fontsize=14)\n    ax.set_ylabel('Price', fontsize=14)\n    ax.set_title(title, fontsize=14)\n    ax.legend(loc='best', fontsize=14)\nline_plot(hist[\"diamond price\"], \"diamond price\", title='')\n#line_plot(hist[\"gold price\"], \"gold price\", title='')","e781b81d":"# plot gold price development\ndef line_plot(line1, label1=None, title='', lw=2):\n    fig, ax = plt.subplots(1, figsize=(14, 6))\n    ax.plot(line1, label=label1, linewidth=lw)\n    ax.set_xlabel('date', fontsize=14)\n    ax.set_ylabel('Price', fontsize=14)\n    ax.set_title(title, fontsize=14)\n    ax.legend(loc='best', fontsize=14)\n#line_plot(hist[\"diamond price\"], \"diamond price\", title='')\nline_plot(hist[\"gold price\"], \"gold price\", title='')","5825e29b":"# plot inflation rate development\ndef line_plot(line1, label1=None, title='', lw=2):\n    fig, ax = plt.subplots(1, figsize=(14, 6))\n    ax.plot(line1, label=label1, linewidth=lw)\n    ax.set_xlabel('date', fontsize=14)\n    ax.set_ylabel('Rate', fontsize=14)\n    ax.set_title(title, fontsize=14)\n    ax.legend(loc='upper right', fontsize=14)\nline_plot(hist[\"inflation rate\"], \"inflation rate\", title='')","cbeee563":"# plot fed rate and interest rate development\ndef line_plot(line2, line3, label2=None, label3=None, title='', lw=2):\n    fig, ax = plt.subplots(1, figsize=(14, 6))\n    ax.plot(line2, label=label2, linewidth=lw, color='#f2a553')\n    ax.plot(line3, label=label3, linewidth=lw, color=\"#c14953\")\n    ax.set_xlabel('date', fontsize=14)\n    ax.set_ylabel('Rate', fontsize=14)\n    ax.set_title(title, fontsize=14)\n    ax.legend(loc='best', fontsize=14)\nline_plot(hist[\"interest rate\"], hist[\"fed rate\"], \"interest rate\", \"fed rate\", title='')\n","8ff781d8":"# Heat map\nax = plt.figure(figsize=(12,10))\nsns.heatmap(hist.corr(),annot=True,cmap=\"Reds\", fmt='.0%')\nplt.show()","c0a8ec91":"# multivariate multi-step encoder-decoder lstm\n\n# split a univariate dataset into train\/test sets\ndef split_dataset(hist):\n \t# split into standard weeks\n \ttrain, test = hist[1:-328], hist[-328:-6]\n \t# restructure into windows of weekly data\n \ttrain = array(split(train, len(train)\/7))\n \ttest = array(split(test, len(test)\/7))\n \treturn train, test\n\n#%%\n# evaluate one or more weekly forecasts against expected values\ndef evaluate_forecasts(actual, predicted):\n\tscores = list()\n\t# calculate an RMSE score for each day\n\tfor i in range(actual.shape[1]):\n\t\t# calculate mse\n\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n\t\t# calculate rmse\n\t\trmse = sqrt(mse)\n\t\t# store\n\t\tscores.append(rmse)\n\t# calculate overall RMSE\n\ts = 0\n\tfor row in range(actual.shape[0]):\n\t\tfor col in range(actual.shape[1]):\n\t\t\ts += (actual[row, col] - predicted[row, col])**2\n\tscore = sqrt(s \/ (actual.shape[0] * actual.shape[1]))\n\treturn score, scores\n \n# summarize scores\ndef summarize_scores(name, score, scores):\n\ts_scores = ', '.join(['%.1f' % s for s in scores])\n\tprint('%s: [%.3f] %s' % (name, score, s_scores))\n    \n# convert history into inputs and outputs\ndef to_supervised(train, n_input, n_out=7):\n\t# flatten data\n\tdata = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n\tX, y = list(), list()\n\tin_start = 0\n\t# step over the entire history one time step at a time\n\tfor _ in range(len(data)):\n\t\t# define the end of the input sequence\n\t\tin_end = in_start + n_input\n\t\tout_end = in_end + n_out\n\t\t# ensure we have enough data for this instance\n\t\tif out_end <= len(data):\n\t\t\tX.append(data[in_start:in_end, :])\n\t\t\ty.append(data[in_end:out_end, 0])\n\t\t# move along one time step\n\t\tin_start += 1\n\treturn array(X), array(y)\n \n# train the model\ndef build_model(train, n_input):\n\t# prepare data\n\ttrain_x, train_y = to_supervised(train, n_input)\n\t# define parameters\n\tverbose, epochs, batch_size = 1, 50, 16\n\tn_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n\t# reshape output into [samples, timesteps, features]\n\ttrain_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n\t# define model\n\tmodel = Sequential()\n\tmodel.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n\tmodel.add(RepeatVector(n_outputs))\n\tmodel.add(LSTM(200, activation='relu', return_sequences=True))\n\tmodel.add(TimeDistributed(Dense(100, activation='relu')))\n\tmodel.add(TimeDistributed(Dense(1)))\n\tmodel.compile(loss='mse', optimizer='adam')\n\t# fit network\n\tmodel.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n\treturn model\n \n# make a forecast\ndef forecast(model, history, n_input):\n\t# flatten data\n\tdata = array(history)\n\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n\t# retrieve last observations for input data\n\tinput_x = data[-n_input:, :]\n\t# reshape into [1, n_input, n]\n\tinput_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n\t# forecast the next week\n\tyhat = model.predict(input_x, verbose=1)\n\t# we only want the vector forecast\n\tyhat = yhat[0]\n\treturn yhat\n \n# evaluate a single model\ndef evaluate_model(train, test, n_input):\n\t# fit model\n\tmodel = build_model(train, n_input)\n\t# history is a list of weekly data\n\thistory = [x for x in train]\n\t# walk-forward validation over each week\n\tpredictions = list()\n\tfor i in range(len(test)):\n\t\t# predict the week\n\t\tyhat_sequence = forecast(model, history, n_input)\n\t\t# store the predictions\n\t\tpredictions.append(yhat_sequence)\n\t\t# get real observation and add to history for predicting the next week\n\t\thistory.append(test[i, :])\n\t# evaluate predictions days for each week\n\tpredictions = array(predictions)\n\tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n\treturn score, scores, predictions\n    \n\n#%%\n# load the new file\nhist = pd.read_csv('..\/input\/diamond-prices\/diamond_data_merged_with_other_variables.csv', header = 0) \nhist.info()  \n# date as index\nhist[\"date\"] = pd.to_datetime(hist[\"date\"])\nhist = hist.set_index('date')\nhist.info() \n# split into train and test\ntrain, test = split_dataset(hist.values)\n\n#%%\n# evaluate model and get scores\nn_input = 15\nscore, scores, predictions = evaluate_model(train, test, n_input)\n\n# summarize scores RMSE\nsummarize_scores('lstm RMSE', score, scores)","a425e000":"# predictions\npre = predictions.mean(axis=0)\nprint(pre)","89e40847":"df = pd.read_csv(\"..\/input\/diamond-prices\/df_diamond_data_merged_with_other_variables.csv\")\n\ndate_actual = df[\"date\"].iloc[0]\n\ndate_future = []\nfor i in range (1,8):\n    date_future.append(date_actual + str(timedelta(i)))","270fd9d3":"# plot predictions (05.06.2021 - 11.06.2021)\nplt.plot(date_future, pre.tolist(), color = \"#c14953\", marker='o', label='natural diamonds')\nplt.title('diamond price predictions', pad = 10)\nplt.xlabel('date', labelpad = 10)\nplt.ylabel('diamond price', labelpad = 10)\nplt.axis(ymin=10000, ymax=10800)\nplt.xticks(rotation=45)\nplt.legend(loc=\"best\")\npyplot.show()","d1337ab5":"# plot predictions vs. actual future prices (05.06.2021 - 11.06.2021)\nact = [10392.26, 10397.22, 10397.28, 10404.28, 10412.21, 10419.12, 10419.12]\nplt.plot(date_future, act, color = \"#74a09e\", marker='o', label='actual')\nplt.plot(date_future, pre.tolist(), color = \"#c14953\", marker='o', label='predicted')\nplt.title('predicted vs. actual natural diamond prices', pad = 10)\nplt.xlabel('date', labelpad = 10)\nplt.ylabel('diamond price', labelpad = 10)\nplt.axis(ymin=10000, ymax=10800)\nplt.xticks(rotation=45)\nplt.legend(loc=\"upper right\")\npyplot.show()","bfca9b04":"# prediction for lab-grown diamonds (lg = lab-grown) - conservative scenario\n\n# create conservative list\nlist_conservative = []\nfor i in pre:\n    list_conservative.append(i * 0.35)\n    \nlg_conservative = np.asarray(list_conservative)\n\n# plot predictions natural vs. lab-grown (05.06.2021 - 11.06.2021)\n# plt.plot(date_future, pre.tolist(), color = \"#c14953\", marker='o', label='natural diamonds')\nplt.plot(date_future, lg_conservative, color = \"#f2a553\", marker='o', \n         label='lab-grown diamonds')\nplt.title('diamond price predictions', pad = 10)\nplt.xlabel('date', labelpad = 10)\nplt.ylabel('diamond price', labelpad = 10)\nplt.axis(ymin=3400, ymax=3800)\nplt.xticks(rotation=45)\nplt.legend(loc=\"upper right\")\npyplot.show()","8a9d9da1":"# Linear Regression\n     \nX = hist[[\"inflation rate\", \"interest rate\", \"fed rate\", \"gold price\"]]\ny = hist[\"diamond price\"]    \n\nX_train = X[7:]\nX_test = X[:7]\ny_train = y[7:]\ny_test = y[:7]\n\n# Create Classifier\nclf = LinearRegression()\n\n# Train the model \nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)\nprint(y_pred)\n\n\n# RMSE linear regression (last week)\nRMSE_linear = mean_squared_error(y_test, y_pred, squared=False) # False = RMSE\nprint(\"RMSE linear regression: \", RMSE_linear)","05a51e1e":"# RMSE LSTM\n\n# RMSE LSTM - last week\nsummarize_scores('RMSE LSTM (last week)', score, scores)\n\n# RMSE LSTM - future week\nRMSE_lstm_future = mean_squared_error(act, pre, squared=False) # False = RMSE\nprint(\"RMSE lstm (future week): \", RMSE_lstm_future)","cb4a6e19":"![bild_diamond.jpg](attachment:2ee358da-e4fe-402c-bb18-be55fee04854.jpg)","e2dab0cd":"* Looking-up the actual diamond prices for the predicted seven days on investing.com and plotting them against the predicted values results in the following figure:","4d9ce8b8":"<h1><center>Diamond Price Prediction Using LSTM Neural Network<\/center><\/h1>","196d7741":"# 2.\tProcedure\n\nThe leading industry methodology for a data mining resp. data analysing process model is the so-called CRISP-DM. It consists of the following six major interconnected phases: \n\n(1) business understanding\n\n(2) data understanding\n\n(3) data preparation \n\n(4) modelling\n\n(5) evaluation\n\n(6) deployment\n\n\n\n**2.1 Business Understanding**\n\n* Diamonds are traditionally classified into three different market segments: industrial, jewellery and investment. In this paper the jewellery segment is observed. According to Paul Zimnisky, a leading global diamond industry analyst, the global synthetic gem diamond production will rise from 1 million carat in 2015 to 6 million carats in 2025. \n* The question is how diamond prices (for natural and lab grown diamonds) in this segment will develop in the future. This question is not an easy one to answer as diamond prices are influenced by many factors like trade barriers, political instability, operational disruptions like mine closures or economic downturns resp. upturns. \n* Moreover, natural and lab grown prices are not strictly bound together by a certain ratio. Nevertheless, we can see that lab-grown prices are somehow attached to prices for natural diamonds. This is because diamantaires are bringing their habits from the natural business to the lab-grown business. Lab-growns started at a percentage of about 65% of natural diamonds in 2017. Advances in technology, consolidation and production capacity growth in China are causing unit costs and prices of lab-grown diamonds to drop in 2019 and 2020. In 2020 the percentage for lab-growns was already about 35% of naturals as shown in the following figure:","3b5243aa":"* Now we look at the historical development of diamond prices as well as the considered indicators. For the diamond prices we can see the following price development since April 2018:","02e2ff76":"* First of all, the dataset is divided by the ratio of approximately 70\/30 into a training and a test data set. This means 806 rows of data are used for training the predictive model and 328 rows for evaluating the model.\n* The model contains a single hidden LSTM layer with 200 units. The number of units in the hidden layer is not related to the number of time steps in the input sequences. The LSTM layer is followed by a completely connected layer with 200 nodes that will interpret the features learned by the LSTM layer. As we want to predict seven days, an output layer will directly predict a vector with seven elements, one for each day in the output sequence.\n* The prices are in USD and it would be useful to have an error metric in the same units. Both Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) fit this bill, although RMSE is more commonly used and will therefore be adopted here. \n* As loss function the mean squared error loss function is used as it is a good match for the chosen error metric of RMSE. \n* For optimization the efficient Adam (Adaptive Moment Estimation) implementation of stochastic gradient descent is used and the model is fitted for 50 epochs with a batch size of 16. The small batch size and the stochastic nature of the algorithm means that the model will learn a slightly different mapping of inputs to outputs each time it is trained. This means results can vary when the model is evaluated. \n* As activation function \"rectified linear unit activation function\" (ReLU) is used. This function allows a fast-learning process.\n* The argument \u201cn_input\u201d is used to define the number of prior observations that the model will use as input in order to make a prediction. n_input is 15 days here, which means that 15 days are used is input to make a prediction. ","463fba52":"A look at inflation rates hypothesizes a strong relation with diamond prices:","fa904e33":"In the next step we plot the predictions:","939950e7":"* Real time prices in the diamond market are reflected by the so-called **Diamond Financial Index (DFX)** which is available on a daily base since 26th April 2018. Datasets for other variables (inflation rate, interest rate, fed rate, gold price) are also downloaded starting with this date. End date is 04th June 2021. This results in five datasets with 1.134 rows each. Columns which are not needed are dropped (volume, change % etc.).\n\n* The five datasets have been downloaded from the following websites and merged to one dataset:\n\n    * diamond price (DFX): https:\/\/www.investing.com\/indices\/get-diamonds-general\n    * inflation rate: https:\/\/fred.stlouisfed.org\/series\/T10YIE\n    * interest rate: https:\/\/fred.stlouisfed.org\/series\/DFII10\n    * fed rate: https:\/\/fred.stlouisfed.org\/series\/DFF\n    * gold price: https:\/\/www.boerse-online.de\/rohstoffe\/historisch\/goldpreis\/usd\/\n\n\n* To merge the datasets, date has been used as index. A few missing values in the datasets have been filled in by copying the value from the day before. The merged dataset has been saved as csv file.\n\n* So we load the csv file in the next step:","f7c15dff":"* After training the model price predictions for natural diamonds are calculated for the next seven days:","8669b7ad":"Fed rate (effective federal funds rate) and risk-free interest rate (10-year treasury inflation-indexed security, constant maturity) are showing a downward trend since 2018:","c15e77d1":"After a robust performance in 2018, we see a challenging year for the diamond industry in 2019 (due to rising trade barriers and political instability) followed by a difficult first half of 2020 (due to the Covid-19 pandemic) and recovery in the second half of 2020 and the beginning of 2021.\n\nGold prices on the contrary are showing a positive trend since 2018:","f8d269fb":"**2.4 Modelling**\n\n* As mentioned before a \u201cMulti-Step LSTM Time Series Forecasting Model\u201d is used to predict future diamond prices. At this point I want to pay tribute to an amazing inspiration:\n\n<div class=\"alert alert-block alert-info\"> \n    \nThe programming code from Jason Brownlee for power usage was adapted to price prediction for this project (https:\/\/machinelearningmastery.com\/how-to-develop-lstm-models-for-multi-step-time-series-forecasting-of-household-power-consumption\/).\nThanks for inspiring me and letting me learn from your work!\n    \n<\/div>","5a99c4a4":"Next, we will take a look on the correlation between the diamond price (our target variable) and our indicators (our input variables). The following heatmap will show the correlations:","b08b337f":"**2.6 Deployment**\n\n* As already mentioned above diamond prices depend on a lot of factors like technological progress, operational disruptions, economic problems, political factors etc. Therefore, it\u2019s surely not possible to do a long-term prediction. The purpose of this paper was to look only to the near future and predict prices for the next seven days. The model can be used with sequential data to forecast other prices like stock market prices or cryptocurrency prices.","0fa1434b":"**2.2 Data Understanding**\n\n* Before modelling the neural network to predict prices in the future, we look at the historical development of diamond prices as well as the considered indicators. \n\n* To analyse the data, we first need to import the required libraries (like Keras, Scikit-learn, Pandas, Numpy, Matplotlib, Seaborn, Math and Datetime).","c77ef323":"**2.5 Evaluation**\n\n* So, when is a model considered skillful? A model is considered skillful if it achieves a performance better than a naive model resp. even better than linear models. What we do here is to compare the overall score of the LSTM with the overall score of a linear regression model.\n* So we first calculate the RMSE of the linear model:","e1707205":"* Then we calculate the RMSE of the LSTM model:","ddf0aaee":"* Thus, the ratio between natural and lab-grown prices is changing over time. So, what we can do is predicting the natural prices in the first step and calculate lab-grown prices in the next step (as lab-grown prices are somehow attached to natural ones as already mentioned) with the following assumptions:\n  * The simplest assumption is to assume that the percentage for lab-growns stays at 35% of the natural ones (conservative scenario). \n  * If the actual downward trend of lab-grown prices continues, lab-grown diamonds could expand into the wider mass jewellery segment (major fashion jewellery retailers are already adding lab-grown diamonds to their product offerings), targeting a different audience than natural diamonds. Ronnie VanderLinden, owner of New York-based wholesaler Diamex Inc., doesn\u2019t expect the price of lab-grown diamonds to fall any further than current Lightbox rates. He assumes that 800 USD a carat is the bottom as there are still the fixed costs of labour and polishing, plus growth, and wages aren\u2019t going back down either. Based on this assumption 800 USD a carat would be the minimum price (pessimistic scenario).\n  * Alternatively, if the trend of product differentiation reverses, we could see more lab-grown diamonds in the premium jewellery segment, compensating for the decreased supply of natural diamonds. In this scenario lab-grown prices could be on a 2017\/18 level (optimistic scenario).\n* As we predict only a few days into the future, the first scenario (conservative scenario) is the scenario we consider.\n* So, we start by predicting the price development of natural diamonds (and calculate the price development of lab-grown diamonds based on these prices). To predict prices, indicators are needed. Empirical findings support the argument that diamond prices in the jewellery segment respond to economic downturns resp. upturns and are therefore also correlated with disposable income. Disposable income in turn has been found to be correlated with inflation rates and interest rates. As historical data on a daily base is available for inflation rates and interest rates (but not for disposable income) these rates are taken into consideration. \n* Because the US are playing a big role in the diamond business, the following US rates are considered:\n * **inflation rate** (10-year breakeven inflation rate)\n * **interest rate** (10-year treasury inflation-indexed security, constant maturity, risk-free) \n * **fed rate** (effective federal funds rate)\n* Furthermore, **gold prices** are taken into consideration as they could be an indicator for diamond prices in the jewellery segment as well.\n","f8e55bfe":"* Based on the price prediction for natural diamonds the prices for lab-grown diamonds are calculated by multiplying the natural prices with 0,35 (ratio between natural and lab-grown prices):","2571207c":"* The overall RMSE for the LSTM across a forecast of the last seven days is 137. \n* So we compare the overall score of 137 with the overall score of the linear regression model. \n* The overall RMSE of the linear regression model predicting the last seven days is 337. \n* Therefor the overall RMSE of the LSTM neural network is much lower and for this reason more skillful than a linear model.","82e76074":"* Please note that in this figure a different y-axis scale is used than in the figures above.","825a75f2":"We can see a strong correlation between the diamond price, and all considered input variables. Inflation rate, interest rate and fed rate are positively correlated whereas the gold price is negatively correlated with the diamond price. This means that the chosen input variables are probably good indicators to predict diamond prices in the future.","91794682":"# 1.\tIntroduction\n\n**1.1\tGoal**\n\nThis notebook has the purpose of analysing and predicting diamond prices using Long Short Term Memory (LSTM) neural network. As input for the LSTM indicators like inflation rate, interest rate (10-year treasury inflation-indexed security, constant maturity, risk-free), fed rate (effective federal funds rate) and gold price are used.\n\n**1.2\tRelevance**\n\nDiamond and graphite are the solid forms of carbon. Diamond as crystalized carbon is widely used in the industry. It can not only be created by compressing graphite, but in a purer and more reliable way via Plasma-enhanced chemical vapor deposition (PECVD). Lab-grown diamonds can be used as investment, windows for ultraviolet lasers, cutting tools or in doped form in the next generation of processors in quantum computing. Above all they are more and more used in jewellery. \n2018 was a turning point for the arise of lab-grown diamonds in the jewellery sector. Before 2018 diamond retailers were not willing to give lab-grown diamonds a chance as they considered themselves as luxury retailers. In May 2018 Lightbox, De Beers\u2019 lab-grown diamond subsidiary, made its debut at JCK Las Vegas (Americas most comprehensive jewellery gathering), just as retail jewellery gatekeepers indicated they were finally open for lab-grown diamonds. Since then, lab-grown diamonds are a fundamental threat to the natural diamond industry. They are not just a competitive product like gems, pearls, or gold jewellery. They are a replacement product. Questions about lab-grown diamond prices and how they are changing are consuming supporters and critics of the lab-grown diamonds in the jewellery sector.\n\n**1.3\tResearch Question**\n\nHow will prices of natural and lab-grown diamonds develop in the future?\n\n**1.4\tCurrent State of Research \u2013 Price Prediction**\n\nWhen it comes to price prediction machine learning has been successful in predicting stock market prices through a host of different time series models. There is also a limited but quite restrictive application in predicting cryptocurrency prices. However, there is no application found so far for diamond price prediction. The reason behind this is obvious as diamond prices depend on a lot of factors like technological progress, operational disruptions, economic problems, political factors etc. \n\n**1.5\tCurrent State of Research \u2013 LSTM**\n\nWe use sequential data as base for our price prediction. For sequential data Recurrent neural networks (RNN) are state of the art. The algorithm remembers its input due to its internal memory, which makes it perfectly applicable for solving machine learning problems involving sequential data. LSTM are an extension of recurrent neural networks. They basically extend the memory so that they can remember inputs over a longer period of time. Moreover, LSTM can remember important information and forget irrelevant information at the same time. Most important LSTMs offer a number of benefits when it comes to multi-step time series forecasting:\n*     Native Support for Sequences: LSTMs are a type of RNN, and as such are designed to take sequence data as input, unlike other models where lag observations must be presented as input features.\n*     Multivariate Inputs: LSTMs directly support multiple parallel input sequences for multivariate inputs, unlike other models where multivariate inputs are presented in a flat structure.\n*     Vector Output: Like other neural networks, LSTMs are able to map input data directly to an output vector that may represent multiple output time steps.\n\n**1.6\tKnowledge Gap**\n\nSeveral code examples for LSTM modelling publicized on data science blogs are wrong because they don\u2019t use the output of LSTM as input for the next prediction. So, they are only replicating the input and lead to wrong results. To avoid that problem in this notebook a \u201cMulti-Step LSTM Time Series Forecasting Model\u201d is used.\n","31c1ab68":"# 3.\tOutlook\n\n* Data has not been normalized before fed into the neural network. Maybe the performance of the LSTM model can be improved by using Min Max Scaler to normalize data. \n* Moreover, the structure and hyperparameters for the LSTM model can be tuned to further lift the model performance on average. Diagnostics such as learning curves for the train and validation loss and mean squared error may help to tune the structure and hyperparameters of the model.\n* Further interesting questions would be to find out\n    * if there is any impact from tweets of certain key players in the diamond jewellery industry (like De Beers, Harry Winston, Tiffany, Cartier etc.) on the fluctuation of the diamond prices.\n    * if there is any correlation between customer sentiment and the development of the diamond prices. \n* If any correlation between customer sentiment and diamond prices could be found and if customer sentiment can be measured with a certain frequency (at best daily), customer sentiment could be used as an input variable for the LSTM model.","070e446e":"![image.png](attachment:90086d74-3e31-4439-9ca6-5d67ab7aebbf.png)\n\nSource: https:\/\/www.bain.com\/insights\/global-diamond-industry-2020-21\/","6a5db4cd":"**2.3 Data Preparation** (done before, therefore not part of this notebook)\n\n* Data merge:\nFive single datasets had to be merged to one dataset. Therefore, date has been used as index. For this purpose the \u201c.set_index\u201d and \u201cpd.to_datetime\u201d functions have been used. Then datasets have been merged with the \u201c.merge\u201d function.\n\n* Fill in missing values:\nThere were a few missing values in the datasets. A very simple approach to fill in missing values is to copy the value from the day before. We implemented this in a function named \u201cfill_missing()\u201d that will take the Numpy array of the data and copy values from one day ago."}}