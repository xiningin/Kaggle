{"cell_type":{"19fd8b51":"code","0af327d0":"code","5dd87e1a":"code","99c90040":"code","b101d0c7":"code","97a49c51":"code","df32e6f4":"code","29e5e0fb":"code","883a0604":"code","efbc726c":"code","4e4f437e":"code","85143262":"code","2c1c7175":"code","05e38d99":"code","3c3aeb12":"code","3573c565":"code","72025a1e":"code","8cf5861d":"code","64ba8ade":"code","586bfd0a":"code","91d3ee6a":"code","bb384494":"code","99d879f1":"code","a210d1e5":"code","38c0a2c7":"code","8610ac1f":"code","90ca5536":"code","1428b39e":"code","ff19f58a":"code","55bf991e":"code","14ab292f":"code","8746061f":"code","6b84f2c3":"markdown","32c284f1":"markdown","4ba70fb1":"markdown","3d141942":"markdown","16d06e12":"markdown","a9060e9a":"markdown","a7dd11e5":"markdown","37a2c0b8":"markdown","046a3cf0":"markdown","becefffd":"markdown","17212ea9":"markdown","f28e04f3":"markdown","07d48f66":"markdown","25ab0fee":"markdown","0ce42576":"markdown","40d1048b":"markdown"},"source":{"19fd8b51":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0af327d0":"df=pd.read_csv('\/kaggle\/input\/Smarket.csv')","5dd87e1a":"df.head()","99c90040":"df.info()","b101d0c7":"df.describe()\ndf=df.drop(columns=['Unnamed: 0'])","97a49c51":"import seaborn as sns\n\nsns.set(rc={'figure.figsize':(11.7,8.27)})\nsns.heatmap(df.corr(),cmap=sns.diverging_palette(20, 220, n=200), linewidths=.5)","df32e6f4":"import matplotlib.pyplot as plt","29e5e0fb":"import plotly.graph_objects as go\nimport plotly.express as px\nimport datetime","883a0604":"sns.countplot(df['Year'])","efbc726c":"checker=df['Year'][0]\ncounter=1\ndf['Date']=0\nfor i in range(len(df)):\n    if df['Year'].iloc[i]==checker:\n        df['Date'].iloc[i]=counter\n        counter+=1\n    else:\n        counter=1\n        checker=df['Year'].iloc[i]\n        df['Date'].iloc[i]=counter\n        ","4e4f437e":"fig = px.line(df, x=\"Date\", y=\"Volume\", color='Year')\nfig.show()","85143262":"fig = px.line(df, x=\"Date\", y=\"Lag1\", color='Year')\nfig.show()","2c1c7175":"vol_means=[]\nsum=0\nchecker=df['Year'][0]\ncounter=0\nfor i in range(len(df)):\n    if df['Year'].iloc[i]==checker:\n        sum+=df['Volume'].iloc[i]\n        counter+=1\n    else:\n        vol_means.append(sum\/counter)\n        checker=df['Year'].iloc[i]\n        sum=0\n        counter=0\nvol_means.append(sum\/counter)","05e38d99":"print(vol_means)\nprint(df.Year.unique())","3c3aeb12":"fig = px.bar(y=vol_means, x=df.Year.unique(),color=vol_means)\nfig.show()","3573c565":"lag_means=[]\nsum=0\nchecker=df['Year'][0]\ncounter=0\nfor i in range(len(df)):\n    if df['Year'].iloc[i]==checker:\n        sum+=df['Lag1'].iloc[i]\n        counter+=1\n    else:\n        lag_means.append(sum\/counter)\n        checker=df['Year'].iloc[i]\n        sum=0\n        counter=0\nlag_means.append(sum\/counter)","72025a1e":"lag_means","8cf5861d":"fig = go.Figure(data=[go.Bar(y=lag_means, x=df['Year'].unique())])\n# Customize aspect\n\nfig.update_traces(marker_color='rgb(152, 180, 212)',marker_line_width=1.5)\nfig.update_layout(title_text='Return on shares Lag1 , avg. per Year',paper_bgcolor='rgb(0, 0, 0)',plot_bgcolor='rgb(0, 0, 0)')","64ba8ade":"lag_means=[]\nsum=0\nchecker=df['Year'][0]\ncounter=0\nfor i in range(len(df)):\n    if df['Year'].iloc[i]==checker:\n        sum+=df['Today'].iloc[i]\n        counter+=1\n    else:\n        lag_means.append(sum\/counter)\n        checker=df['Year'].iloc[i]\n        sum=0\n        counter=0\nlag_means.append(sum\/counter)","586bfd0a":"fig = go.Figure(data=[go.Bar(y=lag_means, x=df['Year'].unique())])\n# Customize aspect\nfig.update_traces(marker_color='rgb(149, 82, 81)', marker_line_color='rgb(155, 35, 53)',\n                  marker_line_width=1.5)\nfig.update_layout(title_text='Return on shares Today , avg. per Year',paper_bgcolor='rgb(223, 207, 190)',plot_bgcolor='rgb(223, 207, 190)')","91d3ee6a":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split","bb384494":"X=df.drop(columns=['Direction'])\ny=pd.get_dummies(df['Direction'])\ny=y.drop(columns='Down')\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nclf = LogisticRegression(random_state=0).fit(X_train, y_train)","99d879f1":"coef=clf.coef_.tolist()","a210d1e5":"coef=coef[0]","38c0a2c7":"for i in range(len(list(coef))):\n    print(X.columns[i],'has coefficient coeff -----------',coef[i])\n    print(\"\")\nprint('Intercept has the coeff------------- ',clf.intercept_)","8610ac1f":"import math\n\n# (p\/1-p)= e^0.827\n\n#Let RHS = x\n\nx=math.exp(0.827)\nprint(x)","90ca5536":"from sklearn.metrics import classification_report, confusion_matrix\n\nclf.score(X_train, y_train)\n","1428b39e":"clf.score(X_test,y_test)","ff19f58a":"cf=confusion_matrix(y_test, clf.predict(X_test))","55bf991e":"sns.heatmap(cf, annot=True)\n","14ab292f":"print(classification_report(y_test, clf.predict(X_test)))","8746061f":"from sklearn import metrics\ny_pred_proba = clf.predict_proba(X_test)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\nauc = metrics.roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","6b84f2c3":"# Interpreting the Logistic regression Coefficients , \n\n1) Log(odds) of being 'UP' as a response increase by 3.7275 for i unit increase in year , i.e we can say that as the years passed by. Making it simpler we can say that if we went from 2001->2002 , our odds of making profit increased by 3.72 \n\n2) Also, we can see the coefficient of today as 8.275 , i.e we can say that , if the Today's return went up by 1% , the log(odds) of being \"UP\" as a response increased by 8.72 . If we want to portray a real picuture -> , if today increased by 0.1% , then the let's calculate the probability increase , that we get an 'UP' .\n\n                                            log( p\/1-p) -> log(odds) increase by 0.827 .\n                                                        p\/1-p =e^0.827\n                                                            p=?\n","32c284f1":"# Its very hard to visulaize this data in its raw form , lets resort to calculating year-wise mean values for lag1 , lag2, volumes","4ba70fb1":"# What does the graph plotted below tell us???\n\n* The year on year volumn of shares traded is increasing.\n* But does it lead to a better responses for us , i.e does this increases \/ decrease the number of ups and downs per year?\n* does it have any change in the lag1-lag5 values?","3d141942":"# The Smarket data , this data showcases the S&P 500 stock idnex for 1250 days . This data is from 2001 to 2005 .For each date the percentage returns on the previous 5 days Lag1-Lag5 have been recorded as follows ->\n\nA data frame with 1250 observations on the following 9 variables.\n\n* Year:The year that the observation was recorded\n\n* Lag1:Percentage return for previous day\n\n* Lag2 :Percentage return for 2 days previous\n\n* Lag3:Percentage return for 3 days previous\n\n* Lag4:Percentage return for 4 days previous\n\n* Lag5:Percentage return for 5 days previous\n\n* Volume:Volume of shares traded (number of daily shares traded in billions)\n\n* Today:Percentage return for today\n\n* Direction:A factor with levels Down and Up indicating whether the market had a positive or negative return on a given day","16d06e12":"# Visualizing Lag1","a9060e9a":"# What does this graph tell us ??\n\n* The graph shows that the values of 1 Day returs were net negative for Year 2001, and year 2002\n* The graph also shows that the value of 1 Day returns were net psoitive for the Year 2003, 2004 ,2005","a7dd11e5":"# STUDYING THE ROC AND AUC ","37a2c0b8":"# Model Fitting","046a3cf0":"### So, here we can see that we technically do not actually have an equally distributed data  ,\n\n1) 2001 - 240 values\n\n2) (2002-2005) - 250 values each","becefffd":"# Visualiztions with Plotyllyyyyyy","17212ea9":"# p\/1-p = 2.286 , so we can say  that probability(p) increases by approximately 0.7 , that we will get 'UP' as an output :)","f28e04f3":"# As we can see that the AUC is approximately  equal to 1 , i really don't need to work out and find another threshold which classifies the data better , also the default threshold =0.5 for the sklearn linear regression has worked trmendouly well , but we could change that if we wanted to :)\n","07d48f66":"# Visulaizing Volumes","25ab0fee":"# Visualizing Today","0ce42576":"## The only correlation we see is between volume and Year , i.e the number of shares traded increases year on year , let's plot this idea to see if it is actually correct ","40d1048b":"# STUDYING THE PRECISION AND RECALL VALUES"}}