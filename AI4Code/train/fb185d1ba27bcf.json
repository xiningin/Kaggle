{"cell_type":{"a60481ca":"code","3ce0967f":"code","bd6c4a3a":"code","d99947b0":"code","6f1d05c8":"code","85aa2b29":"code","125092da":"code","0cc77ba2":"code","4101d5f1":"code","efee16bf":"code","2295ddbe":"code","7838643a":"code","5cf48ac7":"code","9e656020":"code","253c98f9":"code","77325cad":"code","7076e8cd":"code","79239378":"code","2adcbb2c":"code","c00e72f4":"code","e76462be":"markdown","6aaf7a01":"markdown","4eab4660":"markdown","f317105b":"markdown","ef67efae":"markdown","ddf6d2c5":"markdown","44655832":"markdown","8d840aed":"markdown","2a220181":"markdown","5207b2d5":"markdown","691a3e94":"markdown","3496caf0":"markdown","b2edac06":"markdown"},"source":{"a60481ca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3ce0967f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n\nimport os\nfrom os import walk","bd6c4a3a":"import tensorflow as tf\ntf.random.set_seed(0)\ntf.keras.backend.clear_session()","d99947b0":"classes = {\"buildings\":0,\"forest\":1,\"glacier\":2, \"mountain\":3, \"sea\":4, \"street\":5}\ndir_pred = '..\/input\/intel-image-classification\/seg_pred\/seg_pred'\ndir_test = '..\/input\/intel-image-classification\/seg_test\/seg_test'\ndir_train =  '..\/input\/intel-image-classification\/seg_train\/seg_train'","6f1d05c8":"# read in the names of the images in the prediction set\n(dirpath_pred, dirnames_pred, fnames_pred) = next(walk(dir_pred))\nprint(\"Size of the prediction set is {}\".format(len(fnames_pred)))","85aa2b29":"def read_image_names_class(dpath):\n    fnames = {}\n    x, dirnames, y = next(walk(dpath))\n    for d in dirnames:\n        _,_,temp = next(walk(os.path.join(dpath,d)))\n        fnames[classes[d]] = temp        \n    \n    return dirnames, fnames\n\ndef check_class_imbalance(fnames):\n    count = 0\n    class_summary = {}\n    for key,value in fnames.items():\n        count = count + len(value)\n        class_summary[key] = len(value)\n        \n    summary = pd.DataFrame.from_dict(class_summary, orient='index', columns=[\"Count\"])  \n    summary['CumCount'] = np.cumsum(summary['Count']) \n    summary['Class'] = summary.index\n    summary['Class'] = summary['Class'].apply(class_from_key)\n    \n    return summary\n\ndef class_from_key(x):\n    for key, value in classes.items():\n        if x == value:\n            return key\n        \ndef sample_images_from_class(nsample, classname, path, fnames):\n    sind = np.random.random_integers(1,len(fnames[classes[classname]]),nsample)\n    spath = [os.path.join(path, classname, fnames[classes[classname]][i]) for i in sind]\n    \n    return spath\n\ndef plot_sampled_images(path, fnames):\n    nsample = 3\n    ncols = len(classes)\n    \n    fig, ax = plt.subplots(nsample, ncols, figsize=(20, 3*nsample))\n    \n    for i,cl in enumerate(classes.keys()):\n        sp = sample_images_from_class(nsample, cl, path, fnames)\n        for j,spj in enumerate(sp):            \n            img = mpimg.imread(spj)\n            ax[j,i].imshow(img)\n            ax[j,i].axis('off')\n            ax[j,i].set_title(cl)   \n            \ndef sample_prediction_images(path, fnames, nsample):\n    sind = np.random.random_integers(1,len(fnames), nsample)\n    spj = []\n    for sp in sind:\n        spj.append(os.path.join(path, fnames[sp]))\n    \n    return spj\n    \ndef plot_sampled_prediction_images(path, fnames):    \n    nsample = 3\n    ncols = len(classes)\n    \n    fig, ax = plt.subplots(nsample, ncols, figsize=(20, 3*nsample))\n    sind = np.random.random_integers(1,len(fnames), nsample*ncols)\n    \n    axs = ax.ravel()\n    for i, sp in enumerate(sind):\n        spj = os.path.join(path, fnames[sp])\n        img = mpimg.imread(spj)\n        axs[i].imshow(img)\n        axs[i].axis('off')\n    \ndef get_true_pred(model, ds):\n    y = model.predict(ds)\n\n    ytrue = []\n    ypred = []\n\n    ypred.append(np.argmax(y,axis=1))\n    for img, lbl in ds:\n        for l in lbl:\n            ytrue.append(np.argmax(l.numpy()))    \n    \n    return ytrue, ypred\n\ndef plot_confMat(ytrue, ypred):\n    cm = confusion_matrix(y_true = ytrue,y_pred = ypred[0])\n    cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[class_from_key(x) for x in range(6)])\n    fig,ax = plt.subplots(1,1,figsize=(8,8))\n    cmd.plot(include_values=True, cmap = plt.cm.Blues, ax=ax)\n\n    plt.title(\"Accuracy score is {:.2f}\".format(accuracy_score(y_true = ytrue,y_pred = ypred[0])))\n    \ndef read_prepare_image_predict(fpath, mod):\n    img = tf.keras.preprocessing.image.load_img(fpath, grayscale=False, color_mode='rgb')\n    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,4))\n    ax1.imshow(img)\n    ax1.axis('off')\n    \n    parr = tf.keras.preprocessing.image.img_to_array(img)    \n    tparr = tf.expand_dims(parr, axis=0)\n    \n    pred = mod.predict(tparr)\n    y = [p for p in pred[0]]\n    x = [class_from_key(i) for i in range(6)]\n    \n    sns.barplot(x=x,y=y,ax=ax2)\n    \n    return pred","125092da":"dirnames_train, fnames_train = read_image_names_class(dir_train)\ntrain_summary = check_class_imbalance(fnames_train)\ntrain_summary.head(10)\nsns.barplot(data=train_summary, x = 'Class', y='Count').set_title(\"Distribution across classes in training set\")\nplot_sampled_images(dir_train, fnames_train)","0cc77ba2":"dirnames_test, fnames_test = read_image_names_class(dir_test)\ntest_summary = check_class_imbalance(fnames_test)\ntest_summary.head(10)\n\nsns.barplot(data=test_summary, x = 'Class', y='Count').set_title(\"Distribution across classes in test set\")\n\nplot_sampled_images(dir_test, fnames_test)","4101d5f1":"plot_sampled_prediction_images(dir_pred, fnames_pred)","efee16bf":"batch = 32\nshuff = True\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(dir_train,\n                                                               validation_split=0.2,  subset=\"training\",\n                                                               seed=0,  image_size=(150, 150),\n                                                               batch_size=batch, shuffle= shuff, label_mode='categorical')\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(dir_train,\n                                                               validation_split=0.2,  subset=\"validation\",\n                                                               seed=0,  image_size=(150, 150),\n                                                               batch_size=batch, shuffle= shuff, label_mode='categorical')\n","2295ddbe":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","7838643a":"train_model = False","5cf48ac7":"if train_model:\n    mod = tf.keras.models.Sequential([    \n        tf.keras.layers.experimental.preprocessing.Rescaling(scale=1.\/255, input_shape = (150,150,3)),\n        tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.2),\n        tf.keras.layers.experimental.preprocessing.RandomFlip(mode=\"horizontal\"),\n        tf.keras.layers.experimental.preprocessing.RandomRotation(factor=0.05),\n        tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.2, width_factor=0.2),\n        tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=(0.1, 0.3), width_factor=(0.1,0.3)),\n\n        tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.2),\n\n        tf.keras.layers.Conv2D(filters=12, kernel_size=(3,3), activation='relu', padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.2),    \n        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n\n        tf.keras.layers.Conv2D(filters=12, kernel_size=(1,1), activation='relu', padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.2),    \n        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n\n        tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.2),   \n        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n\n        tf.keras.layers.Conv2D(filters=16, kernel_size=(5,5), activation='relu', padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.2),      \n        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n\n        tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.2),\n\n        tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.2),\n\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dropout(0.4),\n\n        tf.keras.layers.Dense(units=256, activation='relu'),\n        tf.keras.layers.Dense(units=128, activation='relu'),\n        tf.keras.layers.Dense(units=6, activation='softmax')\n            ])\n    \n    mets = ['accuracy', tf.metrics.Precision(), tf.metrics.Recall(), \n        tf.metrics.TrueNegatives(), tf.metrics.TruePositives(), tf.metrics.FalseNegatives(), tf.metrics.FalsePositives()]\n    mod.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n                loss=tf.keras.losses.CategoricalCrossentropy(), metrics= ['accuracy'])\n    \n    earlystop = tf.keras.callbacks.EarlyStopping(patience=10, min_delta=1e-3, restore_best_weights=True)\n    lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5, min_lr=1e-7)\n\n    # traindat_aug = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=10, width_shift_range=0.2, height_shift_range=0.2, \n    #                                                           brightness_range=(-2.,2.), zoom_range=0.2, horizontal_flip=True, \n    #                                                           rescale=1.\/255, validation_split=0.2)\n    # testdat_aug = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)\n\n\n    # train_ds = traindat_aug.flow_from_directory(dir_train, target_size=(150,150), batch_size=batch, class_mode='categorical', subset=\"training\")\n    # valid_ds = traindat_aug.flow_from_directory(dir_train, target_size=(150,150), batch_size=batch, class_mode='categorical', subset=\"validation\")\n    # test_ds = testdat_aug.flow_from_directory(dir_test, target_size=(150,150), batch_size=batch, class_mode='categorical')\n\n    # traindat_aug.fit(train_ds)","9e656020":"if train_model:\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"..\/input\/cnn-20210612-0700\/model_weights.h5\", monitor='val_acc', verbose=1, save_weights_only=True, mode='max')\n    hist = mod.fit(train_ds, epochs=50, batch_size=batch, verbose=1, shuffle=shuff, validation_data=val_ds, callbacks=[earlystop, lr, checkpoint])\nelse:\n    with open(\"..\/input\/cnn-20210612-0700\/CNN_Intel.json\",\"r\") as json_file:\n        loaded_model_json = json_file.read()\n        mod = tf.keras.models.model_from_json(loaded_model_json)\n        mod.load_weights(\"..\/input\/cnn-20210612-0700\/model_weights.h5\")\n    mod.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n                loss=tf.keras.losses.CategoricalCrossentropy(), metrics= ['accuracy'])","253c98f9":"mod.summary()","77325cad":"if train_model:\n    for key in hist.history.keys():\n        plt.plot(hist.history[key],label=key)\n    plt.legend()\n    # plt.ylim([0,1])","7076e8cd":"if train_model:\n    model_json = mod.to_json()\n    with open(\"CNN_Intel.json\",\"w\") as json_file:\n        json_file.write(model_json)","79239378":"train_ds1 = tf.keras.preprocessing.image_dataset_from_directory(dir_train,                                                   \n                                                               seed=0,  image_size=(150, 150),\n                                                               batch_size=batch, shuffle= False, label_mode='categorical')\ny_true, y_pred = get_true_pred(mod, train_ds1)\nplot_confMat(y_true, y_pred)\n\nmod.evaluate(train_ds1)","2adcbb2c":"test_ds1 = tf.keras.preprocessing.image_dataset_from_directory(dir_test, seed=0,  image_size=(150, 150),\n                                                               batch_size=batch, shuffle= False, label_mode='categorical')\n# y_test = mod.predict(test_ds)\n# tf.keras.utils.to_categorical(np.argmax(y_test,axis=1))\ny_true, y_pred = get_true_pred(mod, test_ds1)\nplot_confMat(y_true, y_pred)\n\nmod.evaluate(test_ds1)","c00e72f4":"sp = sample_prediction_images(dir_pred, fnames_pred, 5)\nfor spj in sp:\n    read_prepare_image_predict(spj,mod)","e76462be":"# Sample the prediction images","6aaf7a01":"# CNN Model","4eab4660":"# Foreword\n\nMulti-class image classification of natural scenes from around the world\n\n![NaturalScenes-Classification.PNG](attachment:20a9e4ef-3190-4e47-8a31-7f8a79d08e3f.PNG)","f317105b":"# Prediction with test dataset, not seen by the model","ef67efae":"# The data","ddf6d2c5":"# Prediction dataset","44655832":"# Dataset used for training","8d840aed":"# Load libraries","2a220181":"# Load the data","5207b2d5":"# Train the CNN","691a3e94":"# Helper functions","3496caf0":"# Sample the training data","b2edac06":"# Sample the test data"}}