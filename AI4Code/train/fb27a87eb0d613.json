{"cell_type":{"f8a2d4a6":"code","1ef70853":"code","c594774e":"code","a37fc74f":"code","7c274ff1":"code","bbcc2659":"code","7b44b017":"code","50bcdfc1":"code","36275460":"code","82fdfd9c":"code","845e767a":"code","1c48091a":"code","1b8b90d5":"code","1b4a6811":"code","d29c555e":"code","42c21ea4":"code","066fe077":"code","3af7d5f0":"code","447b60ca":"code","aced5956":"code","b07b48ed":"code","c9b947df":"markdown","d25b37dc":"markdown","6efb6266":"markdown","91ea408d":"markdown","3ec425a7":"markdown","a2a69d5f":"markdown","5cc2b50d":"markdown","ec4f1f26":"markdown","215b600e":"markdown","eeb45274":"markdown","40e92efd":"markdown"},"source":{"f8a2d4a6":"import numpy as np\nimport codecs\nimport tensorflow as tf\nimport pandas as pd\nimport ast\nimport tqdm\nprint(tf.__version__)","1ef70853":"dialogs = pd.read_csv('..\/input\/cleaned-data-for-the-chatbot-collected-from-movies\/dialogs_expanded.csv')","c594774e":"dialogs.head()","a37fc74f":"dialogs.shape","7c274ff1":"input_texts = pd.read_csv('..\/input\/cleaned-data-for-the-chatbot-collected-from-movies\/input3.csv')\ntarget_texts = pd.read_csv('..\/input\/cleaned-data-for-the-chatbot-collected-from-movies\/target3.csv')","bbcc2659":"for i in input_texts.index:\n    typ = type(input_texts.text[i])\n    if typ == float:\n        input_texts.text[i] = ' '\n\nfor i in target_texts.index:\n    typ = type(target_texts.text[i])\n    if typ == float:\n        target_texts.text[i] = ' '","7b44b017":"def prepare_vocab(texts):\n    vocab = sorted(set(''.join(texts)))\n    vocab.append('<START>')\n    vocab.append('<END>')\n    vocab_size = len(vocab)\n    char2idx = {u:i for i, u in enumerate(vocab)}\n    idx2char = np.array(vocab)\n    return vocab_size, char2idx, idx2char\n\ninput_texts_for_vocabs = input_texts.text.values.tolist()\ntarget_texts_for_vocabs = target_texts.text.values.tolist()\nINPUT_VOCAB_SIZE, input_char2idx, input_idx2char = prepare_vocab(input_texts_for_vocabs)\nTARGET_VOCAB_SIZE, target_char2idx, target_idx2char = prepare_vocab(target_texts_for_vocabs)","50bcdfc1":"input_texts_as_int = [[input_char2idx[c] for c in text] for text in dialogs['question']]\ntarget_texts_as_int = [[target_char2idx[c] for c in text] for text in dialogs['answer']]","36275460":"encoder_input_seqs = [np.array(text) for text in input_texts_as_int]\ndecoder_input_seqs = []\ndecoder_target_seqs = []\nfor target_text in target_texts_as_int:\n    decoder_input_seqs.append(np.array([target_char2idx['<START>']] + target_text))\n    decoder_target_seqs.append(np.array(target_text + [target_char2idx['<END>']]))","82fdfd9c":"max_enc_seq_length = 100\nmax_dec_seq_length = 100\n\nencoder_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n    encoder_input_seqs,\n    value=input_char2idx[' '],\n    padding='post',\n    maxlen=max_enc_seq_length)\n\ndecoder_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n    decoder_input_seqs,\n    value=target_char2idx[' '],\n    padding='post',\n    maxlen=max_dec_seq_length)\n\ndecoder_target_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n    decoder_target_seqs,\n    value=target_char2idx[' '],\n    padding='post',\n    maxlen=max_dec_seq_length)","845e767a":"max_enc_seq_length, max_dec_seq_length","1c48091a":"encoder_input_seqs.shape, decoder_input_seqs.shape, decoder_target_seqs.shape","1b8b90d5":"''.join(input_idx2char[encoder_input_seqs[0]])","1b4a6811":"H_SIZE = 512 \nEMB_SIZE = 512 \n\nclass Encoder_att(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n        self.embed = tf.keras.layers.Embedding(INPUT_VOCAB_SIZE, EMB_SIZE)\n        self.lstm_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(H_SIZE, return_sequences=True, return_state=True))\n        self.lstm_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(H_SIZE, return_sequences=True, return_state=True))\n        self.lstm_3 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(H_SIZE, return_sequences=True, return_state=True))\n        \n    def call(self, x):\n        out = self.embed(x)\n        out, f_h_1, f_c_1, b_h_1, b_c_1 = self.lstm_1(out)\n        out, f_h_2, f_c_2, b_h_2, b_c_2 = self.lstm_2(out)\n        out, f_h_3, f_c_3, b_h_3, b_c_3 = self.lstm_3(out)\n        h_1 = tf.keras.layers.Concatenate()([f_h_1, b_h_1])\n        c_1 = tf.keras.layers.Concatenate()([f_c_1, b_c_1])\n        h_2 = tf.keras.layers.Concatenate()([f_h_2, b_h_2])\n        c_2 = tf.keras.layers.Concatenate()([f_c_2, b_c_2])\n        h_3 = tf.keras.layers.Concatenate()([f_h_3, b_h_3])\n        c_3 = tf.keras.layers.Concatenate()([f_c_3, b_c_3])\n        state_1 = (h_1, c_1)\n        state_2 = (h_2, c_2)\n        state_3 = (h_3, c_3)\n        return out, (state_1, state_2, state_3)\n\nclass Decoder_att(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n        self.embed = tf.keras.layers.Embedding(TARGET_VOCAB_SIZE, EMB_SIZE)\n        self.lstm_1 = tf.keras.layers.LSTM(H_SIZE*2, return_sequences=True, return_state=True)\n        self.lstm_2 = tf.keras.layers.LSTM(H_SIZE*2, return_sequences=True, return_state=True)\n        self.lstm_3 = tf.keras.layers.LSTM(H_SIZE*2, return_sequences=True, return_state=True)\n        self.attention = tf.keras.layers.Attention()\n        self.fc = tf.keras.layers.Dense(TARGET_VOCAB_SIZE, activation='softmax')\n        \n    def call(self, x, init_state, encoder_outputs, training=True):\n        out = self.embed(x)\n        out, h_1, c_1 = self.lstm_1(out, initial_state=init_state[0])\n        out, h_2, c_2 = self.lstm_2(out, initial_state=init_state[1])\n        out, h_3, c_3 = self.lstm_3(out, initial_state=init_state[2])\n        out = self.attention([out, encoder_outputs], training=training)\n        out = self.fc(out)\n        state_1 = (h_1, c_1)\n        state_2 = (h_2, c_2)\n        state_3 = (h_3, c_3)\n        return out, (state_1, state_2, state_3)\n\nencoder_model_att = Encoder_att()\ndecoder_model_att = Decoder_att()\n\nencoder_inputs_att = tf.keras.layers.Input(shape=(None,))\ndecoder_inputs_att = tf.keras.layers.Input(shape=(None,))\n\nencoder_outputs_att, enc_state_att = encoder_model_att(encoder_inputs_att)\ndecoder_outputs_att, _ = decoder_model_att(decoder_inputs_att, enc_state_att, encoder_outputs_att)\n\nseq2seq = tf.keras.Model([encoder_inputs_att, decoder_inputs_att], decoder_outputs_att)","d29c555e":"seq2seq.summary()","42c21ea4":"BATCH_SIZE = 64\nEPOCHS = 50\n\nloss = tf.losses.SparseCategoricalCrossentropy()\nseq2seq.compile(optimizer='rmsprop', loss=loss, metrics=['accuracy'])\n\nfor iterate in range(0, 40):\n    seq2seq.fit([encoder_input_seqs, decoder_input_seqs], decoder_target_seqs,\\\n          batch_size=BATCH_SIZE, steps_per_epoch=50, epochs=EPOCHS)\n    print(next_line('Tell me about itTell me about it'))\n    print(next_line('What are you thinking about?'))\n    print(next_line('Close the door!'))\n    print(next_line('What is your name?'))\n    print(next_line('How about we have lunch together?'))\n    print(next_line('What time is it?'))\n    seq2seq.save_weights(f'model_att{iterate}iter_expanded')","066fe077":"seq2seq.load_weights('..\/input\/cleaned-data-for-the-chatbot-collected-from-movies\/model_att29iter_expanded')","3af7d5f0":"def seq2seq_att_inference(input_seq):\n    output, state = encoder_model_att(input_seq)\n\n    target_seq = np.array([[target_char2idx['<START>']]])\n\n    decoded_sentence = ''\n    while True:\n        output_tokens, state = decoder_model_att(x=target_seq, init_state=state, encoder_outputs=output, training=False)\n\n        sampled_token_index = np.argmax(np.array(output_tokens[0, -1, :]))\n        sampled_char = target_idx2char[sampled_token_index]\n        decoded_sentence += sampled_char\n\n        if (sampled_char == '<END>' or\n           len(decoded_sentence) > max_dec_seq_length):\n            break\n\n        target_seq = np.array([[sampled_token_index]])\n\n    return decoded_sentence","447b60ca":"def next_line(line):\n    int_seq = np.array([input_char2idx[c] for c in line])\n    int_seq_pad = np.zeros(100)\n    int_seq_pad[:len(int_seq)] = int_seq\n    int_seq_pad = int_seq_pad.reshape(1, -1)\n    decoded = seq2seq_att_inference(int_seq_pad)\n    if decoded[-5:] == '<END>':\n        decoded = decoded[:-5]\n    decoded = decoded.rstrip()\n    return decoded","aced5956":"line = 'Hi, how are you?'\nprint(line)\nfor _ in range(10):\n    line = next_line(line)\n    print(line)","b07b48ed":"def own_dialog(len_of_conversation):\n    for i in range(len_of_conversation):\n        line_input = str(input())\n        line_output = next_line(line_input)\n        print(line_output)\nown_dialog(10)","c9b947df":"#### We are faced with the task of writing a simple chat bot using a neural network. We'll be using the Cornell Movie-Dialogs Corpus dataset. It contains more than 130 thousand refined replicas from 617 films.\n#### What does cleared mean - we can remove all dialogues with long lines. Important: we do not remove the long lines themselves, but the entire dialogues with such lines, so that we have coherent dialogues. Thus, more than 130 thousand replicas turned out and not 220.\n#### Our model will implement the attention mechanism.","d25b37dc":"Let's add padding.","6efb6266":"## Inference","91ea408d":"> It takes a very long time to train again, so we load the weights with the model I have already trained","3ec425a7":"## Create and train the model.\nLet's create a model. Our model will have three bidirectional LSTM layers and an attention mechanism. On our data, the model should train long enough to give a good result.","a2a69d5f":"### Text encoding.\nWe are now ready to encode our sequences numerically. Let's use the functions from the practical assignment.\nFirst, let's code the dictionaries for both sequences.","5cc2b50d":"### Loading the data.","ec4f1f26":"Now let's encode the sequences themselves using dictionaries.\nSince for our model we need to enter the Encoder and enter and exit the Decoder, we will prepare three sequences of numbers.","215b600e":"For the answers to be meaningful, you need to connect BERT or something like this","eeb45274":"## Prepare to learning\n","40e92efd":"Most of the answers are at least grammatically correct"}}