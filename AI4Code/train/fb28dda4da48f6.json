{"cell_type":{"c493fa6f":"code","7d1d1902":"code","9b48aeb8":"code","0a69d12b":"code","f7eda349":"code","bc46b124":"code","1275d54d":"code","072ad3f7":"code","7b09214a":"code","dd338a47":"code","2ce3084c":"code","beeb925a":"code","ed4a6ec7":"code","12f2104e":"code","637c4e32":"code","32b6d33d":"code","b3a92509":"code","b114d0a6":"code","869a20c7":"code","34ca98e5":"code","5a4436ad":"code","9f365461":"code","e29d904a":"code","892a954a":"code","b58dffc6":"code","276e422c":"code","35b3050b":"code","0852060d":"code","101a2303":"code","4795c295":"code","24d9d4cc":"markdown"},"source":{"c493fa6f":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt","7d1d1902":"df=pd.read_csv('..\/input\/logistic-regression\/Social_Network_Ads.csv')","9b48aeb8":"df.head()","0a69d12b":"df.info()","f7eda349":"gen= pd.get_dummies(df.Gender, drop_first=True)\ndf=pd.concat([df,gen], axis=1)\ndf.drop('Gender',axis=1, inplace=True)\ndf.head()","bc46b124":"from sklearn.model_selection import train_test_split","1275d54d":"X= df.drop(['Purchased','User ID'], axis=1)\nX.head()","072ad3f7":"y= df.Purchased\ny.head()","7b09214a":"# train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)","dd338a47":"from sklearn.preprocessing import StandardScaler","2ce3084c":"scaler= StandardScaler()","beeb925a":"X_train[['Age','EstimatedSalary']]=scaler.fit_transform(X_train[['Age','EstimatedSalary']])","ed4a6ec7":"X_train.head()","12f2104e":"purchase_rate= (sum(df['Purchased'])\/len(df['Purchased']))*100\npurchase_rate","637c4e32":"import statsmodels.api as sm","32b6d33d":"lm01= sm.GLM(y_train,(sm.add_constant(X_train)), family= sm.families.Binomial())\nlm01=lm01.fit()\nlm01.summary()","b3a92509":"X_train_sm= sm.add_constant(X_train)","b114d0a6":"y_train_pred=lm01.predict(X_train_sm)","869a20c7":"y_train_pred=y_train_pred.values.reshape(-1)\ny_train_pred[:10]","34ca98e5":"y_train_pred_final= pd.DataFrame({'Purchase':y_train.values, 'Purchase_prob':y_train_pred})\ny_train_pred_final['User ID']=y_train.index\ny_train_pred_final.head()","5a4436ad":"numbers = [float(x)\/10 for x in range(10)]\nfor i in numbers:\n    y_train_pred_final[i]= y_train_pred_final.Purchase_prob.map(lambda x: 1 if x > i else 0)\ny_train_pred_final.head()","9f365461":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix(y_train_pred_final.Purchase, y_train_pred_final[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])\/total1\n    \n    speci = cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","e29d904a":"cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\nplt.show()","892a954a":"# from the above graph we are choosing 0.4 as the cut-off probability\ny_train_pred_final['final_predicted']=y_train_pred_final.Purchase_prob.map( lambda x: 1 if x > 0.4 else 0)\ny_train_pred_final.head()","b58dffc6":"y_train_pred_final.drop([0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9], axis=1, inplace=True)\ny_train_pred_final.head()","276e422c":"#accuracy\nmetrics.accuracy_score(y_train_pred_final.Purchase, y_train_pred_final.final_predicted)","35b3050b":"confusion01= metrics.confusion_matrix(y_train_pred_final.Purchase, y_train_pred_final.final_predicted)\nconfusion01","0852060d":"TP = confusion01[1,1] # true positive \nTN = confusion01[0,0] # true negatives\nFP = confusion01[0,1] # false positives\nFN = confusion01[1,0] # false negatives","101a2303":"# Let's see the sensitivity of our logistic regression model\nTP \/ float(TP+FN)","4795c295":"# Let us calculate specificity\nTN \/ float(TN+FP)","24d9d4cc":"# Model Building"}}