{"cell_type":{"3416a377":"code","890f40a3":"code","25850606":"code","60b15621":"code","852305fe":"code","9b0b3695":"code","684c5838":"code","1531aa59":"code","2b37f7a3":"code","2c2db2d0":"code","b24d281d":"code","9de7d98d":"code","3c183dce":"code","1f87ca71":"code","a9fa1770":"code","db2e7be2":"code","74063f1a":"code","33f45954":"code","c21b8c6f":"code","232f0626":"code","18035e7e":"code","8d030d58":"code","7a8ef681":"markdown","6cc1a0ba":"markdown","2faaa670":"markdown","9548e2a4":"markdown","504525a2":"markdown","18cff345":"markdown","f8cab6ae":"markdown","8d449b7e":"markdown","816ede53":"markdown","81237d5d":"markdown"},"source":{"3416a377":"from modelarts.session import Session\nsession = Session()\nsession.download_data(bucket_path=\"20ai-project\/data.npy\", path=\"\/home\/ma-user\/work\/data.npy\")\nsession.download_data(bucket_path=\"20ai-project\/label.npy\", path=\"\/home\/ma-user\/work\/label.npy\")\nsession.download_data(bucket_path=\"20ai-project\/new_test_data.npy\", path=\"\/home\/ma-user\/work\/new_test_data.npy\")\n# session.download_data(bucket_path=\"20ai-project\/new_test_label.npy\", path=\"\/home\/ma-user\/work\/new_test_label.npy\")","890f40a3":"import os\nimport random\nimport numpy as np\nimport skimage\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom numpy.random import seed\nfrom keras import backend as K\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, TensorBoard\nfrom keras import backend as keras\nfrom keras.models import load_model\nfrom keras.utils import to_categorical\n# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nseed(12345)\nos.mkdir('fig')\nos.mkdir('check1channel')","25850606":"# select your own datapath\ndata = np.load('data.npy')\nlabel = np.load('label.npy')","60b15621":"j = 1500\nplt.figure(figsize=(8,4),dpi=200)\nplt.subplot(1,2,1)\nplt.imshow(np.squeeze(data[j,:,:]),cmap=plt.cm.gray)\nplt.subplot(1,2,2)\nplt.imshow(np.squeeze(label[j,:,:]),interpolation=\"bilinear\",vmin=0.2,vmax=1.0,cmap=plt.cm.gray)\nfigname = '.\/fig\/data_' +str(j)+'.jpg'\nplt.savefig(figname)","852305fe":"def Z_ScoreNormalization(x): #\u7070\u5ea6\u503c\u5f52\u4e00\u5316\n    for i in range(len(x)):\n        mu = np.average(x[i,:])\n        sigma = np.std(x[i,:])\n        x[i,:] = (x[i,:] - mu) \/ sigma;\n    return x;","9b0b3695":"# normalize data\ndata = Z_ScoreNormalization(data)\ndata = np.reshape(data,(2000,128,128,1))\nlabel = np.reshape(label,(2000,128,128,1))\n# split the train_data and val_data\ntrain_data = data[0:1600]\nval_data = data[1600:2000]\ntrain_label = label[0:1600]\nval_label = label[1600:2000]\nprint(train_data.shape)\nprint(val_data.shape)\nprint(train_label.shape)\nprint(val_label.shape)","684c5838":"#given network\ndef unet(pretrained_weights=None, input_size1=(None, None, 1)):\n    input = Input(input_size1, name='input')\n    conv1 = Conv2D(16, (3,3), activation='relu', padding='same')(input)\n    conv1 = Conv2D(16, (3,3), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n\n    conv2 = Conv2D(32, (3,3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(32, (3,3), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n\n    conv3 = Conv2D(64, (3,3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(64, (3,3), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n\n    conv4 = Conv2D(128, (3,3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(128, (3,3), activation='relu', padding='same')(conv4)\n\n    up5 = concatenate([UpSampling2D(size=(2,2))(conv4), conv3], axis=-1)\n    conv5 = Conv2D(64, (3,3), activation='relu', padding='same')(up5)\n    conv5 = Conv2D(64, (3,3), activation='relu', padding='same')(conv5)\n\n    up6 = concatenate([UpSampling2D(size=(2,2))(conv5), conv2], axis=-1)\n    conv6 = Conv2D(32, (3,3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(32, (3,3), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([UpSampling2D(size=(2,2))(conv6), conv1], axis=-1)\n    conv7 = Conv2D(16, (3,3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(16, (3,3), activation='relu', padding='same')(conv7)\n\n    conv8 = Conv2D(1, (1,1), activation='sigmoid')(conv7)\n    model = Model(inputs=[input], outputs=[conv8])\n    model.summary()\n    return model","1531aa59":"#one more layer\n#each layer one more convlution with a (1,1) kernel\ndef unet(pretrained_weights=None, input_size1=(None, None, 1)):\n    input = Input(input_size1, name='input')\n    conv1 = Conv2D(16, (3,3), activation='relu', padding='same')(input)\n    conv1 = Conv2D(16, (3,3), activation='relu', padding='same')(conv1)\n    conv1 = Conv2D(16, (3,3), activation='relu', padding='same')(conv1)\n    conv1 = Conv2D(16, (3,3), activation='relu', padding='same')(conv1)\n    conv1 = Conv2D(16, (3,3), activation='relu', padding='same')(conv1)\n    conv1 = Conv2D(16, (1,1), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n\n    conv2 = Conv2D(32, (3,3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(32, (3,3), activation='relu', padding='same')(conv2)\n    conv2 = Conv2D(32, (3,3), activation='relu', padding='same')(conv2)\n    conv2 = Conv2D(32, (3,3), activation='relu', padding='same')(conv2)\n    conv2 = Conv2D(32, (3,3), activation='relu', padding='same')(conv2)\n    conv2 = Conv2D(32, (1,1), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n\n    conv3 = Conv2D(64, (3,3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(64, (3,3), activation='relu', padding='same')(conv3)\n    conv3 = Conv2D(64, (3,3), activation='relu', padding='same')(conv3)\n    conv3 = Conv2D(64, (3,3), activation='relu', padding='same')(conv3)\n    conv3 = Conv2D(64, (3,3), activation='relu', padding='same')(conv3)\n    conv3 = Conv2D(64, (1,1), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n\n    conv4 = Conv2D(128, (3,3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(128, (3,3), activation='relu', padding='same')(conv4)\n    conv4 = Conv2D(128, (3,3), activation='relu', padding='same')(conv4)\n    conv4 = Conv2D(128, (3,3), activation='relu', padding='same')(conv4)\n    conv4 = Conv2D(128, (3,3), activation='relu', padding='same')(conv4)\n    conv4 = Conv2D(128, (1,1), activation='relu', padding='same')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2,2))(conv4)\n    \n    conv5 = Conv2D(256, (3,3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(256, (3,3), activation='relu', padding='same')(conv5)\n    conv5 = Conv2D(256, (3,3), activation='relu', padding='same')(conv5)\n    conv5 = Conv2D(256, (3,3), activation='relu', padding='same')(conv5)\n    conv5 = Conv2D(256, (3,3), activation='relu', padding='same')(conv5)\n    conv5 = Conv2D(256, (1,1), activation='relu', padding='same')(conv5)\n\n    up6 = concatenate([UpSampling2D(size=(2,2))(conv5), conv4], axis=-1)\n    conv6 = Conv2D(128, (3,3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(128, (3,3), activation='relu', padding='same')(conv6)\n    conv6 = Conv2D(128, (3,3), activation='relu', padding='same')(conv6)\n    conv6 = Conv2D(128, (3,3), activation='relu', padding='same')(conv6)\n    conv6 = Conv2D(128, (3,3), activation='relu', padding='same')(conv6)\n    conv6 = Conv2D(128, (1,1), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([UpSampling2D(size=(2,2))(conv6), conv3], axis=-1)\n    conv7 = Conv2D(64, (3,3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(64, (3,3), activation='relu', padding='same')(conv7)\n    conv7 = Conv2D(64, (3,3), activation='relu', padding='same')(conv7)\n    conv7 = Conv2D(64, (3,3), activation='relu', padding='same')(conv7)\n    conv7 = Conv2D(64, (3,3), activation='relu', padding='same')(conv7)\n    conv7 = Conv2D(64, (1,1), activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([UpSampling2D(size=(2,2))(conv7), conv2], axis=-1)\n    conv8 = Conv2D(32, (3,3), activation='relu', padding='same')(up8)\n    conv8 = Conv2D(32, (3,3), activation='relu', padding='same')(conv8)\n    conv8 = Conv2D(32, (3,3), activation='relu', padding='same')(conv8)\n    conv8 = Conv2D(32, (3,3), activation='relu', padding='same')(conv8)\n    conv8 = Conv2D(32, (3,3), activation='relu', padding='same')(conv8)\n    conv8 = Conv2D(32, (1,1), activation='relu', padding='same')(conv8)\n    \n    up9 = concatenate([UpSampling2D(size=(2,2))(conv8), conv1], axis=-1)\n    conv9 = Conv2D(16, (3,3), activation='relu', padding='same')(up9)\n    conv9 = Conv2D(16, (3,3), activation='relu', padding='same')(conv9)\n    conv9 = Conv2D(16, (3,3), activation='relu', padding='same')(conv9)\n    conv9 = Conv2D(16, (3,3), activation='relu', padding='same')(conv9)\n    conv9 = Conv2D(16, (3,3), activation='relu', padding='same')(conv9)\n    conv9 = Conv2D(16, (1,1), activation='relu', padding='same')(conv9)\n\n    conv10 = Conv2D(1, (1,1), activation='sigmoid')(conv9)\n    model = Model(inputs=[input], outputs=[conv10])\n    model.summary()\n    return model","2b37f7a3":"#one more layer\n#begin with 32\n#each layer one more convlution with a (1,1) kernel\ndef unet(pretrained_weights=None, input_size1=(None, None, 1)):\n    input = Input(input_size1, name='input')\n    conv1 = Conv2D(32, (3,3), activation='relu', padding='same')(input)\n    conv1 = Conv2D(32, (3,3), activation='relu', padding='same')(conv1)\n    conv1 = Conv2D(32, (3,3), activation='relu', padding='same')(conv1)\n    conv1 = Conv2D(32, (3,3), activation='relu', padding='same')(conv1)\n    conv1 = Conv2D(32, (3,3), activation='relu', padding='same')(conv1)\n    conv1 = Conv2D(32, (1,1), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n\n    conv2 = Conv2D(64, (3,3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(64, (3,3), activation='relu', padding='same')(conv2)\n    conv2 = Conv2D(64, (3,3), activation='relu', padding='same')(conv2)\n    conv2 = Conv2D(64, (3,3), activation='relu', padding='same')(conv2)\n    conv2 = Conv2D(64, (3,3), activation='relu', padding='same')(conv2)\n    conv2 = Conv2D(64, (1,1), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n\n    conv3 = Conv2D(128, (3,3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(128, (3,3), activation='relu', padding='same')(conv3)\n    conv3 = Conv2D(128, (3,3), activation='relu', padding='same')(conv3)\n    conv3 = Conv2D(128, (3,3), activation='relu', padding='same')(conv3)\n    conv3 = Conv2D(128, (3,3), activation='relu', padding='same')(conv3)\n    conv3 = Conv2D(128, (1,1), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n\n    conv4 = Conv2D(256, (3,3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(256, (3,3), activation='relu', padding='same')(conv4)\n    conv4 = Conv2D(256, (3,3), activation='relu', padding='same')(conv4)\n    conv4 = Conv2D(256, (3,3), activation='relu', padding='same')(conv4)\n    conv4 = Conv2D(256, (3,3), activation='relu', padding='same')(conv4)\n    conv4 = Conv2D(256, (1,1), activation='relu', padding='same')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2,2))(conv4)\n    \n    conv5 = Conv2D(512, (3,3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(512, (3,3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(512, (3,3), activation='relu', padding='same')(conv5)\n    conv5 = Conv2D(512, (3,3), activation='relu', padding='same')(conv5)\n    conv5 = Conv2D(512, (3,3), activation='relu', padding='same')(conv5)\n    conv5 = Conv2D(512, (1,1), activation='relu', padding='same')(conv5)\n\n    up6 = concatenate([UpSampling2D(size=(2,2))(conv5), conv4], axis=-1)\n    conv6 = Conv2D(256, (3,3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(256, (3,3), activation='relu', padding='same')(conv6)\n    conv6 = Conv2D(256, (3,3), activation='relu', padding='same')(conv6)\n    conv6 = Conv2D(256, (3,3), activation='relu', padding='same')(conv6)\n    conv6 = Conv2D(256, (3,3), activation='relu', padding='same')(conv6)\n    conv6 = Conv2D(256, (1,1), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([UpSampling2D(size=(2,2))(conv6), conv3], axis=-1)\n    conv7 = Conv2D(128, (3,3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(128, (3,3), activation='relu', padding='same')(conv7)\n    conv7 = Conv2D(128, (3,3), activation='relu', padding='same')(conv7)\n    conv7 = Conv2D(128, (3,3), activation='relu', padding='same')(conv7)\n    conv7 = Conv2D(128, (3,3), activation='relu', padding='same')(conv7)\n    conv7 = Conv2D(128, (1,1), activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([UpSampling2D(size=(2,2))(conv7), conv2], axis=-1)\n    conv8 = Conv2D(64, (3,3), activation='relu', padding='same')(up8)\n    conv8 = Conv2D(64, (3,3), activation='relu', padding='same')(conv8)\n    conv8 = Conv2D(64, (3,3), activation='relu', padding='same')(conv8)\n    conv8 = Conv2D(64, (3,3), activation='relu', padding='same')(conv8)\n    conv8 = Conv2D(64, (3,3), activation='relu', padding='same')(conv8)\n    conv8 = Conv2D(64, (1,1), activation='relu', padding='same')(conv8)\n    \n    up9 = concatenate([UpSampling2D(size=(2,2))(conv8), conv1], axis=-1)\n    conv9 = Conv2D(32, (3,3), activation='relu', padding='same')(up9)\n    conv9 = Conv2D(32, (3,3), activation='relu', padding='same')(conv9)\n    conv9 = Conv2D(32, (3,3), activation='relu', padding='same')(conv9)\n    conv9 = Conv2D(32, (3,3), activation='relu', padding='same')(conv9)\n    conv9 = Conv2D(32, (3,3), activation='relu', padding='same')(conv9)\n    conv9 = Conv2D(32, (1,1), activation='relu', padding='same')(conv9)\n\n    conv10 = Conv2D(1, (1,1), activation='sigmoid')(conv9)\n    model = Model(inputs=[input], outputs=[conv10])\n    model.summary()\n    return model","2c2db2d0":"model = unet()\nmodel.compile(optimizer=Adam(lr=5e-4), loss='binary_crossentropy',metrics=['accuracy'])\n# checkpoint\nfilepath=\"check1channel\/fault-{epoch:02d}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy',verbose=1, save_best_only=False, mode='max')\ncallbacks_list = [checkpoint]\nprint(\"data prepared, ready to train!\")\n# Fit the model\nhistory = model.fit(train_data, train_label,\n#                    validation_split=0.2,\n                    validation_data=(val_data,val_label),\n                    epochs=40,\n                    batch_size=8,\n                    shuffle=True,\n                    verbose=1,callbacks=callbacks_list)\n","b24d281d":"def showHistory(history):\n  # list all data in history\n  print(history.history.keys())\n  fig = plt.figure(figsize=(10,6))\n\n  # summarize history for accuracy\n  plt.plot(history.history['acc'])\n  plt.plot(history.history['val_acc'])\n  plt.title('Model accuracy',fontsize=20)\n  plt.ylabel('Accuracy',fontsize=20)\n  plt.xlabel('Epoch',fontsize=20)\n  plt.legend(['train', 'test'], loc='center right',fontsize=20)\n  plt.tick_params(axis='both', which='major', labelsize=18)\n  plt.tick_params(axis='both', which='minor', labelsize=18)\n  plt.show()\n\n  # summarize history for loss\n  fig = plt.figure(figsize=(10,6))\n  plt.plot(history.history['loss'])\n  plt.plot(history.history['val_loss'])\n  plt.title('Model loss',fontsize=20)\n  plt.ylabel('Loss',fontsize=20)\n  plt.xlabel('Epoch',fontsize=20)\n  plt.legend(['train', 'test'], loc='center right',fontsize=20)\n  plt.tick_params(axis='both', which='major', labelsize=18)\n  plt.tick_params(axis='both', which='minor', labelsize=18)\n  plt.show()","9de7d98d":"showHistory(history)","3c183dce":"model = load_model('.\/check1channel\/fault-28.hdf5')","1f87ca71":"# need a threshold to get the true predict result \nthreshold = 0.4\nresult = model.predict(val_data)\nresult[result>threshold]=1\nresult[result<threshold]=0\n# np.save('.\/Data\/data\/result.npy',result)","a9fa1770":"j=200\nplt.figure(figsize=(12,4),dpi=150)\nplt.subplot(1,3,1)\nplt.imshow(np.squeeze(val_data[j,:,:,:]),cmap=plt.cm.gray)\nplt.subplot(1,3,2)\nplt.imshow(np.squeeze(result[j,:,:,:]),interpolation=\"bilinear\",vmin=0.2,vmax=1.0,cmap=plt.cm.gray)\nplt.subplot(1,3,3)\nplt.imshow(np.squeeze(val_label[j,:,:]),interpolation=\"bilinear\",vmin=0.2,vmax=1.0,cmap=plt.cm.gray)\n# savefig\nfigname = '.\/fig\/data_pred_nothreshold_' +str(j)+'.jpg'\nplt.savefig(figname)","db2e7be2":"new_test_data = np.load('new_test_data.npy')\n# new_test_label = np.load('new_test_label.npy')\nreal_test_data = np.reshape(new_test_data,(100,256,640,1))\n# real_test_label = np.reshape(new_test_label,(100,256,640,1))","74063f1a":"temp = 0.25\nreal_result = model.predict(real_test_data)\nreal_result[real_result>temp]=1\nreal_result[real_result<temp]=0\nresult = np.squeeze(real_result)\n# np.save('.\/Data\/data\/real_result.npy',real_result)","33f45954":"j=50\nplt.figure(figsize=(6,6),dpi=150)\nplt.subplot(2,1,1)\nplt.imshow(np.squeeze(real_test_data[j,:,:,:]),cmap=plt.cm.gray)\nplt.subplot(2,1,2)\nplt.imshow(np.squeeze(real_result[j,:,:]),interpolation=\"bilinear\",vmin=0.2,vmax=1.0,cmap=plt.cm.gray)","c21b8c6f":"result_csv = np.reshape(result,(-1))\nprint(result_csv.shape)","232f0626":"df = pd.DataFrame(result_csv)\ndf=df.astype(int)\ndf=df.astype(str)\ndf['index'] = range(len(df))\nnew_col = ['value', 'index']\ndf.columns = new_col\norder = ['index','value']\ndf=df[order]\ndf=df.astype(str)\nprint(df)","18035e7e":"#choose your own name\ndf.to_csv('2_13_5.csv',index=False)","8d030d58":"import moxing as mox\nmox.file.copy('2_13_5.csv','obs:\/\/geo-ai-dataset\/2_13_5.csv')\nprint(\"done\")","7a8ef681":"## 3. Define the neural network","6cc1a0ba":"### 2.1 visualize the train dataset","2faaa670":"## 4. Plot the loss and acc","9548e2a4":"## 2. Load the train dataset","504525a2":"# Final project: Fault Segmentation \n### This assignment is to implement convolutional neural networks for fault data segmentation\n### AI in geosciences, ESS1502","18cff345":"## 7. Output the results as csv and upload it to the kaggle","f8cab6ae":"#### Task: Train and validate your networks\/models on the provide dataset. You are free to use Tensorflow, Keras, or Pytorch to implement your networks. The test result need to upload to the kaggle platform to get the final score ","8d449b7e":"## 5. Validate the network using val_data","816ede53":"## 6. Predictions on the testing datasets and visualize the prediction results","81237d5d":"## 1. Import the requirements"}}