{"cell_type":{"54f74341":"code","a6213675":"code","6f427e58":"code","b8659024":"code","82d7d76f":"code","405c0d9f":"code","090f4b7b":"code","200b4d6f":"code","52153394":"code","c798664c":"code","62bad143":"code","d2cff94d":"code","cb22d7b6":"code","f90747d3":"code","a8c9c05d":"code","88ded7c2":"code","931ff549":"code","bd878d2d":"code","a3ba2b40":"code","979f1a08":"code","74bb384a":"code","18c587f8":"code","33ca1d01":"code","cf00984f":"code","c4b73996":"code","4321c07d":"code","e49eca12":"code","efa5eca2":"code","13268deb":"code","ff12ae56":"code","9e86efaa":"code","eef56499":"code","829ae4a2":"code","824fa65a":"code","62397980":"code","7c5c3fc8":"code","78385ecf":"code","f061a412":"code","a88a8364":"code","eecb4bef":"code","32b8ce4d":"code","ca00fb91":"code","364adea9":"markdown","a8a9229c":"markdown","c23342c6":"markdown","f5c8d9d2":"markdown","2554b198":"markdown","fba8cc72":"markdown","4720542c":"markdown","8619496d":"markdown","15932783":"markdown","47886a2d":"markdown","9cda63ea":"markdown","b5a5752b":"markdown","a60ea2aa":"markdown","82da6f26":"markdown","a71aab1c":"markdown","bf5f09fc":"markdown"},"source":{"54f74341":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LinearRegression, Ridge, ElasticNet, Lasso\nfrom sklearn.linear_model import RidgeCV, ElasticNetCV, LassoCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import StandardScaler\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a6213675":"data = pd.read_csv(\"\/kaggle\/input\/Hitters.csv\")\ndata.head()","6f427e58":"df = data.copy()","b8659024":"df.describe().T","82d7d76f":"corr = df.corr()\nsns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)\nplt.show()","405c0d9f":"df.isna().sum()","090f4b7b":"df.League.value_counts()","200b4d6f":"df.Division.value_counts()","52153394":"df.NewLeague.value_counts()","c798664c":"df.groupby(['League', 'Division']).agg({'Salary':'mean'})","62bad143":"# Fill nan salaries by mean of group(League and Division)\ndf['Salary'] = df.groupby(['League', 'Division'])['Salary'].transform(lambda x: x.fillna(x.mean()))","d2cff94d":"df.isna().sum()","cb22d7b6":"df.info()","f90747d3":"le = LabelEncoder()\ndf['League'] = le.fit_transform(df['League'])\ndf['Division'] = le.fit_transform(df['Division'])\ndf['NewLeague'] = le.fit_transform(df['NewLeague'])\ndf.head()","a8c9c05d":"y = df[['Salary']]\nX = df.drop('Salary', axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 46)\nprint(\"X_train: \", X_train.shape, \"X_test: \", X_test.shape, \"y_train: \", y_train.shape, \"y_test: \", y_test.shape)","88ded7c2":"linreg = LinearRegression()\nlinreg.fit(X_train, y_train)\ny_pred_linreg = linreg.predict(X_test)\nlinreg_error = np.sqrt(mean_squared_error(y_test, y_pred_linreg))\nprint(linreg_error)","931ff549":"ridge = Ridge()\nridge.fit(X_train, y_train)\ny_pred_ridge = ridge.predict(X_test)\nridge_error = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\nprint(ridge_error)","bd878d2d":"alphas = [0.01, 0.001, 0.1, 1, 2, 1.1]\ntuned_ridge = RidgeCV(alphas=alphas).fit(X_train, y_train)\ny_pred_tuned_ridge = tuned_ridge.predict(X_test)\ntuned_ridge_error = np.sqrt(mean_squared_error(y_test, y_pred_tuned_ridge))\nprint(tuned_ridge_error)","a3ba2b40":"tuned_ridge.alpha_","979f1a08":"lasso = Lasso() \nlasso.fit(X_train, y_train)\ny_pred_lasso = lasso.predict(X_test)\nlasso_error = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\nprint(lasso_error)","74bb384a":"alphas = [0.01, 0.001, 0.1, 1, 2, 1.1]\ntuned_lasso = LassoCV(alphas=alphas).fit(X_train, y_train)\ny_pred_tuned_lasso = tuned_lasso.predict(X_test)\ntuned_lasso_error = np.sqrt(mean_squared_error(y_test, y_pred_tuned_lasso))\nprint(tuned_lasso_error)","18c587f8":"enet = ElasticNet()\nenet.fit(X_train, y_train)\ny_pred_enet = enet.predict(X_test)\nenet_error = np.sqrt(mean_squared_error(y_test, y_pred_enet))\nprint(enet_error)","33ca1d01":"alphas = [0.01, 0.001, 0.1, 1, 2, 1.1]\nratios = [.1, .5, .7, .9, .95, .99, 1]\ntuned_enet = ElasticNetCV(alphas=alphas, l1_ratio= ratios).fit(X_train, y_train)\ny_pred_tuned_enet = tuned_enet.predict(X_test)\ntuned_enet_error = np.sqrt(mean_squared_error(y_test, y_pred_tuned_enet))\nprint(tuned_enet_error)","cf00984f":"# plot\nscores = [linreg_error, tuned_ridge_error, tuned_lasso_error, tuned_enet_error]\nplt.plot(scores, marker=\"o\" ) \nplt.legend()\nplt.show()","c4b73996":"clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\nclf.fit_predict(df)\ndf_scores = clf.negative_outlier_factor_\nnp.sort(df_scores)[:30]","4321c07d":"esik_deger = np.sort(df_scores)[4]","e49eca12":"aykiri_tf = df_scores > esik_deger\naykiri_tf[:10]","efa5eca2":"yeni_df = df[aykiri_tf]\nyeni_df","13268deb":"y = yeni_df[['Salary']]\nX = yeni_df.drop('Salary', axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 46)\nprint(\"X_train: \", X_train.shape, \"X_test: \", X_test.shape, \"y_train: \", y_train.shape, \"y_test: \", y_test.shape)","ff12ae56":"linreg = LinearRegression()\nlinreg.fit(X_train, y_train)\ny_pred_linreg = linreg.predict(X_test)\nlinreg_error = np.sqrt(mean_squared_error(y_test, y_pred_linreg))\nprint(linreg_error)","9e86efaa":"alphas = [0.01, 0.001, 0.1, 1, 2, 1.1]\ntuned_ridge = RidgeCV(alphas=alphas).fit(X_train, y_train)\ny_pred_tuned_ridge = tuned_ridge.predict(X_test)\ntuned_ridge_error = np.sqrt(mean_squared_error(y_test, y_pred_tuned_ridge))\nprint(tuned_ridge_error)","eef56499":"alphas = [0.01, 0.001, 0.1, 1, 2, 1.1]\ntuned_lasso = LassoCV(alphas=alphas).fit(X_train, y_train)\ny_pred_tuned_lasso = tuned_lasso.predict(X_test)\ntuned_lasso_error = np.sqrt(mean_squared_error(y_test, y_pred_tuned_lasso))\nprint(tuned_lasso_error)","829ae4a2":"alphas = [0.01, 0.001, 0.1, 1, 2, 1.1]\nratios = [.1, .5, .7, .9, .95, .99, 1]\ntuned_enet = ElasticNetCV(alphas=alphas, l1_ratio= ratios).fit(X_train, y_train)\ny_pred_tuned_enet = tuned_enet.predict(X_test)\ntuned_enet_error = np.sqrt(mean_squared_error(y_test, y_pred_tuned_enet))\nprint(tuned_enet_error)","824fa65a":"# plot\nscores = [linreg_error, tuned_ridge_error, tuned_lasso_error, tuned_enet_error]\nplt.plot(scores, marker=\"o\" ) \nplt.show()","62397980":"from sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense","7c5c3fc8":"scaler = MinMaxScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","78385ecf":"model = Sequential()\n\nmodel.add(Dense(4, activation = 'relu'))\nmodel.add(Dense(64, activation = 'relu'))\nmodel.add(Dense(32, activation = 'tanh'))\nmodel.add(Dense(16, activation = 'relu'))\nmodel.add(Dense(8, activation = 'relu'))\nmodel.add(Dense(4, activation = 'relu'))\n\n\nmodel.add(Dense(1))\n\nmodel.compile(optimizer = 'rmsprop', loss='mse')","f061a412":"model.fit(x = X_train, y = y_train, epochs=250)","a88a8364":"loss_df = pd.DataFrame(model.history.history)\nloss_df.plot();","eecb4bef":"model.evaluate(X_test, y_test, verbose=0)","32b8ce4d":"test_predictions = model.predict(X_test)","ca00fb91":"np.sqrt(mean_squared_error(y_test, test_predictions))","364adea9":"## Lof_Linear_Regression","a8a9229c":"# Lasso Regression","c23342c6":"# Plot","f5c8d9d2":"**After applied LOF we decrease error from 322 to 295.**","2554b198":"# Label Encoder","fba8cc72":"# Filling NaN Values","4720542c":"# ElasticNet","8619496d":"We dropped 5 outlier rows. ","15932783":"## Lof_Ridge_Regression","47886a2d":"## LOF_PLOT","9cda63ea":"# Ridge Regression","b5a5752b":"# Linear Regression","a60ea2aa":"# LOF","82da6f26":"## Lof_ElasticNet_Regression","a71aab1c":"# Keras","bf5f09fc":"## Lof_Lasso_Regression"}}