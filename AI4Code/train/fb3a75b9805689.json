{"cell_type":{"5b637c36":"code","f7be3fd8":"code","8557d30f":"code","038708bd":"code","292f5684":"code","fa9cc84f":"code","ee026e7a":"code","9eae26dc":"code","6a6d869a":"code","a1d06f24":"code","462102c1":"code","588ae620":"code","76f1fe82":"code","7142c973":"code","a1752594":"code","7a621d8f":"code","92c8234b":"code","76260a3c":"code","a550bc2c":"code","bf86099b":"code","706b6f8d":"code","48e6f92b":"code","7b897878":"code","ef7f90ba":"markdown","ec2012b9":"markdown","92aefd41":"markdown","959c0f8d":"markdown","09321f0b":"markdown","17b01588":"markdown","bf2b0ba9":"markdown","0a8e85cc":"markdown","232d4778":"markdown","fb1cef6d":"markdown","4e6d6e01":"markdown"},"source":{"5b637c36":"# This is for HW 3 DS 6040 BML Course\n# Shilpa Narayan (smn7ba)\n# Inspired by code written by William F Basener\n# University of Virginia\n\nimport pymc3 as pm\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt","f7be3fd8":"def plot_traces(traces, retain=0):\n    '''\n    Convenience function:\n    Plot traces with overlaid means and values\n    '''\n\n    ax = pm.traceplot(traces[-retain:],\n                      lines=tuple([(k, {}, v['mean'])\n                                   for k, v in pm.summary(traces[-retain:]).iterrows()]))\n\n    for i, mn in enumerate(pm.summary(traces[-retain:])['mean']):\n        ax[i,0].annotate('{:.2f}'.format(mn), xy=(mn,0), xycoords='data'\n                    ,xytext=(5,10), textcoords='offset points', rotation=90\n                    ,va='bottom', fontsize='large', color='#AA0022')","8557d30f":"data = pd.read_csv('..\/input\/iris-flower-dataset\/IRIS.csv')\ndata = data[['sepal_length','sepal_width','petal_length','petal_width','species']]\nprint(np.unique(data['species']))\ndata.describe()","038708bd":"data.loc[data['species'] == 'Iris-setosa',:].mean()*10","292f5684":"data.loc[data['species'] == 'Iris-setosa',:].cov()*10","fa9cc84f":"g = sns.pairplot(data, hue=\"species\", palette=\"husl\", markers=[\"o\", \"s\", \"D\"])","ee026e7a":"with pm.Model() as model:\n    pm.glm.GLM.from_formula(formula = 'species ~  sepal_length + sepal_width + petal_length + petal_width',  #\n                            data = data, \n                            family = pm.glm.families.Binomial())\n\n    trace = pm.sample(1000)","9eae26dc":"trace.varnames","6a6d869a":"plot_traces(trace)","a1d06f24":"pm.plots.forestplot(trace, figsize=(12, 5))\n# The creates a matplotlib plot, so we can modify with standard matplotlib commands\nplt.grid()  # add a grid to the plot","462102c1":"plt.figure(figsize=(9,7))\nsns.jointplot(trace['petal_length'], trace['petal_width'], kind=\"hex\", color=\"#4CB391\")\nplt.xlabel(\"petal_length\")\nplt.ylabel(\"petal_width\");\nplt.show()\n\nplt.figure(figsize=(9,7))\nsns.jointplot(trace['sepal_length'], trace['sepal_width'], kind=\"hex\", color=\"#4CB391\")\nplt.xlabel(\"sepal_length\")\nplt.ylabel(\"sepal_width\");\nplt.show()\n\nplt.figure(figsize=(9,7))\nsns.jointplot(trace['petal_length'], trace['sepal_length'], kind=\"hex\", color=\"#4CB391\")\nplt.xlabel(\"petal_length\")\nplt.ylabel(\"sepal_length\");\nplt.show()\n\nplt.figure(figsize=(9,7))\nsns.jointplot(trace['sepal_length'], trace['petal_width'], kind=\"hex\", color=\"#4CB391\")\nplt.xlabel(\"sepal_length\")\nplt.ylabel(\"petal_width\");\nplt.show()\n\nplt.figure(figsize=(9,7))\nsns.jointplot(trace['sepal_width'], trace['petal_width'], kind=\"hex\", color=\"#4CB391\")\nplt.xlabel(\"sepal_width\")\nplt.ylabel(\"petal_width\");\nplt.show()","588ae620":"chd_data = pd.read_csv(\"..\/input\/coronary-heart-disease\/CHDdata.csv\")\nchd_data.head()","76f1fe82":"chd_data.describe()","7142c973":"# Standardize the data (mean for each numerical variable of zero, standard deviation of one.)\nfor key in chd_data.keys()[0:9]:\n    try:\n        print(\"Standardizing \"+key+\".\")\n        chd_data[key] = chd_data[key] - np.mean(chd_data[key])\n        chd_data[key] = chd_data[key] \/ np.std(chd_data[key])\n    except:\n        print(\"Predictor \"+key+\" cannot be standardized (probably a categorical variable).\")\nchd_data.describe()","a1752594":"# Lets check the mean of each class to get a first look at the seperation\nprint(\"Mean for CHD Positive:\")\nprint(np.array([chd_data[chd_data.chd == 1].mean()[0:8]]))\nprint(\"Mean for CHD Negative:\")\nprint(np.array([chd_data[chd_data.chd == 0].mean()[0:8]]))","7a621d8f":"chd_data.head()","92c8234b":"from scipy.stats import beta\nfrom scipy.stats import norm","76260a3c":"with pm.Model() as model:\n    my_priors = {\"Intercept\": pm.Normal.dist(mu=0, sd=1),\n               \"sbp\":  pm.Normal.dist(mu=0, sd=1),\n               \"tobacco\": pm.Normal.dist( mu=0, sd=1),\n               \"ldl\": pm.Normal.dist( mu=0, sd=1),\n               \"adiposity\": pm.Normal.dist(mu=0, sd=1),\n               \"typea\": pm.Normal.dist( mu=0, sd=1),\n               \"obersity\": pm.Normal.dist( mu=0, sd=1),\n               \"alcohol\": pm.Normal.dist(mu=0, sd=1),\n               \"age\": pm.Normal.dist(mu=0, sd=1),\n               \"famhist\": pm.Beta('p',1,1)\n              }\n    pm.glm.GLM.from_formula(formula = 'chd ~ sbp + tobacco + ldl + adiposity + typea + obesity + alcohol + age + famhist', \n                            data = chd_data, \n                            family = pm.glm.families.Binomial(),priors=my_priors)\n    \n    approx = pm.fit(50000, method = 'advi')","a550bc2c":"advi_elbo = pd.DataFrame(\n    {'ELBO': -approx.hist,\n     'n': np.arange(approx.hist.shape[0])})\n\n_ = sns.lineplot(y='ELBO', x='n', data=advi_elbo)","bf86099b":"trace_VI = approx.sample(draws=5000)","706b6f8d":"plot_traces(trace_VI)","48e6f92b":"pm.plots.forestplot(trace_VI, figsize=(12, 5))\n# The creates a matplotlib plot, so we can modify with standard matplotlib commands\nplt.grid()  # add a grid to the plot","7b897878":"pm.summary(trace_VI).round(2)","ef7f90ba":"# Question 2. Logistic Regression for Predicting Coronary Heart Disease","ec2012b9":"Here are the variable names in the output.  ","92aefd41":"Load the data and look a the data frame.","959c0f8d":"We are using the seaborn plottng library.  This enables a very nice pairs plot for our classes.","09321f0b":"# Solution 2\n* <b>The results from this analysis are simialr to results from Q2 of the assignment before splitting the data into to training and test data. The variable coefficents almost same as the logit regression from Question 2 before splitting the data into train\/test. <\/b>\n* <b>We used the same data and used non-informative priors therefore the results being similar makes sense.<\/b>","17b01588":"Now we perform our MCMC computaiton.  With pymc3, this is very easy.  We use the usual \"with\" declaration for pymc3, then use glm for our logistic model and just have to specidfy the formula, the data, and the family.  The family is what tells pymc3 that this will be logistic regression.\n\nWe are going to use the default priors for GLM coefficients from PyMC3, which is $p(\\theta)=N(0,10^{12}I)$.  These are very weak priors.","bf2b0ba9":"### Added priors as requested in the question","0a8e85cc":"Now we can build our model in PYMC3 and examine the results:","232d4778":"# Question 1: Bayesian Logistic Regression with PyMC3","fb1cef6d":"We define a function that will be helpful for plotting.  This function does little mathematically, but will give us very nice trace plots.","4e6d6e01":"# Solution 1 \n\n<b>Sepal length and sepal width have the coeffecient as zero in their distribution which means that there may not be a realtionship between the response variable and them or they may have insignificant influence on the response variable. The 94% credible interval for sepal width doesn't include zero thoughg which means that we are 94% confident that there could bea relationship between sepal width and the resposne variable. However, the 94% credible interval for sepal length does contain zero and that means we are 94% confident that the range can include zero as a coeffecient indicating that there may not be a relationship with the resposne variable. The trace plot, forest plot and joint plots above demonstrate the same.<\/b> <Br>\n<br>\n<b>From the firestplots we can observe that among the influencing predictor variables petal_width and petal_length, petal_width has more variability. From the joint plots we can see that, Sepal_width and petal_width seem to have a collinear relationship and that is why may be it is enough to just have one of them in the model. Petal length and sepal length seem to have slight correlation as well. <\/b>"}}