{"cell_type":{"a13151a1":"code","63d18458":"code","79843d83":"code","e37ffb24":"code","3d27ae32":"code","e5d030f8":"code","a24d3d14":"code","1a29a137":"code","aa50fca8":"code","8e24961d":"code","3c2d1309":"code","efb91c6e":"code","5e021f48":"code","86a431ab":"code","6f7a75d5":"code","95b7f25c":"code","74bd350b":"code","cb6b6d07":"code","7d587680":"code","c2d363b1":"code","004e398f":"markdown","ca60a387":"markdown","ad1d926e":"markdown","cc4ea796":"markdown","dc9eeb4f":"markdown","840c61c8":"markdown","c6eeaac9":"markdown","2c5445f8":"markdown","5945ab53":"markdown","b9319914":"markdown","f2a5225f":"markdown"},"source":{"a13151a1":"import os\nbase_dataset_folder = '..\/input\/intel-image-classification'\ntrain_data_folder = os.path.join(base_dataset_folder, 'seg_train\/seg_train')\ntest_data_folder = os.path.join(base_dataset_folder, 'seg_test\/seg_test')\npred_data_folder = os.path.join(base_dataset_folder, 'seg_pred')","63d18458":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.layers.experimental.preprocessing import Rescaling, RandomFlip, RandomRotation, RandomContrast, RandomZoom, RandomTranslation\n\nseed = 42 # By setting a fixed seed, we can generate the same validation split among different runs\n# This is really useful for not mixing training and validation data up in case we decide to load a previously-saved model and resume its training in a different runtime\n\n# Model that rescaled data to a size which is more suitable for NNs\nrescale = tf.keras.Sequential([\n    Rescaling(1.\/255)\n])\n\n# Model that performs random data augmentation\naugment = tf.keras.Sequential([\n    RandomContrast(0.3),\n    RandomFlip('horizontal'),\n    RandomZoom(0.1, 0.1, 'reflect'),\n    RandomRotation(0.1, 'reflect'),\n    RandomTranslation(0.1, 0.1, 'reflect'),\n    layers.Lambda(lambda x: tf.clip_by_value(x, 0, 255))\n])\n\n# Training set (80%) with data augmentation\ntrain_data = image_dataset_from_directory(\n    directory = train_data_folder,\n    labels = 'inferred',\n    label_mode = 'categorical', # One-hot labels\n    batch_size = 64,\n    image_size = (150, 150),\n    shuffle = True, # Shuffle images\n    seed = seed,\n    validation_split = 0.2,\n    subset = 'training'\n).map(lambda x, y: (rescale(augment(x)), y)).repeat()\n\n# Validation set (20%)\n# Data augmentation is NOT applied to validation images\nvalidation_data = image_dataset_from_directory(\n    directory = train_data_folder,\n    labels = 'inferred',\n    label_mode = 'categorical',\n    batch_size = 64,\n    image_size = (150, 150),\n    shuffle = True,\n    seed = seed,\n    validation_split = 0.2,\n    subset = 'validation'\n).map(lambda x, y: (rescale(x), y)).repeat()","79843d83":"import tensorflow.keras as keras\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\n\ninput_layer = keras.Input(shape=(150, 150, 3))\n\nconvbase = InceptionResNetV2(weights = 'imagenet', # Pretrained weights\n    include_top = False, # We will add our own customized top\n    input_tensor = input_layer,\n    pooling = 'avg' # Very good alternative to a flatten layer\n) \n\nconvbase.trainable = False # At the beginning we will train just the top\n\nconvbase.summary()","e37ffb24":"from tensorflow.keras import models, layers\n\n# Define the top of the network\ntop = convbase.output\ntop = layers.Dropout(0.2)(top)\ntop = layers.Dense(1024, activation='relu')(top)\ntop = layers.Dense(512, activation='relu')(top)\ntop = layers.Dense(32, activation='relu')(top)\ntop = layers.Dense(6, activation='softmax')(top)\n\nmodel = keras.Model(convbase.input, top)\nmodel.summary()","3d27ae32":"from tensorflow.keras import backend as K\n\ndef recall(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1))) # All the ones that have a positive label\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    return recall\n\ndef precision(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1))) # All the ones predicted to be positives\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    return precision\n\ndef f1score(y_true, y_pred):\n    p = precision(y_true, y_pred)\n    r = recall(y_true, y_pred)\n    return 2*((p*r)\/(p+r+K.epsilon()))","e5d030f8":"import numpy as np\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n\ncallback_valloss_checkpoint = ModelCheckpoint(\n    filepath = '.\/checkpoints\/epoch-{epoch:02d}_valloss-{val_loss:.4f}_valacc-{val_acc:.4f}.h5',\n    save_weights_only = False, # Save whole model\n    monitor = 'val_loss',\n    mode = 'min',\n    save_best_only = True\n)\n\ncallback_valacc_checkpoint = ModelCheckpoint(\n    filepath = '.\/checkpoints\/epoch-{epoch:02d}_valloss-{val_loss:.4f}_valacc-{val_acc:.4f}.h5',\n    save_weights_only = False,\n    monitor = 'val_acc',\n    mode = 'max',\n    save_best_only = True\n)\n\nlr_start = 0.001; lr_decay = 0.9\ncallback_lrscheduler = LearningRateScheduler(lambda epoch: lr_start * np.power(lr_decay, epoch))","a24d3d14":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc', f1score, precision, recall])\n\nhistory = model.fit(\n    train_data,\n    steps_per_epoch = 175,\n    epochs = 50,\n    validation_data = validation_data,\n    validation_steps = 45,\n    callbacks = [callback_valloss_checkpoint, callback_valacc_checkpoint, callback_lrscheduler]\n)","1a29a137":"# Save final model and optimizer state\nmodel.save('.\/base_model.h5')","aa50fca8":"import matplotlib.pyplot as plt\n\nacc = history.history['acc']; val_acc = history.history['val_acc']\nloss = history.history['loss']; val_loss = history.history['val_loss']\nprec = history.history['precision']; val_prec = history.history['val_precision']\nrecl = history.history['recall']; val_recl = history.history['val_recall']\nf1 = history.history['f1score']; val_f1 = history.history['val_f1score']\n\nepochs = range(len(acc))\n\nfig, axes = plt.subplots(1, 3, figsize=(25,6))\nfig.tight_layout()\n\naxes[0].plot(epochs, acc, 'bo', label='Training accuracy')\naxes[0].plot(epochs, val_acc, 'b', label='Validation accuracy')\naxes[0].set_title('Training and validation accuracy')\naxes[0].legend()\n\naxes[1].plot(epochs, loss, 'co', label='Training loss')\naxes[1].plot(epochs, val_loss, 'c', label='Validation loss')\naxes[1].set_title('Training and validation loss')\naxes[1].legend()\n\naxes[2].plot(epochs, prec, 'ro', label='Training precision')\naxes[2].plot(epochs, val_prec, 'r', label='Validation precision')\naxes[2].plot(epochs, recl, 'yo', label='Training recall')\naxes[2].plot(epochs, val_recl, 'y', label='Validation recall')\naxes[2].plot(epochs, f1, 'go', label='Training f1-score')\naxes[2].plot(epochs, val_f1, 'g', label='Validation f1-score')\naxes[2].set_title('Training and validation precision\/recall\/f1')\naxes[2].legend()\n\nplt.show()","8e24961d":"# best = '\/.\/checkpoints\/epoch-?_valloss-?_valacc-?.h5'\nbest = '.\/base_model.h5' # No need to load a intermediate checkpoint since there was no visible overfitting\n\n# Load best model and optimizer state\nmodel = models.load_model(best, custom_objects={'f1score': f1score, 'precision': precision, 'recall': recall})\nmodel.compile(loss=model.loss, optimizer=model.optimizer, metrics=['acc', f1score, precision, recall])","3c2d1309":"for layer in model.layers: layer.trainable = True # Re-enable the training for the convnet weights\nfor i in range(-4, 0): model.layers[i].trainable = False # But disable the training for the top\n\nmodel.summary()","efb91c6e":"callback_valloss_checkpoint = ModelCheckpoint(\n    filepath = '.\/checkpoints\/tuned_epoch-{epoch:02d}_valloss-{val_loss:.4f}_valacc-{val_acc:.4f}.h5',\n    save_weights_only = False,\n    monitor = 'val_loss',\n    mode = 'min',\n    save_best_only = True\n)\n\ncallback_valacc_checkpoint = ModelCheckpoint(\n    filepath = '.\/checkpoints\/tuned_epoch-{epoch:02d}_valloss-{val_loss:.4f}_valacc-{val_acc:.4f}.h5',\n    save_weights_only = False,\n    monitor = 'val_acc',\n    mode = 'max',\n    save_best_only = True\n)\n\nlr_start = 0.0001; lr_decay = 0.9 # Initial LR 10 times smaller than with top training, since the convnet is already well-trained\ncallback_lrscheduler = LearningRateScheduler(lambda epoch: lr_start * np.power(lr_decay, epoch))","5e021f48":"history = model.fit(\n    train_data,\n    steps_per_epoch = 175,\n    epochs = 30,\n    validation_data = validation_data,\n    validation_steps = 45,\n    callbacks = [callback_valloss_checkpoint, callback_valacc_checkpoint, callback_lrscheduler]\n)","86a431ab":"model.save('.\/finetuned_model.h5')","6f7a75d5":"acc = history.history['acc']; val_acc = history.history['val_acc']\nloss = history.history['loss']; val_loss = history.history['val_loss']\nprec = history.history['precision']; val_prec = history.history['val_precision']\nrecl = history.history['recall']; val_recl = history.history['val_recall']\nf1 = history.history['f1score']; val_f1 = history.history['val_f1score']\n\nepochs = range(len(acc))\n\nfig, axes = plt.subplots(1, 3, figsize=(25,6))\nfig.tight_layout()\n\naxes[0].plot(epochs, acc, 'bo', label='Training accuracy')\naxes[0].plot(epochs, val_acc, 'b', label='Validation accuracy')\naxes[0].set_title('Training and validation accuracy')\naxes[0].legend()\n\naxes[1].plot(epochs, loss, 'co', label='Training loss')\naxes[1].plot(epochs, val_loss, 'c', label='Validation loss')\naxes[1].set_title('Training and validation loss')\naxes[1].legend()\n\naxes[2].plot(epochs, prec, 'ro', label='Training precision')\naxes[2].plot(epochs, val_prec, 'r', label='Validation precision')\naxes[2].plot(epochs, recl, 'yo', label='Training recall')\naxes[2].plot(epochs, val_recl, 'y', label='Validation recall')\naxes[2].plot(epochs, f1, 'go', label='Training f1-score')\naxes[2].plot(epochs, val_f1, 'g', label='Validation f1-score')\naxes[2].set_title('Training and validation precision\/recall\/f1')\naxes[2].legend()\n\nplt.show()","95b7f25c":"# Test set\ntest_data = image_dataset_from_directory(\n    directory = test_data_folder,\n    labels = 'inferred',\n    label_mode = 'categorical',\n    batch_size = 16,\n    image_size = (150, 150),\n    shuffle = True,\n).map(lambda x, y: (rescale(x), y)).repeat()","74bd350b":"scores = model.evaluate(test_data, steps=100, verbose=0)\n\nprint('Accuracy: %.4f - Loss: %.4f\\nF1-score: %.4f - Precision: %.4f - Recall: %.4f' % (scores[1], scores[0], scores[2], scores[3], scores[4]))","cb6b6d07":"labels = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n\nit = iter(test_data)\nbatch = next(it) # Gets a batch of 16 test images\n\nfig, axes = plt.subplots(4, 4, figsize=(15,15))\nfig.tight_layout()\nfig.subplots_adjust(hspace=.25)\n\nfor i in range(4):\n    for j in range(4):\n        ax = axes[i,j]\n        image = batch[0][i*4+j].numpy()\n        net_input = image.reshape((1, 150, 150, 3))\n        truth = np.argmax(batch[1][i*4+j])\n        prediction = np.argmax(model.predict(net_input))\n        ax.set_title('Label: %s\\nPrediction: %s' % (labels[truth].capitalize(), labels[prediction].capitalize()))\n        ax.imshow(image)","7d587680":"# Prediction set\nprediction_data = image_dataset_from_directory(\n    directory = pred_data_folder,\n    label_mode = None,\n    batch_size = 16,\n    image_size = (150, 150),\n    shuffle = True,\n).map(lambda x: rescale(x)).repeat()","c2d363b1":"it = iter(prediction_data)\nbatch = next(it) # Gets a batch of 16 prediction images\n\nfig, axes = plt.subplots(4, 4, figsize=(15,15))\nfig.tight_layout()\n\nfor i in range(4):\n    for j in range(4):\n        ax = axes[i,j]\n        image = batch[i*4+j].numpy()\n        net_input = image.reshape((1, 150, 150, 3))\n        prediction = np.argmax(model.predict(net_input))\n        ax.set_title('%s' % labels[prediction].capitalize())\n        ax.imshow(image)","004e398f":"# Training the top","ca60a387":"# Fine-tuning results","ad1d926e":"![InceptionResNetv2](https:\/\/1.bp.blogspot.com\/-O7AznVGY9js\/V8cV_wKKsMI\/AAAAAAAABKQ\/maO7n2w3dT4Pkcmk7wgGqiSX5FUW2sfZgCLcB\/s1600\/image00.png)","cc4ea796":"# Fine-tuning the convnet","dc9eeb4f":"# Defining custom metrics","840c61c8":"# Network model","c6eeaac9":"# Loading the dataset","2c5445f8":"# Training results","5945ab53":"# Final considerations\n\n1. It might be worth to re-train the wole model without separating a validation set from the training data - in this way the network would have more samples to train with, instead of using it for validating its performance.\n2. The dataset contains a little bit of noise and some images of certain classes (street\/building, mountain\/glacier) are not easy to classify either for a human, since the difference among these classes is really subtle sometimes.\n3. All the code included in this notebook was developed during a 5-day university contest organized at the end of a machine learning course.","b9319914":"# Testing some predictions","f2a5225f":"# Score on test data"}}