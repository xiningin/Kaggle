{"cell_type":{"9290f979":"code","f9f23c7f":"code","e7904c6c":"code","6fbadc74":"code","91d21e1e":"code","3f41d65d":"code","8fecab7f":"code","e31948c4":"code","91d0e7f9":"code","e1348c89":"code","8afcbe2d":"code","326939a2":"code","59eddd38":"code","b83ee923":"code","ba5144b1":"code","1451bb29":"code","b4e29e5c":"code","ec464124":"code","dfba320b":"code","81bc29e3":"code","293d4310":"code","75ac78c2":"code","f19e4454":"code","2801dfce":"code","60d46cc5":"code","f874fca7":"code","15449eac":"code","19edb78d":"code","ad6efff2":"code","7ddce5f6":"code","293e672d":"code","280f996a":"code","ff10b291":"code","5716d2f6":"code","1029d00d":"code","3b8758e1":"code","22e1788a":"code","7b056395":"code","27867ac3":"code","6d741063":"code","bcb65143":"code","132bf190":"code","dc46043a":"code","4c5bfac5":"code","d1d16f3f":"code","fa272979":"code","125984f0":"code","eee815d7":"code","6d16f5f9":"markdown","e89be579":"markdown","e2092f8a":"markdown","d98ade85":"markdown","6e9aa547":"markdown","b14385ed":"markdown","ea86abe2":"markdown","63bee946":"markdown","60dfd023":"markdown","1f7d396b":"markdown","ca1e0eca":"markdown","8aa25450":"markdown","46d1998a":"markdown","7600bef4":"markdown","cad1156e":"markdown","6e5344cd":"markdown","f64088e7":"markdown","cfe7a9ec":"markdown"},"source":{"9290f979":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f9f23c7f":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns ","e7904c6c":"data_diamond=pd.read_csv('..\/input\/diamonds\/diamonds.csv')\ndata_diamond.head()","6fbadc74":"data_diamond.shape","91d21e1e":"data_diamond.describe()","3f41d65d":"data_diamond.info()","8fecab7f":"data_diamond.dtypes","e31948c4":"data_diamond.mean()","91d0e7f9":"data_diamond.median()","e1348c89":"data_diamond.columns","8afcbe2d":"#finding numeric columns \ndiamond_numeric=data_diamond.select_dtypes(include=[np.number])\nnumeric_cols=diamond_numeric.columns.values\nprint(numeric_cols)","326939a2":"#finding non numeric columns \ndiamond_non_numeric=data_diamond.select_dtypes(exclude=[np.number])\nnon_numeric_cols=diamond_non_numeric.columns.values\nprint(non_numeric_cols)","59eddd38":"#finding out the missing data from heatmap \ncols=data_diamond.columns[:30]\ncolours=['#000099', '#ffff00']\nsns.heatmap(data_diamond[cols].isnull(),cmap=sns.color_palette(colours))","b83ee923":"#finding missing data through percentage list \nfor col in data_diamond.columns:\n    pct_missing=np.mean(data_diamond[col].isnull())\n    print('{} - {}%'.format(col, round(pct_missing*100)))","ba5144b1":"data_diamond.count()","1451bb29":"data_diamond.shape","b4e29e5c":"data_diamond.nunique()","ec464124":"data_diamond.isnull().sum()","dfba320b":"#finding the rows that consist of duplicate data \nduplicate_rows_diamond=data_diamond[data_diamond.duplicated()]\nprint(\"number of duplicated rows: \",duplicate_rows_diamond.shape)\n","81bc29e3":"correlations=data_diamond.corr()\nsns.heatmap(correlations,annot=True, xticklabels=correlations.columns,yticklabels=correlations.columns)","293d4310":"#renaming the column names \ndata_diamond=data_diamond.rename(columns={\"Unnamed: 0\":\"Count\",\"x\":\"X-axis\",\"y\":\"Y-axis\",\"z\":\"Z-axis\"})\ndata_diamond.head(5)","75ac78c2":"data_diamond.head(5)","f19e4454":"sns.pairplot(data=data_diamond)","2801dfce":"sns.relplot(x='carat',y='price',hue='cut',data=data_diamond)","60d46cc5":"sns.relplot(x='clarity',y='price',hue='color',data=data_diamond)","f874fca7":"sns.distplot(data_diamond['X-axis'],bins=10)","15449eac":"sns.distplot(data_diamond['Y-axis'],bins=5)","19edb78d":"sns.distplot(data_diamond['Z-axis'],bins=5)","ad6efff2":"sns.catplot(x='table',kind='box',color='red',data=data_diamond)","7ddce5f6":"sns.catplot(x='depth',kind='box',data=data_diamond,color='green')","293e672d":"sns.catplot(x='price',kind='box',data=data_diamond,color='blue')","280f996a":"fig=plt.figure(figsize=(18,6))\nsns.boxplot(x=\"cut\",y=\"price\",data=data_diamond)\nplt.title(\"Cut versus Price\")\nplt.show()","ff10b291":"fig=plt.figure(figsize=(16,8))\nsns.boxplot(x=\"color\",y=\"price\",data=data_diamond)\nplt.title(\"Color Versus Price\")\nplt.show()","5716d2f6":"fig=plt.figure(figsize=(16,8))\nsns.boxplot(x=\"clarity\",y=\"price\",data=data_diamond)\nplt.title(\"clarity versus price\")\nplt.show()","1029d00d":"fig=plt.figure(figsize=(16,8))\nsns.boxplot(x=\"carat\",y=\"price\",data=data_diamond)\nplt.title(\"carrat versus price\")\nplt.show()","3b8758e1":"fig=plt.figure(figsize=(16,8))\nsns.boxplot(x=\"table\",y=\"price\",data=data_diamond)\nplt.title(\"table versus price\")\nplt.show()","22e1788a":"fig=plt.figure(figsize=(16,8))\nsns.boxplot(x=\"depth\",y=\"price\",data=data_diamond)\nplt.title(\"Depth versus price\")\nplt.show()","7b056395":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\nfrom sklearn .preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder","27867ac3":"#converting categorical value in numerical value \ndf_diamond=data_diamond.apply(LabelEncoder().fit_transform)\ndf_diamond.head(5)","6d741063":"x= df_diamond[['carat','cut','color','clarity','price']]\ny=df_diamond[['table','depth','X-axis','Y-axis','Z-axis']]","bcb65143":"x","132bf190":"y","dc46043a":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=10)","4c5bfac5":"len(x_train) , len(x_test), len(y_train),len(y_test)","d1d16f3f":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\n\nlr.fit(x_train,y_train)\n\ny_pred=lr.predict(x_test)\n\nscore_lr= lr.score(x_test,y_test)\naccuracy_lr= cross_val_score(estimator=lr,X= x_train, y= y_train,cv=8, verbose=1)\nr2_lr= r2_score(y_test,y_pred)\nmse_lr = mean_squared_error(y_test,y_pred)\n\n#printing results \nprint(\"score is: \",score_lr)\nprint(\"accuracy is: \",accuracy_lr)\nprint(\"r2_score is: \",r2_lr)\nprint(\"mean squared error is: \",mse_lr)\n","fa272979":"dec_tree= DecisionTreeRegressor(random_state=0)\n\ndec_tree.fit(x_train,y_train)\n\ny_pred=dec_tree.predict(x_test)\naccuracy_dt=cross_val_score(estimator=dec_tree, X=x_train, y=y_train,cv=8, verbose=1)\nscore_dt= dec_tree.score(x_test,y_test)\nr2_dt=r2_score(y_test,y_pred)\nmse_dt=mean_squared_error(y_test,y_pred)\n\nprint(\"Accuracy is: \",accuracy_dt)\nprint(\"Score is: \",score_dt)\nprint(\"r2_score is: \",r2_dt)\nprint(\"mean squared error is: \",mse_dt)","125984f0":"rf_reg= RandomForestRegressor(max_depth=2,random_state=0)\n\nrf_reg.fit(x_train,y_train)\n\naccuracy_rf= cross_val_score(estimator=rf_reg, X = x_train, y= y_train, cv=8, verbose=1)\nscore_rf= rf_reg.score(x_test,y_test)\nr2_rf=r2_score(y_test,y_pred)\nmse_rf=mean_squared_error(y_test,y_pred)\n\nprint(\"Accuracy is: \",accuracy_rf)\nprint(\"Score is: \",score_rf)\nprint(\"r2_score is: \",r2_rf)\nprint(\"mean squared error: \",mse_rf)\n","eee815d7":"k = KNeighborsRegressor(n_neighbors=2)\nk.fit(x_train, y_train)\n\ny_pred=k.predict(x_test)\n\naccuracy_k= cross_val_score(estimator=k, X = x_train, y= y_train,cv=8, verbose=1)\nscore_k= k.score(x_test,y_test)\nr2_k=r2_score(y_test,y_pred)\nmse_k=mean_squared_error(y_test,y_pred)\n\nprint(\"Accuracy is: \",accuracy_k)\nprint(\"Score is: \",score_k)\nprint(\"r2_Score is: \",r2_k)\nprint(\"mean squared error is: \",mse_k)","6d16f5f9":"The above percentage list and heat mapshows that dataset is already clean and have no missing data ","e89be579":"> First we will find uncleaned data through heatmap and percentage list method ","e2092f8a":"# KNeighbors Regression","d98ade85":"> we have renamed some column names which efficiently descirbes data within them ","6e9aa547":"# Decision Tree Regressor ","b14385ed":"> # visualizing basic insights of data which are useful for data cleaning ","ea86abe2":"# Dividing into train and test data ","63bee946":"> viewing table columns and information through pandas library ","60dfd023":"> before finding any results of visualization of dataset we will first find correlation between columns of our cleaned data set which is type of heatmap ","1f7d396b":">  now we will show name of columns in our dataset and find out which one is numeric and which one is non numeric for data cleaning purpose","ca1e0eca":"# Random Forest Regression","8aa25450":"> we will now find unique values and see if there is any duplicate data present in the dataset or not \nif we will find any duplicate data or row we will simply either replace numeric value with median or we will just drop that particular column","46d1998a":"The rows in the dataset doesnot consist of duplicate rows ","7600bef4":"# Linear Regression Model ","cad1156e":"# Data Cleaning \nData cleaning is important step before analysing any data and finding insight of that data, while working on any dataset its necessary to find out either the data is clean or unclean.\n\nif it is clean then we should go for exploratory data analysis and if data is uncleaned then we should first clean the data ","6e5344cd":"# Exploratory Data Analysis","f64088e7":"> Now we will use divide the dataset into training and testing dataset through train test split function and perform regression techniques to find accuracy and other relevant values ","cfe7a9ec":"# Import basic libraries for visualization"}}