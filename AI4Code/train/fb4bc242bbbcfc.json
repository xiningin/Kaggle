{"cell_type":{"b29d14ad":"code","d651a772":"code","8fedbf0e":"code","7ed9d514":"code","c4bfdbd4":"code","aa9cf6b2":"code","465242e8":"code","91017e75":"code","5bec91af":"code","2b7fa6b6":"code","235cdd28":"code","3fcbe9bb":"code","e945c3ef":"code","374f51fa":"code","00d2eb07":"code","521405de":"code","1b9d73ce":"code","7b9d1510":"code","43f61b77":"code","3ccd1c44":"code","265d6a58":"code","aaea87c6":"code","2e95680f":"code","eedd6e71":"code","47358751":"code","63b2cdeb":"code","6a4d37ec":"code","a6f09347":"code","b36c5764":"code","46387fe0":"code","54eee73e":"code","c1a37f9e":"code","a1ebdf36":"code","1e35d1d2":"code","93280e97":"code","ca99984e":"code","5c53e515":"code","2c8f5d07":"code","88e19c6e":"code","73052856":"code","3a70df93":"code","9a283373":"code","922d95b1":"code","00fe6662":"code","ae88322f":"code","fa72035a":"code","6d68703e":"markdown","bae3b2f4":"markdown","a950fac1":"markdown","80f33118":"markdown","e4c0a7f0":"markdown","71b56ec3":"markdown","c271d4c2":"markdown"},"source":{"b29d14ad":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scikitplot as skplt\nimport matplotlib.gridspec as gridspec\n%matplotlib inline\nfrom IPython.display import display_html\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\n\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC \nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, accuracy_score\nimport tensorflow as tf\nimport matplotlib.gridspec as gridspec\nfrom sklearn.metrics import roc_curve, auc\n\nblue_red = ['#74a09e','#86c1b2','#98e2c6','#f3c969','#f2a553', '#d96548', '#c14953']\nsns.palplot(sns.color_palette(blue_red))\n\n# Set Style\nsns.set_style(\"whitegrid\")\nsns.despine(left=True, bottom=True)","d651a772":"seed = 42\ntf.random.set_seed(\n    seed\n)\n","8fedbf0e":"df = pd.read_csv('..\/input\/coronary-artery-disease\/Coronary_artery.csv')\nprint(print('Features:{}'.format(df.columns.tolist())))","7ed9d514":"df['class'].replace({4: 3}, inplace = True)","c4bfdbd4":"df.head(5)","aa9cf6b2":"df.info()","465242e8":"df.describe()","91017e75":"print(df.shape)\nprint(df.isnull().values.any())","5bec91af":"df2 = pd.read_csv('..\/input\/coronary-artery-disease\/data.csv')\ndf2.info()","2b7fa6b6":"df2 = df2[~df2.isin(['?'])]\ndf2 = df2.dropna(axis=0)\ndf2['class'].replace({4: 3}, inplace = True)\ndf2.info()","235cdd28":"df2.head()","3fcbe9bb":"correlation_mat = df2.corr()\nplt.figure(figsize=(20,20))\nax=sns.heatmap(correlation_mat, annot = True)\nplt.show(ax)","e945c3ef":"#sns.pairplot(df2, height = 1.5, palette = 'rocket')","374f51fa":"black_red = [\n    '#1A1A1D', '#4E4E50', '#C5C6C7', '#6F2232', '#950740', '#C3073F'\n]","00d2eb07":"fig = plt.figure(constrained_layout = True, figsize = (25,12))\n\n#create grid\n\ngrid = gridspec.GridSpec(ncols = 4, nrows = 2, figure = fig)\n\nax1 = fig.add_subplot(grid[0, :2])\nax1.set_title('Gender Distribution')\n\n\nsns.countplot(df['sex'],\n             alpha = 0.9,\n             hue = df['class'],\n             ax = ax1,\n             palette = 'rocket',\n             order=df['sex'].value_counts().index)\n\nax1.legend()\nplt.xticks(fontsize = 14)\n\nax2 = fig.add_subplot(grid[0, 2:])\nax2.set_title('Chest Pain Distribution')\nsns.countplot(df['cp'],\n             alpha = 0.9,\n             hue = df['class'],\n             ax = ax2, \n             palette = 'rocket',\n             order=df['cp'].value_counts().index)\nax2.legend()\nplt.xticks( fontsize = 14)\n\nax3 = fig.add_subplot(grid[1, :2])\nax3.set_title('Resting Electrographic Results Distribution')\nsns.countplot(df['restecg'],\n             alpha = 0.9,\n             hue = df['class'],\n             ax = ax3, \n             palette = 'rocket',\n             order=df['restecg'].value_counts().index)\nax3.legend()\nplt.xticks(fontsize = 14)\n\nax4 = fig.add_subplot(grid[1, 2:])\nax4.set_title('Defect Type Distribution')\nsns.countplot(df['thal'],\n             alpha = 0.9,\n             hue = df['class'],\n             ax = ax4, \n             palette = 'rocket',\n             order=df['thal'].value_counts().index)\nax4.legend()\nplt.xticks(fontsize = 14)\nplt.show()","521405de":"fig = plt.figure(constrained_layout = True, figsize = (15,9))\n\n#create grid\n\ngrid = gridspec.GridSpec(ncols = 1, nrows = 4, figure = fig)\nax1 = fig.add_subplot(grid[0, :])\n\nsns.distplot(df.age, ax = ax1, color = blue_red[1])\nax1.set_title('Age Distribution')\n\nax2 = fig.add_subplot(grid[1, :])\nsns.distplot(df.chol, ax = ax2, color = blue_red[2])\nax2.set_title('Cholestrol Distribution')\n\n\nax3 = fig.add_subplot(grid[2, :])\nsns.distplot(df.trestbps, ax = ax3, color = blue_red[3])\nax3.set_title('Resting Blood Sugar Distribution')\n\nax4 = fig.add_subplot(grid[3, :])\nsns.distplot(df.thalach, ax = ax4, color = blue_red[4])\nax4.set_title('Maximum Heart Rate Distribution')","1b9d73ce":"import plotly.express as px\nfig = px.sunburst(data_frame = df,\n                 path = [ 'sex','class','cp'],\n                 color = 'class',\n                 maxdepth = -1,\n                 title = 'Sunburst Chart gender > class > chestpain')\nfig.update_traces(textinfo = 'label+percent parent')\nfig.update_layout(margin=dict(t=0, l=0, r=0, b=0))\nfig.show()","7b9d1510":"print(df2.sex.unique())\nprint(df2.cp.unique())\nprint(df2.fbs.unique())\nprint(df2.restecg.unique())\nprint(df2.exang.unique())\nprint(df2.slope.unique())\nprint(df2.ca.unique())\nprint(df2.thal.unique())","43f61b77":"df_new = df2.rename(columns={'class': 'label'})\nformula = 'label ~ age+sex+cp+trestbps+chol+fbs+restecg+thalach+exang+oldpeak+slope+ca+thal'\nresult = smf.glm(formula = formula, data=df_new).fit()\nprint(result.summary())","3ccd1c44":"#df_new['label'].replace({4: 3}, inplace = True)","265d6a58":"X = df_new[['cp', 'restecg', 'thalach', 'oldpeak', 'slope', 'ca', 'thal']]\nY = df_new['label']\nX = pd.get_dummies(X, columns=['cp', 'restecg', 'slope', 'ca', 'thal'])\nX.head()","aaea87c6":"X_train, X_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.20, random_state=42)","2e95680f":"tree_model = DecisionTreeClassifier(max_depth = 25)\ntree_model.fit(X_train, y_train)\ny_pred_tree = tree_model.predict(X_test)\n\ny_pred_train_tree = tree_model.predict(X_train)\ntree_confusion = metrics.confusion_matrix(y_train, y_pred_train_tree)\nprint('Confusion Matrix for Train:\\n{}'.format(tree_confusion))\nacc=accuracy_score(y_train, y_pred_train_tree) \nprint('Train case accuracy is :'+ format(acc))\nprint('\\n')\n\ny_pred_test_tree = tree_model.predict(X_test)\ntree_confusion = metrics.confusion_matrix(y_test, y_pred_test_tree)\nprint('Confusion Matrix for Test:\\n{}'.format(tree_confusion))\nacc= accuracy_score(y_test, y_pred_test_tree)\nprint('Test case accuracy is :'+ format(acc))\nprint('\\n')\n\nprint(classification_report(y_test, y_pred_test_tree))","eedd6e71":"y_pred_prob_tree = tree_model.predict_proba(X_test)\n\nskplt.metrics.plot_roc(y_test, y_pred_prob_tree, figsize = (10, 10))\nplt.show()","47358751":"# Feature Scaling\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n","63b2cdeb":"\n# Fitting Random Forest Classification to the Training set\nclassifier = RandomForestClassifier(n_estimators = 15, criterion = 'entropy', random_state = 42)\nclassifier.fit(X_train, y_train)\n\ny_pred_train = classifier.predict(X_train)\n\n# Making the Confusion Matrix\nrandom_confusion = metrics.confusion_matrix(y_train, y_pred_train)\nprint('Confusion Matrix for train:\\n{}'.format(random_confusion))\nacc=accuracy_score(y_train, y_pred_train)\nprint('Train case accuracy is :'+ format(acc))\nprint('\\n')\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nrandom_confusion = metrics.confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix for test:\\n{}'.format(random_confusion))\nacc=accuracy_score(y_test, y_pred)\nprint('Test case accuracy is :'+ format(acc))\nprint('\\n')\nprint(classification_report(y_test, y_pred))","6a4d37ec":"y_pred_prob_rf = classifier.predict_proba(X_test)\nskplt.metrics.plot_roc(y_test, y_pred_prob_rf, figsize = (10, 10))\nplt.show()","a6f09347":"svm_model_linear = SVC(decision_function_shape='ovo',kernel = 'poly', C = 1, probability = True).fit(X_train, y_train) \n#kernel='poly' gives best result\n\nsvm_predictions_train = svm_model_linear.predict(X_train) \ncm1 = metrics.confusion_matrix(y_train, svm_predictions_train) \nacc1=accuracy_score(y_train, svm_predictions_train)\nprint('Confusion Matrix for train:\\n{}'.format(cm1))\nprint('Train case accuracy is :'+ format(acc1))\nprint('\\n')\nsvm_predictions = svm_model_linear.predict(X_test) \n# creating a confusion matrix  and finding accuracy\ncm = metrics.confusion_matrix(y_test, svm_predictions) \nacc=accuracy_score(y_test, svm_predictions)\nprint('Confusion Matrix for test:\\n{}'.format(cm))\nprint('Test case accuracy is :'+ format(acc))\nprint('\\n')\nprint(classification_report(y_test, svm_predictions))","b36c5764":"y_pred_prob_svm = svm_model_linear.predict_proba(X_test)\nskplt.metrics.plot_roc(y_test, y_pred_prob_svm, figsize = (10, 10))\nplt.show()","46387fe0":"# training a KNN classifier \n\nknn = KNeighborsClassifier(n_neighbors = 7).fit(X_train, y_train) \nknn_predictions_train = knn.predict(X_train) \ncm1 = metrics.confusion_matrix(y_train, knn_predictions_train) \nacc1=accuracy_score(y_train, knn_predictions_train)\nprint('Confusion Matrix for train:\\n{}'.format(cm1))\nprint('Train case accuracy is :'+ format(acc1))\nprint('\\n')\nknn_predictions = knn.predict(X_test) \n# creating a confusion matrix  and finding accuracy\ncm = metrics.confusion_matrix(y_test, knn_predictions) \nacc=accuracy_score(y_test, knn_predictions)\nprint('Confusion Matrix for test:\\n{}'.format(cm))\nprint('Test case accuracy is :'+ format(acc))\nprint('\\n')\nprint(classification_report(y_test, knn_predictions))","54eee73e":"y_pred_prob_knn = knn.predict_proba(X_test)\nskplt.metrics.plot_roc(y_test, y_pred_prob_knn, figsize = (10, 10))\nplt.show()","c1a37f9e":"\n# instantiate model\nlogreg = LogisticRegression()\n\n# fit model\nlogreg.fit(X_train, y_train)\ny_pred_train = logreg.predict(X_train)\ny_pred_class = logreg.predict(X_test)\nconfusion1 = metrics.confusion_matrix(y_train, y_pred_train)\nacc=accuracy_score(y_train, y_pred_train)\nconfusion = metrics.confusion_matrix(y_test, y_pred_class)\nacc1=accuracy_score(y_test, y_pred_class)\nprint(confusion1)\nprint('Train case accuracy is :'+ format(acc))\nprint('\\n')\nprint(confusion)\nprint('Test case accuracy is :'+ format(acc1))\nprint('\\n')\nprint(classification_report(y_test, y_pred_class))","a1ebdf36":"y_pred_prob_log = logreg.predict_proba(X_test)\n#plt.figure(figsize = (10, 10))\nskplt.metrics.plot_roc(y_test, y_pred_prob_log, figsize = (10, 10))\nplt.show()","1e35d1d2":"X= df2[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach','exang', 'oldpeak', 'slope', 'ca', 'thal']]\n\ny= df2['class']\nX = np.asarray(X).astype('float32')\ny = np.asarray(y).astype('float32')\n# Split the dataset using a 70:30 split\nX_train1, X_test1, y_train1, y_test1 = model_selection.train_test_split(X, y, test_size=0.20, random_state=0)\n\n#Check the shape of each variable, remember the X variable must be in matrix form and the y varibale a vector\nX_train1.shape, y_train1.shape, X_test1.shape, y_test1.shape","93280e97":"from keras.utils.np_utils import to_categorical\n\nY_train1 = to_categorical(y_train1, num_classes=None)\nY_test1 = to_categorical(y_test1, num_classes=None)\nprint(Y_train1.shape)\nprint(Y_train1[:10])","ca99984e":"import tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers.core import Flatten, Dense, Dropout\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import Adam\nmodel = Sequential()\nmodel.add(Dense(16, input_dim=13, kernel_initializer='normal', activation='relu'))\nmodel.add(Dense(10, kernel_initializer='normal', activation='relu'))\nmodel.add(Dense(8, kernel_initializer='normal', activation='relu'))\nmodel.add(Dense(4, activation='softmax'))\n#compiling model\nadam = Adam(lr = 0.001)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])","5c53e515":"estop = EarlyStopping(patience=10, mode='min', min_delta=0.001, monitor='val_loss')\n\nhistory = model.fit(X_train1, Y_train1, validation_data=(X_test1, Y_test1), epochs=100, batch_size=10, verbose = 1, callbacks = [estop])","2c8f5d07":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('MODEL ACCURACY')\nplt.ylabel('Accuracy')\nplt.xlabel('No. of epochs')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","88e19c6e":"categorical_pred = np.argmax(model.predict(X_train1), axis=1)\n\nprint('Results for Categorical Model')\nprint(accuracy_score(y_train1, categorical_pred))\nprint(classification_report(y_train1, categorical_pred))","73052856":"probas = model.predict_proba(X_test1, batch_size=10)\nskplt.metrics.plot_roc(y_test1, probas, figsize = (10, 10))","3a70df93":"Y_train_binary = y_train1.copy()\nY_test_binary = y_test1.copy()\n\nY_train_binary[Y_train_binary > 0] = 1\nY_test_binary[Y_test_binary > 0] = 1\n\nprint(Y_train_binary[:20])","9a283373":"model2 = Sequential()\nmodel2.add(Dense(8, input_dim=13, kernel_initializer='normal', activation='relu'))\nmodel2.add(Dense(4, kernel_initializer='normal', activation='relu'))\nmodel2.add(Dense(1, activation='sigmoid'))\n#compiling model\nadam = Adam(lr = 0.001)\nmodel2.compile(loss=\"binary_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])","922d95b1":"history2 = model2.fit(X_train1, Y_train_binary, validation_data=(X_test1, Y_test_binary), epochs=100, batch_size=10, verbose = 1, callbacks = [estop])","00fe6662":"plt.plot(history2.history['accuracy'])\nplt.plot(history2.history['val_accuracy'])\nplt.title('MODEL ACCURACY')\nplt.ylabel('Accuracy')\nplt.xlabel('No. of epochs')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","ae88322f":"y_pred_prob = model2.predict_proba(X_test1)\nfpr1, tpr1, thresholds1 = metrics.roc_curve(Y_test_binary, y_pred_prob)\n\nrandom_probs = [0 for i in range(len(y_test))]\np_fpr, p_tpr, _ = metrics.roc_curve(y_test, random_probs, pos_label=1)\nplt.style.use('seaborn')\n\n# plot roc curves\nplt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Test Data')\nplt.plot(p_fpr, p_tpr, linestyle='--', color='blue', label = 'Threshold')\n# title\nplt.title('ROC curve for Logistic Regression')\n# x label\nplt.xlabel('False Positive Rate')\n# y label\nplt.ylabel('True Positive rate')\n\nplt.legend(loc='best')\nplt.savefig('ROC',dpi=300)\nplt.show();\nprint('AUC socre for Test data: {}'.format(metrics.roc_auc_score(Y_test_binary, y_pred_prob)))","fa72035a":"binary_pred = np.round(model2.predict(X_test1)).astype(int)\n\nprint('Results for Binary Model')\nprint(accuracy_score(Y_test_binary, binary_pred))\nprint(classification_report(Y_test_binary, binary_pred))","6d68703e":"# SVM","bae3b2f4":"# Logistic Regression\n","a950fac1":"# Decision Tree","80f33118":"# Random Forest","e4c0a7f0":"# Binary NN","71b56ec3":"# KNN","c271d4c2":"# Neural Net"}}