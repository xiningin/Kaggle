{"cell_type":{"3182274e":"code","f20a3146":"code","93aec95a":"code","1051e465":"code","a4f69ada":"code","a3fc61a3":"code","25a40164":"code","fd454c25":"code","70f708a3":"code","b53edf47":"code","86c34b8d":"code","3ff40940":"markdown","2d81ff13":"markdown","27171cdc":"markdown","553118b7":"markdown","97260b55":"markdown","07ad42e1":"markdown","fcf30b3c":"markdown","cedae616":"markdown","021ed7df":"markdown"},"source":{"3182274e":"import os, math, glob, re\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport matplotlib.pyplot as plt\n\nfrom kaggle_datasets import KaggleDatasets\n\nfrom tensorflow.keras import layers\nimport tensorflow as tf","f20a3146":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)","93aec95a":"mri_types = ['FLAIR','T1w','T1wCE','T2w']\nIMAGE_SIZE  = 128\nIMAGE_DEPTH = 32\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nCHANNELS  = len(mri_types)\n\nAUTO = tf.data.AUTOTUNE","1051e465":"GCS_PATH = KaggleDatasets().get_gcs_path(\"rsna-brain-tumor-classification-tfrecords\")\ntf_train_path = GCS_PATH + \"\/tfrecords\/train\"\ntf_valid_path = GCS_PATH + \"\/tfrecords\/valid\"","a4f69ada":"def deserialize_example(serialized_string):\n    image_feature_description = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'MGMT_value': tf.io.FixedLenFeature([], tf.float32)\n    }\n    parsed_record = tf.io.parse_single_example(serialized_string, image_feature_description)\n    image = tf.io.decode_raw(parsed_record['image'], tf.float64)\n    image = tf.reshape(image,[IMAGE_SIZE,IMAGE_SIZE,IMAGE_DEPTH,CHANNELS])\n    \n    label = parsed_record['MGMT_value']\n    return image, label","a3fc61a3":"train_set = tf.data.TFRecordDataset(str(tf_train_path + os.sep + \"brain_train.tfrec\"),\n                                   compression_type=\"GZIP\", num_parallel_reads=AUTO).map(deserialize_example).batch(BATCH_SIZE).prefetch(AUTO)\nvalid_set = tf.data.TFRecordDataset(str(tf_valid_path + os.sep + \"brain_val.tfrec\"),\n                                   compression_type=\"GZIP\", num_parallel_reads=AUTO).map(deserialize_example).batch(BATCH_SIZE).prefetch(AUTO)","25a40164":"d = train_set.take(1)\nfor i, j in d:\n    image = i\n    label = j\n\n\nimg_id = np.random.randint(0, BATCH_SIZE)\nchannel = np.random.randint(0,CHANNELS)\n\nplt.figure(figsize=(20,10),facecolor=(0,0,0))\ncols = IMAGE_DEPTH\/\/4\nrows = 4\n\nplt.axis(\"off\")\nfor layer_idx in range(IMAGE_DEPTH):\n    ax = plt.subplot(rows,cols,layer_idx+1)\n    ax.imshow(np.squeeze(image[img_id,:,:,layer_idx,channel]), cmap=\"gray\")\n    ax.axis(\"off\")\n    ax.set_title(str(layer_idx+1),color='r',y=-0.01)\n    \nplt.suptitle(f\"Batch Image NO.: {img_id}, MRI Type: {mri_types[channel]}, Shape: {image[img_id].shape}\", color=\"w\")\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.show()","fd454c25":"def get_model(width=128, height=128, depth=32):\n\n    inputs = tf.keras.Input((width, height, depth, 4))\n\n    x = layers.Conv3D(filters=32, kernel_size=2, activation=\"relu\", padding=\"same\")(inputs)\n    x = layers.MaxPool3D(2)(x)\n\n    x = layers.Conv3D(filters=64, kernel_size=2, activation=\"relu\", padding=\"same\")(x)\n    x = layers.MaxPool3D(2)(x)\n\n    x = layers.Conv3D(filters=128, kernel_size=2, activation=\"relu\", padding=\"same\")(x)\n    x = layers.MaxPool3D(2)(x)\n    \n    x = layers.Conv3D(filters=256, kernel_size=2, activation=\"relu\", padding=\"same\")(x)\n    x = layers.MaxPool3D(2)(x)\n    \n    x = layers.Conv3D(filters=512, kernel_size=2, activation=\"relu\", padding=\"same\")(x)\n    x = layers.MaxPool3D(2)(x)\n    \n    x = layers.Flatten()(x)\n    x = layers.Dense(units=128, activation=\"relu\")(x)\n    x = layers.Dense(units=128, activation=\"relu\")(x)\n\n    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n\n    model = tf.keras.Model(inputs, outputs)\n\n    return model\n\n\nwith strategy.scope():\n    model = get_model(width=IMAGE_SIZE, height=IMAGE_SIZE, depth=IMAGE_DEPTH)\n    model.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(),metrics=[\"accuracy\", \"AUC\"])\n\nmodel.summary()","70f708a3":"early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=5)\nhistory = model.fit(train_set, validation_data=valid_set, epochs=10, callbacks=[early_stopping_cb])","b53edf47":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(16,7))\nacc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(1,len(acc)+1) # Get number of epochs\nax1 = plt.subplot(1,2,1)\nax1.plot(epochs, acc, 'r')\nax1.plot(epochs, val_acc, 'b')\nax1.set_xticks([i for i in epochs])\nax1.set_title('Training and validation Accuracy')\nax1.legend([\"Training\", \"Validation\" ])\nax1.set_xlabel(\"epochs\")\nax1.set_ylabel(\"Accuracy\")\n\nax2 = plt.subplot(1,2,2)\nax2.plot(epochs, loss, 'r')\nax2.plot(epochs, val_loss, 'b')\nax2.set_xticks([i for i in epochs])\nax2.legend([\"Training\", \"Validation\" ])\nax2.set_xlabel(\"Epochs\")\nax2.set_ylabel(\"Loss\")\nax2.set_title('Training and validation loss')\n\nplt.show()","86c34b8d":"model.save(\"my_simple_model_v2.h5\")","3ff40940":"# Create Model","2d81ff13":"# Read TFRecords and Create Dataset","27171cdc":"# Prediction and Submission","553118b7":"# Plot Model Metrics","97260b55":"I have converted Original dataset with [this](https:\/\/www.kaggle.com\/kavehshahhosseini\/rsna-brain-tumor-convert-dicom-to-tfrecord) notebook to TFRecords and I have created a new dataset, which you can find it [here](https:\/\/www.kaggle.com\/kavehshahhosseini\/rsna-brain-tumor-classification-tfrecords). You should add the converted dataset, to the notebook to go further. I have splitted the data to train with 465 samples and each of them with shape `(128,128,32,4)` and validation data with 117 samples and the same shape.  ","07ad42e1":"# Visualize Image","fcf30b3c":"# Set Constants","cedae616":"I have created another kernel for prediction ","021ed7df":"# Train Model"}}