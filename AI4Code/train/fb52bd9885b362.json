{"cell_type":{"4a65dbbe":"code","bcf798a4":"code","454c908f":"code","6eb79921":"code","c8c2892d":"code","f9339854":"code","e8440f5e":"code","94d7a0c1":"code","a5ff38ec":"code","0d724d10":"code","7dd23755":"code","72eb4abf":"code","f35ed253":"code","adf4ae28":"code","de2fb299":"code","c74b497f":"code","a36827bd":"code","779b2919":"code","388d0a66":"code","d24a9e51":"code","430947e8":"code","f873b127":"code","c15df835":"code","4ec3fc94":"code","13461b37":"code","af2423d0":"code","22a5991f":"code","72bd86e8":"code","8e68cd61":"code","bef74bc2":"code","83458e8e":"code","1abb4a88":"code","b0a00c54":"code","ae66d241":"code","31ec8e4d":"markdown","ac379ef8":"markdown","785a8a18":"markdown","cce8162a":"markdown","ecd6e78d":"markdown","09087747":"markdown","73ca993e":"markdown","d1d31f2c":"markdown","04b156f9":"markdown","ef07ef54":"markdown","e29176a4":"markdown","2756875a":"markdown","0c178fe5":"markdown","51f8b2f0":"markdown","c3179acb":"markdown","39fd373e":"markdown","46f541ae":"markdown"},"source":{"4a65dbbe":"!python -m pip install -U gensim\n# Add environment Packages paths to conda\nimport os, sys\n# env_name = \"food_review\"\n# sys.path.append(f\"C:\\\\Environments\\\\{env_name}\\\\lib\\\\site-packages\\\\\")\n\nimport pandas as pd\nimport numpy as np\n\n# Text preprocessing packages\nimport nltk # Text libarary\n# nltk.download('stopwords')\nimport string # Removing special characters {#, @, ...}\nimport re # Regex Package\nfrom nltk.corpus import stopwords # Stopwords\nfrom nltk.stem import SnowballStemmer, WordNetLemmatizer # Stemmer & Lemmatizer\nfrom gensim.utils import simple_preprocess  # Text ==> List of Tokens\n\n# Text Embedding\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Modelling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Saving Model\nimport pickle\n\n# Visualization Packages\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(font_scale=1.3)\n%matplotlib inline\n\nnltk.download('stopwords')","bcf798a4":"%%time\ndf = pd.read_csv('..\/input\/amazon-fine-food-reviews\/Reviews.csv')\ndf.head()","454c908f":"f\"{df.shape[0]:,} Review\"","6eb79921":"cols = ['Text', 'Score']\ndf_text = df[cols].copy()\ndf_text","c8c2892d":"df_text.drop_duplicates(keep = False, inplace = True)\ndf_text","f9339854":"df_text['target'] = [0 if i < 3 else 1 for i in df_text['Score']]\ndf_text","e8440f5e":"sns.countplot(x= df_text['target'])","94d7a0c1":"# Sample from positive reviews Same number of negative reviews\nNEG_N = df_text.target.value_counts()[0]\ndf_pos = df_text[df_text['target'] == 1]['Text'].sample(NEG_N, replace=False)\ndf_text_balanced = pd.concat([df_text.loc[df_pos.index], df_text[df_text.target == 0]])","a5ff38ec":"df_text_balanced","0d724d10":"## PLot the target again after balancing\n## Write your code here\nsns.countplot(x= df_text_balanced['target'])","7dd23755":"# from nltk.tokenize import word_tokenize\n\n# tokenized_text = df_text.apply(lambda row: nltk.word_tokenize(row['Text']), axis=1)\n\n# stop_words = set(stopwords.words('english'))\n# stemmer = SnowballStemmer(\"english\")\n\n\n# tokenized_text\nfrom nltk.corpus import stopwords\ndf_text_balanced['Text'] = df_text_balanced['Text'].apply(lambda x: \" \".join(x.lower() for\nx in x.split()))","72eb4abf":"df_text_balanced['Text'] = df_text_balanced['Text'].str.replace('[^\\w\\s]', \"\")\ndf_text_balanced.Text.head(5)","f35ed253":"#remove the stopwords\nstop = stopwords.words('english')\ndf_text_balanced['Text'] = df_text_balanced['Text'].apply(lambda x: \" \".join(x for x in\nx.split() if x not in stop))\ndf_text_balanced.Text.head()","adf4ae28":"#Lemmatization\n!python -m pip install \"textblob==0.15.3\"\nfrom textblob import TextBlob\nfrom textblob import Word\n\n\ndf_text_balanced['Text'] = df_text_balanced['Text'].apply(lambda x: \" \".join([Word(word).\nlemmatize() for word in x.split()]))\ndf_text_balanced.Text.head()","de2fb299":"X = df_text_balanced['Text'] ## Write your code here\ny = df_text_balanced['target'] ## Write your code here\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\nprint(X.shape)\nprint(y.shape)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","c74b497f":"## TFIDF embedding for the Description\nvectorizer = TfidfVectorizer() ## Write your code here\n# fit on training (such vectorizer will be saved for deployment)\nvectorizer_tfidf = vectorizer.fit(X_train) ## Write your code here\n# transform on training data\nX_train = vectorizer_tfidf.fit_transform(X_train) ## Write your code here\n# transform on testing data\nX_test = vectorizer.transform(X_test) ## Write your code here\n","a36827bd":"# See the dimensions of your data embeddings before entering to the model\nX_train.shape, X_test.shape","779b2919":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score","388d0a66":"## initialize your Model\nclf = RandomForestClassifier(random_state=0) \n# Fit your Model on the Training Dataset\nclf.fit(X_train, y_train)\n# Predict on Test data\npreds = clf.predict(X_test)\n# Calculate Model Accuracy\nacc = accuracy_score(preds, y_test)\nprint(f\"Model Accuracy = {round(acc*100,2)}%\")","d24a9e51":"import string\ndef remove_punctuation(text):\n    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n    return punctuationfree.lower()","430947e8":"def remove_stopwords(text):\n    stopwordsfree=\" \".join([ x for x in text.split() if x not in stop])\n    return stopwordsfree","f873b127":"def lemmetize_sentence(text):\n    lemmatizer = WordNetLemmatizer()\n    word_list = nltk.word_tokenize(text)\n    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n    return lemmatized_output","c15df835":"x = remove_stopwords('I hate so and i love much')\nx","4ec3fc94":"def raw_test(review, model, vectorizer):\n    # Clean Review\n    review_c = remove_punctuation(remove_stopwords(lemmetize_sentence(review)))\n    print(review_c)\n\n    # Embed review using tf-idf vectorizer\n    embedding =vectorizer.transform([review_c])\n    \n    # Predict using your model\n    prediction = model.predict(embedding) \n    \n    # Return the Sentiment Prediction\n    return \"Positive\" if prediction == 1 else \"Negative\"","13461b37":"review_1 = \"That's a good Dish, Good Job\"\nreview_2 = \"That's the worst Dish ever tasted\"\nreview_3 = 'I hate it'\nreview_4 = 'bad'\nreview_5 = 'I LOVE IT'","af2423d0":"raw_test(review_1, clf, vectorizer_tfidf)","22a5991f":"raw_test(review_4, clf, vectorizer_tfidf)","72bd86e8":"raw_test(review_3, clf, vectorizer_tfidf)","8e68cd61":"raw_test(review_2, clf, vectorizer_tfidf)","bef74bc2":"# import pickle","83458e8e":"# model_name = 'rf_model.pk'\n# vectorizer_name = 'tfidf_vectorizer.pk'\n\n# model_path = os.path.join('..Your\/Location', model_name)\n# pickle.dump(clf , open(model_path, 'wb'))\n\n# vect_path = os.path.join('..Your\/Location', vectorizer_name)\n# pickle.dump(vectorizer_tfidf , open(vect_path,'wb'))","1abb4a88":"# loaded_model = pickle.load(open(model_path,'rb'))\n# loaded_vect = pickle.load(open(vect_path,'rb'))","b0a00c54":"# raw_test(review_1, loaded_model, loaded_vect)","ae66d241":"# raw_test(review_2, loaded_model, loaded_vect)","31ec8e4d":"### Split Test & Training Data","ac379ef8":"### Raw Instance Prediction","785a8a18":"### Target Variable Pre-Processing\n`target` will be \n - 0 if score < 3 \n - 1 otherwise","cce8162a":"### Read Dataset","ecd6e78d":"### Saving Models for Deployment","09087747":"#### Plot Countplot for target Variable","73ca993e":"### Modelling","d1d31f2c":"### Load model Again and test them","04b156f9":"### Text Pre-Processing","ef07ef54":"### Import Packages","e29176a4":"### Problem Description","2756875a":"##### Sklearn framework steps\n - init\n - fit\n - predict","0c178fe5":"This notebook shows an NLP application: Amazon Food Review. In particular, we will preprocess reviews (Text) written by some people and deploy a machine learning\nmodel to classify new reviews whether they are positive or negative.\n\nhttps:\/\/www.kaggle.com\/snap\/amazon-fine-food-reviews\/code","51f8b2f0":"Notice how such variance is huge. Accordingly, we need to down-sample such data to balance positive and negative classes.\n\n### Balance Data Target","c3179acb":"### Text Embedding\n - Use `TfidfVectorizer`\n - `fit` on the training data only\n - `transform` on training and test ","39fd373e":"### Drop Duplicates\nSave the Cleaned data-frame also with the variable `df_text`","46f541ae":"# Great Job !\n### Now Deploy your ML model using Streamlit Framework"}}