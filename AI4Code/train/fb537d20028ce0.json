{"cell_type":{"3bbd6aee":"code","3f9c2c42":"code","e9939016":"code","971d2bd7":"code","64918462":"code","8f54b97f":"code","5096e653":"code","b29112df":"code","481aacd7":"code","00255eac":"code","718b67d9":"code","0d48d1b2":"code","422c98fb":"code","98a9cb21":"code","b9763533":"code","bbdee2b0":"code","4c882ec2":"code","6c82acd3":"code","bc1dd2d8":"code","63e3b215":"code","b5225398":"code","ff39ed92":"code","221f747a":"code","18e13241":"code","23a2e7e8":"code","967a16a0":"code","9610276b":"code","f3bfd646":"code","a09ff1fc":"code","79c4e04d":"code","4e16d305":"code","c1f266ee":"code","16b96e82":"code","f7570a5d":"code","029409e5":"code","5313744f":"code","a8f56efb":"code","4a2c5965":"code","3717b3d4":"code","10d03d99":"code","2034de47":"code","d9693179":"markdown","a11b532d":"markdown","ec3e78ce":"markdown","dc290b9d":"markdown","69e13bdc":"markdown","7f4d287e":"markdown","aeb9f84d":"markdown","3e2215d5":"markdown"},"source":{"3bbd6aee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3f9c2c42":"pip install emoji --upgrade","e9939016":"import re\nimport regex\nimport pandas as pd\nimport numpy as np\nimport emoji\nimport plotly.express as px\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom os import path\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n#% matplotlib inline","971d2bd7":"!git clone https:\/\/github.com\/amueller\/word_cloud.git\n% cd word_cloud\n!pip install . ","64918462":"def startsWithDateAndTime(s):\n    pattern='^([0-9]+)(\\\/)+([0-9]+)(\\\/)([0-9]+), ([0-9]+):([0-9][0-9]) (AM|PM|am|pm)? -'\n    result=re.match(pattern,s)\n    if result:\n        return True\n    return False","8f54b97f":"def FindAuthor(s):\n    s=s.split(\":\")\n    if len(s)==2:\n        return True\n    else:\n        return False","5096e653":"def getDataPoint(line):\n    splitLine= line.split(' - ')\n    dateTime=splitLine[0]\n    date,time=dateTime.split(', ')\n    message=' '.join(splitLine[1:])\n    if FindAuthor(message):\n        splitMessage=message.split(': ')\n        author= splitMessage[0]\n        message=' '.join(splitMessage[1:])\n    else:\n        author=None\n    return date,time,author,message","b29112df":"parsedData=[]\nconversationPath=\"..\/input\/chathistoryanalyzer\/WhatsApp Chat with harif Launde.txt\"","481aacd7":"with open(conversationPath,encoding=\"utf-8\") as fp:\n    fp.readline()\n    messageBuffer=[]\n    date,time,author=None,None,None\n    while True:\n        line=fp.readline()\n        if not line:\n            break\n        line=line.strip()\n        if startsWithDateAndTime(line):\n            if len(messageBuffer)>0:\n                parsedData.append([date,time,author,' '.join(messageBuffer)])\n            messageBuffer.clear()\n            date,time,author,message=getDataPoint(line)\n            messageBuffer.append(message)\n        else:\n            messageBuffer.append(line)","00255eac":"df = pd.DataFrame(parsedData, columns=['Date', 'Time', 'Author', 'Message']) # Initialising a pandas Dataframe.\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])","718b67d9":"df.head()","0d48d1b2":"df.Author.unique()","422c98fb":"df=df.dropna()\ndf.info()","98a9cb21":"df.Author.unique()","b9763533":"total_messages=df.shape[0]\nprint(total_messages)","bbdee2b0":"media_messages = df[df['Message'] == '<Media omitted>'].shape[0]\nprint(media_messages)","4c882ec2":"def split_count(text):\n\n    emoji_list = []\n    data = regex.findall(r'\\X', text)\n    for word in data:\n        if any(char in emoji.UNICODE_EMOJI for char in word):\n            emoji_list.append(word)\n\n    return emoji_list\n\ndf[\"emoji\"] = df[\"Message\"].apply(split_count)","6c82acd3":"emojis = sum(df['emoji'].str.len())\nprint(emojis)","bc1dd2d8":"URLPATTERN = r'(https?:\/\/\\S+)'\ndf['urlcount'] = df.Message.apply(lambda x: re.findall(URLPATTERN, x)).str.len()","63e3b215":"links=np.sum(df.urlcount)","b5225398":"print(\"Group Wise Stats\")\nprint(\"Messages:\",total_messages)\nprint(\"Media:\",media_messages)\nprint(\"Emojis:\",emojis)\nprint(\"Links:\",links)","ff39ed92":"media_messages_df=df[df['Message']=='<Media Omitted>']","221f747a":"messages_df=df.drop(media_messages_df.index)","18e13241":"messages_df.info()","23a2e7e8":"messages_df['Letter_Count'] = messages_df['Message'].apply(lambda s : len(s))\nmessages_df['Word_Count'] = messages_df['Message'].apply(lambda s : len(s.split(' ')))\nmessages_df[\"MessageCount\"]=1","967a16a0":"messages_df.head()","9610276b":"messages_df[\"emojicount\"]=df[\"emoji\"].str.len()","f3bfd646":"l = messages_df.Author.unique()\n\nfor i in range(len(l)):\n  # Filtering out messages of particular user\n  req_df= messages_df[messages_df[\"Author\"] == l[i]]\n  # req_df will contain messages of only one particular user\n  print(f'Stats of {l[i]} -')\n  # shape will print number of rows which indirectly means the number of messages\n  print('Messages Sent', req_df.shape[0])\n  #Word_Count contains of total words in one message. Sum of all words\/ Total Messages will yield words per message\n  words_per_message = (np.sum(req_df['Word_Count']))\/req_df.shape[0]\n  print('Words per message', words_per_message)\n  #media conists of media messages\n  media = media_messages_df[media_messages_df['Author'] == l[i]].shape[0]\n  print('Media Messages Sent', media)\n  # emojis conists of total emojis\n  emojis = sum(req_df['emoji'].str.len())\n  print('Emojis Sent', emojis)\n  #links consist of total links\n  links = sum(req_df[\"urlcount\"])   \n  print('Links Sent', links)   \n  print()","a09ff1fc":"total_emojis_list = list(set([a for b in messages_df.emoji for a in b]))  ##unique emojis in group\ntotal_emojis = len(total_emojis_list)\nprint(total_emojis)","79c4e04d":"total_emojis_list = list([a for b in messages_df.emoji for a in b])    ##most used emojis\nemoji_dict = dict(Counter(total_emojis_list))\nemoji_dict = sorted(emoji_dict.items(), key=lambda x: x[1], reverse=True)\nprint(emoji_dict)","4e16d305":"emoji_df = pd.DataFrame(emoji_dict, columns=['emoji', 'count'])\nemoji_df","c1f266ee":"Emoji Distribution Plots","16b96e82":"import plotly.express as px\nfig=px.pie(emoji_df,values='count',names='emoji')\nfig.update_traces(textposition='inside',textinfo='percent+label')\nfig.show()","f7570a5d":"l = messages_df.Author.unique()\nfor i in range(len(l)):\n  dummy_df = messages_df[messages_df['Author'] == l[i]]\n  total_emojis_list = list([a for b in dummy_df.emoji for a in b])\n  emoji_dict = dict(Counter(total_emojis_list))\n  emoji_dict = sorted(emoji_dict.items(), key=lambda x: x[1], reverse=True)\n  print('Emoji Distribution for', l[i])\n  author_emoji_df = pd.DataFrame(emoji_dict, columns=['emoji', 'count'])\n  fig = px.pie(author_emoji_df, values='count', names='emoji')\n  fig.update_traces(textposition='inside', textinfo='percent+label')\n  fig.show()\n%matplotlib inline","029409e5":"def f(i):\n  l = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n  return l[i];\nday_df=pd.DataFrame(messages_df[\"Message\"])\nday_df['day_of_date'] = messages_df['Date'].dt.weekday\nday_df['day_of_date'] = day_df[\"day_of_date\"].apply(f)\nday_df[\"messagecount\"] = 1\nday = day_df.groupby(\"day_of_date\").sum()\nday.reset_index(inplace=True)","5313744f":"fig = px.line_polar(day, r='messagecount', theta='day_of_date', line_close=True)\nfig.update_traces(fill='toself')\nfig.update_layout(\n  polar=dict(\n    radialaxis=dict(\n      visible=True,\n    )),\n  showlegend=False\n)\nfig.show()","a8f56efb":"messages_df['Time'].value_counts().head(10).plot.barh() # Top 10 Times of the day at which the most number of messages were sent\nplt.xlabel('Number of messages')\nplt.ylabel('Time')","4a2c5965":"messages_df.iloc[messages_df['Word_Count'].argmax()]","3717b3d4":"text = \" \".join(review for review in messages_df.Message)\nprint (\"There are {} words in all the messages.\".format(len(text)))","10d03d99":"stopwords = set(STOPWORDS)\nstopwords.update([\"ra\", \"ga\", \"na\", \"ani\", \"em\", \"ki\", \"ah\",\"ha\",\"la\",\"eh\",\"ne\",\"le\",\"ni\",\"lo\",\"Ma\",\"Haa\",\"ni\"])\n  # Generate a word cloud image\nwordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n  # Display the generated image:\n  # the matplotlib way:\n  \nplt.figure( figsize=(10,5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","2034de47":"l = messages_df.Author.unique()\nfor i in range(len(l)):\n  dummy_df = messages_df[messages_df['Author'] == l[i]]\n  text = \" \".join(review for review in dummy_df.Message)\n  stopwords = set(STOPWORDS)\n  stopwords.update([\"ra\", \"ga\", \"na\", \"ani\", \"em\", \"ki\", \"ah\",\"ha\",\"anta\",\"kuda\",\"ante\",\"la\",\"eh\",\"Nen\",\"ne\",\"haa\",\"Haa\",\"le\"])\n  # Generate a word cloud image\n  print('Author name',l[i])\n  wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n  # Display the generated image:\n  # the matplotlib way:\n  \n  plt.figure( figsize=(10,5))\n  plt.imshow(wordcloud, interpolation='bilinear')\n  plt.axis(\"off\")\n  plt.show()","d9693179":"Person-wise Emoji Distribution","a11b532d":"Daywise Distribution of messages","ec3e78ce":"Let us see the total word count","dc290b9d":"Author : Aniruddha Panja","69e13bdc":"Wordcloud ","7f4d287e":"Seperating the media and text images","aeb9f84d":"Let us see the time at which the members are most active","3e2215d5":"Let's see the msg which contained the maximum no of words."}}