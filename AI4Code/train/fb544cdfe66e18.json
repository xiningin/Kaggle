{"cell_type":{"65d46955":"code","36101cb6":"code","ae2eabc7":"code","c8ee6292":"code","b7a33056":"code","b539ca4d":"code","9b095d10":"code","2a1f0008":"markdown"},"source":{"65d46955":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import GroupKFold\nimport cupy as cp\nfrom tqdm import tqdm\nimport plotly.express as px\n\ndata_folder = \"..\/input\/shopee-product-matching\/\"\n#ranges0 = [(0.55, 0.65), (0.50, 0.60), (0.45, 0.55), (0.45, 0.55), (0.40, 0.50)]\nranges1 = [(0.50, 0.60), (0.45, 0.55), (0.45, 0.55), (0.50, 0.60), (0.55, 0.65)]\n#ranges2 = [(0.50, 0.60), (0.45, 0.55), (0.40, 0.50), (0.40, 0.50), (0.35, 0.45)]\n#ranges3 = [(0.45, 0.55), (0.40, 0.50), (0.40, 0.50), (0.30, 0.40), (0.30, 0.40)]\n#ranges4 = [(0.40, 0.50), (0.30, 0.40), (0.20, 0.30), (0.20, 0.30), (0.20, 0.30)]\n#ranges5 = [(0.20, 0.30), (0.20, 0.30), (0.15, 0.25), (0.10, 0.20), (0.10, 0.20)]","36101cb6":"def create_submission_format(df):\n    tmp = df.groupby(\"label_group\").posting_id.unique().to_dict()\n    matches = df.label_group.map(lambda x: \" \".join(tmp[x]))\n    return matches","ae2eabc7":"train = pd.read_csv(data_folder+\"train.csv\")\n\ntrain[\"target\"] = create_submission_format(train)\n\ncv_splitter = GroupKFold(n_splits=5)\ntrain[\"fold\"] = -1\n\n# Assign folds for validation\nfor fold, (train_idx, valid_idx) in enumerate(cv_splitter.split(train, None, train.label_group)):\n    train.loc[valid_idx, \"fold\"] = fold\n","c8ee6292":"# Taken from Gunes Evitan's post here:  https:\/\/www.kaggle.com\/c\/shopee-product-matching\/discussion\/224782\ndef matches_to_f1_score(y_true, y_pred, mean=True):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n\n    tp = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    fp = y_pred.apply(lambda x: len(x)).values - tp\n    fn = y_true.apply(lambda x: len(x)).values - tp\n\n    precision = tp \/ (tp + fp)\n    recall = tp \/ (tp + fn)\n    f1 = 2 * ((precision * recall) \/ (precision + recall))\n\n    if mean:\n        f1 = f1.mean()\n\n    return f1\n\ndef get_best_threshold(method, embeddings, posting_ids, correct_matches, candidates):\n\n    scores = dict()\n    for threshold in candidates:\n\n        matches = method(embeddings, posting_ids, threshold, create_submission=False)\n        \n        scores[threshold] = matches_to_f1_score(pd.Series(matches), pd.Series(correct_matches))\n\n        print(f\"Method:{method.__name__},   Threshold:{threshold:.4f},   F1-Score: {scores[threshold]:.4f}\")\n\n    best_threshold = max(scores, key=scores.get)\n    best_score = scores[best_threshold]\n    print(\"*\"*50)\n    print(f\"Best Threshold:{best_threshold:.4f},  Best F1-Score: {best_score:.4f}\")\n    print(\"*\"*50)\n    \n    return best_threshold, best_score\n\n# Modified xhulu's euclidian distance code for cosine distance \ndef cosine_find_matches_cupy(embeddings, posting_ids, threshold, create_submission=True):\n    empty_emb_idx = np.squeeze(np.argwhere(embeddings.sum(axis=1) == 0), axis=1)\n    embeddings = cp.array(embeddings)\n    embeddings =  embeddings \/ cp.linalg.norm(embeddings, axis=1)[:,None]\n    N = embeddings.shape[0]\n    matches = []\n   \n\n    for i in tqdm(range(N)):\n        v = embeddings[i, :]\n        thresholded_bool = 1 - cp.dot(embeddings,v) < threshold\n        thresholded_ix = cp.argwhere(thresholded_bool).squeeze(-1)\n        thresholded_ix = thresholded_ix.get()\n        match = \" \".join(posting_ids[thresholded_ix])\n        matches.append(match)\n    \n    # Match zero vector embeddins only with themselves\n    for i in empty_emb_idx:\n        matches[i] = posting_ids[i]\n    \n    return matches","b7a33056":"# Create embeddings\ndimension = 25000\nvectorizer = TfidfVectorizer(stop_words = 'english', binary = True, max_features = dimension)\ntext_emb = vectorizer.fit_transform(pd.read_csv(data_folder + \"train.csv\").title)\n\ntracker = pd.DataFrame(columns=[\"dimension\", \"n_label_group\", \"n_post\", \"optimum_threshold\", \"score\"], data=np.zeros((10,5)))\n\nprint(\"************************ EMBEDDING SIZE: \", dimension, \"**************************************************\")\nfor folds_before, (search_from, search_to) in enumerate(ranges1):\n    print(\"=\"*50)\n    print(\"All Folds up to Fold:\", folds_before)\n    print(\"=\"*50)\n    valid_emb = text_emb[train.fold <= folds_before,].toarray().astype(np.float32)\n    valid_df = train.loc[train.fold <= folds_before,]\n    n_label_group = valid_df.label_group.nunique()\n    n_post = valid_df.shape[0]\n    print(\"Number of Label Groups: \", n_label_group)\n    print(\"Number of Posts: \", n_post)\n    best_threshold, best_score = get_best_threshold(cosine_find_matches_cupy, valid_emb, valid_df.posting_id.values, valid_df.target.values, np.arange(search_from, search_to, 0.02))\n    tracker.iloc[folds_before,] = (dimension, n_label_group, n_post, best_threshold, best_score)\n    del valid_emb\n    del valid_df\n    ","b539ca4d":"tracker[:5]","9b095d10":"TRACKER = tracker[:5]\nfig = px.scatter(TRACKER, x=\"n_post\", y=\"optimum_threshold\", trendline=\"ols\", facet_col=\"dimension\")\nfig.show()","2a1f0008":"# How Optimum Threshold Changes Based on Test Size?\nWe know that test dataset is x2 times the training datasize. Therefore,\nWe know that having more\/less crowded space might effect the value of optimum threshold to decide a match. Given that test dataset is x2 times the training datasize, I will calculate optimum threshold values for differnet datasize to understand the relationship between datasize and optimum threshold. Hence, we can come up with an estimate of optimum threshold for 70k test examples.\n\nAnother factor effecting the relationship between test size and threshold can be the number of dimensions of our embeddings. Therefore, I will be running those experiments for different embedding sizes too and compare the results. \n\nI ran a couple of experiments before to decide ranges to search optimum threshold.\n\n**FOR [RESULTS](#conclusion) PLEASE GO TO THE END OF THE NOTEBOOK**"}}