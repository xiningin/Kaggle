{"cell_type":{"49087766":"code","a51a42dc":"code","2af43524":"code","8951961f":"code","eb5a2091":"code","154fe1f0":"code","946a3676":"code","18b23e55":"code","80b46c1c":"code","241b0f76":"code","f47401b8":"code","f53202e3":"code","63b51d87":"markdown","03585dbd":"markdown","d9199a1c":"markdown","e43062c4":"markdown","7feb845d":"markdown","5797de52":"markdown","c9bc5942":"markdown","fa955778":"markdown","6067a33f":"markdown","9ce13a6e":"markdown"},"source":{"49087766":"import tensorflow as tf              # math library\nimport numpy as np                   # linear algebra\nimport pandas as pd                  # data analysis\nimport seaborn as sns                # plotting\nimport matplotlib.pyplot as plt      # plotting\nimport pathlib                       # image import\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\ntrain_data_path = pathlib.Path('..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train\/')\ntest_data_path = pathlib.Path('..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test\/')\n\ntrain_file_paths = list(train_data_path.glob(r'**\/*.jpg'))\ntest_file_paths = list(test_data_path.glob(r'**\/*.jpg'))","a51a42dc":"# Define MLP Hyperparameters \n\n# Batch size is the number of samples in an epoch used to estimate model error.\ntrain_batch_size = 870     # size of training batches, doesn't need to evenly divide\nval_batch_size = 290       # size of val batch should evenly divide total val images\ntest_batch_size = 290      # size of test batch should evenly divide total test images\n\ninput_shape = (200, 200)   # dimensions of input images\ndropout = 0.2              # droupout rate to prevent overfitting\nlearning_rate = 0.001      # default Adam learning rate is 0.001  \nepochs = 50                # rounds of training\n\nsample_fraction = 1.00     # size of sample from full dataset\ntest_size = 0.2            # size of testing set (holdout dataset)\nvalidation_size = 0.2      # size of validation set","2af43524":"# Build dataframe, consisting of 87000 (image filepath, label) pairs\ndef build_dataframe(filepath):\n    \n    labels = []\n    \n    # Parse labels from file path ...\/asl_alphabet_train\/B\/B100.jpg\n    for i in range(len(filepath)):\n        labels.append(str(filepath[i]).split(\"\/\")[-2])\n    \n    # Convert lists to Series objects and concatenate\n    filepath = pd.Series(filepath, name='Filepath').astype(str)\n    labels = pd.Series(labels, name='Label')\n    df = pd.concat([filepath, labels], axis=1)\n    \n    # Randomize the DataFrame and reset index\n    df = df.sample(frac=1).reset_index(drop = True)\n    \n    print(df,\"\\n\")\n    \n    return df","8951961f":"def generate_image_data():\n    \n    # ImageDataGenerators create tensor image data. Data will be looped over in batches.\n    # Generates train\/validate sets. Must know about validation split.\n    # Training dataframe is further divided into two subsets: training and validation\n    train_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n        validation_split=validation_size\n    )\n    \n    test_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n    )\n\n    print('Image Sets (train, validation, test):')\n    \n    # Images used to train\/create the model\n    train_images = train_data_generator.flow_from_dataframe(\n        dataframe=train_df,\n        x_col='Filepath',\n        y_col='Label',\n        target_size=input_shape,\n        color_mode='rgb',\n        class_mode='categorical',\n        batch_size=train_batch_size,\n        shuffle=True,\n        seed=0,\n        subset='training',\n    )\n\n    # Images used to validate the model before testing. \n    # Can be used to tune the model's parameters without exposing it to the test set.\n    # The model is fit on the training set. The fitted model is used to predict the \n    # responses for the observations in the validation set. The validation set error \n    # rate is an estimate of the test error rate.\n    val_images = train_data_generator.flow_from_dataframe(\n        dataframe=train_df,\n        x_col='Filepath',\n        y_col='Label',\n        target_size=input_shape,\n        color_mode='rgb',\n        class_mode='categorical',\n        batch_size=val_batch_size,\n        shuffle=True,\n        seed=0,\n        subset='validation',\n    )\n\n    # Images used to test the model, providing unbiased estimate of the model's accuracy.\n    test_images = test_data_generator.flow_from_dataframe(\n        dataframe=test_df,\n        x_col='Filepath',\n        y_col='Label',\n        target_size=input_shape,\n        color_mode='rgb',\n        class_mode='categorical',\n        batch_size=test_batch_size,\n        shuffle=False\n    )\n    \n    return train_data_generator, test_data_generator, train_images, val_images, test_images","eb5a2091":"# Populate dataframe with (filename, label) pairs\ndf = build_dataframe(train_file_paths)\n\n# Split dataset into training and testing data:\n#    Pull a sample of size sample_fraction from the dataset.\n#    Test set is test_size proportion of sample, training set is the rest.\ntrain_df, test_df = train_test_split(df.sample(frac = sample_fraction), test_size=test_size, random_state=0)\n\n# Create data generators and image sets.\ntrain_generator,test_generator,train_images,val_images,test_images = generate_image_data()\n\n# Confirm data shape\nprint('\\nImage Shape:')\nfor images, labels in train_images:\n    print(images.shape, labels.shape)\n    plt.imshow(images[0])\n    break","154fe1f0":"# Using a Sequential model to build a stacked layer neural network.\n# Each layer has one input tensor and one output tensor.\nmodel = tf.keras.models.Sequential([\n  \n  # INPUT LAYER\n  # Flattens the multi-dimensional image array into a 1-dimensional vector\n  tf.keras.layers.Flatten(input_shape=(input_shape[0],input_shape[1],3)),\n  \n  # HIDDEN LAYERS:\n  # This layer implements the output = activation(dot(input,kernel)+bias).\n  #    kernel: a weights matrix created by the layer.\n  #    bias: a bias vector created by the layer.\n    \n  tf.keras.layers.Dense(512, activation='relu'),\n\n  tf.keras.layers.Dense(256, activation='relu'),\n\n  tf.keras.layers.Dense(128, activation='relu'),\n\n  # The dropout represents a threshold at which we eliminate some units at random. \n  # In the final hidden layer, this gives each unit a 20% chance of being eliminated\n  # at every training step. Helps prevent overfitting.\n  tf.keras.layers.Dropout(dropout),\n  \n  # OUTPUT LAYER: \n  # Apply softmax function here to satisfy loss function requirements.\n  tf.keras.layers.Dense(29, activation='softmax')\n])\n\n# List model shape and parameters\nmodel.summary()\n\n# Adam: Adaptive Movement Estimation\n# Optimizer: e.g. gradient descent. Determines direction and extent of change.\n# Loss: estimates loss of system. Used when training the model.\n# Metrics: Judges the performance of the model (others: probabilistic, regression, T\/F)\n# Metrics are not used when training the model.\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","946a3676":"# Train the model without validation data\n#history = model.fit(train_images, epochs=epochs)\n\n# Train the model with validation data\nfit_history = model.fit(train_images, validation_data=val_images, epochs=epochs)\n\n# Plot accuracy and losses for training set and validation set\nfig, axes = plt.subplots(2, 1, figsize=(15, 10))\nax = axes.flat\n\npd.DataFrame(fit_history.history)[['accuracy','val_accuracy']].plot(ax=ax[0])\nax[0].set_title(\"Accuracy\", fontsize = 15)\nax[0].set_ylim(0,1.1)\n\npd.DataFrame(fit_history.history)[['loss','val_loss']].plot(ax=ax[1])\nax[1].set_title(\"Loss\", fontsize = 15)\nplt.show()","18b23e55":"# Determine unbiased loss values and metrics for model using test data.\n(loss, accuracy) = model.evaluate(test_images, verbose=1)\nprint(f'\\nThe final model has prediction accuracy of {accuracy * 100:.2f}% and loss of {loss:.5f}.')","80b46c1c":"# Predict category for test images and convert to letter labels\npredictions = model.predict(test_images)\npredictions = np.argmax(predictions, axis=1)\n\nlabels = (train_images.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predictions]\n\n# Display sample of test images and predictions\nfig, axes = plt.subplots(nrows=4, ncols=6, figsize=(20, 12),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(test_df.Filepath.iloc[i]))\n    ax.set_title(f\"True: {test_df.Label.iloc[i].split('_')[0]}\\nPredicted: {predictions[i].split('_')[0]}\", fontsize = 15)\nplt.tight_layout()\nplt.show()","241b0f76":"# Analysis: Confusion Matrix\n#\n#   Columns: predicted label\n#      Rows: true label\n\ny_test = list(test_df.Label)\ncf_matrix = confusion_matrix(y_test, predictions, normalize='true')\nplt.figure(figsize = (17,12))\nsns.heatmap(cf_matrix, annot=True, xticklabels = sorted(set(y_test)), yticklabels = sorted(set(y_test)),cbar=False)\nplt.title('Normalized Confusion Matrix', fontsize = 23)\nplt.xticks(fontsize=12,rotation=45)\nplt.yticks(fontsize=12)\nplt.show()","f47401b8":"# Analysis: Classification Report\n#\n#   precision: the ability of the classifier not commit false positives\n#   recall: proportion of correct predictions\n#   f1-score: proportion of true positives compared to (true + false positives).\n#   support: number of images per category\n#   macro avg: averaging unweighted mean per label\n#   weighted avg: averaging the support-weighted mean per label\n\nprint(classification_report(y_test, predictions))","f53202e3":"print(f'    Image Total: {df.shape[0]}')\nprint(f' Category Total: {len(df.Label.unique())}')\nprint(f'Images\/Category: 3000')\nprint(f'         Labels: {sorted(df.Label.unique())} \\n')\n\n# Sample 40 images from dataset\nfig, axes = plt.subplots(nrows=4, ncols=10, figsize=(15, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df.Filepath[i]))\n    ax.set_title(df.Label[i])\nplt.tight_layout(pad=.5)\nplt.show()","63b51d87":"# Step 3: Build Image Data Generators","03585dbd":"# Step 8: Predict Test Image Labels","d9199a1c":"# Step 5: Build the Model","e43062c4":"# Step 2: Build Image and Label Dataframe","7feb845d":"# Step 7: Evaluate the Model with Test Data","5797de52":"# Step 1: Define Model Hyperparameters","c9bc5942":"# Step 6: Train and Validate the Model","fa955778":"# Step 9: Analysis of Predictions","6067a33f":"# Extras","9ce13a6e":"# Step 4: Prepare Train, Validation and Test Data"}}