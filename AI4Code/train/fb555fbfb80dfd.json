{"cell_type":{"a51748e5":"code","96fb9253":"code","9a69c7ed":"code","92024323":"code","9df880c3":"code","12c0098a":"code","bdb97e97":"code","ea5f18c1":"code","0a81a911":"code","c7f60551":"code","1b9d064d":"code","ddfafb60":"code","6d9bfced":"code","e97516cb":"code","a3710a84":"code","567b1c04":"code","7c00c229":"code","d71d568b":"code","00b19d99":"code","5f1f6ef9":"code","7c3e6b88":"code","e9f1785c":"code","d82abe14":"code","648e61dd":"code","9331b529":"code","4a0630db":"code","96eac732":"code","39808dc1":"code","bff9ece8":"code","05e6f7fb":"code","d0d107a7":"code","e9963c06":"code","8c705ab3":"code","5eeab8e5":"code","43897e1b":"code","d7a8295b":"code","bf466b3d":"code","e985d18c":"markdown","8ba30fac":"markdown","4531c6ef":"markdown","4706e046":"markdown","a15ff8a5":"markdown","00267592":"markdown","e6574428":"markdown","c987d790":"markdown","19563b6a":"markdown","612b0630":"markdown","2666f3d8":"markdown","b67e5c53":"markdown","0901242b":"markdown","0c47dd76":"markdown","fba3ebde":"markdown","e3b2b96b":"markdown"},"source":{"a51748e5":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.metrics import mean_absolute_error,mean_squared_error\nfrom statsmodels.graphics.tsaplots import plot_acf,plot_pacf\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.ar_model import AR\nfrom datetime import datetime\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nimport math\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom keras.preprocessing.sequence import TimeseriesGenerator\nfrom statsmodels.tsa.seasonal import seasonal_decompose","96fb9253":"cor_inf = pd.read_csv('..\/input\/novel-corona-virus-2019-dataset\/time_series_covid_19_confirmed.csv')\ncor_inf.head(5)","9a69c7ed":"#drop lat long and province\/state columns\ncor_inf.columns","92024323":"cor_inf.drop(labels = ['Province\/State','Lat', 'Long'],axis = 1, inplace= True)","9df880c3":"cor_inf.head(20)","12c0098a":"cor_inf.shape","bdb97e97":"#cor_inf['Country\/Region'].value_counts()","ea5f18c1":"#group by data based upon country since the countries name are repeated more than once \ncor_inf = cor_inf.groupby(['Country\/Region']).sum()","0a81a911":"cor_inf.loc['China'].tail(5)","c7f60551":"#reshape the data as per the time series analysis\ncor_inf_re = pd.DataFrame()\nfor i in range(0,len(cor_inf)):\n    cor_inf_re[cor_inf.index[i]] = cor_inf.iloc[i].values\n    ","1b9d064d":"type(cor_inf.index[0])","ddfafb60":"cor_inf_re.index = cor_inf.columns[:]","6d9bfced":"cor_inf_re.head(5)","e97516cb":"def total_infected_sum():\n    count = []\n    for i in range(0,len(cor_inf_re)):\n        count.append(sum(cor_inf_re.iloc[i].values))\n    return count","a3710a84":"cor_inf_re['Total infected'] = total_infected_sum()","567b1c04":"cor_inf_re.tail(5)","7c00c229":"def parser(date):\n    date = datetime.strptime(date,'%m\/%d\/%y')\n    date  = str(date.day) + '-' + str(date.month) + '-' + str(date.year)\n    print(date)\n    return datetime.strptime(date,'%d-%m-%Y')","d71d568b":"#convert str to datetime in index \ntimestamp = []\nfor i in range(0,len(cor_inf_re)):\n    timestamp.append(parser(cor_inf_re.index[i]))\ncor_inf_re.index = timestamp","00b19d99":"cor_inf_re.to_csv('.\/covid_19_confirmed.csv')","5f1f6ef9":"#preparing for time series\ninfected_people = cor_inf_re['Total infected']","7c3e6b88":"#column for infected per day\ndiff = []\ndiff.append(cor_inf_re['Total infected'][0])\nfor i in range(0,len(cor_inf_re['Total infected']) - 1):\n    diff.append(cor_inf_re['Total infected'][i+1] - cor_inf_re['Total infected'][i])\n\ncor_inf_re['Infected_per_Day'] = diff","e9f1785c":"#visualization\nplt.xlabel('dates')\nplt.ylabel('infected people')\ninfected_people.plot(figsize = (11,5),marker='o')\nplt.legend()","d82abe14":"#check the statistical part of the data\ninfected_people.describe()","648e61dd":"#to check if there is an trend or seasonality\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nresult = seasonal_decompose(infected_people)","9331b529":"result.trend.plot(figsize=(12,4))","4a0630db":"result.seasonal.plot(figsize=(12,4))","96eac732":"#autocorrelation graph\nplot_acf(infected_people)","39808dc1":"plot_pacf(infected_people)","bff9ece8":"infec_one = infected_people.diff(periods=1)\ninfec_one = infec_one[1:]\nplot_acf(infec_one)","05e6f7fb":"train = infected_people.iloc[:-8]\ntest = infected_people.iloc[-8:]","d0d107a7":"model = ExponentialSmoothing(train,trend = \"mul\",seasonal_periods=7,seasonal=\"add\").fit()","e9963c06":"predictions = model.predict(start = 50 ,end= 57 )\n#predictions","8c705ab3":"plt.figure(figsize = (12,4))\npredictions.plot(c ='r',marker = 'o',markersize=10,linestyle='--')\ntest.plot(marker = 'o',markersize=10,linestyle='--')\nprint(\"root mean squared error : \",math.sqrt(mean_squared_error(test,predictions)))\nprint(\"mean absolute error : \",mean_absolute_error(test,predictions))","5eeab8e5":"model = SARIMAX(train,order = (4,2,1),trend='t',seasonal_order=(2, 2, 1, 14))\nmodel_fit = model.fit()","43897e1b":"predictions = model_fit.predict(start = 53,end=60)\npredictions","d7a8295b":"plt.figure(figsize = (12,4))\nplt.plot(predictions,'r',marker = 'o',markersize=10,linestyle='--')\nplt.plot(test,marker = 'o',markersize=10,linestyle='--')\nprint(\"root mean squared error : \",math.sqrt(mean_squared_error(test,predictions)))\nprint(\"mean absolute error : \",mean_absolute_error(test,predictions))","bf466b3d":"predictions = model_fit.predict(start = 50,end=67)\npredictions","e985d18c":"Single, Double and Triple Exponential Smoothing can be implemented in Python using the ExponentialSmoothing Statsmodels class.\n\nFirst, an instance of the ExponentialSmoothing class must be instantiated, specifying both the training data and some configuration for the model.\n\nSpecifically, you must specify the following configuration parameters:\n\n<li>trend: The type of trend component, as either \u201cadd\u201d for additive or \u201cmul\u201d for multiplicative. Modeling the trend can be disabled by setting it to None.<\/li>\n<li>damped: Whether or not the trend component should be damped, either True or False.<\/li>\n<li>seasonal: The type of seasonal component, as either \u201cadd\u201d for additive or \u201cmul\u201d for multiplicative. Modeling the seasonal component can be disabled by setting it to None.<\/li>\n<li>seasonal_periods: The number of time steps in a seasonal period, e.g. 12 for 12 months in a yearly seasonal structure (more here).\n<\/li>\n\nThe model can then be fit on the training data by calling the fit() function.\n\nThis function allows you to either specify the smoothing coefficients of the exponential smoothing model or have them optimized. By default, they are optimized (e.g. optimized=True). These coefficients include:\n\nsmoothing_level (alpha): the smoothing coefficient for the level.\nsmoothing_slope (beta): the smoothing coefficient for the trend.\nsmoothing_seasonal (gamma): the smoothing coefficient for the seasonal component.\ndamping_slope (phi): the coefficient for the damped trend.","8ba30fac":"<b>Sum all the count of infected people of each country to get the total infected people per date\n<\/b>","4531c6ef":"<p>Now we want to reshape the data as per the requirement i.e make index as dates,and column\nname as country names\n<\/p>","4706e046":"<h2>Forecasting The Number Of People Infected With Coronavirus in the World<\/h2>","a15ff8a5":"<p>Now only we need to convert index datatype i.e object to datetime <\/p>","00267592":"<h3>Importing necessary libraries<\/h3>","e6574428":"<p> Drop the <b>Province\/State<\/b>,<b> Latitude<\/b> and <b> Longitude<\/b> columns  as they make the data to narrow and data for those column might be missing for some countries <\/p>","c987d790":"<h3>Data Preprocessing for the covid-19 dataset<\/h3>","19563b6a":"<h2>Exponential Smoothing<\/h2>","612b0630":"<h2>SARIMAX model<\/h2>","2666f3d8":"<h3>Visualization of dataset<\/h3>","b67e5c53":"<p>As a result I go over a sarima model as i seen it perform better although the prediction\nas per the real data was really close and it didn't ovefit the model which in the case of exponenetial smoothning\n<\/p>","0901242b":"<p> as per the result it might be that after the end of march, it will affect to 450000\npeople all over the world so precaution and prevention is a first priority of evry human\nbeing<\/p>","0c47dd76":"<h3>Reshaping the data to proceed with Forecasting<\/h3>","fba3ebde":"<p>The valuable features what we are hunting for is <li>Country names.<\/li><li>Count of\n    infected people<\/li><li> Dates<\/li> <\/br>At which they were affected in the country.\n    As we are not focused on predicting on indiviual country as it might be \n    bias on some country as a result the prediction might be very large or too small\n    which may be act as outlier.<\/p>","e3b2b96b":"<p>To get the total infected people per day in the world we sum the count of infected people from all the countries and group them as per dates<\/p>\n<p>But before we saw that in the country\/Region column we have duplicated data as a result\nwe need to first sum all the country and then get the count of all the people infected <\/p>"}}