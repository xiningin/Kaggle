{"cell_type":{"9a5b35db":"code","f7991c69":"code","9f4ff7fa":"code","50b5895f":"code","752a8364":"code","a22b33d4":"code","3b45c32a":"code","8d97d63a":"code","9abde9f0":"code","8f06ec63":"code","2537e613":"code","56ccca73":"code","e30b2e89":"code","fa9cd87e":"code","0a4b65cf":"code","f25ba778":"code","3e138172":"code","8a1fe329":"code","6ee58985":"code","fc81f559":"code","4a74f06a":"code","9a3eae9b":"code","e09da6a4":"code","a011a6db":"code","cc1b888c":"code","f20d3186":"code","a149ff2f":"code","caf39dc0":"code","c41d09fe":"code","7a76b1b0":"code","c4555b72":"code","9327bc2a":"code","ae18b357":"code","778d18fc":"code","c08a0d23":"code","1317d02d":"code","64c57ce7":"code","d49d0e21":"code","c84371ae":"code","5e06fbc6":"code","bb19dfba":"code","918b9efb":"code","7e8d18c0":"code","4bf16549":"code","ddcf4102":"code","25a97ab0":"code","8a276425":"code","d5aa77c0":"code","525dad21":"code","acda44f4":"code","cd9d484b":"code","1b06a0b4":"code","98376fb2":"code","f326c1df":"code","02585fac":"code","47e1ec9a":"code","bae5b56f":"code","6ef25248":"markdown","36fa1bbb":"markdown","532aaa24":"markdown","e6fbf68d":"markdown","e28e03e0":"markdown","bcaba014":"markdown","d830fe36":"markdown","948e7ae6":"markdown","627ff0bd":"markdown","adf4356b":"markdown","c50f9e09":"markdown","3ed4ce30":"markdown","aaa8bf2b":"markdown","3045c5e8":"markdown","08a01a3f":"markdown","760a5e97":"markdown","6c7a54d4":"markdown","b083e616":"markdown","2357fa4f":"markdown","c52f9e25":"markdown","a7615787":"markdown","cbebdc68":"markdown","8bc130da":"markdown","6b3faca4":"markdown","7f9ee74d":"markdown"},"source":{"9a5b35db":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f7991c69":"df = pd.read_csv('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')\nprint(df.head())","9f4ff7fa":"df.info()","50b5895f":"columns = df.columns\ncolumns","752a8364":"import matplotlib.pyplot as plt\nimport seaborn as sns\ndf_age = df['age']\ndf_age.value_counts()\n# df_age.hist()\n\nsns.histplot(df_age, kde=True)\n","a22b33d4":"df_age = df[df['output'] == 1]\nprint(df_age)","3b45c32a":"sns.histplot(df_age['age'], kde = True)","8d97d63a":"df_sex = df['sex'].value_counts()\ndf_sex","9abde9f0":"df_sex.plot(kind='bar')\nplt.show()","8f06ec63":"df[df['output'] == 1]['sex'].value_counts().plot(kind = 'bar')\nplt.show()","2537e613":"df['cp'].value_counts().plot(kind='bar')\nplt.show()","56ccca73":"df[df['output']==1]['cp'].value_counts().plot(kind='bar')\nplt.show()","e30b2e89":"from matplotlib.pyplot import figure\n\nfigure(figsize=(10, 6), dpi=80)\ndf['trtbps'].value_counts().plot(kind='bar')\nplt.xlabel('Blood Pressure')\nplt.ylabel('Count')\nplt.title('Blood pressure Analysis')\nplt.show()","fa9cd87e":"from matplotlib.pyplot import figure\n\nfigure(figsize=(10, 6), dpi=80)\ndf[df['output']==1]['trtbps'].value_counts().plot(kind='bar')\nplt.xlabel('Blood Pressure')\nplt.ylabel('Count')\nplt.title('Blood pressure Analysis with heart attack')\nplt.show()","0a4b65cf":"# sns.histplot(df['trtbps'], kde = True)\nsns.kdeplot(df['trtbps'],shade=True, color='green')\nplt.title('BloodPressure Analysis')\nplt.show()","f25ba778":"from matplotlib.pyplot import figure\n\nfigure(figsize=(12, 6), dpi=80)\nsns.histplot(df['chol'], kde =True, color = 'green')\nsns.histplot(df[df['output']==1]['chol'], kde =True, color='red')\nplt.xlabel('Cholestrol')\nplt.ylabel('Count')\nplt.show()","3e138172":"figure(figsize=(12, 6), dpi=80)\nsns.histplot(df[df['output']==1]['chol'], kde =True)\nplt.xlabel('Cholestrol')\nplt.ylabel('Count')\nplt.title('Cholestrol Analysis with Heart attack')\nplt.show()","8a1fe329":"df['fbs'].value_counts().plot(kind = 'bar', color ='Purple')\nplt.show()","6ee58985":"df[df['output']==1]['fbs'].value_counts().plot(kind = 'bar', color = 'green')\nplt.show()","fc81f559":"df['restecg'].value_counts().plot(kind = 'bar')\nplt.show","4a74f06a":"df[df['output']==1]['restecg'].value_counts().plot(kind = 'bar')\nplt.show()","9a3eae9b":"fig = plt.figure(figsize=(16,16))\nfig = plt.subplot(431)\ndf['exng'].value_counts().plot(kind = 'bar', color='red')\nplt.legend()\nfig = plt.subplot(432)\ndf[df['output']==1]['exng'].value_counts().plot(kind = 'bar', color = 'pink')\nplt.legend()\nplt.subplot(433)\ndf[df['output']==1]['restecg'].value_counts().plot(kind = 'bar', color='green')\nplt.legend()\nplt.subplot(434)\ndf['restecg'].value_counts().plot(kind = 'bar', color ='grey')\nplt.legend()\nplt.show()","e09da6a4":"df[df['output']==1]['exng'].value_counts().plot(kind = 'bar')\nplt.show()","a011a6db":"figure(figsize=(12, 6), dpi=80)\nsns.histplot(df['oldpeak'], kde =True)\nplt.xlabel('OldPeak')\nplt.ylabel('Count')\nplt.title('Old Peak Analysis')\nplt.show()","cc1b888c":"figure(figsize=(12, 6), dpi=80)\nsns.histplot(df[df['output']==1]['oldpeak'], kde =True)\nplt.xlabel('oldpeak')\nplt.ylabel('Count')\nplt.title('oldpeak Analysis with Heart attack')\nplt.show()","f20d3186":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split","a149ff2f":"y = df.pop('output')\nx = df\nx_train,x_test,y_train,y_test = train_test_split(x, y,test_size=0.25, random_state=100)","caf39dc0":"print(x_train.columns)","c41d09fe":"model = RandomForestClassifier().fit(x_train,y_train)","7a76b1b0":"model.feature_importances_","c4555b72":"plt.barh(x_train.columns, model.feature_importances_)\nplt.show()","9327bc2a":"sorted_indx = model.feature_importances_.argsort()","ae18b357":"plt.barh(x_train.columns[sorted_indx], model.feature_importances_[sorted_indx])\nplt.show()","778d18fc":"df_new = df[['oldpeak','caa','thalachh','cp','thall','chol','age','trtbps']]","c08a0d23":"print(df_new.head())","1317d02d":"x_train,x_test,y_train,y_test = train_test_split(df_new,y,test_size=0.25,random_state=100)\nmodel_new = RandomForestClassifier(n_estimators=500, max_features=2, max_depth=5, class_weight='balanced')\nmodel_new.fit(x_train,y_train)","64c57ce7":"y_train.value_counts()","d49d0e21":"y_predicted = model_new.predict(x_test)","c84371ae":"from sklearn.metrics import accuracy_score, classification_report\n\naccuracy_score(y_test,y_predicted)","5e06fbc6":"classification_report(y_test,y_predicted)","bb19dfba":"model_new.oob_score","918b9efb":"print(model_new)","7e8d18c0":"from sklearn.ensemble import GradientBoostingClassifier\nclf = GradientBoostingClassifier(learning_rate = 0.2, n_estimators=500).fit(x_train,y_train)\ny_pred = clf.predict(x_test)","4bf16549":"accuracy_score(y_test,y_pred)","ddcf4102":"sns.heatmap(df.corr(),cmap='YlGnBu')\nplt.show()","25a97ab0":"print(df.head())","8a276425":"sns.countplot(data=df, x='fbs',hue='sex')\nplt.show()","d5aa77c0":"sns.pairplot(data=df)\nplt.show()","525dad21":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.fit_transform(x_test)","acda44f4":"x_train,x_test","cd9d484b":"scaled_model = RandomForestClassifier(n_estimators=500, max_depth = 2, max_features = 7, class_weight='balanced', min_samples_leaf=10)\nscaled_model.fit(x_train,y_train)","1b06a0b4":"y_pred = scaled_model.predict(x_test)","98376fb2":"print(f\"The Accuracy Score is {accuracy_score(y_test,y_pred) *100} %\")","f326c1df":"from sklearn.svm import SVC","02585fac":"svc_model = SVC()\nsvc_model.fit(x_train,y_train)","47e1ec9a":"y_pred_svc = svc_model.predict(x_test)","bae5b56f":"accuracy_score(y_test,y_pred_svc)","6ef25248":"We dont have any null values in the **heart attack** dataset","36fa1bbb":"Whoever having with 120 and 130 mmhg Blood pressure results in high chance of heart attack","532aaa24":"# Fasting Blood Pressure Analysis","e6fbf68d":"Choloestrol with contain 200 to 300 mg\/dl having high records in the dataset and it is right skewed.","e28e03e0":"Whoever having Type 1 rest ecg possible of high chance of heart attack.","bcaba014":"Whoever having less than 120 of fasting blood level will have high chance of Heart attack","d830fe36":"Type 0 and Type 1 having high counts in the heart attack dataset.","948e7ae6":"# Exercised Induced Angina","627ff0bd":"Getting the Accuracy score of **84.2 %**","adf4356b":"Type 0 Chest pain contain high records in the dataset.","c50f9e09":"Whoever having the Type 2 chest pain possible of high probability Heart attack.","3ed4ce30":"1. Data Preparing","aaa8bf2b":"Around 50 to 55 age people were highly affected from Heart attack.\nFollow that 40 to 45 age people with high counts were affected in the Heart attack.","3045c5e8":"120 mmhg with having high record count in the dataset.","08a01a3f":"# Cholestrol Analysis","760a5e97":"Old Peak data wont help on the model, it doesnt have much impact on analysis","6c7a54d4":"# Resting Electrocardiographic Results","b083e616":"Males are highly affected in heart attack when compared to female.","2357fa4f":"# Old Peak","c52f9e25":"Whoever having not exercised induced angina is possible of having heart attack.","a7615787":"Male count is double when comparitively with female in the heart attack dataset","cbebdc68":"Around 52 to 62 age people data were in the dataset with higher counts","8bc130da":"Around 180 to 260 mg\/dl cholestrol level peoplehaving high chance of probability of heart attack.","6b3faca4":"Fasting blood pressure less than 120 is having high count in the dataset.","7f9ee74d":"For not having exercised induced angina having high count in the dataset."}}