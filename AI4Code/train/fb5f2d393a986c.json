{"cell_type":{"4eaf6f4f":"code","d8a9c415":"code","78005c45":"code","aea71fb6":"code","38b20bd2":"code","d09cbff4":"code","2adef118":"code","c91d4b12":"code","5aeabcd7":"code","f3548c73":"code","2804a702":"code","dce9014a":"code","2f949212":"code","ef54071f":"code","1ec8b982":"code","dca84d56":"code","391e4d83":"code","01d46d36":"code","f47499da":"code","f921bd6e":"code","1df402da":"code","4fbd8c96":"code","03a206b7":"code","919e881c":"code","affb607b":"code","4b015467":"code","8627c4a0":"code","564edc00":"markdown","aa662436":"markdown","a9a7e168":"markdown","d23a6acd":"markdown"},"source":{"4eaf6f4f":"#Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model\n# file path\nimport os\nprint(os.listdir(\"..\/input\"))","d8a9c415":"path='..\/input\/data.csv'\ndf= pd.read_csv(path)","78005c45":"#Let's see the features of the dataset\ndf.head()\ndf.columns","aea71fb6":"#since there are a lot of unnecessary features for prediction of 'Overall score' I dropped them out . \ndf=df.drop(['Unnamed: 0','ID', 'Position', 'Name', 'Photo', 'Nationality','Potential', 'Flag', 'Club', 'Club Logo', 'Value', 'Wage', 'Special',\n       'Preferred Foot', 'International Reputation', 'Weak Foot',\n       'Skill Moves', 'Work Rate', 'Body Type', 'Real Face',\n       'Jersey Number', 'Joined', 'Loaned From', 'Contract Valid Until', 'Release Clause','LS', 'ST', 'RS', 'LW', 'LF', 'CF', 'RF', 'RW',\n       'LAM', 'CAM', 'RAM', 'LM', 'LCM', 'CM', 'RCM', 'RM', 'LWB', 'LDM',\n       'CDM', 'RDM', 'RWB', 'LB', 'LCB', 'CB', 'RCB', 'RB','Height', 'Weight'] , 1)","38b20bd2":"#To make sure the left features are appropriate\ndf.columns","d09cbff4":"df.describe()","2adef118":"len(df)","c91d4b12":"df=df.dropna()\n#There is a lot of data that is missing, therefore we drop those lines of data\ndf.isnull().sum()","5aeabcd7":"len(df)","f3548c73":"f , axes = plt.subplots(figsize = (10,5))\nax = sns.countplot('Age', data = df)\nplt.ylabel('Number of players')","2804a702":"f , axes = plt.subplots(figsize = (20,5))\nax = sns.countplot('Overall', data = df)\nplt.ylabel('Number of players')\nplt.xlabel('Overall Score')","dce9014a":"#First of all I will split the data into three sets: train, validation and test sets (60:20:20)\ntrain, validate, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])","2f949212":"train.head()","ef54071f":"validate.head()","1ec8b982":"test.head()","dca84d56":"train.describe()","391e4d83":"#The training values of y should contain only Overall score and x values should be without Overall score.\nx_train=np.array(train.drop(['Overall',], axis=1))\ny_train=np.array(train['Overall'])\n\nx_validate=np.array(validate.drop(['Overall',], axis=1))\ny_validate=np.array(validate['Overall'])\n\nx_test=np.array(test.drop(['Overall',], axis=1))\ny_test=np.array(test['Overall'])","01d46d36":"len(x_train), len(x_validate) , len(x_test)","f47499da":"#I created a function that runs a model and gives the MSE for the selected test set and alpha\ndef model_run(x1, y1, x2, y2, alpha):\n    model = linear_model.Ridge(alpha)\n    model.fit(x1, y1)\n    predictions=model.predict(x2)\n    \n    differences=[(x-y)**2 for (x,y) in zip(predictions, y2)]\n    MSE=sum(differences)\/len(differences)\n    \n    return MSE","f921bd6e":"#This creates a set of values of alpha\nlist=np.logspace(-3,5,100)","1df402da":"#Let's create a loop to run a model for the values of alpha with training data set\nalpha=[]\nyaxis=[]\nfor item in list:\n    alpha.append((item))\n    yaxis.append(model_run(x_train, y_train, x_train, y_train, item))\na=yaxis","4fbd8c96":"#Let's create a loop to run a model for the values of alpha with validation data set\nalpha=[]\nyaxis=[]\nfor item in list:\n    alpha.append((item))\n    yaxis.append(model_run(x_train, y_train, x_validate, y_validate, item))\nb=yaxis","03a206b7":"#Let's create a loop to run a model for the values of alpha with testing data set\nalpha=[]\nyaxis=[]\nfor item in list:\n    alpha.append((item))\n    yaxis.append(model_run(x_train, y_train, x_test, y_test, item))\nc=yaxis","919e881c":"#To illustrate the results of comparison, I will try to plot the values of MSE with respect to values of alpha.\n#In addition, the graph shows the minimum results on each validation and testing data.\n#The red line shows the optimum value of alpha among both sets. \nplt.plot(alpha, a, label='Training')\nplt.xscale('log')\nplt.plot(alpha, b, label='Validation')\nplt.xscale('log')\nplt.plot(alpha, c, label='Testing')\nplt.xscale('log')\n\nplt.xlabel('alpha')\nplt.ylabel('MSE')\nplt.plot(alpha[b.index(min(b))], min(b), 'ro')\nplt.plot(alpha[c.index(min(c))], min(c), 'ro')\n\nsum=[]\nfor i in range(100):\n    sum.append(b[i]+c[i])\nplt.axvline(x=alpha[sum.index(min(sum))], label='Minimum of sum of training and testing sets', color='r')\n\nplt.legend()","affb607b":"# Let's determine the minimum point of sum of validation and testing sets:\nbest_alpha=alpha[sum.index(min(sum))]\nprint('The tuned parameter of regulizer is = ' +str(best_alpha))\n# For our case the value of alpha is optimum to this model. ","4b015467":"#Let's see the MSE and R2 for validation set:\nMSE=b[sum.index(min(sum))]\nprint('MSE = '+ str(MSE))\n\nFVU=MSE\/np.var(y_validate)\nR2=1-FVU\nprint('R2 = '+ str(R2))","8627c4a0":"#Let's see the MSE and R2 for test set:\nMSE=c[sum.index(min(sum))]\nprint('MSE = '+ str(MSE))\n\nFVU=MSE\/np.var(y_test)\nR2=1-FVU\nprint('R2 = '+ str(R2))","564edc00":"# In FIFA19, prediction of players overall score\n\nFIFA is a football based game developed by game giants EA Sports every year. So, it was no surprise that EA Sports launched FIFA 19 earlier this year. FIFA 19 contains a rich dataset with plenty of attributes covering all aspects of a real-life footballer in an attempt to immitate him as much as possible in the virtual world. This rich dataset provides a huge oppurtunity for us, data scientists or data analysts (you choose the term !) to analyze and come up with visualizations and patterns. In this paper, I will try to learn analyzing models performance. In the end, I will end up with a model with tuned alpha parameter of regulizer. \n\nThe data can be found via the link below:\nhttps:\/\/www.kaggle.com\/karangadiya\/fifa19\n","aa662436":"# Model assessment:","a9a7e168":"# Splitting the data\nThe main task here to use all features to determine the overall score of the player.","d23a6acd":"# Results:\nAs a resut, the alpha value for the regulizer is 8902.15 while the MSE and R2 is 6.8 and 0.85. The value of R2 shows that the model at some level performs well on given data with selected features."}}