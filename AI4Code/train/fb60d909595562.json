{"cell_type":{"4430b279":"code","480f1097":"code","abc64610":"code","98880d76":"code","f7abb1ed":"code","a6ff43d6":"code","7544eb0f":"code","989c5f78":"code","ef813252":"code","90a60074":"code","4d2fd521":"code","1418c245":"code","9a6958eb":"code","3e636869":"code","65e3758d":"code","c2f57874":"code","47841adc":"code","ec951b28":"code","8e9534ba":"code","73d7423a":"code","2d76b698":"code","28573b06":"code","7bfccaff":"markdown","92d0b6e7":"markdown"},"source":{"4430b279":"import numpy as np\nimport pandas as pd \nimport os\nprint(os.listdir(\"..\/input\"))\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2\nimport gc","480f1097":"df = pd.read_csv('..\/input\/openimagevallabel\/validation-annotations-human-imagelabels.csv', usecols=[0,2,3])\ndf = df[df.Confidence == 1]\nclasses = np.array(['\/m\/01g317', '\/m\/09j2d', '\/m\/04yx4', '\/m\/0dzct', '\/m\/07j7r', '\/m\/05s2s', '\/m\/03bt1vf', '\/m\/07yv9', '\/m\/0cgh4', '\/m\/01prls']\n)\nli = []\nfor i in classes:\n    li.append(df[df.LabelName == i])\ndf = pd.concat(li).sample(frac=1).reset_index(drop=True)\ndel li\ngc.collect()\ndf.head()","abc64610":"labels = df.LabelName.tolist()\nImageid = df.ImageID.values\nprint(len(df))","98880d76":"from keras.preprocessing.image import load_img, img_to_array\nfrom keras.layers import Dense, Conv2D, PReLU, BatchNormalization, MaxPooling2D, Dropout, Flatten\nimport keras\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K\nfrom keras.models import load_model, Sequential\nfrom tqdm import tqdm_notebook\nfrom tqdm import tqdm","f7abb1ed":"df.head(),gc.collect()","a6ff43d6":"X_train = [np.array(load_img('..\/input\/open-image-val\/validation\/validation\/{}.jpg'.format(i),target_size=(100,100), grayscale=True))\/255 for i in tqdm(Imageid[10000:20000])]","7544eb0f":"X_Val = [np.array(load_img('..\/input\/open-image-val\/validation\/validation\/{}.jpg'.format(i),target_size=(100,100), grayscale=True))\/255 for i in tqdm(Imageid[:2000])]","989c5f78":"#Y_train = labels[10000:20000]\n#Y_Val = labels[:2000]\nclasses = classes.tolist()\nY_train, Y_Val = [], []\nfor i in tqdm(labels[10000:20000]):\n    temp = np.zeros(10)\n    temp[classes.index(i)] = 1\n    Y_train.append(temp)\n    del temp\nfor i in tqdm(labels[:2000]):\n    temp = np.zeros(10)\n    temp[classes.index(i)] = 1\n    Y_Val.append(temp)\n    del temp\nY_train = np.array(Y_train)\nY_Val = np.array(Y_Val)\ngc.collect(), Y_train[0]","ef813252":"nn = Sequential()\nnn.add(BatchNormalization(input_shape=(100, 100, 1)))\nnn.add(Conv2D(4, kernel_size=(2,2), strides=(1,1)))\nnn.add(PReLU())\nnn.add(BatchNormalization())\nnn.add(Dropout(0.25))\nnn.add(Conv2D(8, kernel_size=(2,2), strides=(1,1)))\nnn.add(PReLU())\nnn.add(BatchNormalization())\nnn.add(Dropout(0.25))\nnn.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\nnn.add(Conv2D(16, kernel_size=(2,2), strides=(1,1)))\nnn.add(PReLU())\nnn.add(BatchNormalization())\nnn.add(Dropout(0.25))\nnn.add(Conv2D(32, kernel_size=(2,2), strides=(1,1)))\nnn.add(PReLU())\nnn.add(BatchNormalization())\nnn.add(Dropout(0.25))\nnn.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\nnn.add(Conv2D(64, kernel_size=(2,2), strides=(1,1)))\nnn.add(PReLU())\nnn.add(BatchNormalization())\nnn.add(Dropout(0.25))\nnn.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\nnn.add(Conv2D(64, kernel_size=(2,2), strides=(1,1)))\nnn.add(PReLU())\nnn.add(BatchNormalization())\nnn.add(Dropout(0.25))\nnn.add(Flatten())\nnn.add(Dense(2048))\nnn.add(PReLU())\nnn.add(BatchNormalization())\nnn.add(Dropout(0.25))\nnn.add(Dense(1024))\nnn.add(PReLU())\nnn.add(BatchNormalization())\nnn.add(Dropout(0.25))\nnn.add(Dense(512))\nnn.add(PReLU())\nnn.add(BatchNormalization())\nnn.add(Dropout(0.25))\nnn.add(Dense(128))\nnn.add(PReLU())\nnn.add(BatchNormalization())\nnn.add(Dropout(0.25))\nnn.add(Dense(50))\nnn.add(PReLU())\nnn.add(BatchNormalization())\nnn.add(Dropout(0.25))\nnn.add(Dense(16))\nnn.add(PReLU())\nnn.add(BatchNormalization())\nnn.add(Dropout(0.25))\nnn.add(Dense(10, activation='softmax'))","90a60074":"nn.compile(loss=keras.losses.categorical_crossentropy, metrics=['accuracy'], optimizer='adam')\nnn.summary()","4d2fd521":"X_train = np.array(X_train).reshape((10000,100,100,1))\nX_Val = np.array(X_Val).reshape((2000,100,100,1))","1418c245":"gc.collect()","9a6958eb":"nn.fit(X_train, Y_train, validation_data=(X_Val,Y_Val), batch_size=100, epochs=17, verbose=2)","3e636869":"del X_train, Y_train, X_Val, Y_Val, df\ngc.collect()","65e3758d":"df = pd.read_csv('..\/input\/inclusive-images-challenge\/stage_1_sample_submission.csv', usecols=[0])\nim = df.image_id.tolist()\ndf.head()","c2f57874":"X_test = [np.array(load_img('..\/input\/inclusive-images-challenge\/stage_1_test_images\/{}.jpg'.format(i),target_size=(100,100), grayscale=True))\/255 for i in tqdm_notebook(im)]","47841adc":"X_test = np.array(X_test).reshape((32580,100,100,1))","ec951b28":"pre = nn.predict(X_test).argsort(1)[:,:5]\ndel X_test\ngc.collect()","8e9534ba":"p = []\nfor it in tqdm(pre):\n    p.append(' '.join([classes[int(i)] for i in it]))","73d7423a":"df['labels'] = p\ndf.head()","2d76b698":"df.to_csv('sub.csv', index=False)","28573b06":"!cat sub.csv","7bfccaff":"## If you find this kernel helpful, please upvote it.\n## If you have any questions or suggestions please let me know.","92d0b6e7":"# CNN with 20 Classes trained on Open Image Validation Set"}}