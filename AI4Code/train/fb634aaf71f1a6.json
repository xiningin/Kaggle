{"cell_type":{"e78ee4e4":"code","60213afb":"code","4b13275b":"code","fa88f8b1":"code","09deb6b8":"code","d4096629":"code","d770429c":"code","99a5bf53":"code","7dea86c3":"code","9e30c40e":"code","edf32656":"code","c266ff43":"code","ef14474c":"code","f72ad792":"code","266f2ac7":"code","f47d2fbd":"code","364cd657":"code","6ab889a6":"code","8dfbb5e2":"code","b4e6f6d0":"code","d44e7296":"code","5406567b":"code","176eeb3c":"code","7bd2af90":"code","597df76d":"code","6f6375ce":"markdown","c94250c6":"markdown","e561b135":"markdown","e4ec0341":"markdown","df2d9fc5":"markdown","14676854":"markdown","7ff9dcfb":"markdown","50288c31":"markdown","4598e5a1":"markdown","13f4665d":"markdown","c46c160e":"markdown","85dd525b":"markdown","1a74de81":"markdown","e14e5236":"markdown","56cbecb6":"markdown","fccce1b9":"markdown","9c3f978f":"markdown","190c3da7":"markdown","31470338":"markdown","3939890c":"markdown","8324510e":"markdown","64ca8cae":"markdown","2ee74d4d":"markdown","e53a4a8f":"markdown","f200c9ce":"markdown","84945b5a":"markdown","bad21355":"markdown","e987c450":"markdown","9481d29c":"markdown","3d4d1c34":"markdown"},"source":{"e78ee4e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport lightgbm as lgb\nfrom kaggle.competitions import twosigmanews\nfrom sklearn.metrics import confusion_matrix, accuracy_score","60213afb":"env = twosigmanews.make_env()\n\nmarket_orig, news_orig = env.get_training_data()","4b13275b":"# We'll use data from 2013 onwards to speed things up a bit\nmarket_orig = market_orig[market_orig['time'] >= \"2013-01-01\"]\nmarket_orig.head()","fa88f8b1":"def unique_asset_names(df):\n    return \"TODO\"\n\nunique_asset_names(market_orig)","09deb6b8":"def most_common_asset_name(df):\n    return \"TODO\"\n\nmost_common_asset_name(market_orig)","d4096629":"def max_next10(df):\n    return \"TODO\"\n\nmax_next10(market_orig)","d770429c":"# Matplotlib is available as \"plt\"\nplt.figure(figsize=(12,7))\n\ndef plot_fb(df):\n    return \"TODO\"\n\nplot_fb(market_orig)","99a5bf53":"def asset_presence(df):\n    return \"TODO\"\n\nasset_presence(market_orig)","7dea86c3":"def remove_unknown(df):\n    return df\n\nmarket = remove_unknown(market_orig)","9e30c40e":"def clip_next10(df):\n    return df\n\nmarket = clip_next10(market)","edf32656":"def remove_short_lived(df):\n    return df\n\nmarket = remove_short_lived(market)","c266ff43":"# https:\/\/github.com\/bukosabino\/ta\/blob\/master\/ta\/momentum.py\ndef ema(series, periods, fillna=False):\n    if fillna:\n        return series.ewm(span=periods, min_periods=0).mean()\n    return series.ewm(span=periods, min_periods=periods).mean()\n\ndef rsi(close, n=14, fillna=False):\n    \"\"\"Relative Strength Index (RSI)\n    Compares the magnitude of recent gains and losses over a specified time\n    period to measure speed and change of price movements of a security. It is\n    primarily used to attempt to identify overbought or oversold conditions in\n    the trading of an asset.\n    https:\/\/www.investopedia.com\/terms\/r\/rsi.asp\n    Args:\n        close(pandas.Series): dataset 'Close' column.\n        n(int): n period.\n        fillna(bool): if True, fill nan values.\n    Returns:\n        pandas.Series: New feature generated.\n    \"\"\"\n    diff = close.diff()\n    which_dn = diff < 0\n\n    up, dn = diff, diff*0\n    up[which_dn], dn[which_dn] = 0, -up[which_dn]\n\n    emaup = ema(up, n, fillna)\n    emadn = ema(dn, n, fillna)\n\n    rsi = 100 * emaup \/ (emaup + emadn)\n    if fillna:\n        rsi = rsi.replace([np.inf, -np.inf], np.nan).fillna(50)\n    return pd.Series(rsi, name='rsi')","ef14474c":"# TODO: Add the RSI indicator to the market df","f72ad792":"def add_volume_avg(df):\n    return df\n\nadd_volume_avg(market)","266f2ac7":"def add_lag_features(df):\n    return df\n    \nmarket = add_lag_features(market)","f47d2fbd":"# Returns:\n#    X: numpy matrix with relevant features only\n#    y: numpy array of class values, 0 if returnsOpenNextMktres10 is negative, else 1\n\nTRAIN_END_DATE  = \"\"\nTEST_START_DATE = \"\"\n\ndef get_data(df):\n    pass\n\nX_train, y_train = get_data()\nX_test, y_test   = get_data()","364cd657":"def train_clf(X_train, y_train):\n    # https:\/\/lightgbm.readthedocs.io\/en\/latest\/Parameters.html\n    params = {\n        'objective': 'binary',\n        'num_threads': 4\n    }\n\n    train_set = lgb.Dataset(X_train, y_train)\n\n    # https:\/\/lightgbm.readthedocs.io\/en\/latest\/Python-API.html#training-api\n    lgb_clf = lgb.train(params, train_set)\n    \n    return lgb_clf\n\nclf = train_clf(X_train, y_train)","6ab889a6":"def accuracy(clf, X_test, y_test):\n    return 0\n\naccuracy(clf, X_test, y_test)","8dfbb5e2":"# You can use this helper, if you want.\ndef plot_feature_importances(clf, feature_columns):\n    features_imp = pd.DataFrame()\n    features_imp['features'] = list(feature_columns)[:]\n    features_imp['importance'] = clf.feature_importance()\n    features_imp = features_imp.sort_values(by='importance', ascending=False).reset_index()\n    shape = features_imp.shape[0]\n    \n    y_plot = -np.arange(shape)\n    plt.figure(figsize=(10,7))\n    plt.barh(y_plot, features_imp.loc[:shape,'importance'].values)\n    plt.yticks(y_plot,(features_imp.loc[:shape,'features']))\n    plt.xlabel('Feature importance')\n    plt.title('Features importance')\n    plt.tight_layout()\n\n","b4e6f6d0":"# Returns a series of confidence values\ndef get_confidence(clf, X_test):\n    y_pred = clf.predict(X_test)\n    \n    return \"TODO\"\n\nconfidence = get_confidence(clf, X_test)","d44e7296":"# You can use this helper:\ndef get_scoring_data(market):\n    test_df         = market[[market['time'] > TEST_START_DATE]\n    test_df['date'] = df['time'].dt.date\n                     \n    actual_returns  = test_df['returnsOpenNextMktres10'].values.clip(-1, 1)\n    universe        = test_df['universe']\n    dates           = test_df['date']\n\n    return actual_returns, universe, dates\n\nactual_returns, universe, dates = get_scoring_data(market)","5406567b":"def score(confidence, actual_returns, universe, dates):\n    return 0\n\nscore(confidence, actual_returns, universe, dates)","176eeb3c":"# Modify the \"score\" function above to plot your strategy's daily returns","7bd2af90":"def cross_validate():\n    # 1. Create folds based on date from the data\n    # 2. Train a classifier for each fold\n    # 3. Test against related test set\n    # 4. Evaluate the results\n    \n    pass\n\ncross_validate()","597df76d":"# Implement a voting strategy, you can reuse a lot of the code from the cross_validation step","6f6375ce":"# Section 2. Preprocessing","c94250c6":"## 2.3 Remove instances where the asset is not present in the data for more than 30 days (use \"assetCode\")","e561b135":"##  1.1 How many unique assetNames are there?","e4ec0341":"## 6.1 Cross-validate your model using an appropriate approach for time series data\nLets see if the model performs similarly on data from different time periods.\n\nHopyfully, you can reuse some of the functions you've previously created.","df2d9fc5":"## 3.3 (Optional) - Add additional lag features for some relevant columns. Compute min, max and mean for different window sizes\n\n*Hint:*\n\n'76-tpircs-ade\/rogoegqq\/moc.elggak.www\/\/:sptth :lenrek siht ni noitaripsni dna spit ecnamrofrep doog emos ereht'[::-1]\n\n\n","14676854":"# 8 Revise your pipeline\nNow you hopefully have a good sense of the problem, and you can back and try to improve each step a long the way. \n\nHere's a few things you can try for a better score:\n\n* Better preprocessing\n* Use the news data set\n* Multiclass classification\n* Probability Selection\n* Further post-preprocessing strategies\n* Any ideas that you might have","7ff9dcfb":"## 7.1 Democratize your solution. \nImplement a way for multiple classifiers to have a say about the confidence interval","50288c31":"# 6 Model Evaluation","4598e5a1":"## 2.1 Remove all rows where assetName is \"Unknown\"\n*Hint:*\n\n'dnammoc nisi eht htiw emarfatad eht no gniksam naeloob esu ot si noitulos elbissop a'[::-1]","13f4665d":"# 5 Confidence Interval & Scoring","c46c160e":"\n# Section 4 - Binary Classification in LightGBM ","85dd525b":"# 7. Voting\n","1a74de81":"# Load the data from the competition environment\nYou can only load the data from the env once - you'll need to completely restart your kernel if you lose it (second right button at the very bottom)","e14e5236":"## 1.2 Find the most common assetName.\nHint:\n\n'noitagergga tnuoc htiw denibmoc ybpuorg noitcnuf sadnap eht esu nac uoy'[::-1]","56cbecb6":"# Section 3. Feature Creation","fccce1b9":"## 3.1 Add the (RSI) indicator for a few different periods (default is 14)","9c3f978f":"## 5.2 Compute the score of your strategy\n\nMake sure you group the predictions by day, and use the formula in the competition description.","190c3da7":"## 5.1 Construct a confidence value for each sample in the test set","31470338":"## 1.5 What is the min, max and mean amount of days an asset is present in the dataset? (use \"assetCode\")","3939890c":"## 1.3  What is the maximum value of returnsOpenNextMktres10?","8324510e":"# Section 1, Data Investigation\n","64ca8cae":"## 4.4 Plot the feature importances of your trained model","2ee74d4d":"## 4.3 Report the test accuracy score of your classifier\n","e53a4a8f":"## 2.2 Limit the returnsOpenNextMktres10 column to values between -1 and 1\n\n*Hint:*\n\n'noitcnuf pilc sadnap eht yrt'[::-1]","f200c9ce":"## 4.1 Separate the data into a train and test set based on reasonable dates\n\nIt is wise to have small gap between your train set and test set.","84945b5a":"## 3.2 Add features which measures the average volume of the last [5, 10, 20] days\n\n*Hint:*\n\n'emarfatad eht revo wodniw gnillor a etaerc nac uoy'[::-1]","bad21355":"# Backtick hands on kernel\nAfter some initial setup a few sectionsfollows, that upon completetion will allow you to implement a simple stock market price prediction pipeline.\n\nThe pandas API documenation is a useful source to solve some of the problems: https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/index.html\n\n## 1 Data investigation\n## 2 Preprocessing\n## 3 Feature Creation\n## 4 Binary Classification in LightGBM\n## 5 Confidence Interval & Scoring\n## 6 Model Evaluation\n## 7 Voting","e987c450":"## 4.2 Familiarize yourself with the LightGBM API","9481d29c":"## 1.4 Plot the close price of Facebook (assetCode=\"FB.O\") over time\n\nHint:\n\n'sixa x sa nmuloc emit eht ssap ,biltolptam fo noitcnuf tolp eht tuo kcehc'[::-1]","3d4d1c34":"## 5.3 Plot the daily returns of your strategy"}}