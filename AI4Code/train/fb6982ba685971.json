{"cell_type":{"c7afd102":"code","160e1f90":"code","8ecba9aa":"code","50b0cd8e":"code","81f5bfdb":"code","fde7e061":"code","f7abddbf":"code","36c67e21":"code","cb1f9874":"code","c4f18849":"code","77479010":"code","21d4c3b4":"code","217ad2cb":"code","f26ee5f4":"code","17f01807":"code","219b09f2":"code","cad3b6cc":"code","6c0ad67a":"code","7cd9acb7":"code","a1b25800":"code","5fc6adc4":"code","7985e791":"code","52bf3c73":"code","a9df7fa6":"code","0668ecfa":"code","226f71d5":"code","ae8192a3":"code","e79cf66e":"code","323f3573":"code","c40708b4":"code","8b4d5df0":"code","6511f5d8":"code","e7500a96":"code","37f2da58":"code","ab9c3ac4":"code","7616c786":"code","01c90d20":"code","72227f02":"code","ae07fd0c":"code","d99b1038":"code","f51538a0":"code","15958247":"code","0a03b537":"code","0660519a":"code","84916b01":"code","ac9c452c":"code","5e078425":"code","315739b5":"code","2099824d":"code","dfc8fb75":"code","7a28d87d":"code","1a12a5ed":"code","606d3fbb":"code","51249127":"code","6c9d5b93":"code","ec292f95":"code","075cc963":"code","5dca2c9d":"code","54872de1":"code","8e0dc08a":"markdown","87deebf1":"markdown","7f65a07e":"markdown","94564c97":"markdown","2d3fb551":"markdown","09eff522":"markdown","605282f9":"markdown","31d9a510":"markdown","13c51e13":"markdown","563be607":"markdown","4ad3192a":"markdown","1118a07e":"markdown","871e3ae3":"markdown","12c72d09":"markdown","e2d3d236":"markdown","40303108":"markdown","a4c0cfe8":"markdown","73852429":"markdown","d66982fc":"markdown","726dca43":"markdown","2d811d76":"markdown","ca820e42":"markdown","5612efbd":"markdown","a3781ef2":"markdown","5330a17d":"markdown","67c99a9b":"markdown","d0ca2d53":"markdown","30812d16":"markdown","2fc4a9b3":"markdown","87058f82":"markdown","ebe5a42d":"markdown","30ebd69a":"markdown","12e160da":"markdown","fe8760aa":"markdown","31e74000":"markdown","8f1ded76":"markdown","8b541951":"markdown","2d0c5605":"markdown","b9f75179":"markdown","6086b5d9":"markdown","1d26c54d":"markdown","409c0c6f":"markdown","63915f68":"markdown","eec687d2":"markdown","0e157d9a":"markdown","4f78af52":"markdown","54cb9505":"markdown","db80b2b1":"markdown","68b05ee9":"markdown"},"source":{"c7afd102":"from sklearn.ensemble import GradientBoostingClassifier\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom imblearn.over_sampling import SMOTE\nimport warnings\n\nfrom sklearn.exceptions import ConvergenceWarning\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n\npd.pandas.set_option('display.max_columns', None)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\n","160e1f90":"df1 = pd.read_csv(\"..\/input\/credit-risk\/credit_risk.csv\")","8ecba9aa":"df1.columns","50b0cd8e":"df1.describe().T","81f5bfdb":"df1.drop(['Unnamed: 0'],axis=1,inplace=True)\n","fde7e061":"df = df1.copy()","f7abddbf":"df.head()","36c67e21":"df.shape","cb1f9874":"df.columns","c4f18849":"df.info()\n","77479010":"df.size","21d4c3b4":"df['Sex'].value_counts()","217ad2cb":"df['Saving accounts'].value_counts()","f26ee5f4":"df['Checking account'].value_counts()","17f01807":"df['Credit amount'].value_counts()\n","219b09f2":"df['Credit amount'].unique()","cad3b6cc":"df['Purpose'].value_counts()\n","6c0ad67a":"df['Risk'].value_counts()","7cd9acb7":"def load_credit_risk():\n    dataframe = pd.read_csv(\"..\/input\/credit-risk\/credit_risk.csv\")\n    return dataframe","a1b25800":"df['Job'] = df['Job'].astype(\"str\")","5fc6adc4":"cat_cols = [col for col in df.columns if df[col].dtypes == 'O']\nprint('Number of Categorical Variables : ', len(cat_cols))","7985e791":"cat_cols","52bf3c73":"sns.pairplot(df[['Age','Credit amount','Duration']])\nplt.show()","a9df7fa6":"num_cols = [col for col in df.columns if df[col].dtypes != 'O' and col not in \"Id\"]\nprint('Number of Numerical Variables: ', len(num_cols))","0668ecfa":"num_cols","226f71d5":"def hist_for_nums(data, numeric_cols):\n    col_counter = 0\n    data = data.copy()\n    for col in numeric_cols:\n        data[col].hist(bins=20)\n        plt.xlabel(col)\n        plt.title(col)\n        plt.show()\n        col_counter += 1\n    print(col_counter, \"variables have been plotted\")   ","ae8192a3":" hist_for_nums(df, num_cols)","e79cf66e":"df.corr()\n","323f3573":"corrmat = df.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat,vmin = 0,vmax=1,square=True,cmap=\"YlGnBu\",ax=ax)\nplt.show()","c40708b4":"df[\"Risk\"].value_counts()","8b4d5df0":"fig1, ax1 = plt.subplots()\nax1.pie(df[\"Risk\"].value_counts(),  labels=['good','bad'], autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')\nplt.show()","6511f5d8":"df.isnull().values.any()","e7500a96":"df.isnull().sum()","37f2da58":"df[\"Saving accounts\"].value_counts()","ab9c3ac4":"df[\"Saving accounts\"].fillna(df[\"Saving accounts\"].mode()[0], inplace=True)","7616c786":"df[\"Saving accounts\"].value_counts()","01c90d20":"df.isnull().sum()","72227f02":"df['Checking account'] = df['Checking account'].fillna(\"None\")","ae07fd0c":"df.isnull().sum()","d99b1038":"df = df.reset_index(drop=True)","f51538a0":"df.columns","15958247":"df.groupby(\"Sex\")[\"Risk\"].value_counts()","0a03b537":"df.groupby(\"Purpose\")[\"Risk\"].value_counts()","0660519a":"df.groupby(\"Housing\")[\"Risk\"].value_counts()","84916b01":"\ndef outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.5)\n    quartile3 = dataframe[variable].quantile(0.95)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\n\ndef has_outliers(dataframe, num_col_names, plot=False):\n    variable_names = []\n    for col in num_col_names:\n        low_limit, up_limit = outlier_thresholds(dataframe, col)\n        if dataframe[(dataframe[col] > up_limit) | (dataframe[col] < low_limit)].any(axis=None):\n            number_of_outliers = dataframe[(dataframe[col] > up_limit) | (dataframe[col] < low_limit)].shape[0]\n            print(col, \":\", number_of_outliers)\n            variable_names.append(col)\n            if plot:\n                sns.boxplot(x=dataframe[col])\n                plt.show()\n    return variable_names","ac9c452c":"def replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\n\nfor col in num_cols:\n    replace_with_thresholds(df, col)\n","5e078425":"has_outliers(df, num_cols)","315739b5":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ndf[\"Sex\"]= le.fit_transform(df[\"Sex\"])","2099824d":"\ndef one_hot_encoder(dataframe):\n    dataframe = pd.get_dummies(dataframe, columns=[\"Job\",'Housing', 'Saving accounts', 'Checking account', 'Purpose'], drop_first=True)\n    new_columns = [c for c in dataframe.columns if c not in original_columns]\n    return dataframe, new_columns","dfc8fb75":"df.head()","7a28d87d":"df.info()","1a12a5ed":"df = df.reset_index(drop=True)","606d3fbb":"df_new = df[['Age', 'Credit amount', 'Duration']]","51249127":"\ndef robust_scaler(variable):\n    var_median = variable.median()\n    quartile1 = variable.quantile(0.25)\n    quartile3 = variable.quantile(0.75)\n    interquantile_range = quartile3 - quartile1\n\n    if int(interquantile_range) == 0:\n        quartile1 = variable.quantile(0.05)\n        quartile3 = variable.quantile(0.95)\n        interquantile_range = quartile3 - quartile1\n        z = (variable - var_median) \/ interquantile_range\n        return round(z, 3)\n    else:\n        z = (variable - var_median) \/ interquantile_range\n    return round(z, 3)\n\nfor col in df_new:\n    df[col] = robust_scaler(df[col])\n","6c9d5b93":"df.drop(['Sex',\"Job\",'Housing', 'Saving accounts', 'Checking account', 'Purpose'],axis=1,inplace=True)\n","ec292f95":"\nX = df.drop('Risk', axis=1)\ny = df[[\"Risk\"]]\n","075cc963":"smt = SMOTE(random_state=12345)\nX_res, y_res = smt.fit_sample(X, y)","5dca2c9d":"\nmodels = []\n\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('SVR', SVC()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('RandomForests', RandomForestClassifier()))\nmodels.append(('GradientBoosting', GradientBoostingClassifier()))\nmodels.append(('XGBoost', XGBClassifier()))\nmodels.append(('Light GBM', LGBMClassifier()))\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=46)\n","54872de1":"\nfor name,model in models:\n    mod = model.fit(X_train,y_train)\n    y_pred = mod.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    cvscore = cross_val_score(model, X,y, cv = 10).mean()\n    print(\"Holdout Method:\",end=\" \")\n    print(name,acc)\n    print(\"Cross Val Score\",end=\" \")\n    print(name,cvscore)\n    print(\"*********************************************\")","8e0dc08a":"Males take place in higher-risk groups  more than females.","87deebf1":"* Robust Scaler uygulayaca\u011f\u0131m de\u011fi\u015fkenleri se\u00e7tim.","7f65a07e":"# 4. ANALYSIS of NUMERICAL VARIABLE","94564c97":"* ****The sample size has been increased since it is an unbalanced data set.","2d3fb551":"* Label encoding was applied to geography categorical variables.","09eff522":"**List of Variable**","605282f9":"![](http:\/\/)![image.png](attachment:image.png)\nSource:https:\/\/www.quora.com\/","31d9a510":"### 6.2. Outlier Treatment","13c51e13":"**Data Summary**","563be607":"'Age', 'Sex', 'Job', 'Housing', 'Saving accounts',\n       'Checking account', 'Credit amount', 'Duration', 'Purpose', 'Risk'","4ad3192a":"**Convert the type of 'Job'**","1118a07e":"### Unbalanced Data Set","871e3ae3":"**Finding the number of values in the target column**","12c72d09":"One of the biggest difficulties in Machine Learning (ML) algorithms is an imbalanced data set (Gu et al., 2008).\nThat is,  the difference between variable class\u2019 ratio is huge. In other words, this will be happened \nwhen the ratio of one class of the variable is too small, and the ratio of the other class is too large. \nIn a short, the difference between the two classes is very large. This situation causes majority classes \nto be dominant in the ML algorithms. As a result, the classification accuracy of the minority classes can be small \ncompared to the classification accuracy of the majority classes.\n\nThere are basically two ways to overcome this challenge: 1) data-level approach, and 2) algorithm approach. \nIn addition, there are three categories of data-level approach: the over-sampling technique, \nthe combined technique, and the under-sampling technique. In this study, Synthetic Minority Over-sampling \nTechnique (SMOTE), which is an over-sampling technique, was used. SMOTE increases a number of small class, \nand is to produce synthetic instances. This technique  has an advantage to avoid the over-fitting \nproblem (Jeatrakul et al., 2010).","e2d3d236":"# 8. MODELING\n","40303108":"# 6. DATA PREPROCESSING & FEATURE ENGINEERING","a4c0cfe8":"There existed 394 missing values for 'Checking account' and 183 for'Saving accounts' in dataset.\n\nFor categorical columns (string columns), the missing values can be filled with mode. For numerical columns (float columns), the missing values can be filled with with mean.","73852429":"**Correlation of variables with Heatmap**","d66982fc":"* People's vacation and educational purposes bring about a high credit risk.","726dca43":"As seen from the values above, there is an imbalance between the classes of the dependent variable.","2d811d76":"\"Unnamed: 0\" was dropped  since it didnt effect the dependent variable.","ca820e42":"# 8. LABEL ENCODING & ONE-HOT ENCODING","5612efbd":" **list of Categorical Variable**\n*  'Sex', Job, 'Housing', 'Saving accounts', 'Checking account', 'Purpose', 'Risk'","a3781ef2":"* One hot encoding was applied to geography categorical variables.","5330a17d":"Credit risk analysis is an important issue in the credit industry which has a rapid growth in last three decades. \nEspecially globalization of economic and prevalent of information need an effective risk management in banking sytstem.\n Credit-risk evaluation is a method to overcome risk management problem . In doing so, credit scoring methods have been \n widely used by banking industry for reducing the cost of credit risk and improving the development of financial consumption. \n \nIn our current time,  97% of banks uses credit scoring and approves credit card applications. In addition, \nthe Federal Home Loan Mortgage Corporation and Federal National Mortgage Corporation want financial institutions \nto use credit scoring for mortgage origination and insurance applications (Mester, 1997).  At this point, \ncredit-risk evaluation is a very challenging topic in terms of  credit scoring. For predicting potential risk \nand minimizing the side effect of credit risk, this study is to develop a machine learning model that can classify\n credit risk.","67c99a9b":"* The risk profile of applicants screened by male and female is not similar.","d0ca2d53":" The index has been reorganized.","30812d16":"**Visualization of numeric variables**","2fc4a9b3":"**Objective**\n* The primary aim of this study is to develop a machine learning model that can classify credit risk.","87058f82":"# **References**\n\n* Gu, Q., Cai, Z., Zhu, L., & Huang, B. (2008). Data mining on imbalanced data sets. In 2008 International Conference on Advanced Computer Theory and Engineering (pp. 1020-1024). IEEE.\n* Jeatrakul, P., Wong, K. W., & Fung, C. C. (2010). Classification of imbalanced data by combining the complementary neural network and SMOTE algorithm. In International Conference on Neural Information Processing (pp. 152-159). Springer, Berlin, Heidelberg.\n* Mester, L. J. (1997). What\u2019s the point of credit scoring? Federal Reserve Bank of Philedelphia Business Review, September.\n","ebe5a42d":"# 5. ANALYSIS of DEPENDENT VARIABLE (TARGET ANALYSIS)","30ebd69a":"In this section, first of all, categorical variables should be determined.\nWhich variables in the data set are categorical?","12e160da":"# 3. EXPLORATORY DATA ANALYSIS ON CATEGORICAL DATA","fe8760aa":"there is no multicollinearity among the independent variables","31e74000":"Among the purposes, vacation and educational purposes constitute the most risky credit group.","8f1ded76":"The pairplot is visualized by using the seaborn library. Each variable has been compared with another variable.","8b541951":"**6.1. Missing Values\n1. Checking  missing value","2d0c5605":"For outlier treatment, the interquartile range (IQR)  method are used to detect outliers.  This is done in \nfollowing steps:First, calculate IQR value for the data; Second, multiply IQR by 1.5 ; Third, add 1.5 x (IQR) to \nthe third quartile; Fourth  subtract 1.5 x (IQR) from the first quartile.","b9f75179":"How many numeric variables are in the data set?","6086b5d9":"# 3. UNDERSTANDING THE DATA-SET","1d26c54d":"# 1. IMPORT SOME NECESSARY LIBRARIES","409c0c6f":"**Drop Feature**","63915f68":"The suppression approach can be a good method if we are not sure that the outlier observations are outliers or\n if we want to consider the outliers in our data.","eec687d2":"**The description of  variables in this data as follows:\n\n**Dependent Variable\n* Risk : Risk (Good, Bad Risk)\n\n**Independent Variable\n* Age: age in years (numerical)\n* Sex: female,male (qualitative)\n* Housing : rent, own, and free (qualitative)\n* Job : unemployed\/ unskilled - non-resident, unskilled - resident, skilled employee \/ official,and management\/ self-employed\/highly qualified employee\/ officer (qualitative)\n* Saving accounts: little, moderate, quite rich, and rich (qualitative)\n* Checking account: little, moderate, and rich (qualitative)\n* Credit amount: Loan Amount(DM)(numerical)\n* Duration: Duration in month (numerical)\n* Purpose: car, furniture\/equipment, radio\/TV, domestic appliances, repairs, education, business, and vacation\/others (qualitative)","0e157d9a":"After an imputation of missing values, the values of Saving accounts variable follows as;","4f78af52":"This dataset  is obtained from from the UCI Repository of Machine Learning Databases is public available at\nhttps:\/\/archive.ics.uci.edu\/ml\/datasets\/statlog+(german+credit+data). The German credit dataset consists of 1000 loan \napplications. This dataset is classified as good credit risks (300 samples)  and bad credit risk (700 samples).  That is,\nthe sample size is 1000.  In this dataset,there is one dependent variable (Risk) and nine independent or predictor \nvariables ('Age', 'Sex', 'Job', 'Housing', 'Saving accounts','Checking account', 'Credit amount', 'Duration', 'Purpose').","54cb9505":"# Risk","db80b2b1":"# 2. Load Data","68b05ee9":"# **Introduction**"}}