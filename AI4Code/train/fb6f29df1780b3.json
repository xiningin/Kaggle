{"cell_type":{"e5cab423":"code","9910c32c":"code","521fc86f":"code","cf3c19c1":"code","fbca63d7":"code","fb8960c4":"code","5acf222e":"code","a61bdb31":"code","75885128":"code","cdb8903f":"code","b17510d4":"code","9cc73ff5":"markdown","0f8ea2a0":"markdown","4d9743a5":"markdown"},"source":{"e5cab423":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport keras\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","9910c32c":"IMG_WIDTH  = 96\nIMG_HEIGHT = 96\nIMG_CHANNELS = 1\n\nBATCH_SIZE = 128\nEPOCHS = 5","521fc86f":"df = pd.read_csv('..\/input\/facial-keypoints-detection\/training.zip')\nimages = df.pop(\"Image\")\ny = df[[\"nose_tip_x\", \"nose_tip_y\"]].values\nprint(df.shape)\ndf.head()","cf3c19c1":"images = np.array([[float(pixel) for pixel in image.split()]  for image in images])\nimages = images.reshape(-1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)","fbca63d7":"fig, ax = plt.subplots(3, 2, figsize=(12, 12))\nfor i in range(3):\n    for j in range(2):\n        idx = np.random.randint(len(images))\n        ax[i][j].imshow(images[idx], cmap=\"gray\")\n        ax[i][j].scatter(y[idx][0], y[idx][1], color=\"r\", marker=\"x\")\nfig.show()","fb8960c4":"images = images \/ 255.0\ny = y \/ 96.0","5acf222e":"model = keras.Sequential()\nmodel.add(keras.layers.Input(images.shape[1:]))\nmodel.add(keras.layers.Conv2D(filters=20, kernel_size=(3,3), strides=(2, 2), activation=\"relu\"))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Dropout(0.2))\nmodel.add(keras.layers.Conv2D(filters=40, kernel_size=3, strides=2, activation=\"relu\"))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Dropout(0.2))\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(2))\nmodel.add(keras.layers.Activation(\"sigmoid\"))\n\nmodel.compile(loss=\"mse\", \n              optimizer=keras.optimizers.Adam(1e-3)) # no accuracy metric\n\nmodel.summary()","a61bdb31":"model.fit(images, y, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.15)","75885128":"test_df = pd.read_csv('..\/input\/facial-keypoints-detection\/test.zip')\ntest_images = test_df.pop(\"Image\")\ntest_images = np.array([[float(pixel) for pixel in image.split()]  for image in test_images])\ntest_images = test_images.reshape(-1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)","cdb8903f":"test_preds = model.predict(test_images \/ 255.0) * 96.0","b17510d4":"fig, ax = plt.subplots(3, 2, figsize=(12, 12))\nfor i in range(3):\n    for j in range(2):\n        idx = np.random.randint(len(test_images))\n        ax[i][j].imshow(test_images[idx], cmap=\"gray\")\n        ax[i][j].scatter(test_preds[idx][0], test_preds[idx][1], color=\"r\", marker=\"x\")\nfig.show()","9cc73ff5":"## Testing","0f8ea2a0":"## Model\nNote how I use the sigmoid activation even though it's a regression problem. Try doing it without it to see what happens.","4d9743a5":"Preprocess the data:"}}