{"cell_type":{"2b22189f":"code","7169e40c":"code","4cae5018":"code","bea075db":"code","70e6111b":"code","0b83542c":"code","03c92cd4":"code","1bd1c782":"code","4d0f5c1b":"code","c898632a":"code","e6b5487f":"code","81773e04":"code","6629b63c":"code","497da4b6":"code","55fc3ad5":"code","0f20ab18":"code","824cc837":"code","cc624853":"code","48d7a363":"code","12c045a8":"code","f2ee7ee0":"code","27a1cfc5":"code","1ce95d23":"code","01e7b7fd":"code","fe870f4d":"code","aba4cfc7":"markdown","a79b388d":"markdown","7ffc09cc":"markdown","1e1d425c":"markdown","9dee57d3":"markdown"},"source":{"2b22189f":"# # import the modules we'll need\n# from IPython.display import HTML\n# import pandas as pd\n# import numpy as np\n# import base64\n\n# # function that takes in a dataframe and creates a text link to  \n# # download it (will only work for files < 2MB or so)\n# def create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n#     csv = df.to_csv()\n#     b64 = base64.b64encode(csv.encode())\n#     payload = b64.decode()\n#     html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n#     html = html.format(payload=payload,title=title,filename=filename)\n#     return HTML(html)","7169e40c":"import os\nprint(os.listdir(\"..\/working\"))","4cae5018":"import os\nprint(os.listdir('..'))","bea075db":"import numpy as np\nimport pandas as pd\nimport time\nfrom sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, roc_curve, make_scorer\nimport matplotlib.pyplot as plt\nimport scipy.sparse\nimport pickle","70e6111b":"tic = time.time()\nX_train_str = pd.read_csv(\"..\/input\/x_train.txt\", delimiter= \"\\r\\t\", header = None, names = ['comment'], dtype = str)\nX_train_str = np.squeeze(X_train_str.values)\ntoc = time.time()\nprint(toc-tic)","0b83542c":"tic = time.time()\nY_train_str = pd.read_csv('..\/input\/y_train.csv', header = 0, sep =',')['Probability'].values\ntoc = time.time()\nprint(toc-tic)","03c92cd4":"tic = time.time()\nX_test_str = pd.read_csv(\"..\/input\/x_test.txt\", delimiter= \"\\r\\t\", header = None, names = ['comment'], dtype = str)\nX_test_str = np.squeeze(X_test_str.values)\ntoc = time.time()\nprint(toc-tic)","1bd1c782":"# X_train_small = X_train_str[0:int(len(X_train_str)*0.8)].copy()\n# Y_train_small = Y_train_str[0:int(len(Y_train_str)*0.8)].copy()","4d0f5c1b":"text_clf2 = Pipeline([\n    ('tfidf', TfidfVectorizer()),\n    ('clf', LogisticRegression())\n])","c898632a":"text_clf3 = Pipeline([\n    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), max_features=800000, max_df=0.8, norm='l2', use_idf=True, sublinear_tf=True)),\n    ('clf', LogisticRegression(random_state=23, C=5))\n])","e6b5487f":"tic = time.time()\ntext_clf3.fit(X_train_str, Y_train_str)\ntoc = time.time()\nprint(toc-tic)","81773e04":"predicted_answ = text_clf3.predict_proba(X_test_str)\npredicted_answ = predicted_answ[:,1]","6629b63c":"predicted_answ = predicted_answ.reshape((len(predicted_answ),1))\nind = np.array(range(1,400001,1), dtype=int)\nind = ind.reshape((len(ind),1))\nkaggle_answ = np.hstack((ind, predicted_answ))\nkaggle_answ_pd = pd.DataFrame(kaggle_answ, columns=['Id', 'Probability'])\nkaggle_answ_pd['Id'] = kaggle_answ_pd['Id'].astype(int)\nkaggle_answ_pd","497da4b6":"# # create a random sample dataframe\n# df = kaggle_answ_pd\n\n# # create a link to download the dataframe\n# create_download_link(df)\n\n# # \u2193 \u2193 \u2193  Yay, download link! \u2193 \u2193 \u2193 ","55fc3ad5":"# my_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices})\n# # you could use any filename. We choose submission here\nkaggle_answ_pd.to_csv('kaggle02.csv', index=False)","0f20ab18":"# # Function for writing predictions to a file\n# def write_to_submission_file(predicted_labels, out_file,\n#                              target='Probability', index_label=\"Id\"):\n#     predicted_df = pd.DataFrame(predicted_answ,\n#                                 index = np.arange(1, predicted_answ.shape[0] + 1),\n#                                 columns=[target])\n#     predicted_df.to_csv(out_file, index_label=index_label)","824cc837":"# write_to_submission_file(predicted_answ, '___tututu.csv')","cc624853":"# parameters = {\n#     'tfidf__use_idf': [True],\n#     'tfidf__ngram_range': [(1, 2)],\n#     'tfidf__sublinear_tf': [True],\n# #     'tfidf__max_df': [0.7, 0.8, 0.9, 1.0],\n# #     'tfidf__min_df': [0.],\n#     'tfidf__norm': ['l2'],\n#     'tfidf__max_features': [170000],\n    \n# #     'clf__loss': ['squared_loss'],\n# #     'clf__penalty': ['l2'],\n# #     'clf__alpha': [1e-4],\n# #     'clf__max_iter': [5],\n#     'clf__random_state': [23],\n# #     'clf__tol': [None]\n# #     'clf__loss': ['squared_loss'],\n#     'clf__C': [5]\n# }\n\n# roc_score = make_scorer(roc_auc_score, needs_proba=True)\n# gs_clf = GridSearchCV(text_clf2, parameters, cv=2, scoring = roc_score, n_jobs=-1)","48d7a363":"# tic = time.time()\n# gs_clf = gs_clf.fit(X_train_small, Y_train_small)\n# toc = time.time()\n# print(toc-tic)","12c045a8":"# datafr = pd.DataFrame.from_dict(gs_clf.cv_results_).sort_values('rank_test_score')\n# datafr[datafr.columns[0:30]]","f2ee7ee0":"# datafr.columns","27a1cfc5":"# gs_clf.best_params_","1ce95d23":"# predicted_answ = gs_clf.best_estimator_.predict_proba(X_test_str)\n# predicted_answ = predicted_answ[:,1]","01e7b7fd":"# # Function for writing predictions to a file\n# def write_to_submission_file(predicted_labels, out_file,\n#                              target='Probability', index_label=\"Id\"):\n#     predicted_df = pd.DataFrame(predicted_answ,\n#                                 index = np.arange(1, predicted_answ.shape[0] + 1),\n#                                 columns=[target])\n#     predicted_df.to_csv(out_file, index_label=index_label)","fe870f4d":"# write_to_submission_file(predicted_answ, '\/content\/drive\/My Drive\/Colab Notebooks\/Sentiment_Analisys\/submission04.csv')","aba4cfc7":"# This is final answer - submission03","a79b388d":"### Small amount of data","7ffc09cc":"### Fitting dataset with text_clf3 - pipeline with parameters","1e1d425c":"### Finding parameters with GridSearchCV","9dee57d3":"### Make a pipelines"}}