{"cell_type":{"0eacb543":"code","f6db1bbc":"code","8c7e2bb8":"code","6d59c5fd":"code","9e054b8c":"code","6191eef1":"code","5588f72b":"code","de73ca97":"code","ad093e6f":"code","7b3318e0":"code","8f3973b9":"code","0ad4ace8":"code","8ba4cc8b":"code","534759f2":"markdown","375a687e":"markdown","032c1b31":"markdown","9cdc0d98":"markdown","e63de0e5":"markdown","5e8ddcd2":"markdown","0b81b80c":"markdown"},"source":{"0eacb543":"#!\/usr\/bin\/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Wed Feb 13 16:14:50 2019\n\n@author: shyam\n\"\"\"\n\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\nimport tensorflow as tf\nimport keras\nimport os\nimport cv2\n\nconfig = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \nsess = tf.Session(config=config) \nkeras.backend.set_session(sess)\n","f6db1bbc":"S=64\n\n#From Keras Documentation\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrainDatagen = ImageDataGenerator(\n                    rescale=1.\/255,\n                    shear_range=0.2,\n                    zoom_range=0.2,\n                    horizontal_flip=True)\n\ntestDatagen = ImageDataGenerator(rescale=1.\/255)\n\ntrainDataset = trainDatagen.flow_from_directory(\n        '..\/input\/training_set\/training_set',\n        target_size=(S, S),\n        batch_size=32,\n        class_mode='binary')\n\ntestDataset = testDatagen.flow_from_directory(\n        '..\/input\/test_set\/test_set',\n        target_size=(S, S),\n        batch_size=32,\n        class_mode='binary')","8c7e2bb8":"#Initializing CNN\nclassifier = Sequential()","6d59c5fd":"#Adding 1st Convolution Layer\nclassifier.add(Convolution2D(filters=32, kernel_size=(3,3), strides=(1,1), input_shape=(S,S,3), activation='relu', padding='same'))\n\n#Adding 1st MaxPooling Layer to reduce the size of feature map\nclassifier.add(MaxPooling2D(pool_size=(2,2), strides=(2,2) ))\n\n#Adding 1st BatchNormalization Layer for higher Learning Rate\nclassifier.add(BatchNormalization())\n\n#Adding 1st Dropout Layer to eliminate overfitting\n#classifier.add(Dropout(0.2))","9e054b8c":"#Adding 2nd Convolution Layer\nclassifier.add(Convolution2D(filters=16, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same'))\n\n#Adding 2nd MaxPooling Layer to reduce the size of feature map\nclassifier.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n\n#Adding 2nd BatchNormalization Layer for higher Learning Rate\nclassifier.add(BatchNormalization())\n\n#Adding 2nd Dropout Layer to eliminate overfitting\nclassifier.add(Dropout(0.2))","6191eef1":"\"\"\"\n#Adding 3rd Convolution Layer\nclassifier.add(Convolution2D(filters=32, kernel_size=(3,3), strides=(2,2), activation='relu', padding='same'))\n\n#Adding 3rd MaxPooling Layer to reduce the size of feature map\nclassifier.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n\n#Adding 3rd BatchNormalization Layer for higher Learning Rate\nclassifier.add(BatchNormalization())\n\n#Adding 3rd Dropout Layer to eliminate overfitting\n#classifier.add(Dropout(0.2))\n\"\"\"","5588f72b":"#Adding Flatten Layer to convert 2D matrix into an array\nclassifier.add(Flatten())","de73ca97":"#Adding Fully connected layer\nclassifier.add(Dense(units=32,activation='relu'))\n\n#Adding Output Layer\nclassifier.add(Dense(units=1,activation='sigmoid'))\n","ad093e6f":"print(classifier.summary())","7b3318e0":"#Compiling the CNN\nclassifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n#Fitting the CNN to images\nhistory = classifier.fit_generator(trainDataset,\n                         steps_per_epoch=8005,\n                         epochs=10,\n                         validation_data=testDataset,\n                         validation_steps=2000,\n                         verbose = 1)","8f3973b9":"from matplotlib import pyplot as plt\nplt.plot(history.history['acc'],'green',label='Accuracy')\nplt.plot(history.history['loss'],'red',label='Loss')\nplt.title('Training Accuracy & Loss')\nplt.xlabel('Epoch')\nplt.figure()\nplt.plot(history.history['val_acc'],'green',label='Accuracy')\nplt.plot(history.history['val_loss'],'red',label='Loss')\nplt.title('Validation Accuracy & Loss')\nplt.xlabel('Epoch')\nplt.figure()","0ad4ace8":"from matplotlib import pyplot as plt\n\ndirectory = os.listdir(\"..\/input\/test_set\/test_set\/cats\")\nprint(directory[10])\n\nimgCat = cv2.imread(\"..\/input\/test_set\/test_set\/cats\/\" + directory[10])\nplt.imshow(imgCat)\n\nimgCat = cv2.resize(imgCat, (S,S))\nimgCat = imgCat.reshape(1,S,S,3)\n\npred = classifier.predict(imgCat)\nprint(\"Probability that it is a Cat = \", \"%.2f\" % (1-pred))\n\n","8ba4cc8b":"directory = os.listdir(\"..\/input\/test_set\/test_set\/dogs\" )\nprint(directory[10])\n\nimgDog = cv2.imread(\"..\/input\/test_set\/test_set\/dogs\/\" + directory[10])\nplt.imshow(imgDog)\n\nimgDog = cv2.resize(imgDog, (S,S))\nimgDog = imgDog.reshape(1,S,S,3)\n\npred = classifier.predict(imgDog)\nprint(\"Probability that it is a Dog = \", \"%.2f\" % pred)","534759f2":"**Visualising Accuracy and Loss w.r.t. the Epochs**","375a687e":"**Compiling and Fitting the CNN to our Dataset**","032c1b31":"**Predicting Results for some Images**","9cdc0d98":"**Model Summary**","e63de0e5":"**Data Augmentation**","5e8ddcd2":"***CAT vs DOG Classification using Convolution Neural Networks***","0b81b80c":"**Building Convolution Neural Network**"}}