{"cell_type":{"859be974":"code","fc396563":"code","b3d0570e":"code","602beda2":"code","a3d80200":"code","07b6b86b":"code","c316dea9":"code","fc419995":"code","b67a3860":"code","9aa1112c":"code","e62484ec":"code","836d2985":"code","46cec7e2":"code","1ad3b7fb":"code","d105fae4":"code","e9d71221":"code","3cf45100":"code","620af4c4":"code","013255ba":"code","b2f6c4d5":"code","a7846c98":"code","25502aff":"code","e10f94f0":"code","e0c2e547":"code","927dbbca":"code","08e27d83":"code","b68b3879":"code","c29c30d1":"code","6356bed0":"code","93b02893":"code","0054556d":"code","55141c85":"code","b15098a0":"code","31519f77":"code","00177ca4":"code","148618ce":"code","49b1ac79":"code","49993978":"code","a1c92228":"code","6d6f7d65":"code","b5df8f3c":"code","b7ae4dbe":"code","cb8c01b4":"code","c8c4dcd4":"code","5188fb01":"code","bfab31ab":"code","d7c1c918":"code","48234e1b":"code","7992d547":"markdown","668f23b2":"markdown"},"source":{"859be974":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fc396563":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nimport cv2\nimport tensorflow as tf\n\nsns.set(style='white', context='notebook', palette='deep')","b3d0570e":"# Load the data\ntrain = pd.read_csv(\"\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/test.csv\")\ndf_train = pd.read_csv(\"\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/train.csv\")","602beda2":"df_train.head()","a3d80200":"Y_train = train[\"pneumonia\"]\n\n# Drop 'label' column\nX_train = train.drop(labels = [\"pneumonia\"],axis = 1) \n\n# free some space\ndel train \n\ng = sns.countplot(Y_train)\n\nY_train.value_counts()","07b6b86b":"#https:\/\/towardsdatascience.com\/complete-image-augmentation-in-opencv-31a6b02694f5\n\n#https:\/\/machinelearningmastery.com\/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks\/","c316dea9":"# example of horizontal shift image augmentation\nfrom numpy import expand_dims\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom matplotlib import pyplot\n# load the image\nimg = load_img('\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/1a4b8ecb-4eb9-49dd-af42-2c5801333ede.jpeg')\n# convert to numpy array\ndata = img_to_array(img)\n# expand dimension to one sample\nsamples = expand_dims(data, 0)\n# create image data augmentation generator\ndatagen = ImageDataGenerator(width_shift_range=[-200,200])\n# prepare iterator\nit = datagen.flow(samples, batch_size=1)\n# generate samples and plot\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# generate batch of images\n\tbatch = it.next()\n\t# convert to unsigned integers for viewing\n\timage = batch[0].astype('uint8')\n\t# plot raw pixel data\n\tpyplot.imshow(image)\n# show the figure\npyplot.show()","fc419995":"#Imagem com pneumonia\n#img = cv2.imread('\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/7c05f8d3-57d4-4e4d-8dcd-7ae57699708c.jpeg',0) ## classe =2\n\nimg = cv2.imread('\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/1a4b8ecb-4eb9-49dd-af42-2c5801333ede.jpeg',0) ## classe =2\n\n#(2136, 3216)\n\n#img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\nimg = cv2.resize(img, (224, 224))\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    #im = im.reshape(desired_size, desired_size , 1)\n    #im = cv2.addWeighted(im, 4, cv2.blur(im, ksize=(10,10)), -4, 128)\nimg = cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , 300\/10) ,-4 ,128) # the trick is to add this line\n#img = cv2.equalizeHist(img) \n\nprint(img.shape)\n\nplt.imshow(img)","b67a3860":"# example of vertical shift image augmentation\nfrom numpy import expand_dims\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom matplotlib import pyplot\n# load the image\nimg = load_img('\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/1a4b8ecb-4eb9-49dd-af42-2c5801333ede.jpeg')\n# convert to numpy array\ndata = img_to_array(img)\n# expand dimension to one sample\nsamples = expand_dims(data, 0)\n# create image data augmentation generator\ndatagen = ImageDataGenerator(height_shift_range=0.15)\n# prepare iterator\nit = datagen.flow(samples, batch_size=1)\n# generate samples and plot\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# generate batch of images\n\tbatch = it.next()\n\t# convert to unsigned integers for viewing\n\timage = batch[0].astype('uint8')\n\t# plot raw pixel data\n\tpyplot.imshow(image)\n# show the figure\npyplot.show()","9aa1112c":"# example of rotation image augmentation\nfrom numpy import expand_dims\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom matplotlib import pyplot\n# load the image\nimg = load_img('\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/1a4b8ecb-4eb9-49dd-af42-2c5801333ede.jpeg')\n# convert to numpy array\ndata = img_to_array(img)\n# expand dimension to one sample\nsamples = expand_dims(data, 0)\n# create image data augmentation generator\ndatagen = ImageDataGenerator(rotation_range=45)\n# prepare iterator\nit = datagen.flow(samples, batch_size=1)\n# generate samples and plot\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# generate batch of images\n\tbatch = it.next()\n\t# convert to unsigned integers for viewing\n\timage = batch[0].astype('uint8')\n\t# plot raw pixel data\n\tpyplot.imshow(image)\n# show the figure\npyplot.show()","e62484ec":"#Shear shear_range\n# example of Shear shear_range image augmentation\nfrom numpy import expand_dims\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom matplotlib import pyplot\n# load the image\nimg = load_img('\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/1a4b8ecb-4eb9-49dd-af42-2c5801333ede.jpeg')\n# convert to numpy array\ndata = img_to_array(img)\n# expand dimension to one sample\nsamples = expand_dims(data, 0)\n# create image data augmentation generator\ndatagen = ImageDataGenerator(shear_range=20)\n# prepare iterator\nit = datagen.flow(samples, batch_size=1)\n# generate samples and plot\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# generate batch of images\n\tbatch = it.next()\n\t# convert to unsigned integers for viewing\n\timage = batch[0].astype('uint8')\n\t# plot raw pixel data\n\tpyplot.imshow(image)\n# show the figure\npyplot.show()","836d2985":"#https:\/\/minerandodados.com.br\/lidando-com-classes-desbalanceadas-machine-learning\/","46cec7e2":"# Check the data\nX_train.isnull().any().describe()","1ad3b7fb":"test.isnull().any().describe()","d105fae4":"print(X_train)","e9d71221":"os.mkdir('\/kaggle\/working\/pneum-preproc\/')\nos.mkdir('\/kaggle\/working\/pneum-preproc\/test')\nos.mkdir('\/kaggle\/working\/pneum-preproc\/train')\nos.listdir('\/kaggle\/working\/pneum-preproc\/')","3cf45100":"def preprocess_image(image_path):\n      image = cv2.imread(image_path)\n      image = cv2.resize(image, (224,224))\n      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n      #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n      image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 300\/10) ,-4 ,128) # the trick is to add this line\n      #image = cv2.equalizeHist(image) \n      # Normalization\n      image = image.astype(np.float32)\/255.\n      return image","620af4c4":"from tqdm import tqdm\n\ndesired_size=224\ndepth = 3\n\nN = df_train.shape[0]\nX_train = np.empty((N, desired_size, desired_size, depth), dtype=np.uint8)\n#X_train = np.empty((N, desired_size, desired_size), dtype=np.uint8)\n\nfor i, image_id in enumerate(tqdm(df_train['fileName'])):\n    X_train[i, :, :, :] = preprocess_image(\n        f'\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/{image_id}'\n    )\n    #Save images preprocessadas\n    cv2.imwrite('\/kaggle\/working\/pneum-preproc\/train\/' + image_id ,X_train[i])","013255ba":"# pre processando dados teste\nfrom tqdm import tqdm\n\ndesired_size=224\ndepth = 3\n\nN = test.shape[0]\nX_test = np.empty((N, desired_size, desired_size, depth), dtype=np.uint8)\n\nfor i, image_id in enumerate(tqdm(test['fileName'])):\n    X_test[i, :, :, :] = preprocess_image(\n        f'\/kaggle\/input\/i2a2-brasil-pneumonia-classification\/images\/{image_id}'\n    )\n    #Save images preprocessadas\n    cv2.imwrite('\/kaggle\/working\/pneum-preproc\/test\/' + image_id ,X_test[i])","b2f6c4d5":"y_train = pd.get_dummies(df_train['pneumonia']).values","a7846c98":"print(y_train)","25502aff":"# Split the train and the validation set for the fitting\n# stratify = para classes desbalanceadas\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train,test_size=0.3,random_state = 1, stratify=Y_train)","e10f94f0":"from tensorflow.keras.optimizers import Adam,SGD\nfrom tensorflow.keras.layers import GlobalMaxPooling2D, Dense,Flatten,MaxPooling2D,GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\nfrom tensorflow.keras import Sequential\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.xception import preprocess_input\nfrom keras.applications.resnet50 import ResNet50\nfrom tensorflow.python.keras.layers import Flatten, Dense, Conv2D, Dropout, BatchNormalization\nimport datetime, os\n","e0c2e547":"# importando a Xception pr\u00e9-treinada\nmodel_0 = tf.keras.applications.resnet50.ResNet50(input_shape = (224, 224, 3),\n                                           include_top = False,\n                                           weights = 'imagenet')","927dbbca":"#https:\/\/www.kaggle.com\/madz2000\/pneumonia-detection-using-cnn-92-6-accuracy","08e27d83":"model_0.trainable = True\nmodel_2 = Sequential()\nmodel_2.add(model_0)\nmodel_2.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\nmodel_2.add(MaxPooling2D((2, 2)))\n\n\nmodel_2.add(Flatten())\nmodel_2.add(Dense(100))\nmodel_2.add(Dense(1, activation = 'sigmoid'))\n\nmodel_2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n\n# visualizando o sumario da rede\nmodel_2.summary()","b68b3879":"logs_dir = '.\\logs'","c29c30d1":"# early stopping - efetuada a parada do treinamento quando o value_loss n\u00e3o obtem mais melhorias\nearly_stopping = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience= 10,\n                              verbose=0, mode='auto')\n\n# model checkpoint - armazena o melhor modelo ou peso treinado para ser usado no teste final\n# https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/callbacks\/ModelCheckpoint\nmc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n\n#tensorboard callback -->> n\u00e3o entendo bem de como fucniona o tensor board mas foi necessario manter aqui no c\u00f3digo para mantero o callback\n# \nlogdir = os.path.join(logs_dir,datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\ntensorboard_callback = TensorBoard(logdir, histogram_freq = 1)\n\n#reduce lr on plateau - aplica a redu\u00e7\u00e3o da taxa de aprendizado quando a metrica para de ser melhorada, \u00e9 aplicado a cada 10 epocas\n# https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/callbacks\/ReduceLROnPlateau\nred_lr_plat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n\n# https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/callbacks\/ModelCheckpoint\ncallbacks = [tensorboard_callback,early_stopping,mc, red_lr_plat]","6356bed0":"# With data augmentation\n\ndatagen = ImageDataGenerator(\n            width_shift_range=[-200,200],\n            height_shift_range=0.15,\n            rotation_range=45,\n            shear_range=20)  # randomly flip images\n\n\ndatagen.fit(X_train)","93b02893":"# prepare an iterators to scale images\ntrain_iterator = datagen.flow(X_train,Y_train, batch_size=32)\nval_iterator = datagen.flow(X_val,Y_val,batch_size=32)\nprint('Batches train=%d, test=%d' % (len(train_iterator), len(val_iterator)))","0054556d":"X_val.shape","55141c85":"X_test.shape","b15098a0":"test.shape","31519f77":"#fit model\nhistory = model_2.fit_generator(train_iterator,\n                            steps_per_epoch = 20,\n                            validation_data = val_iterator,\n                            validation_steps = 1,\n                            epochs = 10,\n                            callbacks=callbacks)\n\n# mostrando o treinamento\nhistory","00177ca4":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","148618ce":"# Look at confusion matrix \n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model_2.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(2)) ","49b1ac79":"# Display some error results \n\n# Errors are difference between predicted labels and true labels\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","49993978":"test.shape","a1c92228":"print(X_test)","6d6f7d65":"test.head()","b5df8f3c":"X_test.shape","b7ae4dbe":"# predict results\nresults = model_2.predict(X_test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"pneumonia\")","cb8c01b4":"print(results)","c8c4dcd4":"filenames=test['fileName']","5188fb01":"filenames.head()","bfab31ab":"#submission=pd.concat({\"fileName\":filenames,\n#                      \"pneumonia\": results})","d7c1c918":"submission=pd.DataFrame({\"fileName\":filenames,\n                      \"pneumonia\": results})","48234e1b":"results.to_csv(\"submission_v7.csv\",index=False)","7992d547":"https:\/\/minerandodados.com.br\/lidando-com-classes-desbalanceadas-machine-learning\/","668f23b2":"Technique Setting ImageDataGenerator:\n\nRotation 45\n\nVertical Shift 0.2\n\nHorizontal Shift 0.15\n\nShear 16"}}