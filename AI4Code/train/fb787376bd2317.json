{"cell_type":{"788ef26e":"code","e6300f59":"code","ec011d0e":"code","15284d71":"code","16929e28":"code","3085498a":"code","a7b51797":"code","48dc82a9":"code","93138cc0":"code","700111b5":"code","ed58b6e3":"markdown"},"source":{"788ef26e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e6300f59":"pip install d2l","ec011d0e":"%matplotlib inline\nimport torch\nfrom d2l import torch as d2l","15284d71":"x = torch.arange(-8.0, 8.0, 0.1, requires_grad=True)\ny = torch.relu(x)\nd2l.plot(x.detach(), y.detach(), 'x', 'relu(x)', figsize=(5, 2.5))","16929e28":"y.backward(torch.ones_like(x), retain_graph=True)\nd2l.plot(x.detach(), x.grad, 'x', 'grad of relu', figsize=(5, 2.5))","3085498a":"y = torch.sigmoid(x)\nd2l.plot(x.detach(), y.detach(), 'x', 'sigmoid(x)', figsize=(5, 2.5))","a7b51797":"x.grad.data.zero_()\ny.backward(torch.ones_like(x), retain_graph=True)\nd2l.plot(x.detach(), x.grad, 'x', 'grad of sigmoid', figsize=(5, 2.5))","48dc82a9":"y = torch.tanh(x)\nd2l.plot(x.detach(), y.detach(), 'x', 'tanh(x)', figsize=(5, 2.5))","93138cc0":"# Clear out previous gradients.\nx.grad.data.zero_()\ny.backward(torch.ones_like(x), retain_graph=True)\nd2l.plot(x.detach(), x.grad, 'x', 'grad of tanh', figsize=(5, 2.5))","700111b5":"#pip install d2l\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\nbatch_size = 256\ntrain_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\nnum_inputs, num_outputs, num_hiddens = 784, 10, 256\n\nW1 = nn.Parameter(\n    torch.randn(num_inputs, num_hiddens, requires_grad=True) * 0.01)\nb1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))\nW2 = nn.Parameter(\n    torch.randn(num_hiddens, num_outputs, requires_grad=True) * 0.01)\nb2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))\n\nparams = [W1, b1, W2, b2]\n#def sigmoid(X):\n#    a = torch.zeros_like(X)\n#    return 1\/ (1 + torch.exp(-X))\ndef relu(X):\n    a = torch.zeros_like(X)\n    return torch.max(X,a)\ndef net(X):\n    X = X.reshape((-1, num_inputs))\n    H = relu(X @ W1 + b1)  # Here '@' stands for matrix multiplication\n    return (H @ W2 + b2)\nloss = nn.CrossEntropyLoss()\nnum_epochs, lr = 10, 0.1\nupdater = torch.optim.SGD(params, lr=lr)\nd2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)\nd2l.predict_ch3(net, test_iter)","ed58b6e3":"![](https:\/\/d2l.ai\/_images\/mlp.svg)"}}