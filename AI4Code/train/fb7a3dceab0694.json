{"cell_type":{"ab32606b":"code","53476589":"code","e12d6c9f":"code","75550254":"code","d2d2fef7":"code","0c0df443":"code","7442fcd0":"code","69808fca":"code","86873e2f":"code","7753e6e0":"code","0a68e6a5":"code","d4d9dd7b":"code","7f3b1182":"code","315e0a84":"code","79c65eac":"code","50186f4a":"markdown","338f6a28":"markdown","d3b5b99a":"markdown","59112b2d":"markdown","b0600692":"markdown","1b7335e8":"markdown","9df8e504":"markdown","59dcdf24":"markdown","762e84a3":"markdown","fe77f048":"markdown"},"source":{"ab32606b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","53476589":"# Loading Data\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\ny_train = train[\"label\"]\nx_train = train.drop(labels = [\"label\"], axis=1)\n\ndel train\n\n#g = sns.countplot(y_train)\n#y_train.value_counts()","e12d6c9f":"# Normalizing Data\nx_train = x_train \/ 255.0\ntest = test \/ 255.0\n","75550254":"#Reshaping images in 3 dimensions\nx_train = x_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\n","d2d2fef7":"# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nfrom keras.utils.np_utils import to_categorical\n\ny_train = to_categorical(y_train, num_classes = 10)\n","0c0df443":"#Spliting data into train and validation set\nfrom sklearn.model_selection import train_test_split\n\nrandom_seed = 2\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state=random_seed)\n#g = plt.imshow(x_train[5][:,:,0])","7442fcd0":"#CNN Model\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.layers.normalization import BatchNormalization\n\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32,kernel_size=3,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32,kernel_size=5,strides=2,padding='same',activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(64,kernel_size=3,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,kernel_size=3,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,kernel_size=5,strides=2,padding='same',activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","69808fca":"epochs = 60 # but actually it should be more than 1\nbatch_size = 86\n","86873e2f":"#Data augmentation\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndatageneration = ImageDataGenerator(\n        featurewise_center=False,  \n        samplewise_center=False,  \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False, \n        zca_whitening=False,  \n        rotation_range=10, \n        zoom_range = 0.1,\n        width_shift_range=0.1, \n        height_shift_range=0.1,  \n        horizontal_flip=False,  \n        vertical_flip=False)  \n\ndatageneration.fit(x_train)\n","7753e6e0":"#fitting the model\nhistory = model.fit_generator(datageneration.flow(x_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (x_val,y_val),\n                              verbose = 2, steps_per_epoch=x_train.shape[0] \/\/ batch_size)\n","0a68e6a5":"# Confusion matrix \nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\ny_pred = model.predict(x_val)\n# Convert predictions classes to one hot vectors \ny_pred_classes = np.argmax(y_pred,axis = 1) \n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_true, y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","d4d9dd7b":"model.save(\"dig_rec.model\")","7f3b1182":"from keras.models import model_from_json\n\n# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")","315e0a84":"# predict results\nresults = model.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\n","79c65eac":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","50186f4a":"# Predicting the test set","338f6a28":"# Label encoding\n### We have 10 labels, 0,1,...,9. They should be encode in one hot vector, for exp : 7-->> [0,0,0,0,0,0,0,1,0,0]","d3b5b99a":"# Normalization\n### to change the grayscale range from [0..255] to [0..1]","59112b2d":"# Data augmentation\n### With these method we make more training images from our train data set using some image preprocessing techniks.","b0600692":"# Train and define CNN model\n### CNN layers and kernels and those activation functions and other stuffs could be a very long story, I think, easy google \"CNN model in keras\" or some thing else :) ","1b7335e8":"# **Brief but Useful ;)**","9df8e504":"# Loading the Data\n### Frist load the data using pandas Lib in two train and test sets.\n","59dcdf24":"# Reshape\n### The images are in vector form with 784 elements, now we reshapeinto 28x28x1 matrices.","762e84a3":"# Confusion Matrix\n### a visual represetation of model drawbacks.","fe77f048":"# Spliting data\n### in order to have a better training and more training accuracy, spliting data to train and validation set is good idea. "}}