{"cell_type":{"6b84e102":"code","5e53f78b":"code","c07095b7":"code","a9bf23ac":"code","1a3d6856":"code","5901bc9c":"code","8a6b48a6":"code","3b80aa0c":"code","f2ff734d":"code","60c8ecb7":"code","92cda560":"code","005f1c7f":"code","0b234717":"code","21911827":"code","9fc5403d":"code","e2b153a6":"code","0c18bb2c":"code","0e263fa0":"code","531318f5":"code","b6382198":"code","70bf3b72":"code","e49a753f":"code","3edaeb2d":"code","c16c2a0e":"code","dba01a6c":"code","7f5d6ced":"code","d6b06388":"code","7cb639b7":"code","29af85fd":"code","4ff30650":"code","b226f7dc":"code","450fb6bc":"code","807c5cd3":"code","043716b6":"code","f713c2be":"code","00e85498":"code","e2ff8d2a":"markdown","12e2692d":"markdown","906a9100":"markdown","21c8156a":"markdown","f17f93f1":"markdown","456d4f11":"markdown","7f1d8439":"markdown","ae7c74ac":"markdown","83799075":"markdown","ec844f21":"markdown","e1667909":"markdown","d6cddc44":"markdown","c36299a7":"markdown","320a5697":"markdown"},"source":{"6b84e102":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\n%matplotlib inline \nimport matplotlib as mlp\nimport matplotlib.pyplot as plt\nimport os\n\nprint(os.listdir(\"..\/input\"))\ndata = pd.read_csv('..\/input\/WA_Fn-UseC_-Telco-Customer-Churn.csv')","5e53f78b":"data.head()","c07095b7":"data.dtypes","a9bf23ac":"data.isnull().values.any()","1a3d6856":"def to_float(x):\n    try:\n        return np.float(x)\n    except:\n        return np.nan\n\ndata['TotalCharges'] = data['TotalCharges'].apply(to_float)\ndata['SeniorCitizen'] = data['SeniorCitizen'].astype(object)\n\ndata.dtypes","5901bc9c":"data['Churn'].value_counts()","8a6b48a6":"y_True = data['Churn'][data['Churn'] == 'Yes']\nprint(str( (y_True.shape[0] \/ float(data['Churn'].shape[0])) * 100 ) + \"% of churn\")","3b80aa0c":"data.hist(bins=10, figsize=(12,7))\nplt.show()","f2ff734d":"data.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)\nplt.show()","60c8ecb7":"data.groupby('Churn').describe()","92cda560":"#comparing characteristics of those who churned and those who didn't\ndata.boxplot(column='TotalCharges', by='Churn')\ndata.boxplot(column='MonthlyCharges', by='Churn')\ndata.boxplot(column='tenure', by='Churn')","005f1c7f":"old_customers = data[data['tenure'] > 65]\nold_customers.head()","0b234717":"old_customers['Churn'].value_counts()","21911827":"churned_customers = data[data['Churn'] == 'Yes']\nchurned_customers.hist()","9fc5403d":"churned_customers.boxplot(column='TotalCharges', by='Churn')\nchurned_customers.boxplot(column='MonthlyCharges', by='Churn')\nchurned_customers.boxplot(column='tenure', by='Churn')","e2b153a6":"data.corr()","0c18bb2c":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn_pandas import DataFrameMapper\n\ndef encode_categorical_cols(dataframe):\n    categorical_columns = dataframe.dtypes.pipe(lambda x: x[x == 'object'])\n\n    mapping = []\n    mapping += ((col, LabelEncoder()) for col in categorical_columns.index if col != 'customerID')\n    mapping += ((col, None) for col in dataframe.dtypes.index if col not in categorical_columns.index or col == 'customerID')\n        \n    mapper = DataFrameMapper(mapping, df_out=True)\n    \n    stages = []\n    stages += [(\"pre_processing_mapper\", mapper)]\n\n    pipeline = Pipeline(stages)\n    transformed_df = pipeline.fit_transform(dataframe)\n    return transformed_df\n\nencoded_data = encode_categorical_cols(data)\nencoded_data.dtypes","0e263fa0":"encoded_data.head()","531318f5":"encoded_data.corr()","b6382198":"correlations = encoded_data.corr()\n# plot correlation matrix\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(correlations, vmin=-1, vmax=1)\nfig.colorbar(cax)\nticks = np.arange(0,20,1)\nax.set_xticks(ticks)\nax.set_yticks(ticks)\nax.set_xticklabels(encoded_data.columns)\nax.set_yticklabels(encoded_data.columns)\nplt.xticks(rotation=90)\nplt.show()","70bf3b72":"encoded_data.hist(bins=10, figsize=(12,7))","e49a753f":"data['TechSupport'].value_counts()","3edaeb2d":"encoded_data = encoded_data.loc[:,('MonthlyCharges', 'TotalCharges', 'tenure', 'Contract', 'Churn')]","c16c2a0e":"encoded_data[['TotalCharges\/tenure']] = encoded_data[['TotalCharges']].div(encoded_data.tenure, axis=0) \nencoded_data.head()","dba01a6c":"encoded_data.loc[encoded_data['MonthlyCharges']-encoded_data['TotalCharges\/tenure'] > encoded_data['TotalCharges']*0.10]","7f5d6ced":"encoded_data['ChargedMore'] = np.where(encoded_data['MonthlyCharges']-encoded_data['TotalCharges\/tenure'] > encoded_data['TotalCharges']*0.10, 1, 0)\nencoded_data.head()","d6b06388":"# Binning numerical columns\nencoded_data['CatTenure'] = pd.qcut(encoded_data.tenure, q=3, labels=False )\nencoded_data['CatMonthlyCharges']= pd.qcut(encoded_data.MonthlyCharges, q=3, labels=False)\nencoded_data.head()","7cb639b7":"final_df = encoded_data.loc[:,('Contract', 'Churn', 'CatTenure', 'CatMonthlyCharges', 'ChargedMore')]\nfinal_df.head()","29af85fd":"final_df.corr()","4ff30650":"from sklearn.model_selection import *\n\ntarget = final_df['Churn']\ndataset = final_df.loc[:,('Contract', 'CatTenure', 'CatMonthlyCharges')]\n\ntrain_data, test_data, train_target, expected = train_test_split(dataset, target, test_size=0.3, stratify=target)","b226f7dc":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import *\n\nrandom_forest = RandomForestClassifier(n_estimators=10)\nmodel = random_forest.fit(train_data, train_target)\npredicted = model.predict(test_data)\n\nprint('Random Forest accuracy: {:.3f}'.format(accuracy_score(expected, predicted)))\nprint('Random Forest ROC accuracy: {:.3f}'.format(roc_auc_score(expected, predicted)))\nprint('Random Forest F1 score: {:.3f}'.format(f1_score(expected, predicted, average='weighted')))\nprint('Confusion matrix')\nprint(confusion_matrix(expected, predicted))","450fb6bc":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nlogreg = LogisticRegression()\nlogreg.fit(train_data, train_target)\npredicted = logreg.predict(test_data)\nprint('Logistic regression accuracy: {:.3f}'.format(accuracy_score(expected, predicted)))\nprint('Logistic regression ROC accuracy: {:.3f}'.format(roc_auc_score(expected, predicted)))\nprint ('Logistic regression F1 score: {:.3f}'.format(f1_score(expected, predicted, average='weighted')))\nprint('Confusion matrix')\nprint(confusion_matrix(expected, predicted))","807c5cd3":"from sklearn.svm import SVC\nsvc = SVC()\nsvc.fit(train_data, train_target)\npredicted = svc.predict(test_data)\nprint('Support vector machine accuracy: {:.3f}'.format(accuracy_score(expected, predicted)))\nprint('Support vector machine ROC accuracy: {:.3f}'.format(roc_auc_score(expected, predicted)))\nprint ('Support vector machine F1 score: {:.3f}'.format(f1_score(expected, predicted, average='weighted')))\nprint('Confusion matrix')\nprint(confusion_matrix(expected, predicted))","043716b6":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=25)\nknn.fit(train_data, train_target)\npredicted = knn.predict(test_data)\nprint('KNN accuracy: {:.3f}'.format(accuracy_score(expected, predicted)))\nprint('KNN ROC accuracy: {:.3f}'.format(roc_auc_score(expected, predicted)))\nprint ('KNN F1 score: {:.3f}'.format(f1_score(expected, predicted, average='weighted')))\nprint('Confusion matrix')\nprint(confusion_matrix(expected, predicted))","f713c2be":"random_forest = RandomForestClassifier()\n\nn_estimators = [20, 50, 100]\nmax_features = ['auto', 'sqrt']\nmax_depth = [10, 20, None]\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\nclass_weight = [None, 'balanced']\n\nparameters = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap, 'class_weight' : class_weight}\n\nclf = GridSearchCV(random_forest, param_grid = parameters, cv = 3, n_jobs = -1)\nmodel = clf.fit(train_data, train_target)\nprint(model.best_params_)\n#{'bootstrap': True, 'min_samples_leaf': 1, 'n_estimators': 20, 'min_samples_split': 2, 'max_features': 'auto', 'max_depth': 10, 'class_weight': None}\nprint(model.best_estimator_)\npredicted = model.predict(test_data)\n\nprint('Random Forest accuracy: {:.3f}'.format(accuracy_score(expected, predicted)))\nprint('Random Forest ROC accuracy: {:.3f}'.format(roc_auc_score(expected, predicted)))\nprint ('Random Forest F1 score: {:.3f}'.format(f1_score(expected, predicted, average='weighted')))\nprint('Confusion matrix')\nprint(confusion_matrix(expected, predicted))","00e85498":"C_param_range = [0.001,0.01,0.1,1,10,100]\npenal = ['l1', 'l2']\n\nlogreg_params = {'C': C_param_range, 'penalty' : penal, 'class_weight' : class_weight}\nlogreg = GridSearchCV(LogisticRegression(), param_grid = logreg_params, cv = 10, n_jobs = -1)\nlogreg_model = logreg.fit(train_data, train_target)\nprint(logreg_model.best_params_)\nprint(logreg_model.best_estimator_)\npredicted = logreg_model.predict(test_data)\n\nprint('Logistic regression accuracy: {:.3f}'.format(accuracy_score(expected, predicted)))\nprint('Logistic regression ROC accuracy: {:.3f}'.format(roc_auc_score(expected, predicted)))\nprint ('Logistic regression F1 score: {:.3f}'.format(f1_score(expected, predicted, average='weighted')))\nprint('Confusion matrix')\nprint(confusion_matrix(expected, predicted))","e2ff8d2a":"#### Checking for null values","12e2692d":"### Profile of customers who churned","906a9100":"#### Random Forest","21c8156a":"### Using KFoldCV with hyperparameter tuning","f17f93f1":"### Simple univariate analysis","456d4f11":"### Checking the dataset","7f1d8439":"#### Logistic Regression","ae7c74ac":"### Check the relationship between variables","83799075":"#### Drop unnecessary columns","ec844f21":"#### Using stratified sampling","e1667909":"TotalCharges has a fairly positive correlation with tenure","d6cddc44":"### Checking class distribution","c36299a7":"#### Convert TotalCharges to float and SeniorCitizen to object","320a5697":"What makes old customers churn? Check the outliers from tenure"}}