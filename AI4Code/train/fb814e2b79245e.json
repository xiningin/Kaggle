{"cell_type":{"8f08e468":"code","1526ea3e":"code","532bf1cc":"code","0c1efade":"code","a5c927f7":"code","982c6265":"code","1a20bf33":"code","2ed58b3d":"code","46ebab93":"code","450a3295":"code","1c038bb7":"code","1c1839cb":"code","6dbb5ad2":"code","591eb7e7":"code","9377a4de":"code","93f5da3c":"code","f61a6fd4":"markdown","587e3fd7":"markdown","954cc23d":"markdown","ddb13939":"markdown","49ece744":"markdown","52c5d304":"markdown","ba733c1c":"markdown","a97cb23f":"markdown","0e5906f4":"markdown","e80798a4":"markdown","2ad57027":"markdown"},"source":{"8f08e468":"# \u30d1\u30c3\u30b1\u30fc\u30b8\u306eimport\nimport os\nimport numpy as np\nimport json\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport random\n\n\nfrom tqdm import tqdm\n\nimport torch\nimport torchvision\nimport torch.utils.data as data\nimport torch.nn as nn\nimport torch.optim as optim\nimport pandas as pd\nfrom torchvision import models, transforms\nfrom sklearn.model_selection import train_test_split ","1526ea3e":"# PyTorch\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u78ba\u8a8d\nprint(\"PyTorch Version: \",torch.__version__)\nprint(\"Torchvision Version: \",torchvision.__version__)","532bf1cc":"# \u4e71\u6570\u306e\u30b7\u30fc\u30c9\u3092\u8a2d\u5b9a\ntorch.manual_seed(1234)\nnp.random.seed(1234)\nrandom.seed(1234)","0c1efade":"\nresize = 224\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\n\ntrain_transforms = transforms.Compose([\n                transforms.RandomResizedCrop(\n                    resize, scale=(0.5, 1.0)),  # \u30c7\u30fc\u30bf\u30aa\u30fc\u30ae\u30e5\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\n                transforms.RandomHorizontalFlip(),  # \u30c7\u30fc\u30bf\u30aa\u30fc\u30ae\u30e5\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\n                transforms.ToTensor(),  # \u30c6\u30f3\u30bd\u30eb\u306b\u5909\u63db\n                transforms.Normalize(mean, std)  # \u6a19\u6e96\u5316\n    ])\nval_transforms = transforms.Compose([\n                transforms.Resize(resize),  # \u30ea\u30b5\u30a4\u30ba\n                transforms.CenterCrop(resize),  # \u753b\u50cf\u4e2d\u592e\u3092resize\u00d7resize\u3067\u5207\u308a\u53d6\u308a\n                transforms.ToTensor(),  # \u30c6\u30f3\u30bd\u30eb\u306b\u5909\u63db\n                transforms.Normalize(mean, std)  # \u6a19\u6e96\u5316\n    ])","a5c927f7":"# \u753b\u50cf\u524d\u51e6\u7406\u306e\u52d5\u4f5c\u3092\u78ba\u8a8d\n\n# 1. \u753b\u50cf\u8aad\u307f\u8fbc\u307f\nimage_file_path = '..\/input\/cassava-leaf-disease-classification\/test_images\/2216849948.jpg'\nimg = Image.open(image_file_path)  # [\u9ad8\u3055][\u5e45][\u8272RGB]\n\n# 2. \u5143\u306e\u753b\u50cf\u306e\u8868\u793a\nplt.imshow(img)\nplt.show()\n\n# 3. \u753b\u50cf\u306e\u524d\u51e6\u7406\u3068\u51e6\u7406\u6e08\u307f\u753b\u50cf\u306e\u8868\u793a\nimg_transformed = train_transforms(img)  # torch.Size([3, 224, 224])\n\n# (\u8272\u3001\u9ad8\u3055\u3001\u5e45)\u3092 (\u9ad8\u3055\u3001\u5e45\u3001\u8272)\u306b\u5909\u63db\u3057\u30010-1\u306b\u5024\u3092\u5236\u9650\u3057\u3066\u8868\u793a\nimg_transformed = img_transformed.numpy().transpose((1, 2, 0))\nimg_transformed = np.clip(img_transformed, 0, 1)\nplt.imshow(img_transformed)\nplt.show()","982c6265":"PATH = \"..\/input\/cassava-leaf-disease-classification\/train_images\/\"\nIMG_SIZE = 224\n\nclass CassavaDataset(data.Dataset):\n    def __init__(self,path,image_ids,labels,image_size, mode='val'):\n        self.image_ids = image_ids\n        self.labels = labels\n        self.path = path\n        self.image_size = image_size\n        self.mode = mode\n\n    def __len__(self):\n        return len(self.image_ids)\n    \n    def __getitem__(self,item):\n      image_ids = str(self.image_ids[item])\n      labels = self.labels[item]\n      img = Image.open(self.path+image_ids)\n      \n      if self.mode==\"train\":\n        return train_transforms(img),torch.tensor(labels,dtype=torch.long)\n      else:\n        return val_transforms(img),torch.tensor(labels,dtype=torch.long)\n        #return torch.tensor(img,dtype=torch.float),torch.tensor(labels,dtype=torch.long)\n    \ndfx = pd.read_csv(\"..\/input\/cassava-leaf-disease-classification\/train.csv\")\nxtrain, xval, ytrain, yval = train_test_split(dfx[\"image_id\"].values,\n                                              dfx.label.values,\n                                              test_size = 0.1, random_state=0)\nIMG_SIZE = 224\n\n# \u5b9f\u884c\ntrain_dataset = CassavaDataset(PATH,xtrain,ytrain,IMG_SIZE, mode=\"train\")\nval_dataset   = CassavaDataset(PATH,xval,yval,IMG_SIZE)\nprint(dfx)","1a20bf33":"IMG_SIZE = 224\n\n# DataLoader\u3092\u4f5c\u6210\u3059\u308b\nbatch_size = 32\n\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True)\n\nval_dataloader = torch.utils.data.DataLoader(\n    val_dataset, batch_size=batch_size, shuffle=False)\n\n# \u8f9e\u66f8\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u307e\u3068\u3081\u308b\ndataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}","2ed58b3d":"# \u5b66\u7fd2\u6e08\u307f\u306eVGG-16\u30e2\u30c7\u30eb\u3092\u30ed\u30fc\u30c9\n\n# VGG-16\u30e2\u30c7\u30eb\u306e\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u751f\u6210\nuse_pretrained = True  # \u5b66\u7fd2\u6e08\u307f\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u4f7f\u7528\n#use_pretrained = False  # \u5b66\u7fd2\u6e08\u307f\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u4f7f\u7528\nnet = models.vgg16(pretrained=use_pretrained)\n\n# VGG16\u306e\u6700\u5f8c\u306e\u51fa\u529b\u5c64\u306e\u51fa\u529b\u30e6\u30cb\u30c3\u30c8\u3092\u75c5\u6c174\u7a2e\u3068\u5065\u5eb7\u306e5\u3064\u306b\u4ed8\u3051\u66ff\u3048\u308b\nnet.classifier[6] = nn.Linear(in_features=4096, out_features=5)\n\n# \u8a13\u7df4\u30e2\u30fc\u30c9\u306b\u8a2d\u5b9a\nnet.train()\n\nprint('\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a2d\u5b9a\u5b8c\u4e86\uff1a\u5b66\u7fd2\u6e08\u307f\u306e\u91cd\u307f\u3092\u30ed\u30fc\u30c9\u3057\u3001\u8a13\u7df4\u30e2\u30fc\u30c9\u306b\u8a2d\u5b9a\u3057\u307e\u3057\u305f')","46ebab93":"# \u640d\u5931\u95a2\u6570\u306e\u8a2d\u5b9a\ncriterion = nn.CrossEntropyLoss()","450a3295":"# \u30d5\u30a1\u30a4\u30f3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3067\u5b66\u7fd2\u3055\u305b\u308b\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u3001\u5909\u6570params_to_update\u306e1\uff5e3\u306b\u683c\u7d0d\u3059\u308b\n\nparams_to_update_1 = []\nparams_to_update_2 = []\nparams_to_update_3 = []\n\n# \u5b66\u7fd2\u3055\u305b\u308b\u5c64\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u540d\u3092\u6307\u5b9a\nupdate_param_names_1 = [\"features\"]\nupdate_param_names_2 = [\"classifier.0.weight\",\n                        \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"]\nupdate_param_names_3 = [\"classifier.6.weight\", \"classifier.6.bias\"]\n\n# \u30d1\u30e9\u30e1\u30fc\u30bf\u3054\u3068\u306b\u5404\u30ea\u30b9\u30c8\u306b\u683c\u7d0d\u3059\u308b\nfor name, param in net.named_parameters():\n    if update_param_names_1[0] in name:\n        param.requires_grad = True\n        params_to_update_1.append(param)\n        print(\"params_to_update_1\u306b\u683c\u7d0d\uff1a\", name)\n\n    elif name in update_param_names_2:\n        param.requires_grad = True\n        params_to_update_2.append(param)\n        print(\"params_to_update_2\u306b\u683c\u7d0d\uff1a\", name)\n\n    elif name in update_param_names_3:\n        param.requires_grad = True\n        params_to_update_3.append(param)\n        print(\"params_to_update_3\u306b\u683c\u7d0d\uff1a\", name)\n\n    else:\n        param.requires_grad = False\n        print(\"\u52fe\u914d\u8a08\u7b97\u306a\u3057\u3002\u5b66\u7fd2\u3057\u306a\u3044\uff1a\", name)","1c038bb7":"# \u6700\u9069\u5316\u624b\u6cd5\u306e\u8a2d\u5b9a\noptimizer = optim.SGD([\n    {'params': params_to_update_1, 'lr': 1e-4},\n    {'params': params_to_update_2, 'lr': 5e-4},\n    {'params': params_to_update_3, 'lr': 1e-3}\n], momentum=0.9)","1c1839cb":"# \u30e2\u30c7\u30eb\u3092\u5b66\u7fd2\u3055\u305b\u308b\u95a2\u6570\u3092\u4f5c\u6210\n\n\ndef train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n\n    # \u521d\u671f\u8a2d\u5b9a\n    # GPU\u304c\u4f7f\u3048\u308b\u304b\u3092\u78ba\u8a8d\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(\"\u4f7f\u7528\u30c7\u30d0\u30a4\u30b9\uff1a\", device)\n\n    # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092GPU\u3078\n    net.to(device)\n\n    # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304c\u3042\u308b\u7a0b\u5ea6\u56fa\u5b9a\u3067\u3042\u308c\u3070\u3001\u9ad8\u901f\u5316\u3055\u305b\u308b\n    torch.backends.cudnn.benchmark = True\n\n    # epoch\u306e\u30eb\u30fc\u30d7\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch+1, num_epochs))\n        print('-------------')\n\n        # epoch\u3054\u3068\u306e\u8a13\u7df4\u3068\u691c\u8a3c\u306e\u30eb\u30fc\u30d7\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                net.train()  # \u30e2\u30c7\u30eb\u3092\u8a13\u7df4\u30e2\u30fc\u30c9\u306b\n            else:\n                net.eval()   # \u30e2\u30c7\u30eb\u3092\u691c\u8a3c\u30e2\u30fc\u30c9\u306b\n\n            epoch_loss = 0.0  # epoch\u306e\u640d\u5931\u548c\n            epoch_corrects = 0  # epoch\u306e\u6b63\u89e3\u6570\n\n            # \u672a\u5b66\u7fd2\u6642\u306e\u691c\u8a3c\u6027\u80fd\u3092\u78ba\u304b\u3081\u308b\u305f\u3081\u3001epoch=0\u306e\u8a13\u7df4\u306f\u7701\u7565\n            if (epoch == 0) and (phase == 'train'):\n                continue\n\n            # \u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\u304b\u3089\u30df\u30cb\u30d0\u30c3\u30c1\u3092\u53d6\u308a\u51fa\u3059\u30eb\u30fc\u30d7\n            for inputs, labels in tqdm(dataloaders_dict[phase]):\n\n                # GPU\u304c\u4f7f\u3048\u308b\u306a\u3089GPU\u306b\u30c7\u30fc\u30bf\u3092\u9001\u308b\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                                \n                # optimizer\u3092\u521d\u671f\u5316\n                optimizer.zero_grad()\n\n                # \u9806\u4f1d\u642c\uff08forward\uff09\u8a08\u7b97\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = net(inputs)\n                    loss = criterion(outputs, labels)  # \u640d\u5931\u3092\u8a08\u7b97\n                    _, preds = torch.max(outputs, 1)  # \u30e9\u30d9\u30eb\u3092\u4e88\u6e2c\n\n                    # \u8a13\u7df4\u6642\u306f\u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                    # \u7d50\u679c\u306e\u8a08\u7b97\n                    epoch_loss += loss.item() * inputs.size(0)  # loss\u306e\u5408\u8a08\u3092\u66f4\u65b0\n                    # \u6b63\u89e3\u6570\u306e\u5408\u8a08\u3092\u66f4\u65b0\n                    epoch_corrects += torch.sum(preds == labels.data)\n\n            # epoch\u3054\u3068\u306eloss\u3068\u6b63\u89e3\u7387\u3092\u8868\u793a\n            epoch_loss = epoch_loss \/ len(dataloaders_dict[phase].dataset)\n            epoch_acc = epoch_corrects.double(\n            ) \/ len(dataloaders_dict[phase].dataset)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n            ","6dbb5ad2":"# \u5b66\u7fd2\u30fb\u691c\u8a3c\u3092\u5b9f\u884c\u3059\u308b\nnum_epochs=1\ntrain_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)","591eb7e7":"# PyTorch\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u4fdd\u5b58\nsave_path = '.\/weights_fine_tuning.pth'\ntorch.save(net.state_dict(), save_path)","9377a4de":"# PyTorch\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u30ed\u30fc\u30c9\nload_path = '.\/weights_fine_tuning.pth'\nload_weights = torch.load(load_path)\nnet.load_state_dict(load_weights)\n\n# GPU\u4e0a\u3067\u4fdd\u5b58\u3055\u308c\u305f\u91cd\u307f\u3092CPU\u4e0a\u3067\u30ed\u30fc\u30c9\u3059\u308b\u5834\u5408\nload_weights = torch.load(load_path, map_location={'cuda:0': 'cpu'})\nnet.load_state_dict(load_weights)","93f5da3c":"from torch.utils.data import Dataset ,DataLoader\n\nIMG_SIZE=224\nTEST_FILE_PATH = \"..\/input\/cassava-leaf-disease-classification\/test_images\/\"\n    \nclass CassavaTestDataset(data.Dataset):\n    def __init__(self,path,image_ids,image_size, mode='val'):\n        print(path)\n        print(image_ids)\n        print(image_size)\n        self.image_ids = image_ids\n        self.path = path\n        self.image_size = image_size\n\n    def __len__(self):\n        return len(self.image_ids)\n    \n    def __getitem__(self,item):\n      image_ids = str(self.image_ids[item])\n      img = Image.open(self.path+image_ids)\n    \n      return val_transforms(img)\n        \nsample = pd.read_csv(\"..\/input\/cassava-leaf-disease-classification\/sample_submission.csv\")\ntest_dataset = CassavaTestDataset(TEST_FILE_PATH,sample.image_id,sample.label,IMG_SIZE)\ntest_loader = DataLoader(test_dataset,\n                      batch_size=1,\n                      shuffle=False)\n\n# \u521d\u671f\u8a2d\u5b9a\n# GPU\u304c\u4f7f\u3048\u308b\u304b\u3092\u78ba\u8a8d\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"\u4f7f\u7528\u30c7\u30d0\u30a4\u30b9\uff1a\", device)\n\n# \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092GPU\u3078\nnet.to(device)\n    \nfin_outputs = []\n\nfor inputs in test_loader:\n\n    # GPU\u304c\u4f7f\u3048\u308b\u306a\u3089GPU\u306b\u30c7\u30fc\u30bf\u3092\u9001\u308b\n    inputs = inputs.to(device)\n    \n    outputs = net(inputs)\n    outputs = nn.Softmax(dim=-1)(outputs)\n    outputs = torch.argmax(outputs,dim=1)\n    fin_outputs.append(outputs.cpu().detach().numpy())\n                \nsample[\"label\"] = np.array(fin_outputs).reshape(-1)\nsample[[\"image_id\",\"label\"]].to_csv(\"submission.csv\",index=False)\nsample.head()","f61a6fd4":"# DataSet\u3092\u4f5c\u6210","587e3fd7":"# \u5165\u529b\u753b\u50cf\u306e\u524d\u51e6\u7406\u30af\u30e9\u30b9\u3092\u4f5c\u6210","954cc23d":"# \u5b66\u7fd2\u30fb\u691c\u8a3c\u3092\u5b9f\u65bd","ddb13939":"# \u6700\u9069\u5316\u624b\u6cd5\u3092\u8a2d\u5b9a\n* Optimizer\u304cVGG\u30e2\u30c7\u30eb\u306e\u3069\u3053\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u66f4\u65b0(\uff1d\u5b66\u7fd2\u30fb\u6700\u9069\u5316)\u3059\u308b\u304b\u3092\u6307\u5b9a\u3059\u308b\n* Optimizer\u306f\u201d\u8aa4\u5dee\u9006\u4f1d\u642c\u6cd5\u201d\u3092\u7528\u3044\u3066\u3001\u640d\u5931\u95a2\u6570\u3092\u6700\u5c0f\u5316\u3059\u308b\u3088\u3046\u306bVGG\u30e2\u30c7\u30eb\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u66f4\u65b0(\uff1d\u5b66\u7fd2\u30fb\u6700\u9069\u5316)\u5f79\u5272\u3092\u62c5\u3046","49ece744":"# \u640d\u5931\u95a2\u6570\u3092\u5b9a\u7fa9\n* \u640d\u5931\u95a2\u6570\u306f\u3001\u30e2\u30c7\u30eb\u304c\u3044\u304b\u306b\u554f\u984c\u3092\u5b66\u7fd2\u30fb\u63a8\u8ad6\u3067\u304d\u308b\u304b\u3092\u56f3\u308b\u6307\u6a19\u201d\u30ed\u30b9(\u640d\u5931)\u201d\u306e\u8a08\u7b97\u65b9\u6cd5\u3092\u6307\u5b9a\u3059\u308b","52c5d304":"# \u5b66\u7fd2\u3057\u305f\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4fdd\u5b58\u30fb\u30ed\u30fc\u30c9","ba733c1c":"# 1.5 \u300c\u30d5\u30a1\u30a4\u30f3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u300d\u3067\u7cbe\u5ea6\u5411\u4e0a\u3092\u5b9f\u73fe\u3059\u308b\u65b9\u6cd5  \n- \u672c\u30d5\u30a1\u30a4\u30eb\u3067\u306f\u3001\u5b66\u7fd2\u6e08\u307f\u306eVGG\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3057\u3001\u30d5\u30a1\u30a4\u30f3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3067\u30a2\u30ea\u3068\u30cf\u30c1\u306e\u753b\u50cf\u3092\u5206\u985e\u3059\u308b\u30e2\u30c7\u30eb\u3092\u5b66\u7fd2\u3057\u307e\u3059","a97cb23f":"# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u8868\u793a","0e5906f4":"# \u5b66\u7fd2\u76ee\u6a19  \n1.PyTorch\u3067GPU\u3092\u4f7f\u7528\u3059\u308b\u5b9f\u88c5\u30b3\u30fc\u30c9\u3092\u66f8\u3051\u308b\u3088\u3046\u306b\u306a\u308b  \n2.\u6700\u9069\u5316\u624b\u6cd5\u306e\u8a2d\u5b9a\u306b\u304a\u3044\u3066\u3001\u5c64\u3054\u3068\u306b\u7570\u306a\u308b\u5b66\u7fd2\u7387\u3092\u8a2d\u5b9a\u3057\u305f\u30d5\u30a1\u30a4\u30f3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3092\u5b9f\u88c5\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308b  \n3.\u5b66\u7fd2\u3057\u305f\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4fdd\u5b58\u30fb\u30ed\u30fc\u30c9\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308b ","e80798a4":"# \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30e2\u30c7\u30eb\u306e\u4f5c\u6210","2ad57027":"# DataLoader\u3092\u4f5c\u6210"}}