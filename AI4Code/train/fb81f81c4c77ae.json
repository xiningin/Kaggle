{"cell_type":{"51eb40d8":"code","a2f92fdf":"code","f01727d5":"code","44c8bc8c":"code","e9f0341c":"code","599c86ae":"code","d5517a35":"code","18626026":"code","82784d37":"code","711befb1":"markdown","5046ec12":"markdown","186c0180":"markdown","4c77ac01":"markdown","4d9e5312":"markdown","18649c94":"markdown","4bc629e7":"markdown","fb791fa8":"markdown"},"source":{"51eb40d8":"#import required libraries\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport numpy as np\nimport time\n%matplotlib inline\nimport warnings\nimport os\nwarnings.filterwarnings('ignore')\nos.listdir('..\/input\/2018-chicago-crime-data')","a2f92fdf":"df = pd.read_csv('..\/input\/2018-chicago-crime-data\/Crimes_-_2018.csv')\nprint(df.isnull().sum())\nprint(\"--------------------------\")\nprint(\"this dataset has \",len(df),\" observations\")","f01727d5":"df.dropna(inplace=True)\ndf.reset_index(drop=True, inplace=True)\ndf.head(2)","44c8bc8c":"from sklearn.preprocessing import StandardScaler\nsf = df[['Primary Type','Longitude','Latitude']]\nscaler = StandardScaler()\nscaler.fit(sf.drop('Primary Type',axis=1))\nscaled_features = scaler.transform(sf.drop('Primary Type',axis=1))\nsf_feat = pd.DataFrame(scaled_features,columns=sf.columns[1:])\nsf_feat.head()","e9f0341c":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(scaled_features,sf['Primary Type'],\n                                                    test_size=0.30)","599c86ae":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\nprint(classification_report(y_test,pred))","d5517a35":"results = pd.DataFrame(classification_report(y_test,pred,output_dict=True))\nresults = results.swapaxes(\"index\", \"columns\") \nresults['categories'] = results.index\nresults = results.sort_values('f1-score',ascending=0)\nresults.drop(['accuracy','macro avg','weighted avg'],inplace=True)\nresults.insert(0,'K-Value','k=1')\nresults.reset_index(drop=True, inplace=True)\nfig = px.bar(results,x='categories',y=\"f1-score\",color_discrete_sequence=('#00A8E8','#003459'),\n             opacity=.7,title='F1 Scores by Crime Type')\nfig.show()","18626026":"error_rate = []\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))\nerror_rt = pd.DataFrame(error_rate,columns = ['error rate'])\nerror_rt['K-value'] = range(1,40)\nfig = px.line(error_rt,x='K-value',y='error rate',color_discrete_sequence=('#1D3557','#00A8E8')\n             ,title='Error Rate Using Different K-Values')\nfig.show()","82784d37":"knn = KNeighborsClassifier(n_neighbors=35)\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\noptimized_results = pd.DataFrame(classification_report(y_test,pred,output_dict=True))\noptimized_results = optimized_results.swapaxes(\"index\", \"columns\") \noptimized_results['categories'] = optimized_results.index\noptimized_results.drop(['accuracy','macro avg','weighted avg'],inplace=True)\noptimized_results.insert(0,'K-Value','k=25')\noptimized_results.reset_index(drop=True, inplace=True)\ncombined = results.append(optimized_results,ignore_index = True)\ncombined = combined.sort_values('f1-score',ascending=0)\nfig = px.bar(combined,x='categories',y=\"f1-score\",color='K-Value',barmode='group',color_discrete_sequence=('#003459','#00A8E8'),\n             opacity=.7,title='F1 Scores Using Different K-Values')\nfig.show()","711befb1":"### Run our first K-Nearest Neighbors Model","5046ec12":"### Change the K-value and re-run\nWe can slightly decrease our error rate by increasing our K-value to 25. Lets do this and see how this alters our results.","186c0180":"### Optimize the Model\nThere are a few different ways to optimize a K-Neighbors Model:\n- Changing the K value (n_neighbors = [])\n- Changing the Distance Function (p = [1,2])\n- Change you variables\n\nFor this model I'm going to look for our optimal K-value. Fair warning, this takes some time to run","4c77ac01":"#### Delete Some Nulls\nLooks like nulls are going to be a problem. I want to do most of my analysis around Lon\/Lat so I'm going to have to clean this up. Seeing as this is a massive dataset, I'm not concerted with deleting 4,600 rows. We should stil, have enough data for our model.","4d9e5312":"### Format the data into our Train - Test Split","18649c94":"## Getting Started\nImport the dataset with Pandas and check if nulls are going to be an issue.","4bc629e7":"## Build the Model\n### First prep the Data\nLet's scale the data to make is more digestable for the model using StandardScaler. Let's try to create model that tries to predict what type of crime has occered based on Longatude and Latitude.","fb791fa8":"### Results\nThe results show _very_ different results for different types of crimes. This shows us that some crimes tend to take place in similar locations, wheras others are more random in nature. Lets graph this to get a better idea of what this loks like."}}