{"cell_type":{"cdd6a751":"code","c8766f36":"code","1136321a":"code","cd8a34f7":"code","856da16a":"code","460c8525":"code","a2dff413":"code","0bc3f516":"code","eeb8f984":"code","2fc26b12":"code","f7044d20":"code","230d1405":"code","69f96dfe":"code","de4257c5":"code","ec1974c8":"code","0de235ee":"code","2d86fd8c":"code","9a40b55e":"code","34bb9530":"code","71d43b81":"markdown","39ebfe69":"markdown","d3b88c5b":"markdown","0c89afa1":"markdown"},"source":{"cdd6a751":"import numpy as np \nimport pandas as pd\nfrom tqdm import tqdm\nimport os, random, time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport glob\nimport cv2\nimport math\n\nimport albumentations\nimport imgaug.augmenters as iaa\nfrom albumentations.augmentations import functional as Fa\nfrom albumentations.core.transforms_interface import ImageOnlyTransform\nfrom PIL import Image, ImageOps, ImageEnhance\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_addons as tfa\n\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision import transforms\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\n\nAUTO = tf.data.experimental.AUTOTUNE\n\n\nCONFIG = {\n'random_seed' : 42,\n'validation_split' : 0.2, # divisible \n'IMAGE_SIZE' : 224,\n'batch_size' : 128,\n'epoch' : 20,\n'MEAN' : [0.48664735 ,0.45366779 ,0.41572613],\n'STD' :  [0.26272767 ,0.25603925, 0.25867402]\n}\n\n# Seed everything for reproductiveness\n\nrandom.seed(CONFIG['random_seed'])\nos.environ[\"PYTHONHASHSEED\"] = str(CONFIG['random_seed'])\nnp.random.seed(CONFIG['random_seed'])\n\nTRAIN_DIR = '..\/input\/dogs-vs-cats\/train\/train\/'\nTEST_DIR = '..\/input\/dogs-vs-cats\/test\/test\/'","c8766f36":"CATS = glob.glob(f'{TRAIN_DIR}\/cat*')\nDOGS = glob.glob(f'{TRAIN_DIR}\/dog*')\n\nfig = go.Figure(data=[go.Pie(labels=['Cats','Dogs'], values=[len(CATS),len(DOGS)])])\nfig.show()","1136321a":"fig, axs = plt.subplots(4,4,figsize=(15,15))\nfig.suptitle('Cats')\nfor index,i in enumerate(axs.flatten()):\n    i.imshow(cv2.cvtColor(cv2.imread(CATS[index]),cv2.COLOR_BGR2RGB))","cd8a34f7":"fig, axs = plt.subplots(4,4,figsize=(15,15))\nfig.suptitle('Dogs')\nfor index,i in enumerate(axs.flatten()):\n    i.imshow(cv2.cvtColor(cv2.imread(DOGS[index]),cv2.COLOR_BGR2RGB))","856da16a":"CATS = pd.DataFrame({'path':CATS,'label':0})\nDOGS = pd.DataFrame({'path':DOGS,'label':1})\n\ntrain_df = pd.concat([CATS,DOGS])\nX_train,X_test,y_train,y_test = train_test_split(train_df.path.values,train_df.label.values,test_size=CONFIG['validation_split'],stratify=train_df.label,random_state=CONFIG['random_seed'])\ntrain_df\n\n\n\nprint(len(X_train),len(X_test))\n\ntrain = tf.data.Dataset.from_tensor_slices((X_train,y_train))\ntest = tf.data.Dataset.from_tensor_slices((X_test,y_test))","460c8525":"def load_img_and_resize(path,label=None):\n    img = tf.io.read_file(path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, [CONFIG['IMAGE_SIZE'], CONFIG['IMAGE_SIZE']])\n    if label is not None:\n        return img, label\n    else:\n        return img\n\ndef normalize(img,label=None):\n    img = tf.image.per_image_standardization(img)\n    if label is not None:\n        return img, label\n    else:\n        return img\n\n\ndef augment(img,label):\n    img = tf.image.random_flip_left_right(img)\n    return img,label\n\ntrain = train.map(load_img_and_resize,num_parallel_calls=AUTO)\ntrain = train.map(normalize,num_parallel_calls=AUTO)\ntrain = train.map(augment,num_parallel_calls=AUTO)\ntrain = train.batch(CONFIG['batch_size'])\ntrain = train.prefetch(10)\ntrain = train.repeat()\n\noptions = tf.data.Options()\noptions.experimental_deterministic = False\ntrain = train.with_options(options)\n\ntest = test.map(load_img_and_resize,num_parallel_calls=AUTO).map(normalize,num_parallel_calls=AUTO).batch(CONFIG['batch_size']).prefetch(10).repeat()","a2dff413":"# def calc_mean_and_std():\n#     pixel_num = 0\n#     temp = np.zeros((len(train_df),3))\n    \n#     for index,i in tqdm(enumerate(train_df.path.values)):\n#         img = cv2.imread(i)\n#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n#         img = img\/255.0\n#         pixel_num += img.size\/3\n#         temp[index] = np.sum(img,(0,1))\n    \n#     MEAN = np.sum(temp,0)\/pixel_num\n    \n    \n#     temp = np.zeros((len(train_df),3))\n    \n#     for index,i in tqdm(enumerate(train_df.path.values)):\n#         img = cv2.imread(i)\n#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n#         img = img\/255.0\n#         img = np.square(img - MEAN)\n#     #     print(np.sum(img,(0,1)))\n#     #     break\n#         temp[index] = np.sum(img,(0,1))\n    \n#     temp = np.sum(temp,0)\/pixel_num\n#     STD = np.sqrt(temp)\n            \n    \n#     return MEAN,STD\n\n# MEAN,STD = calc_mean_and_std()","0bc3f516":"def make_model():\n\n    model = keras.models.Sequential([\n        keras.layers.Input(shape=(224, 224,3)),\n        tf.keras.applications.ResNet50(\n        include_top=False,\n        weights=\"imagenet\",\n        pooling='avg'\n    ),\n        keras.layers.Dense(1,activation='sigmoid')\n    ])\n    \n    model.compile(\n        optimizer=tfa.optimizers.Lookahead(tf.keras.optimizers.Adam()),\n        loss='binary_crossentropy',\n        metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.BinaryCrossentropy()]\n    )\n    model.layers[0].trainable=False\n    print(model.summary())\n    return model","eeb8f984":"def step_decay(epoch):\n    initial_lrate = 0.001\n    \n    if epoch < 5:\n        return initial_lrate\n    \n    drop = 0.05\n    epochs_drop = float(CONFIG['epoch'])\n    lrate = initial_lrate * math.pow(drop,epoch\/epochs_drop)\n    return lrate\n\nlrate = tf.keras.callbacks.LearningRateScheduler(step_decay)\n\nes = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=0, patience=5\n)\n\nmchp = tf.keras.callbacks.ModelCheckpoint(\n    'best_model', monitor='val_loss', verbose=0, save_best_only=True\n)\n\n\nmodel = make_model()\nhist = model.fit(train,epochs=20,validation_data = test,steps_per_epoch=len(X_train)\/\/CONFIG['batch_size'],validation_steps=len(X_test)\/\/CONFIG['batch_size'],callbacks=[lrate,es,mchp])","2fc26b12":"hist_df = pd.DataFrame(hist.history)\nhist_df.to_csv('hist_df')","f7044d20":"hist_df['epoch'] = np.arange(1,len(hist_df)+1)\nhist_df","230d1405":"fig = px.line(hist_df,x='epoch',y=['accuracy','val_accuracy'],title='Accuracy')\nfig.show()","69f96dfe":"fig = px.line(hist_df,x='epoch',y=['loss','val_loss'],title='Loss')\nfig.show()","de4257c5":"fig = px.line(hist_df,x='epoch',y=['auc','val_auc'],title='AUC')\nfig.show()","ec1974c8":"fig = px.line(hist_df,x='epoch',y=['lr'],title='Learning rate')\nfig.show()","0de235ee":"def only_paths(x,y):\n    return x\n\npreds = model.predict(test.map(only_paths),steps=len(X_test)\/\/CONFIG['batch_size'])","2d86fd8c":"tn, fp, fn, tp = confusion_matrix(y_test[:CONFIG['batch_size']*(len(X_test)\/\/CONFIG['batch_size'])],np.round(preds).astype(np.int32).reshape(len(preds))).ravel()\nprint(tn, fp, fn, tp)","9a40b55e":"eval_loss = abs(preds.reshape(len(preds))-y_test[:CONFIG['batch_size']*(len(X_test)\/\/CONFIG['batch_size'])])\narg_sorted_eval_loss = np.argsort(eval_loss)\nfig, axs = plt.subplots(4,4,figsize=(15,15))\nfig.suptitle('Min losses')\nfor index,i in enumerate(axs.flatten()):\n    i.imshow(cv2.cvtColor(cv2.imread(X_train[arg_sorted_eval_loss[index]]),cv2.COLOR_BGR2RGB))\n    i.set_title(str(eval_loss[arg_sorted_eval_loss[index]]))","34bb9530":"arg_sorted_eval_loss = np.flip(arg_sorted_eval_loss)\nfig, axs = plt.subplots(4,4,figsize=(15,15))\nfig.suptitle('Max losses')\nfor index,i in enumerate(axs.flatten()):\n    i.imshow(cv2.cvtColor(cv2.imread(X_train[arg_sorted_eval_loss[index]]),cv2.COLOR_BGR2RGB))\n    i.set_title(str(eval_loss[arg_sorted_eval_loss[index]]))","71d43b81":"# Let's use basic augmentation and see how it performs","39ebfe69":"# Plot top losses","d3b88c5b":"## Creating tf Datasets for train and validation","0c89afa1":"## Loading Cats and Dogs paths to two lists"}}