{"cell_type":{"6d865e01":"code","c8382637":"code","d5832c6e":"code","657a694e":"code","2f10ec9d":"code","a3753240":"code","c2e18c71":"code","04178ab8":"code","37d41959":"code","deaa686a":"code","71fc3990":"code","fc99db38":"code","fd06c1f8":"code","6731f99f":"code","0346a773":"code","66b5cc71":"code","40ae34fe":"code","201e10e3":"markdown","27926177":"markdown","aaf5e7e2":"markdown","bf39c8ab":"markdown","f8844d68":"markdown","9e7799d2":"markdown"},"source":{"6d865e01":"#importando bibliotecas\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesRegressor\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nimport re\nimport operator\nfrom sklearn.feature_selection import SelectKBest, f_classif","c8382637":"#lendo o banco de dados\n\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\", dtype={\"Age\": np.float64})\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\", dtype={\"Age\": np.float64})\n\n#isolando a coluna alvo\ntarget = train[\"Survived\"].values\n#juntando os dois datasets para aplicarmos o pr\u00e9-processamento a ambos\nfull = pd.concat([train, test],sort=True) ","d5832c6e":"print(full.head())","657a694e":"print(full.describe())","2f10ec9d":"print(full.info())","a3753240":"#pegando o sobrenome e o t\u00edtulo dos passageiros\nfull['surname'] = full[\"Name\"].apply(lambda x: x.split(',')[0].lower())\n\nfull[\"Title\"] = full[\"Name\"].apply(lambda x: re.search(' ([A-Za-z]+)\\.',x).group(1))\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 2, \"Mme\": 3,\"Don\": 9,\"Dona\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\nfull[\"TitleCat\"] = full.loc[:,'Title'].map(title_mapping)","c2e18c71":"#verificando o tamanho da fam\u00edlia e separando em grupos\nfull[\"FamilySize\"] = full[\"SibSp\"] + full[\"Parch\"] + 1\nfull[\"FamilySize\"] = pd.cut(full[\"FamilySize\"], bins=[0,1,4,20], labels=[0,1,2])","04178ab8":"#Lidando com as colunas de string e valores na \n\n#criando a coluna de tamanho do nome para substituir a de nome\nfull[\"NameLength\"] = full[\"Name\"].apply(lambda x: len(x))\n\n#transformando a coluna embarked em pandas categorical\nfull[\"Embarked\"] = pd.Categorical(full.Embarked).codes\n\n#convertendo a coluna Sex usando dummies\nfull = pd.concat([full,pd.get_dummies(full['Sex'])],axis=1)\n\n#transformando a coluna cabincat para valores de int categ\u00f3ricos e preenchendo seus na com 0\nfull['CabinCat'] = pd.Categorical(full.Cabin.fillna('0').apply(lambda x: x[0])).codes\n\n#preenchendo o(1) valor na de Fare com a m\u00e9dia da coluna\nfull[\"Fare\"] = full[\"Fare\"].fillna(np.mean(full[\"Fare\"]))\n\n\n#convertendo a coluna de cabine\n#fun\u00e7\u00e3o que verifica se a cabine tem digitos pares, \u00edmpares ou na \ndef get_type_cabine(cabine):\n    # Use a regular expression to search for a title. \n    cabine_search = re.search('\\d+', cabine)\n    # If the title exists, extract and return it.\n    if cabine_search:\n        num = cabine_search.group(0)\n        if np.float64(num) % 2 == 0:\n            return '2'\n        else:\n            return '1'\n    return '0'\n#preenchendo os nas com string vazia\nfull[\"Cabin\"] = full[\"Cabin\"].fillna(\" \")\n\nfull[\"CabinType\"] = full[\"Cabin\"].apply(get_type_cabine)","37d41959":"#separando passageiros em crian\u00e7as(pessoas com menos de 18 anos), mulheres e homens\nchild_age = 18\ndef get_person(passenger):\n    age, sex = passenger\n    if (age < child_age):\n        return 'child'\n    elif (sex == 'female'):\n        return 'female_adult'\n    else:\n        return 'male_adult'\nfull = pd.concat([full, pd.DataFrame(full[['Age', 'Sex']].apply(get_person, axis=1), columns=['person'])],axis=1)\n\n#convertendo a coluna person usando dummies\nfull = pd.concat([full,pd.get_dummies(full['person'])],axis=1)","deaa686a":"#colunas baseadas no ingresso\ntable_ticket = pd.DataFrame(full[\"Ticket\"].value_counts())\ntable_ticket.rename(columns={'Ticket':'Ticket_Members'}, inplace=True)\n\ntable_ticket['Ticket_perishing_women'] = full.Ticket[(full.female_adult == 1.0) \n                                    & (full.Survived == 0.0) \n                                    & ((full.Parch > 0) | (full.SibSp > 0))].value_counts()\ntable_ticket['Ticket_perishing_women'] = table_ticket['Ticket_perishing_women'].fillna(0)\ntable_ticket['Ticket_perishing_women'][table_ticket['Ticket_perishing_women'] > 0] = 1.0 \n\ntable_ticket['Ticket_surviving_men'] = full.Ticket[(full.male_adult == 1.0) \n                                    & (full.Survived == 1.0) \n                                    & ((full.Parch > 0) | (full.SibSp > 0))].value_counts()\ntable_ticket['Ticket_surviving_men'] = table_ticket['Ticket_surviving_men'].fillna(0)\ntable_ticket['Ticket_surviving_men'][table_ticket['Ticket_surviving_men'] > 0] = 1.0 \n\ntable_ticket[\"Ticket_Id\"]= pd.Categorical(table_ticket.index).codes\n\ntable_ticket[\"Ticket_Id\"][table_ticket[\"Ticket_Members\"] < 3 ] = -1\ntable_ticket[\"Ticket_Members\"] = pd.cut(table_ticket[\"Ticket_Members\"], bins=[0,1,4,20], labels=[0,1,2])\n\nfull = pd.merge(full, table_ticket, left_on=\"Ticket\",right_index=True,how='left', sort=False)","71fc3990":"#colunas baseada no sobrenome\ntable_surname = pd.DataFrame(full[\"surname\"].value_counts())\ntable_surname.rename(columns={'surname':'Surname_Members'}, inplace=True)\n\ntable_surname['Surname_perishing_women'] = full.surname[(full.female_adult == 1.0) \n                                    & (full.Survived == 0.0) \n                                    & ((full.Parch > 0) | (full.SibSp > 0))].value_counts()\ntable_surname['Surname_perishing_women'] = table_surname['Surname_perishing_women'].fillna(0)\ntable_surname['Surname_perishing_women'][table_surname['Surname_perishing_women'] > 0] = 1.0 \n\ntable_surname['Surname_surviving_men'] = full.surname[(full.male_adult == 1.0) \n                                    & (full.Survived == 1.0) \n                                    & ((full.Parch > 0) | (full.SibSp > 0))].value_counts()\ntable_surname['Surname_surviving_men'] = table_surname['Surname_surviving_men'].fillna(0)\ntable_surname['Surname_surviving_men'][table_surname['Surname_surviving_men'] > 0] = 1.0 \n\ntable_surname[\"Surname_Id\"]= pd.Categorical(table_surname.index).codes\n\n\ntable_surname[\"Surname_Id\"][table_surname[\"Surname_Members\"] < 3 ] = -1\n\ntable_surname[\"Surname_Members\"] = pd.cut(table_surname[\"Surname_Members\"], bins=[0,1,4,20], labels=[0,1,2])\n\nfull = pd.merge(full, table_surname, left_on=\"surname\",right_index=True,how='left', sort=False)","fc99db38":"#coluna de idade\nclassers = ['Fare','Parch','Pclass','SibSp','TitleCat', 'CabinCat','female','male', 'Embarked', 'FamilySize', 'NameLength','Ticket_Members','Ticket_Id']\netr = ExtraTreesRegressor(n_estimators=200)\nX_train = full[classers][full['Age'].notnull()]\nY_train = full['Age'][full['Age'].notnull()]\nX_test = full[classers][full['Age'].isnull()]\netr.fit(X_train,np.ravel(Y_train))\nage_preds = etr.predict(X_test)\nfull['Age'][full['Age'].isnull()] = age_preds","fd06c1f8":"#colunas dispon\u00edveis\nfeatures = ['female','male','Age','male_adult','female_adult', 'child','TitleCat', 'Pclass',\n'Pclass','Ticket_Id','NameLength','CabinType','CabinCat', 'SibSp', 'Parch',\n'Fare','Embarked','Surname_Members','Ticket_Members','FamilySize',\n'Ticket_perishing_women','Ticket_surviving_men',\n'Surname_perishing_women','Surname_surviving_men']\n\n#separando os dados em treino e teste de novo\ntrain = full[0:891].copy()\ntest = full[891:].copy()\n\n#usando o selectorKBest para conseguir as melhores colunas para o modelo\nselector = SelectKBest(f_classif, k=len(features))\nselector.fit(train[features], target)\nscores = -np.log10(selector.pvalues_)\nindices = np.argsort(scores)[::-1]","6731f99f":"#definindo o modelo\nrfc = RandomForestClassifier(n_estimators=3000, min_samples_split=4, class_weight={0:0.745,1:0.255})","0346a773":"# testando (cross validation)\nkf = StratifiedKFold(n_splits=10,random_state=42)\n\nscores = cross_val_score(rfc, train[features], target, cv=kf)\nprint(\"Accuracy: %0.3f (+\/- %0.2f) [%s]\" % (scores.mean()*100, scores.std()*100, 'RFC Cross Validation'))\nrfc.fit(train[features], target)\nscore = rfc.score(train[features], target)\nprint(\"Accuracy: %0.3f            [%s]\" % (score*100, 'RFC full test'))\nimportances = rfc.feature_importances_\nindices = np.argsort(importances)[::-1]\nfor f in range(len(features)):\n    print(\"%d. feature %d (%f) %s\" % (f + 1, indices[f]+1, importances[indices[f]]*100, features[indices[f]]))\n","66b5cc71":"#predicting\nrfc.fit(train[features], target)\npredictions = rfc.predict(test[features])","40ae34fe":"#prediction file\nPassengerId =np.array(test[\"PassengerId\"]).astype(int)\nmy_prediction = pd.DataFrame(predictions, PassengerId, columns = [\"Survived\"])\n\nmy_prediction.to_csv(\"my_prediction.csv\", index_label = [\"PassengerId\"])","201e10e3":"#Modelo","27926177":"#Visualizando","aaf5e7e2":"#Submission file","bf39c8ab":"#Importando bibliotecas e lendo o banco","f8844d68":"#Testando","9e7799d2":"#Pr\u00e9-processamento"}}