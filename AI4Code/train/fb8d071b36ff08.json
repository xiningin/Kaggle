{"cell_type":{"619180a9":"code","970c2353":"code","43a89fbc":"code","ef4b9488":"code","44bd6f5e":"code","fc7ded45":"code","8e951c5d":"code","eb2d3a26":"code","d06fc680":"code","26ab0a2e":"code","f091681e":"code","97220a8f":"code","673232f1":"code","2011a47b":"code","b01cba5e":"code","1418e85d":"code","b0229ccb":"code","14da750a":"code","15aed3b9":"code","eb649ddf":"code","4a84bc1d":"code","10f8c613":"code","2c3b0a5b":"code","fe009fb8":"code","add81a36":"code","6cbf4ba4":"code","dbb371b1":"code","524a54a3":"code","ea5d8c5a":"markdown","c3f9dbc2":"markdown","f6efadb3":"markdown","4777f763":"markdown","8231eb68":"markdown","3b3c7fb5":"markdown","15f68deb":"markdown","ae7c5e82":"markdown","acfbfd70":"markdown","613277d9":"markdown","4d32a35c":"markdown","68d5c7bc":"markdown","79ab61cf":"markdown","db19cab3":"markdown","74ab8638":"markdown","b50d638a":"markdown","cf9a37cc":"markdown","13b186a7":"markdown","2592de81":"markdown","89d0a646":"markdown"},"source":{"619180a9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sb\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler\nfrom sklearn.metrics import mean_squared_error, explained_variance_score\nfrom sklearn.linear_model import RidgeCV, Ridge\nfrom sklearn.ensemble import VotingRegressor, GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestRegressor, StackingRegressor\nfrom xgboost import XGBRegressor","970c2353":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (25, 15)","43a89fbc":"data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ndata.drop(columns=['Id'], inplace=True)","ef4b9488":"data.head()","44bd6f5e":"\ndata.columns[data.isna().any()].tolist()","fc7ded45":"data.info()","8e951c5d":"def cleanNumericalData(df, feature):\n    mode = df[feature].dropna().value_counts().index[0]\n    df[feature] = df[feature].replace(np.nan, mode)\n    return df[feature]","eb2d3a26":"nonObjCols = data.select_dtypes(exclude=['object']).columns\nfor feature in nonObjCols:\n    data[feature] = cleanNumericalData(data, feature)","d06fc680":"data['MasVnrType'] = data['MasVnrType'].replace(np.nan, data.MasVnrType.value_counts().index[0])\ndata['Electrical'] = data['Electrical'].replace(np.nan, data.Electrical.value_counts().index[0])","26ab0a2e":"data = pd.get_dummies(data)\ncolumns = data.columns\ndata = pd.DataFrame(data, columns = columns)\ny = data.SalePrice.values\n\nX = data.loc[:, data.columns != 'SalePrice'].values","f091681e":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=18)","97220a8f":"inScale = RobustScaler()\noutScale = RobustScaler()\n\nX_train = inScale.fit_transform(X_train)\ny_train = outScale.fit_transform(y_train.reshape(-1, 1))\nX_test = inScale.transform(X_test)\ny_test = outScale.transform(y_test.reshape(-1, 1))\n","673232f1":"ridge = Ridge(alpha=14).fit(X_train, y_train)\n\ndata_predicted = ridge.predict(X_test)\n\nMAX = 200\nx = range(len(data_predicted))[0:MAX]\nplt.scatter(x,y_test[0:MAX],color='g', linewidths=5)\nplt.scatter(x,data_predicted[0:MAX],color='r', linewidths=3)\nplt.plot(data_predicted[0:MAX], color = 'r', linewidth=2)\n\nmse = mean_squared_error(y_test, data_predicted)\nprint(\"MSE: %.4f\" % mse)\n\nevs = explained_variance_score(y_test, data_predicted)\nprint(\"EVS: %.4f\" % evs)\n\nscore = ridge.score(X_test, y_test)\nprint(\"Score: %.4f\" % score)","2011a47b":"rcv = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1, 10]).fit(X_train, y_train)\n\ndata_predicted = rcv.predict(X_test)\n\nMAX = 200\nx = range(len(data_predicted))[0:MAX]\nplt.scatter(x,y_test[0:MAX],color='g', linewidths=5)\nplt.scatter(x,data_predicted[0:MAX],color='r', linewidths=3)\nplt.plot(data_predicted[0:MAX], color = 'r', linewidth=2)\n\nmse = mean_squared_error(y_test, data_predicted)\nprint(\"MSE: %.4f\" % mse)\n\nevs = explained_variance_score(y_test, data_predicted)\nprint(\"EVS: %.4f\" % evs)\n\nscore = rcv.score(X_test, y_test)\nprint(\"Score: %.4f\" % score)","b01cba5e":"rf = RandomForestRegressor(n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_features='sqrt', max_depth=50, bootstrap=False, random_state=2, n_jobs=-1).fit(X_train, y_train.ravel())\n\ndata_predicted = rf.predict(X_test)\n\nMAX = 200\nx = range(len(data_predicted))[0:MAX]\nplt.scatter(x,y_test[0:MAX],color='g', linewidths=5)\nplt.scatter(x,data_predicted[0:MAX],color='r', linewidths=3)\nplt.plot(data_predicted[0:MAX], color = 'r', linewidth=2)\n\nmse = mean_squared_error(y_test, data_predicted)\nprint(\"MSE: %.4f\" % mse)\n\nevs = explained_variance_score(y_test, data_predicted)\nprint(\"EVS: %.4f\" % evs)\n\nscore = rf.score(X_test, y_test)\nprint(\"Score: %.4f\" % score)","1418e85d":"gbr = GradientBoostingRegressor(n_estimators=400,learning_rate=0.1,max_depth=2,subsample=1,random_state=1).fit(X_train, y_train.ravel()) # based on aboved Hyper-tuning\n\ndata_predicted = gbr.predict(X_test)\n\nMAX = 200\nx = range(len(data_predicted))[0:MAX]\nplt.scatter(x,y_test[0:MAX],color='g', linewidths=5)\nplt.scatter(x,data_predicted[0:MAX],color='r', linewidths=3)\nplt.plot(data_predicted[0:MAX], color = 'r', linewidth=2)\n\nmse = mean_squared_error(y_test, data_predicted)\nprint(\"MSE: %.4f\" % mse)\n\nevs = explained_variance_score(y_test, data_predicted)\nprint(\"EVS: %.4f\" % evs)\n\nscore = gbr.score(X_test, y_test)\nprint(\"Score: %.4f\" % score)","b0229ccb":"xb = XGBRegressor(colsample_bytree=0.2, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=1000, objective='reg:squarederror', subsample=0.2).fit(X_train, y_train.ravel())\n\ndata_predicted = xb.predict(X_test)\n\nMAX = 200\nx = range(len(data_predicted))[0:MAX]\nplt.scatter(x,y_test[0:MAX],color='g', linewidths=5)\nplt.scatter(x,data_predicted[0:MAX],color='r', linewidths=3)\nplt.plot(data_predicted[0:MAX], color = 'r', linewidth=1)\n\nmse = mean_squared_error(y_test, data_predicted)\nprint(\"MSE: %.4f\" % mse)\n\nevs = explained_variance_score(y_test, data_predicted)\nprint(\"EVS: %.4f\" % evs)\n\nscore = xb.score(X_test, y_test)\nprint(\"Score: %.4f\" % score)","14da750a":"estimators = [('ridge', ridge), ('ridgecv', rcv), ('randomforest', rf), ('gradientboost', gbr), ('xgboost', xb)]\n                                                                                                               \nsr = StackingRegressor(estimators=estimators, final_estimator=RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1), cv = 10).fit(X_train, y_train.ravel())\n\ndata_predicted = sr.predict(X_test)\n\nMAX = 200\nx = range(len(data_predicted))[0:MAX]\nplt.scatter(x,y_test[0:MAX],color='g', linewidths=5)\nplt.scatter(x,data_predicted[0:MAX],color='r', linewidths=3)\nplt.plot(data_predicted[0:MAX], color = 'r', linewidth=2)\n\nmse = mean_squared_error(y_test, data_predicted)\nprint(\"MSE: %.4f\" % mse)\n\nevs = explained_variance_score(y_test, data_predicted)\nprint(\"EVS: %.4f\" % evs)\n\nscore = sr.score(X_test, y_test)\nprint(\"Score: %.4f\" % score)","15aed3b9":"vr = VotingRegressor([('ridge', ridge), ('ridgecv', rcv), ('randomforest', rf), ('gradientboost', gbr), ('xgboost', xb), ('sr', sr)]).fit(X_train, y_train.ravel())\n\ndata_predicted = vr.predict(X_test)\n\nMAX = 200\nx = range(len(data_predicted))[0:MAX]\nplt.scatter(x,y_test[0:MAX],color='g', linewidths=5)\nplt.scatter(x,data_predicted[0:MAX],color='r', linewidths=3)\nplt.plot(data_predicted[0:MAX], color = 'r', linewidth=2)\n\nmse = mean_squared_error(y_test, data_predicted)\nprint(\"MSE: %.4f\" % mse)\n\nevs = explained_variance_score(y_test, data_predicted)\nprint(\"EVS: %.4f\" % evs)\n\nscore = vr.score(X_test, y_test)\nprint(\"Score: %.4f\" % score)","eb649ddf":"data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ndata.head()\nid_values = data.Id.values","4a84bc1d":"nonObjCols = data.select_dtypes(exclude=['object']).columns\nfor feature in nonObjCols:\n    data[feature] = cleanNumericalData(data, feature)","10f8c613":"data['MasVnrType'] = data['MasVnrType'].replace(np.nan, data.MasVnrType.value_counts().index[0])\ndata['Electrical'] = data['Electrical'].replace(np.nan, data.Electrical.value_counts().index[0])","2c3b0a5b":"data = pd.get_dummies(data)\ntcol = data.columns","fe009fb8":"diffCols = [x for x in columns if x not in tcol]\n\ndata[diffCols] = 0\ndata = pd.DataFrame(data, columns = columns)\ndata.drop(['SalePrice'], axis=1, inplace=True)","add81a36":"for col in data.columns:\n    if (data[col].isna().sum() > 0):\n        print(col)","6cbf4ba4":"data = inScale.transform(data)\n\ny = vr.predict(data)\n\nPredicted_Values = outScale.inverse_transform(y.reshape(-1, 1))\n\nPredicted_Values.shape","dbb371b1":"result = pd.DataFrame(id_values, columns=['Id'])\n\nresult['SalePrice'] = Predicted_Values\n\nresult","524a54a3":"result.to_csv(\"Result.csv\", index=False)","ea5d8c5a":"**Data scaling**","c3f9dbc2":"**List out all the features in the data that have undefined values**","f6efadb3":"**Replace the NaN values with mode (Note: Not all NA are invalid)**","4777f763":"**XGBoost**","8231eb68":"**Ensembling**","3b3c7fb5":"**Splitting data into Train and Test sets**","15f68deb":"**Read Test data**","ae7c5e82":"**Ensure there are no feature(s) with NaN values**","acfbfd70":"**One-Hot Encoding**","613277d9":"**Ridge CV**","4d32a35c":"# House Prices - Playing with Stacking and Ensembling\n**(Public Score - 0.12718)**\n","68d5c7bc":"**Replace the NaN values with mode**","79ab61cf":"**Stacking**","db19cab3":"**Import necessary libraries**","74ab8638":"**Read the input file nd display contents**","b50d638a":"**Gradient Boosting**","cf9a37cc":"**Identify missing features in test data, add them and set their values to zero**","13b186a7":"**Ridge**","2592de81":"**One-Hot Encoding**","89d0a646":"**Random Forest**"}}