{"cell_type":{"eb2bdc74":"code","28cbb566":"code","a975e9db":"code","b991ffec":"code","1f67ed12":"code","da4c2386":"code","023f76f5":"code","ebf64a26":"code","8e3b7695":"code","64d2f648":"code","ca8fe744":"code","156245d7":"code","cf60ed71":"code","977faf4a":"code","d4afd992":"code","e6488b70":"code","8d71f8db":"code","ec693470":"code","5d30c39e":"code","ec8d1a88":"code","834c2aaf":"code","cba7276f":"code","6f737d7e":"markdown","45b1ad3f":"markdown","a752042a":"markdown","cacd6d38":"markdown","af196d03":"markdown","40ce74fa":"markdown","716b1414":"markdown"},"source":{"eb2bdc74":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","28cbb566":"%matplotlib inline\nimport random\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set()","a975e9db":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score","b991ffec":"train = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv')","1f67ed12":"train.head()","da4c2386":"test.head()","023f76f5":"mapping = {\n    0: 'T-shirt\/top',\n    1: 'Trouser',\n    2: 'Pullover',\n    3: 'Dress',\n    4: 'Coat',\n    5: 'Sandal',\n    6: 'Shirt',\n    7: 'Sneaker',\n    8: 'Bag',\n    9: 'Ankle boot'\n}","ebf64a26":"ax = sns.countplot(x='label', data=train, orient='v')\nax.set_xticklabels([mapping[i] for i in mapping], rotation=45, horizontalalignment='right')\nplt.show()","8e3b7695":"ax = sns.countplot(x='label', data=test, orient='v')\nax.set_xticklabels([mapping[i] for i in mapping], rotation=45, horizontalalignment='right')\nplt.show()","64d2f648":"x_train = train.drop(['label'], axis=1)\ny_train = train['label']\n\nx_test = test.drop(['label'], axis=1)\ny_test = test['label']","ca8fe744":"plt.figure(figsize=(10, 6))\n\nfor i in range(4):\n    rand = random.randint(0, x_train.shape[0])\n    plt.subplot(1, 4, i + 1)\n    plt.imshow(x_train.loc[rand].values.reshape(28, 28))\n    plt.axis('off')\n    plt.title(mapping[y_train[rand]])\n\nplt.show()","156245d7":"x_train, x_test = x_train \/ 255., x_test \/ 255.\nx_train, x_test = x_train.values.reshape(-1, 28, 28, 1),\\\n                  x_test.values.reshape(-1, 28, 28, 1)","cf60ed71":"y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)","977faf4a":"x_train, x_cv, y_train, y_cv = train_test_split(x_train, y_train, test_size=0.2, random_state=42)","d4afd992":"model = tf.keras.models.Sequential([\n    # 1\n    tf.keras.layers.Conv2D(\n        filters=32, \n        input_shape=(28, 28, 1),\n        kernel_size=3,\n        strides=1,\n        padding='same',\n        activation='relu'\n    ),\n    tf.keras.layers.BatchNormalization(),\n    \n    # 2\n    tf.keras.layers.Conv2D(\n        filters=32, \n        kernel_size=3,\n        strides=1,\n        padding='same',\n        activation='relu'\n    ),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.25),\n    \n    # 3\n    tf.keras.layers.Conv2D(\n        filters=64, \n        kernel_size=3,\n        strides=1,\n        padding='same',\n        activation='relu'\n    ),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Dropout(0.25),\n    \n    # 4\n    tf.keras.layers.Conv2D(\n        filters=128,\n        kernel_size=3,\n        strides=1,\n        padding='same',\n        activation='relu'\n    ),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.25),\n    \n    # FC\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(10, 'softmax')\n]) \n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()","e6488b70":"history = model.fit(\n    x_train, y_train, batch_size=128,\n    steps_per_epoch=x_train.shape[0] \/\/ 128,\n    epochs=40, verbose=2, validation_data=(x_cv, y_cv),\n    callbacks=[tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)]\n)","8d71f8db":"loss_train = history.history['loss']\nloss_validation = history.history['val_loss']\nepochs = range(1, len(history.history['loss']) + 1)\nplt.plot(epochs, loss_train, 'g', label='Training')\nplt.plot(epochs, loss_validation, 'b', label='Validation')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Loss')\nplt.legend()\nplt.show()","ec693470":"acc_train = history.history['accuracy']\nacc_validation = history.history['val_accuracy']\nepochs = range(1, len(history.history['accuracy']) + 1)\nplt.plot(epochs, acc_train, 'g', label='Training')\nplt.plot(epochs, acc_validation, 'b', label='Validation')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Accuracy')\nplt.legend()\nplt.show()","5d30c39e":"y_hat = model.predict(x_test)\ny_pred = [np.argmax(p) for p in np.round(y_hat)]","ec8d1a88":"sns.heatmap(\n    confusion_matrix(\n        y_test, \n        y_pred\n    ),\n    cmap='YlGnBu'\n)\nplt.title('Confusion Matrix')\nplt.show()","834c2aaf":"print(classification_report(y_test, y_pred, target_names=list(mapping.values())))","cba7276f":"for c in [0, 6]:\n    plt.figure(figsize=(10, 6))\n    for i, v in enumerate(y_test[y_test == c].to_frame().tail(4).index.tolist()):\n        plt.subplot(1, 4, i + 1)\n        plt.imshow(x_test[v].reshape(28, 28))\n        plt.axis('off')\n        plt.title('Actual: ' + mapping[y_test[v]]\n                  + '\\nPredicted: ' + mapping[y_pred[v]])\n    plt.show()","6f737d7e":"# Data Modelling","45b1ad3f":"# Dependencies","a752042a":"# Frequent Misclassifications","cacd6d38":"# Model Evaluation","af196d03":"# Data Exploration","40ce74fa":"# Model Building","716b1414":"# Model Training"}}