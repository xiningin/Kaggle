{"cell_type":{"6d7243fe":"code","cd348381":"code","f6d24fc3":"code","decd15fa":"code","5ae552d9":"code","f6aba627":"code","5883c22b":"code","738c033b":"code","d7adf3c5":"code","278c9a78":"code","e771b13e":"code","bfa42de7":"code","be0cbc9a":"code","6ed19765":"code","63aed28f":"code","4762f78e":"code","f844b80d":"code","9842beb9":"code","e5726da6":"code","be17a1cc":"code","21aee2bf":"code","b6509b0e":"code","5eb1c046":"code","7e1671d9":"code","f9714444":"markdown","b43adfd9":"markdown","760fb16c":"markdown","068e0c98":"markdown","758788d0":"markdown"},"source":{"6d7243fe":"import h5py\n\nimport numpy as np\nimport pandas as pd\n\nfrom glob import glob\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","cd348381":"# Age and 4 anonymized targets, 443 partially missed observations\ntrain_scores = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/train_scores.csv').sort_values(by='Id')\n\n# Somehow preprocessed morphometry (after group ICA), simplest feature set\nloadings = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/loading.csv')\n\n# resting-state fMRI Functional Network Connectivity matrices. \n# In simple setting, these are cross-correlations (in this case something more sophisticated) between\n# every pair of brain regions presented in train\/test *.mat\nfnc = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/fnc.csv')\n\n# Submit Age and 4 scores for test ids\nsample = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/sample_submission.csv')\n\n# List of some of subjects from test set whose data were collected from different scanner\nreveal = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/reveal_ID_site2.csv')\n\n# 53 unique numbers between 2 and 99 (somehow related to brain regions? regions keys?)\nicn_nums = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/ICN_numbers.csv')\n\n# Brain template\n# \/kaggle\/input\/trends-assessment-prediction\/fMRI_mask.nii \n\n# train\/test fMRI spatial maps\n# *.mat","f6d24fc3":"loadings.head(3)","decd15fa":"# 53 * 52 \/ 2 = 1378 + Id column\nfnc.head(3)","5ae552d9":"import re\nfrom tqdm import tqdm","f6aba627":"r = re.compile('\\d+')\ncol_dict = {}\nfor col in fnc.columns:\n    ind = r.findall(col)\n    if ind:\n        col_dict[col] = [int(i) for i in ind]","5883c22b":"def get_matrix(df_row, return_idx=False):\n    matrix = np.zeros((100, 100))\n    for col in df_row.index[1:]:\n        i, j = col_dict[col]\n        matrix[i, j] = df_row[col]\n    matrix += matrix.T\n    \n    idx = np.array([ 2,  3,  4,  5,  7,  8,  9, 11, 12, 13, 15, 16, 17, 18, 20, 21, 23,\n                     27, 32, 33, 37, 38, 40, 43, 45, 48, 51, 53, 54, 55, 56, 61, 62, 63,\n                     66, 67, 68, 69, 70, 71, 72, 77, 79, 80, 81, 83, 84, 88, 93, 94, 96,\n                     98, 99])\n    if return_idx:\n        return matrix[:, idx][idx, :], idx \n    return matrix[:, idx][idx, :]","738c033b":"degrees = []\nfor row in tqdm(fnc.iterrows()):\n    mat = get_matrix(row[1])\n    degrees.append(mat.sum(axis=1))","d7adf3c5":"_, idx = get_matrix(fnc.iloc[0], return_idx=True)\ndegrees = pd.DataFrame(degrees, columns=idx)\ndegrees['Id'] = fnc['Id']","278c9a78":"len(glob('\/kaggle\/input\/trends-assessment-prediction\/fMRI_train\/*.mat')), len(glob('\/kaggle\/input\/trends-assessment-prediction\/fMRI_test\/*.mat'))","e771b13e":"sbj = glob('\/kaggle\/input\/trends-assessment-prediction\/fMRI_train\/*.mat')[10]\n\nwith h5py.File(sbj, 'r') as f:\n    mat = f['SM_feature'][()]\n    mat = np.moveaxis(mat, [0,1,2,3], [3,2,1,0])\n    \nprint(mat.shape)","bfa42de7":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import GridSearchCV, KFold, cross_val_predict","be0cbc9a":"# train\/test Ids\ntrain_ids = sorted(loadings[loadings['Id'].isin(train_scores.Id)]['Id'].values)\ntest_ids = sorted(loadings[~loadings['Id'].isin(train_scores.Id)]['Id'].values)\n\n# generate test DataFrame\ntest_prediction = pd.DataFrame(test_ids, columns=['Id'], dtype=str)\n\ntarget_columns = ('age', 'domain1_var1', 'domain1_var2','domain2_var1','domain2_var2')\nfnc_columns = fnc.columns[1:]\ndegrees_columns = degrees.columns[:-1]\n\n# generate X, targets\ndata = pd.merge(loadings, train_scores, on='Id')#.dropna()\ndata = pd.merge(data, fnc, on='Id')\ndata = pd.merge(data, degrees, on='Id')\n\n# X_train = data.drop(list(target_columns), axis=1).drop('Id', axis=1)\n# y_train = data[list(target_columns)]\n\nX_test = pd.merge(loadings[loadings.Id.isin(test_ids)], fnc, on='Id')\nX_test = pd.merge(X_test, degrees, on='Id').drop('Id', axis=1)","6ed19765":"from sklearn.metrics import make_scorer\n\ndef MAPE(y_true, y_pred, **kwargs):\n    '''Returns MAPE between y_true and y_pred'''\n    return np.sum(np.abs(y_true - y_pred)) \/ y_true.sum()\n\nmape_scorer = make_scorer(MAPE, greater_is_better=False)","63aed28f":"# Setting up the model\n# model = RandomForestRegressor(\n#     max_depth=5,\n#     min_samples_split=10,\n#     min_samples_leaf=5\n# )\n\n# model = Lasso()\nmodel = Ridge()\n# model = SVR()\n\n\ncv = KFold(n_splits = 5, shuffle=True, random_state=29)\n\n# grid = {\n#     'max_depth':[2, 5, 10],\n#     'n_estimators':[20, 30],\n#     'max_features':[0.1, 0.2, 0.3, 0.5]\n# }\n\ngrid = {\n    'alpha': [0.0003, 0.001, 0.003, 0.01, 0.03]\n}\n# grid = {\n#     'C': [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 0.5, 0.85, 1, 3, 5, 10]\n# }\n\n# grid = {\n#     'alpha': np.linspace(0.0001, 0.001, 20)\n# }\ngs = GridSearchCV(model, grid, n_jobs=-1, cv=cv, verbose=0, scoring=mape_scorer)","4762f78e":"# age 0.1446\n\n# domain1_var1 0.1512\n\n# domain1_var2 0.1513\n\n# domain2_var1 0.1819\n\n# domain2_var2 0.1763","f844b80d":"# Training the model\nbest_models = {}\ntotal_score = []\n\nfor col in target_columns:\n    \n    X_train = data.dropna(subset=[col], axis=0).drop(list(target_columns), axis=1).drop('Id', axis=1)\n    X_train[fnc_columns] \/= 500\n    y_train = data.dropna(subset=[col], axis=0)[col]\n    \n    gs.fit(X_train, y_train)\n    best_models[col] = gs.best_estimator_\n    \n    # Train performance\n    y_pred = cross_val_predict(gs.best_estimator_, X_train, y_train, cv=cv, n_jobs=-1)\n    total_score.append(MAPE(y_train, y_pred))\n    print(col, MAPE(y_train, y_pred))\n\ntotal_score = np.array(total_score)\nprint(f'Total score: {np.sum(total_score*[.3, .175, .175, .175, .175])}')","9842beb9":"def get_pred(col, model):\n    X_train = data.dropna(subset=[col], axis=0).drop(list(target_columns), axis=1).drop('Id', axis=1)\n    X_train[fnc_columns] \/= 500\n    y_train = data.dropna(subset=[col], axis=0)[col]\n    \n    # Train performance\n    y_pred = cross_val_predict(model, X_train, y_train, cv=cv, n_jobs=-1)\n    return y_pred","e5726da6":"# Predicting test\nX_test[fnc_columns] \/= 500\n\nfor col in target_columns:\n    test_prediction[col] = best_models[col].predict(X_test)","be17a1cc":"# Evaluate the lb metric on local cv\n\n# def lb_metric(y_true, y_pred):\n#     '''Computes lb metric, both y_true and y_pred should be DataFrames of shape n x 5'''\n#     y_true = y_true[['age', 'domain1_var1', 'domain1_var2','domain2_var1','domain2_var2']]\n#     y_pred = y_pred[['age', 'domain1_var1', 'domain1_var2','domain2_var1','domain2_var2']]\n    \n#     weights = np.array([.3, .175, .175, .175, .175])\n#     return np.sum(weights * np.abs(y_pred.values - y_true.values).sum(axis=0) \/ y_train.values.sum(axis=0))","21aee2bf":"# train_prediction_cv = {}\n# for col in target_columns:\n#     train_prediction_cv[col] = cross_val_predict(best_models[col], X_train, y_train[col], cv = cv, n_jobs=-1)\n# train_prediction_cv = pd.DataFrame(train_prediction_cv)\n\n# lb_metric(y_train, train_prediction_cv)","b6509b0e":"def make_sub(test_prediction):\n    '''Converts 5877 x 6 DataFrame of predictions into 29385 x 2 DataFrame with valid Id'''\n    target_columns = ('age', 'domain1_var1', 'domain1_var2','domain2_var1','domain2_var2')\n    _columns = (0,1,2,3,4)\n    tst = test_prediction.rename(columns=dict(zip(target_columns, _columns)))\n    tst = tst.melt(id_vars='Id',\n           value_vars=_columns,\n           value_name='Predicted')\n\n    tst['target_type'] = tst.variable.map(dict(zip(_columns, target_columns)))\n    tst['Id_'] = tst[['Id', 'target_type']].apply(lambda x: '_'.join((str(x[0]), str(x[1]))), axis=1)\n\n    return tst.sort_values(by=['Id', 'variable'])\\\n              .drop(['Id', 'variable', 'target_type'],axis=1)\\\n              .rename(columns={'Id_':'Id'})\\\n              .reset_index(drop=True)\\\n              [['Id', 'Predicted']]","5eb1c046":"sub = make_sub(test_prediction)\n\nsub.head()","7e1671d9":"sub.to_csv('ridge_mape_500.csv', index=False)","f9714444":"# Build a model\n\nupd1. add mape_scorer\n\nupd2. add fnc to features\n\nupd3. add degrees features\n\nupd4. add fcn\/500 from https:\/\/www.kaggle.com\/aerdem4\/rapids-svm-on-trends-neuroimaging , switch to Ridge regression\n\ntodo: fit on all available targets (currently observation is dropped if any target is missing)","b43adfd9":"## Making a submission","760fb16c":"## Explore all csv","068e0c98":"# Exploring fnc","758788d0":"## Implement mape scorer\n\nSince lb uses weighted mape (all targets are > 0), we will implement mape scorer to pass into GridSearchCV"}}