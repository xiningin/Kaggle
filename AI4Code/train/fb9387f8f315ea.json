{"cell_type":{"57f5d828":"code","b4a12880":"code","91c16aab":"code","16290d80":"code","8ee788bc":"code","b7944042":"code","98b311f3":"code","d3116a3a":"code","aaf9b13b":"code","71c49198":"code","a1925987":"code","f92369ba":"code","42a2369b":"code","9c33580a":"code","7e960815":"code","fe489f7a":"code","580be7fd":"code","5218a7a5":"code","c345ff77":"code","9cc58f1d":"code","ef39e4a3":"code","e23886e8":"code","25bc6467":"code","17dba425":"code","e5a62060":"code","076402e7":"code","b8a84dd2":"code","be9e5862":"code","5558ec1c":"code","6eda2259":"code","479bea49":"code","3d81a494":"code","56af3700":"markdown","f5d29e4c":"markdown","0e319919":"markdown","c05fc7a1":"markdown","6274455f":"markdown","7146531c":"markdown","587497b4":"markdown","5955fd86":"markdown","7c333dde":"markdown","5714fe3d":"markdown","85fd89f4":"markdown","7e66df7a":"markdown","cadf2231":"markdown","f601e688":"markdown","73b0724d":"markdown","4ac3ff68":"markdown","35969f69":"markdown","dc5b58f7":"markdown","dfa18e14":"markdown","6b93c74c":"markdown","e5490c7c":"markdown","b0033bce":"markdown","17290595":"markdown","cf464c07":"markdown","417bcb91":"markdown","a8988e69":"markdown","3cb3e27f":"markdown","6d5f4ead":"markdown","20b54523":"markdown","fba7b108":"markdown","a747da22":"markdown","91fedfa7":"markdown","a5a9a0fc":"markdown","fc7b9c68":"markdown","97549435":"markdown","7bdb04ae":"markdown"},"source":{"57f5d828":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport pylab as plt\n\n# defini\u00e7\u00f5es para gr\u00e1ficos\nplt.rc('figure', figsize=(10, 5))\nfizsize_with_subplots = (10, 10)\nbin_size = 20\n\n# df_train \u00e9 o nosso dataframe com os dados de treinamento para constru\u00e7\u00e3o de nosso modelo.\ndf_train = pd.read_csv('..\/input\/lab2_train.csv')\ndf_train.head()","b4a12880":"## Lista as colunas e marca as que possuem algum valor nulo\nprint(df_train.isnull().any())\nprint()\n\n## Na informa\u00e7\u00e3o b\u00e1sica do dataframe, podemos ver o n\u00famero de valores n\u00e3o nulos de cada coluna.\nprint(df_train.info())","91c16aab":"## Cria um novo dataframe (df_train2) sem a coluna Cabin\ndf_train2 = df_train.drop('Cabin', axis=1)\ndf_train2.info()","16290d80":"media_idade = df_train2['Age'].mean()\nmediana_idade = df_train2['Age'].median()\n\nprint(media_idade)\nprint(mediana_idade)\n\ndf_train2['Age'].hist()\nplt.title('Idade')","8ee788bc":"## preenche os nulos com a m\u00e9dia das idades\ndf_train2['Age'].fillna(media_idade, inplace=True) ## O inplace altera no pr\u00f3prio dataframe em vez de termos de criar outro\ndf_train2['Age'].hist()\nplt.title('Idade')","b7944042":"# histograma s\u00f3 \u00e9 poss\u00edvel com valores num\u00e9ricos, mas Embarked \u00e9 categ\u00f3rico\ndf_train2['Embarked'].value_counts().plot(kind='bar', title='Porto de embarque') ","98b311f3":"df_train2['Embarked'].fillna('S', inplace=True)\ndf_train2.info()","d3116a3a":"df_train2.to_csv('lab2_train_no_nulls.csv', index=False)","aaf9b13b":"# Vamos carregar nossos dados j\u00e1 sem os nulos\ndf_train = pd.read_csv('lab2_train_no_nulls.csv')","71c49198":"df_train.describe()","a1925987":"print(df_train.sort_values('Age', ascending=False).head(5)['Age'])\nprint(df_train.sort_values('Age', ascending=True).head(5)['Age'])","f92369ba":"df_train.loc[df_train['Age']==133, 'Age'] = media_idade ## Aqui substituimos os valores de idade iguais a 133 pela m\u00e9dia","42a2369b":"print(df_train.sort_values('Fare', ascending=False).head(5)['Fare'])\nprint(df_train.sort_values('Fare', ascending=True).head(5)['Fare'])","9c33580a":"mediana_tarifa = df_train['Fare'].median()\ndf_train.loc[df_train['Fare']>5000, 'Fare'] = mediana_tarifa\ndf_train.loc[df_train['Fare']<0, 'Fare'] = mediana_tarifa","7e960815":"print(df_train.sort_values('Fare', ascending=False).head(5)['Fare'])\nprint(df_train.sort_values('Fare', ascending=True).head(5)['Fare'])","fe489f7a":"df_train.to_csv('train_no_nulls_no_outliers.csv', index=False)","580be7fd":"##Recarregando os dados da parte anterior...\ndf_train = pd.read_csv('train_no_nulls_no_outliers.csv')\ndf_train.head(2)","5218a7a5":"novas_colunas = pd.get_dummies(df_train['Embarked']) \ndf_train2 = pd.concat([df_train,novas_colunas], axis=1) # axis = 1 concatena colunas. axis = 0 concatena linhas\ndf_train2.head(3)","c345ff77":"df_train2.drop('Embarked', axis=1, inplace=True)","9cc58f1d":"novas_colunas_pclass = pd.get_dummies(df_train['Pclass']) \nnovas_colunas_sex = pd.get_dummies(df_train['Sex']) \n\ndf_train3 = pd.concat([df_train2,novas_colunas_pclass, novas_colunas_sex], axis=1)\ndf_train3.drop(['Pclass', 'Sex'], axis=1, inplace=True)\ndf_train3.head(3)","ef39e4a3":"df_train3.to_csv('train_no_nulls_no_outliers_ohe.csv', index=False)","e23886e8":"##Recarregando os dados da parte anterior, antes de fazer o OHE\ndf_train = pd.read_csv('train_no_nulls_no_outliers.csv')\ndf_train.head(2)","25bc6467":"import hashlib\n\ndef hashFunction(numero_colunas, dict_linha):\n    novas_features = [0]*numero_colunas # cria uma lista vazia com o tamanho pr\u00e9-determinado\n    \n    for coluna in dict_linha:\n        coluna_e_valor = (str(coluna) + str(dict_linha[coluna])).encode('utf-8')\n        posicao = int(int(hashlib.md5(coluna_e_valor).hexdigest(), 16) % numero_colunas) # calcula o hash\n        novas_features[posicao] += 1 # adiciona 1 na posi\u00e7\u00e3o onde caiu o hash\n\n    return novas_features","17dba425":"coluna_e_valor = 'Animal_Rato'.encode('utf-8')\nprint(int(hashlib.md5(coluna_e_valor).hexdigest(), 16))\n\n#int(int(hashlib.md5(coluna_e_valor).hexdigest(), 16) % numero_colunas)","e5a62060":"dict_categorias = df_train[['Sex', 'Embarked', 'Pclass']].T.to_dict()\nprint(dict_categorias.get(0))\nprint(dict_categorias.get(1))","076402e7":"num_colunas = 4\nfor i in range(num_colunas):\n    print(hashFunction(num_colunas, dict_categorias[i]))","b8a84dd2":"num_colunas = 5\n\nnovas_colunas = []\nfor dict_ in dict_categorias.values():\n    novas_colunas.append(hashFunction(num_colunas, dict_))\n    \n# convertemos nossa lista em dataframe nomeando as colunas como h0, h1, h2 ... hn\nnovas_colunas = pd.DataFrame(novas_colunas, columns=['h'+str(i) for i in range(num_colunas)]) \nnovas_colunas.head()","be9e5862":"df_train2 = pd.concat([df_train,novas_colunas], axis=1)\ndf_train2.head()","5558ec1c":"df_train2.to_csv('train_no_nulls_no_outliers_feat_hash.csv', index=False)","6eda2259":"## recarregando nossos dados\ndf_train = pd.read_csv('train_no_nulls_no_outliers_feat_hash.csv')\ndf_train.head(2)","479bea49":"from sklearn import preprocessing\n\n## dados originais\nage_original = df_train['Age'].values.reshape(-1, 1)\n## Normaliza os dados\nage_standard = preprocessing.StandardScaler().fit_transform(df_train['Age'].values.reshape(-1, 1)) \n## Muda a escala dos dados para valores entre 0 e 1 (valores padr\u00e3o, que poderiam ser personalizados)\nage_minmax = preprocessing.MinMaxScaler().fit_transform(df_train['Age'].values.reshape(-1, 1))","3d81a494":"from matplotlib import pyplot as plt\n\ndef plot():\n    plt.figure(figsize=(8,6))\n\n    plt.scatter([0]*len(age_original), age_original,\n            color='green', label='Original', alpha=0.5)\n\n    plt.scatter([1]*len(age_original), age_standard, color='red',\n            label='Normalizado', alpha=0.3)\n\n    plt.scatter([2]*len(age_original), age_minmax,\n            color='blue', label='escala entre [min=0, max=1]', alpha=0.3)\n\n    plt.xlabel('Idade')\n    plt.ylabel('Idade')\n    plt.legend(loc='upper left')\n    plt.grid()\n\n    plt.tight_layout()\n\nplot()\nplt.show()","56af3700":"Aqui confirmamos o valor negativo e um valor 10x do bilhete mais caro para o segundo mais caro. Vamos trat\u00e1-los como erros e atualiz\u00e1-los com o valor da mediana da tarifa. Usaremos a mediana em vez da m\u00e9dia, pois ela \u00e9 menos sens\u00edvel aos outliers.","f5d29e4c":"As colunas que nos interessam s\u00e3o `Age`, `SibSP`, `Parch` e `Fare`, pois as demais s\u00e3o categ\u00f3ricas ou apenas o ID do passageiro. Olhando as 4 colunas, podemos ver algumas coisas incomuns:\n\n* A menor tarifa \u00e9 negativa (o que \u00e9 provavelmente um erro) e a maior \u00e9 um n\u00famero 10x maior que o Terceiro Quartil (75% percentil)\n* H\u00e1 algu\u00e9m com idade 133 anos. Hoje j\u00e1 parece improv\u00e1vel (ver <a href=\"https:\/\/pt.wikipedia.org\/wiki\/Lista_das_pessoas_mais_velhas_do_mundo\">esse<\/a> verbete da wikipedia). Na \u00e9poca do desastre, deve se tratar tamb\u00e9m de um outlier (ou erro).\n\nA discuss\u00e3o sobre outliers \u00e9 subjetiva. Sem o conhecimento do dom\u00ednio do problema (como fizemos com a idade), \u00e9 muito dif\u00edcil dizer o que \u00e9 um outlier. Mas para fins did\u00e1ticos, vamos tratar aqui as anomalias como erros nos dados e vamos remov\u00ea-los trocando pelo valor m\u00e9dio.\n\nPrimeiro, vamos mostrar os 5 maiores e 5 menores idades.","0e319919":"Agora vamos usar nossa fun\u00e7\u00e3o. Para isso, primeiro precisamos converter nossos dados em uma lista de dicion\u00e1rios. O m\u00e9todo <a href=\"http:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.DataFrame.to_dict.html\">pd.to_dict()<\/a> retorna os dados no formato:\n<pre>[{'Embarked': {0: 'S', 1: 'C'}}, {'Pclass' : {0:3, 1:1}}, {'Sex': {0:'male', 1:'female'}}] <\/pre>\nou seja, cria um dicion\u00e1rio para cada coluna e n\u00f3s queremos um dicion\u00e1rio para cada linha. Logo, vamos transpor o dataframe para obter no formato que queremos:","c05fc7a1":"E agora convertendo todos os dados e anexando-os no nosso data frame","6274455f":"Agora vamos fazer o mesmo para as colunas `PClass` e `Sex`","7146531c":"Fazendo um pequeno teste","587497b4":"Nessa primeira etapa vamos analisar e elaborar estrat\u00e9gias de remo\u00e7\u00e3o de valores nulos em nossos dados. O primeiro passo \u00e9 ver quais colunas possuem nulos, o que pode ser feito de duas formas:","5955fd86":"Conferindo a remo\u00e7\u00e3o dos outliers","7c333dde":"Como a m\u00e9dia e mediana s\u00e3o muito pr\u00f3ximos, a diferen\u00e7a ser\u00e1 m\u00ednima. Ent\u00e3o, vamos trocar os nulos pela m\u00e9dia e depois gerar novo histograma de idades.","5714fe3d":"### Parte 3.2 - Feature Hashing","85fd89f4":"## Parte 2 - Remo\u00e7\u00e3o de outliers","7e66df7a":"Nessa parte do laborat\u00f3rio vamos exercitar a remo\u00e7\u00e3o de outliers. Vale ressaltar que os dados originais foram modificados para incluir ocorr\u00eancias incomuns em alguns atributos.\n\nO primeiro passo para identificar outliers \u00e9 ver uma breve descri\u00e7\u00e3o dos dados num\u00e9ricos.","cadf2231":"### Carregando nossos dados","f601e688":"Agora vamos salvar nosso data frame com os dados categ\u00f3ricos convertidos usando OHE.","73b0724d":"Como podemos ver, o formato do histograma se modifica completamente, mas essa ser\u00e1 nossa op\u00e7\u00e3o para essa coluna. Por \u00faltimo vamos analisar a coluna Embarked, que tem poucos valores nulos. Vamos gerar um histograma:","4ac3ff68":"Agora vamos fazer o mesmo para o campo tarifa:","35969f69":"No caso da coluna idade, podemos notar que apenas o valor 133 parece fora da normalidade. Vamos troc\u00e1-lo pelo valor m\u00e9dio das idades, que j\u00e1 calculamos na Parte 1.","dc5b58f7":"Por fim vamos salvar nossos dados","dfa18e14":"Pronto. Agora nossos dados n\u00e3o cont\u00e9m nulos. Vamos salv\u00e1-los para recuperar posteriormente.","6b93c74c":"Agora podemos remover a coluna original dos nossos dados.","e5490c7c":"Por \u00faltimo, vamos exercitar a normaliza\u00e7\u00e3o e *Feature Scaling* dos dados. Nessa t\u00e9cnica, ajustamos os dados num\u00e9ricos para que todos fiquem na mesma escala, melhorando a efici\u00eancia do uso de diversos algoritmos de aprendizado de m\u00e1quina. Nessa <a href=\"https:\/\/en.wikipedia.org\/wiki\/Feature_scaling\">entrada<\/a> da wikipedia tem uma descri\u00e7\u00e3o desses m\u00e9todos e <a href=\"http:\/\/sebastianraschka.com\/Articles\/2014_about_feature_scaling.html\">nesse blog<\/a> tem uma explica\u00e7\u00e3o da import\u00e2ncia.","b0033bce":"Como observado acima, temos 891 registros ao todo. As colunas `Age`, `Cabin` e `Embarked` s\u00e3o as que possuem valores nulos.\n\nO caso da coluna `Cabin` \u00e9 o mais cr\u00edtico, pois ele possui apenas 22% de dados preenchidos (provavelmente apenas pessoas da primeira classe) e essa informa\u00e7\u00e3o pode n\u00e3o ser muito \u00fatil. Nesse caso, vamos simplesmente remover a coluna de nossos dados. \n\n*Obs: essa \u00e9 uma op\u00e7\u00e3o apenas para exercitar as possibilidades de forma did\u00e1tica. V\u00e1rios algoritmos podem se beneficiar da informa\u00e7\u00e3o da cabine, mesmo com poucos exemplos.*","17290595":"N\u00e3o faremos o tratamento de todos nossos dados num\u00e9ricos aqui, mas apenas demonstraremos o funcionamento desses m\u00e9todos na coluna Idade (`Age`).","cf464c07":"Nessa parte do laborat\u00f3rio vamos exercitar algumas tarefas comuns na atividade de *Feature Engineering*, que consiste em remodelar atributos para obter melhor(?) desempenho nos algoritmos. Entre as tarefas faremos convers\u00e3o de categorias usando OHE (*one-hot-encoding*) e *Feature Hashing*, e tamb\u00e9m a produ\u00e7\u00e3o de novas colunas calculadas com base em outras.\n\nN\u00e3o h\u00e1 uma \"receita de bolo\" para essas atividades. \u00c9 sempre uma quest\u00e3o de experimenta\u00e7\u00e3o e ver quais modelos s\u00e3o melhores que outros. ","417bcb91":"> ### Parte 3.3 - Normaliza\u00e7\u00e3o e *Feature Scaling* dos dados","a8988e69":"Abaixo vamos criar nossa fun\u00e7\u00e3o de Hash que converte um dicion\u00e1rio no formato:\n<pre>{Sex: 'male', Pclass: 3, Embarked: 'S'}<\/pre>\ne converte numa lista de tamanho fixo usando Feature Hashing.","3cb3e27f":"# Laborat\u00f3rio 2 - Limpeza e tratamento de dados","6d5f4ead":"Nesse laborat\u00f3rio vamos fazer alguns tratamentos de dados do nosso estudo de caso do Titanic. Esse laborat\u00f3rio est\u00e1 dividido da seguinte forma:\n\n* Parte 1 - Remo\u00e7\u00e3o de Nulos\n* Parte 2 - Remo\u00e7\u00e3o de outliers\n* Parte 3 - *Feature Engineering*\n\nApenas para relembrar, aqui est\u00e3o nossos atributos (*features*)\n<pre>\nsurvival        Sobreviveu ao acidente?\n                (0 = N\u00e3o; 1 = Sim)\npclass          Classe do passageiro\n                (1 = primeira classe; 2 = segunda classe; 3 = terceira classe)\nname            Nome\nsex             G\u00eanero\nage             Idade\nsibsp           Soma do n\u00famero irm\u00e3os + cunhados + c\u00f4njuge\nparch           Soma do n\u00famero pais + filhos\nticket          N\u00famero da passagem\nfare            Valor da passagem\ncabin           N\u00famero da cabine\nembarked        Porto de embarque\n                (C = Cherbourg; Q = Queenstown; S = Southampton)\n<\/pre>","20b54523":"Por fim, vamos salvar nosso trabalho","fba7b108":"### Parte 3.1 - OHE (*One-hot-encoding*)","a747da22":"A t\u00e9cnica de Feature Hashing \u00e9 semelhante \u00e0 OHE, mas ela limita o n\u00famero de colunas para um tamanho fixo, usando uma fun\u00e7\u00e3o de Hash para definir em qual das N colunas vai \"cair\" uma determinada categoria de uma coluna. Com isso, podem haver colis\u00f5es, mas espera-se que elas sejam poucas e h\u00e1 evid\u00eancias emp\u00edricas de que o desempenho \u00e9 pouco afetado comparando com OHE, mas temos uma economia de espa\u00e7o de mem\u00f3ria e de tempo de processamento com o Feature Hashing.\n\nNessa parte do laborat\u00f3rio vamos fazer Feature Hashing para as mesmas tr\u00eas colunas da etapa anterior: `Sex`, `Pclass`, `Embarked`.","91fedfa7":"## Parte 1 - Remo\u00e7\u00e3o de nulos","a5a9a0fc":"Agora vamos analisar a coluna idade. Temos duas op\u00e7\u00f5es:\n* Trocar nulo por um valor (m\u00e9dia ou mediana)\n* Ignorar\n\nA segunda op\u00e7\u00e3o limita o uso de alguns algoritmos, mas a primeira tamb\u00e9m tem seus problemas. Vamos analisar a primeira op\u00e7\u00e3o e para isso vamos calcular a m\u00e9dia e a mediana das idades e ver o histograma dos dados originais.","fc7b9c68":"## Parte 3 - *Feature Engineering*","97549435":"A t\u00e9cnica de One-hot-encoding \u00e9 utilizada para converter dados que s\u00e3o categ\u00f3ricos em num\u00e9ricos de forma a n\u00e3o influenciar de forma equivocada alguns algoritmos. Converter cada valor poss\u00edvel para a coluna em n\u00fameros de 1 a N implicaria em haver uma rela\u00e7\u00e3o fixa de dist\u00e2ncia geom\u00e9trica entre os dados, o que normalmente n\u00e3o ocorre.\n\nA convers\u00e3o funciona de forma bem simples: para cada categoria em uma determinada coluna, \u00e9 criada uma nova coluna onde o valor ser\u00e1 1 quando a linha tiver aquele valor para a categoria ou 0 caso contr\u00e1rio. Na figura abaixo h\u00e1 um exemplo:\n\n<img src=\"..\/input\/ohe.png\" align=\"center\">\n\nO c\u00f3digo abaixo usa o m\u00e9todo get_dummies da biblioteca pandas para criar 3 novas colunas para cada um dos 3 valores poss\u00edveis para a coluna `Embarked`.","7bdb04ae":"Como podemos ver no gr\u00e1fico, a grande maioria dos passageiros embarcaram no porto de Southampton (S), ent\u00e3o vamos, nesse caso, atribuir os valores faltantes para o valor mais comum:"}}