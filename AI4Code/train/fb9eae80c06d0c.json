{"cell_type":{"7d0ee4f2":"code","a20ed7d7":"code","8a03d017":"code","d02c80b6":"code","cd3b7a2d":"code","1698fcda":"code","cab2d1ac":"code","3404f49e":"code","00fed3c4":"code","fbe9f701":"code","551cb680":"code","7fb74d86":"code","d774be22":"code","6ec2a29b":"code","5bb7a6ac":"code","84518966":"code","61704e4d":"code","d146d0a0":"code","4c562769":"code","c5b1b7f4":"code","6d094a61":"code","84d856d1":"code","912c9d27":"code","7c98933e":"code","80a374d5":"code","680a5e98":"code","77e6e994":"code","10b778df":"code","ba255a16":"code","244ff707":"code","c68d3d7c":"code","6e3d9278":"code","807b2fc4":"code","81b29e9f":"code","da64de17":"code","8c21b0fe":"code","ee866759":"code","97e4a0e7":"code","6887584d":"code","1b614009":"code","3221dd00":"code","0119ec0c":"code","3e5053ba":"code","bb636ef3":"code","4125b98f":"code","e3541bdc":"code","a81887a3":"code","e114ee0b":"code","e8eb645e":"code","3a4b8786":"code","22e8c86a":"code","37062efd":"code","e1a6a56b":"code","b7e5f877":"code","b552a0f9":"code","25f1b292":"code","ebed749c":"code","d7b479a0":"code","c0139085":"code","c021c21c":"code","332f26ea":"code","b5506b84":"code","171f11a0":"code","eb14c652":"code","88702175":"code","db23fdb1":"code","da0f32a1":"code","4a292f23":"code","52755623":"code","13cd6e37":"code","5289db85":"code","e64af662":"code","c74b4f96":"code","028f3f14":"code","77eaf814":"code","2052acde":"code","a9ab6165":"code","0972bd1f":"code","bba3c8b2":"code","7599be35":"code","a57b4365":"code","8ab4dc96":"code","7bd71de1":"code","55a94489":"code","b628c76a":"code","a16f9a03":"code","c9d61cef":"code","252da39f":"code","5ea06f79":"code","854d7b2f":"code","4ae09685":"code","a3781ee1":"code","31fc95d0":"code","fc531a6a":"code","e5c14fd1":"code","56074f8d":"code","19128509":"code","7be9c9f9":"code","0c813f2d":"code","9cccdc60":"code","fe136d88":"code","7706f2b5":"code","7088c8a2":"code","165aeda2":"code","f7afb4a8":"code","572ee35b":"code","4c327c10":"code","ef4f72f0":"code","a5dbdb4c":"code","8a7bf4c1":"code","80d6d311":"code","58c737b6":"code","ec9a5bab":"code","73a29214":"code","c5cfac4a":"code","67a154b0":"code","6915e81c":"code","b5697e1e":"code","4b214540":"code","a2855355":"code","d91e27fc":"code","b4a5d7ad":"code","9387f480":"code","bf0f3cdd":"code","c9c2ef31":"code","307255bc":"code","423c9114":"code","5a2b2ece":"code","cf46ff83":"code","fd96f237":"code","f508a330":"code","a39d08ab":"code","dd7b5568":"code","947645ac":"code","ac693bb9":"code","d22265b9":"code","ccba1ede":"code","e59e6850":"code","35d5c142":"code","78ca50ce":"code","9cf2018b":"code","491a5a43":"code","fe4919ad":"code","1103699b":"code","b8b7bc7a":"code","3e74f5e7":"code","c9e36da0":"code","8b7cdec9":"code","baadaddb":"code","e88bd4e8":"code","7b8a9f41":"code","fcf2d65b":"code","39be84a6":"code","5ca3366a":"code","0f9b7250":"code","babccff4":"code","c385fc7b":"code","bb12b9a3":"markdown","8d659c45":"markdown","0e520172":"markdown","90f56f7e":"markdown","22d11793":"markdown","d55434bb":"markdown","66f1a626":"markdown","568c07e5":"markdown","a4518952":"markdown","e541950c":"markdown","df5b98a1":"markdown","68e8436c":"markdown"},"source":{"7d0ee4f2":"import pandas as pd\nimport numpy as np\nimport io\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\nimport scipy\nfrom scipy.fftpack import fftshift\nfrom matplotlib import style\nimport missingno as msno\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# warnings.filterwarnings('always')\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom sklearn.preprocessing import KBinsDiscretizer\nplt.style.use(\"bmh\")\nsns.set(style='whitegrid',color_codes=True)\n%matplotlib inline\nfrom sklearn.decomposition import PCA\n\nfrom scipy.stats import spearmanr, kendalltau\nimport missingno as msno\nimport os\nimport joblib\nimport tarfile\nimport urllib\n\n\n# classifiaction.\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC,SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, StackingClassifier,GradientBoostingClassifier,BaggingClassifier,AdaBoostClassifier,ExtraTreesClassifier,StackingClassifier\n# HistGradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.tree import plot_tree\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.naive_bayes import BernoulliNB,GaussianNB,MultinomialNB\n# #regression\n# from sklearn.svm import SVR\n# from sklearn.neighbors import KNeighborsRegressor\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.tree import DecisionTreeRegressor\n# from xgboost import XGBRegressor\n# from catboost import CatBoostRegressor\n# from lightgbm import LGBMRegressor\n# from sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor\n# from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet,RidgeCV\n\n#model selection\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, KFold, train_test_split, cross_validate\n\n# #evaluation metrics\n# from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error # for regression\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score, plot_confusion_matrix, classification_report  # for classification\n\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, roc_curve, classification_report, confusion_matrix, accuracy_score, make_scorer\n\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\n\n# Preprocessing & Imputing\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\n\n# Validating and Tuning\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit \nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\nfrom sklearn.metrics import roc_curve, auc,roc_auc_score\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.multiclass import OneVsRestClassifier\n\nfrom tpot import TPOTClassifier\n\nfrom sklearn.metrics import classification_report, confusion_matrix  \n# #model selection\n# from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, KFold, train_test_split, cross_validate\n\n# #evaluation metrics\n# from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error # for regression\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score  # for classification\n\nfrom sklearn import metrics\n\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier","a20ed7d7":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndf=train.copy()\n\ndf.info()","8a03d017":"test.info()","d02c80b6":"df.head()","cd3b7a2d":"df.Embarked.value_counts()","1698fcda":"df.Parch.value_counts()","cab2d1ac":"df.SibSp.value_counts()","3404f49e":"df.Survived.value_counts()","00fed3c4":"df.Pclass.value_counts()","fbe9f701":"df.Sex.value_counts()","551cb680":"df.describe()","7fb74d86":"df.describe(include='O')","d774be22":"sns.heatmap(df.isnull(), cmap='viridis', cbar=False, yticklabels=False)","6ec2a29b":"df.Age.isna().sum()","5bb7a6ac":"df.Cabin.isna().sum()","84518966":"df.Embarked.isna().sum()","61704e4d":"def check_missing_values(df, df_name=None):\n    print(f'{df_name} - Missing values:')\n    print('-'*30)\n    columns = df.columns\n\n    for column in columns:\n        count_missing_values = df[column].isnull().sum()\n        missing_values = (count_missing_values \/ len(df[column])) * 100\n    \n        if missing_values !=0:\n            print(f'{column} --> {count_missing_values} values | {missing_values:.2f}%')","d146d0a0":"check_missing_values(df,'train')","4c562769":"check_missing_values(test,'test')","c5b1b7f4":"df[df.Age.isna()]","6d094a61":"df[df.Embarked.isna()]","84d856d1":"for i,cat in enumerate(df[['Survived', 'Pclass', 'Sex', 'Parch', 'SibSp', 'Embarked']]):\n    val_counts = df[cat].value_counts()\n    dominant_frac = val_counts.iloc[0:7] \/ len(df)\n    print(f'`{val_counts.index[0]}` alone contributes to {round(dominant_frac * 100, 2)}% of {cat}')\n    print('----------------------------------')","912c9d27":"df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","7c98933e":"df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","80a374d5":"df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","680a5e98":"df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","77e6e994":"df[[\"Embarked\", \"Survived\"]].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","10b778df":"g = sns.FacetGrid(df, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","ba255a16":"df['numeric_ticket'] = df.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\ndf['ticket_letters'] = df.Ticket.apply(lambda x: ''.join(x.split(' ')[:-1])\\\n.replace('.','').replace('\/','').lower() if len(x.split(' ')[:-1]) >0 else 0)","244ff707":"test['numeric_ticket'] = test.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\ntest['ticket_letters'] = test.Ticket.apply(lambda x: ''.join(x.split(' ')[:-1])\\\n.replace('.','').replace('\/','').lower() if len(x.split(' ')[:-1]) >0 else 0)","c68d3d7c":"df['numeric_ticket'].value_counts()","6e3d9278":"test['numeric_ticket'].value_counts()","807b2fc4":"df['ticket_letters'].value_counts()","81b29e9f":"pd.pivot_table(df,index='Survived',columns='numeric_ticket', values = 'Ticket', aggfunc='count')","da64de17":"pd.pivot_table(df,index='Survived',columns='ticket_letters', values = 'Ticket', aggfunc='count')","8c21b0fe":"df['cabin_multiple'] = df.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split(' ')))\ndf['cabin_adv'] = df.Cabin.apply(lambda x: str(x)[0])\ndf['numeric_ticket'] = df.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\ndf['ticket_letters'] = df.Ticket.apply(lambda x: ''.join(x.split(' ')[:-1]).replace('.','').replace('\/','').lower() if len(x.split(' ')[:-1]) >0 else 0)\ndf['name_title'] = df.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())","ee866759":"test['cabin_multiple'] = test.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split(' ')))\ntest['cabin_adv'] = test.Cabin.apply(lambda x: str(x)[0])\ntest['numeric_ticket'] = test.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\ntest['ticket_letters'] = test.Ticket.apply(lambda x: ''.join(x.split(' ')[:-1]).replace('.','').replace('\/','').lower() if len(x.split(' ')[:-1]) >0 else 0)\ntest['name_title'] = test.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())","97e4a0e7":"df['norm_sibsp'] = np.log(df.SibSp+1)\ndf['norm_Parch'] = np.log(df.Parch+1)\n\ndf['norm_fare'] = np.log(df.Fare+1)","6887584d":"test['norm_sibsp'] = np.log(test.SibSp+1)\ntest['norm_Parch'] = np.log(test.Parch+1)\n\n# test['norm_fare'] = np.log(test.Fare+1)","1b614009":"df.drop(['PassengerId', 'Cabin', 'Ticket'], axis=1, inplace=True)\ntest.drop(['Cabin', 'Ticket'], axis=1, inplace=True)","3221dd00":"df.hist(bins=15, figsize=(10, 7))\nplt.tight_layout()","0119ec0c":"fig, axes = plt.subplots(1, 4, figsize=(20,5))\n\nsns.distplot(df['Age'].dropna(), kde=False, bins=30, ax=axes[0])\naxes[0].set_title('Age Distribution overall')\n\nsns.distplot(df[df['Sex']=='male']['Age'].dropna(),\n             kde=False, color='blue', bins=30, ax=axes[1])\naxes[1].set_title('Age Distribution (Male)')\n\nsns.distplot(df[df['Sex']=='female']['Age'].dropna(),\n             kde=False, color='orange', bins=30, ax=axes[2])\naxes[2].set_title('Age Distribution (Female)')\n\nsns.kdeplot(df[df['Sex']=='male']['Age'].dropna(),\n            color='blue', ax=axes[3])\nsns.kdeplot(df[df['Sex']=='female']['Age'].dropna(),\n            color='orange', ax=axes[3])","3e5053ba":"fig, axes = plt.subplots(1, 2, figsize=(12,5))\n\nsns.countplot(x='Sex', data=df, ax=axes[0])\naxes[0].set_title('Number of males and females')\n\nsns.countplot(x='Sex', hue='Survived', data=df, ax=axes[1], palette='Set3')\naxes[1].set_title('Survival by sex')\naxes[1].set_ylabel('')","bb636ef3":"fig, axes = plt.subplots(1, 3, figsize=(16,5))\n\nsns.countplot(x='Pclass', data=df, ax=axes[0], palette='Set1')\naxes[0].set_title('Number of people in each Pclass')\n\nsns.countplot(x='Pclass', hue='Sex', data=df, ax=axes[1])\naxes[1].set_title('Sex by Pclass')\naxes[1].set_ylabel('')\n\nsns.countplot(x='Pclass', hue='Survived', data=df, ax=axes[2], palette='Set3')\naxes[2].set_title('Survival by Pclass')\naxes[2].set_ylabel('')\n\nplt.tight_layout()","4125b98f":"grid = sns.FacetGrid(df, col='Pclass', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Embarked', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","e3541bdc":"grid = sns.FacetGrid(df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","a81887a3":"fig, axes = plt.subplots(1, 3, figsize=(16,5))\n\nsns.countplot(x='Embarked', data=df, ax=axes[0], palette='Set1')\naxes[0].set_title('Number of people in each Embarkation')\n\nsns.countplot(x='Embarked', hue='Sex', data=df, ax=axes[1])\naxes[1].set_title('Sex by Embarcation')\naxes[1].set_ylabel('')\n\nsns.countplot(x='Embarked', hue='Survived', data=df, ax=axes[2], palette='Set3')\naxes[2].set_title('Survival by Embarcation')\naxes[2].set_ylabel('')\n\nplt.tight_layout()","e114ee0b":"grid = sns.FacetGrid(df, col='Embarked', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","e8eb645e":"grid = sns.FacetGrid(df, row='Embarked', col='Survived', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","3a4b8786":"fig, axes = plt.subplots(1, 3, figsize=(14,5))\n\nsns.pointplot(x ='Sex', y=\"Survived\", data=df, ax=axes[0])\naxes[0].set_title('Survival by Sex')\n\nsns.pointplot(x ='Pclass', y=\"Survived\", data=df, ax=axes[1])\naxes[1].set_title('Survival by Pclass')\naxes[1].set_ylabel('')\n\nsns.pointplot(x ='Embarked', y=\"Survived\", data=df, ax=axes[2])\naxes[2].set_title('Survival by Embarkation')\naxes[2].set_ylabel('')\n\nfor ax in axes:\n    ax.set_yticks(np.arange(0, 1.1, 0.1))\n\nplt.tight_layout()","22e8c86a":"def tukey_outliers(x):\n    q1 = np.percentile(x,25)\n    q3 = np.percentile(x,75)\n    \n    iqr = q3-q1\n    \n    min_range = q1 - iqr*1.5\n    max_range = q3 + iqr*1.5\n    \n    outliers = x[(x<min_range) | (x>max_range)]\n    return outliers","37062efd":"nums = ['Age', 'Fare']\n\nfor col in nums:\n    outliers = tukey_outliers(df[col])\n    if len(outliers):\n        print(f\"* {col} has these tukey outliers,\\n{outliers}\\n\")\n    else:\n        print(f\"* {col} doesn't have any tukey outliers.\\n\")","e1a6a56b":"sns.boxplot(x='Survived', y='Age', data=df, palette='Set3')\nplt.title('Survival by Age')","b7e5f877":"fig, axes = plt.subplots(1,2)\nplt.tight_layout(0.2)\n\nprint(\"Before Shape:\",df.shape)\n## Removing humidity bellow 0 outliers\ndf2 = df[(df['Age']<66)]\nprint(\"After Shape:\",df2.shape)\n\nsns.boxplot(df['Age'],orient='v',ax=axes[0])\naxes[0].title.set_text(\"Before\")\nsns.boxplot(df2['Age'],orient='v',ax=axes[1])\naxes[1].title.set_text(\"After\")\nplt.show()\n# Replace new dataset with previous and resetting indexes\n# df=df2;\n# df=df.reset_index(drop=True)","b552a0f9":"sns.boxplot(x='Survived', y='Fare', data=df)\nplt.title('Survival by Fare')","25f1b292":"fig, axes = plt.subplots(1,2)\nplt.tight_layout(0.2)\n\nprint(\"Before Shape:\",df.shape)\n## Removing humidity bellow 0 outliers\ndf2 = df[(df['Fare']<46)]\nprint(\"After Shape:\",df2.shape)\n\nsns.boxplot(df['Fare'],orient='v',ax=axes[0])\naxes[0].title.set_text(\"Before\")\nsns.boxplot(df2['Fare'],orient='v',ax=axes[1])\naxes[1].title.set_text(\"After\")\nplt.show()\n# Replace new dataset with previous and resetting indexes\n# df=df2;\n# df=df.reset_index(drop=True)","ebed749c":"df.corr()['Survived']","d7b479a0":"plt.figure(figsize=(8,8))\n\nsns.heatmap(df.corr(), annot=True, cmap='magma', square=True,\n            linecolor=\"white\", linewidths=0.1)\nplt.title('Correlations between variables')","c0139085":"df['Familysize'] = df['SibSp'] + df['Parch']+1\ntest['Familysize'] = test['SibSp'] + test['Parch']+1\n\ndf[[\"Familysize\", \"Survived\"]].groupby(['Familysize'], as_index=False)\\\n.mean().sort_values(by='Survived', ascending=False)","c021c21c":"df['Alone'] = df['Familysize'].apply(lambda x: 1 if x == 0 else 0)\n\ntest['Alone'] = test['Familysize'].apply(lambda x: 1 if x == 0 else 0)","332f26ea":"df[df['Embarked'].isnull()]","b5506b84":"fig, axes = plt.subplots(2, 2, figsize=(16,8))\n\nsns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Pclass\", data=df, ax=axes[0,0])\n\nsns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Sex\", data=df, ax=axes[0,1])\n\nsns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Survived\", data=df, ax=axes[1,0])\n\nsns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Alone\", data=df, ax=axes[1,1])\n\nplt.tight_layout()","171f11a0":"df['Embarked'].fillna('C',inplace=True)","eb14c652":"test.hist(column='Fare')","88702175":"test.Fare.median()","db23fdb1":"# test.Fare.value_counts()","da0f32a1":"test.Fare.replace(np.nan,test.Fare.median(),inplace=True)\n\ntest['norm_fare'] = np.log(test.Fare+1)","4a292f23":"plt.figure(figsize=(12, 7))\n\ntestPlot = sns.boxplot(x='Pclass', y='Age', hue='Sex', data=df)\n\nm1 = df.groupby(['Pclass', 'Sex'])['Age'].median().values\nmL1 = [str(np.round(s, 2)) for s in m1]\n\nind = 0\nfor tick in range(len(testPlot.get_xticklabels())):\n    testPlot.text(tick-.2, m1[ind+1]+1, mL1[ind+1],  horizontalalignment='center',  color='w', weight='semibold')\n    testPlot.text(tick+.2, m1[ind]+1, mL1[ind], horizontalalignment='center', color='w', weight='semibold')\n    ind += 2","52755623":"m1[0+1]+1","13cd6e37":"m1[0]+1","5289db85":"m1","e64af662":"def get_age(cols):\n    age = cols[0]\n    pclass = cols[1]\n    sex = cols[2]\n    \n    if pd.isnull(age):\n\n        if pclass == 1:\n            if sex == 'male':\n                return 40\n            else:\n                return 35\n\n        elif pclass == 2:\n            if sex == 'male':\n                return 30\n            else:\n                return 28\n\n        else:\n            if sex == 'male':\n                return 25\n            else:\n                return 21.5\n            \n    else:\n        return age","c74b4f96":"df['Age'] = df[['Age','Pclass', 'Sex']].apply(get_age, axis=1)","028f3f14":"test['Age'] = test[['Age','Pclass', 'Sex']].apply(get_age, axis=1)","77eaf814":"def get_title(name):\n    for string in name.split():\n        if '.' in string:\n            return string[:-1]","2052acde":"df['Title'] = df['Name'].apply(lambda x: get_title(x))\n\ntest['Title'] = test['Name'].apply(lambda x: get_title(x))","a9ab6165":"df.Title.value_counts()","0972bd1f":"df.Name[10].split()","bba3c8b2":"df.drop('Name', axis=1, inplace=True)\n\ntest.drop('Name', axis=1, inplace=True)","7599be35":"# ['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n#        'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'Countess',\n#        'Jonkheer']","a57b4365":"df['Title'] = df['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', \n                                             'Major', 'Rev', 'Sir', 'Dona', 'Countess', 'Jonkheer'], 'Other')\n\ndf['Title'] = df['Title'].replace('Mlle', 'Miss')\ndf['Title'] = df['Title'].replace('Ms', 'Miss')\ndf['Title'] = df['Title'].replace('Mme', 'Mrs')","8ab4dc96":"test['Title'] = test['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', \n                                             'Major', 'Rev', 'Sir', 'Dona', 'Countess', 'Jonkheer'], 'Other')\n\ntest['Title'] = test['Title'].replace('Mlle', 'Miss')\ntest['Title'] = test['Title'].replace('Ms', 'Miss')\ntest['Title'] = test['Title'].replace('Mme', 'Mrs')","7bd71de1":"df.Title.value_counts()","55a94489":"df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","b628c76a":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Other\": 5}\ndf['Title_num'] = df['Title'].map(title_mapping)\ndf['Title_num'] = df['Title_num'].fillna(0)\n\ntest['Title_num'] = test['Title'].map(title_mapping)\ntest['Title_num'] = test['Title_num'].fillna(0)","a16f9a03":"df.Title_num.value_counts()","c9d61cef":"df['Sex_num'] = df['Sex'].replace( {'female': 0, 'male': 1})\n\ntest['Sex_num'] = test['Sex'].replace( {'female': 0, 'male': 1})","252da39f":"df['Embarked_num'] = df['Embarked'].replace( {'S': -1, 'Q': 0, 'C': 1})\n\ntest['Embarked_num'] = df['Embarked'].replace( {'S': -1, 'Q': 0, 'C': 1})","5ea06f79":"df['Pclass_num'] = df['Pclass'].replace( {1: -1, 2: 0, 3: 1})\n\ntest['Pclass_num'] = test['Pclass'].replace( {1: -1, 2: 0, 3: 1})","854d7b2f":"grid = sns.FacetGrid(df, row='Pclass', col='Sex', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","4ae09685":"# guess_ages = np.zeros((2,3))\n\n# for i in range(0, 2):\n#     for j in range(0, 3):\n#         guess_df = df[(df['Sex'] == i) & (df['Pclass'] == j+1)]['Age'].dropna()\n\n#         # age_mean = guess_df.mean()\n#         # age_std = guess_df.std()\n#         # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n\n#         age_guess = guess_df.median()\n\n#         # Convert random age float to nearest .5 age\n#         guess_ages[i,j] = int( (age_guess\/0.5) + 0.5 ) * 0.5\n            \n# for i in range(0, 2):\n#     for j in range(0, 3):\n#         df.loc[ (df.Age.isnull()) & (df.Sex == i) & (df.Pclass == j+1),'Age'] = guess_ages[i,j]\n\n# df['Age'] = df['Age'].astype(int)\n\n","a3781ee1":"# df['AgeBand'] = pd.cut(df['Age'], 5)\n# df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","31fc95d0":"df['Age1'] = df.Age\n\ntest['Age1'] = test.Age","fc531a6a":"df.loc[ df['Age'] <= 16, 'Age'] = 0\ndf.loc[(df['Age'] > 16) & (df['Age'] <= 32), 'Age'] = 1\ndf.loc[(df['Age'] > 32) & (df['Age'] <= 48), 'Age'] = 2\ndf.loc[(df['Age'] > 48) & (df['Age'] <= 64), 'Age'] = 3\ndf.loc[ df['Age'] > 64, 'Age'] = 4","e5c14fd1":"test.loc[ test['Age'] <= 16, 'Age'] = 0\ntest.loc[(test['Age'] > 16) & (test['Age'] <= 32), 'Age'] = 1\ntest.loc[(test['Age'] > 32) & (test['Age'] <= 48), 'Age'] = 2\ntest.loc[(test['Age'] > 48) & (test['Age'] <= 64), 'Age'] = 3\ntest.loc[ test['Age'] > 64, 'Age'] = 4","56074f8d":"# df = df.drop(['AgeBand'], axis=1)","19128509":"df['Age*Class'] = df.Age * df.Pclass\n\ntest['Age*Class'] = test.Age * test.Pclass","7be9c9f9":"# df['FareBand'] = pd.qcut(df['Fare'], 4)\n# df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","0c813f2d":"df['Fare1'] = df.Fare\n\ntest['Fare1'] = test.Fare","9cccdc60":"df.loc[ df['Fare'] <= 7.91, 'Fare'] = 0\ndf.loc[(df['Fare'] > 7.91) & (df['Fare'] <= 14.454), 'Fare'] = 1\ndf.loc[(df['Fare'] > 14.454) & (df['Fare'] <= 31), 'Fare']   = 2\ndf.loc[ df['Fare'] > 31, 'Fare'] = 3\ndf['Fare'] = df['Fare'].astype(int)\n\n# df = df.drop(['FareBand'], axis=1)","fe136d88":"test.loc[ test['Fare'] <= 7.91, 'Fare'] = 0\ntest.loc[(test['Fare'] > 7.91) & (test['Fare'] <= 14.454), 'Fare'] = 1\ntest.loc[(test['Fare'] > 14.454) & (test['Fare'] <= 31), 'Fare']   = 2\ntest.loc[ test['Fare'] > 31, 'Fare'] = 3\ntest['Fare'] = test['Fare'].astype(int)\n","7706f2b5":"# sex = pd.get_dummies(df['Sex'], prefix='Sex', drop_first=True)\nembarked = pd.get_dummies(df['Embarked'], prefix='Embarked', drop_first=True)\npclass = pd.get_dummies(df['Pclass'], prefix='Pclass', drop_first=True)\ntitle = pd.get_dummies(df['Title'], prefix='Title', drop_first=True)\n\ndf.drop(['Sex', 'Embarked', 'Pclass', 'Title'], axis=1, inplace=True)\n\ndf = pd.concat([df, embarked, pclass, title], axis=1)","7088c8a2":"embarked = pd.get_dummies(test['Embarked'], prefix='Embarked', drop_first=True)\npclass = pd.get_dummies(test['Pclass'], prefix='Pclass', drop_first=True)\ntitle = pd.get_dummies(test['Title'], prefix='Title', drop_first=True)\n\ntest.drop(['Sex', 'Embarked', 'Pclass', 'Title'], axis=1, inplace=True)\n\ntest = pd.concat([test, embarked, pclass, title], axis=1)","165aeda2":"df.corr()['Survived'].sort_values()[:-1]","f7afb4a8":"df.corr()['Survived'].sort_values()[:-1].plot.bar()","572ee35b":"df.Age.unique().max()","4c327c10":"df.Age.unique().min()","ef4f72f0":"df.Fare.unique().max()","a5dbdb4c":"df.Fare.unique().min()","8a7bf4c1":"df.dtypes","80d6d311":"df.ticket_letters.unique()","58c737b6":"df.cabin_adv.unique()","ec9a5bab":"# df.ticket_letters.apply(LabelEncoder().fit_transform)\n\n# df[ \"cabin_adv\"] = le.fit_transform(df[ \"cabin_adv\"])\n# test[ \"cabin_adv\"] = le.transform(test[ \"cabin_adv\"])\n\n# df[ \"ticket_letters\"] = le.fit_transform(df[ \"ticket_letters\"])\n# test[ \"ticket_letters\"] = le.transform(test[ \"ticket_letters\"])\n\n# df[[\"ticket_letters\", \"cabin_adv\"]] = le.fit_transform(df[[\"ticket_letters\", \"cabin_adv\"]])\n\n# test[[\"ticket_letters\", \"cabin_adv\"]] = le.transform(test[[\"ticket_letters\", \"cabin_adv\"]])","73a29214":"# df.drop(['name_title','cabin_adv','ticket_letters'], axis=1,inplace=True)","c5cfac4a":"X = df.drop(['Survived','name_title','cabin_adv','ticket_letters'], axis=1)\ny = df['Survived']","67a154b0":"X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=1)","6915e81c":"# scaler = StandardScaler()\n# df[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])","b5697e1e":"best_lr = LogisticRegression(C=6,penalty='l2',solver='liblinear')\nbest_lr.fit(X_train, y_train)\ny_pred = best_lr.predict(X_test)","4b214540":"print(f'Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%')\nprint('-'*55)\nprint(classification_report(y_test, y_pred))\nprint('-'*55)\nprint(confusion_matrix(y_test, y_pred))","a2855355":"error_rate = []\n\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    \n    pred_i = knn.predict(X_test)\n    \n    error_rate.append(np.mean(pred_i != y_test))","d91e27fc":"# Plot Error rate vs Number of neighbors\nplt.figure(figsize=(10,6))\nplt.plot(range(1,40), error_rate,color='blue', ls='--',\n         marker='o', markerfacecolor='red', markersize=10)\nplt.xlabel('Neighbors')\nplt.ylabel('Error rate')\nplt.title('Error rate vs Number of neighbors')","b4a5d7ad":"knn = KNeighborsClassifier(n_neighbors=15,algorithm='ball_tree',n_jobs=-1)\nknn.fit(X_train, y_train)\n\ny_pred = knn.predict(X_test)","9387f480":"print(f'Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%')\nprint('-'*55)\nprint(classification_report(y_test, y_pred))\nprint('-'*55)\nprint(confusion_matrix(y_test, y_pred))","bf0f3cdd":"rf = RandomForestClassifier(random_state=121)\n\nrf.fit(X_train, y_train)\n\ny_pred = rf.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy:', accuracy)","c9c2ef31":"param_grid = {\n   'criterion':['giny', 'entropy'],\n   'n_estimators':[50, 100, 500, 750, 1000],\n   'max_depth':[5,6,7, 8,9,10],\n   'min_samples_split':[2, 5, 10, 15, 100],\n   'min_samples_leaf':[1, 5, 10]}","307255bc":"# model = GridSearchCV(rf, param_grid=param_grid, cv=5, n_jobs=-1)\n\n# model.fit(X_train, y_train)\n\n# print('Best Params:', model.best_params_)","423c9114":"best_rf = RandomForestClassifier(random_state=121, criterion='entropy', max_depth=9, min_samples_leaf=5, min_samples_split=2, n_estimators=50)\n\nbest_rf.fit(X_train, y_train)\n\ny_pred = best_rf.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)","5a2b2ece":"print(f'Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%')\nprint('-'*55)\nprint(classification_report(y_test, y_pred))\nprint('-'*55)\nprint(confusion_matrix(y_test, y_pred))","cf46ff83":"# nb_classifier = GaussianNB()\n\n# params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n# gs_NB = GridSearchCV(estimator=nb_classifier, \n#                  param_grid=params_NB, \n#                  cv=10,   # use any cross validation technique \n#                  verbose=1, \n#                  scoring='accuracy') \n# gs_NB.fit(X_train, y_train)\n\n# print(gs_NB.best_params_)\n\n# print(confusion_matrix(y_test, y_pred))","fd96f237":"nb_classifier = GaussianNB(var_smoothing= 8.111308307896872e-05)\n\nnb_classifier.fit(X_train, y_train)\n\ny_pred = nb_classifier.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy:', accuracy)","f508a330":"print(confusion_matrix(y_test, y_pred))","a39d08ab":"SVC_classifier = SVC()\n\nSVC_classifier.fit(X_train, y_train)\n\ny_pred = SVC_classifier.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy:', accuracy)\nprint(confusion_matrix(y_test, y_pred))","dd7b5568":"LinearSVC_classifier = LinearSVC()\n\nLinearSVC_classifier.fit(X_train, y_train)\n\ny_pred = LinearSVC_classifier.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy:', accuracy)\nprint(confusion_matrix(y_test, y_pred))","947645ac":"GradientBoosting_classifier = GradientBoostingClassifier()\n\nGradientBoosting_classifier.fit(X_train, y_train)\n\ny_pred = GradientBoosting_classifier.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy:', accuracy)","ac693bb9":"print(confusion_matrix(y_test, y_pred))","d22265b9":"Bagging_classifier = BaggingClassifier()\n\nBagging_classifier.fit(X_train, y_train)\n\ny_pred = Bagging_classifier.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy:', accuracy)","ccba1ede":"print(confusion_matrix(y_test, y_pred))","e59e6850":"AdaBoost_classifier = AdaBoostClassifier()\n\nAdaBoost_classifier.fit(X_train, y_train)\n\ny_pred = AdaBoost_classifier.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy:', accuracy)","35d5c142":"print(confusion_matrix(y_test, y_pred))","78ca50ce":"xgb = XGBClassifier(random_state=121)\n\nxgb.fit(X_train, y_train)\n\ny_pred = xgb.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy:', accuracy)","9cf2018b":"print(confusion_matrix(y_test, y_pred))","491a5a43":"CatBoost_classifier = CatBoostClassifier()\n\nCatBoost_classifier.fit(X_train, y_train)\n\ny_pred = CatBoost_classifier.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy:', accuracy)","fe4919ad":"print(confusion_matrix(y_test, y_pred))","1103699b":"LGBM_classifier = LGBMClassifier()\n\nLGBM_classifier.fit(X_train, y_train)\n\ny_pred = LGBM_classifier.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy:', accuracy)","b8b7bc7a":"print(confusion_matrix(y_test, y_pred))","3e74f5e7":"classifiers = [('Logistic Regression', best_lr),\n               ('GB', GradientBoosting_classifier),\n               ('Cat', CatBoost_classifier),\n               ('LGBM', LGBM_classifier),\n               ('Random Forest', best_rf),\n               ('Xgboost', xgb)]\n\nfor name_clf, clf in classifiers:\n    y_pred = clf.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    print(f'{name_clf} accuracy: {round(acc, 3)}%')","c9e36da0":"print(confusion_matrix(y_test, y_pred))","8b7cdec9":"from sklearn.ensemble import VotingClassifier\n\nvc = VotingClassifier(estimators=classifiers,voting='soft')\n\nvc.fit(X_train, y_train)\n\ny_pred = vc.predict(X_test)\n\nacc_vc = accuracy_score(y_test, y_pred)\n\nprint(f'Ensembler Accuracy: {round(acc_vc, 3)}%')","baadaddb":"print(confusion_matrix(y_test, y_pred))","e88bd4e8":"perceptron = Perceptron()\nperceptron.fit(X_train, y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_test, y_test) * 100, 2)\nacc_perceptron","7b8a9f41":"sgd = SGDClassifier()\nsgd.fit(X_train, y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_test, y_test) * 100, 2)\nacc_sgd","fcf2d65b":"test.set_index('PassengerId',inplace=True)","39be84a6":"test_df = test.drop(['name_title','cabin_adv','ticket_letters'], axis=1)","5ca3366a":"y_pred = best_rf.predict(test_df)","0f9b7250":"test.reset_index(inplace=True)","babccff4":"test.info()","c385fc7b":"test['Survived'] = y_pred\ntest[['PassengerId','Survived']].to_csv('\/kaggle\/working\/gender_submission.csv', index=False)","bb12b9a3":"Survival rates","8d659c45":"There are more males than females\n\nMales tend to die, Females tend to survive","0e520172":"Create Family size (Family = SibSp + Parch) and Alone if doesn't have family members\n\nFill all the missing values of Age in both dataframes (with mean based on Sex and Pclass) -> Maybe use some algorithm to predict them, in a future project.\n\nFill 2 values of Emarked from df_train with the most common one or check in relation with other variables\n","90f56f7e":"# Numerical variables","22d11793":"### Based on the median values of the plots seems likely to be 'C' > 'S', definitely is not Q. I'll go with C since Pclass, Sex and Survived point to that.","d55434bb":"Pclass=3 had most passengers, however most did not survive. \n\nInfant passengers in Pclass=2 and Pclass=3 mostly survived.\n\nMost passengers in Pclass=1 survived.\n\nPclass varies in terms of Age distribution of passengers.","66f1a626":"Female passengers had much better survival rate than males.\n\nException in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\n\nMales had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports.\n\nPorts of embarkation have varying survival rates for Pclass=3 and among male passengers.","568c07e5":"The distributions by sex are similar\n\nThere are extreme values (outliers?)","a4518952":"More people in third class\n\nHigher ratio Survive:Die in third class\n\nMore men than women die indepentedly of the class","e541950c":"Summary of Variables and what to do with each one\n\nPassengerId: Unique identification of the passenger. -> Delete\n\nSurvived: Survival (0 = No, 1 = Yes). -> Ready\n\nPclass: Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd). -> Encode (categorical)\n\nName: Name of the passenger. -> Still don't know\n\nSex: Sex. -> Encode (categorical)\n\nAge: Age in years. -> Fill missing values in an easy way and maybe group in intervals\n\nSibSp: # of siblings \/ spouses aboard the Titanic. -> Ready\n\nParch: # of parents \/ children aboard the Titanic. -> Ready\n\nTicket: Ticket number. -> Delete?\n\nFare: Passenger fare. -> Maybe group in intervals\n\nCabin: Cabin number. -> Delete\n\nEmbarked: Port of Embarkation. Encode (categorical)","df5b98a1":"# Workflow goals\nThe data science solutions workflow solves for seven major goals.\n\n### Classifying. \nWe may want to classify or categorize our samples. We may also want to understand the implications or correlation of different classes with our solution goal.\n\n### Correlating.\nOne can approach the problem based on available features within the training dataset. Which features within the dataset contribute significantly to our solution goal? Statistically speaking is there a correlation among a feature and solution goal? As the feature values change does the solution state change as well, and visa-versa? This can be tested both for numerical and categorical features in the given dataset. We may also want to determine correlation among features other than survival for subsequent goals and workflow stages. Correlating certain features may help in creating, completing, or correcting features.\n\n### Converting.\nFor modeling stage, one needs to prepare the data. Depending on the choice of model algorithm one may require all features to be converted to numerical equivalent values. So for instance converting text categorical values to numeric values.\n\n### Completing.\nData preparation may also require us to estimate any missing values within a feature. Model algorithms may work best when there are no missing values.\n\n### Correcting.\nWe may also analyze the given training dataset for errors or possibly innacurate values within features and try to corrent these values or exclude the samples containing the errors. One way to do this is to detect any outliers among our samples or features. We may also completely discard a feature if it is not contribting to the analysis or may significantly skew the results.\n\n### Creating.\nCan we create new features based on an existing feature or a set of features, such that the new feature follows the correlation, conversion, completeness goals.\n\n### Charting. \nHow to select the right visualization plots and charts depending on nature of the data and the solution goals.","68e8436c":"Infants (Age <=4) had high survival rate.\n\nOldest passengers (Age = 80) survived.\n\nLarge number of 15-25 year olds did not survive.\n\nMost passengers are in 15-35 age range."}}