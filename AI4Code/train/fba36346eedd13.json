{"cell_type":{"7a0612dc":"code","0f1ddeac":"code","645855e6":"code","149acb9b":"code","eea7fb2e":"code","5e54a376":"code","01b03963":"code","8cdf6758":"code","fdfeb540":"code","d271a858":"code","51fdf2eb":"code","4f21f0b9":"code","800685e6":"code","3df0baf6":"code","523d66c7":"code","8142e64a":"code","5565c874":"code","f1721cd4":"code","58b3e466":"code","eac4b8dd":"code","85ae9b15":"code","bf1c1981":"code","7e55935a":"code","882399e5":"code","c8c04e69":"code","7be4e3e9":"code","63deb665":"code","34b23a46":"code","3e5a411c":"code","e2413306":"code","67984d5d":"code","0acfbd40":"code","8f370367":"code","0d64a880":"code","3c7a7eac":"code","fa381da1":"code","571f35aa":"code","cff9ba6d":"code","ee9ac791":"code","69435fdd":"code","6d351ea8":"code","fb9ac720":"code","403f698a":"markdown"},"source":{"7a0612dc":"import os\nimport gc\nimport time\nimport numpy as np\nimport pandas as pd\nfrom contextlib import contextmanager\nimport multiprocessing as mp\nfrom functools import partial\nfrom scipy.stats import kurtosis, iqr, skew\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport warnings\n","0f1ddeac":"warnings.simplefilter(action='ignore', category=FutureWarning)","645855e6":"pd.set_option('display.max_rows', 60)\npd.set_option('display.max_columns', 100)","149acb9b":"debug = True","eea7fb2e":"num_rows = 30000 if debug else None","5e54a376":"# GENERAL CONFIGURATIONS\nNUM_THREADS = 4\nDATA_DIRECTORY = \"..\/input\/\"\nSUBMISSION_SUFIX = \"_model2_04\"","01b03963":"path = DATA_DIRECTORY\nnum_rows = num_rows","8cdf6758":"train = pd.read_csv(os.path.join(path, 'application_train.csv'), nrows=num_rows)","fdfeb540":"test = pd.read_csv(os.path.join(path, 'application_test.csv'), nrows=num_rows)","d271a858":"train.head()","51fdf2eb":"df = train.append(test)","4f21f0b9":"del train, test;","800685e6":"gc.collect()","3df0baf6":"df['CODE_GENDER'].value_counts()","523d66c7":"df = df[df['CODE_GENDER'] != 'XNA']","8142e64a":"df = df[df['AMT_INCOME_TOTAL']<20000000]","5565c874":"(df['DAYS_EMPLOYED']==365243).sum()","f1721cd4":"df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)","58b3e466":"df['DAYS_LAST_PHONE_CHANGE'].replace(0, np.nan, inplace=True)","eac4b8dd":"docs = [f for f in df.columns if 'FLAG_DOC' in f]","85ae9b15":"df['DOCUMENT_COUNT'] = df[docs].sum(axis=1)","bf1c1981":"df['DOCUMENT_COUNT'].hist()","7e55935a":"df[docs].kurtosis(axis=1).hist()","882399e5":"df['NEW_DOC_KURT'] = df[docs].kurtosis(axis=1)","c8c04e69":"def get_age_label(days_birth):\n    \"\"\" Return the age group label (int). \"\"\"\n    age_years = -days_birth \/ 365\n    if age_years < 27: return 1\n    elif age_years < 40: return 2\n    elif age_years < 50: return 3\n    elif age_years < 65: return 4\n    elif age_years < 99: return 5\n    else: return 0","7be4e3e9":"df['AGE_RANGE'] = df['DAYS_BIRTH'].apply(lambda x: get_age_label(x))","63deb665":"df['EXT_SOURCE_1'] * df['EXT_SOURCE_2']* df['EXT_SOURCE_3']","34b23a46":"df['EXT_SOURCES_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\ndf['EXT_SOURCES_WEIGHTED'] = df.EXT_SOURCE_1 * 2 + df.EXT_SOURCE_2 * 1 + df.EXT_SOURCE_3 * 3","3e5a411c":"#credit ratio preprocessing\ndf['CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] \/ df['AMT_ANNUITY']\ndf['CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] \/ df['AMT_GOODS_PRICE']","e2413306":"#income ratio preprocessing\ndf['ANNUITY_TO_INCOME_RATIO'] = df['AMT_ANNUITY'] \/ df['AMT_INCOME_TOTAL']\ndf['CREDIT_TO_INCOME_RATIO'] = df['AMT_CREDIT'] \/ df['AMT_INCOME_TOTAL']\ndf['INCOME_TO_EMPLOYED_RATIO'] = df['AMT_INCOME_TOTAL'] \/ df['DAYS_EMPLOYED']\ndf['INCOME_TO_BIRTH_RATIO'] = df['AMT_INCOME_TOTAL'] \/ df['DAYS_BIRTH']","67984d5d":"#time ratio (period)\ndf['EMPLOYED_TO_BIRTH_RATIO'] = df['DAYS_EMPLOYED'] \/ df['DAYS_BIRTH']\ndf['ID_TO_BIRTH_RATIO'] = df['DAYS_ID_PUBLISH'] \/ df['DAYS_BIRTH']\ndf['CAR_TO_BIRTH_RATIO'] = df['OWN_CAR_AGE'] \/ df['DAYS_BIRTH']\ndf['CAR_TO_EMPLOYED_RATIO'] = df['OWN_CAR_AGE'] \/ df['DAYS_EMPLOYED']\ndf['PHONE_TO_BIRTH_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] \/ df['DAYS_BIRTH']","0acfbd40":"#define functions\ndef timer(name):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(name, time.time() - t0))\n\n\ndef group(df_to_agg, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n    agg_df = df_to_agg.groupby(aggregate_by).agg(aggregations)\n    agg_df.columns = pd.Index(['{}{}_{}'.format(prefix, e[0], e[1].upper())\n                               for e in agg_df.columns.tolist()])\n    return agg_df.reset_index()\n\n\ndef group_and_merge(df_to_agg, df_to_merge, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n    agg_df = group(df_to_agg, prefix, aggregations, aggregate_by= aggregate_by)\n    return df_to_merge.merge(agg_df, how='left', on= aggregate_by)\n\n\ndef do_mean(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].mean().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_median(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].median().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_std(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].std().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_sum(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].sum().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef one_hot_encoder(df, categorical_columns=None, nan_as_category=True):\n    \"\"\"Create a new column for each categorical value in categorical columns. \"\"\"\n    original_columns = list(df.columns)\n    if not categorical_columns:\n        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n    categorical_columns = [c for c in df.columns if c not in original_columns]\n    return df, categorical_columns\n\n\ndef label_encoder(df, categorical_columns=None):\n    \"\"\"Encode categorical values as integers (0,1,2,3...) with pandas.factorize. \"\"\"\n    if not categorical_columns:\n        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    for col in categorical_columns:\n        df[col], uniques = pd.factorize(df[col])\n    return df, categorical_columns\n\n\ndef add_features(feature_name, aggs, features, feature_names, groupby):\n    feature_names.extend(['{}_{}'.format(feature_name, agg) for agg in aggs])\n\n    for agg in aggs:\n        if agg == 'kurt':\n            agg_func = kurtosis\n        elif agg == 'iqr':\n            agg_func = iqr\n        else:\n            agg_func = agg\n\n        g = groupby[feature_name].agg(agg_func).reset_index().rename(index=str,\n                                                                     columns={feature_name: '{}_{}'.format(feature_name,agg)})\n        features = features.merge(g, on='SK_ID_CURR', how='left')\n    return features, feature_names","8f370367":"#groupby\ngroup = ['ORGANIZATION_TYPE', 'NAME_EDUCATION_TYPE', 'OCCUPATION_TYPE', 'AGE_RANGE', 'CODE_GENDER']\n\n\n\ndf = do_mean(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_MEAN')\ndf = do_std(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_STD')\n\ndf = do_mean(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_MEAN')\ndf = do_std(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_STD')\n\ndf = do_mean(df, group, 'AMT_CREDIT', 'GROUP_CREDIT_MEAN')\n\ndf = do_mean(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_MEAN')\ndf = do_std(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_STD')","0d64a880":"# Encode categorical features (LabelEncoder)\ndf, le_encoded_cols = label_encoder(df, None)","3c7a7eac":"def drop_application_columns(df):\n    \"\"\" Drop features based on permutation feature importance. \"\"\"\n    drop_list = [\n        'CNT_CHILDREN', 'CNT_FAM_MEMBERS', 'HOUR_APPR_PROCESS_START',\n        'FLAG_EMP_PHONE', 'FLAG_MOBIL', 'FLAG_CONT_MOBILE', 'FLAG_EMAIL', 'FLAG_PHONE',\n        'FLAG_OWN_REALTY', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION',\n        'REG_CITY_NOT_WORK_CITY', 'OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE',\n        'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_YEAR', \n        'COMMONAREA_MODE', 'NONLIVINGAREA_MODE', 'ELEVATORS_MODE', 'NONLIVINGAREA_AVG',\n        'FLOORSMIN_MEDI', 'LANDAREA_MODE', 'NONLIVINGAREA_MEDI', 'LIVINGAPARTMENTS_MODE',\n        'FLOORSMIN_AVG', 'LANDAREA_AVG', 'FLOORSMIN_MODE', 'LANDAREA_MEDI',\n        'COMMONAREA_MEDI', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'BASEMENTAREA_AVG',\n        'BASEMENTAREA_MODE', 'NONLIVINGAPARTMENTS_MEDI', 'BASEMENTAREA_MEDI', \n        'LIVINGAPARTMENTS_AVG', 'ELEVATORS_AVG', 'YEARS_BUILD_MEDI', 'ENTRANCES_MODE',\n        'NONLIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'LIVINGAPARTMENTS_MEDI',\n        'YEARS_BUILD_MODE', 'YEARS_BEGINEXPLUATATION_AVG', 'ELEVATORS_MEDI', 'LIVINGAREA_MEDI',\n        'YEARS_BEGINEXPLUATATION_MODE', 'NONLIVINGAPARTMENTS_AVG', 'HOUSETYPE_MODE',\n        'FONDKAPREMONT_MODE', 'EMERGENCYSTATE_MODE']","fa381da1":"df = drop_application_columns(df)","571f35aa":"drop_list= ['CNT_CHILDREN', 'CNT_FAM_MEMBERS', 'HOUR_APPR_PROCESS_START',\n        'FLAG_EMP_PHONE', 'FLAG_MOBIL', 'FLAG_CONT_MOBILE', 'FLAG_EMAIL', 'FLAG_PHONE',\n        'FLAG_OWN_REALTY', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION',\n        'REG_CITY_NOT_WORK_CITY', 'OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE',\n        'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_YEAR', \n        'COMMONAREA_MODE', 'NONLIVINGAREA_MODE', 'ELEVATORS_MODE', 'NONLIVINGAREA_AVG',\n        'FLOORSMIN_MEDI', 'LANDAREA_MODE', 'NONLIVINGAREA_MEDI', 'LIVINGAPARTMENTS_MODE',\n        'FLOORSMIN_AVG', 'LANDAREA_AVG', 'FLOORSMIN_MODE', 'LANDAREA_MEDI',\n        'COMMONAREA_MEDI', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'BASEMENTAREA_AVG',\n        'BASEMENTAREA_MODE', 'NONLIVINGAPARTMENTS_MEDI', 'BASEMENTAREA_MEDI', \n        'LIVINGAPARTMENTS_AVG', 'ELEVATORS_AVG', 'YEARS_BUILD_MEDI', 'ENTRANCES_MODE',\n        'NONLIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'LIVINGAPARTMENTS_MEDI',\n        'YEARS_BUILD_MODE', 'YEARS_BEGINEXPLUATATION_AVG', 'ELEVATORS_MEDI', 'LIVINGAREA_MEDI',\n        'YEARS_BEGINEXPLUATATION_MODE', 'NONLIVINGAPARTMENTS_AVG', 'HOUSETYPE_MODE',\n        'FONDKAPREMONT_MODE', 'EMERGENCYSTATE_MODE'    \n]","cff9ba6d":"for doc_num in [2,4,5,6,7,9,10,11,12,13,14,15,16,17,19,20,21]:\n                drop_list.append('FLAG_DOCUMENT_{}'.format(doc_num))\ndf.drop(drop_list, axis=1, inplace=True)\nreturn df","ee9ac791":"def get_age_label(days_birth):\n    \"\"\" Return the age group label (int). \"\"\"\n    age_years = -days_birth \/ 365\n    if age_years < 27: return 1\n    elif age_years < 40: return 2\n    elif age_years < 50: return 3\n    elif age_years < 65: return 4\n    elif age_years < 99: return 5\n    else: return 0","69435fdd":"def get_bureau(path, num_rows= None):\n    bureau = pd.read_csv(os.path.join(path, 'bureau.csv'), nrows=num_rows)\n    \n    bureau['CREDIT_DURATION'] = -bureau['DAYS_CREDIT'] + bureau['DAYS_CREDIT_ENDDATE']\n    bureau['ENDDATE_DIF'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_ENDDATE_FACT']\n    \n    bureau['DEBT_PERCENTAGE'] = bureau['AMT_CREDIT_SUM'] \/ bureau['AMT_CREDIT_SUM_DEBT']\n    bureau['DEBT_CREDIT_DIFF'] = bureau['AMT_CREDIT_SUM'] - bureau['AMT_CREDIT_SUM_DEBT']\n    bureau['CREDIT_TO_ANNUITY_RATIO'] = bureau['AMT_CREDIT_SUM'] \/ bureau['AMT_ANNUITY']","6d351ea8":"    # One-hot encoder\n    bureau, categorical_cols = one_hot_encoder(bureau, nan_as_category= False)\n    # Join bureau balance features\n    bureau = bureau.merge(get_bureau_balance(path, num_rows), how='left', on='SK_ID_BUREAU')\n    # Flag months with late payments (days past due)\n    bureau['STATUS_12345'] = 0\n    for i in range(1,6):\n        bureau['STATUS_12345'] += bureau['STATUS_{}'.format(i)]\n\n    # Aggregate by number of months in balance and merge with bureau (loan length agg)\n    features = ['AMT_CREDIT_MAX_OVERDUE', 'AMT_CREDIT_SUM_OVERDUE', 'AMT_CREDIT_SUM',\n        'AMT_CREDIT_SUM_DEBT', 'DEBT_PERCENTAGE', 'DEBT_CREDIT_DIFF', 'STATUS_0', 'STATUS_12345']\n    agg_length = bureau.groupby('MONTHS_BALANCE_SIZE')[features].mean().reset_index()\n    agg_length.rename({feat: 'LL_' + feat for feat in features}, axis=1, inplace=True)\n    bureau = bureau.merge(agg_length, how='left', on='MONTHS_BALANCE_SIZE')\n    del agg_length; gc.collect()\n\n    # General loans aggregations\n    agg_bureau = group(bureau, 'BUREAU_', BUREAU_AGG)\n    # Active and closed loans aggregations\n    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n    agg_bureau = group_and_merge(active,agg_bureau,'BUREAU_ACTIVE_',BUREAU_ACTIVE_AGG)\n    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n    agg_bureau = group_and_merge(closed,agg_bureau,'BUREAU_CLOSED_',BUREAU_CLOSED_AGG)\n    del active, closed; gc.collect()\n    # Aggregations for the main loan types\n    for credit_type in ['Consumer credit', 'Credit card', 'Mortgage', 'Car loan', 'Microloan']:\n        type_df = bureau[bureau['CREDIT_TYPE_' + credit_type] == 1]\n        prefix = 'BUREAU_' + credit_type.split(' ')[0].upper() + '_'\n        agg_bureau = group_and_merge(type_df, agg_bureau, prefix, BUREAU_LOAN_TYPE_AGG)\n        del type_df; gc.collect()\n    # Time based aggregations: last x months\n    for time_frame in [6, 12]:\n        prefix = \"BUREAU_LAST{}M_\".format(time_frame)\n        time_frame_df = bureau[bureau['DAYS_CREDIT'] >= -30*time_frame]\n        agg_bureau = group_and_merge(time_frame_df, agg_bureau, prefix, BUREAU_TIME_AGG)\n        del time_frame_df; gc.collect()\n\n    # Last loan max overdue\n    sort_bureau = bureau.sort_values(by=['DAYS_CREDIT'])\n    gr = sort_bureau.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].last().reset_index()\n    gr.rename({'AMT_CREDIT_MAX_OVERDUE': 'BUREAU_LAST_LOAN_MAX_OVERDUE'}, inplace=True)\n    agg_bureau = agg_bureau.merge(gr, on='SK_ID_CURR', how='left')\n    # Ratios: total debt\/total credit and active loans debt\/ active loans credit\n    agg_bureau['BUREAU_DEBT_OVER_CREDIT'] = \\\n        agg_bureau['BUREAU_AMT_CREDIT_SUM_DEBT_SUM']\/agg_bureau['BUREAU_AMT_CREDIT_SUM_SUM']\n    agg_bureau['BUREAU_ACTIVE_DEBT_OVER_CREDIT'] = \\\n        agg_bureau['BUREAU_ACTIVE_AMT_CREDIT_SUM_DEBT_SUM']\/agg_bureau['BUREAU_ACTIVE_AMT_CREDIT_SUM_SUM']\n    return agg_bureau\n\n\ndef get_bureau_balance(path, num_rows= None):\n    bb = pd.read_csv(os.path.join(path, 'bureau_balance.csv'), nrows= num_rows)\n    bb, categorical_cols = one_hot_encoder(bb, nan_as_category= False)\n    # Calculate rate for each category with decay\n    bb_processed = bb.groupby('SK_ID_BUREAU')[categorical_cols].mean().reset_index()\n    # Min, Max, Count and mean duration of payments (months)\n    agg = {'MONTHS_BALANCE': ['min', 'max', 'mean', 'size']}\n    bb_processed = group_and_merge(bb, bb_processed, '', agg, 'SK_ID_BUREAU')\n    del bb; gc.collect()\n    return bb_processed\n","fb9ac720":"# ------------------------- PREVIOUS PIPELINE -------------------------\n\ndef get_previous_applications(path, num_rows= None):\n    \"\"\" Process previous_application.csv and return a pandas dataframe. \"\"\"\n    prev = pd.read_csv(os.path.join(path, 'previous_application.csv'), nrows= num_rows)\n    pay = pd.read_csv(os.path.join(path, 'installments_payments.csv'), nrows= num_rows)\n\n    # One-hot encode most important categorical features\n    ohe_columns = [\n        'NAME_CONTRACT_STATUS', 'NAME_CONTRACT_TYPE', 'CHANNEL_TYPE',\n        'NAME_TYPE_SUITE', 'NAME_YIELD_GROUP', 'PRODUCT_COMBINATION',\n        'NAME_PRODUCT_TYPE', 'NAME_CLIENT_TYPE']\n    prev, categorical_cols = one_hot_encoder(prev, ohe_columns, nan_as_category= False)\n\n    # Feature engineering: ratios and difference\n    prev['APPLICATION_CREDIT_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_CREDIT']\n    prev['APPLICATION_CREDIT_RATIO'] = prev['AMT_APPLICATION'] \/ prev['AMT_CREDIT']\n    prev['CREDIT_TO_ANNUITY_RATIO'] = prev['AMT_CREDIT']\/prev['AMT_ANNUITY']\n    prev['DOWN_PAYMENT_TO_CREDIT'] = prev['AMT_DOWN_PAYMENT'] \/ prev['AMT_CREDIT']\n    # Interest ratio on previous application (simplified)\n    total_payment = prev['AMT_ANNUITY'] * prev['CNT_PAYMENT']\n    prev['SIMPLE_INTERESTS'] = (total_payment\/prev['AMT_CREDIT'] - 1)\/prev['CNT_PAYMENT']\n\n    # Active loans - approved and not complete yet (last_due 365243)\n    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n    active_df = approved[approved['DAYS_LAST_DUE'] == 365243]\n    # Find how much was already payed in active loans (using installments csv)\n    active_pay = pay[pay['SK_ID_PREV'].isin(active_df['SK_ID_PREV'])]\n    active_pay_agg = active_pay.groupby('SK_ID_PREV')[['AMT_INSTALMENT', 'AMT_PAYMENT']].sum()\n    active_pay_agg.reset_index(inplace= True)\n    # Active loans: difference of what was payed and installments\n    active_pay_agg['INSTALMENT_PAYMENT_DIFF'] = active_pay_agg['AMT_INSTALMENT'] - active_pay_agg['AMT_PAYMENT']\n    # Merge with active_df\n    active_df = active_df.merge(active_pay_agg, on= 'SK_ID_PREV', how= 'left')\n    active_df['REMAINING_DEBT'] = active_df['AMT_CREDIT'] - active_df['AMT_PAYMENT']\n    active_df['REPAYMENT_RATIO'] = active_df['AMT_PAYMENT'] \/ active_df['AMT_CREDIT']\n    # Perform aggregations for active applications\n    active_agg_df = group(active_df, 'PREV_ACTIVE_', PREVIOUS_ACTIVE_AGG)\n    active_agg_df['TOTAL_REPAYMENT_RATIO'] = active_agg_df['PREV_ACTIVE_AMT_PAYMENT_SUM']\/\\\n                                             active_agg_df['PREV_ACTIVE_AMT_CREDIT_SUM']\n    del active_pay, active_pay_agg, active_df; gc.collect()\n\n    # Change 365.243 values to nan (missing)\n    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n    # Days last due difference (scheduled x done)\n    prev['DAYS_LAST_DUE_DIFF'] = prev['DAYS_LAST_DUE_1ST_VERSION'] - prev['DAYS_LAST_DUE']\n    approved['DAYS_LAST_DUE_DIFF'] = approved['DAYS_LAST_DUE_1ST_VERSION'] - approved['DAYS_LAST_DUE']\n\n    # Categorical features\n    categorical_agg = {key: ['mean'] for key in categorical_cols}\n    # Perform general aggregations\n    agg_prev = group(prev, 'PREV_', {**PREVIOUS_AGG, **categorical_agg})\n    # Merge active loans dataframe on agg_prev\n    agg_prev = agg_prev.merge(active_agg_df, how='left', on='SK_ID_CURR')\n    del active_agg_df; gc.collect()\n    # Aggregations for approved and refused loans\n    agg_prev = group_and_merge(approved, agg_prev, 'APPROVED_', PREVIOUS_APPROVED_AGG)\n    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n    agg_prev = group_and_merge(refused, agg_prev, 'REFUSED_', PREVIOUS_REFUSED_AGG)\n    del approved, refused; gc.collect()\n    # Aggregations for Consumer loans and Cash loans\n    for loan_type in ['Consumer loans', 'Cash loans']:\n        type_df = prev[prev['NAME_CONTRACT_TYPE_{}'.format(loan_type)] == 1]\n        prefix = 'PREV_' + loan_type.split(\" \")[0] + '_'\n        agg_prev = group_and_merge(type_df, agg_prev, prefix, PREVIOUS_LOAN_TYPE_AGG)\n        del type_df; gc.collect()\n\n    # Get the SK_ID_PREV for loans with late payments (days past due)\n    pay['LATE_PAYMENT'] = pay['DAYS_ENTRY_PAYMENT'] - pay['DAYS_INSTALMENT']\n    pay['LATE_PAYMENT'] = pay['LATE_PAYMENT'].apply(lambda x: 1 if x > 0 else 0)\n    dpd_id = pay[pay['LATE_PAYMENT'] > 0]['SK_ID_PREV'].unique()\n    # Aggregations for loans with late payments\n    agg_dpd = group_and_merge(prev[prev['SK_ID_PREV'].isin(dpd_id)], agg_prev,\n                                    'PREV_LATE_', PREVIOUS_LATE_PAYMENTS_AGG)\n    del agg_dpd, dpd_id; gc.collect()\n    # Aggregations for loans in the last x months\n    for time_frame in [12, 24]:\n        time_frame_df = prev[prev['DAYS_DECISION'] >= -30*time_frame]\n        prefix = 'PREV_LAST{}M_'.format(time_frame)\n        agg_prev = group_and_merge(time_frame_df, agg_prev, prefix, PREVIOUS_TIME_AGG)\n        del time_frame_df; gc.collect()\n    del prev; gc.collect()\n    return agg_prev\n\n# ------------------------- POS-CASH PIPELINE -------------------------\n\ndef get_pos_cash(path, num_rows= None):\n    \"\"\" Process POS_CASH_balance.csv and return a pandas dataframe. \"\"\"\n    pos = pd.read_csv(os.path.join(path, 'POS_CASH_balance.csv'), nrows= num_rows)\n    pos, categorical_cols = one_hot_encoder(pos, nan_as_category= False)\n    # Flag months with late payment\n    pos['LATE_PAYMENT'] = pos['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n    # Aggregate by SK_ID_CURR\n    categorical_agg = {key: ['mean'] for key in categorical_cols}\n    pos_agg = group(pos, 'POS_', {**POS_CASH_AGG, **categorical_agg})\n    # Sort and group by SK_ID_PREV\n    sort_pos = pos.sort_values(by=['SK_ID_PREV', 'MONTHS_BALANCE'])\n    gp = sort_pos.groupby('SK_ID_PREV')\n    df = pd.DataFrame()\n    df['SK_ID_CURR'] = gp['SK_ID_CURR'].first()\n    df['MONTHS_BALANCE_MAX'] = gp['MONTHS_BALANCE'].max()\n    # Percentage of previous loans completed and completed before initial term\n    df['POS_LOAN_COMPLETED_MEAN'] = gp['NAME_CONTRACT_STATUS_Completed'].mean()\n    df['POS_COMPLETED_BEFORE_MEAN'] = gp['CNT_INSTALMENT'].first() - gp['CNT_INSTALMENT'].last()\n    df['POS_COMPLETED_BEFORE_MEAN'] = df.apply(lambda x: 1 if x['POS_COMPLETED_BEFORE_MEAN'] > 0\n                                                and x['POS_LOAN_COMPLETED_MEAN'] > 0 else 0, axis=1)\n    # Number of remaining installments (future installments) and percentage from total\n    df['POS_REMAINING_INSTALMENTS'] = gp['CNT_INSTALMENT_FUTURE'].last()\n    df['POS_REMAINING_INSTALMENTS_RATIO'] = gp['CNT_INSTALMENT_FUTURE'].last()\/gp['CNT_INSTALMENT'].last()\n    # Group by SK_ID_CURR and merge\n    df_gp = df.groupby('SK_ID_CURR').sum().reset_index()\n    df_gp.drop(['MONTHS_BALANCE_MAX'], axis=1, inplace= True)\n    pos_agg = pd.merge(pos_agg, df_gp, on= 'SK_ID_CURR', how= 'left')\n    del df, gp, df_gp, sort_pos; gc.collect()\n\n    # Percentage of late payments for the 3 most recent applications\n    pos = do_sum(pos, ['SK_ID_PREV'], 'LATE_PAYMENT', 'LATE_PAYMENT_SUM')\n    # Last month of each application\n    last_month_df = pos.groupby('SK_ID_PREV')['MONTHS_BALANCE'].idxmax()\n    # Most recent applications (last 3)\n    sort_pos = pos.sort_values(by=['SK_ID_PREV', 'MONTHS_BALANCE'])\n    gp = sort_pos.iloc[last_month_df].groupby('SK_ID_CURR').tail(3)\n    gp_mean = gp.groupby('SK_ID_CURR').mean().reset_index()\n    pos_agg = pd.merge(pos_agg, gp_mean[['SK_ID_CURR','LATE_PAYMENT_SUM']], on='SK_ID_CURR', how='left')\n\n    # Drop some useless categorical features\n    drop_features = [\n        'POS_NAME_CONTRACT_STATUS_Canceled_MEAN', 'POS_NAME_CONTRACT_STATUS_Amortized debt_MEAN',\n        'POS_NAME_CONTRACT_STATUS_XNA_MEAN']\n    pos_agg.drop(drop_features, axis=1, inplace=True)\n    return pos_agg\n\n# ------------------------- INSTALLMENTS PIPELINE -------------------------\n\ndef get_installment_payments(path, num_rows= None):\n    \"\"\" Process installments_payments.csv and return a pandas dataframe. \"\"\"\n    pay = pd.read_csv(os.path.join(path, 'installments_payments.csv'), nrows= num_rows)\n    # Group payments and get Payment difference\n    pay = do_sum(pay, ['SK_ID_PREV', 'NUM_INSTALMENT_NUMBER'], 'AMT_PAYMENT', 'AMT_PAYMENT_GROUPED')\n    pay['PAYMENT_DIFFERENCE'] = pay['AMT_INSTALMENT'] - pay['AMT_PAYMENT_GROUPED']\n    pay['PAYMENT_RATIO'] = pay['AMT_INSTALMENT'] \/ pay['AMT_PAYMENT_GROUPED']\n    pay['PAID_OVER_AMOUNT'] = pay['AMT_PAYMENT'] - pay['AMT_INSTALMENT']\n    pay['PAID_OVER'] = (pay['PAID_OVER_AMOUNT'] > 0).astype(int)\n    # Payment Entry: Days past due and Days before due\n    pay['DPD'] = pay['DAYS_ENTRY_PAYMENT'] - pay['DAYS_INSTALMENT']\n    pay['DPD'] = pay['DPD'].apply(lambda x: 0 if x <= 0 else x)\n    pay['DBD'] = pay['DAYS_INSTALMENT'] - pay['DAYS_ENTRY_PAYMENT']\n    pay['DBD'] = pay['DBD'].apply(lambda x: 0 if x <= 0 else x)\n    # Flag late payment\n    pay['LATE_PAYMENT'] = pay['DBD'].apply(lambda x: 1 if x > 0 else 0)\n    # Percentage of payments that were late\n    pay['INSTALMENT_PAYMENT_RATIO'] = pay['AMT_PAYMENT'] \/ pay['AMT_INSTALMENT']\n    pay['LATE_PAYMENT_RATIO'] = pay.apply(lambda x: x['INSTALMENT_PAYMENT_RATIO'] if x['LATE_PAYMENT'] == 1 else 0, axis=1)\n    # Flag late payments that have a significant amount\n    pay['SIGNIFICANT_LATE_PAYMENT'] = pay['LATE_PAYMENT_RATIO'].apply(lambda x: 1 if x > 0.05 else 0)\n    # Flag k threshold late payments\n    pay['DPD_7'] = pay['DPD'].apply(lambda x: 1 if x >= 7 else 0)\n    pay['DPD_15'] = pay['DPD'].apply(lambda x: 1 if x >= 15 else 0)\n    # Aggregations by SK_ID_CURR\n    pay_agg = group(pay, 'INS_', INSTALLMENTS_AGG)\n\n    # Installments in the last x months\n    for months in [36, 60]:\n        recent_prev_id = pay[pay['DAYS_INSTALMENT'] >= -30*months]['SK_ID_PREV'].unique()\n        pay_recent = pay[pay['SK_ID_PREV'].isin(recent_prev_id)]\n        prefix = 'INS_{}M_'.format(months)\n        pay_agg = group_and_merge(pay_recent, pay_agg, prefix, INSTALLMENTS_TIME_AGG)\n\n    # Last x periods trend features\n    group_features = ['SK_ID_CURR', 'SK_ID_PREV', 'DPD', 'LATE_PAYMENT',\n                      'PAID_OVER_AMOUNT', 'PAID_OVER', 'DAYS_INSTALMENT']\n    gp = pay[group_features].groupby('SK_ID_CURR')\n    func = partial(trend_in_last_k_instalment_features, periods= INSTALLMENTS_LAST_K_TREND_PERIODS)\n    g = parallel_apply(gp, func, index_name='SK_ID_CURR', chunk_size=10000).reset_index()\n    pay_agg = pay_agg.merge(g, on='SK_ID_CURR', how='left')\n\n    # Last loan features\n    g = parallel_apply(gp, installments_last_loan_features, index_name='SK_ID_CURR', chunk_size=10000).reset_index()\n    pay_agg = pay_agg.merge(g, on='SK_ID_CURR', how='left')\n    return pay_agg\n\n\ndef trend_in_last_k_instalment_features(gr, periods):\n    gr_ = gr.copy()\n    gr_.sort_values(['DAYS_INSTALMENT'], ascending=False, inplace=True)\n    features = {}\n\n    for period in periods:\n        gr_period = gr_.iloc[:period]\n        features = add_trend_feature(features, gr_period, 'DPD',\n                                           '{}_TREND_'.format(period))\n        features = add_trend_feature(features, gr_period, 'PAID_OVER_AMOUNT',\n                                           '{}_TREND_'.format(period))\n    return features\n\n\ndef installments_last_loan_features(gr):\n    gr_ = gr.copy()\n    gr_.sort_values(['DAYS_INSTALMENT'], ascending=False, inplace=True)\n    last_installment_id = gr_['SK_ID_PREV'].iloc[0]\n    gr_ = gr_[gr_['SK_ID_PREV'] == last_installment_id]\n\n    features = {}\n    features = add_features_in_group(features, gr_, 'DPD',\n                                     ['sum', 'mean', 'max', 'std'],\n                                     'LAST_LOAN_')\n    features = add_features_in_group(features, gr_, 'LATE_PAYMENT',\n                                     ['count', 'mean'],\n                                     'LAST_LOAN_')\n    features = add_features_in_group(features, gr_, 'PAID_OVER_AMOUNT',\n                                     ['sum', 'mean', 'max', 'min', 'std'],\n                                     'LAST_LOAN_')\n    features = add_features_in_group(features, gr_, 'PAID_OVER',\n                                     ['count', 'mean'],\n                                     'LAST_LOAN_')\n    return features\n\n# ------------------------- CREDIT CARD PIPELINE -------------------------\n\ndef get_credit_card(path, num_rows= None):\n    \"\"\" Process credit_card_balance.csv and return a pandas dataframe. \"\"\"\n    cc = pd.read_csv(os.path.join(path, 'credit_card_balance.csv'), nrows= num_rows)\n    cc, cat_cols = one_hot_encoder(cc, nan_as_category=False)\n    cc.rename(columns={'AMT_RECIVABLE': 'AMT_RECEIVABLE'}, inplace=True)\n    # Amount used from limit\n    cc['LIMIT_USE'] = cc['AMT_BALANCE'] \/ cc['AMT_CREDIT_LIMIT_ACTUAL']\n    # Current payment \/ Min payment\n    cc['PAYMENT_DIV_MIN'] = cc['AMT_PAYMENT_CURRENT'] \/ cc['AMT_INST_MIN_REGULARITY']\n    # Late payment\n    cc['LATE_PAYMENT'] = cc['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n    # How much drawing of limit\n    cc['DRAWING_LIMIT_RATIO'] = cc['AMT_DRAWINGS_ATM_CURRENT'] \/ cc['AMT_CREDIT_LIMIT_ACTUAL']\n    # Aggregations by SK_ID_CURR\n    cc_agg = cc.groupby('SK_ID_CURR').agg(CREDIT_CARD_AGG)\n    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n    cc_agg.reset_index(inplace= True)\n\n    # Last month balance of each credit card application\n    last_ids = cc.groupby('SK_ID_PREV')['MONTHS_BALANCE'].idxmax()\n    last_months_df = cc[cc.index.isin(last_ids)]\n    cc_agg = group_and_merge(last_months_df,cc_agg,'CC_LAST_', {'AMT_BALANCE': ['mean', 'max']})\n\n    # Aggregations for last x months\n    for months in [12, 24, 48]:\n        cc_prev_id = cc[cc['MONTHS_BALANCE'] >= -months]['SK_ID_PREV'].unique()\n        cc_recent = cc[cc['SK_ID_PREV'].isin(cc_prev_id)]\n        prefix = 'INS_{}M_'.format(months)\n        cc_agg = group_and_merge(cc_recent, cc_agg, prefix, CREDIT_CARD_TIME_AGG)\n    return cc_agg\n\n\n# ------------------------- UTILITY FUNCTIONS -------------------------\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(name, time.time() - t0))\n\n\ndef group(df_to_agg, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n    agg_df = df_to_agg.groupby(aggregate_by).agg(aggregations)\n    agg_df.columns = pd.Index(['{}{}_{}'.format(prefix, e[0], e[1].upper())\n                               for e in agg_df.columns.tolist()])\n    return agg_df.reset_index()\n\n\ndef group_and_merge(df_to_agg, df_to_merge, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n    agg_df = group(df_to_agg, prefix, aggregations, aggregate_by= aggregate_by)\n    return df_to_merge.merge(agg_df, how='left', on= aggregate_by)\n\n\ndef do_mean(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].mean().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_median(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].median().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_std(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].std().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef do_sum(df, group_cols, counted, agg_name):\n    gp = df[group_cols + [counted]].groupby(group_cols)[counted].sum().reset_index().rename(\n        columns={counted: agg_name})\n    df = df.merge(gp, on=group_cols, how='left')\n    del gp\n    gc.collect()\n    return df\n\n\ndef one_hot_encoder(df, categorical_columns=None, nan_as_category=True):\n    \"\"\"Create a new column for each categorical value in categorical columns. \"\"\"\n    original_columns = list(df.columns)\n    if not categorical_columns:\n        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n    categorical_columns = [c for c in df.columns if c not in original_columns]\n    return df, categorical_columns\n\n\ndef label_encoder(df, categorical_columns=None):\n    \"\"\"Encode categorical values as integers (0,1,2,3...) with pandas.factorize. \"\"\"\n    if not categorical_columns:\n        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    for col in categorical_columns:\n        df[col], uniques = pd.factorize(df[col])\n    return df, categorical_columns\n\n\ndef add_features(feature_name, aggs, features, feature_names, groupby):\n    feature_names.extend(['{}_{}'.format(feature_name, agg) for agg in aggs])\n\n    for agg in aggs:\n        if agg == 'kurt':\n            agg_func = kurtosis\n        elif agg == 'iqr':\n            agg_func = iqr\n        else:\n            agg_func = agg\n\n        g = groupby[feature_name].agg(agg_func).reset_index().rename(index=str,\n                                                                     columns={feature_name: '{}_{}'.format(feature_name,agg)})\n        features = features.merge(g, on='SK_ID_CURR', how='left')\n    return features, feature_names\n\n\ndef add_features_in_group(features, gr_, feature_name, aggs, prefix):\n    for agg in aggs:\n        if agg == 'sum':\n            features['{}{}_sum'.format(prefix, feature_name)] = gr_[feature_name].sum()\n        elif agg == 'mean':\n            features['{}{}_mean'.format(prefix, feature_name)] = gr_[feature_name].mean()\n        elif agg == 'max':\n            features['{}{}_max'.format(prefix, feature_name)] = gr_[feature_name].max()\n        elif agg == 'min':\n            features['{}{}_min'.format(prefix, feature_name)] = gr_[feature_name].min()\n        elif agg == 'std':\n            features['{}{}_std'.format(prefix, feature_name)] = gr_[feature_name].std()\n        elif agg == 'count':\n            features['{}{}_count'.format(prefix, feature_name)] = gr_[feature_name].count()\n        elif agg == 'skew':\n            features['{}{}_skew'.format(prefix, feature_name)] = skew(gr_[feature_name])\n        elif agg == 'kurt':\n            features['{}{}_kurt'.format(prefix, feature_name)] = kurtosis(gr_[feature_name])\n        elif agg == 'iqr':\n            features['{}{}_iqr'.format(prefix, feature_name)] = iqr(gr_[feature_name])\n        elif agg == 'median':\n            features['{}{}_median'.format(prefix, feature_name)] = gr_[feature_name].median()\n    return features\n\n\ndef add_trend_feature(features, gr, feature_name, prefix):\n    y = gr[feature_name].values\n    try:\n        x = np.arange(0, len(y)).reshape(-1, 1)\n        lr = LinearRegression()\n        lr.fit(x, y)\n        trend = lr.coef_[0]\n    except:\n        trend = np.nan\n    features['{}{}'.format(prefix, feature_name)] = trend\n    return features\n\n\ndef parallel_apply(groups, func, index_name='Index', num_workers=0, chunk_size=100000):\n    if num_workers <= 0: num_workers = NUM_THREADS\n    #n_chunks = np.ceil(1.0 * groups.ngroups \/ chunk_size)\n    indeces, features = [], []\n    for index_chunk, groups_chunk in chunk_groups(groups, chunk_size):\n        with mp.pool.Pool(num_workers) as executor:\n            features_chunk = executor.map(func, groups_chunk)\n        features.extend(features_chunk)\n        indeces.extend(index_chunk)\n\n    features = pd.DataFrame(features)\n    features.index = indeces\n    features.index.name = index_name\n    return features\n\n\ndef chunk_groups(groupby_object, chunk_size):\n    n_groups = groupby_object.ngroups\n    group_chunk, index_chunk = [], []\n    for i, (index, df) in enumerate(groupby_object):\n        group_chunk.append(df)\n        index_chunk.append(index)\n        if (i + 1) % chunk_size == 0 or i + 1 == n_groups:\n            group_chunk_, index_chunk_ = group_chunk.copy(), index_chunk.copy()\n            group_chunk, index_chunk = [], []\n            yield index_chunk_, group_chunk_\n\n\ndef reduce_memory(df):\n    \"\"\"Reduce memory usage of a dataframe by setting data types. \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024 ** 2\n    print('Initial df memory usage is {:.2f} MB for {} columns'\n          .format(start_mem, len(df.columns)))\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type != object:\n            cmin = df[col].min()\n            cmax = df[col].max()\n            if str(col_type)[:3] == 'int':\n                # Can use unsigned int here too\n                if cmin > np.iinfo(np.int8).min and cmax < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif cmin > np.iinfo(np.int16).min and cmax < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif cmin > np.iinfo(np.int32).min and cmax < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif cmin > np.iinfo(np.int64).min and cmax < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if cmin > np.finfo(np.float16).min and cmax < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif cmin > np.finfo(np.float32).min and cmax < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024 ** 2\n    memory_reduction = 100 * (start_mem - end_mem) \/ start_mem\n    print('Final memory usage is: {:.2f} MB - decreased by {:.1f}%'.format(end_mem, memory_reduction))\n    return df\n\n# ------------------------- CONFIGURATIONS -------------------------\n\n# GENERAL CONFIGURATIONS\nNUM_THREADS = 4\nDATA_DIRECTORY = \"..\/input\/\"\nSUBMISSION_SUFIX = \"_model2_04\"\n\n# INSTALLMENTS TREND PERIODS\nINSTALLMENTS_LAST_K_TREND_PERIODS =  [12, 24, 60, 120]\n\n# LIGHTGBM CONFIGURATION AND HYPER-PARAMETERS\nGENERATE_SUBMISSION_FILES = True\nSTRATIFIED_KFOLD = False\nRANDOM_SEED = 737851\nNUM_FOLDS = 10\nEARLY_STOPPING = 100\n\nLIGHTGBM_PARAMS = {\n    'boosting_type': 'goss',\n    'n_estimators': 10000,\n    'learning_rate': 0.005134,\n    'num_leaves': 54,\n    'max_depth': 10,\n    'subsample_for_bin': 240000,\n    'reg_alpha': 0.436193,\n    'reg_lambda': 0.479169,\n    'colsample_bytree': 0.508716,\n    'min_split_gain': 0.024766,\n    'subsample': 1,\n    'is_unbalance': False,\n    'silent':-1,\n    'verbose':-1\n}\n\n# AGGREGATIONS\nBUREAU_AGG = {\n    'SK_ID_BUREAU': ['nunique'],\n    'DAYS_CREDIT': ['min', 'max', 'mean'],\n    'DAYS_CREDIT_ENDDATE': ['min', 'max'],\n    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n    'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n    'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean', 'sum'],\n    'AMT_ANNUITY': ['mean'],\n    'DEBT_CREDIT_DIFF': ['mean', 'sum'],\n    'MONTHS_BALANCE_MEAN': ['mean', 'var'],\n    'MONTHS_BALANCE_SIZE': ['mean', 'sum'],\n    # Categorical\n    'STATUS_0': ['mean'],\n    'STATUS_1': ['mean'],\n    'STATUS_12345': ['mean'],\n    'STATUS_C': ['mean'],\n    'STATUS_X': ['mean'],\n    'CREDIT_ACTIVE_Active': ['mean'],\n    'CREDIT_ACTIVE_Closed': ['mean'],\n    'CREDIT_ACTIVE_Sold': ['mean'],\n    'CREDIT_TYPE_Consumer credit': ['mean'],\n    'CREDIT_TYPE_Credit card': ['mean'],\n    'CREDIT_TYPE_Car loan': ['mean'],\n    'CREDIT_TYPE_Mortgage': ['mean'],\n    'CREDIT_TYPE_Microloan': ['mean'],\n    # Group by loan duration features (months)\n    'LL_AMT_CREDIT_SUM_OVERDUE': ['mean'],\n    'LL_DEBT_CREDIT_DIFF': ['mean'],\n    'LL_STATUS_12345': ['mean'],\n}\n\nBUREAU_ACTIVE_AGG = {\n    'DAYS_CREDIT': ['max', 'mean'],\n    'DAYS_CREDIT_ENDDATE': ['min', 'max'],\n    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n    'AMT_CREDIT_SUM': ['max', 'sum'],\n    'AMT_CREDIT_SUM_DEBT': ['mean', 'sum'],\n    'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean'],\n    'DAYS_CREDIT_UPDATE': ['min', 'mean'],\n    'DEBT_PERCENTAGE': ['mean'],\n    'DEBT_CREDIT_DIFF': ['mean'],\n    'CREDIT_TO_ANNUITY_RATIO': ['mean'],\n    'MONTHS_BALANCE_MEAN': ['mean', 'var'],\n    'MONTHS_BALANCE_SIZE': ['mean', 'sum'],\n}\n\nBUREAU_CLOSED_AGG = {\n    'DAYS_CREDIT': ['max', 'var'],\n    'DAYS_CREDIT_ENDDATE': ['max'],\n    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n    'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n    'AMT_CREDIT_SUM_DEBT': ['max', 'sum'],\n    'DAYS_CREDIT_UPDATE': ['max'],\n    'ENDDATE_DIF': ['mean'],\n    'STATUS_12345': ['mean'],\n}\n\nBUREAU_LOAN_TYPE_AGG = {\n    'DAYS_CREDIT': ['mean', 'max'],\n    'AMT_CREDIT_MAX_OVERDUE': ['mean', 'max'],\n    'AMT_CREDIT_SUM': ['mean', 'max'],\n    'AMT_CREDIT_SUM_DEBT': ['mean', 'max'],\n    'DEBT_PERCENTAGE': ['mean'],\n    'DEBT_CREDIT_DIFF': ['mean'],\n    'DAYS_CREDIT_ENDDATE': ['max'],\n}\n\nBUREAU_TIME_AGG = {\n    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n    'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n    'AMT_CREDIT_SUM': ['max', 'sum'],\n    'AMT_CREDIT_SUM_DEBT': ['mean', 'sum'],\n    'DEBT_PERCENTAGE': ['mean'],\n    'DEBT_CREDIT_DIFF': ['mean'],\n    'STATUS_0': ['mean'],\n    'STATUS_12345': ['mean'],\n}\n\nPREVIOUS_AGG = {\n    'SK_ID_PREV': ['nunique'],\n    'AMT_ANNUITY': ['min', 'max', 'mean'],\n    'AMT_DOWN_PAYMENT': ['max', 'mean'],\n    'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n    'RATE_DOWN_PAYMENT': ['max', 'mean'],\n    'DAYS_DECISION': ['min', 'max', 'mean'],\n    'CNT_PAYMENT': ['max', 'mean'],\n    'DAYS_TERMINATION': ['max'],\n    # Engineered features\n    'CREDIT_TO_ANNUITY_RATIO': ['mean', 'max'],\n    'APPLICATION_CREDIT_DIFF': ['min', 'max', 'mean'],\n    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean', 'var'],\n    'DOWN_PAYMENT_TO_CREDIT': ['mean'],\n}\n\nPREVIOUS_ACTIVE_AGG = {\n    'SK_ID_PREV': ['nunique'],\n    'SIMPLE_INTERESTS': ['mean'],\n    'AMT_ANNUITY': ['max', 'sum'],\n    'AMT_APPLICATION': ['max', 'mean'],\n    'AMT_CREDIT': ['sum'],\n    'AMT_DOWN_PAYMENT': ['max', 'mean'],\n    'DAYS_DECISION': ['min', 'mean'],\n    'CNT_PAYMENT': ['mean', 'sum'],\n    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n    # Engineered features\n    'AMT_PAYMENT': ['sum'],\n    'INSTALMENT_PAYMENT_DIFF': ['mean', 'max'],\n    'REMAINING_DEBT': ['max', 'mean', 'sum'],\n    'REPAYMENT_RATIO': ['mean'],\n}\n\nPREVIOUS_APPROVED_AGG = {\n    'SK_ID_PREV': ['nunique'],\n    'AMT_ANNUITY': ['min', 'max', 'mean'],\n    'AMT_CREDIT': ['min', 'max', 'mean'],\n    'AMT_DOWN_PAYMENT': ['max'],\n    'AMT_GOODS_PRICE': ['max'],\n    'HOUR_APPR_PROCESS_START': ['min', 'max'],\n    'DAYS_DECISION': ['min', 'mean'],\n    'CNT_PAYMENT': ['max', 'mean'],\n    'DAYS_TERMINATION': ['mean'],\n    # Engineered features\n    'CREDIT_TO_ANNUITY_RATIO': ['mean', 'max'],\n    'APPLICATION_CREDIT_DIFF': ['max'],\n    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n    # The following features are only for approved applications\n    'DAYS_FIRST_DRAWING': ['max', 'mean'],\n    'DAYS_FIRST_DUE': ['min', 'mean'],\n    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n    'DAYS_LAST_DUE': ['max', 'mean'],\n    'DAYS_LAST_DUE_DIFF': ['min', 'max', 'mean'],\n    'SIMPLE_INTERESTS': ['min', 'max', 'mean'],\n}\n\nPREVIOUS_REFUSED_AGG = {\n    'AMT_APPLICATION': ['max', 'mean'],\n    'AMT_CREDIT': ['min', 'max'],\n    'DAYS_DECISION': ['min', 'max', 'mean'],\n    'CNT_PAYMENT': ['max', 'mean'],\n    # Engineered features\n    'APPLICATION_CREDIT_DIFF': ['min', 'max', 'mean', 'var'],\n    'APPLICATION_CREDIT_RATIO': ['min', 'mean'],\n    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n}\n\nPREVIOUS_LATE_PAYMENTS_AGG = {\n    'DAYS_DECISION': ['min', 'max', 'mean'],\n    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n    # Engineered features\n    'APPLICATION_CREDIT_DIFF': ['min'],\n    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n}\n\nPREVIOUS_LOAN_TYPE_AGG = {\n    'AMT_CREDIT': ['sum'],\n    'AMT_ANNUITY': ['mean', 'max'],\n    'SIMPLE_INTERESTS': ['min', 'mean', 'max', 'var'],\n    'APPLICATION_CREDIT_DIFF': ['min', 'var'],\n    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n    'DAYS_DECISION': ['max'],\n    'DAYS_LAST_DUE_1ST_VERSION': ['max', 'mean'],\n    'CNT_PAYMENT': ['mean'],\n}\n\nPREVIOUS_TIME_AGG = {\n    'AMT_CREDIT': ['sum'],\n    'AMT_ANNUITY': ['mean', 'max'],\n    'SIMPLE_INTERESTS': ['mean', 'max'],\n    'DAYS_DECISION': ['min', 'mean'],\n    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n    # Engineered features\n    'APPLICATION_CREDIT_DIFF': ['min'],\n    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n}\n\nPOS_CASH_AGG = {\n    'SK_ID_PREV': ['nunique'],\n    'MONTHS_BALANCE': ['min', 'max', 'size'],\n    'SK_DPD': ['max', 'mean', 'sum', 'var'],\n    'SK_DPD_DEF': ['max', 'mean', 'sum'],\n    'LATE_PAYMENT': ['mean']\n}\n\nINSTALLMENTS_AGG = {\n    'SK_ID_PREV': ['size', 'nunique'],\n    'DAYS_ENTRY_PAYMENT': ['min', 'max', 'mean'],\n    'AMT_INSTALMENT': ['min', 'max', 'mean', 'sum'],\n    'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n    'DPD': ['max', 'mean', 'var'],\n    'DBD': ['max', 'mean', 'var'],\n    'PAYMENT_DIFFERENCE': ['mean'],\n    'PAYMENT_RATIO': ['mean'],\n    'LATE_PAYMENT': ['mean', 'sum'],\n    'SIGNIFICANT_LATE_PAYMENT': ['mean', 'sum'],\n    'LATE_PAYMENT_RATIO': ['mean'],\n    'DPD_7': ['mean'],\n    'DPD_15': ['mean'],\n    'PAID_OVER': ['mean']\n}\n\nINSTALLMENTS_TIME_AGG = {\n    'SK_ID_PREV': ['size'],\n    'DAYS_ENTRY_PAYMENT': ['min', 'max', 'mean'],\n    'AMT_INSTALMENT': ['min', 'max', 'mean', 'sum'],\n    'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n    'DPD': ['max', 'mean', 'var'],\n    'DBD': ['max', 'mean', 'var'],\n    'PAYMENT_DIFFERENCE': ['mean'],\n    'PAYMENT_RATIO': ['mean'],\n    'LATE_PAYMENT': ['mean'],\n    'SIGNIFICANT_LATE_PAYMENT': ['mean'],\n    'LATE_PAYMENT_RATIO': ['mean'],\n    'DPD_7': ['mean'],\n    'DPD_15': ['mean'],\n}\n\nCREDIT_CARD_AGG = {\n    'MONTHS_BALANCE': ['min'],\n    'AMT_BALANCE': ['max'],\n    'AMT_CREDIT_LIMIT_ACTUAL': ['max'],\n    'AMT_DRAWINGS_ATM_CURRENT': ['max', 'sum'],\n    'AMT_DRAWINGS_CURRENT': ['max', 'sum'],\n    'AMT_DRAWINGS_POS_CURRENT': ['max', 'sum'],\n    'AMT_INST_MIN_REGULARITY': ['max', 'mean'],\n    'AMT_PAYMENT_TOTAL_CURRENT': ['max', 'mean', 'sum', 'var'],\n    'AMT_TOTAL_RECEIVABLE': ['max', 'mean'],\n    'CNT_DRAWINGS_ATM_CURRENT': ['max', 'mean', 'sum'],\n    'CNT_DRAWINGS_CURRENT': ['max', 'mean', 'sum'],\n    'CNT_DRAWINGS_POS_CURRENT': ['mean'],\n    'SK_DPD': ['mean', 'max', 'sum'],\n    'SK_DPD_DEF': ['max', 'sum'],\n    'LIMIT_USE': ['max', 'mean'],\n    'PAYMENT_DIV_MIN': ['min', 'mean'],\n    'LATE_PAYMENT': ['max', 'sum'],\n}\n\nCREDIT_CARD_TIME_AGG = {\n    'CNT_DRAWINGS_ATM_CURRENT': ['mean'],\n    'SK_DPD': ['max', 'sum'],\n    'AMT_BALANCE': ['mean', 'max'],\n    'LIMIT_USE': ['max', 'mean']\n}\n\n\nif __name__ == \"__main__\":\n    pd.set_option('display.max_rows', 60)\n    pd.set_option('display.max_columns', 100)\n    with timer(\"Pipeline total time\"):\n        main(debug= False)\n","403f698a":"## Preprocessing"}}