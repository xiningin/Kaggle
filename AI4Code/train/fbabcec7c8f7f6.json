{"cell_type":{"b18b9cca":"code","0a0ec9ae":"code","2a58fdf6":"code","78649a48":"code","f01f89f4":"code","b562acbe":"code","6a4898c9":"code","9d075c11":"code","d7b46fed":"code","0643f137":"code","d280d9e2":"code","f7d40c3a":"code","5faf920b":"code","6eaf71e2":"code","55fda1a0":"code","8d366f50":"markdown","50bccb2c":"markdown","df474606":"markdown","89def2c9":"markdown","f312579a":"markdown","dfcaff0d":"markdown","c114e085":"markdown","1eaf1e53":"markdown","2038ac8b":"markdown"},"source":{"b18b9cca":"import numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport tqdm\nfrom socket import socket\nnp.random.seed(1337) # for reproducibility\n","0a0ec9ae":"\nCATEGORIES = ['covid', 'healthy']\nDATADIR = '..\/input\/covidistesgp\/CovidDataset\/train'\nfor category in CATEGORIES:\n    path = os.path.join(DATADIR,category)\n    for img in os.listdir(path):\n        img_arr = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)   \n        plt.imshow(img_arr, cmap='gray')\n        plt.xlabel(category)\n        plt.show()\n        break","2a58fdf6":"IMG_SIZE=50\ntrain_data=[]\ntest_data=[]\n\ndef create_data(data_dir):\n    for category in CATEGORIES:\n        path=os.path.join(data_dir, category)\n        class_num=CATEGORIES.index(category)\n        \n        for img in (os.listdir(path)):                                             ## We use os to iterate over all our files in the directory \n            try:\n                img_arr=cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)   ## GRAYSCALING\n                img_arr=cv2.resize(img_arr, (IMG_SIZE,IMG_SIZE))                   ## RESIZING\n                if(data_dir=='..\/input\/covidistesgp\/CovidDataset\/train'):\n                    train_data.append([img_arr,class_num])\n                else:\n                    test_data.append([img_arr,class_num])\n            except exception as e:\n                pass","78649a48":"create_data('..\/input\/covidistesgp\/CovidDataset\/train')\ncreate_data('..\/input\/covidistesgp\/CovidDataset\/validation')\n\nprint(len(train_data))\nprint(len(test_data))","f01f89f4":"for sample in train_data[:10]:\n    print(sample[1])","b562acbe":"import random\n\nrandom.shuffle(train_data)              ## Shuffling the dataset\n\nfor sample in train_data[:10]:\n    print(sample[1])","6a4898c9":"x_train=[]\ny_train=[]\nx_test=[]\ny_test=[]\n\nfor features,label in train_data:\n    x_train.append(features)\n    y_train.append(label)\n    \nfor features,label in test_data:\n    x_test.append(features)\n    y_test.append(label)\n\nx_train = np.array(x_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)   ## reshaping the dataset to (length, 50, 50, 1)\nx_test = np.array(x_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n\nprint(len(x_train))\nprint(len(x_test))","9d075c11":"import pickle\n\npickle_out_x_train = open(\"x_train.pickle\",\"wb\")          # open\/create a file called x_train.pickle, and write into it         \npickle.dump(x_train, pickle_out_x_train)                  # dump the contents of the np array\npickle_out_x_train.close()                                # close the file\n\npickle_out_y_train = open(\"y_train.pickle\",\"wb\")\npickle.dump(y_train, pickle_out_y_train)\npickle_out_y_train.close()\n\npickle_out_x_test = open(\"x_test.pickle\",\"wb\")\npickle.dump(x_test, pickle_out_x_test)\npickle_out_x_test.close()\n\npickle_out_y_test = open(\"y_test.pickle\",\"wb\")\npickle.dump(y_test, pickle_out_y_test)\npickle_out_y_test.close()\n\nprint(len(x_train))\nprint(len(x_test))","d7b46fed":"pickle_in_x_train = open(\"x_train.pickle\",\"rb\")           # open the file\ntrainX = pickle.load(pickle_in_x_train)                   # load its contents into a python varriable\npickle_in_x_train.close()                                 # close the file\n\npickle_in_y_train = open(\"y_train.pickle\",\"rb\")\ntrainY = pickle.load(pickle_in_y_train)\npickle_in_y_train.close()\n\npickle_in_x_test = open(\"x_test.pickle\",\"rb\")\ntestX = pickle.load(pickle_in_x_test)\npickle_in_x_test.close()\n\npickle_in_y_test = open(\"y_test.pickle\",\"rb\")\ntestY = pickle.load(pickle_in_y_test)\npickle_in_y_test.close()\n\nprint(str(len(trainX)) + ', ' + str(len(testX)))","0643f137":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n\nprint(len(x_test))","d280d9e2":"### NORMALIZE the data (trainX, trainY) from 0-255 to 0-1, and convert trainX,trainY,testX,testY to np arrays\n### approx. (1 x 4) lines of code\ntrainX = np.array(trainX\/255.0)\ntrainY = np.array(trainY)\ntestX = np.array(testX\/255.0)\ntestY = np.array(testY)\n\ntestX.shape[0]\n","f7d40c3a":"model = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(8,8), padding='valid', input_shape=(50, 50, 1), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='valid', activation='tanh'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='valid', activation='tanh'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters=256, kernel_size=(1,1), padding='valid', activation='tanh'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='tanh'))\nmodel.add(Dense(50, activation='tanh'))\nmodel.add(Dense(30, activation='tanh'))\nmodel.add(Dense(10, activation='tanh'))\n### Use model.add to add layers (example: conv2D layers, then Maxpooling2D layers, Dense)\n### Experiment with tf keras documentation to complete the model\n### approx 5-12 lines of code, feel free to experiment with different model structures\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam', metrics=[tf.keras.metrics.AUC()])\n\nmodel.summary()","5faf920b":"model.fit(trainX, trainY, batch_size=32, epochs=5, validation_split=0.3)","6eaf71e2":"score = model.evaluate(trainX, trainY, verbose = 1) \n\nprint('Train loss:', score[0]) \nprint('Train accuracy:', score[1])","55fda1a0":"score = model.evaluate(testX, testY, verbose = 0) \n\nprint('Test loss:', score[0]) \nprint('Test accuracy:', score[1])","8d366f50":"### Now fill out the code in the below 2 cells following the instructions","50bccb2c":"# Deep Learning SGP WEEK 3 Convolutional Neural Networks","df474606":"### Its pretty important that we randomise our images rather than having all covid images together and all healthy images together","89def2c9":"### Our Dataset is visible on the top right of the screen. We have two categories for images (covid, healthy) for both 'train' and 'validation' folders","f312579a":"### After we've done this preprocessing work, its handy to store our final array instead of repeating this everytime we want to use these values\n### For this, we use the python library called pickle to store all the values and load them in directly later","dfcaff0d":"#### Expected training accuracy 90-98% ","c114e085":"### Now we use a python library called openCV to read and perform some operations on the input data, such as GRAYSCALING and RESIZING","1eaf1e53":"#### Expected Test Accuracy 70-80%","2038ac8b":"Expected: 2000, 200\n"}}