{"cell_type":{"88700fd0":"code","9fa05733":"code","3cebcb24":"code","92e413b8":"code","1399825e":"code","046bfe4c":"code","e9980a7b":"code","dc3127a1":"code","0feb2adf":"code","e5bc569b":"code","47a2bacd":"code","fd09f9d6":"code","af6e2130":"code","bdbd71c5":"code","b955c63a":"code","ed5b28df":"code","196eb032":"code","9af23ed1":"code","7ed82ffd":"code","1983b576":"code","23fb62bf":"code","cc3d10d1":"code","82254d6f":"code","31c3c935":"code","34e46cec":"code","778dff09":"code","6cc9f1f2":"code","084f5cc8":"code","01d44a24":"code","bc94e910":"code","a1416012":"code","cb144eb6":"code","26ddfafe":"code","5581b395":"code","e492b956":"code","8865bc3c":"code","24ad6043":"code","39df00d3":"code","f0b50fcd":"markdown","9b6bd950":"markdown","73b09f8d":"markdown","653a7e17":"markdown","73d04283":"markdown","71e4cefe":"markdown","7096cc4b":"markdown","b4dac0ff":"markdown","367d21a5":"markdown"},"source":{"88700fd0":"import os \nimport cv2                 \nimport numpy as np         \n                 \nfrom random import shuffle\nimport tensorflow as tf \nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport glob as gb\nfrom tensorflow.keras.utils import to_categorical","9fa05733":"#read DataSet\nTrianImage=\"\/kaggle\/input\/chest-xray-covid19-pneumonia\/Data\/train\/\"\nTestImage=\"\/kaggle\/input\/chest-xray-covid19-pneumonia\/Data\/test\/\"\n\n\nprint(TrianImage)\nprint(TestImage)","3cebcb24":"#to get all image names in train file\nPneumonaimages = os.listdir(TrianImage + \"\/PNEUMONIA\")\nNormalimages = os.listdir(TrianImage + \"\/NORMAL\")\nCOVID19images = os.listdir(TrianImage + \"\/COVID19\")\n\n\n\n\n","92e413b8":"#plot to show the size of some image\n#plot PNEUMONIA\nplt.figure(figsize=(20,10))\nfor i in range(6):\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(plt.imread(os.path.join(TrianImage + \"\/PNEUMONIA\",Pneumonaimages[i])),cmap='gray')\n    plt.title(\"PNEUMONIA\")\n    \nplt.show()\n#plot NORMAL\nplt.figure(figsize=(20,10))\nfor i in range(6):\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(plt.imread(os.path.join(TrianImage + \"\/NORMAL\",Normalimages[i])),cmap='gray')\n    plt.title(\"NORMAL\")\n\nplt.show()\n#plot \nplt.figure(figsize=(20,10))\nfor i in range(6):\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(plt.imread(os.path.join(TrianImage + \"\/COVID19\",COVID19images[i])),cmap='gray')\n    plt.title(\"COVID19\")","1399825e":"\nsizeImage=300 # to resize the all image as same size\n\ntrain_datagen = ImageDataGenerator(\n      samplewise_center=True,\n      samplewise_std_normalization= True,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      fill_mode='nearest',\n        rotation_range=90\n\n                                  )\n\n\n# NOTE: YOU MUST USE A BATCH SIZE OF 10 (batch_size=10) FOR THE \n# TRAIN GENERATOR.\nbatch_size=256\ntrain_generator =train_datagen.flow_from_directory(\n     TrianImage,\n     batch_size= batch_size,\n     shuffle=shuffle,\n     target_size=(sizeImage, sizeImage)\n\n)\n\ntest_generator =ImageDataGenerator(\n      samplewise_center=True,\n      samplewise_std_normalization= True,).flow_from_directory(\n                                             TestImage,\n                                             batch_size= 32,\n                                             shuffle=shuffle,\n                                             target_size=(sizeImage, sizeImage)\n\n                                                                )\n","046bfe4c":"trainShape=train_generator.__getitem__(0)[0].shape\ntestShape=test_generator.__getitem__(0)[0].shape","e9980a7b":"train_generator.class_indices","dc3127a1":"#show labels\ntest_generator.__getitem__(0)[1]","0feb2adf":"#Shape of Data\nprint(\"Train Shape \\n\",trainShape)\nprint(\"Test Shape \\n\",testShape)","e5bc569b":"#validation data\n\nx_val=test_generator.__getitem__(0)[0]\ny_val=test_generator.__getitem__(0)[1]\nx_val.shape , y_val.shape","47a2bacd":"\n\nLabels={0:'COVID19',1:'NORMAL' ,2:'PNEUMONIA' }\n\n# convert label to code\ndef getCode(code):\n    return Labels[code]\n\n\n# convert code to label \ndef getLabel(n):\n    for x,c in Labels.items():\n        if n==c:\n            return x\n        \n        \n        \n#Test        \nprint(getCode(0))\nprint(getLabel(\"COVID19\"))","fd09f9d6":"plt.figure(figsize=(20,10))\n\nfor i in range(9):\n\n    plt.subplot(3, 3, i + 1)\n   \n    plt.imshow(train_generator.__getitem__(0)[0][i])\n    \n    plt.title(getLabel(np.argmax(train_generator.__getitem__(0)[1][i])))","af6e2130":"# #Reading image data\n# import glob as gb\n# import cv2  \n# sizeImage=300 # to resize the all image as same size\n\n# #to read all images from directory\n# def getData(Dir,sizeImage):\n#     X=[]\n#     y=[]\n#     for folder in  os.listdir(Dir) : #to get the file name \n#         files = gb.glob(pathname= str( Dir  +\"\/\" +folder+ '\/\/*.jpg' )) # to get the images\n#         for file in files:\n#                 picture=cv2.imread(file) #  or plt.imread(file)\n#                 imageArray=cv2.resize(picture,(sizeImage,sizeImage))\n#                 X.append(list(imageArray))\n#                 y.append(getCode(folder))\n#     X=np.array(X)\n#     y=np.array(y)\n#     return X,y","bdbd71c5":"# #get train data\n# X_train, y_train = getData(TrianImage,sizeImage)\n# # get test data\n# X_test , y_test = getData(TestImage,sizeImage)\n\n","b955c63a":"# print(\"X_train Shape        \",X_train.shape)\n# print(\"X_test Shape         \",X_test.shape)\n","ed5b28df":"# # #Convert y_train to categorical\n# y_train=to_categorical(y_train,3)\n# print(\"y_train \",y_train.shape)\n\n\n\n# #Convert y_train to categorical\n# y_test=to_categorical(y_test,3)\n# print(\"y_test \",y_test.shape)\n","196eb032":"#load weight\nNetwork_Weight=\"\/kaggle\/input\/densenet-keras\/DenseNet-BC-169-32-no-top.h5\"\nprint(Network_Weight)","9af23ed1":"from tensorflow.keras.applications.densenet import DenseNet169\npre_trained_model = DenseNet169(input_shape = (sizeImage, sizeImage, 3), \n                                include_top = False, \n                                weights = None)\npre_trained_model.load_weights(Network_Weight)\nfor layer in pre_trained_model.layers:\n    layer.trainable = False  #to make the layers to Freeze Weights\n# pre_trained_model.summary()","7ed82ffd":"from tensorflow.keras import Model\nfrom tensorflow.keras.layers import Conv2D\n\n\n#Add Conv2D to Class activation Map\nc=Conv2D(256, (3,3) , activation=\"relu\")(pre_trained_model.output)\nc=Conv2D(128, (3,3) , activation=\"relu\")(c)\nc=Conv2D(64, (3,3) , activation=\"relu\" , name=\"Class_activation_map\")(c)\n\n#Flatten\nx = tf.keras.layers.Flatten()(c)\n\n#Full Connected Layers\nx = tf.keras.layers.Dense(512, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)#Add dropout to avoid Overfit\n\nx = tf.keras.layers.Dense(256, activation='relu')(x)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\n\nx = tf.keras.layers.Dropout(0.4)(x)#Add dropout to avoid Overfit\nx = tf.keras.layers.Dense(64, activation='relu')(x)\n\nx=tf.keras.layers.Dense(3 , activation='sigmoid')(x)\n       \nmodel = Model( pre_trained_model.input, x) \n\n# print(model.summary())\n#compile\nmodel.compile(optimizer='adam', loss=\"binary_crossentropy\",metrics=['accuracy'])","1983b576":"\nmodel.get_layer( name=\"Class_activation_map\",index=-9).name","23fb62bf":"\n#callbacks \nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , ModelCheckpoint ,EarlyStopping\n# lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, epsilon=0.0001, patience=1, verbose=1)\ncheckpoint = ModelCheckpoint(\"Covid-19_paper_weights.h5\", monitor='val_loss', verbose=1, save_best_only=True)\n# early_stopping=EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1,)\n","cc3d10d1":"import tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\ntf.config.list_physical_devices('GPU')","82254d6f":"epochs = 40\n\nhistory = model.fit_generator(train_generator,               \n                              validation_data=(x_val,y_val),\n                              steps_per_epoch=5144\/batch_size,#number of data\/batch_size\n                              \n                              callbacks=[checkpoint],\n                              \n                              epochs=epochs , verbose=1)","31c3c935":"import matplotlib.pyplot as plt \nplt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.show()\n\n\n\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.show()","34e46cec":"#Class activation map\nimport scipy as sp\nfor i in range(10):\n    image_index=i\n    #class activation map\n    cam_model=Model(inputs=model.inputs,outputs=(model.layers[-9].output , model.layers[-1].output))\n    # cam_model.summary()\n\n    # get weights\n    get_weights=cam_model.layers[-1].get_weights()[0]\n\n    print(get_weights.shape)\n\n    features , results=cam_model.predict(test_generator.__getitem__(i)[0][image_index].reshape(1,sizeImage,sizeImage,3))\n    predication=np.argmax(results)\n    class_activation_weights=get_weights[:,predication]\n    features.shape\n\n    #zoom image \n    class_activation_features=sp.ndimage.zoom(features.reshape(3, 3, 64), (sizeImage\/3, sizeImage\/3, 1), order=2)\n\n    print(class_activation_features.shape, class_activation_weights.shape)\n\n    cam_output=np.dot(class_activation_features ,class_activation_weights)\n\n\n    plt.imshow(cam_output ,  cmap='jet', alpha=0.5)\n    plt.imshow(test_generator.__getitem__(i)[0][image_index], alpha=0.5)\n    title=Labels[predication]+\" <=> \"+ Labels[np.argmax(test_generator.__getitem__(i)[1][image_index])]\n    plt.title(title)\n    plt.show()","778dff09":"#Evaluate Model\nmodel.evaluate(test_generator)","6cc9f1f2":"model.save('modelCovid19___4.h5')","084f5cc8":"#prediction\npred=model.predict(test_generator)","01d44a24":"print(len(pred))","bc94e910":"y_test=[]\nfor i in range(round(1288\/32)+1):\n    y_test.extend(test_generator.__getitem__(i)[1])","a1416012":"print(len(y_test))\ny_test=np.array(y_test)\ny_test","cb144eb6":"y_test=np.argmax(y_test,axis=1)\npred= np.argmax(pred,axis=1)","26ddfafe":"print(\"pred \\n\",len(pred))\nprint(\"y_test \\n\",len(y_test))","5581b395":"print(\"y_test \\n\",y_test)\nprint(\"pred \\n\",pred)","e492b956":"#confusion_matrix to check in accuracy \nfrom sklearn.metrics import confusion_matrix\ncm=confusion_matrix(pred,y_test)\nprint(cm)","8865bc3c":"plt.figure(figsize=(20,10))\nfor i in range(0,9):\n    \n    plt.subplot(3, 3, i + 1)\n    \n    plt.imshow(test_generator.__getitem__(0)[0][i],cmap='gray')\n    plt.title(f\"   Real: {getLabel(y_test[i])   } Vs  Predict: {getLabel(pred[i])}\")","24ad6043":"#lto load model\nfrom keras.models import load_model\nloadedModel=load_model(\"modelCovid19___2.h5\")","39df00d3":"loadedModel.compile(optimizer='adam', loss=\"binary_crossentropy\",metrics=['accuracy'])\nloadedModel.evaluate(test_generator)","f0b50fcd":"# Build Model","9b6bd950":"We also use the generator to transform the values in each batch so that their mean is $0$ and their standard deviation is 1.\nThis will facilitate model training by standardizing the input distribution","73b09f8d":"# Test","653a7e17":"# Another Way To Load Data","73d04283":"#  import libraries","71e4cefe":"# ImageDataGenerator (DataAugmentation )","7096cc4b":"# Explore Data After DataAugmentation and standardizing ","b4dac0ff":"# # **Explore the Data**","367d21a5":"The generator also converts our single channel X-ray images (gray-scale) to a three-channel format by repeating the values in the image across all channels.\nWe will want this because the pre-trained model that we'll use requires three-channel inputs."}}