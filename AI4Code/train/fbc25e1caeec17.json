{"cell_type":{"d34c35b7":"code","44db4c33":"code","84ef84fa":"code","e177f97d":"code","a59344c6":"code","77891ca2":"code","cc81685a":"code","dad218ab":"code","9375f808":"code","5e9d7e02":"code","d8f2d922":"code","e5d86a32":"code","b781602d":"code","400123f0":"code","30497b4a":"code","89133169":"code","7cf07293":"code","ad5edcef":"code","2a175f25":"code","100940d7":"code","8e44a8ec":"code","cea77870":"code","94291330":"code","49116f40":"code","eb36d300":"code","832721d5":"code","9136a478":"markdown","70355328":"markdown","7107b394":"markdown","4c584aec":"markdown","001b79c3":"markdown","d5677f37":"markdown","8ea47de8":"markdown","b6396c77":"markdown"},"source":{"d34c35b7":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom sklearn.metrics import confusion_matrix\nimport plotly.express as px\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.applications.resnet import ResNet101\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.xception import Xception\n\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization","44db4c33":"def make_history_plot(history):\n\n    xepochs = [x for x in range (len(history.history['loss']))]\n\n    fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Accuracy over time\", \"Loss over time\"))\n\n    for metric in ['accuracy', 'val_accuracy']:\n        fig.add_trace(go.Scatter(x=xepochs, y=history.history[metric], mode='lines+markers', name=metric), row=1, col=1)\n\n    for metric in ['loss', 'val_loss']:\n        fig.add_trace(go.Scatter(x=xepochs, y=history.history[metric], mode='lines+markers', name=metric), row=1, col=2)\n\n    fig.update_xaxes(title_text=\"Epoch\", row=1, col=1)\n    fig.update_xaxes(title_text=\"Epoch\", row=1, col=2)\n\n    fig.update_yaxes(title_text=\"Accuracy\", row=1, col=1)\n    fig.update_yaxes(title_text=\"Loss\", row=1, col=2)\n\n    fig.show()","84ef84fa":"def predict(model, val_ds):\n    y_val = []\n    y_val_pred = []\n\n    for images, targets in val_ds:\n        for image, target in zip(images, targets):\n            img_array = image.numpy().astype(\"uint8\")\n            prediction = model.predict(np.array([img_array]))\n            y_val_pred.append(np.argmax(prediction))\n            y_val.append(np.argmax(target))\n    return (y_val, y_val_pred)","e177f97d":"def make_confussion_matrix(y_val, y_val_pred, classes):\n    cm = confusion_matrix(y_val, y_val_pred)\n    fig = px.imshow(\n        cm,\n        labels=dict(x=\"Predicted\", y=\"Real\"),\n        x=classes,\n        y=classes\n    )\n\n    fig.update_xaxes(side=\"top\")\n    fig.show()","a59344c6":"path = \"\/kaggle\/input\/corn-or-maize-leaf-disease-dataset\/data\"\nclasses = os.listdir(path)\nimage_size = (256, 256)\nbatch_size = 32\nepochs = 20\n\nprint(f\"Tama\u00f1o de las im\u00e1genes: {image_size}\")\nprint(f\"Tama\u00f1o del batch: {batch_size}\")\nprint(f\"Epochs: {epochs}\")\nprint(f\"Clases: {classes}\")\n","77891ca2":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    path,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1848,\n    image_size=image_size,\n    batch_size=batch_size,\n    label_mode=\"categorical\",\n    class_names=classes\n)","cc81685a":"val_ds  = tf.keras.preprocessing.image_dataset_from_directory(\n    path,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1848,\n    image_size=image_size,\n    batch_size=batch_size,\n    label_mode=\"categorical\",\n    class_names=classes\n)","dad218ab":"plt.figure()\nfor images, labels in train_ds.take(1):\n    for i in range(15):\n        ax = plt.subplot(3, 5, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(classes[np.argmax(labels[i])])\n        plt.axis(\"off\")\nplt.show()","9375f808":"resnet_101_base_model = ResNet101(weights='imagenet', include_top=False)\nx = resnet_101_base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(512, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dense(256, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nresnet_101_predictions = Dense(len(classes), activation='softmax')(x)\n\nresnet_101_model = Model(inputs=resnet_101_base_model.input, outputs=resnet_101_predictions)\n\nfor layer in resnet_101_base_model.layers:\n    layer.trainable = False\n\nresnet_101_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[\"accuracy\"],)","5e9d7e02":"resnet_101_history = resnet_101_model.fit(train_ds, epochs=epochs, validation_data=val_ds)","d8f2d922":"(resnet_101_y_val, resnet_101_y_val_pred) = predict(resnet_101_model, val_ds)","e5d86a32":"make_history_plot(resnet_101_history)","b781602d":"cm = confusion_matrix(resnet_101_y_val, resnet_101_y_val_pred)\nfig = px.imshow(\n    cm,\n    labels=dict(x=\"Predicted\", y=\"Real\"),\n    x=classes,\n    y=classes\n)\n\nfig.update_xaxes(side=\"top\")\nfig.show()","400123f0":"print(classification_report(resnet_101_y_val, resnet_101_y_val_pred, target_names=classes))","30497b4a":"vgg19_base_model = VGG19(weights='imagenet', include_top=False)\nx = vgg19_base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nvgg19_predictions = Dense(len(classes), activation='softmax')(x)\n\nvgg19_model = Model(inputs=vgg19_base_model.input, outputs=vgg19_predictions)\n\nfor layer in vgg19_base_model.layers:\n    layer.trainable = False\n\nvgg19_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[\"accuracy\"],)","89133169":"vgg19_history = vgg19_model.fit(train_ds, epochs=epochs, validation_data=val_ds)","7cf07293":"(vgg19_y_val, vgg19_y_val_pred) = predict(vgg19_model, val_ds)","ad5edcef":"make_history_plot(vgg19_history)","2a175f25":"make_confussion_matrix(vgg19_y_val, vgg19_y_val_pred, classes)","100940d7":"print(classification_report(vgg19_y_val, vgg19_y_val_pred, target_names=classes))","8e44a8ec":"xception_base_model = Xception(weights='imagenet', include_top=False)\nx = xception_base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dense(256, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nxception_predictions = Dense(len(classes), activation='softmax')(x)\n\nxception_model = Model(inputs=xception_base_model.input, outputs=xception_predictions)\n\nfor layer in xception_base_model.layers:\n    layer.trainable = False\n\nxception_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[\"accuracy\"],)","cea77870":"xception_history = xception_model.fit(train_ds, epochs=epochs, validation_data=val_ds)","94291330":"(xception_y_val, xception_y_val_pred) = predict(xception_model, val_ds)","49116f40":"make_history_plot(xception_history)","eb36d300":"make_confussion_matrix(xception_y_val, xception_y_val_pred, classes)","832721d5":"print(classification_report(xception_y_val, xception_y_val_pred, target_names=classes))","9136a478":"# Modelos","70355328":"## Xception","7107b394":"## Funciones comunes para todos los modelos","4c584aec":"## Resnet 101","001b79c3":"## Dataset de entrenamiento y validaci\u00f3n","d5677f37":"## Constantes","8ea47de8":"## Muestra de las im\u00e1genes","b6396c77":"## VGG19"}}