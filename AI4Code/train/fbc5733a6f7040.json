{"cell_type":{"d9ef3cde":"code","5f6c3881":"code","e94f4d87":"code","ec5276ab":"code","5fdc477d":"code","0a399265":"code","76e6e871":"code","6299e5ba":"code","c5336f6f":"code","9eb4483d":"code","75039dc4":"code","093a85d8":"code","e5b0cae3":"code","a6d4c239":"code","a872c2c9":"code","4d78a33f":"code","e9a9b5f7":"code","facccb63":"code","52f41d95":"code","afb5c8da":"code","645f7136":"code","9ac465be":"code","c212926f":"code","3c76a65d":"code","d83d003e":"code","47b45afa":"code","e59b2afd":"markdown","60ef1179":"markdown","4f127ea0":"markdown","0a3407b5":"markdown","cd420bac":"markdown","75400cf4":"markdown","e9ea412e":"markdown","fbf574ba":"markdown","69ad647a":"markdown","47a5bb2e":"markdown","1921d8c8":"markdown","6bbdaea3":"markdown","14cec7e2":"markdown","d701e486":"markdown","c59f2699":"markdown","1e7f21a6":"markdown","b1cad6fa":"markdown","df4610cb":"markdown"},"source":{"d9ef3cde":"import numpy as np \nimport pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pydicom as dicom\nfrom os import listdir\nfrom glob import glob\nimport plotly.express as px\nimport cv2 as cv\nimport math","5f6c3881":"data_folder = \"\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\"","e94f4d87":"!ls -la \/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification","ec5276ab":"df_labels = pd.read_csv(f\"{data_folder}\/train_labels.csv\")\ndf_labels.head()","5fdc477d":"print(f\"Dataset shape: {df_labels.shape}\")\ndf_labels.groupby('MGMT_value').size().reset_index(name='counts')","0a399265":"sns.countplot(x = 'MGMT_value',data =df_labels)\nplt.show()","76e6e871":"train_data_path = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train'\npatients = os.listdir(train_data_path)\npatients.sort()\ndf_labels['patient_id'] = patients","6299e5ba":"# Create a list of .dicom files\n\npatient_scan_files = [] \nfor dir_name, subdir_list, file_list in os.walk(train_data_path):\n    for file_name in file_list:\n        if \".dcm\" in file_name.lower():\n            patient_scan_files.append(os.path.join(dir_name,file_name))\n            \npatient_scan_files.sort()\n\nprint(f\"Number of patients: {len(patients)}\")\nprint(\"Number of (.dicom) files =\", len(patient_scan_files))","c5336f6f":"# Read a single dicom files\nds = dicom.dcmread(patient_scan_files[6])\nprint(f\"Size of dicom file: {ds.pixel_array.shape}\")\nplt.imshow(ds.pixel_array, cmap='gray')\nplt.show()","9eb4483d":"IMG_PX_SIZE = 150\n\nfor patient in patients[6:7]:\n    print(f\"Patient Id: {patient}\")\n    label = df_labels._get_value(df_labels[df_labels['patient_id'] == str(patient)].index.tolist()[0], \n                                 'MGMT_value')\n    print(f\"MGMT promoter methylation present: {True if label == 1 else False}\\n\")\n    path = train_data_path + '\/' + patient \n    \n    # For every patient record there are 4 different types of scans available \n    patient_scan_types = os.listdir(path)\n    for scan_type in patient_scan_types:\n        dicom_path = path + '\/' + scan_type +'\/*.dcm'\n        dicom_files = sorted(glob(dicom_path),key=lambda f: int(f.split('Image-')[1].split('.')[0]))\n        slices = [dicom.read_file(file)for file in dicom_files]\n        slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n        print(f\"Scan Type:{scan_type}, {len(slices)}, {slices[0].pixel_array.shape}\")\n        fig = plt.figure()\n        mid = len(slices)\/\/2\n        for num, dicom_slice in enumerate(slices[mid-4:mid+4]):\n            y = fig.add_subplot(3,4,num+1)\n            img = cv.resize(np.array(dicom_slice.pixel_array),(IMG_PX_SIZE, IMG_PX_SIZE))\n            plt.imshow(img)\n        plt.show()\n        ","75039dc4":"# generator function to extract chunks from the list of slices \ndef chunks(dicom_file_list, number_chunks):\n    for i in range(0, len(dicom_file_list), number_chunks):\n        yield dicom_file_list[i:i+number_chunks]\n        \ndef mean(dicom_file_list):\n    return sum(dicom_file_list)\/len(dicom_file_list)","093a85d8":"IMG_PX_SIZE = 150\nNUM_SLICES = 10\n\ndef preprocess_data(patient, scan_type, df_labels, img_px_size=150, num_slices=10, visualize=False):\n    label = df_labels._get_value(df_labels[df_labels['patient_id'] == str(patient)].index.tolist()[0], \n                                 'MGMT_value')\n    dicom_path = train_data_path + '\/' + patient +'\/'+ scan_type +'\/*.dcm'\n    dicom_files = sorted(glob(dicom_path),key=lambda f: int(f.split('Image-')[1].split('.')[0]))\n    slices = [dicom.read_file(file)for file in dicom_files]\n    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n\n    new_slices = []\n    # Resize the all the slices\n    slices = [cv.resize(np.array(each_slice.pixel_array),(img_px_size, img_px_size)) for each_slice in slices]\n\n    # Determine the size of the chunks\n    chunk_size = math.ceil(len(slices) \/ num_slices)\n\n\n    for slice_chunk in chunks(slices, chunk_size):\n        chunk = list(map(mean, zip(*slice_chunk)))\n        new_slices.append(chunk)\n\n    # Handle uneven chunks \n    new_slices_size = len(new_slices)\n\n    if (new_slices_size != num_slices):\n        if (new_slices_size < num_slices):\n            for _ in range(num_slices-new_slices_size):\n                new_slices.append(new_slices[-1])\n        elif(new_slices_size > num_slices):\n            missing_slices = new_slices_size - num_slices\n            for _ in range(missing_slices):\n                val = list(map(mean, zip(*[new_slices[num_slices-1], new_slices[num_slices]])))\n                del new_slices[num_slices]\n                new_slices[num_slices -1] = val\n                    \n    if visualize:\n        fig = plt.figure()\n        for num, dicom_slice in enumerate(new_slices):\n            y = fig.add_subplot(4,5,num+1)\n            plt.imshow(dicom_slice, cmap='gray')\n        plt.show()\n                    \n    if label == 1: label = np.array([0,1])\n    elif label == 0: label = np.array([1,0])\n    \n    return np.array(new_slices), label","e5b0cae3":"master_data = []\n\nfor i, patient in enumerate(patients):\n    if i%100 == 0:\n            print(f\"Processed {i} patients\")\n    for scan_type in patient_scan_types:\n        try:\n            img_data , label = preprocess_data(patient,\n                                               scan_type,\n                                               df_labels, \n                                               img_px_size=IMG_PX_SIZE, \n                                               num_slices=NUM_SLICES, \n                                               visualize=False)\n            master_data.append([img_data, label])\n        except Exception as e:\n            print(str(e))\n            print(f\"Unabled to preprrocess the {i} patient scans\")\n        \nnp.save('masterdata-{}-{}-{}.npy'.format(IMG_PX_SIZE, IMG_PX_SIZE, NUM_SLICES), master_data)","a6d4c239":"import tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\nimport tensorflow as tfv1\n\nIMG_SIZE_PX = 150\nSLICE_COUNT = 10\n\nn_classes = 2\nbatch_size = 10\n\nx = tf.placeholder('float')\ny = tf.placeholder('float')\n\nkeep_rate = 0.8","a872c2c9":"def conv3d(x, W):\n    return tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='SAME')\n\ndef maxpool3d(x):\n    return tf.nn.max_pool3d(x, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='SAME')","4d78a33f":"def convolutional_neural_network(x):\n    #                # 5 x 5 x 5 patches, 1 channel, 32 features to compute.\n    weights = {'W_conv1':tf.Variable(tf.random_normal([3,3,3,1,32])),\n               #       5 x 5 x 5 patches, 32 channels, 64 features to compute.\n               'W_conv2':tf.Variable(tf.random_normal([3,3,3,32,64])),\n               #                                  64 features\n               'W_fc':tf.Variable(tf.random_normal([8871936,1024])),\n               'out':tf.Variable(tf.random_normal([1024, n_classes]))}\n\n    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n               'b_conv2':tf.Variable(tf.random_normal([64])),\n               'b_fc':tf.Variable(tf.random_normal([1024])),\n               'out':tf.Variable(tf.random_normal([n_classes]))}\n\n    #                            image X      image Y        image Z\n    x = tf.reshape(x, shape=[-1, IMG_SIZE_PX, IMG_SIZE_PX, NUM_SLICES, 1])\n\n    conv1 = tf.nn.relu(conv3d(x, weights['W_conv1']) + biases['b_conv1'])\n    conv1 = maxpool3d(conv1)\n\n\n    conv2 = tf.nn.relu(conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\n    conv2 = maxpool3d(conv2)\n\n    fc = tf.reshape(conv2,[-1, 8871936])\n    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n    fc = tf.nn.dropout(fc, keep_rate)\n\n    output = tf.matmul(fc, weights['out'])+biases['out']\n\n    return output","e9a9b5f7":"master_data = np.load('.\/masterdata-150-150-20.npy', allow_pickle=True)\n# If you are working with the basic sample data, use maybe 2 instead of 100 here... you don't have enough data to really do this\ntrain_data = master_data[:-100]\nvalidation_data = master_data[-100:]\n\n\ndef train_neural_network(x):\n    prediction = convolutional_neural_network(x)\n    cost = tfv1.reduce_mean( tfv1.nn.softmax_cross_entropy_with_logits(prediction,y) )\n    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n    \n    hm_epochs = 10\n    with tf.Session() as sess:\n        sess.run(tf.initialize_all_variables())\n        \n        successful_runs = 0\n        total_runs = 0\n        for epoch in range(hm_epochs):\n            epoch_loss = 0\n            for data in train_data:\n                total_runs += 1\n                try:\n                    X = data[0]\n                    Y = data[1]\n                    _, c = sess.run([optimizer, cost], feed_dict={x: X, y: Y})\n                    epoch_loss += c\n                    successful_runs += 1\n                except Exception as e:\n                    # I am passing for the sake of notebook space, but we are getting 1 shaping issue from one \n                    # input tensor. Not sure why, will have to look into it. Guessing it's\n                    # one of the depths that doesn't come to 20.\n                    pass\n                    #print(str(e))\n            \n            print('Epoch', epoch+1, 'completed out of',hm_epochs,'loss:',epoch_loss)\n\n            correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n            accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n\n            print('Accuracy:',accuracy.eval({x:[i[0] for i in validation_data], y:[i[1] for i in validation_data]}))\n            \n        print('Done. Finishing accuracy:')\n        print('Accuracy:',accuracy.eval({x:[i[0] for i in validation_data], y:[i[1] for i in validation_data]}))\n        \n        print('fitment percent:',successful_runs\/total_runs)\n        \n# train_neural_network(x)","facccb63":"# helper methods \n\ndef read_dcm(path):\n    return dicom.dcmread(path)\n\ndef read_dcm_by_seq(cohort, patient_id, mri_sequence):\n    files_glob = f'{data_folder}\/{cohort}\/{patient_id}\/{mri_sequence}\/*.dcm'\n    sorted_files = sorted(glob(files_glob),key=lambda f: int(f.split('Image-')[1].split('.')[0]))\n    return [dicom.read_file(f) for f in sorted_files]\n\ndef display_dcm(dicom):\n    plt.imshow(dicom.pixel_array)\n    plt.show()\n    \ndef display_full_scan(dicom_instance_list):\n    images = np.array([dcm.pixel_array for dcm in dicom_instance_list])\n    fig = px.imshow(images, \n                    animation_frame=0, \n                    binary_string=True, \n                    labels=dict(animation_frame=\"instance\"), \n                    height=600)\n    fig.show()\n    ","52f41d95":"# Extract Scan orientation information\n\ndef scan_orientation(dcm):\n    rt = None\n    (x1, y1, z1, x2, y2, z2) = [round(cord) for cord in dcm.ImageOrientationPatient]\n    if (x1,y1,x2,y2) == (1,0,0,0):\n        rt = 'coronal'\n    if (x1,y1,x2,y2) == (1,0,0,1):\n        rt = 'axial'\n    if (x1,y1,x2,y2) == (0,1,0,0):\n        rt = 'sagittal'\n        \n    if (rt):\n        return rt\n    else:\n        raise ValueError(f\"Failed extract the Scan Orientation\")","afb5c8da":"cohort = 'train'\npatient_id  = '00000'","645f7136":"flair_data_files = read_dcm_by_seq(cohort, patient_id, 'FLAIR')\nt1w_data_files = read_dcm_by_seq(cohort, patient_id, 'T1w')\nt1wce_data_files = read_dcm_by_seq(cohort, patient_id, 'T1wCE')\nt2w_data_files = read_dcm_by_seq(cohort, patient_id, 'T2w')","9ac465be":"print(f\"Scan Orientation of MRI Sequences,  Total Number of Instances \\n\")\n\nprint(f\"FailR: {scan_orientation(flair_data_files[0])}, Instances: {len(flair_data_files)} \\n\")\n\nprint(f\"T1w: {scan_orientation(t1w_data_files[0])}, Instances: {len(t1w_data_files)}\\n\")\n\nprint(f\"T1wce: {scan_orientation(t1wce_data_files[0])}, Instances: {len(t1wce_data_files)}\\n\")\n\nprint(f\"T2w: {scan_orientation(t2w_data_files[0])}, Instances: {len(t2w_data_files)}\\n\")","c212926f":"display_full_scan(flair_data_files)","3c76a65d":"display_full_scan(t1w_data_files)","d83d003e":"display_full_scan(t1wce_data_files)","47b45afa":"display_full_scan(t2w_data_files)","e59b2afd":"> **The target variable MGMT_value for each subject in the training data indicates the presence of MGMT promoter methylation.** ","60ef1179":"The most common MRI sequences are T1-weighted and T2-weighted scans. (https:\/\/case.edu\/med\/neurology\/NR\/MRI%20Basics.htm)\n\n- T1-weighted images are produced by using short TE and TR times. The contrast and brightness of the image are predominately determined by T1 properties of tissue. Conversely, \n\n- T2-weighted images are produced by using longer TE and TR times. In these images, the contrast and brightness are predominately determined by the T2 properties of tissue.\n\n- A third commonly used sequence is the Fluid Attenuated Inversion Recovery (Flair). The Flair sequence is similar to a T2-weighted image except that the TE and TR times are very long\n\n- T1WCE is another sequence in which contrast is enhanced. \n\nThese sequences results in different contrast of Gray scale in the scans ","4f127ea0":"**Dataset has scan taken for all these MRI sequence techniques.** \n\nLet's fetch one Patient  data and analze it","0a3407b5":"### Visualize the full MRI scans**\n\n*1. Flair*","cd420bac":"## Scan Analysis","75400cf4":"MR scanner can generate three types of orientations of human brain.\n1. Axial - from top to down\n2. Coronal - from front to back\n3. Sagittal - and side to side\n\nIn the X-Y-Z coordinate system, \n- A axial is an X-Y plane, parallel to the ground, the head from the feet. \n- A coronal is an X-Z plane, the front from the back. \n- A sagittal is a Y-Z plane, which separates left from right\n\n![image.png](attachment:0e49a4a9-5539-4800-97b9-daab38271624.png)","e9ea412e":"### Load all the dicom files as per thier sequence of MRI for the given Patient ID","fbf574ba":"> **Dataste is banalanced to some extent**","69ad647a":"*2. T1w*","47a5bb2e":"*3. T1wc*","1921d8c8":"### Attributes of Data ","6bbdaea3":"**Start and end of the scan has a lot of empty frames which needs to removed in preprocessing**","14cec7e2":"### Orientations of the scans for each sequence type","d701e486":"Input size is too big for convolutional network to handle, using opencv to resize it\n\nLet's read one patient record and resize it","c59f2699":"## Load in dataset labels ","1e7f21a6":"### Preprocessing\n\nThere are three problems that needs to addressed \n\n1. Input size of the dicom files need to reduced currently it is 512X512 \n    - This can be achieved using opencv as shown above\n    \n2. Slices for each scan type is different \n    - One way to get same number of slices for the scan is chunck the list of slices based on predefined NUM_SLICES then average all the chunks to get single chunk. \n    \n    \n3. Scan color contrast need to be retained ","b1cad6fa":"## Load in the train data\n\n```\nTraining\/Validation\/Testing\n\u2502\n\u2514\u2500\u2500\u2500 00000\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500 FLAIR\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 ...\n\u2502   \u2514\u2500\u2500\u2500 T1w\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 ...\n\u2502   \u2514\u2500\u2500\u2500 T1wCE\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 ...\n\u2502   \u2514\u2500\u2500\u2500 T2w\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 .....\n\n```\n","df4610cb":"*4. T2w*"}}