{"cell_type":{"32cd6614":"code","a4d4ac9f":"code","dc1f7004":"code","57b22852":"code","283385c7":"code","d9396da6":"code","2a1b1931":"code","ef981f5b":"code","da72d968":"code","b2f94e0b":"code","359aa6fa":"code","b33d1853":"code","87171572":"code","82035070":"code","e11dd3d3":"code","b5316606":"code","c4aad3fd":"markdown","4ee0b47a":"markdown","e91ac1c1":"markdown","b290cd3f":"markdown","f8bb461f":"markdown","101def42":"markdown","c03f9515":"markdown","6a75f07a":"markdown"},"source":{"32cd6614":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split","a4d4ac9f":"df_LIB = pd.read_csv(\"\/kaggle\/input\/crystal-system-properties-for-liion-batteries\/lithium-ion batteries.csv\")\ndatapath = '..\/Ram\/Data_Sets\/'\nfilename = 'LIB.csv'\ntrain_datafile = datapath + filename\n#df_LIB = pd.read_csv(train_datafile)\nprint(df_LIB.shape)\ndf_LIB.head()","dc1f7004":"!pip install deep_autoviml --upgrade","57b22852":"!pip install chemparse\nimport chemparse","283385c7":"LIB_dict = df_LIB.Formula.apply(chemparse.parse_formula)\nLIB_dict = pd.json_normalize(LIB_dict)\nLIB_dict = LIB_dict.fillna(0)\ndf_LIB = df_LIB.join(LIB_dict)","d9396da6":"df_LIB.head()","2a1b1931":"df_LIB = df_LIB.drop(['Materials Id', 'Formula'], axis =1)","ef981f5b":"train, test = train_test_split(df_LIB, test_size=0.1, random_state=99)\nprint(train.shape, test.shape)","da72d968":"target = 'Crystal System'","b2f94e0b":"from deep_autoviml import deep_autoviml as deepauto","359aa6fa":"######   D E F A U L T S    S E T T I N G S   F O R   D E E P    A U T O  V I M L ###\nkeras_model_type =  \"fast1\" ## always try \"fast\" first, then \"fast2\", \"auto\", etc.\n### always set early_stopping to True first and then change it to False\n#### You always need 15 max_trials to get something decent #####\n#### always set tuner to \"storm\" and then \"optuna\". \n### NLP char limit kicks off NLP processing. Feature Cross later.\nproject_name = \"LiB\"\nmodel_options = {'nlp_char_limit':50, 'cat_feat_cross_flag':False,\n                 'max_trials': 10, \"tuner\": \"storm\"}\nkeras_options = {\"patience\":10, 'class_weight': True, 'early_stopping': True, \n                 'lr_scheduler': '', \"optimizer\": 'RMS'}\n","b33d1853":"model, cat_vocab_dict = deepauto.fit(train, target, keras_model_type=keras_model_type,\n\t\tproject_name=project_name, keras_options=keras_options,  \n\t\tmodel_options=model_options, save_model_flag=False, use_my_model='',\n\t\tmodel_use_case='', verbose=1)","87171572":"predictions = deepauto.predict(model, project_name, test_dataset=test,\n                                 keras_model_type=keras_model_type, \n                                 cat_vocab_dict=cat_vocab_dict)","82035070":"y_preds = predictions[-1]\ny_preds[:4]","e11dd3d3":"y_test = test[target].values\ny_test[:4]","b5316606":"from deep_autoviml import print_classification_model_stats, print_regression_model_stats\nprint_classification_model_stats(y_test, y_preds)","c4aad3fd":"# Let's visualize the dataset using AutoViz","4ee0b47a":"# deep_autoviml is an AutoML library for building deep learning models using tensorflow and keras using a single line of code.\n## For github visit: [deep_autoviml](https:\/\/github.com\/AutoViML\/deep_autoviml)\n## It will automatically perform the following given train and test:\n- Load a wide variety of performant DNN architectures such as deep and wide, deep and cross models, etc.\n- Use a hypertuner named Storm-Tuner to select the best hyper params for each of the model architectures\n- Select the best model and add pre-processing layers for feature transformation and do selective feature engineering\n- For NLP tasks: it select a BERT or USE model along with text processors\n- Train best model and run predictions using the trained model\n- You can automatically save the model with its preprocessing layers and load it elsewhere or serve it using tf.serving on Cloud providers","e91ac1c1":"#### That's how you get 96% balanced accuracy on a very tiny but very difficult dataset!","b290cd3f":"# we will now use deep_autoviml to see how well it performs on this tiny dataset","f8bb461f":"# Pip Install Deep AutoViML library here","101def42":"av = AutoViz_Class()\ndf_autoviz = av.AutoViz(filename=\"\",dfte=df_LIB, depVar=target)","c03f9515":"!pip install autoviz\n!pip install xlrd\n#importing Autoviz class\nfrom autoviz.AutoViz_Class import AutoViz_Class","6a75f07a":"### This notebook is derived from the following notebook by Divya. Our many thanks!!\nhttps:\/\/www.kaggle.com\/dgladha\/lib-classification"}}