{"cell_type":{"e1ee52ca":"code","27a3ba46":"code","482c9a24":"code","ef2565ec":"code","6a4eb130":"code","7bd34433":"code","52013a88":"code","ddb64f47":"code","33e7032c":"code","5679f903":"code","134ec3b6":"code","9c3c8c91":"code","45594cb0":"code","efb1f335":"code","f93fd009":"code","1a4f9613":"code","d97d0ca7":"code","939d6c4c":"code","39a7c618":"code","c2429441":"code","61a7b763":"code","3135e79f":"code","6f2a8c0c":"code","bf43dd72":"code","425c0b88":"code","acf4a410":"code","c537cbd4":"code","8cf2d864":"code","5fd0f4a5":"code","a3b948c3":"code","b3a9dc26":"code","459ad9ed":"code","e247e23f":"code","9666e554":"code","2d5b19fb":"code","a90deafc":"code","b4de274b":"code","6015d224":"code","d738194f":"markdown","f2cb5629":"markdown","23f585ce":"markdown","54705691":"markdown","0545a887":"markdown"},"source":{"e1ee52ca":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","27a3ba46":"training_dir='\/kaggle\/input\/siim-isic-melanoma-classification\/train.csv'\ntest_dir='\/kaggle\/input\/siim-isic-melanoma-classification\/test.csv'\ntrain_dataframe=pd.read_csv(training_dir)\ntest_dataframe=pd.read_csv(test_dir)\ntrain_dataframe.head(7)\n","482c9a24":"test=pd.read_csv(test_dir)","ef2565ec":"train_dataframe['target'].value_counts()","6a4eb130":"#percentage of people not suffering from Melanoma are:\nprint('Non-Melonoma patients are :',(32542\/(32542+584)*100))\nprint('Melonoma patients are : ',(584\/(32542+584)*100))","7bd34433":"#Format in which we need to submit the submission file.\nsubmission=pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/sample_submission.csv')\nsubmission.head(10)","52013a88":"train_dataframe['sex'].value_counts() \n#It shows,there is no gender biasness in this dataset,both are approximately equal","ddb64f47":"train_dataframe.describe()","33e7032c":"#'anatom_site_general_challenge' is the location of cancer,so it is very important feature.\n\nlabels=train_dataframe['anatom_site_general_challenge'].value_counts()\nvalues=train_dataframe['anatom_site_general_challenge'].value_counts().values\n# i will try to plot it using graph,i think pie chart is good \nfig=labels.plot.pie(y=values,figsize=(10,10),autopct='%1.1f%%',startangle=15, shadow = True)\n","5679f903":"train_dataframe.drop(train_dataframe.loc[train_dataframe['diagnosis']=='unknown'].index, inplace=True)","134ec3b6":"#Another feature is diagnosis\n#I try to remove the \"unknown\" valued rows.\n\ndiag_index=train_dataframe['diagnosis'].value_counts()\ndiag_labels=train_dataframe['diagnosis'].value_counts().values\ndiag_index,diag_labels","9c3c8c91":"diag_index.plot.pie(y=diag_labels,subplots=True,figsize=(7,5), startangle=15)","45594cb0":"df=train_dataframe.drop(['image_name','patient_id','sex','age_approx','anatom_site_general_challenge','target'],axis=1)","efb1f335":"df","f93fd009":"# if we will try to figure out that in which category of diagnosis ,most of the people are maligant or not maligant\npd.crosstab(df['diagnosis'].values,df['benign_malignant'])","1a4f9613":"benign_data=train_dataframe[train_dataframe['target']==0].sample(1500) #i have taken a small sample of benign_data\nmaligant_data=train_dataframe[train_dataframe['target']==1]\ntrain=pd.concat([benign_data,maligant_data])\ntrain=train.reset_index()","d97d0ca7":"train","939d6c4c":"train_dir='\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'\ntest_dir='\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/test\/'\ndata=[]\nlabels=[]\nfor i in range(train.shape[0]):\n    data.append(train_dir+train['image_name'].iloc[i]+'.jpg')\n    labels.append(train['target'].iloc[i])\ndf=pd.DataFrame(data)\ndf.columns=['images']\ndf['target']=labels","39a7c618":"train.shape,df.shape","c2429441":"# ..\/input\/siim-isic-melanoma-classification\/jpeg\/train","61a7b763":"test_data=[]\nfor i in range(test.shape[0]):\n    test_data.append(test_dir + test['image_name'].iloc[i]+'.jpg')\ndf_test=pd.DataFrame(test_data)\ndf_test.columns=['images']","3135e79f":"df_test","6f2a8c0c":"from sklearn.model_selection import train_test_split\nx_train,x_val,y_train,y_val=train_test_split(df['images'],df['target'],test_size=0.2,random_state=42)\n\ntrain_gen = pd.DataFrame({'image_dir': x_train, 'target': y_train})\nval_gen = pd.DataFrame({'image_dir': x_val, 'target': y_val})","bf43dd72":"train_gen","425c0b88":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,horizontal_flip=True)\nval_datagen=ImageDataGenerator(rescale=1.\/255)\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_gen,\n    x_col='image_dir',\n    y_col='target',\n    target_size=(256, 256),\n    batch_size=8,\n    shuffle=True,\n    class_mode='raw')\n\nvalidation_generator = val_datagen.flow_from_dataframe(\n    val_gen,\n    x_col='image_dir',\n    y_col='target',\n    target_size=(256, 256),\n    shuffle=False,\n    batch_size=8,\n    class_mode='raw')","acf4a410":"train_gen.shape,val_gen.shape","c537cbd4":"#from keras.applications.vgg16 import VGG16\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras import layers\nfrom keras.metrics import AUC\nfrom keras.activations import sigmoid\nfrom keras.optimizers import SGD, Adam, Adamax\nfrom keras import Model","8cf2d864":"from tensorflow.keras.applications import EfficientNetB0\nmodel=EfficientNetB0(weights='imagenet',include_top=False,drop_connect_rate=0.4,input_shape=(256, 256, 3))\n","5fd0f4a5":"x = layers.Flatten()(model.output)\noutput = layers.Dense(1, activation='sigmoid')(x)\nmodel = Model(model.input, output)","a3b948c3":"pip install focal-loss","b3a9dc26":"import keras\nfrom focal_loss import BinaryFocalLoss\nfrom keras.metrics import AUC\nopt = keras.optimizers.Adam(lr = 1e-5)\n# model.compile(loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'],optimizer=opt)\nmodel.compile(loss=BinaryFocalLoss(gamma=2), metrics=['AUC'],optimizer=opt)","459ad9ed":"nb_epochs = 25\nbatch_size=8\nnb_train_steps = train_gen.shape[0]\/\/batch_size\nnb_val_steps=val_gen.shape[0]\/\/batch_size\nprint(\"Number of training and validation steps: {} and {}\".format(nb_train_steps,nb_val_steps))","e247e23f":"#CallBacks Function\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ReduceLROnPlateau\nearly_stop=EarlyStopping(monitor=\"val_loss\",\n                         patience=10,\n                         mode=\"auto\",)\nLearning_rate_reduction=ReduceLROnPlateau(monitor='val_loss',patience=2,verbose=1,factor=0.5,min_lr=0.001)\n\ncallbacks=[early_stop,Learning_rate_reduction]","9666e554":"hist=model.fit_generator(\n    train_generator,\n    steps_per_epoch=nb_train_steps,\n    epochs=nb_epochs,\n    validation_data=validation_generator,\n    callbacks=callbacks,\n    validation_steps=nb_val_steps)\n\n# history = model.fit_generator(train_generator,validation_data = validation_generator,epochs = 20, verbose = 1,callbacks=callbacks)","2d5b19fb":"import cv2\ntarget=[]\nfor path in df_test['images']:\n    img=cv2.imread(str(path))\n    img = cv2.resize(img, (256,256))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)\/255.\n    img=np.reshape(img,(1,256,256,3))\n    prediction=model.predict(img)\n    target.append(prediction[0][0])\n\nsubmission['target']=target","a90deafc":"submission.to_csv('submission.csv', index=False)","b4de274b":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nacc = hist.history['auc']\nval_acc = hist.history['val_auc']\nloss = hist.history['loss']\nval_loss = hist.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\n#accuracy plot\nplt.plot(epochs, acc, color='green', label='Training Accuracy')\nplt.plot(epochs, val_acc, color='blue', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.figure()\n#loss plot\nplt.plot(epochs, loss, color='pink', label='Training Loss')\nplt.plot(epochs, val_loss, color='red', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","6015d224":"import pickle\nPkl_Filename = \"Pickle_RL_Model.pkl\"\nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(model, file)","d738194f":"** 82% data are unknown  and 16% are navus**","f2cb5629":"**benign cases are diagnosed as nevus\n**and those diagnosed as \"melanoma\" are maligant**","23f585ce":"***Mean of age is approx 49,and 75% of dataset lies under 60 ,\nand 1remaining upto 90 so there are not much more outliers in the dataset w.r.t age***","54705691":"As we saw above we have 33126 training_dataset and in which there is only 584 having label 1 or suffered from Melanoma. \nSo,here \"data imblance\" problem arises.\nonly 1.7% of people suffered from meloma in the given dataset","0545a887":"**If we look at the graph carefully,\nmore than 51% of data lies under \"torso\"\nit means half of the person having cancer on \"torso\"**"}}