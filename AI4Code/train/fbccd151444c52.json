{"cell_type":{"2a5aea2d":"code","1619bee1":"code","d38fc602":"code","0c406ca1":"code","59fee0f5":"code","03c71109":"code","69d64497":"code","5b3fee89":"code","083e67a0":"code","39b20563":"code","d2ab1678":"code","242c7eba":"code","203bb2fe":"code","e8c26f57":"code","1a13d986":"code","2c37dccd":"code","a2ee1456":"code","c9f0a792":"code","bfc4d156":"code","cc95728a":"code","4edd13f5":"code","295be1de":"code","0b4c00cf":"code","bf33b247":"code","72da7cf9":"code","7dfafe8f":"code","d4370ffc":"code","3fe4913d":"code","7dc848a1":"code","1143847f":"code","9a62067e":"code","246c220a":"code","f6f4eda7":"code","543f0658":"code","6fd23dc0":"code","8012922c":"code","f09934be":"code","1b0199cf":"code","c7e2c056":"code","79cb7cbf":"code","b43cdbff":"code","7f04e48c":"code","d249f5c2":"code","617663dd":"code","9bb16ef8":"code","62a74937":"code","c802e812":"code","864f4f77":"markdown","b2b73d2c":"markdown","8c768fed":"markdown","b780580c":"markdown","3a66c1a3":"markdown","56a8dbe5":"markdown","5e7211ea":"markdown","3c204a4c":"markdown","1e6dffeb":"markdown","0f6a69fa":"markdown","064d3a30":"markdown","77df1250":"markdown","0eb23cf9":"markdown","5acd3b4e":"markdown","e2efee87":"markdown","84812ab6":"markdown","fa41d97a":"markdown","08acd745":"markdown"},"source":{"2a5aea2d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1619bee1":"# libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.datasets import CIFAR10\nfrom torchvision.transforms import ToTensor\nfrom torchvision.utils import make_grid\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data import random_split\n%matplotlib inline\n\nfrom pathlib import Path\nimport os\nimport cv2\nimport glob\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport torchvision.transforms as transforms\nimport torch\nimport torchvision.transforms.functional as F\nimport torch.nn.functional as F\nimport torch.optim as optim","d38fc602":"!pip install albumentations > \/dev\/null 2>&1","0c406ca1":"!pip install pretrainedmodels > \/dev\/null 2>&1","59fee0f5":"import albumentations\nimport pretrainedmodels\nfrom tqdm.notebook import tqdm","03c71109":"model_resnet18 = torch.hub.load('pytorch\/vision', 'resnet18', pretrained=True)\nmodel_resnet34 = torch.hub.load('pytorch\/vision', 'resnet34', pretrained=True)","69d64497":"for name, param in model_resnet18.named_parameters():\n    if(\"bn\" not in name):\n        param.requires_grad = False\n        \nfor name, param in model_resnet34.named_parameters():\n    if(\"bn\" not in name):\n        param.requires_grad = False","5b3fee89":"num_classes = 2\n\nmodel_resnet18.fc = nn.Sequential(nn.Linear(model_resnet18.fc.in_features,512),\n                                  nn.ReLU(),\n                                  nn.Dropout(),\n                                  nn.Linear(512, num_classes))\n\nmodel_resnet34.fc = nn.Sequential(nn.Linear(model_resnet34.fc.in_features,512),\n                                  nn.ReLU(),\n                                  nn.Dropout(),\n                                  nn.Linear(512, num_classes))","083e67a0":"def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=5, device=\"cpu\"):\n    for epoch in range(epochs):\n        training_loss = 0.0\n        valid_loss = 0.0\n        model.train()\n        for batch in train_loader:\n            optimizer.zero_grad()\n            inputs, targets = batch\n            inputs = inputs.to(device)\n            targets = targets.to(device)\n            output = model(inputs)\n            loss = loss_fn(output, targets)\n            loss.backward()\n            optimizer.step()\n            training_loss += loss.data.item() * inputs.size(0)\n        training_loss \/= len(train_loader.dataset)\n        \n        model.eval()\n        num_correct = 0 \n        num_examples = 0\n        for batch in val_loader:\n            inputs, targets = batch\n            inputs = inputs.to(device)\n            output = model(inputs)\n            targets = targets.to(device)\n            loss = loss_fn(output,targets) \n            valid_loss += loss.data.item() * inputs.size(0)\n                        \n            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n            num_correct += torch.sum(correct).item()\n            num_examples += correct.shape[0]\n        valid_loss \/= len(val_loader.dataset)\n\n        print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}, accuracy = {:.4f}'.format(epoch, training_loss,\n        valid_loss, num_correct \/ num_examples))\n","39b20563":"## read the csv data files\ntrain_df = pd.read_csv('..\/input\/janatahack-av-computervision\/train_SOaYf6m\/train.csv')\ntest_df = pd.read_csv('..\/input\/janatahack-av-computervision\/test_vc2kHdQ.csv')\nsubmit = pd.read_csv('..\/input\/janatahack-av-computervision\/sample_submission_yxjOnvz.csv')","d2ab1678":"train_df.shape, test_df.shape","242c7eba":"## set the data folder\ndata_folder = Path(\"..\/input\/janatahack-av-computervision\")\ndata_path = \"..\/input\/janatahack-av-computervision\/train_SOaYf6m\/images\/\"\n\npath = os.path.join(data_path , \"*jpg\")","203bb2fe":"files = glob.glob(path)\ndata=[]\nfor file in files:\n    image = cv2.imread(file)\n    data.append(image)","e8c26f57":"data_path","1a13d986":"class EmergencyDataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None):\n        self.df = pd.read_csv(csv_file)\n        self.transform = transform\n        self.root_dir = root_dir\n        \n    def __len__(self):\n        return len(self.df)    \n    \n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        img_id, img_label = row['image_names'], row['emergency_or_not']\n        img_fname = self.root_dir + str(img_id)\n#         + \".jpg\"\n        img = Image.open(img_fname)\n        if self.transform:\n            img = self.transform(img)\n        return img, img_label","2c37dccd":"batch_size=32\nimg_dimensions = 224\n\n# Normalize to the ImageNet mean and standard deviation\n# Could calculate it for the cats\/dogs data set, but the ImageNet\n# values give acceptable results here.\nimg_transforms = transforms.Compose([\n    transforms.Resize((img_dimensions, img_dimensions)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n    ])\n\nimg_test_transforms = transforms.Compose([\n    transforms.Resize((img_dimensions,img_dimensions)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n    ])\n\ndef check_image(path):\n    try:\n        im = Image.open(path)\n        return True\n    except:\n        return False\n","a2ee1456":"TRAIN_CSV = '..\/input\/janatahack-av-computervision\/train_SOaYf6m\/train.csv'\ntransform = transforms.Compose([\n    transforms.Resize((img_dimensions, img_dimensions)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n    ])\ndataset = EmergencyDataset(TRAIN_CSV, data_path, transform=transform)","c9f0a792":"torch.manual_seed(10)\n\nval_pct = 0.2\nval_size = int(val_pct * len(dataset))\ntrain_size = len(dataset) - val_size","bfc4d156":"train_ds, val_ds = random_split(dataset, [train_size, val_size])\nlen(train_ds), len(val_ds)","cc95728a":"batch_size = 32","4edd13f5":"def show_batch(dl, invert=True):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(16, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        data = 1-images if invert else images\n        ax.imshow(make_grid(data, nrow=16).permute(1, 2, 0))\n        break","295be1de":"train_data_loader  = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\nvalidation_data_loader = DataLoader(val_ds, batch_size*2, num_workers=2, pin_memory=True)\n\n\nTEST_CSV = '..\/input\/janatahack-av-computervision\/sample_submission_yxjOnvz.csv'\ntest_dataset = EmergencyDataset(TEST_CSV, data_path, transform=transform)\ntest_data_loader = DataLoader(test_dataset, batch_size, num_workers=2, pin_memory=True)","0b4c00cf":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\") \nelse:\n    device = torch.device(\"cpu\")","bf33b247":"print(device)","72da7cf9":"print(f'Num training images: {len(train_data_loader.dataset)}')\nprint(f'Num validation images: {len(validation_data_loader.dataset)}')\nprint(f'Num test images: {len(test_data_loader.dataset)}')","7dfafe8f":"def valid_model(model):\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in validation_data_loader:\n            images, labels = data[0].to(device), data[1].to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    print('correct: {:d}  total: {:d}'.format(correct, total))\n    print('accuracy = {:f}'.format(correct \/ total))","d4370ffc":"model_resnet18.to(device)\noptimizer = optim.Adam(model_resnet18.parameters(), lr=0.001)\ntrain(model_resnet18, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=10, device=device)","3fe4913d":"valid_model(model_resnet18)","7dc848a1":"@torch.no_grad()\ndef predict_dl(dl, model):    \n#     torch.cuda.empty_cache()\n    batch_probs = []\n    for xb, _ in tqdm(dl):\n        probs = model(xb)        \n        batch_probs.append(probs.cpu().detach())\n    batch_probs = torch.cat(batch_probs)\n\n    return [x.numpy() for x in batch_probs]\n ","1143847f":"submission_df = pd.read_csv(TEST_CSV)\ntest_preds = predict_dl(test_data_loader, model_resnet18)\nsubmission_df.emergency_or_not = np.argmax(test_preds, axis = 1)\nsubmission_df.head()","9a62067e":"submission_df['emergency_or_not'].value_counts()","246c220a":"submission_df.to_csv('submission.csv', index=False)","f6f4eda7":"submission_df.head()","543f0658":"# import the modules we'll need\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n\n# create a link to download the dataframe\ncreate_download_link(submission_df)","6fd23dc0":"model_resnet34.to(device)\noptimizer = optim.Adam(model_resnet34.parameters(), lr=0.001)\ntrain(model_resnet34, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=10, device=device)","8012922c":"valid_model(model_resnet34)","f09934be":"data_path","1b0199cf":"import os\ndef find_classes(dir):\n    classes = os.listdir(dir)\n    classes.sort()\n    class_to_idx = {classes[i]: i for i in range(len(classes))}\n    return classes, class_to_idx\n\ndef make_prediction(model, filename):\n    labels, _ = find_classes(data_path)\n    img = Image.open(filename)\n    img = img_test_transforms(img)\n    img = img.unsqueeze(0)\n    prediction = model(img.to(device))\n    prediction = prediction.argmax()\n    print(labels[prediction])\n    \nmake_prediction(model_resnet34, '\/kaggle\/input\/janatahack-av-computervision\/train_SOaYf6m\/images\/2345.jpg')\nmake_prediction(model_resnet34, '\/kaggle\/input\/janatahack-av-computervision\/train_SOaYf6m\/images\/438.jpg')","c7e2c056":"torch.save(model_resnet18.state_dict(), \".\/model_resnet18.pth\")\ntorch.save(model_resnet34.state_dict(), \".\/model_resnet34.pth\")\n\n# Remember that you must call model.eval() to set dropout and batch normalization layers to\n# evaluation mode before running inference. Failing to do this will yield inconsistent inference results.\n\nresnet18 = torch.hub.load('pytorch\/vision', 'resnet18')\nresnet18.fc = nn.Sequential(nn.Linear(resnet18.fc.in_features,512),nn.ReLU(), nn.Dropout(), nn.Linear(512, num_classes))\nresnet18.load_state_dict(torch.load('.\/model_resnet18.pth'))\nresnet18.eval()\n\nresnet34 = torch.hub.load('pytorch\/vision', 'resnet34')\nresnet34.fc = nn.Sequential(nn.Linear(resnet34.fc.in_features,512),nn.ReLU(), nn.Dropout(), nn.Linear(512, num_classes))\nresnet34.load_state_dict(torch.load('.\/model_resnet34.pth'))\nresnet34.eval()","79cb7cbf":"# Test against the average of each prediction from the two models\nmodels_ensemble = [resnet18.to(device), resnet34.to(device)]\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for data in validation_data_loader:\n        images, labels = data[0].to(device), data[1].to(device)\n        predictions = [i(images).data for i in models_ensemble]\n        avg_predictions = torch.mean(torch.stack(predictions), dim=0)\n        _, predicted = torch.max(avg_predictions, 1)\n\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \nprint('accuracy = {:f}'.format(correct \/ total))\nprint('correct: {:d}  total: {:d}'.format(correct, total))","b43cdbff":"# Test against the average of each prediction from the two models\nmodels_ensemble = [resnet18.to(device), resnet34.to(device)]\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for data in test_data_loader:\n        images = data[0].to(device)\n        predictions = [i(images).data for i in models_ensemble]\n        avg_predictions = torch.mean(torch.stack(predictions), dim=0)\n        _, predicted = torch.max(avg_predictions, 1)","7f04e48c":"predicted","d249f5c2":"# Project name used for jovian.commit\n# project_name = '01-Emergency_Vehicle_Detection_using_Pretrained_Models'","617663dd":"# !pip install jovian --upgrade --quiet","9bb16ef8":"# import jovian","62a74937":"# Clear previously recorded hyperparams & metrics\n# jovian.reset()","c802e812":"# torch.save(model_resnet18.state_dict(), \"model_resnet18.pth\")\n# torch.save(model_resnet34.state_dict(), \"model_resnet34.pth\")\n# jovian.commit(project=project_name, environment=None, \n#               outputs=['model_resnet18.pth', 'model_resnet34.pth'])","864f4f77":"![image.png](attachment:image.png)","b2b73d2c":"### Ensemble on Test data","8c768fed":"Since we don\u2019t want to have to train the models again every time we start up a jupyter notebook, lets see how we can save them to disk and then reload them.","b780580c":"### Make some predictions","3a66c1a3":"### ResNet34 network","56a8dbe5":"### Test with an ensemble","5e7211ea":"**Evaluation Metric**\n\nThe evaluation metric for this competition is Accuracy.\n\nThe link to the above datasets and problem statement are:\n\nhttps:\/\/datahack.analyticsvidhya.com\/contest\/janatahack-computer-vision-hackathon\/#ProblemStatement","3c204a4c":"**Data Description**\n* train.zip: contains 2 csvs and 1 folder containing image data\n* train.csv \u2013 [\u2018image_names\u2019, \u2018emergency_or_not\u2019] contains the image name and correct class for 1646 (70%) train images\n* images \u2013 contains 2352 images for both train and test sets\n* test.csv: [\u2018image_names\u2019] contains just the image names for the 706 (30%) test images\n* sample_submission.csv: [\u2018image_names\u2019,\u2019emergency_or_not\u00ad\u2019] contains the exact format for a valid * submission (1 - For Emergency Vehicle, 0 - For Non Emergency Vehicle)","1e6dffeb":"Fatalities due to traffic delays of emergency vehicles such as ambulance & fire brigade is a huge problem. In daily life, we often see that emergency vehicles face difficulty in passing through traffic. So differentiating a vehicle into an emergency and non emergency category can be an important component in traffic monitoring as well as self drive car systems as reaching on time to their destination is critical for these services.\n\nIn this problem, you will be working on classifying vehicle images as either belonging to the emergency vehicle or non-emergency vehicle category. For the same, you are provided with the train and the test dataset. Emergency vehicles usually includes police cars, ambulance and fire brigades.","0f6a69fa":"The magic of ensembles is that given two models with accuracy of 0.920973 and 0.924012 we are able to make predictions and get to 0.927052, which is higher than any individual model.(Validation data)","064d3a30":"Now check against our holdout test set","77df1250":"### Train and test the models","0eb23cf9":"### Preparing data","5acd3b4e":"### Save and upload","e2efee87":"### Save and load models","84812ab6":"We\u2019ll use a very simple ensemble here. Take the prediction for each image from each model, average them to generate a new prediction for the image.","fa41d97a":"### Emergency vs Non-Emergency Vehicle Classification","08acd745":"# Assignment 5 - Course Project"}}