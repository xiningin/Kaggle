{"cell_type":{"72a6e3f9":"code","1be9ef4f":"code","89e22873":"code","04dfcfbd":"code","53ba889e":"code","c60ec124":"code","c00225ce":"code","87c23c90":"code","0afc4693":"code","077af24e":"code","b407025b":"code","25bdbbd9":"code","5d414b7e":"code","f0480178":"code","e6151b42":"code","269f64aa":"code","b44f2617":"code","880c4967":"code","e4674815":"markdown","7517c8b4":"markdown","867353b3":"markdown","f97448bb":"markdown","c8d12ede":"markdown","39cc13dc":"markdown","13d7db48":"markdown","54ffccc7":"markdown"},"source":{"72a6e3f9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1be9ef4f":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\nfrom lightgbm import LGBMClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')","89e22873":"train = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')\nsample_sub = pd.read_csv('..\/input\/nlp-getting-started\/sample_submission.csv')","04dfcfbd":"train.isna().sum()","53ba889e":"train.duplicated(subset='text').sum()","c60ec124":"train.drop_duplicates(subset='text', ignore_index=True, inplace=True)","c00225ce":"data = train['target'].value_counts()\ndata.plot.pie(autopct='%.1f%%')","87c23c90":"def clean_text(dataset, shape):\n    updated_text = []\n    for i in range(0, shape):\n        tweet_text = re.sub('[^a-zA-Z]', ' ', dataset['text'][i]).lower().split()\n        ps = PorterStemmer()\n        all_stop_words = stopwords.words('english')\n        all_stop_words.remove('not')\n        tweet_text = [ps.stem(word) for word in tweet_text if word not in set(all_stop_words)]\n        tweet_text = ' '.join(tweet_text)\n        updated_text.append(tweet_text)\n    return updated_text","0afc4693":"count_vect = CountVectorizer()","077af24e":"X = count_vect.fit_transform(clean_text(train, train.shape[0])).toarray()\ny = train['target']","b407025b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)","25bdbbd9":"lgbm = LGBMClassifier(random_state=123, num_iterations=90)\nlgbm.fit(X_train, y_train)","5d414b7e":"y_pred = lgbm.predict(X_test)","f0480178":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)\nprint(accuracy_score(y_test, y_pred), f1_score(y_test, y_pred))","e6151b42":"test_data = clean_text(test, test.shape[0])\ntest_x = count_vect.transform(test_data).toarray()\ny_test_pred = lgbm.predict(test_x)","269f64aa":"sample_sub['target'] = y_test_pred","b44f2617":"sample_sub.head()","880c4967":"sample_sub.to_csv('nlp_1.csv', index=False)","e4674815":"Test data clean, predict and submit","7517c8b4":"**NLP - A simple guide.**","867353b3":"Null check, ignored filling nan as text variable doesn't have any","f97448bb":"Loading the data","c8d12ede":"Not much difference seen in target imbalance","39cc13dc":"Count Vectorizer used as Bag of words","13d7db48":"A small utility for cleaning the text using stemmer and stop words","54ffccc7":"Duplicate check, deleted text variable duplicates"}}