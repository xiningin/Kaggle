{"cell_type":{"ec8747cc":"code","efc8bac5":"code","1915482a":"code","d5a7c386":"code","b7022511":"code","ff98b829":"code","23d9ff00":"code","5f1b6d6a":"code","525e18fb":"code","ca8f4e3b":"code","154ab88b":"code","36079380":"code","121bad02":"code","ec1e5ade":"code","759df033":"code","ccb98782":"code","9553cefb":"code","b366e6c1":"code","1d474519":"code","d3e00181":"code","08ca85e8":"code","23051fcd":"code","99d9c1be":"code","0528591d":"code","46905efb":"code","824e24e0":"code","f02ba9a1":"code","0a8176e4":"code","68550d97":"code","1364636d":"code","65d04641":"code","a8c758c0":"code","75f9def1":"code","c07ccf53":"code","6d27ad1b":"code","b126590e":"code","403ae69a":"code","87619f10":"code","b90e2f92":"code","b453e8ad":"markdown","efd452e7":"markdown","5276991a":"markdown","1f605c41":"markdown","9ee833a9":"markdown","1c6aa50e":"markdown","d866e4d7":"markdown","05ae3b0f":"markdown","aee9fa7a":"markdown","553da2f6":"markdown","46accc35":"markdown","427acd0a":"markdown","dd7b7697":"markdown","98c45996":"markdown","40f5e4c1":"markdown","9bf2da78":"markdown","a69dc325":"markdown","db8eeca7":"markdown","ad88079c":"markdown","fd33c7d4":"markdown","c635f076":"markdown","71feef1a":"markdown"},"source":{"ec8747cc":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport zipfile\nimport numpy as np\ntf.__version__","efc8bac5":"image_n = tf.keras.preprocessing.image.load_img(r'..\/input\/covid-data-gradient-crescent\/all\/train\/normal\/NORMAL2-IM-1293-0001.jpeg', target_size=(550,550))\nimage_n","1915482a":"image_c = tf.keras.preprocessing.image.load_img(r'..\/input\/covid-data-gradient-crescent\/all\/train\/covid\/1312A392-67A3-4EBF-9319-810CF6DA5EF6.jpeg', target_size=(550,550))\nimage_c","d5a7c386":"train_imagenerator = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input, rotation_range = 50, width_shift_range = 0.2,\n                                     height_shift_range = 0.2,\n                                     zoom_range = 0.1,\n                                     horizontal_flip = True,\n                                     vertical_flip = True)","b7022511":"train_generator = train_imagenerator.flow_from_directory('..\/input\/covid-data-gradient-crescent\/all\/train', target_size = (550, 550), batch_size=16,\n                                                         class_mode = 'categorical', shuffle = True)","ff98b829":"step_size_train = train_generator.n \/\/ train_generator.batch_size\nstep_size_train","23d9ff00":"test_imagenerator = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input)\ntest_generator = test_imagenerator.flow_from_directory('..\/input\/covid-data-gradient-crescent\/all\/test',target_size=(550,550),batch_size=1,\n                                                       class_mode = 'categorical',shuffle = False)","5f1b6d6a":"step_size_test = test_generator.n \/\/ test_generator.batch_size\nstep_size_test","525e18fb":"#loading the model:\nbase_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)","ca8f4e3b":"base_model.summary()","154ab88b":"x = base_model.output","36079380":"x = tf.keras.layers.GlobalAveragePooling2D()(x) # to do the Pooling is necessary the last layer\n\n#the dense layers:\nx = tf.keras.layers.Dense(1024, activation='relu')(x)\nx = tf.keras.layers.Dense(1024, activation='relu')(x)\nx = tf.keras.layers.Dense(512, activation='relu')(x)\npreds = tf.keras.layers.Dense(4, activation='softmax')(x)","121bad02":"model = tf.keras.Model(inputs = base_model.input, outputs = preds)\nmodel.summary()","ec1e5ade":"for i, layer in enumerate(model.layers):\n    print(i, layer.name)","759df033":"for layer in model.layers[:175]:\n    layer.trainable = False","ccb98782":"for layer in model.layers[175:]:\n    layer.trainable = True","9553cefb":"model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit_generator(generator=train_generator,\n                              epochs=25,\n                              steps_per_epoch=step_size_train,\n                              validation_data = test_generator,\n                              validation_steps=step_size_test)","b366e6c1":"np.mean(history.history['val_accuracy'])","1d474519":"np.std(history.history['val_accuracy'])","d3e00181":"plt.plot(history.history['loss'], label='Training loss')\nplt.plot(history.history['val_loss'], label='Validation loss')\nplt.title('Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend();","08ca85e8":"plt.plot(history.history['accuracy'], label='Training accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation accuracy')\nplt.title('Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend();","23051fcd":"filenames = test_generator.filenames\nfilenames","99d9c1be":"predictions = model.predict_generator(test_generator, steps = len(filenames))\npredictions","0528591d":"predictions2 = []\n\nfor i in range(len(predictions)):\n    predictions2.append(np.argmax(predictions[i]))","46905efb":"predictions2","824e24e0":"test_generator.class_indices","f02ba9a1":"from sklearn.metrics import accuracy_score, confusion_matrix\naccuracy_score(predictions2, test_generator.classes)","0a8176e4":"cm = confusion_matrix(predictions2, test_generator.classes)\ncm","68550d97":"sns.heatmap(cm, annot=True);","1364636d":"image = tf.keras.preprocessing.image.load_img(r'..\/input\/covid-data-gradient-crescent\/all\/test\/covid\/ryct.2020200034.fig5-day0.jpeg', target_size=(550,550))\nplt.imshow(image);","65d04641":"image = tf.keras.preprocessing.image.img_to_array(image)\nnp.shape(image)","a8c758c0":"image = np.expand_dims(image, axis = 0)\nnp.shape(image)","75f9def1":"image = tf.keras.applications.resnet50.preprocess_input(image)\npredictions = model.predict(image)\nprint(predictions)","c07ccf53":"prediction = list(train_generator.class_indices)[np.argmax(predictions[0])]\nprediction","6d27ad1b":"image2 = tf.keras.preprocessing.image.load_img(r'..\/input\/covid-data-gradient-crescent\/all\/test\/normal\/NORMAL2-IM-1406-0001.jpeg', target_size=(550,550))\nplt.imshow(image2);","b126590e":"image2 = tf.keras.preprocessing.image.img_to_array(image2)\nnp.shape(image2)","403ae69a":"image2 = np.expand_dims(image2, axis = 0)\nnp.shape(image2)","87619f10":"image2 = tf.keras.applications.resnet50.preprocess_input(image2)\npredictions2 = model.predict(image2)\nprint(predictions2)","b90e2f92":"prediction2 = list(train_generator.class_indices)[np.argmax(predictions2[0])]\nprediction2","b453e8ad":"Let's create a ``for`` to name the layers","efd452e7":"And now we are going to compare it with the real answers that are in the database","5276991a":"Here it will get the name of the files that are in the test database","1f605c41":"# The predictions","9ee833a9":"Going to the end of these layers we see ``174 conv5_block3_out`` which indicates that from the top we are going to use the imaginet weights and ``175 global_average_pooling2d`` down we will do the image recognition training. And so we will create two `` for`` to freeze those that we will not use for training and so you can update this bottom part","1c6aa50e":"# All files that were used here were extracted from [Detecting COVID-19 induced Pneumonia from Chest X-rays with Transfer Learning: An implementation in Tensorflow and Keras](https:\/\/towardsdatascience.com\/detecting-covid-19-induced-pneumonia-from-chest-x-rays-with-transfer-learning-an-implementation-311484e6afc1)","d866e4d7":"# Forecasting using image","05ae3b0f":"Let's get the highest values:","aee9fa7a":"The command ``base_model.summary()`` will show the layers of the Neural Network","553da2f6":"**Let's try with another one:**","46accc35":"# Evaluating the model:","427acd0a":"# Transfer Learning:","dd7b7697":"Here it returns the probability of being from each of the classes","98c45996":"Let's calculate the average of hits for each ``epoch``","40f5e4c1":"Let's calculate the standard deviation","9bf2da78":"If ``step_size_test`` and ``step_size_train`` are not defined, the `` epoch`` will go through all the records and may take longer.","a69dc325":"As we will use ``Tensorflow``, we will have to format the images","db8eeca7":"When creating the variable ``x`` it is simply to receive the last layer of the Neural Network and then create the custom data architecture","ad88079c":"All of this is the connection of the layers, now in fact we are going to build our complete Neural Network.","fd33c7d4":"We will generate some graphs to better visualize the data:","c635f076":"**Let's upload one of these images:**","71feef1a":"It will return values between 0 and 3 indicating a forecast made by the Neural Network. Which class the image belongs to"}}