{"cell_type":{"d1bbe8ff":"code","65a22f66":"code","40b82835":"code","c4035d62":"code","483d7c0f":"code","a0bda074":"code","6af066c6":"code","3e1b66bc":"code","fab1c33c":"code","95d6c11a":"code","5e12f59e":"code","df7cebcb":"code","02562c51":"code","640799e3":"code","22c3ac6f":"code","3974256c":"code","a4a75fd1":"code","0df40442":"code","f5a895e9":"code","6df08b87":"code","544a9858":"code","720a13b0":"code","b695c444":"code","81f65311":"code","c9810917":"code","ad5415e9":"code","fe069f84":"code","282e63ba":"code","bc78dbea":"code","7d4dcc79":"code","ca4fbdd8":"code","346707b3":"code","cd7d97e9":"code","2dfce577":"code","0edd71aa":"code","b9f17788":"code","00c2343f":"code","407bb04a":"code","fbe69c49":"code","075566ba":"code","cbe4d0ba":"code","4eaa669c":"code","a417f63b":"code","81edc8d2":"markdown","a2fd65d5":"markdown","a555721d":"markdown","01715e41":"markdown","c91a85d9":"markdown","e821c776":"markdown","f382fa52":"markdown","c3bb27fe":"markdown"},"source":{"d1bbe8ff":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","65a22f66":"pd.set_option('display.max_columns', 100)\nencoding_latin=\"latin\"\ndf = pd.read_csv('\/kaggle\/input\/world-happiness\/2019.csv', low_memory = False, encoding = encoding_latin)\ndf.head()","40b82835":"df.info()","c4035d62":"df.describe()","483d7c0f":"df.shape","a0bda074":"df_happy = round(100*(df.isnull().sum()\/len(df)), 2)\ndf_happy","6af066c6":"top5_counrties_2019 = df.sort_values(by='Healthy life expectancy', ascending=False).head(5)\ntop5_counrties_2019","3e1b66bc":"top5_counrties_Social_2019 = df.sort_values(by='Social support', ascending=False).head(5)\ntop5_counrties_Social_2019","fab1c33c":"df = df.drop(['Overall rank', 'Country or region'], axis = 1)\ndf.head()","95d6c11a":"sns.pairplot(df)","5e12f59e":"corr=df.corr()\ncorr.style.background_gradient(cmap='coolwarm')","df7cebcb":"df_2019 = df.copy()\ndf_2019.head()","02562c51":"from sklearn.model_selection import train_test_split\ndf_2019_train, df_2019_test = train_test_split(df_2019, train_size = 0.7, test_size = 0.3, random_state = 100)","640799e3":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","22c3ac6f":"num_vars = ['Score', 'GDP per capita', 'Social support']\ndf_2019_train[num_vars] = scaler.fit_transform(df_2019_train[num_vars])\ndf_2019_train.head()","3974256c":"y_train = df_2019_train.pop('Score')\nX_train = df_2019_train","a4a75fd1":"from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","0df40442":"lm = LinearRegression()\nlm.fit(X_train, y_train)\n\nrfe = RFE(lm, 10)             # running RFE\nrfe = rfe.fit(X_train, y_train)","f5a895e9":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","6df08b87":"col = X_train.columns[rfe.support_]\ncol","544a9858":"X_train.columns[~rfe.support_]","720a13b0":"# Creating X_test dataframe with RFE selected variables\nX_train_rfe = X_train[col]","b695c444":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_rfe = sm.add_constant(X_train_rfe)","81f65311":"lm = sm.OLS(y_train,X_train_rfe).fit() ","c9810917":"print(lm.summary())","ad5415e9":"X_train_new = X_train_rfe.drop([\"Generosity\"], axis = 1)","fe069f84":"import statsmodels.api as sm  \nX_train_lm = sm.add_constant(X_train_new)","282e63ba":"lm = sm.OLS(y_train,X_train_lm).fit()","bc78dbea":"print(lm.summary())","7d4dcc79":"X_train_new.columns","ca4fbdd8":"X_train_new = X_train_new.drop(['const'], axis=1)","346707b3":"# Calculate the VIFs for the new model\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","cd7d97e9":"y_train_score = lm.predict(X_train_lm)","2dfce577":"# Importing the required libraries for plots.\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","0edd71aa":"# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_score), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)            \nplt.xlabel('Errors', fontsize = 18)  ","b9f17788":"num_vars = ['Score', 'GDP per capita', 'Social support']\n\ndf_2019_test[num_vars] = scaler.transform(df_2019_test[num_vars])\ndf_2019_test[num_vars].head()","00c2343f":"y_test = df_2019_test.pop('Score')\nX_test = df_2019_test","407bb04a":"# Now let's use our model to make predictions.\n\n# Creating X_test_new dataframe by dropping variables from X_test\nX_test_new = X_test[X_train_new.columns]\n\n# Adding a constant variable \nX_test_new = sm.add_constant(X_test_new)","fbe69c49":"# Making predictions\ny_pred = lm.predict(X_test_new)\ny_pred.head()","075566ba":"# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure()\nplt.scatter(y_test,y_pred)\nfig.suptitle('y_test vs y_pred', fontsize=20)          \nplt.xlabel('y_test', fontsize=18)                      \nplt.ylabel('y_pred', fontsize=16) ","cbe4d0ba":"df.columns","4eaa669c":"from sklearn import linear_model\nX = df[['GDP per capita', 'Social support', 'Healthy life expectancy','Freedom to make life choices', 'Generosity','Perceptions of corruption']]\ny = df['Score']\n\nlm = linear_model.LinearRegression()\nmodel = lm.fit(X,y)\nlm.coef_","a417f63b":"lm.intercept_","81edc8d2":"Making Predictions","a2fd65d5":"Rescaling the Features","a555721d":"Dividing into X_test and y_test","01715e41":"Applying the scaling on the test sets","c91a85d9":"Model Evaluation","e821c776":"Generosity is insignificant in presence of other variables","f382fa52":"Residual Analysis of the train data","c3bb27fe":"Splitting the Data into Training and Testing Sets"}}