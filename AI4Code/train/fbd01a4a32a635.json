{"cell_type":{"0cca6256":"code","4ab97587":"code","46430e9a":"code","cf3d431c":"code","0e585894":"code","5229ff42":"code","f1803997":"code","9e64fe8f":"code","8ca380e1":"code","77670294":"code","c50d11b8":"markdown","f48fcf4c":"markdown","44c3fcf6":"markdown","95cb3f7c":"markdown","13cf5592":"markdown"},"source":{"0cca6256":"import pandas as pd\n\ndf = pd.read_csv(\n    \"\/kaggle\/input\/count-the-paperclips\/train.csv\", \n    na_values=['NA', '?'])\n\ndf['filename']=\"clips-\"+df[\"id\"].astype(str)+\".png\"","4ab97587":"TRAIN_PCT = 0.9\nTRAIN_CUT = int(len(df) * TRAIN_PCT)\n\ndf_train = df[0:TRAIN_CUT]\ndf_validate = df[TRAIN_CUT:]\n\nprint(f\"Training size: {len(df_train)}\")\nprint(f\"Validate size: {len(df_validate)}\")","46430e9a":"df_train","cf3d431c":"import tensorflow as tf\nimport keras_preprocessing\nfrom keras_preprocessing import image\nfrom keras_preprocessing.image import ImageDataGenerator\n\nIMAGES_DIR = \"\/kaggle\/input\/count-the-paperclips\/clips-data-2020\/clips\"\n\ntraining_datagen = ImageDataGenerator(\n  rescale = 1.\/255,\n  horizontal_flip=True,\n  vertical_flip=True,\n  fill_mode='nearest')\n\ntrain_generator = training_datagen.flow_from_dataframe(\n        dataframe=df_train,\n        directory=IMAGES_DIR,\n        x_col=\"filename\",\n        y_col=\"clip_count\",\n        target_size=(256, 256),\n        batch_size=32,\n        class_mode='other')\n\nvalidation_datagen = ImageDataGenerator(rescale = 1.\/255)\n\nval_generator = validation_datagen.flow_from_dataframe(\n        dataframe=df_validate,\n        directory=IMAGES_DIR,\n        x_col=\"filename\",\n        y_col=\"clip_count\",\n        target_size=(256, 256),\n        class_mode='other')","0e585894":"from tensorflow.keras.callbacks import EarlyStopping\n\nmodel = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    # This is the first convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(256, 256, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    # The second convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(1, activation='linear')\n])\n\n\nmodel.summary()\nepoch_steps = 250 # needed for 2.2\nvalidation_steps = len(df_validate)\nmodel.compile(loss = 'mean_squared_error', optimizer='adam')\nmonitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto',\n        restore_best_weights=True)\nhistory = model.fit(train_generator,  \n  verbose = 1, \n  validation_data=val_generator, callbacks=[monitor], epochs=25)\n#  steps_per_epoch=epoch_steps, validation_steps=validation_steps, # needed for 2.2","5229ff42":"df_test = pd.read_csv(\n    \"\/kaggle\/input\/count-the-paperclips\/test.csv\", \n    na_values=['NA', '?'])\n\ndf_test['filename']=\"clips-\"+df_test[\"id\"].astype(str)+\".png\"\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntest_generator = validation_datagen.flow_from_dataframe(\n        dataframe=df_test,\n        directory=IMAGES_DIR,\n        x_col=\"filename\",\n        batch_size=1,\n        shuffle=False,\n        target_size=(256, 256),\n        class_mode=None)","f1803997":"test_generator.reset()\npred = model.predict(test_generator,steps=len(df_test))","9e64fe8f":"df_submit = pd.DataFrame({'id':df_test['id'],'clip_count':pred.flatten()})","8ca380e1":"df_submit.to_csv(\"\/kaggle\/working\/submit.csv\",index=False)","77670294":"!ls \/kaggle\/input\/count-the-paperclips\/clips-data-2020","c50d11b8":"Next we construct the neural network.","f48fcf4c":"Create DataGenerators for training and validation. This is what links the .csv with the images. This part might take a few minutes to run.","44c3fcf6":"Separate into a training and validation (for early stopping)","95cb3f7c":"This is my starter code for the Kaggle competition. Will discuss this in greater detail during the Zoom meeting on Monday. This could may evolve a bit. This is a basic implementation that should get around 2.3 RMSE on the leaderboard. Next, we build a dataframe that contains the filenames and the clip_count. You will need to modify the paths below to match where you put train.csv and master.csv.","13cf5592":"# Generate Submission File"}}