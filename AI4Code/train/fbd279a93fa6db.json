{"cell_type":{"e0c44e8c":"code","1283613e":"code","ae3125e9":"code","e59dc1ae":"code","96d8ec66":"code","6a102522":"code","de368d23":"code","717cbec0":"code","a5298514":"code","1accfbc9":"code","306581bf":"code","0a3750de":"code","52ecc1b7":"code","cdfad551":"code","1a022898":"code","8ebbd271":"code","fe270660":"code","8f5126c9":"markdown","0cdc232d":"markdown","7da9a0d9":"markdown","599d8619":"markdown","1c3230e6":"markdown","eed7c993":"markdown","2fcbcd0e":"markdown","71d43212":"markdown","794e1923":"markdown","4b6ca3b7":"markdown","2588c3e7":"markdown","2885abe8":"markdown","2fc50dae":"markdown","e5c9298f":"markdown","69c06258":"markdown","836f8ea0":"markdown","3e6e673c":"markdown","48f61344":"markdown","38b75e3c":"markdown","84d40989":"markdown","c2650249":"markdown","b9b9c59a":"markdown","c25ced25":"markdown","d5aea81c":"markdown","fc30859e":"markdown","d68b256c":"markdown"},"source":{"e0c44e8c":"import numpy as np # linear algebra\nimport matplotlib as mpl\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import preprocessing\nimport math\nimport random\nfrom sklearn.preprocessing import StandardScaler\nfrom time import time\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn import svm\nfrom sklearn.metrics import *\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import f1_score\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import learning_curve\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# for inline plots\n%matplotlib inline\n\n# initialise figure sizes\nmpl.rcParams['figure.figsize'] = (10,5)\nmpl.rc('xtick', labelsize = 15) \nmpl.rc('ytick', labelsize = 15)\n\n#initialise figure sizes\nfont = {'size'   : 15}\nmpl.rc('font', **font)\nprint('running')","1283613e":"# get data from csv files\ntest  = pd.read_csv('..\/input\/test.csv')\ntrain = pd.read_csv('..\/input\/train.csv')\n","ae3125e9":"# divide into X and y data\nX_all = pd.DataFrame(train.iloc[:,1:train.shape[1]])\ny_all = pd.DataFrame(train.iloc[:,0])\n\nX_test = test\n\n#slpit into, these will be chnges later as is approriate \nX_train, X_val, y_train, y_val = train_test_split(X_all, y_all, test_size = 0.25)\n\n#determine sizes of datasets\nn_all,m_all = X_train.shape\nn_train,m_train = X_train.shape\nn_val, m_val = X_val.shape\nn_test,m_test = X_test.shape\n\n# print a summary of loaded results\nprint('FULL DATA')\nprint('Number of features (m): %.0f'%(m_all))\nprint('Number of traiing samples (n): %.0f'%(n_all))\n\nprint('TRAINING DATA')\nprint('Number of features (m): %.0f'%(m_train))\nprint('Number of traiing samples (n): %.0f'%(n_train))\n\nprint('\\nVALIDATION DATA')\nprint('Number of features (m): %.0f'%(m_val))\nprint('Number of traiing samples (n): %.0f'%(n_val))\n\nprint('\\nTEST DATA')\nprint('Number of features (m): %.0f'%(m_test))\nprint('Number of traiing samples (n): %.0f'%(n_test))","e59dc1ae":"\n# Plot images in an O x P = N_samples subplot\ndef PlotSamples(N_samples, X, y, Label):\n    n, m = X.shape\n        \n    rows = int(round(np.sqrt(N_samples)))\n    columns = math.ceil(N_samples\/rows)\n    \n    sample_i = random.sample(range(0, n), N_samples)\n    mpl.rcParams['figure.figsize'] = [9,9]\n        \n    f, ax = plt.subplots(rows, columns)\n    plt.tight_layout(pad = 0.2, w_pad = .1, h_pad=.1)\n   \n    for i in range(0, rows * columns):\n    \n        if i < N_samples:\n                \n                data = X.iloc[sample_i[i],:].values #this is the first number\n                pix_rows, pix_cols = int(math.sqrt(m)), int(math.sqrt(m))\n                grid = data.reshape((pix_rows, pix_cols))\n                ax[i \/\/ columns, i % columns].imshow(grid)\n                ax[i \/\/ columns, i % columns].axis('off') \n                ax[i \/\/ columns, i % columns].set_title(str(Label) + str(y['label'][sample_i[i]]))\n                \n        else:\n                ax[i \/\/ columns, i % columns].axis('off')\n\n# Plot images in an O x P = N_samples subplot of error made in prediction\ndef PlotError(N, X, False_pred_t, False_pred_f):\n\n    n, m = X.shape   \n    rows = int(round(np.sqrt(N)))\n    columns = math.ceil(N\/rows)\n    \n    sample_i = random.sample(list(False_pred_f.index), N)\n    \n    mpl.rcParams['figure.figsize'] = [9,9]    \n    f, ax = plt.subplots(rows, columns)\n    plt.tight_layout(pad = 0.2, w_pad = .1, h_pad = .1)\n       \n    for i in range(0, rows * columns):\n    \n        if i < N:\n    \n            False_label = 'False Prediction: ' + str(False_pred_f['label'][sample_i[i]]) + '  '\n            True_label = 'True Label: '  + str(False_pred_t['label'][sample_i[i]]) + '  '\n            label1 = False_label + '\\n' + True_label\n            \n            data = X.loc[sample_i[i],:].values #this is the first number\n            \n            pix_rows, pix_cols = int(math.sqrt(m)), int(math.sqrt(m))\n            grid = data.reshape((pix_rows, pix_cols))\n            ax[i \/\/ columns, i % columns].imshow(grid)\n            ax[i \/\/ columns, i % columns].axis('off') \n            ax[i \/\/ columns, i % columns].set_title(label1, fontsize = 12)\n            \n        else:\n            ax[i \/\/ columns, i % columns].axis('off')\n            \n    return\n\n#plot the training and validation confusion matrix in subplots\ndef Confusion(confusion_train, confusion_val):\n    font = {'size'   : 15}\n    mpl.rc('font', **font)\n    \n    class_names = [0,1,2,3,4,5,6,7,8,9]\n    \n    c_train = pd.DataFrame(confusion_train, index = class_names, columns = class_names )\n    c_val = pd.DataFrame(confusion_val, index = class_names, columns = class_names )\n          \n    fig = plt.figure(figsize = (14,7))\n    plt.subplot(121)\n    heatmap = sns.heatmap(c_train, annot = True, cmap=\"YlGnBu\", fmt = \"d\", annot_kws={\"size\": 12})\n    \n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.title('Training Results', fontsize = 15)\n    plt.subplot(122)\n    \n    heatmap = sns.heatmap(c_val, annot = True, cmap=\"YlGnBu\", fmt = \"d\",annot_kws={\"size\": 12})\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.title('Validation Results', fontsize = 15)\n    \n    return fig\n\n# Reduce the size of data by R (0 - 1)\ndef ReduceData(R, X, y):\n    n,m = X.shape\n    \n    X = pd.DataFrame(X)\n    y = pd.DataFrame(y)\n    \n    n_reduce = math.ceil(R * n)\n    \n    X_red = X.iloc[0:n_reduce,:]\n    y_red = y.iloc[0:n_reduce]\n    \n    return(X_red, y_red)\n\n# Normalisation:\ndef Norm(X):\n    X_std = StandardScaler().fit_transform(X)\n    return(X_std)","96d8ec66":"# plot a sample of figures with teh label printed over the number\nprint('Randomly selected samples with their assigned labels:')\nPlotSamples(36, X_all, y_all, 'Label: ')\n","6a102522":"\n# plot a barchart of the label counts\nplt.figure(figsize = [9,5])\nsns.countplot(x = 'label', data = train);\nplt.ylabel('Counts')\nplt.xlabel(\"Number\")\nplt.title('Reoccurance of the Specific Numbers')\nplt.grid(True)","de368d23":"\nmpl.rcParams['figure.figsize'] = (8,5)\npca_model = PCA().fit(X_all)\n\nexplain_ratio = pca_model.explained_variance_ratio_ * 100 #calculate variance ratios\nvar  = np.cumsum((pca_model.explained_variance_ratio_) * 100)\n\nmpl.rcParams['figure.figsize'] = (15,6)\nplt.figure()\nplt.subplot(121)\nplt.bar(range(len(explain_ratio)), explain_ratio)\nplt.xlabel('Individual Component')\nplt.ylabel('Individual Explain Variance (%))')\nplt.title('Individual contribution of Components')\nplt.xlim(0, 50)\nplt.grid(True)\n\nplt.subplot(122)\nplt.plot(var, linewidth = 2)\nplt.xlabel('Number of Components')\nplt.ylabel('Cumulative Explained Variance (%)');\nplt.title('Cumulative Contribution of Components')\nplt.grid(True)\nplt.xlim(0, 400)\nplt.ylim(0,100)\nplt.grid(True)","717cbec0":"# determines the PCA adn SVM models \ndef PCA_SVM_Model(X_std, y, N):\n    \n    #perform PCA feature reduction\n    pca_model = PCA(n_components = N, svd_solver = 'randomized', whiten = True) \n    pca_model.fit(X_std)\n    variance_N = np.sum(explain_ratio[0:N]) # determine the cotribution ofthe first N components\n    \n    X_pca = pd.DataFrame(pca_model.transform(X_std))\n    \n    svm_model = svm.SVC()\n    svm_model.fit(X_pca, y)\n    \n    return(pca_model, svm_model, variance_N)\n     \ndef Apply_PCA_SVM(pca_model, svm_model, X_std):\n    X_pca = pd.DataFrame(pca_model.transform(X_std))\n    # predict y-values training\n    y_pred = pd.DataFrame(svm_model.predict(X_pca))\n    y_pred.columns = ['label']\n    \n    return(y_pred)\n\ndef Error(y, y_pred):\n    f1_sc = f1_score(y, y_pred, average='macro')\n    f1_err = 1 - f1_sc\n    return(f1_sc, f1_err)","a5298514":"#Initialise settings\nN_comp_max = 70\nN_range = range(5, N_comp_max,5)\nReduction = 1\nsplit = 0.25\n\n#Initialise arrays\nf1_train_error = np.zeros(len(N_range))\nf1_val_error = np.zeros(len(N_range))\nvariance_N = np.zeros(len(N_range))\ncnt = 0\n\n# Reduce data and split int training and validation data\nX_red, y_red = ReduceData(Reduction, X_all, y_all) # reduction is only for saving time\nX_train, X_val, y_train, y_val = train_test_split(X_red, y_red, test_size = split)\n\n# determine size of new data sets\nn_all, m_all = X_all.shape\nn_red, m_red = X_red.shape\nn_train,m_train = X_train.shape\nn_val, m_val = X_val.shape\n\n#Normalisation of data\nX_train_std = Norm(X_train)\nX_val_std = Norm(X_val)\n    \nfor i in tqdm(N_range): #run for all selected components number\n    #print('Determining PCA and SVM models based on training set...')\n    pca_model, svm_model, variance_N = PCA_SVM_Model(X_train_std, y_train, i)\n\n    #print('Applying PCA and SVM model based on training set...')\n    y_train_pred = Apply_PCA_SVM(pca_model, svm_model, X_train_std)\n    y_val_pred = Apply_PCA_SVM(pca_model, svm_model, X_val_std)\n\n    #print('Calculating Errors...')\n    f1_train_score, f1_train_error[cnt] = Error(y_train, y_train_pred)\n    f1_val_score, f1_val_error[cnt] = Error(y_val, y_val_pred)\n    \n    cnt = cnt + 1\n\nprint('SUMMARY')\nprint('Size of Original data: %.0f x %.0f'%(n_all, m_all))\nprint('Reduction of input data: %.2f'%(Reduction))\nprint('Size of Reduced data: %.0f x %.0f'%(n_red, m_red))\nprint('Training-Validation Split: %.2f'%(split))\nprint('Size of Training data: %.0f x %.0f'%(n_train, m_train))\nprint('Size of Validation data: %.0f x %.0f'%(n_val, m_val))\nprint('Training-Validation Split: %.2f'%(split))\n    \nplt.figure(figsize = (9,5))\nplt.plot(N_range, f1_train_error, linewidth = 2)\nplt.plot(N_range,f1_val_error, linewidth = 2)\nplt.xlabel('PCA Components')\nplt.ylabel('Error')\nplt.grid(True)\nplt.xlim(0,N_comp_max)\nplt.legend(['Train', 'Validation'])\n","1accfbc9":"# initial settings\nReduction = 1 # reduces teh size of the data (to speed things up)\nsplit = 0.25 # the split fot he training and validation data\nN_components = 50 # Number of PCA components\n\n#reduce the data (if you want) and split into training and validatino\nX_std_red, y_red = ReduceData(Reduction, X_all, y_all) # reduce the size of the data\nX_train, X_val, y_train, y_val = train_test_split(X_std_red, y_red, test_size = split) \n\n#Normalisation of data\nX_train_std = Norm(X_train)\nX_val_std = Norm(X_val)\n\nn_train,m_train = X_train.shape\nn_val,m_val = X_val.shape\n\nprint('Determining PCA and SVM models based on training set...')\npca_model, svm_model, variance_N = PCA_SVM_Model(X_train_std, y_train, N_components)\n\nprint('Applying PCA and SVM model based on training set...')\ny_train_pred = Apply_PCA_SVM(pca_model, svm_model, X_train_std)\ny_val_pred = Apply_PCA_SVM(pca_model, svm_model, X_val_std)\n\n#a Apply the same index as the actual values\ny_train_pred.index = y_train.index\ny_val_pred.index = y_val.index\n\nprint('Calculating Errors...')\nf1_train_score, f1_train_error = Error(y_train, y_train_pred)\nf1_val_score, f1_val_error = Error(y_val, y_val_pred)\n\nprint('Done...')","306581bf":"confusion_train = confusion_matrix(y_train, y_train_pred)\nconfusion_val = confusion_matrix(y_val, y_val_pred) \n\nprint('\\nPCA-SVM SUMMARY')\nprint('Number of components: %.2f'%(N_components))\nprint('Explained Variance Ratio: %.2f %%'%(variance_N))\n\nprint('\\nTRAINING RESULTS')\nprint('Number of training samples: %.0f'%(m_train))\nprint('Training f1 score: %.2f'%(f1_train_score))\nprint(classification_report(y_train_pred, y_train))\n\nprint('\\nVALIDATION RESULTS:')\nprint('Validation f1 score: %.2f'%(f1_val_score))\nprint('Number of validation samples: %.0f'%(m_val))\nprint(classification_report(y_val_pred, y_val))\n\n#plot Confusion tables\nConfusion(confusion_train, confusion_val)\n\n# Determine Errors\nFalse_train_pred_f = y_train_pred[y_train['label'].values!= y_train_pred['label'].values]\nFalse_train_pred_t = y_train[y_train['label'].values!= y_train_pred['label'].values]\nTrue_train_pred = y_train[y_train['label'].values == y_train_pred['label'].values]\n\nFalse_val_pred_f = y_val_pred[y_val['label'].values!= y_val_pred['label'].values]\nFalse_val_pred_t = y_val[y_val['label'].values != y_val_pred['label'].values]\nTrue_val_pred = y_val[y_val['label'].values == y_val_pred['label'].values]\n\nplt.figure(figsize = (14,5))\nplt.subplot(121)\nsns.countplot(x = 'label', data = False_train_pred_f)\nplt.grid(True)\nplt.xlabel('Number')\nplt.ylabel('Counts')\nplt. title('Incorrect Predictions in Training')\n\nplt.subplot(122)\nsns.countplot(x = 'label', data = True_train_pred)\nplt.grid(True)\nplt.xlabel('Number')\nplt.ylabel('Counts')\nplt. title('Correct Predictions in Training')\n\nplt.figure(figsize = (14,5))\nplt.subplot(121)\nsns.countplot(x = 'label', data = False_val_pred_f)\nplt.grid(True)\nplt.xlabel('Number')\nplt.ylabel('Counts')\nplt. title('Incorrect Predictions in Validation')\n\nplt.subplot(122)\nsns.countplot(x = 'label', data = True_val_pred)\nplt.grid(True)\nplt.xlabel('Number')\nplt.ylabel('Counts')\nplt. title('Correct Predictions in Validation')","0a3750de":"print('Randomly selected training samples and their incorreclty predicted values using the PCA and SVM')\n\nPlotError(25, X_train, False_train_pred_t, False_train_pred_f)\n","52ecc1b7":"split = 0.25 # the split fot he training and validation data\nN_components = 50 # Number of PCA components\nm_max = n_all\nm_nstep = 10\nm_range = np.linspace(500, m_max, m_nstep)\n\nf1m_train_error = np.zeros(len(m_range))\nf1m_val_error = np.zeros(len(m_range))\n\ncnt = 0\n\nfor i in tqdm(m_range):\n    i = int(i)\n    X_m = X_all.iloc[0:i,:]\n    y_m = y_all.iloc[0:i]\n    \n    #slpit into \n    Xm_train, Xm_val, ym_train, ym_val = train_test_split(X_m, y_m, test_size = split)\n    \n    #Normalisation of data\n    Xm_train_std = Norm(Xm_train)\n    Xm_val_std = Norm(Xm_val)\n    \n    #print('Determining PCA and SVM models based on training set...')\n    pca_model, svm_model, variance_N = PCA_SVM_Model(Xm_train_std, ym_train, N_components)\n\n    #print('Applying PCA and SVM model based on training set...')\n    ym_train_pred = Apply_PCA_SVM(pca_model, svm_model, Xm_train_std)\n    ym_val_pred = Apply_PCA_SVM(pca_model, svm_model, Xm_val_std)\n\n    #print('Calculating Errors...')\n    f1m_train_score, f1m_train_error[cnt] = Error(ym_train, ym_train_pred)\n    f1m_val_score, f1m_val_error[cnt] = Error(ym_val, ym_val_pred)\n    \n    cnt = cnt + 1\n\nplt.figure(figsize = (8,5))\nplt.plot(m_range, f1m_train_error)\nplt.plot(m_range, f1m_val_error)\nplt.xlabel('Number of Training Examples (m)')\nplt.ylabel('Error')\nplt.grid(True)","cdfad551":"N_components = 50 # Number of PCA components\n\n#Normalisation of data\nX_all_std = Norm(X_all)\nn_all, m_train = X_all.shape\n\nprint('Determining PCA and SVM models based on training set...')\npca_model_FINAL, svm_model_FINAL, variance_N = PCA_SVM_Model(X_all_std, y_all, N_components)\n\nprint('Applying PCA and SVM model based on training set...')\ny_all_pred = Apply_PCA_SVM(pca_model_FINAL, svm_model_FINAL, X_all_std)\n\n#a Apply the same index as the actual values\ny_all_pred.index = y_all.index\n\nprint('Calculating Errors...')\nf1_all_score, f1_all_error = Error(y_all, y_all_pred)\n\nprint('Done...')","1a022898":"confusion_all = confusion_matrix(y_all, y_all_pred)\n\nprint('\\nPCA-SVM SUMMARY')\nprint('Number of components: %.2f'%(N_components))\nprint('Explained Variance Ratio: %.2f %%'%(variance_N))\n\nprint('\\nALL RESULTS')\nprint('Number of training samples: %.0f'%(m_all))\nprint('Training f1 score: %.2f'%(f1_all_score))\nprint(classification_report(y_all_pred, y_all))\n\n#plot Confusion tables\nfont = {'size'   : 15}\nmpl.rc('font', **font)\n\nclass_names = [0,1,2,3,4,5,6,7,8,9]\n\nconfuse_all = pd.DataFrame(confusion_all, index = class_names, columns = class_names )\n\nfig = plt.figure(figsize = (9,9))\nheatmap = sns.heatmap(confuse_all, annot = True, cmap=\"YlGnBu\", fmt = \"d\", annot_kws={\"size\": 12})\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.title('All Results', fontsize = 15)\n        \n# Determine Errors\nFalse_all_pred_f = y_all_pred[y_all['label'].values!= y_all_pred['label'].values]\nFalse_all_pred_t = y_all[y_all['label'].values!= y_all_pred['label'].values]\nTrue_all_pred = y_all[y_all['label'].values == y_all_pred['label'].values]\n\nplt.figure(figsize = (14,5))\nplt.subplot(121)\nsns.countplot(x = 'label', data = False_all_pred_f)\nplt.grid(True)\nplt.xlabel('Number')\nplt.ylabel('Counts')\nplt. title('Incorrect Predictions in Training')\n\nplt.subplot(122)\nsns.countplot(x = 'label', data = True_all_pred)\nplt.grid(True)\nplt.xlabel('Number')\nplt.ylabel('Counts')\nplt. title('Correct Predictions in Training')\n\n","8ebbd271":"print('Randomly selected y_test samples and their predicted values using the PCA and SVM')\nfont = {'size': 12}\nmpl.rc('font', **font)\n\nX_test_std = Norm(X_test)\nX_test_pca = pca_model_FINAL.transform(X_test_std)\n\ny_test_pred = pd.DataFrame(svm_model_FINAL.predict(X_test_pca))\ny_test_pred.columns = ['label']\n\nPlotSamples(25, X_test, y_test_pred, 'Predict: ')","fe270660":"\nsubmission = pd.concat([pd.Series(range(1, (n_test + 1)), name = \"ImageId\"), y_test_pred],axis = 1)\n\nsubmission.to_csv(\"Digits_PCA_SVM.csv\",index = False)\n\nprint('Done')","8f5126c9":"Note: the learning curve is performed on both the PCA and SVM sections\n","0cdc232d":"## Errors","7da9a0d9":"### Helper Functions","599d8619":"the effect of the number of components on the accuarcy of the model ewas investigated by applying various PCA for various number of PCA components","1c3230e6":"### Apply PCA  & SVM to Data","eed7c993":"the PCA method seeks to obtain the optimal directions (or eigenvectors) that captures the most variance ( spreads out the data points the most).\n\n","2fcbcd0e":"it is always wise to check the distribution of the labels. As can be seen below, the distribition of pretty much even. this is good for training \n","71d43212":"## Apply to Test Samples","794e1923":"the plot ont eh left shows the contribution of each PCA component. AS can be seen from the plot the contribution decreases exponential with the number of components. \n\n\nThe plot onthe right shows the distribution of the Explained variances across all features (i.e. pixels). As we can see, out of the 784 features, approximately 80% of the Explained Variance can be described by using about 50 features. So if one wanted to implement a PCA on this, extracting the top 150 features would be a very logical choice as they already account for the majority of the data. ","4b6ca3b7":"## Description","2588c3e7":"\n## Learning Curves","2885abe8":"### Apply PCA & SVM to full dataset","2fc50dae":"### Results of Full Data","e5c9298f":"### Label Distribution","69c06258":"# Training Algorithm","836f8ea0":"### Summary and Analysis","3e6e673c":"### Load Data","48f61344":"A vital part of using PCA  is the ability to estimate how many components are needed to describe the data. This can be determined by looking at the cumulative explained variance ratio as a function of the number of components:","38b75e3c":"### Number of PCA Components","84d40989":"### import Libraries and Initialise setting","c2650249":"### PCA from SK-Learn","b9b9c59a":"# DIGITAL RECOGNIZER using PCA & SVM","c25ced25":"## Principal Component Analysis (PCA)","d5aea81c":"# prepare for Submission","fc30859e":"\nPrincipal Component Analysis (PCA)\n\nIn a nutshell, PCA is a linear transformation algorithm that seeks to project the original features of our data onto a smaller set of features ( or subspace ) while still retaining most of the information. To do this the algorithm tries to find the most appropriate directions\/angles ( which are the principal components ) that maximise the variance in the new subspace.\n\nIn this case goal is to reduce the dimensions of a d-dimensional dataset by projecting it onto a (k)-dimensional subspace (where k << d) in order to increase the computational efficiency while retaining most of the information.\n\nfor more information on this topic see: http:\/\/sebastianraschka.com\/Articles\/2015_pca_in_3_steps.html","d68b256c":"The goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. \n\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n\nThe training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n\nEach pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n\nmore details are provided at the following link\n\nhttps:\/\/www.kaggle.com\/c\/digit-recognizer"}}