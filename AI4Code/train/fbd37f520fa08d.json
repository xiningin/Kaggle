{"cell_type":{"7a43159a":"code","794b5a72":"code","23c73d0f":"code","578caf2a":"code","c4b9fafd":"code","007abb54":"code","7dadedf0":"code","8e9a2e25":"code","544eeab1":"code","67d66587":"code","46f0b667":"code","4f55b062":"code","f90c0f91":"code","e96a0fdc":"code","2791aa57":"code","7f60e70a":"code","239a09f0":"code","d4e14eee":"code","693853bd":"code","b2068bb7":"code","9fbec2b2":"code","49694b3b":"code","32863ab3":"code","e77c1167":"code","96360802":"code","5a52fa36":"code","2b96a37d":"code","4e380275":"code","f9300e78":"code","f1ff24d4":"code","af5ffe26":"code","bacab05c":"code","11eae3f1":"code","1d1d1b7b":"code","c7a0b5cb":"code","dc1466db":"code","31831097":"code","23a0bec4":"code","c00b12f6":"code","7dda5e9f":"code","6d24af8b":"code","a097347a":"code","843ace32":"code","700bc083":"code","090fdaca":"code","8f9483f1":"code","1a45ca4e":"code","50b12e16":"code","357fb5a8":"code","e2daa9f3":"markdown","c7f964b1":"markdown","a507ed06":"markdown","b763f5ba":"markdown","c9ac328f":"markdown","a2e258bc":"markdown","a10f9ecb":"markdown","d6871476":"markdown","799b027f":"markdown","8ad58a48":"markdown","7586a655":"markdown","8a1abad2":"markdown","51b52c18":"markdown","25030a16":"markdown","369ba1a5":"markdown","460986d8":"markdown","ad1108e6":"markdown","ce1d6a9f":"markdown","0e802e60":"markdown","68814ab5":"markdown","3ce9b282":"markdown","40671d1a":"markdown","52fbbac1":"markdown","d000915b":"markdown","97c7f01a":"markdown","579de6d1":"markdown","231cab32":"markdown","68a662d4":"markdown","767566ea":"markdown","b15a1a8a":"markdown","4a19d9a6":"markdown","777c7960":"markdown","9778d9e4":"markdown","9977fd46":"markdown","c72f1dc1":"markdown","60162896":"markdown","86c4ae9f":"markdown","f6ff4a60":"markdown","2501ef3b":"markdown","dca18e1b":"markdown","87824d50":"markdown","267caf33":"markdown","ca3de13c":"markdown","543b5f5e":"markdown","168ff4be":"markdown","3592be5e":"markdown","0eeeba68":"markdown","b44f530f":"markdown","ec9b8b87":"markdown","89c711b1":"markdown","8a1f8ca9":"markdown","c446c49d":"markdown","09297ae4":"markdown"},"source":{"7a43159a":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom scipy.stats import linregress\nfrom sklearn import preprocessing\nfrom scipy import stats\nimport warnings\nimport math\nimport datetime\nsns.set()\nsns.set_style('whitegrid')\n# plt.style.use(\"dark_background\")\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 500)\n%matplotlib inline","794b5a72":"path = '..\/input\/store-sales-time-series-forecasting\/'\n","23c73d0f":"train = pd.read_csv(path + 'train.csv', parse_dates=['date'], infer_datetime_format=True)\ntrain.head(5)","578caf2a":"test = pd.read_csv(path + 'test.csv', parse_dates = ['date'], infer_datetime_format=True)\nids = test['id']\npd.concat([test.head(1), test.tail(1)], axis = 0)","c4b9fafd":"# creating a combined dataset with both test and train rows.\nn_train = train.shape[0]\nn_test = test.shape[0]\ndf = pd.concat([train, test], axis = 0)","007abb54":"stores = pd.read_csv(path + 'stores.csv')\nstores.head(5)","7dadedf0":"oil = pd.read_csv(path + 'oil.csv', parse_dates=['date'], infer_datetime_format=True)\noil.tail(5)","8e9a2e25":"holidays = pd.read_csv(path + 'holidays_events.csv', parse_dates=['date'], infer_datetime_format=True)\nholidays.tail(5)","544eeab1":"transactions = pd.read_csv(path + 'transactions.csv', parse_dates=['date'], infer_datetime_format=True)\ntransactions.tail(5)","67d66587":"df[\"year\"],df[\"month\"], df[\"day\"] = pd.DatetimeIndex(df['date']).year, pd.DatetimeIndex(df['date']).month, pd.DatetimeIndex(df['date']).day\n\ndf['month'].replace([var for var in range (1, 13)],['Jan','Feb','Mar','Apr','May','June','July','Aug','Sept','Oct','Nov','Dec'],inplace=True)\ndf['month'] = pd.Categorical(df['month'],\n                             categories=['Jan','Feb','Mar','Apr','May','June','July','Aug','Sept','Oct','Nov','Dec'],\n                             ordered=True)","46f0b667":"df = df.set_index('date')\ndf['dayofyear'] = df.index.dayofyear\ndf['dayofweek'] = df.index.dayofweek\ndf['week'] = df.index.week","4f55b062":"train = df.iloc[ : n_train, ]\ntest = df.iloc[n_train : , ]","f90c0f91":"def get_missingvalues(data):\n\tstats = data.isnull().sum()\n\tif stats.max() == 0:\n\t\tprint(\"No missing values :)\")\n\telse:\n\t\tfor feature in stats.index:\n\t\t\tif stats[feature] > 0:\n\t\t\t\tprint('{} has {} values missing.'.format(feature, stats[feature]))\n\nprint(\"1. Main dataframe: \")\nget_missingvalues(df)\nprint(\"2. Oil dataframe: \")\nget_missingvalues(oil)\nprint(\"3. Holidays dataframe: \")\nget_missingvalues(holidays)\nprint(\"4. Transactional dataframe: \")\nget_missingvalues(transactions)\nprint(\"5. Stores dataframe: \")\nget_missingvalues(stores)","e96a0fdc":"# Let's check distribution of sales - target variable.\nsns.distplot(train['sales'], kde = True)\nprint(\"Skew : {} Kurtosis : {}\".format(train['sales'].skew(), train['sales'].kurt()))\nplt.title(\"Distribution of feature - sales\");","2791aa57":"# Let's check yearly sales. \nplt.figure(figsize = (18, 9))\nsns.boxenplot(data = train, x = 'year', y = 'sales', palette=\"RdPu_r\")\nplt.title(\"Distribution of sales in a year\", fontsize = 20);","7f60e70a":"# let's plot oil prices.\nfig, ax = plt.subplots(figsize = (18, 10))\ndata = oil.set_index('date')\ntrend = data.rolling(window=7, center = True, min_periods = 3).mean()\nax.plot(trend, linewidth = 3, color = 'red')\nsns.scatterplot(data = oil, x = 'date', y = 'dcoilwtico', color = '0.5', ax=ax)\nsns.lineplot(data = oil, x = 'date', y = 'dcoilwtico', color = '0.5', ax=ax, linewidth = 0.5)\nax.set_title(\"Oil Prices\", fontsize = 18);","239a09f0":"# Let's start by plotting sales price. \nfig, ax = plt.subplots(figsize = (16, 10))\ndata = train.loc[ : , 'sales']\ndata = data.groupby('date').sum()\ntrend = data.rolling(window=30, center=True, min_periods=15).mean()\nax.plot(trend, aa = True, color = '#C94B94')\ntrend = data.rolling(window=365, center=True, min_periods=184).mean()\nax.plot(trend, color = '#490E5E', linewidth = 3)\nax.legend(['30 day rolling window', '365 day rolling window'])\nax.set_title(\"Trend - sales\", fontsize = 18);","d4e14eee":"fig, axs = plt.subplots(3, 1, figsize = (16, 15))\n\nfor year, color in zip(train.year.unique(), sns.color_palette(\"RdPu_r\")):\n#     yearly = train[train.year == year]\n    sns.lineplot(data = train[train.year == year].groupby('dayofyear')['sales'].mean(), color=color,ax = axs[0], linewidth = 1.5, label = str(year))\nsns.lineplot(data = train.groupby('dayofyear')['sales'].mean(), color = 'black',ax = axs[0], linewidth = 6, label = 'mean')   \n\n    \naxs[0].set_title(\"Yearly Sales\", fontsize = 18)\n    \nfor month, color in zip(train.month.unique(), sns.color_palette(\"winter\", n_colors = 12)):\n#     monthly = train[train.month == month]\n    sns.lineplot(data = train[train.month == month].groupby('day')['sales'].mean(), color=color,ax = axs[1], linewidth = 1.5, label = month)             \nsns.lineplot(data = train.groupby('day')['sales'].mean(), color = 'black',ax = axs[1], linewidth = 6, label = 'mean')   \n\naxs[1].set_title(\"Monthly Sales\", fontsize = 18)\n\nfor week, color in zip(train.week.unique(), sns.color_palette('summer', n_colors = 53)):\n    sns.lineplot(data = train[train.week == week].groupby('dayofweek')['sales'].mean(), color=color, ax = axs[2], linewidth = 1.5)\nsns.lineplot(data = train.groupby('dayofweek')['sales'].mean(), color = 'black', ax = axs[2], linewidth = 6, label = 'mean')    \n\naxs[2].set_title(\"Weekly Sales\", fontsize = 18)\n\nplt.tight_layout()","693853bd":"# Creating a periodogram.\nfrom scipy.signal import periodogram\nfs = pd.Timedelta(\"1Y\") \/ pd.Timedelta(\"1D\")\nfreqencies, spectrum = periodogram(\n    train['sales'],\n    fs=fs,\n    detrend='linear',\n    window=\"boxcar\",\n    scaling='spectrum',\n)\nfig, ax = plt.subplots(figsize = (16, 5))\nax.step(freqencies, spectrum, color=\"purple\")\nax.set_xscale(\"log\")\nax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\nax.set_xticklabels(\n    [\n        \"Annual (1)\",\n        \"Semiannual (2)\",\n        \"Quarterly (4)\",\n        \"Bimonthly (6)\",\n        \"Monthly (12)\",\n        \"Biweekly (26)\",\n        \"Weekly (52)\",\n        \"Semiweekly (104)\",\n    ],\n    rotation=60,\n)\nax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\nax.set_ylabel(\"Variance\")\nax.set_title(\"Periodogram\", fontsize = 18);","b2068bb7":"data = train.groupby('store_nbr')['sales'].mean().sort_values(ascending = False)\nplt.figure(figsize = (18, 10))\nsns.barplot(data=data, x = data.index.astype(\"str\"), y = data, palette = \"RdPu_r\",   errcolor=\".2\", edgecolor=\".2\")\nplt.title(\"Sales vs Store\", fontsize = 18);","9fbec2b2":"fig, axs = plt.subplots(1, 2, figsize = (18, 10))\n\ndata_family = train.groupby('family')['sales'].sum().sort_values(ascending = False)\nsns.barplot(y=data_family.index, x=data_family.values, palette = \"RdPu_r\",   errcolor=\".2\", edgecolor=\".2\", ax = axs[0])\naxs[0].set_title(\"Sales vs Item Family\", fontsize = 18)\n\nothers = data_family[-20:].sum()\ndata_family = data_family[:13]\ndata_family['OTHERS'] = others\nplt.title(\"Distribution of sales\", fontsize = 18)\ndata_family.plot.pie()\nplt.tight_layout()","49694b3b":"fig, axs = plt.subplots(1, 2, figsize = (18, 7))\nsns.heatmap(train[['sales', 'onpromotion']].corr(), square = True, annot = True, cmap = \"RdPu\", vmax=1, vmin=-1, fmt = \".1f\", ax = axs[0]);\naxs[0].set_title(\"Correlation Plot\")\n\nsns.scatterplot(data = train, x = 'onpromotion', y = 'sales',ax = axs[1], ci = None, color = '#490E5E')\naxs[1].set_title(\"Linear Relation\")\nfig.suptitle('D \u2192 T (sales vs onpromotion)', fontsize = 18);","32863ab3":"# Lets get all unique holidays and their dates.\n# there are 103 holidays. Let's focus on national holidays.\nholidays = holidays.query(\"locale in ['National']\").set_index('date')","e77c1167":"for date in holidays.index:\n    name=holidays.loc[date]['description']\n    if '+' in name or '-' in name:\n        holidays.drop(index = date, inplace = True)","96360802":"dates = [var for var in holidays.loc[\"2016\", ].index if var in train.index]\nfig, ax = plt.subplots(figsize = (18, 7))\nsns.lineplot(data = train[train['year'] == 2016].sales, estimator = 'sum', ax = ax, color='#C94B94', label = 'sales')\ndata = train.groupby(by = train.index).sum().loc[dates, 'sales']\nplt.scatter(data.index, data, s = 150, color = '#490E5E', label = 'Holiday');","5a52fa36":"df = df.reset_index()\ndf = df.set_index(['date', 'store_nbr', 'family'])\nentries_perday = len(df.loc['2013-01-01'])\ndf = df.reset_index().set_index('date')\nprint('Number of entries in a day across all stores : {}'.format(entries_perday))","2b96a37d":"for lag in range(1, 11):\n    df['sales_lag' + str(lag)] = df['sales'].shift(1782 * lag)\ndf.head(3)","4e380275":"train = df.iloc[:n_train, ]\ntest = df.iloc[n_train:, ]","f9300e78":"plt.figure(figsize = (16, 8))\ncolumns = [col for col in train.columns if 'sales' in col]\nsns.heatmap(data = train[columns].corr(), square = True,\n            annot = True, cmap = \"Reds\", vmax=1, vmin=.83, fmt = \".3f\")\nplt.xticks(rotation = 40)\nplt.title('Correlation - sales vs lagged sales', fontsize = 18);","f1ff24d4":"fig, axs = plt.subplots(2, 5, figsize = (15, 6))\naxs = axs.flatten()\nfor i in range(1, 11):\n    feature = 'sales_lag' + str(i)\n    sns.scatterplot(x=train[feature], y=train['sales'], ax=axs[i - 1], s=5)\n    axs[i - 1].set_title(feature, fontsize = 14)\n\nplt.suptitle('Scatterplot - Lags vs Sales', fontsize = 18)\nplt.tight_layout();","af5ffe26":"df.drop(columns = ['sales_lag1', 'sales_lag2', 'sales_lag3', 'sales_lag4', 'sales_lag5', 'sales_lag6', 'sales_lag8', 'sales_lag9', 'sales_lag10'], inplace = True)","bacab05c":"# Cleaning oil price dataset.\noil = oil.set_index('date')\noil = oil.rename(columns = {'dcoilwtico' : 'oilprice'})","11eae3f1":"holidays = holidays.groupby(holidays.index).first()","1d1d1b7b":"df = df.join(oil, on = 'date', how = 'left')\ndf = df.join(holidays, on = 'date', how = 'left')\ndf['oilprice'] = df['oilprice'].fillna(method = 'bfill')\ndf.head(5)","c7a0b5cb":"df.drop(columns = ['id', 'dayofyear', 'week', 'day', 'year', 'month'], inplace = True)","dc1466db":"df['work_day'] = 1\ndf.loc[df['dayofweek'] > 4, 'work_day'] = 0\ndf.loc[df['description'].notnull(), 'work_day'] = 0\ndf.loc[df.type == 'Bridge', 'work_day'] = 0\ndf.loc[df.type == 'Work Day', 'work_day'] = 1\ndf.loc[df.type == 'Transfer', 'work_day'] = 0\ndf.loc[(df.type == 'Holiday') & (df.transferred == False), 'work_day'] = 0\ndf.loc[(df.type == 'Holiday') & (df.transferred == True), 'work_day'] = 0\n","31831097":"df.drop(columns = ['locale', 'locale_name', 'description', 'transferred'],  inplace = True)","23a0bec4":"df = pd.get_dummies(df, columns=['type'], drop_first=False)","c00b12f6":"df.dayofweek = df.dayofweek.astype('str')\ndf = pd.get_dummies(df, columns = ['dayofweek'], drop_first=True)","7dda5e9f":"train = df.iloc[:n_train, ]\ntest = df.iloc[n_train:, ]","6d24af8b":"from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n# choosing order = 4 because monthly, biweekly, and weekly periodicity was observered in the periodogram.\nfourier = CalendarFourier(freq=\"W\", order=4)\ndata = train.reset_index().set_index(['store_nbr', 'family', 'date'])\ny = data['sales'].unstack(['store_nbr', 'family'])\n\ndp = DeterministicProcess(\n    index= y.index,\n    order=1,\n    seasonal=False,\n    constant=False,\n    additional_terms = [fourier],\n    drop = True\n)\n\nX = dp.in_sample()\nX.shape","a097347a":"# Let's look at our sin\/cos waves created by fourier trainsform.\nfig, axs = plt.subplots(1, 2, figsize = (18, 5))\n\nfor feature, color in zip(X.columns[3: ], sns.color_palette('winter', n_colors=8)):\n    if feature.find('sin') != -1:\n        axs[0].plot(X[feature].head(8), color = color)\n    elif feature.find('cos') != -1:\n        axs[1].plot(X[feature].head(8), color = color)\n\naxs[0].set_title('sin', fontsize = 18)\naxs[1].set_title('cos', fontsize = 18)\n\nplt.suptitle('Fourier Waves', fontsize = 24);","843ace32":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression().fit(X, y)\ny_pred = pd.DataFrame(data = model.predict(X),\n                      index = y.index,\n                      columns=y.columns)","700bc083":"fig, axs = plt.subplots(4, 1, figsize = (18, 15))\ndata = y.mean(axis = 1)\ny_pred = y_pred.mean(axis = 1)\n\n# plotting overall trend\ntrend = data.rolling(window=1, center=True, min_periods=0).mean()\naxs[0].plot(trend, linewidth = 1, color = (0.0, 0.3333333333333333, 0.8333333333333334))\naxs[0].plot(y_pred,  linewidth = 2, color = (0.3333333333333333, 0.6666666666666666, 0.4))\naxs[0].set_title(\"Overall Prediction\", fontsize = 18);\naxs[0].legend(['Actual Values - Daily rolling mean', 'Time Series Prediction'])\n\n# plotting yearly trend\ndata = data.loc['2016']\ntrend = data.rolling(window=1, center=True, min_periods=0).mean()\naxs[1].plot(trend, linewidth = 2, color = (0.0, 0.3333333333333333, 0.8333333333333334))\naxs[1].plot(y_pred.loc['2016'], linewidth = 3, color =  (0.3333333333333333, 0.6666666666666666, 0.4))\naxs[1].set_title(\"Yearly Prediction - 2016\", fontsize = 18);\naxs[1].legend(['Actual Values - Daily rolling mean', 'Time Series Prediction'])\n\n# plotting montly trend\ndata = data.loc['2016-01']\ntrend = data.rolling(window=1, center=True, min_periods=0).mean()\naxs[2].plot(trend, linewidth = 2, color = (0.0, 0.3333333333333333, 0.8333333333333334))\naxs[2].plot(y_pred.loc['2016-01'], linewidth = 3, color =  (0.3333333333333333, 0.6666666666666666, 0.4))\naxs[2].set_title(\"Monthly Prediction - Jan 2016\", fontsize = 18);\naxs[2].legend(['Actual Values - Daily rolling mean', 'Time Series Prediction']);\n\n# plotting weekly trend\ndata = data.loc['2016-01'].iloc[3:10]\ntrend = data.rolling(window=1, center=True, min_periods=0).mean()\naxs[3].plot(trend, linewidth = 2, color = (0.0, 0.3333333333333333, 0.8333333333333334))\naxs[3].plot(y_pred.loc['2016-01-04' : '2016-01-10'], linewidth = 3, color = (0.3333333333333333, 0.6666666666666666, 0.4))\naxs[3].set_title(\"Weekly Prediction - Jan First week 2016\", fontsize = 18);\naxs[3].legend(['Actual Values - Daily rolling mean', 'Time Series Prediction']);\n\nplt.tight_layout();","090fdaca":"delta = y.mean(axis=1) - y_pred","8f9483f1":"dates = [var for var in holidays.loc[\"2016\", ].index if var in train.index]\n\npoints = delta.to_frame(name = 'sales').loc['2016']\npoints = points.groupby(by = points.index).mean()\n\nfig, ax = plt.subplots(figsize = (18, 8))\nax.plot(points, color = 'lightgrey')\nplt.scatter(x = points.index, y = points['sales'], color='#C94B94', s = 5)\nax.scatter(x = dates, y = points.loc[dates, 'sales'], s = 100,  color = (0.0, 0.3333333333333333, 0.8333333333333334))\nplt.plot([datetime.datetime(2016, 1, 1), datetime.datetime(2017, 1, 1)], [0, 0], color = 'black', linewidth = 1)\nplt.title('Error Explained by Holidays', fontsize = 16);","1a45ca4e":"train.drop(columns = ['store_nbr', 'family'], inplace = True)\ntrain = train.groupby(by = train.index).first()\nX = X.join(train, how = 'left')\nX = X.fillna(0)\nX.drop(columns = ['sales', 'work_day'], inplace = True)","50b12e16":"from sklearn.linear_model import  Ridge\nridge_reg = Ridge(random_state=1)\nridge_reg.fit(X, y)\ny_pred = pd.DataFrame(ridge_reg.predict(X), index=y.index, columns=y.columns)","357fb5a8":"from sklearn.metrics import mean_squared_log_error\ny_pred   = y_pred.stack(['store_nbr', 'family']).reset_index()\ny_target = y.stack(['store_nbr', 'family']).reset_index().copy()\n\ny_pred.columns = ['date', 'store_nbr', 'family', 'sales']\ny_target.columns = ['date', 'store_nbr', 'family', 'sales']\ny_target['sales_pred'] = y_pred['sales'].clip(0.)\n\ny_target.groupby('family').apply(lambda r: mean_squared_log_error(r['sales'], r['sales_pred'])).sort_values(ascending=False)","e2daa9f3":"## Adding Lag Features for _sales_","c7f964b1":"Strong correlation (0.4)","a507ed06":"## _Ridge Regression_","b763f5ba":"##### Scatter Plot","c9ac328f":"### B) Time Analysis - **Trend**","a2e258bc":"Store has a strong effect on sales.","a10f9ecb":"### F) Holidays","d6871476":"# **Store Sales - Time Series Forecasting**\nUsing machine learning to predict grocery sales\n<hr>","799b027f":"#### Removing duplicate holidays \nIn certain dates many holidays coincide with each other. This will cause problems while joining the datasets. So i'm removing duplicates.","8ad58a48":"#### No clear trend. We'll have to deseason the data first.","7586a655":"Successfully added lag features.","8a1abad2":"Need to predict the sales between August 16 - 31.","51b52c18":"### Analysis of lagged sales","25030a16":"There are 1782 entries in a day. So if row 1 is about store 1, family - 'AUTOMOTIVE', row 1783 will be about the same store, and family but on the next day.","369ba1a5":"**NOTE :** We can't just simple use the shift function to get lags here. That will give us the sales of some other family of products sold that day.\n<br> We need to take the sales of the same family and store_nbr.","460986d8":"Daily Price of oil in Ecuador. We have the data between 16 - 31 August 2017, so this can be used as a feature.","ad1108e6":"**Oil** is the only dataframe with missing values.","ce1d6a9f":"#### Analysis : \n- Sales start slow but pick up as the year ends. Maybe because of holidays like christmas? \n- Montly sales are highest during the start and end of the month, and a slight uptick is present during the 15th. Could be because of public sector salaries.\n- Weekly sales have a strong seasonality, where sales dip during the middle of the week and peak at the ends.","0e802e60":"# III. Feature Engineering\n<hr>","68814ab5":"We don't have transaction data between 16 - 31 August 2017, so it's this data can't be used for predictions.","3ce9b282":"# I. Getting Started\n<hr>","40671d1a":"### Let's a combined dataset.","52fbbac1":"### A) Distribution","d000915b":"### Additional Notes\n- Wages in the public sector are paid every two weeks on the 15 th and on the last day of the month. Supermarket sales could be affected by this.\n- A magnitude 7.8 earthquake struck Ecuador on April 16, 2016. People rallied in relief efforts donating water and other first need products which greatly affected supermarket sales for several weeks after the earthquake.","97c7f01a":"- Store metadata, including city, state, type, and cluster.\n- cluster is a grouping of similar stores.","579de6d1":"#### Plotting Periodogram\nCreating a periodogram will give us a better understanding of the exact time periods for seasons.","231cab32":"#### Concatenating everything","68a662d4":"Most of the sales are close to 0.","767566ea":"##### Corr-plot","b15a1a8a":"### C) Time Analysis - **Seasonality**","4a19d9a6":"Upward trend present. Maybe related to lower oil prices? ","777c7960":"# II. Exploratory Data Analysis\n<hr>","9778d9e4":"Certain Holidays like New Years day can reduce errors.","9977fd46":"Holidays and Events, with metadata\n- NOTE: Pay special attention to the transferred column. A holiday that is transferred officially falls on that calendar day, but was moved to another date by the government. A transferred day is more like a normal day than a holiday. To find the day that it was actually celebrated, look for the corresponding row where type is Transfer. For example, the holiday Independencia de Guayaquil was transferred from 2012-10-09 to 2012-10-12, which means it was celebrated on 2012-10-12. Days that are type Bridge are extra days that are added to a holiday (e.g., to extend the break across a long weekend). These are frequently made up by the type Work Day which is a day not normally scheduled for work (e.g., Saturday) that is meant to payback the Bridge.\n- Additional holidays are days added a regular calendar holiday, for example, as typically happens around Christmas (making Christmas Eve a holiday).","c72f1dc1":"### Visualizing","60162896":"# IV. Modelling\n<hr>","86c4ae9f":"#### Let's first analyse the missing values.","f6ff4a60":"### Creating necessary columns using date.","2501ef3b":"Prices fell sharply in 2014.","dca18e1b":"Some products are more poplular than others.","87824d50":"### Creating a LinearModel using only time.\nLet's create a model without using other features like oil-price, store-nbr, family etc, to get a idea about how trends and seasons look in our data.","267caf33":"The training data, comprising time series of features store_nbr, family, and onpromotion as well as the target sales.\n - **store_nbr** (id) identifies the store at which the products are sold.\n - **family** (categorical) identifies the type of product sold.\n - **sales** (discrete) gives the total sales for a product family at a particular store at a given date. Fractional values are possible since products can be sold in fractional units (1.5 kg of cheese, for instance, as opposed to 1 bag of chips).\n - **onpromotion** (discrete) gives the total number of items in a product family that were being promoted at a store at a given date.","ca3de13c":"Any holiday with a +\/- is a day leading upto the holiday. Let's get rid of that to reduce dimensions.","543b5f5e":"### D) **C \u2192 T** (Categorical vs Target Analysis)\nCategorical features are - store_nbr and family.","168ff4be":"### Let's see how sales change in 2016 because of holidays","3592be5e":"Monthly, Biweekly, Weekly, Semiweekly seasonality present.","0eeeba68":"#### Dealing with categorical variables\nReplacing holidays with a single feature, which contains weather the day is a holiday or a work day can reduce dimensionality.","b44f530f":"### Next, let's check the effect of holidays on Prediction.","ec9b8b87":"### E) **D \u2192 T** (Discrete vs Target analysis)\nLet's analyize the only discrete independent variable - onpromotion.","89c711b1":"#### Our model follows all seasons reasonably well!","8a1f8ca9":"#### Creating Statsmodel Deterministic Processs","c446c49d":"Looks like a linear relation, but with a lot of outliers, because of the large number of rows.","09297ae4":"Creating dummy variables for month, and day of week"}}