{"cell_type":{"276cedfe":"code","126c1034":"code","cf10ed00":"code","6cc44f02":"code","0da9f69e":"code","9842b020":"code","78caf97d":"code","6332433e":"code","436d3025":"code","b948bef4":"code","14d68658":"code","d31c0d8b":"code","282227ac":"code","046003de":"code","170addde":"code","ad97b1c9":"code","eb381e43":"code","fa423887":"code","6141c02d":"code","e488d67c":"code","c84d2992":"code","23144a3f":"code","5f11812e":"code","2ea2e954":"code","64a56170":"code","bdadec09":"code","9734ee90":"code","91174731":"code","47bece3f":"code","0f295440":"markdown","fa2167a0":"markdown","6cc7241e":"markdown","71ea8452":"markdown","5ef76294":"markdown","b7459dbb":"markdown","221e8fad":"markdown","30b776d4":"markdown","947c3c32":"markdown","077b451d":"markdown","6f264e52":"markdown","ab722101":"markdown","e196b5b8":"markdown","c9044ddb":"markdown","2253a529":"markdown","446edd24":"markdown","8781e531":"markdown","46d69c07":"markdown","c0352aff":"markdown","67810e22":"markdown","9a5745c8":"markdown"},"source":{"276cedfe":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport os\nprint(os.listdir(\"..\/input\"))","126c1034":"train=pd.read_csv(\"..\/input\/train.csv\")\ntrain.head()","cf10ed00":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='Blues')","6cc44f02":"sns.countplot(x='Survived',data=train)","0da9f69e":" sns.countplot(x='Survived',hue='Sex',data=train)","9842b020":" sns.countplot(x='Survived',hue='Pclass',data=train)","78caf97d":"sns.distplot(train['Age'].dropna(),kde=False,bins=30)#we dropped na to prevent them from messing up our distplot","6332433e":"sns.countplot(x='SibSp',data=train)","436d3025":" sns.distplot(train['Fare'],bins=40,kde=False)","b948bef4":"plt.figure(figsize=(10,6))\nsns.boxplot(x='Pclass',y='Age',data=train)","14d68658":"a=train.groupby(train['Pclass'])\nmean=a['Age'].mean()\nprint(mean)","d31c0d8b":"def impute_age(cols):\n    Age=cols[0]\n    Pclass=cols[1]\n    \n    if pd.isnull(Age):\n        \n        if Pclass==1:\n            return 38\n        elif Pclass==2:\n            return 30\n        else:\n            return 25\n    else:\n        return Age\n     ","282227ac":"train['Age']=train[['Age','Pclass']].apply(impute_age,axis=1)","046003de":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='Blues')","170addde":"train.drop('Cabin',axis=1,inplace=True)\ntrain.dropna(inplace=True)\ntrain.head()","ad97b1c9":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='Blues')","eb381e43":"sex=pd.get_dummies(train['Sex'],drop_first=True)\nsex.head()","fa423887":"embark=pd.get_dummies(train['Embarked'],drop_first=True)\nembark.head()","6141c02d":"train=pd.concat([train,sex,embark],axis=1)\ntrain.head(2)","e488d67c":"train.drop(['Name','Sex','Embarked','Ticket','PassengerId'],axis=1,inplace=True)\ntrain.head()","c84d2992":"X=train.drop('Survived',axis=1)\ny=train['Survived']","23144a3f":" from sklearn.model_selection import train_test_split","5f11812e":"X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.35, random_state=42)","2ea2e954":"from sklearn.linear_model import LogisticRegression","64a56170":"logmodel=LogisticRegression()","bdadec09":"logmodel.fit(X_train,y_train)","9734ee90":"predictions=logmodel.predict(X_test)","91174731":"from sklearn.metrics import classification_report","47bece3f":"print(classification_report(y_test,predictions))","0f295440":"From the above table we can see the percision, f1score and recall values for our model.\nConsidreing we only used the training data we can see that we did well as our f1-score quit close to 1.","fa2167a0":"In this kernel I will be trying logistic regression and will be using only the training data.","6cc7241e":"In order to apply ML algortihms to this data set we need to convert the categorical features into  **Dummy variables** using pandas. We do this as our algorith wont be able to directly take these features as inputs.\nIn this dataset we have two categorical features, **Sex** and **Embarked**.","71ea8452":"We can now observe the generall age of people on the titanic. There are quiet a few children but we can observe that most of the passangers are between 20-30   ","5ef76294":"Since we get a heatmap with a solid color we can now confirm that there are no null values in our dataset","b7459dbb":"Lets further explore the data at a visual level","221e8fad":"From the above heatmap we can conlude that we are missing some of the age information and a lot of cabin information. ","30b776d4":"From the above plot we can clearly see that most of the passengers did not have any children or spouse on board.","947c3c32":"Again we we notice a trend and we can clearly see that people who did not survive were of the lowest class(the 3rd class) and among people who did survive there were more people from the first class. But we should also consider the number of people in each class before making any conclusions.","077b451d":"We observe that most of the fare were between 0 and 50 which makes sense as there were more people riding the cheaper third class.","6f264e52":"In order to fill in the age we can use the average age values and impute it based on the passenger class(Pclass). We can observe the average age for each class in the boxplot above.","ab722101":"Now that we have replaced the null values of age lets look at the heat map again","e196b5b8":"The above plot shows how around 550 people did not survive and about 350 people suvived.","c9044ddb":"Now that we have explored the data by going though every column of the test data lets **clean** our data. Using heatmap we obseved that we have missing data for the Age and the Cabin columns. There is a lot of missing data in the Cabin column and so we will be setting it apart for now and focus our attention on the age column.\nWe can fill-in the missing data from the age column instead of just dropping it all off.","2253a529":"Lets train and use a  Model to predict if a passanger survived on the titanic. In this kernel we will be assume that the train dataset is all the data we have and perform a train-test split using scikit-learn so we dont have to clean the test.csv again.","446edd24":"We can now drop the cabin column as it has too much missing information. We can also get rid of any null values as they wont be useful to us.","8781e531":"We dropped the First columns from both Sex and Embark to avoid Multicollinearity.\nLets add these new dataframes to the train dataframe.","46d69c07":"Looking at this plot we can observe a trend. Among people who did not survive there were more males and among people that did survive there were more females.","c0352aff":"We now know the exact mean age values for every class","67810e22":"Now that we have created dummy variables for our categorical features we can now get rid of all the columns that we dont require.\nThese mainly include columns that contain text like the name of the passanger and their ticket. We will also be dropping Sex and Embarked as we have created dummy variabled for them. We also be dropping the Passenger Id as it does not determine if someone will survive or die.","9a5745c8":"Lets Create a simple heat map to see where we are missing most of our data."}}