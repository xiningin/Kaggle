{"cell_type":{"1fe6161b":"code","e39c9ef9":"code","e2343a0c":"code","7b1e1321":"code","4cb1937b":"code","1ab990c9":"code","db0d9d1b":"code","4f05cfa4":"code","b28178b5":"code","5c6bfdcb":"code","398b4acb":"code","ce2525aa":"code","2cae9d6c":"code","92ca53e7":"code","c30559fa":"code","2f6c0cc4":"code","bf57510b":"code","693202db":"code","5d07706c":"code","7f3ff197":"code","f24f0ec5":"code","2e248abb":"code","59c512e9":"code","28ba295e":"code","e081b05b":"code","9b665267":"code","d2e6468e":"code","e10309a0":"code","4568f230":"code","ed4909ea":"code","0899f533":"code","c42ceb1b":"markdown","19f248a3":"markdown","6b0ce9b7":"markdown","5bec85da":"markdown"},"source":{"1fe6161b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e39c9ef9":"file_path = \"..\/input\/lung-cancer-dataset\/lung_cancer_examples.csv\"\ndata = pd.read_csv(file_path, index_col=\"Name\")","e2343a0c":"data.shape","7b1e1321":"data.describe","4cb1937b":"data.tail()","1ab990c9":"num_result_0 = data.loc[data.Result==0].count()\nnum_result_0","db0d9d1b":"num_result_1 = data[data.Result==1].count()\nnum_result_1","4f05cfa4":"x = [\"0\", \"1\"]\ny = [31, 28]\nplt.title(\"Class distribution\")\nplt.ylabel(\"Number of records\")\nplt.bar(x,y)","b28178b5":"sns.swarmplot(x=data['Result'],\n              y=data['Age'])","5c6bfdcb":"sns.swarmplot(x=data['Result'],\n              y=data['Smokes'])","398b4acb":"sns.swarmplot(x=data['Result'],\n              y=data['AreaQ'])","ce2525aa":"sns.swarmplot(x=data['Result'],\n              y=data['Alkhol'])","2cae9d6c":"from sklearn.model_selection import cross_val_score, KFold, train_test_split\nX = data.drop(['Surname','Result'], axis=1)\ny = data['Result'].copy()","92ca53e7":"X.shape","c30559fa":"y.shape","2f6c0cc4":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)","bf57510b":"X_train.shape","693202db":"X_test.shape","5d07706c":"results_dict = {}","7f3ff197":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.naive_bayes import GaussianNB\nkf = KFold(n_splits=5, random_state=0, shuffle=True)","f24f0ec5":"lr = LogisticRegression(C=0.5, random_state=1).fit(X_train, y_train)\nmean_acc_lr = cross_val_score(lr, X_train, y_train, n_jobs=-1, cv=kf, scoring='accuracy').mean()\nresults_dict['Logistic Regression'] = mean_acc_lr\nresults_dict","2e248abb":"knn = KNeighborsClassifier(n_neighbors=5)\nmean_acc_knn = cross_val_score(knn, X_train, y_train, n_jobs=-1, cv=kf, scoring='accuracy').mean()\nresults_dict['KNN'] = mean_acc_knn\nresults_dict","59c512e9":"dt = DecisionTreeRegressor()\nmean_acc_dt = cross_val_score(dt, X_train, y_train, n_jobs=-1, cv=kf, scoring='accuracy').mean()\nresults_dict['Decision Tree'] = mean_acc_dt\nresults_dict","28ba295e":"nb = GaussianNB()\nmean_acc_nb = cross_val_score(nb, X_train, y_train, n_jobs=-1, cv=kf, scoring='accuracy').mean()\nresults_dict['NB'] = mean_acc_nb\nresults_dict","e081b05b":"x = ['Logistic Regression', 'KNN', 'Decision Tree', 'NB']\ny = [results_dict['Logistic Regression'], results_dict['KNN'], results_dict['Decision Tree'], results_dict['NB']]\nplt.title(\"Accuracy comparison\")\nplt.ylabel(\"Accuracy\")\nplt.bar(x,y)","9b665267":"from sklearn.metrics import accuracy_score\nnb = GaussianNB().fit(X_train, y_train)\npredicted = nb.predict(X_test)\naccuracy_score(y_test, predicted)","d2e6468e":"from sklearn.metrics import plot_confusion_matrix\n\ndisp = plot_confusion_matrix(nb, X_test, y_test,\n                                 display_labels=data['Result'],\n                                 cmap=plt.cm.Blues)\n\ndisp.ax_.set_title(\"Confusion Matrix\")\ndisp.confusion_matrix\nplt.show()","e10309a0":"from sklearn.metrics import confusion_matrix\nconfusion = confusion_matrix(y_test, predicted)\nconfusion","4568f230":"TP = confusion[1, 1]\nTN = confusion[0, 0]\nFP = confusion[0, 1]\nFN = confusion[1, 0]","ed4909ea":"sensitivity = TP\/(TP+FN)\nspecificity = TN\/(TN+FP)","0899f533":"\"Sensitivity: {} | Specifictity: {}\".format(sensitivity, specificity)","c42ceb1b":"Using 4 different classifiers and k-fold cross-validation","19f248a3":"Checking the relationship between the features and classes","6b0ce9b7":"Two widely used measures in the medical domain are **sensitivity** and **specificity**. To calculate them we need:\n* True Positive (TP)\n* True Negative (TN)\n* False Positive (FP)\n* False Negative (FN)","5bec85da":"Class Distribution"}}