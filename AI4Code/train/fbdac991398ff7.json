{"cell_type":{"f4bfa93c":"code","fc7acef6":"code","1f5d7f2c":"code","ec81db2c":"code","4241651a":"code","9bc2e25c":"code","93aef7ba":"code","48be7c0b":"code","e101c95b":"code","c660d109":"code","dc70635b":"code","9f5f344b":"code","b7d70348":"code","4cb12fc7":"code","4199166b":"code","5b919cef":"code","5c1918a2":"code","401b25c9":"code","489f45cf":"code","967d0b6e":"code","3ecce9a5":"markdown","02c1bbd2":"markdown","18744d39":"markdown","973fc59a":"markdown","38175ab7":"markdown"},"source":{"f4bfa93c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fc7acef6":"import os\nimport zipfile\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nimport scipy.ndimage\nimport pandas as pd\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom urllib.request import urlopen\nfrom PIL import Image","1f5d7f2c":"# Data\ntrainFolder = \"..\/input\/horses-or-humans-dataset\/horse-or-human\/train\"\ntestFolder = \"..\/input\/horses-or-humans-dataset\/horse-or-human\/validation\"","ec81db2c":"import os\ntrain_human_names = os.listdir(trainFolder)\nprint(train_human_names[:10])","4241651a":"train_horse_names = os.listdir(testFolder)\nprint(train_horse_names[:10])","9bc2e25c":"train_horse_dir = os.path.join('..\/input\/horses-or-humans-dataset\/horse-or-human\/train\/horses')\ntrain_human_dir = os.path.join('..\/input\/horses-or-humans-dataset\/horse-or-human\/validation\/humans')","93aef7ba":"train_horse_names = os.listdir(train_horse_dir)\nprint(train_horse_names[:10])","48be7c0b":"train_human_names = os.listdir(train_human_dir)\nprint(train_human_names[:10])","e101c95b":"print('total training horse images:', len(os.listdir(train_horse_dir)))\nprint('total training human images:', len(os.listdir(train_human_dir)))","c660d109":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n \n# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 4\nncols = 4\n\n# Index for iterating over images\npic_index = 0\n\n# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols * 4, nrows * 4)\n\npic_index += 8\nnext_horse_pix = [os.path.join(train_horse_dir, fname) \n                for fname in train_horse_names[pic_index-8:pic_index]]\nnext_human_pix = [os.path.join(train_human_dir, fname) \n                for fname in train_human_names[pic_index-8:pic_index]]\n\nfor i, img_path in enumerate(next_horse_pix+next_human_pix):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') # Don't show axes (or gridlines)\n \n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n\nplt.show()","dc70635b":"listLabels = labels = ['Horse','Human']","9f5f344b":"# Image generator\nimageGenerator = ImageDataGenerator(\n    rescale = 1.\/255,\n    horizontal_flip=True,\n    zoom_range=0.15,\n    zca_whitening=True,\n    fill_mode='nearest')\n\n# training images\ntrainImages = imageGenerator.flow_from_directory(\n    trainFolder,\n    target_size=(48,48),\n    class_mode='categorical')\n\n# test Images\ntestImages = ImageDataGenerator(rescale=1.\/255)\ntestImages = imageGenerator.flow_from_directory(\n        testFolder,\n        target_size=(48, 48),\n        class_mode='categorical')","b7d70348":"model = keras.Sequential(\n    [\n        keras.Input(shape=(48,48,3)),\n        layers.Flatten(),\n        layers.BatchNormalization(),\n        layers.Dense(128, activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Dense(32, activation=\"relu\"),\n        layers.Dense(2, activation=\"softmax\"),\n    ]\n)","4cb12fc7":"model.build((48, 48))\nmodel.summary()","4199166b":"model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","5b919cef":"early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n\nclass PrintDot(keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs):\n        if epoch % 100 == 0: \n            print('')\n            print(\"Epoch\",epoch,'completed', end='')\n\n            \nqtyEpochs = 50\nhistory = model.fit(trainImages, validation_data=testImages,batch_size=50, shuffle=True, epochs=qtyEpochs, callbacks=[early_stop,PrintDot()], verbose=1)","5c1918a2":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.ylim([0, 1])\nplt.show()\n\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.ylim([0, 1])\nplt.show()","401b25c9":"model_eval = model.evaluate_generator (\n    testImages,\n    verbose=0\n)\n\nprint('Model accuracy:',model_eval[1])\nprint('Model loss:',model_eval[0])","489f45cf":"image = urlopen(\"https:\/\/www.pngitem.com\/pimgs\/m\/50-503903_man-riding-horse-galloping-clipart-man-on-horse.png\")\ntest01 = Image.open(image)\ntest01 = test01.convert('RGB')\ntest01 = test01.resize((48,48))\ntest01_arr = np.asarray(test01) \/ 255\npred = model.predict(np.array([test01_arr]))\nprint(\"Pred:\",labels[pred.argmax(axis=-1)[0]])","967d0b6e":"image = urlopen(\"https:\/\/www.pngitem.com\/pimgs\/m\/50-503903_man-riding-horse-galloping-clipart-man-on-horse.png\")\ntest02 = Image.open(image)\ntest02 = test02.convert('RGB')\ntest02 = test02.resize((48,48))\ntest02_arr = np.asarray(test02) \/ 255\npred = model.predict(np.array([test02_arr]))\nprint(\"Pred:\",labels[pred.argmax(axis=-1)[0]])","3ecce9a5":"### 3. Definir el modelo","02c1bbd2":"### 1. Cargar dataset","18744d39":"### 0. Cargar librer\u00edas","973fc59a":"### 2. Exploramos la data","38175ab7":"### 4. Entrenar la Red Neuronal\nHiperparametros:\n- learning-rate: 0.01\n- Algoritmo de optimizacion: Adam\n- epocs: 200\n- batch: 100"}}