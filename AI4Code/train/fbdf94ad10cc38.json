{"cell_type":{"90cf20a9":"code","645e8100":"code","96a65dde":"code","1b14569e":"code","08e67dc2":"code","9a104209":"code","9913a2b5":"code","7a831530":"code","f3880bea":"code","f20e8a06":"code","147b97c5":"markdown","d861aa5a":"markdown","e335fb25":"markdown","b3e0effc":"markdown","f81e1ad5":"markdown"},"source":{"90cf20a9":"import numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport keras\nfrom scipy import ndimage\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nfrom keras import backend as K\n\nfrom scipy import stats\n\nimport warnings\nwarnings.filterwarnings('ignore')","645e8100":"# Model \/ data parameters\nnum_classes = 10\ninput_shape = (28, 28, 1)\n\n# the data, split between train and test sets\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n\n# Scale images to the [0, 1] range\nx_train = x_train.astype(\"float32\") \/ 255\nx_test = x_test.astype(\"float32\") \/ 255\n# Make sure images have shape (28, 28, 1)\nx_train = np.expand_dims(x_train, -1)\nx_test = np.expand_dims(x_test, -1)\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)","96a65dde":"inp = keras.Input(shape=input_shape)\n\nx = layers.Conv2D(filters=5, kernel_size=(5,5), activation='relu')(inp)\nx = layers.Conv2D(filters=5, kernel_size=(3, 3), activation='relu')(x)\nx = layers.Flatten()(x)\nx = layers.Dense(units=512, activation='relu')(x)\nx = layers.Dense(units=128, activation='relu')(x)\nx = layers.Dense(units=10)(x)\n\n\nmodel = keras.Model(inp, x)\n\nmodel.summary()","1b14569e":"# Source: https:\/\/github.com\/michaeleh\/Evidential-Deep-Learning-to-Quantify-Classification-Uncertainty\/blob\/main\/demo.ipynb\n\nlgamma = tf.math.lgamma\ndigamma = tf.math.digamma\n\nepochs = [1]\n\ndef KL(alpha, num_classes=10):\n    one = K.constant(np.ones((1,num_classes)),dtype=tf.float32)\n    S = K.sum(alpha,axis=1,keepdims=True)  \n\n    kl = lgamma(S) - K.sum(lgamma(alpha),axis=1,keepdims=True) +\\\n    K.sum(lgamma(one),axis=1,keepdims=True) - lgamma(K.sum(one,axis=1,keepdims=True)) +\\\n    K.sum((alpha - one)*(digamma(alpha)-digamma(S)),axis=1,keepdims=True)\n          \n    return kl\n\n\ndef loss_func(y_true, output):\n    y_evidence = K.relu(output)\n    alpha = y_evidence+1\n    S = K.sum(alpha,axis=1,keepdims=True)\n    p = alpha \/ S  \n\n    err = K.sum(K.pow((y_true-p),2),axis=1,keepdims=True)\n    var = K.sum(alpha*(S-alpha)\/(S*S*(S+1)),axis=1,keepdims=True)\n    \n    l =  K.sum(err + var,axis=1,keepdims=True)\n    l = K.sum(l)\n    \n    \n    kl =  K.minimum(1.0, epochs[0]\/50) * K.sum(KL((1-y_true)*(alpha)+y_true))\n    return l + kl","08e67dc2":"batch_size = 1024\nmodel.compile(loss=loss_func, optimizer=\"adam\", metrics=['accuracy'])\n\nfrom tqdm import tqdm\n\nfor i in tqdm(range(30)):\n    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs[0], verbose=0, validation_split=0.2)\n    epochs[0]+=1","9a104209":"score = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Test loss:\", score[0])\nprint(\"Test accuracy:\", score[1])","9913a2b5":"def rotate(im,deg):\n    #rotation angle in degree\n    return ndimage.rotate(im, deg)","7a831530":"def calc_prob_uncertinty(p):\n  \n    evidence = np.maximum(p[0], 0)\n\n    alpha = evidence +1\n\n    u = 10\/ alpha.sum()\n    prob = alpha[np.argmax(alpha)] \/ alpha.sum()\n    return prob, u","f3880bea":"d = 1\ndigit = 1\nangles_range = list(range(0,180,10))\n\ntest_labels = np.argmax(y_test,axis=1)\n\npredictions = []\nuncertinties = []\nprobabilities= []\nimgs = []\nfor angle in angles_range:    \n\n    im = x_test[np.where(test_labels==digit)[0][0]]    \n    shape = im.shape\n    im = rotate(im, angle)    \n    im = cv2.resize(im,shape[:-1],interpolation = cv2.INTER_AREA)\n    imgs.append(im)\n    p = model.predict(np.array([im.reshape(shape)]))  \n    prob, uncertinty = calc_prob_uncertinty(p)\n    uncertinties.append(uncertinty)\n    probabilities.append(prob)  \n    predictions.append(np.argmax(p))\n\nplt.plot(angles_range,probabilities, label=f'Class={d}',marker='o')\nplt.plot(angles_range,uncertinties, label=f'Uncertinty={d}',marker='o')\n\nplt.xlabel('Angle')\nplt.ylabel('Probability')\nplt.legend()\nplt.title('Probability on Rotation')\nplt.grid()\nplt.show()\n\nplt.plot(angles_range,predictions, label=f'Class={d}',marker='o')\nplt.xlabel('Angle')\nplt.ylabel('Predictions')\nplt.legend()\nplt.title('Prediction per Rotation')\nplt.grid()\nplt.show()\n\nf,axs = plt.subplots(1,len(imgs),figsize=(10,20))\nfor ax,im in zip(axs.ravel(),imgs):\n    ax.imshow(im,cmap='gray')\nplt.show()","f20e8a06":"y_pred1 = model.predict(x_test)\ny_pred =  np.argmax(y_pred1,axis=1)\n\n# Separating Wrong Responses of the CNN Classifier\nX_test_wrong, y_test_wrong = x_test[np.where(y_test != y_pred)], y_test[np.where(y_test != y_pred)]\n\n# Separating Correct Responses of the CNN Classifier\nX_test_correct, y_test_correct = x_test[np.where(y_test == y_pred)], y_test[np.where(y_test == y_pred)]\n\nr = 0\nN = 0\nE_F = np.zeros(10)\n\nfor ii in range(10):\n    X_test_wrong_i, y_test_wrong_i = X_test_wrong[np.where(y_test_wrong == ii+1)], y_test_wrong[np.where(y_test_wrong == ii+1)]\n    X_test_correct_i, y_test_correct_i = x_test[np.where(y_test_correct == ii+1)], y_test[np.where(y_test_correct == ii+1)]\n    r = X_test_wrong_i.shape[0]\n    N = X_test_wrong_i.shape[0] + X_test_correct_i.shape[0] \n    \n    E_F[ii] = (1 + r)\/(1+1+N)\n    \nReliability = 1 - 0.1*(sum(E_F))\n\nprint(Reliability)","147b97c5":"#### Source: https:\/\/github.com\/atilberk\/evidential-deep-learning-to-quantify-classification-uncertainty\n#### Paper: https:\/\/arxiv.org\/pdf\/1806.01768.pdf\n\n### Loss Functions\n\nThere are three different loss functions defined in the paper:\n\n#### 1) Integrating out the class probabilities from posterior of Dirichlet prior & Multinomial likelihood - will be mentioned as *Eqn. 3* (as in the paper)\n\n$$\n\\mathcal{L}_i(\\Theta) =\n- log ( \\int \\prod_{j=1}^K p_{ij}^{y_{ij}} \\frac{1}{B(\\alpha_i)} \\prod_{j=1}^K p_{ij}^{\\alpha_{ij} -1 } d\\boldsymbol{p}_i )\n= \\sum_{j=1}^K y_{ij} (log(S_i) - log(\\alpha_{ij}))\n$$\n\n#### 2) Using cross-entropy loss - will be mentioned as *Eqn. 4* (as in the paper)\n\n$$\n\\mathcal{L}_i(\\Theta) =\n\\int [\\sum_{j=1}^K -y_{ij} log(p_{ij})] \\frac{1}{B(\\alpha_i)} \\prod_{j=1}^K p_{ij}^{\\alpha_{ij} -1 } d\\boldsymbol{p}_i \n= \\sum_{j=1}^K y_{ij} (\\psi(S_i) - \\psi(\\alpha_{ij}))\n$$\n\n#### 3) Using sum of squares loss - will be mentioned as *Eqn. 5* (as in the paper)\n\n$$\n\\mathcal{L}_i(\\Theta) =\n\\int ||\\boldsymbol{y}_i - \\boldsymbol{p}_i||_2^2 \\frac{1}{B(\\alpha_i)} \\prod_{j=1}^K p_{ij}^{\\alpha_{ij} -1 } d\\boldsymbol{p}_i \n= \\sum_{j=1}^K \\mathbb{E}[(y_{ij} - p_{ij})^2]\n$$\n\n$$\n= \\sum_{j=1}^K \\mathbb{E}[y_{ij}^2 - 2 y_{ij}p_{ij} + p_{ij}^2] \n= \\sum_{j=1}^K (y_{ij}^2 - 2 y_{ij}\\mathbb{E}[p_{ij}] + \\mathbb{E}[p_{ij}^2])\n$$\n\n$$\n= \\sum_{j=1}^K (y_{ij}^2 - 2 y_{ij}\\mathbb{E}[p_{ij}] + \\mathbb{E}[p_{ij}]^2 + \\text{Var}(p_{ij}))\n= \\sum_{j=1}^K (y_{ij} - \\mathbb{E}[p_{ij}])^2 + \\text{Var}(p_{ij})\n$$\n\n$$\n= \\sum_{j=1}^K (y_{ij}^2 - 2 y_{ij}\\mathbb{E}[p_{ij}] + \\mathbb{E}[p_{ij}]^2 + \\text{Var}(p_{ij}))\n= \\sum_{j=1}^K (y_{ij} - \\mathbb{E}[p_{ij}])^2 + \\text{Var}(p_{ij})\n$$\n\n$$\n= \\sum_{j=1}^K (y_{ij} - \\frac{\\alpha_{ij}}{S_i})^2 + \\frac{\\alpha_{ij}(S_i - \\alpha_{ij})}{S_i^2(S_i + 1)}\n$$\n\n$$\n= \\sum_{j=1}^K (y_{ij} - \\hat{p}_{ij})^2 + \\frac{\\hat{p}_{ij}(1 - \\hat{p}_{ij})}{(S_i + 1)}\n$$","d861aa5a":"## Reliability Evaluation of the Classification Algorithm (Stable Operational Profile)\n\nWe assume, in line with the literature, that the black-box reliability is expressed as the probability of not failing on a randomly chosen input $d_r \\epsilon D$ [[1]](https:\/\/doi.org\/10.1016\/j.ress.2020.107193).\n\nAssuming that each class is an operational profile of the traffic sign recognition and aslo assuming no prior knowledge about the occurrence of failures\nwithin partitions, the priors $f_i (x)$ are set to $Beta(\\boldsymbol{\\alpha_{i}} = 1, \\boldsymbol{\\beta_{i}} = 1)$. Let's consider $N_{i}$ as the number of test images that provided as an input to the algorithm and $r_{i}$ as the number of failures. \n\nThe Dirichlet distribution $D(\\boldsymbol{\\alpha_{1}},..., \\boldsymbol{\\alpha_{n}})$ modeling the OPP before the new observation, with the new information $N_{1}, ..., N_{n}$, will become:\n\n$$\nD(\\boldsymbol{\\alpha_{1}}+N_{1},..., \\boldsymbol{\\alpha_{n}}+N_{n})\n$$\n\n\nBased on equation 14, the updated distribution of the conditional probability of failure in recognising class $i$ in the operation profile or partition $S_{i}$ will be:\n\n$$f_{F_{i}} = B(\\boldsymbol{\\alpha_{i}} + r_{i},\\boldsymbol{\\beta_{i}} + N_{i} - r_{i})$$ \n\nThe expected value of $f_{F_{i}}$ can be calculated as:\n\n$$E[F_{i}] = \\frac{\\boldsymbol{\\alpha_{i}} + r_{i}}{\\boldsymbol{\\beta_{i}} + \\boldsymbol{\\alpha_{i}} + N_{i}}$$\n\nConsidering the same probability of each $OPP_{i}$ as $1\/10$, the reliabiity can be calculated as:\n\n$$\nE[R] = 1 - \\sum_{i=1}^{43} OPP_{i} \\times E[F_{i}] = 1 - 0.1\\times \\sum_{i=1}^{43} \\frac{\\boldsymbol{\\alpha_{i}} + r_{i}}{\\boldsymbol{\\beta_{i}} + \\boldsymbol{\\alpha_{i}} + N_{i}}\n$$\n\nIt should be noted that the partisions can be more detailed by separating the conditions like rain, light, rotation, etc [2,3]. The example that we have considered is a super simplified version. \n\n[[1] Pietrantuono, R., Popov, P., & Russo, S. (2020). Reliability assessment of service-based software under operational profile uncertainty. Reliability Engineering & System Safety, 204, 107193.](https:\/\/doi.org\/10.1016\/j.ress.2020.107193)\n\n[[2] Zhang, M., Zhang, Y., Zhang, L., Liu, C., & Khurshid, S. (2018, September). DeepRoad: GAN-based metamorphic testing and input validation framework for autonomous driving systems. In 2018 33rd IEEE\/ACM International Conference on Automated Software Engineering (ASE) (pp. 132-142).](https:\/\/doi.org\/10.1145\/3238147.3238187)\n\n[[3] J\u00f6ckel, L., Kl\u00e4s, M., & Mart\u00ednez-Fern\u00e1ndez, S. (2019, July). Safe traffic sign recognition through data augmentation for autonomous vehicles software. In 2019 IEEE 19th International Conference on Software Quality, Reliability and Security Companion (QRS-C) (pp. 540-541).](https:\/\/doi.org\/10.1109\/QRS-C.2019.00114)","e335fb25":"Simple LeNet like in the paper without activation","b3e0effc":"## Theory of Evidence\n\nSource: https:\/\/github.com\/atilberk\/evidential-deep-learning-to-quantify-classification-uncertainty\n\nPaper: https:\/\/arxiv.org\/pdf\/1806.01768.pdf\n\nSuppose that there are $K$ outputs of an NN. Then we can write the following equality\n$$u + \\sum_{k = 1}^{K} b_k = 1$$\nwhere $b_k$ corresponds to $k^{th}$ ReLU output which will be interpreted as the *belief mass* of the $k^{th}$ class and $u$ is the *uncertainty mass* of the particular outputs.\n\nEach $b_k$ is defined as follows\n$$b_k =\\frac{e_k}{S}$$\nwhere $e_k$ is the evidence of the $k^{th}$ class and $S$ is the strength of the Dirichlet we'll use and defined as \n$$S = \\sum_{k = 1}^{K} (e_k + 1)$$\nwhich leaves $u$ the following portion\n$$u = \\frac{K}{S}$$\n\n\nReplacing $e_k + 1$ with $a_k$\n$$\\alpha_k = e_k + 1$$\nand using the resultant simplex vector $a$ in a Dirichlet as the density\n$$\nD(\\boldsymbol{p}|\\boldsymbol{\\alpha}) = \\begin{cases} \n      \\frac{1}{B(\\boldsymbol{\\alpha})} \\prod_{i=1}^{K} p_i^{\\alpha_i - 1} & \\text{for } \\boldsymbol{p} \\in \\mathcal{S}_K \\\\\n      0 & \\text{otherwise}\n   \\end{cases}\n$$\n\nAs a result, we can define $\\mathcal{S}_K$ as \n$$\\mathcal{S}_K = \\{ \\boldsymbol{p} | \\sum_{i=1}^K p_i = 1 \\text{ and } 0 \\leq p_1,...,p_K \\leq 1 \\}$$\nand the probability of $k^{th}$ can still be calculated as\n$$\\hat{p}_k = \\frac{\\alpha_k}{S}$$","f81e1ad5":"# Evidential Deep Learning and Reliability Evaluation for MNIST Dataset\n\n### In this notebook, Evidential Deep Learning (EDL) is introduced to quantify classification uncertainty and also a new way to measure the reliability of the Machine Learning classifiers is disscussed. \n\nThe idea of reliability evaluation is going to be a part of [SafeML Project](https:\/\/github.com\/ISorokos\/SafeML).\n\nThe EDL part of this notebook is a modified version of another notebook provided by [Michael Ehrlich on GitHub](https:\/\/github.com\/michaeleh\/Evidential-Deep-Learning-to-Quantify-Classification-Uncertainty\/blob\/main\/demo.ipynb)."}}