{"cell_type":{"058753db":"code","f57bc779":"code","7f27bf96":"code","029e08b6":"code","1604ec88":"code","370b96ad":"code","86b7354b":"code","ca8659df":"code","2c82d25b":"code","b223aa19":"code","eb6a9bc9":"code","7ae19e58":"code","f8815af5":"code","e115053a":"code","b2b31dca":"code","fe52a32d":"code","268bcb18":"markdown","b7d1aa00":"markdown","1da11e2d":"markdown"},"source":{"058753db":"import os\nimport numpy as np\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image","f57bc779":"# create list of all directories\nbase_dir = '\/kaggle\/input\/alaska2-image-steganalysis\/'\nimage_dirs = ['Cover','JUNIWARD', 'JMiPOD',  'UERD']","7f27bf96":"data = {}\n\nfor image_dir in image_dirs:\n    if image_dir==\"Test\":\n        continue\n    images = []\n    for file in os.listdir(os.path.join(base_dir, image_dir)):\n        images.append(file)\n    data[image_dir]=images\n\ntrain_df = pd.DataFrame(data)","029e08b6":"train_df.head()","1604ec88":"def similarity_test(df):\n    similarity = set(df['Cover'] == df['JUNIWARD'])\n    similarity = similarity | set(df['Cover'] ==df['JMiPOD'])\n    similarity = similarity | set(df['Cover'] ==df['UERD'])\n    return similarity\n","370b96ad":"similarity_test(train_df)","86b7354b":"train_df.describe()","ca8659df":"train_df.info()","2c82d25b":"image_id_1 = 41731\nimage_id_2 = 12314\nimage_id_3 = 28962\nimage_id_4 = 127\nsample_images_1 = [base_dir + x[0] +'\/'+x[1] for x in zip(list(train_df.columns) , list(train_df.iloc[image_id_1,:]))]\nsample_images_2 = [base_dir + x[0] +'\/'+x[1] for x in zip(list(train_df.columns) , list(train_df.iloc[image_id_2,:]))]\nsample_images_3 = [base_dir + x[0] +'\/'+x[1] for x in zip(list(train_df.columns) , list(train_df.iloc[image_id_3,:]))]\nsample_images_4 = [base_dir + x[0] +'\/'+x[1] for x in zip(list(train_df.columns) , list(train_df.iloc[image_id_4,:]))]\n\nsample_images_1","b223aa19":"_, axs = plt.subplots(1, 4, figsize=(12, 12))\naxs = axs.flatten()\nfor img,ax in zip(sample_images_1,axs):\n    ax.imshow(cv2.imread(img))\n    ax.set_title(img.split('\/')[-2])\nplt.show()","eb6a9bc9":"multiplier = 10000 # This is used to brighten the diffrential image\n\n_, axs = plt.subplots(1, 4, figsize=(12, 12))\naxs = axs.flatten()\n\nCover = np.array(cv2.imread(sample_images_1[0]))\nfor img,ax in zip(sample_images_1, axs):\n    if 'Cover' in img:\n        ax.imshow(Cover)\n        ax.set_title('Cover')\n        continue\n    image = np.array(cv2.imread(img))\n    new_image = (Cover - image)*multiplier\n    ax.imshow(new_image)\n    title = img.split('\/')[-2] + ' differential'\n    ax.set_title(title)","7ae19e58":"_, axs = plt.subplots(1, 4, figsize=(12, 12))\naxs = axs.flatten()\n\nCover = np.array(cv2.imread(sample_images_2[0]))\nfor img,ax in zip(sample_images_2, axs):\n    if 'Cover' in img:\n        ax.imshow(Cover)\n        ax.set_title('Cover')\n        continue\n    image = np.array(cv2.imread(img))\n    new_image = (Cover - image)*multiplier\n    ax.imshow(new_image)\n    title = img.split('\/')[-2] + ' differential'\n    ax.set_title(title)","f8815af5":"_, axs = plt.subplots(1, 4, figsize=(12, 12))\naxs = axs.flatten()\n\nCover = np.array(cv2.imread(sample_images_3[0]))\nfor img,ax in zip(sample_images_3, axs):\n    if 'Cover' in img:\n        ax.imshow(Cover)\n        ax.set_title('Cover')\n        continue\n    image = np.array(cv2.imread(img))\n    new_image = (Cover - image)*multiplier\n    ax.imshow(new_image)\n    title = img.split('\/')[-2] + ' differential'\n    ax.set_title(title)","e115053a":"from skimage.feature import hog\n\ndef hog_image(img):\n    img=img[:,:,1] \n    fd, hog_image = hog(img, orientations=8, pixels_per_cell=(4, 4),cells_per_block=(2, 2), visualize=True)    \n    return hog_image","b2b31dca":"_, axs = plt.subplots(1, 4, figsize=(12, 12))\naxs = axs.flatten()\nfor img,ax in zip(sample_images_4,axs):\n    ax.imshow(hog_image(np.array(cv2.imread(img))))\n    ax.set_title(img.split('\/')[-2])\nplt.show()","fe52a32d":"_, axs = plt.subplots(1, 4, figsize=(12, 12))\naxs = axs.flatten()\n\nCover = np.array(cv2.imread(sample_images_4[0]))\nfor img,ax in zip(sample_images_4, axs):\n    if 'Cover' in img:\n        ax.imshow(hog_image(Cover))\n        ax.set_title('Cover')\n        continue\n    image = np.array(cv2.imread(img))\n    new_image = (Cover - image)\n    ax.imshow(hog_image(new_image))\n    title = img.split('\/')[-2] + ' differential'\n    ax.set_title(title)","268bcb18":"From the above plots, we can see that these different steganography algorithms are used to change\/hide certain features of the image.\n\nMoreover, these hidden features could contain important information that could be leveraged.","b7d1aa00":"**Histogram of Oriented Gradient** is a feature descriptor that is used to extract features from image data. The HOG descriptor focuses on the structure or the shape of an object. The HOG feature descriptor counts the occurrences of gradient orientation in localized portions of an image.","1da11e2d":"**JUNIWARD JMiPOD** and **UERD** are steganography algorithms that are used to hide information in images"}}