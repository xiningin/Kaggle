{"cell_type":{"aa0c3499":"code","92a06e8f":"code","9b8e0b64":"code","9327b10e":"code","6561d978":"code","adf929c7":"code","64b61c2e":"code","3f9d1ab7":"code","cf2e3dd5":"code","196e2900":"code","203880b1":"code","aac5a54f":"code","8ddc0a96":"code","c4fd30e0":"code","a14304f1":"markdown","a97d2fb6":"markdown","b8954e56":"markdown","c40927a7":"markdown","0850ee1f":"markdown","70731a6d":"markdown"},"source":{"aa0c3499":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport PIL.Image as Image\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\n\n\n\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","92a06e8f":"categories = ['cats', 'dogs']\ntraining_dataset_path = '\/kaggle\/input\/cat-and-dog\/training_set\/training_set'","9b8e0b64":"img = Image.open('\/kaggle\/input\/cat-and-dog\/training_set\/training_set\/dogs\/dog.10.jpg')\nimg","9327b10e":"img = Image.open('\/kaggle\/input\/cat-and-dog\/training_set\/training_set\/cats\/cat.10.jpg')\nimg","6561d978":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)  #Image normalization.\n\ntraining_set = train_datagen.flow_from_directory('..\/input\/cat-and-dog\/training_set\/training_set',\n                                                 target_size = (64, 64),\n                                                 batch_size = 32,\n                                                 class_mode = 'binary')\n\n\n\ntest_set = test_datagen.flow_from_directory('..\/input\/cat-and-dog\/test_set\/test_set',\n                                            target_size = (64, 64),\n                                            batch_size = 32,\n                                            class_mode = 'binary')","adf929c7":"training_set.class_indices","64b61c2e":"# Here training shape is [64,64] and the + [3] is for the RGB channel\nvgg = VGG16(input_shape=[64,64]+ [3], weights='imagenet', include_top=False)","3f9d1ab7":"# We don't want to train the vgg16 model again here. \nfor layer in vgg.layers:\n  layer.trainable = False  ","cf2e3dd5":"# The model has the vgg16 as the pretrained base and on top of it \n#I have two dense layers of 5 units and 1 units. The number of inputs and the number of layers \n#can be altered to improve the accuracy slightly . \n\nmodel = keras.Sequential([\n    vgg,\n    layers.Flatten(),\n    layers.Dense(2, activation='relu'),\n    layers.Dense(1, activation='sigmoid')])","196e2900":"model.summary()","203880b1":"model.compile(\n    optimizer=\"adam\",\n    loss=\"binary_crossentropy\",\n    metrics = [\"accuracy\"]\n)","aac5a54f":"history = model.fit(\n    training_set,\n    validation_data=test_set,\n    epochs=5,\n)","8ddc0a96":"plt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()","c4fd30e0":"plt.plot(history.history['accuracy'], label='train acc')\nplt.plot(history.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()\n","a14304f1":"#### We will be using the VGG 16 architecture as our pretrained base and on top we will add two fully connected layers of 2 and 1 units. \n","a97d2fb6":"#### Thank you for getting this far. A upvote would mean the world to me \ud83d\ude04","b8954e56":"## Preparing and Preprocessing ","c40927a7":"## Model Creation and Training ","0850ee1f":"## Introduction\n\n#### We will do transfer learning to build a classifier that classifies between cats and dogs\ud83d\ude0b. Transfer learning is a technique in which we use a pretrained convolutional neural network ( in this case ) which is called the base and on its top we will add some layers from our end and we will train it with our images from the datasets.\n#### Note :- We do not change the weights, biases and architecture of the pretrained model.( quite obvious )\ud83d\ude36\n\nWhy tranfer learning is used ? \ud83d\ude44\n- Firstly we don't have the resources to train huge neural networks on huge amount of data. \n- Even if we have resources, it would take us probably years to do so\n- Thirdly, Even then we might not be able to get the optimum parameters for the model and the accuracy would be less. \n\nyou can check out this article for more detailed explaination. \n[https:\/\/towardsdatascience.com\/how-transfer-learning-works-a90bc4d93b5e]","70731a6d":"![VGG16%20architecture.png](attachment:VGG16%20architecture.png)\n\n\n\n\nSource : Google "}}