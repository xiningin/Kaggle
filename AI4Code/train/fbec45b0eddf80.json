{"cell_type":{"82596f8d":"code","1c620895":"code","37940484":"code","8cff2031":"code","d200f163":"code","d16f8c14":"code","fad2b1d5":"code","ec71c8c4":"code","bb930d31":"code","57fd2a86":"code","2bd414a3":"code","ad2b8f88":"code","771433f1":"code","2a8c8fdb":"code","02c4d313":"code","19a1a0f7":"code","d9a01853":"code","aa8221c7":"code","4e33e116":"markdown","3c675271":"markdown","6e2471b7":"markdown","7d524520":"markdown","8d3a64d7":"markdown","560449e7":"markdown","76995d85":"markdown","db74c68a":"markdown","dbb4aa96":"markdown","f9845c2c":"markdown","a72a3bdf":"markdown","d1998064":"markdown","6c35b170":"markdown","fdbedc41":"markdown","be401468":"markdown","944935be":"markdown","0f0456a0":"markdown"},"source":{"82596f8d":"import os\nidir = \"..\/input\/\"\nfor x in os.listdir(idir):\n        f = idir + x\n        s = os.stat(f)\n        num_lines = sum(1 for line in open(f))\n        print(x + \":\" + str(round(s.st_size \/ (1024 * 1024)) ) + \" MB : \" + str(num_lines) + \" lines\")\n","1c620895":"rows = 0\nfor line in open(f): \n    print(line)\n    rows += 1\n    if rows > 4:\n        break","37940484":"import numpy as np \nimport pandas as pd \nifile = idir + \"train.csv\"\nnum_rows = 3\ndf = pd.read_csv(ifile, nrows = num_rows, converters={'fullVisitorId': str})\ndf.head()","8cff2031":"df.info()","d200f163":"import json\nj = json.loads(df[\"totals\"][0])\nj","d16f8c14":"from pandas.io.json import json_normalize\njson_normalize(j)","fad2b1d5":"json_cols = ['device', 'geoNetwork', 'totals', 'trafficSource'] # List columns where data is stored in JSON format\n\n# Apply converter to convert JSON format data into JSON object\njson_conv = {col: json.loads for col in (json_cols)}\n\n# Read the CSV with the new converter\ndf = pd.read_csv(idir + \"train.csv\", \n    dtype={'fullVisitorId': str},\n    converters=json_conv, \n    nrows=num_rows)\n\ndf.head()","ec71c8c4":"tdf = json_normalize(df[\"totals\"])\ntdf.head()","bb930d31":"df = df.drop(columns = [\"totals\"])\ndf.head()","57fd2a86":"tdf.columns = [\"totals_\" + col for col in tdf.columns]\ndf = df.merge(tdf, left_index=True, right_index=True)\ndf.head()","2bd414a3":"def ld_dn_df(csv_file, json_cols, rows_to_load = 100 ): \n\n    # Apply converter to convert JSON format data into JSON object\n    json_conv = {col: json.loads for col in (json_cols)}\n\n    # Read the CSV with the new converter\n    df = pd.read_csv(csv_file, \n        dtype={'fullVisitorId': str},\n        converters=json_conv, \n        nrows=rows_to_load, \n        low_memory = False\n        )\n    \n    for jcol in json_cols: \n        tdf = json_normalize(df[jcol])\n        tdf.columns = [jcol + \"_\" + col for col in tdf.columns]\n        df = df.merge(tdf, left_index=True, right_index=True)\n        \n    df = df.drop(columns = json_cols)\n    return df","ad2b8f88":"%%time\nrows_to_load = 1000000\njson_cols = [\"totals\", \"device\", \"geoNetwork\", \"trafficSource\"]\ntrain_df =  ld_dn_df(\"..\/input\/train.csv\", json_cols, rows_to_load)","771433f1":"%%time\ntest_df =  ld_dn_df(\"..\/input\/test.csv\", json_cols, rows_to_load)","2a8c8fdb":"def replace_def_vals(df):\n    df.replace({'(not set)': np.nan,\n               'not available in demo dataset': np.nan,\n               '(not provided)': np.nan,\n               'unknown.unknown': np.nan,\n               '(none)':np.nan,\n               '\/':np.nan,\n               'Not Socially Engaged':np.nan},\n              inplace=True)","02c4d313":"%%time\nreplace_def_vals(train_df)","19a1a0f7":"%%time\nreplace_def_vals(test_df)","d9a01853":"f = '.\/train_flat.csv'\ntrain_df.to_csv(f, index = False)\ns = os.stat(f)\nnum_lines = sum(1 for line in open(f))\nprint(x + \":\" + str(round(s.st_size \/ (1024 * 1024)) ) + \" MB : \" + str(num_lines) + \" lines\")","aa8221c7":"f = '.\/test_flat.csv'\ntest_df.to_csv(f, index = False)\ns = os.stat(f)\nnum_lines = sum(1 for line in open(f))\nprint(x + \":\" + str(round(s.st_size \/ (1024 * 1024)) ) + \" MB : \" + str(num_lines) + \" lines\")\n","4e33e116":"## Save+Data\nThe below code saves the files and checks the number of records and the size.","3c675271":"## Load+data+as+JSON\nWith the above snippets, lets load the CSV file with JSON columns in JSON format\n\n### 1. Read the dataframe with JSON converters\n","6e2471b7":"### 2. Parse json into data frame  \nThe below code will help convert json object into a dataframe.","7d524520":"## Reduce+Data+Size\nWe can take the below steps: <br \/>\n1) Reduce the long default values to simple strings<br \/>\n2) Download 64 bit numbers to 32 bit where possible<br \/>\n3) Create categorical variables from strings<br \/>\nThe below code addresses 1st step","8d3a64d7":"## Working+on+JSON+data\n### 1. Convert strings into JSON data  \nIn the above data frame, columns with JSON data are treated as strings.  We need to convert them to JSON.<br \/>\nBelow code converts JSON String to JSON object","560449e7":"In this notebook, we will explore","76995d85":"### 2. Lets review  first 5 lines of the file","db74c68a":"## Explore+Data\n### 1. Lets look at the size of each file","dbb4aa96":"<b>References<\/b><br \/><br \/>\n\nhttps:\/\/www.kaggle.com\/julian3833\/1-quick-start-read-csv-and-flatten-json-fields<br \/>\nhttp:\/\/pandas.pydata.org\/pandas-docs\/stable\/merging.html<br \/>\nhttps:\/\/stackoverflow.com\/questions\/13293810\/import-pandas-dataframe-column-as-string-not-int <br \/>\nhttps:\/\/docs.python.org\/2\/library\/json.html <br \/>\nhttps:\/\/stackoverflow.com\/questions\/845058\/how-to-get-line-count-cheaply-in-python <br \/>\nhttps:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.io.json.json_normalize.html <br \/>\n","f9845c2c":"### 4. Adding the columns into original df  \nWe now want to add these  columns into the original dataframe.  Lets create a column name by appending the parent column name\n","a72a3bdf":"We can see the data frame is created with all possible columns.  NaN value in  columns where this column doesnt exist in json ","d1998064":"## Read+CSV+Into+Dataframe","6c35b170":"### 3. Drop original column\nWe dont need the original json column and dropping it will reduce RAM","fdbedc41":"## Putting+Together","be401468":"1) [Explore the raw data](#Explore+Data)  \n2) [Reading the data from CSV into Pandas](#Read+CSV+Into+Dataframe)  \n3) [How to interpret JSON format and convert it into data frame](#Working+on+JSON+data)  \n4) [Reading JSON into data frames](#Load+data+as+JSON)  \n5) [Putting learning into action by creating function that reads CSV data and flattens JSON](#Putting+Together)  \n6) [Reduce the size of the data without losing data significance](#Reduce+Data+Size)  \n7) [Save data](#Save+Data)","944935be":"### 2. Convert the json data into columns  \nThe below code takes the json code and converts it into columns","0f0456a0":"### We reduced the size of the data to ~15% of original size!!!  \nTrain CSV has gone down from **1434 MB** to **213 MB**"}}