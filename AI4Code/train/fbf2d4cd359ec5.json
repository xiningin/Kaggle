{"cell_type":{"957c0e43":"code","872362ef":"code","5665c8e2":"code","f9d97ffa":"code","f9f094f3":"code","18255970":"code","e4b739f5":"code","0a54b602":"code","aba925d6":"code","733f7510":"code","b92bc87b":"code","ec7bce7a":"code","7722ffa3":"code","2f49e1c0":"code","c81d4cb4":"code","909cb920":"code","f405f27e":"code","c9d362b8":"code","1f13f1b6":"code","f6f38d67":"code","a770d19f":"code","2863025a":"code","2804e9b6":"code","23620a81":"code","e8bf4b25":"code","6748c1ad":"code","08cbfeb7":"code","54f7f8ae":"code","ab85c59e":"code","5cc924d9":"code","17a82614":"code","3d10087e":"code","9140aef7":"code","f0d058f5":"code","7110a0d9":"code","a0be657a":"code","3a258857":"code","8bd0b7f9":"code","89a85d9c":"code","65bf4e65":"code","ba605971":"markdown","75f1a46b":"markdown","8521b7bb":"markdown","653d16ce":"markdown","db00a712":"markdown","8424c8ab":"markdown","c79b6cc3":"markdown","7a5bc12c":"markdown","f8162587":"markdown","b9e3116b":"markdown","49803a31":"markdown","e7de763a":"markdown","ef5de1a6":"markdown","68fd915f":"markdown","f5d9d5a4":"markdown","c782e982":"markdown","9711358f":"markdown","03564a59":"markdown","7a90c801":"markdown","7006c6b9":"markdown","02d480e0":"markdown","b1867462":"markdown","018f75df":"markdown","9c2f4468":"markdown","286380dc":"markdown","ec943a03":"markdown","2b4d9067":"markdown"},"source":{"957c0e43":"# FOR NUMERICAL ANALYTICS\nimport numpy as np\n# TO STORE AND PROCESS DATA IN DATAFRAME\nimport pandas as pd\npd.options.mode.chained_assignment = None\nimport os\n# BASIC VISUALIZATION PACKAGE\nimport matplotlib.pyplot as plt\n# ADVANCED PLOTTING\nimport seaborn as seabornInstance\n# TRAIN TEST SPLIT\nfrom sklearn.model_selection import train_test_split\n# INTERACTIVE VISUALIZATION\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nimport statsmodels.formula.api as stats\nfrom statsmodels.formula.api import ols\nfrom sklearn import datasets\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import linear_model","872362ef":"#2021 data\ndf_21 = pd.read_csv('..\/input\/world-happiness-report-2021\/world-happiness-report-2021.csv')\nusecols = ['Country name','Ladder score','Logged GDP per capita','Social support',\n                'Healthy life expectancy','Freedom to make life choices','Generosity','Perceptions of corruption']\ndf_21.drop(['Regional indicator','Standard error of ladder score', 'upperwhisker', \n                'lowerwhisker', 'Ladder score in Dystopia', 'Explained by: Log GDP per capita', \n                    'Explained by: Social support', 'Explained by: Healthy life expectancy', \n                        'Explained by: Freedom to make life choices', 'Explained by: Generosity', \n                            'Explained by: Perceptions of corruption', 'Dystopia + residual'],axis=1,inplace=True) \ndf_21.columns = ['Country name','Ladder score','Logged GDP per capita','Social support',\n                'Healthy life expectancy','Freedom to make life choices','Generosity','Perceptions of corruption']\ndf_21['Year'] = 2021 #add year column\ndf_21.head()","5665c8e2":"df = pd.read_csv('..\/input\/world-happiness-report-2021\/world-happiness-report.csv')\n\n#change columnn names in df for pd.append to work properly\ndf.rename(columns = {'year' : 'Year', 'Log GDP per capita' : 'Logged GDP per capita', \n                         'Life Ladder' : 'Ladder score', 'Healthy life expectancy at birth' : 'Healthy life expectancy'}, inplace = True)\ndf.drop(['Positive affect', 'Negative affect'], axis = 1, inplace = True)\n\n#filter 2018, 2019, and 2020 data\nis_2018 = df['Year'] == 2018\nis_2019 = df['Year'] == 2019\nis_2020 = df['Year'] == 2020\ndf_18 = df[is_2018]\ndf_19 = df[is_2019]\ndf_20 = df[is_2020]\ndf_18['Rank'] = df_18['Ladder score'].rank(ascending = 0)\ndf_19['Rank'] = df_19['Ladder score'].rank(ascending = 0)\ndf_20['Rank'] = df_20['Ladder score'].rank(ascending = 0)\ndf_21['Rank'] = df_21['Ladder score'].rank(ascending = 0)","f9d97ffa":"#appending data into two datasets\npreCov = df_18.append([df_19])\nCov = df_20.append([df_21])\ndf = preCov.append([Cov])","f9f094f3":"#Data frame with essential metrics\nevaluation = pd.DataFrame({'Model':[],\n                          'Details':[],\n                          'Root Mean Squared Error (RMSE)': [],\n                          'R-squared (training)': [],\n                          'Adjusted R-squared (training)': [],\n                          'R-squared (test)':[],\n                          'Adjusted R-squared(test)':[],\n                           '5-Fold Cross Validation':[]\n                        })","18255970":"#DATA CLEANSING\ndf.isnull().any()\n\n#fill NaN with their means\ndf.fillna(df.mean(), inplace = True)\ndf.describe()","e4b739f5":"seabornInstance.distplot(df['Ladder score'])\nplt.title('Distribution of Ladder score', fontsize=12)","0a54b602":"seabornInstance.distplot(preCov['Ladder score'])\nplt.title('Distribution of Ladder score before COVID', fontsize=12)","aba925d6":"seabornInstance.distplot(Cov['Ladder score'])\nplt.title('Distribution of Ladder score in COVID', fontsize=12)","733f7510":"px.scatter(df, x=\"Logged GDP per capita\", y=\"Ladder score\", animation_frame=\"Year\",\n           animation_group=\"Country name\",\n           size=\"Rank\", color=\"Country name\", hover_name=\"Country name\",\n           trendline= \"ols\")\ntrain_data, test_data = train_test_split(df, train_size = 0.8, random_state = 3)\nlr = LinearRegression()\nX_train = np.array(train_data['Logged GDP per capita'],\n                   dtype = pd.Series).reshape(-1,1)\ny_train = np.array(train_data['Ladder score'], dtype = pd.Series)\nlr.fit(X_train, y_train)\nX_test = np.array(test_data['Logged GDP per capita'], \n                    dtype = pd.Series).reshape(-1,1)\ny_test = np.array(test_data['Ladder score'], dtype = pd.Series)\npred = lr.predict(X_test)\n#ROOT MEAN SQUARED ERROR\nrmsesm = float(format(np.sqrt(mean_squared_error(y_test,pred)),'.3f'))\n#R-SQUARED (TRAINING)\nrtrsm = float(format(lr.score(X_train, y_train),'.3f'))\n#R-SQUARED (TEST)\nrtesm = float(format(lr.score(X_test, y_test),'.3f'))\ncv = float(format(cross_val_score(lr,df[['Logged GDP per capita']],df['Ladder score'],cv=5).mean(),'.3f'))\nprint (\"Average Score for Test Data: {:.3f}\".format(y_test.mean()))\nprint('Intercept: {}'.format(lr.intercept_))\nprint('Coefficient: {}'.format(lr.coef_))\nr = evaluation.shape[0]\nevaluation.loc[r] = ['Simple Linear Regression','Logged GDP per capita',rmsesm,rtrsm,'-',rtesm,'-',cv]\nevaluation","b92bc87b":"seabornInstance.set_style(style='whitegrid')\nplt.figure(figsize=(12,6))\nplt.scatter(X_test,y_test,color='blue',label=\"Data\", s = 12)\nplt.plot(X_test,lr.predict(X_test),color=\"red\",label=\"Predicted Regression Line\")\nplt.xlabel(\"Logged GDP per Capita\", fontsize=15)\nplt.ylabel(\"Ladder score\", fontsize=15)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)\nplt.legend()\nplt.gca().spines['right'].set_visible(False)\nplt.gca().spines['top'].set_visible(False)","ec7bce7a":"seabornInstance.distplot(df['Logged GDP per capita'])\nplt.title('Distribution of GDP for all 4 years', fontsize=12)","7722ffa3":"'''Happiness score vs GDP'''\npx.scatter(df, x=\"Logged GDP per capita\", y=\"Ladder score\", \n           animation_frame=\"Year\",\n           animation_group=\"Country name\",\n           size=\"Rank\", color=\"Country name\", \n           hover_name=\"Country name\",\n           trendline= \"ols\")","2f49e1c0":"px.scatter(df, x=\"Social support\", y=\"Ladder score\", animation_frame=\"Year\",\n           animation_group=\"Country name\",\n           size=\"Rank\", color=\"Country name\", hover_name=\"Country name\",\n           trendline= \"ols\")\ntrain_data, test_data = train_test_split(df, train_size = 0.8, random_state = 3)\nlr = LinearRegression()\nX_train = np.array(train_data['Social support'],\n                   dtype = pd.Series).reshape(-1,1)\ny_train = np.array(train_data['Ladder score'], dtype = pd.Series)\nlr.fit(X_train, y_train)\nX_test = np.array(test_data['Social support'], \n                    dtype = pd.Series).reshape(-1,1)\ny_test = np.array(test_data['Ladder score'], dtype = pd.Series)\npred = lr.predict(X_test)\n#ROOT MEAN SQUARED ERROR\nrmsesm = float(format(np.sqrt(mean_squared_error(y_test,pred)),'.3f'))\n#R-SQUARED (TRAINING)\nrtrsm = float(format(lr.score(X_train, y_train),'.3f'))\n#R-SQUARED (TEST)\nrtesm = float(format(lr.score(X_test, y_test),'.3f'))\ncv = float(format(cross_val_score(lr,df[['Social support']],df['Ladder score'],cv=5).mean(),'.3f'))\nprint (\"Average Score for Test Data: {:.3f}\".format(y_test.mean()))\nprint('Intercept: {}'.format(lr.intercept_))\nprint('Coefficient: {}'.format(lr.coef_))\nr = evaluation.shape[0]\nevaluation.loc[r] = ['Simple Linear Regression','Social support',rmsesm,rtrsm,'-',rtesm,'-',cv]\nevaluation","c81d4cb4":"seabornInstance.set_style(style='whitegrid')\nplt.figure(figsize=(12,6))\nplt.scatter(X_test,y_test,color='blue',label=\"Data\", s = 12)\nplt.plot(X_test,lr.predict(X_test),color=\"red\",label=\"Predicted Regression Line\")\nplt.xlabel(\"Social support\", fontsize=15)\nplt.ylabel(\"Ladder score\", fontsize=15)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)\nplt.legend()\nplt.gca().spines['right'].set_visible(False)\nplt.gca().spines['top'].set_visible(False)","909cb920":"seabornInstance.distplot(df['Social support'])\nplt.title('Distribution of Social support for all 4 years', fontsize=12)","f405f27e":"'''Happiness score vs Social support'''\npx.scatter(df, x=\"Social support\", y=\"Ladder score\", \n           animation_frame=\"Year\",\n           animation_group=\"Country name\",\n           size=\"Rank\", color=\"Country name\", \n           hover_name=\"Country name\",\n           trendline= \"ols\")","c9d362b8":"px.scatter(df, x=\"Healthy life expectancy\", y=\"Ladder score\", animation_frame=\"Year\",\n           animation_group=\"Country name\",\n           size=\"Rank\", color=\"Country name\", hover_name=\"Country name\",\n           trendline= \"ols\")\ntrain_data, test_data = train_test_split(df, train_size = 0.8, random_state = 3)\nlr = LinearRegression()\nX_train = np.array(train_data['Healthy life expectancy'],\n                   dtype = pd.Series).reshape(-1,1)\ny_train = np.array(train_data['Ladder score'], dtype = pd.Series)\nlr.fit(X_train, y_train)\nX_test = np.array(test_data['Healthy life expectancy'], \n                    dtype = pd.Series).reshape(-1,1)\ny_test = np.array(test_data['Ladder score'], dtype = pd.Series)\npred = lr.predict(X_test)\n#ROOT MEAN SQUARED ERROR\nrmsesm = float(format(np.sqrt(mean_squared_error(y_test,pred)),'.3f'))\n#R-SQUARED (TRAINING)\nrtrsm = float(format(lr.score(X_train, y_train),'.3f'))\n#R-SQUARED (TEST)\nrtesm = float(format(lr.score(X_test, y_test),'.3f'))\ncv = float(format(cross_val_score(lr,df[['Healthy life expectancy']],df['Ladder score'],cv=5).mean(),'.3f'))\nprint (\"Average Score for Test Data: {:.3f}\".format(y_test.mean()))\nprint('Intercept: {}'.format(lr.intercept_))\nprint('Coefficient: {}'.format(lr.coef_))\nr = evaluation.shape[0]\nevaluation.loc[r] = ['Simple Linear Regression','Healthy life expectancy',rmsesm,rtrsm,'-',rtesm,'-',cv]\nevaluation","1f13f1b6":"seabornInstance.set_style(style='whitegrid')\nplt.figure(figsize=(12,6))\nplt.scatter(X_test,y_test,color='blue',label=\"Data\", s = 12)\nplt.plot(X_test,lr.predict(X_test),color=\"red\",label=\"Predicted Regression Line\")\nplt.xlabel(\"Healthy life expectancy\", fontsize=15)\nplt.ylabel(\"Ladder score\", fontsize=15)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)\nplt.legend()\nplt.gca().spines['right'].set_visible(False)\nplt.gca().spines['top'].set_visible(False)","f6f38d67":"seabornInstance.distplot(df['Healthy life expectancy'])\nplt.title('Distribution of Healthy life expectancy for all 4 years', fontsize=12)","a770d19f":"'''Happiness score vs Healthy life expectancy'''\npx.scatter(df, x=\"Healthy life expectancy\", y=\"Ladder score\", \n           animation_frame=\"Year\",\n           animation_group=\"Country name\",\n           size=\"Rank\", color=\"Country name\", \n           hover_name=\"Country name\",\n           trendline= \"ols\")","2863025a":"px.scatter(df, x=\"Freedom to make life choices\", y=\"Ladder score\", animation_frame=\"Year\",\n           animation_group=\"Country name\",\n           size=\"Rank\", color=\"Country name\", hover_name=\"Country name\",\n           trendline= \"ols\")\ntrain_data, test_data = train_test_split(df, train_size = 0.8, random_state = 3)\nlr = LinearRegression()\nX_train = np.array(train_data['Freedom to make life choices'],\n                   dtype = pd.Series).reshape(-1,1)\ny_train = np.array(train_data['Ladder score'], dtype = pd.Series)\nlr.fit(X_train, y_train)\nX_test = np.array(test_data['Freedom to make life choices'], \n                    dtype = pd.Series).reshape(-1,1)\ny_test = np.array(test_data['Ladder score'], dtype = pd.Series)\npred = lr.predict(X_test)\n#ROOT MEAN SQUARED ERROR\nrmsesm = float(format(np.sqrt(mean_squared_error(y_test,pred)),'.3f'))\n#R-SQUARED (TRAINING)\nrtrsm = float(format(lr.score(X_train, y_train),'.3f'))\n#R-SQUARED (TEST)\nrtesm = float(format(lr.score(X_test, y_test),'.3f'))\ncv = float(format(cross_val_score(lr,df[['Freedom to make life choices']],df['Ladder score'],cv=5).mean(),'.3f'))\nprint (\"Average Score for Test Data: {:.3f}\".format(y_test.mean()))\nprint('Intercept: {}'.format(lr.intercept_))\nprint('Coefficient: {}'.format(lr.coef_))\nr = evaluation.shape[0]\nevaluation.loc[r] = ['Simple Linear Regression','Freedom to make life choices',rmsesm,rtrsm,'-',rtesm,'-',cv]\nevaluation","2804e9b6":"seabornInstance.set_style(style='whitegrid')\nplt.figure(figsize=(12,6))\nplt.scatter(X_test,y_test,color='blue',label=\"Data\", s = 12)\nplt.plot(X_test,lr.predict(X_test),color=\"red\",label=\"Predicted Regression Line\")\nplt.xlabel(\"Freedom to make life choices\", fontsize=15)\nplt.ylabel(\"Ladder score\", fontsize=15)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)\nplt.legend()\nplt.gca().spines['right'].set_visible(False)\nplt.gca().spines['top'].set_visible(False)","23620a81":"px.scatter(df, x=\"Generosity\", y=\"Ladder score\", animation_frame=\"Year\",\n           animation_group=\"Country name\",\n           size=\"Rank\", color=\"Country name\", hover_name=\"Country name\",\n           trendline= \"ols\")\ntrain_data, test_data = train_test_split(df, train_size = 0.8, random_state = 3)\nlr = LinearRegression()\nX_train = np.array(train_data['Generosity'],\n                   dtype = pd.Series).reshape(-1,1)\ny_train = np.array(train_data['Ladder score'], dtype = pd.Series)\nlr.fit(X_train, y_train)\nX_test = np.array(test_data['Generosity'], \n                    dtype = pd.Series).reshape(-1,1)\ny_test = np.array(test_data['Ladder score'], dtype = pd.Series)\npred = lr.predict(X_test)\n#ROOT MEAN SQUARED ERROR\nrmsesm = float(format(np.sqrt(mean_squared_error(y_test,pred)),'.3f'))\n#R-SQUARED (TRAINING)\nrtrsm = float(format(lr.score(X_train, y_train),'.3f'))\n#R-SQUARED (TEST)\nrtesm = float(format(lr.score(X_test, y_test),'.3f'))\ncv = float(format(cross_val_score(lr,df[['Generosity']],df['Ladder score'],cv=5).mean(),'.3f'))\nprint (\"Average Score for Test Data: {:.3f}\".format(y_test.mean()))\nprint('Intercept: {}'.format(lr.intercept_))\nprint('Coefficient: {}'.format(lr.coef_))\nr = evaluation.shape[0]\nevaluation.loc[r] = ['Simple Linear Regression','Generosity',rmsesm,rtrsm,'-',rtesm,'-',cv]\nevaluation","e8bf4b25":"seabornInstance.set_style(style='whitegrid')\nplt.figure(figsize=(12,6))\nplt.scatter(X_test,y_test,color='blue',label=\"Data\", s = 12)\nplt.plot(X_test,lr.predict(X_test),color=\"red\",label=\"Predicted Regression Line\")\nplt.xlabel(\"Generosity\", fontsize=15)\nplt.ylabel(\"Ladder score\", fontsize=15)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)\nplt.legend()\nplt.gca().spines['right'].set_visible(False)\nplt.gca().spines['top'].set_visible(False)","6748c1ad":"px.scatter(df, x=\"Perceptions of corruption\", y=\"Ladder score\", animation_frame=\"Year\",\n           animation_group=\"Country name\",\n           size=\"Rank\", color=\"Country name\", hover_name=\"Country name\",\n           trendline= \"ols\")\ntrain_data, test_data = train_test_split(df, train_size = 0.8, random_state = 3)\nlr = LinearRegression()\nX_train = np.array(train_data['Perceptions of corruption'],\n                   dtype = pd.Series).reshape(-1,1)\ny_train = np.array(train_data['Ladder score'], dtype = pd.Series)\nlr.fit(X_train, y_train)\nX_test = np.array(test_data['Perceptions of corruption'], \n                    dtype = pd.Series).reshape(-1,1)\ny_test = np.array(test_data['Ladder score'], dtype = pd.Series)\npred = lr.predict(X_test)\n#ROOT MEAN SQUARED ERROR\nrmsesm = float(format(np.sqrt(mean_squared_error(y_test,pred)),'.3f'))\n#R-SQUARED (TRAINING)\nrtrsm = float(format(lr.score(X_train, y_train),'.3f'))\n#R-SQUARED (TEST)\nrtesm = float(format(lr.score(X_test, y_test),'.3f'))\ncv = float(format(cross_val_score(lr,df[['Perceptions of corruption']],df['Ladder score'],cv=5).mean(),'.3f'))\nprint (\"Average Score for Test Data: {:.3f}\".format(y_test.mean()))\nprint('Intercept: {}'.format(lr.intercept_))\nprint('Coefficient: {}'.format(lr.coef_))\nr = evaluation.shape[0]\nevaluation.loc[r] = ['Simple Linear Regression','Perceptions of corruption',rmsesm,rtrsm,'-',rtesm,'-',cv]\nevaluation","08cbfeb7":"seabornInstance.set_style(style='whitegrid')\nplt.figure(figsize=(12,6))\nplt.scatter(X_test,y_test,color='blue',label=\"Data\", s = 12)\nplt.plot(X_test,lr.predict(X_test),color=\"red\",label=\"Predicted Regression Line\")\nplt.xlabel(\"Perceptions of corruption\", fontsize=15)\nplt.ylabel(\"Ladder score\", fontsize=15)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)\nplt.legend()\nplt.gca().spines['right'].set_visible(False)\nplt.gca().spines['top'].set_visible(False)","54f7f8ae":"seabornInstance.distplot(df['Perceptions of corruption'])\nplt.title('Distribution of perceptions of corruption', fontsize=12)","ab85c59e":"'''Happiness score vs Corruption'''\npx.scatter(df, x=\"Perceptions of corruption\", y=\"Ladder score\", \n           animation_frame=\"Year\",\n           animation_group=\"Country name\",\n           size=\"Rank\", color=\"Country name\", \n           hover_name=\"Country name\",\n           trendline= \"ols\")","5cc924d9":"# DISTRIBUTION OF ALL NUMERIC DATA\nplt.rcParams['figure.figsize'] = (15, 15)\ndf1 = df[['Logged GDP per capita','Social support', 'Healthy life expectancy', 'Freedom to make life choices',\n              'Generosity','Perceptions of corruption']]\nh = df1.hist(bins = 25, figsize = (16,16),\n             xlabelsize = '10', ylabelsize = '10')\nseabornInstance.despine(left = True, bottom = True)\n[x.title.set_size(12) for x in h.ravel()];\n[x.yaxis.tick_left() for x in h.ravel()]","17a82614":"happiness_rank = dict(type = 'choropleth', \n           locations = df_21['Country name'],\n           locationmode = 'country names',\n           z = df_21['Rank'], \n           text = df_21['Country name'],\n           colorscale = 'bluered',\n           autocolorscale=False,\n           reversescale=True,\n           marker_line_color='darkgray',\n           marker_line_width=0.5)\nlayout = dict(title = 'Happiness Rank Across the World', \n             geo = dict(showframe = False, \n                       projection = {'type': 'equirectangular'}))\nworld_map_1 = go.Figure(data = [happiness_rank], layout=layout)\niplot(world_map_1)","3d10087e":"fig, axes = plt.subplots(nrows=4, ncols=2,constrained_layout=True,figsize=(10,10))\nseabornInstance.barplot(x='Logged GDP per capita',y='Country name',\n                        data=df_21.nlargest(10,'Logged GDP per capita'),\n                        ax=axes[0,0],palette=\"Blues_r\")\nseabornInstance.barplot(x='Healthy life expectancy' ,y='Country name',\n                        data=df_21.nlargest(10,'Healthy life expectancy'),\n                        ax=axes[0,1],palette='Blues_r')\nseabornInstance.barplot(x='Social support' ,y='Country name',\n                        data=df_21.nlargest(10,'Social support'),\n                        ax=axes[1,0],palette='Blues_r')\nseabornInstance.barplot(x='Generosity' ,y='Country name',\n                        data=df_21.nlargest(10,'Generosity'),\n                        ax=axes[1,1],palette='Blues_r')\nseabornInstance.barplot(x='Freedom to make life choices' ,y='Country name',\n                        data=df_21.nlargest(10,'Freedom to make life choices'),\n                        ax=axes[2,0],palette='Blues_r')\nseabornInstance.barplot(x='Perceptions of corruption' ,y='Country name',\n                        data=df_21.nlargest(10,'Perceptions of corruption'),\n                        ax=axes[2,1],palette='Blues_r')\nseabornInstance.barplot(x='Ladder score' ,y='Country name',\n                        data=df_21.nlargest(10,'Ladder score'),\n                        ax=axes[3,0],palette='Blues_r')","9140aef7":"mask = np.zeros_like(df[usecols].corr(), dtype=np.bool) \nmask[np.triu_indices_from(mask)] = True\nf, ax = plt.subplots(figsize=(16, 12))\nplt.title('Pearson Correlation Matrix',fontsize=25)\nseabornInstance.heatmap(df[usecols].corr(),\n                        linewidths=0.25,vmax=0.7,square=True,cmap=\"Blues\", \n            linecolor='w',annot=True,annot_kws={\"size\":8},mask=mask,cbar_kws={\"shrink\": .9});","f0d058f5":"# XAC DINH 1 HAM DE TINH GIA TRI \"ADJUSTED R-SQUARED\" \ndef adjustedR2(r2, n, k):     \n    return r2-((k-1)\/(n-k))*(1-r2) # Trong \u0111\u00f3 k l\u00e0 s\u1ed1 parameters v\u00e0 n l\u00e0 s\u1ed1 observations.","7110a0d9":"# MULTIPLE LINEAR REGRESSION 1\ntrain_data_dm,test_data_dm = train_test_split(df,train_size = 0.8,random_state=3)\nindependent_var = ['Logged GDP per capita','Healthy life expectancy',\n                       'Freedom to make life choices','Social support','Generosity',\n                            'Perceptions of corruption']\ncomplex_model_1 = LinearRegression()\ncomplex_model_1.fit(train_data_dm[independent_var],train_data_dm['Ladder score'])\nprint('Intercept: {}'.format(complex_model_1.intercept_))\nprint('Coefficients: {}'.format(complex_model_1.coef_))\nprint('Happiness score = ',np.round(complex_model_1.intercept_,4),\n      '+',np.round(complex_model_1.coef_[0],4),'\u2217 Social support',\n      '+',np.round(complex_model_1.coef_[1],4),'* Logged GDP per capita', \n      '+',np.round(complex_model_1.coef_[2],4),'* Healthy life expectancy',\n      '+',np.round(complex_model_1.coef_[3],4),'* Freedom to make life choices',\n       '+',np.round(complex_model_1.coef_[4],4),'* Generosity',\n      '+',np.round(complex_model_1.coef_[5],4),'* Perceptions of corruption')\npred = complex_model_1.predict(test_data_dm[independent_var])\nrmsecm = float(format(np.sqrt(mean_squared_error(\n                       test_data_dm['Ladder score'],pred)),'.3f'))\nrtrcm = float(format(complex_model_1.score(\n                        train_data_dm[independent_var],\n                        train_data_dm['Ladder score']),'.3f'))\nartrcm = float(format(adjustedR2(complex_model_1.score(\n                           train_data_dm[independent_var],\n                            train_data_dm['Ladder score']),\n                            train_data_dm.shape[0],\n                            len(independent_var)),'.3f'))\nrtecm = float(format(complex_model_1.score(\n                        test_data_dm[independent_var],\n                        test_data_dm['Ladder score']),'.3f'))\nartecm = float(format(adjustedR2(complex_model_1.score(\n                       test_data_dm[independent_var],test_data['Ladder score']),\n                        test_data_dm.shape[0],\n                        len(independent_var)),'.3f'))\ncv = float(format(cross_val_score(complex_model_1,\n                    df[independent_var],\n                    df['Ladder score'],cv=5).mean(),'.3f'))\nr = evaluation.shape[0]\nevaluation.loc[r] = ['Multiple Linear Regression-1','All features',rmsecm,rtrcm,artrcm,rtecm,artecm,cv]\nevaluation.sort_values(by = '5-Fold Cross Validation', ascending=False)","a0be657a":"# MULTIPLE LINEAR REGRESSION 2\ntrain_data_dm,test_data_dm = train_test_split(df,train_size = 0.8,random_state=3)\nindependent_var = ['Logged GDP per capita','Healthy life expectancy','Social support']\ncomplex_model_2 = LinearRegression()\ncomplex_model_2.fit(train_data_dm[independent_var],train_data_dm['Ladder score'])\nprint('Intercept: {}'.format(complex_model_2.intercept_))\nprint('Coefficients: {}'.format(complex_model_2.coef_))\nprint('Happiness score = ',np.round(complex_model_2.intercept_,4),\n      '+',np.round(complex_model_2.coef_[0],4),'\u2217 Social support',\n      '+',np.round(complex_model_2.coef_[1],4),'* Logged GDP per capita', \n      '+',np.round(complex_model_2.coef_[2],4),'* Healthy life expectancy')\npred = complex_model_2.predict(test_data_dm[independent_var])\nrmsecm = float(format(np.sqrt(mean_squared_error(\n                       test_data_dm['Ladder score'],pred)),'.3f'))\nrtrcm = float(format(complex_model_2.score(\n                        train_data_dm[independent_var],\n                        train_data_dm['Ladder score']),'.3f'))\nartrcm = float(format(adjustedR2(complex_model_2.score(\n                            train_data_dm[independent_var],\n                            train_data_dm['Ladder score']),\n                            train_data_dm.shape[0],\n                            len(independent_var)),'.3f'))\nrtecm = float(format(complex_model_2.score(\n                        test_data_dm[independent_var],\n                        test_data_dm['Ladder score']),'.3f'))\nartecm = float(format(adjustedR2(complex_model_2.score(\n                        test_data_dm[independent_var],test_data['Ladder score']),\n                        test_data_dm.shape[0],\n                        len(independent_var)),'.3f'))\ncv = float(format(cross_val_score(complex_model_2,\n                    df[independent_var],\n                    df['Ladder score'],cv=5).mean(),'.3f'))\nr = evaluation.shape[0]\nevaluation.loc[r] = ['Multiple Linear Regression-2','GDP, Support, Health',rmsecm,rtrcm,artrcm,rtecm,artecm,cv]\nevaluation.sort_values(by = '5-Fold Cross Validation', ascending=False)","3a258857":"# RANDOM FOREST\ntrain_data_dm,test_data_dm = train_test_split(df,train_size = 0.8,random_state=3)\nindependent_var = ['Logged GDP per capita','Healthy life expectancy',\n                       'Freedom to make life choices','Social support','Generosity',\n                            'Perceptions of corruption']\ncomplex_model_3 = RandomForestRegressor(n_estimators=200, max_depth=5, min_samples_leaf=20, min_samples_split=40)\ncomplex_model_3.fit(train_data_dm[independent_var],train_data_dm['Ladder score'])\npred = complex_model_3.predict(test_data_dm[independent_var])\nrmsecm = float(format(np.sqrt(mean_squared_error(\n                       test_data_dm['Ladder score'],pred)),'.3f'))\nrtrcm = float(format(complex_model_3.score(\n                        train_data_dm[independent_var],\n                        train_data_dm['Ladder score']),'.3f'))\nartrcm = float(format(adjustedR2(complex_model_3.score(\n                            train_data_dm[independent_var],\n                            train_data_dm['Ladder score']),\n                            train_data_dm.shape[0],\n                            len(independent_var)),'.3f'))\nrtecm = float(format(complex_model_3.score(\n                        test_data_dm[independent_var],\n                        test_data_dm['Ladder score']),'.3f'))\nartecm = float(format(adjustedR2(complex_model_3.score(\n                        test_data_dm[independent_var],test_data['Ladder score']),\n                        test_data_dm.shape[0],\n                        len(independent_var)),'.3f'))\ncv = float(format(cross_val_score(complex_model_3,\n                    df[independent_var],\n                    df['Ladder score'],cv=5).mean(),'.3f'))\nr = evaluation.shape[0]\nevaluation.loc[r] = ['Random Forest','All features',rmsecm,rtrcm,artrcm,rtecm,artecm,cv]\nevaluation.sort_values(by = '5-Fold Cross Validation', ascending=False)\n# n_estimators - Number of trees to build\n# max_depth - maximum depth to which tree can grow, if we increase it very much then, model can overfit\n# min_samples_leaf - minimum number of samples a leaf can have\n# min_samples_split - minimum number of samples a node should have to further split","8bd0b7f9":"col_to_consider=['Logged GDP per capita', 'Social support',\n       'Healthy life expectancy',\n       'Freedom to make life choices',\n       'Generosity', 'Perceptions of corruption']\n# Getting the feature importance\nfeature_importances_ = complex_model_3.feature_importances_\nfeature_importances = pd.DataFrame({'Feature_name':col_to_consider, 'Feature_importance':feature_importances_})\n\nfig, ax=plt.subplots(1, figsize=(15,8))\nseabornInstance.barplot(x='Feature_name', y='Feature_importance', data = feature_importances, ax=ax)\n\n# For making the graph look good\nplt.xticks(fontsize=12, rotation=30); # Rotating the names by 30 degrees as the names were mixing with each other \nplt.yticks(fontsize=14);\n\nplt.xlabel('Feature name',fontsize=18)\nplt.ylabel('Feature importance',fontsize=18)","89a85d9c":"train_data_dm,test_data_dm = train_test_split(df,train_size = 0.8,random_state=3)\nindependent_var = ['Logged GDP per capita','Healthy life expectancy',\n                       'Freedom to make life choices','Social support','Generosity',\n                            'Perceptions of corruption']\nX = train_data_dm[independent_var]\nX = PolynomialFeatures(degree=2).fit_transform(X)\nX_test = PolynomialFeatures(degree=2).fit_transform(test_data_dm[independent_var])\ncomplex_model_4 = LinearRegression()\ncomplex_model_4.fit(X,train_data_dm['Ladder score'])\npred = complex_model_4.predict(X_test)\nrmsecm = float(format(np.sqrt(mean_squared_error(\n                       test_data_dm['Ladder score'],pred)),'.3f'))\nrtrcm = float(format(complex_model_4.score(\n                        X,\n                        train_data_dm['Ladder score']),'.3f'))\nartrcm = float(format(adjustedR2(complex_model_4.score(\n                          X,\n                            train_data_dm['Ladder score']),\n                            train_data_dm.shape[0],\n                            X.shape[1]),'.3f'))\nrtecm = float(format(complex_model_4.score(\n                        X_test,\n                        test_data_dm['Ladder score']),'.3f'))\nartecm = float(format(adjustedR2(complex_model_4.score(\n                       X_test,test_data['Ladder score']),\n                        test_data_dm.shape[0],\n                        X_test.shape[1]),'.3f'))\ncv = float(format(cross_val_score(complex_model_4,\n                    df[independent_var],\n                    df['Ladder score'],cv=5).mean(),'.3f'))\nr = evaluation.shape[0]\nevaluation.loc[r] = ['Polynomial Regression-1','All features',rmsecm,rtrcm,artrcm,rtecm,artecm,cv]\nevaluation.sort_values(by = '5-Fold Cross Validation', ascending=False)","65bf4e65":"# LASSO REGRESSION\ntrain_data_dm, test_data_dm = train_test_split(df, train_size=0.75, random_state=3)\nindependent_var = ['Logged GDP per capita','Healthy life expectancy','Freedom to make life choices','Social support','Generosity','Perceptions of corruption']\n\ncomplex_model_L = linear_model.Lasso(alpha=0.0001)\ncomplex_model_L.fit(train_data_dm[independent_var],train_data_dm['Ladder score'])\n\npred1 = complex_model_L.predict(test_data_dm[independent_var])\nrmsecm = float(format(np.sqrt(mean_squared_error(test_data_dm['Ladder score'],pred1)),'.3f'))\n\nrtrcm = float(format(complex_model_L.score(train_data_dm[independent_var], train_data_dm['Ladder score']),'.3f'))\n\nartrcm = float(format(adjustedR2(complex_model_L.score(train_data_dm[independent_var],\n                                                             train_data_dm['Ladder score']),train_data_dm.shape[0],\n                                                             len(independent_var)),'.3f'))\n\nrtecm = float(format(complex_model_L.score(test_data_dm[independent_var],test_data_dm['Ladder score']),'.3f'))\n\nartecm = float(format(adjustedR2(complex_model_L.score(test_data_dm[independent_var],\n                                                             test_data_dm['Ladder score']),\n                                                             test_data_dm.shape[0],\n                                                             len(independent_var)),'.3f'))\n\ncv1 = float(format(cross_val_score(complex_model_L,df[independent_var],df['Ladder score'],cv=5).mean(),'.3f'))\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['Lasso Regression','alpha=0.0001, All features',rmsecm,rtrcm,artrcm,rtecm,artecm,cv1]\nevaluation.sort_values(by='5-Fold Cross Validation', ascending=False)","ba605971":"Geographic view of Happiness Rank","75f1a46b":"# **4. MODEL BUILDING & EVALUATING**","8521b7bb":"Very scattered, and a weak linear relationship","653d16ce":"Seems like GDP, social support and health are strong correlated with ladder score","db00a712":"# **2. DATA ANALYSING**","8424c8ab":"1. GDP per capita","c79b6cc3":"2. Social support","7a5bc12c":"3. Healthy life expectancy","f8162587":"As expected with the negative slope, but a weak linear relationship => we have to look at the distribution of corruption","b9e3116b":"Top countries in each feature ","49803a31":"4. Lasso Regression","e7de763a":"Feature importance","ef5de1a6":"Relationship between different features with Ladder score","68fd915f":"3. Polynomial Regression","f5d9d5a4":"Histogram of numeric data","c782e982":"5. Generosity","9711358f":"6. Perceptions of corruption","03564a59":"4. Freedom to make life choices","7a90c801":"Corruption is negative skewed, which explains for the weak linear relationship.","7006c6b9":"2. Random Forest from sklearn","02d480e0":"# **3. FEATURE ENGINEERING**","b1867462":"Surprise! Negative slope for generosity and very scattered also","018f75df":"# **1. DATA COLLECTING AND SAVING**","9c2f4468":"2. Multiple LR with GDP, social support and healthy life expectancy","286380dc":"With just single variable LR as in section 2, it is not good enough a fit. To improve the model, it's time for more complex models","ec943a03":"1. Multiple LR with all features","2b4d9067":"American countries tend to be happier than Asian and African countries"}}