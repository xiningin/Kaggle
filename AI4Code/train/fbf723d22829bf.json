{"cell_type":{"5359315e":"code","f9b2a4be":"code","bcb2a1ea":"code","d4a7b448":"code","dcfb9750":"code","8f29979f":"code","6d7a66b7":"code","2b084787":"code","db8b0867":"code","1d69afcf":"code","408f1067":"code","af7b51e9":"code","20a7dfa0":"code","88ceaab9":"code","435d19ea":"code","87e99fd3":"code","0101ca0c":"code","e88e53b6":"markdown","7623dddd":"markdown","9882db86":"markdown","f2f4bf9f":"markdown","62311256":"markdown","0e176056":"markdown","44c830fd":"markdown","36d13e67":"markdown","8231ff58":"markdown","40e59734":"markdown","023bc15a":"markdown","8457f432":"markdown","18bf092c":"markdown","c32aee9b":"markdown"},"source":{"5359315e":"# module imports\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\nimport random\n\n# model imports\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# processing imports\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\n","f9b2a4be":"# fetch the training file\nfile_path_20_percent = '..\/input\/nslkdd\/KDDTrain+_20Percent.txt'\nfile_path_full_training_set = '..\/input\/nslkdd\/KDDTrain+.txt'\nfile_path_test = '..\/input\/nslkdd\/KDDTest+.txt' \n\n#df = pd.read_csv(file_path_20_percent)\ndf = pd.read_csv(file_path_full_training_set)\ntest_df = pd.read_csv(file_path_test)","bcb2a1ea":"#data set doesn't include column names, add them.\ncolumns = (['duration'\n,'protocol_type'\n,'service'\n,'flag'\n,'src_bytes'\n,'dst_bytes'\n,'land'\n,'wrong_fragment'\n,'urgent'\n,'hot'\n,'num_failed_logins'\n,'logged_in'\n,'num_compromised'\n,'root_shell'\n,'su_attempted'\n,'num_root'\n,'num_file_creations'\n,'num_shells'\n,'num_access_files'\n,'num_outbound_cmds'\n,'is_host_login'\n,'is_guest_login'\n,'count'\n,'srv_count'\n,'serror_rate'\n,'srv_serror_rate'\n,'rerror_rate'\n,'srv_rerror_rate'\n,'same_srv_rate'\n,'diff_srv_rate'\n,'srv_diff_host_rate'\n,'dst_host_count'\n,'dst_host_srv_count'\n,'dst_host_same_srv_rate'\n,'dst_host_diff_srv_rate'\n,'dst_host_same_src_port_rate'\n,'dst_host_srv_diff_host_rate'\n,'dst_host_serror_rate'\n,'dst_host_srv_serror_rate'\n,'dst_host_rerror_rate'\n,'dst_host_srv_rerror_rate'\n,'attack'\n,'level'])\n\ndf.columns = columns\ntest_df.columns = columns\n\n# sanity check\ndf.head()","d4a7b448":"# map normal to 0, all attacks to 1\nis_attack = df.attack.map(lambda a: 0 if a == 'normal' else 1)\ntest_attack = test_df.attack.map(lambda a: 0 if a == 'normal' else 1)\n\n#data_with_attack = df.join(is_attack, rsuffix='_flag')\ndf['attack_flag'] = is_attack\ntest_df['attack_flag'] = test_attack\n\n# view the result\ndf.head()","dcfb9750":"# lists to hold our attack classifications\ndos_attacks = ['apache2','back','land','neptune','mailbomb','pod','processtable','smurf','teardrop','udpstorm','worm']\nprobe_attacks = ['ipsweep','mscan','nmap','portsweep','saint','satan']\nU2R = ['buffer_overflow','loadmdoule','perl','ps','rootkit','sqlattack','xterm']\nSybil = ['ftp_write','guess_passwd','http_tunnel','imap','multihop','named','phf','sendmail','snmpgetattack','snmpguess','spy','warezclient','warezmaster','xclock','xsnoop']\n\n# we will use these for plotting below\nattack_labels = ['Normal','DoS','Probe','U2R','Sybil']\n\n# helper function to pass to data frame mapping\ndef map_attack(attack):\n    if attack in dos_attacks:\n        # dos_attacks map to 1\n        attack_type = 1\n    elif attack in probe_attacks:\n        # probe_attacks mapt to 2\n        attack_type = 2\n    elif attack in U2R:\n        # privilege escalation attacks map to 3\n        attack_type = 3\n    elif attack in Sybil:\n        # remote access attacks map to 4\n        attack_type = 4\n    else:\n        # normal maps to 0\n        attack_type = 0\n        \n    return attack_type\n\n# map the data and join to the data set\nattack_map = df.attack.apply(map_attack)\ndf['attack_map'] = attack_map\n\ntest_attack_map = test_df.attack.apply(map_attack)\ntest_df['attack_map'] = test_attack_map\n\n# view the result\ndf.head()","8f29979f":"# attack vs MCS protocols\nattack_vs_protocol = pd.crosstab(df.attack, df.protocol_type)\nattack_vs_protocol","6d7a66b7":"# helper function for drawing mulitple charts.\ndef bake_pies(data_list,labels):\n    list_length = len(data_list)\n    \n    # setup for mapping colors\n    color_list = sns.color_palette()\n    color_cycle = itertools.cycle(color_list)\n    cdict = {}\n    \n    # build the subplots\n    fig, axs = plt.subplots(1, list_length,figsize=(18,10), tight_layout=False)\n    plt.subplots_adjust(wspace=1\/list_length)\n    \n    # loop through the data sets and build the charts\n    for count, data_set in enumerate(data_list): \n        \n        # update our color mapt with new values\n        for num, value in enumerate(np.unique(data_set.index)):\n            if value not in cdict:\n                cdict[value] = next(color_cycle)\n       \n        # build the wedges\n        wedges,texts = axs[count].pie(data_set,\n                           colors=[cdict[v] for v in data_set.index])\n\n        # build the legend\n        axs[count].legend(wedges, data_set.index,\n                           title=\"Flags\",\n                           loc=\"center left\",\n                           bbox_to_anchor=(1, 0, 0.5, 1))\n        # set the title\n        axs[count].set_title(labels[count])\n        \n    return axs   \n\n","2b084787":"# get the series for each protocol\nicmp_attacks = attack_vs_protocol.icmp\ntcp_attacks = attack_vs_protocol.tcp\nudp_attacks = attack_vs_protocol.udp\n\n# create the charts\nbake_pies([icmp_attacks, tcp_attacks, udp_attacks],['icmp','tcp','udp'])\nplt.show()","db8b0867":"# get a series with the count of each flag for attack and normal traffic\nnormal_flags = df.loc[df.attack_flag == 0].flag.value_counts()\nattack_flags = df.loc[df.attack_flag == 1].flag.value_counts()\n\n# create the charts\nflag_axs = bake_pies([normal_flags, attack_flags], ['normal','attack'])        \nplt.show()","1d69afcf":"# get a series with the count of each service for attack and normal MCS\nnormal_services = df.loc[df.attack_flag == 0].service.value_counts()\nattack_services = df.loc[df.attack_flag == 1].service.value_counts()\n\n# create the charts\nservice_axs = bake_pies([normal_services, attack_services], ['normalMCS','attack'])        \nplt.show()\n","408f1067":"# get the intial set of encoded features and encode them\nfeatures_to_encode = ['protocol_type', 'service', 'flag']\nencoded = pd.get_dummies(df[features_to_encode])\ntest_encoded_base = pd.get_dummies(test_df[features_to_encode])\n\n# not all of the features are in the test set, so we need to account for diffs\ntest_index = np.arange(len(test_df.index))\ncolumn_diffs = list(set(encoded.columns.values)-set(test_encoded_base.columns.values))\n\ndiff_df = pd.DataFrame(0, index=test_index, columns=column_diffs)\n\n# we'll also need to reorder the columns to match, so let's get those\ncolumn_order = encoded.columns.to_list()\n\n# append the new columns\ntest_encoded_temp = test_encoded_base.join(diff_df)\n\n# reorder the columns\ntest_final = test_encoded_temp[column_order].fillna(0)\n\n# get numeric features, we won't worry about encoding these at this point\nnumeric_features = ['duration', 'src_bytes', 'dst_bytes']\n\n# model to fit\/test\nto_fit = encoded.join(df[numeric_features])\ntest_set = test_final.join(test_df[numeric_features])","af7b51e9":"# create our target classifications\nbinary_y = df['attack_flag']\nmulti_y = df['attack_map']\n\ntest_binary_y = test_df['attack_flag']\ntest_multi_y = test_df['attack_map']\n\n# build the training sets\nbinary_train_X, binary_val_X, binary_train_y, binary_val_y = train_test_split(to_fit, binary_y, test_size=0.6)\nmulti_train_X, multi_val_X, multi_train_y, multi_val_y = train_test_split(to_fit, multi_y, test_size = 0.6)","20a7dfa0":"# model for the binary classification\nbinary_model = RandomForestClassifier()\nbinary_model.fit(binary_train_X, binary_train_y)\nbinary_predictions = binary_model.predict(binary_val_X)\n\n# calculate and display our base accuracty\nbase_rf_score = accuracy_score(binary_predictions,binary_val_y)\nbase_rf_score","88ceaab9":"# define the list of models that we want to test\nmodels = [\n    RandomForestClassifier(),\n    LogisticRegression(max_iter=250),\n    KNeighborsClassifier(),\n]\n\n# an empty list to capture the performance of each model\nmodel_comps = []\n\n# walk through the models and populate our list\nfor model in models:\n    model_name = model.__class__.__name__\n    accuracies = cross_val_score(model, binary_train_X, binary_train_y, scoring='accuracy')\n    for count, accuracy in enumerate(accuracies):\n        model_comps.append((model_name, count, accuracy))","435d19ea":"# a box plot will do well to show us overall performance and the variation in the models.\nresult_df = pd.DataFrame(model_comps, columns=['model_name', 'count', 'accuracy'])\nresult_df.pivot(index='count',columns='model_name',values='accuracy').boxplot(rot=45)","87e99fd3":"# a helper function for getting some analytical data about our predictions\ndef add_predictions(data_set,predictions,y):\n    prediction_series = pd.Series(predictions, index=y.index)\n\n    # we need to add the predicted and actual outcomes to the data\n    predicted_vs_actual = data_set.assign(predicted=prediction_series)\n    original_data = predicted_vs_actual.assign(actual=y).dropna()\n    conf_matrix = confusion_matrix(original_data['actual'], \n                                   original_data['predicted'])\n    \n    # capture rows with failed predictions\n    base_errors = original_data[original_data['actual'] != original_data['predicted']]\n    \n    # drop columns with no value\n    non_zeros = base_errors.loc[:,(base_errors != 0).any(axis=0)]\n\n    # idetify the type of error\n    false_positives = non_zeros.loc[non_zeros.actual==0]\n    false_negatives = non_zeros.loc[non_zeros.actual==1]\n\n    # put everything into an object\n    prediction_data = {'data': original_data,\n                       'confusion_matrix': conf_matrix,\n                       'errors': base_errors,\n                       'non_zeros': non_zeros,\n                       'false_positives': false_positives,\n                       'false_negatives': false_negatives}\n    \n    return prediction_data\n","0101ca0c":"# capture our prediction data\nbinary_prediction_data = add_predictions(df,\n                                         binary_predictions,\n                                         binary_val_y)\n\n# create a heatmap of the confusion matrix\nsns.heatmap(data=binary_prediction_data['confusion_matrix'],\n            xticklabels = ['Predicted Normal','Predicted Attack'],\n            yticklabels = ['Actual Normal','Actual Attack'],\n            cmap=\"YlGnBu\",\n            fmt='d',\n            annot=True)","e88e53b6":"Data extraction****\nhere we upload our dataset","7623dddd":"Comapre with different model using cross_val_score.","9882db86":"I got 99% accuracy \n","f2f4bf9f":"Our data show that huge normal traffic is http, our attack traffic is all over the MCS. Sybil ttacks are searching for many different paths into MCS systems; some well traveled and some not.\n\n","62311256":"**Model fitting**\nBased on the nature of the data, decision trees are a good starting point for building out predictive models. In this case we'll use a random forest to build and combine multiple trees. ","0e176056":"I classify each of the attacks according to attack type for a more granular prediction model.","44c830fd":"**Confusion Matrix**\nNow, Summarizing the performance of a classification algorithm. ","36d13e67":"Our monitoring strategy uses a series continuous network protocols and capable of learning subtle distinction between threats and legal ones. Historical information fed the machine learning model classify Sybil and other attacks (ddos, probe, u2r). It helps to identify recurring patterns of Sybil, DDoS, U2R, Probe attacks and locate in long-term traffic chain.","8231ff58":" random forest and K-nearest perform well but logistic give loww accuracy","40e59734":"I divide the data into testing and training sets to start: binrary and multi classifications.","023bc15a":"**Data transformations**\nI adding a column that encodes 'normal' values as 0 and any other value as 1. We will use this as our classifier for a simple binary model that idenfities any attack.","8457f432":"**Data profiling**\ni put in table of attack by protocol. ","18bf092c":"**Feature engineering**\n","c32aee9b":"**Visual Representation of Dataset**\n see how things are distributed."}}