{"cell_type":{"3366cbea":"code","a94fc881":"code","1d1f0ccb":"code","4ade729c":"code","51b49a8a":"code","2e3f21a8":"code","54de8367":"code","6ed77606":"code","e451a89e":"code","4ed4702a":"code","0f0efbf6":"code","a5f1f475":"code","1a301465":"code","65fe9854":"code","53d16d0a":"code","ffd933d6":"markdown","f48808d4":"markdown","63ee5077":"markdown","35834a3e":"markdown","3c3ebb13":"markdown","5c7f5887":"markdown"},"source":{"3366cbea":"from keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, GlobalAveragePooling2D, Flatten, BatchNormalization, Dense\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, accuracy_score\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import vgg16,inception_v3,resnet\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom keras.optimizers import Adam, SGD , RMSprop\nfrom keras.models import Model,Sequential\nfrom keras.utils import to_categorical\nfrom matplotlib.pyplot import figure\nfrom keras import optimizers\nfrom keras import models\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport tensorflow as tf\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport datetime\nimport random\nimport pickle\nimport time\nimport cv2\nimport os\n%matplotlib inline","a94fc881":"# Total 400 data 200 train and 100 test and 100 validation\nwith open(\"..\/input\/melanoma\/melanoma_latest.pickle\", \"rb\") as f:\n    (x_train1,x_val1,x_test1,y_train1,y_val1,y_test1)=pickle.load(f,encoding='latin1')\n\n# Total 256 data 152 train and 52 test and 52 validation\nwith open(\"..\/input\/melanoma\/melanoma_latest_256data.pickle\", \"rb\") as f:\n    (x_train2,x_val2,x_test2,y_train2,y_val2,y_test2)=pickle.load(f,encoding='latin1')","1d1f0ccb":"def vgg():\n    vgg = vgg16.VGG16(include_top=False,weights=\"imagenet\",input_shape=(224,224,3),pooling='max')\n    x = vgg.output\n    x = BatchNormalization()(x)\n    x = Flatten()(x)\n    predictions = Dense(2, activation='sigmoid')(x)\n    model = Model(inputs=vgg.input, outputs=predictions)\n    return model\n\ndef inception():\n    inception = inception_v3.InceptionV3(include_top=False,weights=\"imagenet\",input_shape=(224,224,3),pooling='max')\n    x = inception.output\n    x = BatchNormalization()(x)\n    x = Flatten()(x)\n    predictions = Dense(2, activation='sigmoid')(x)\n    model = Model(inputs=inception.input, outputs=predictions)\n    return model","4ade729c":"def plotresult(y1,y2,ylabel,title,legends):\n    plt.plot(y1)\n    plt.plot(y2)\n    plt.title(title)\n    plt.xlabel('Epoch')\n    plt.ylabel(ylabel)\n    # plt.ylim(min_y, max_y)\n    plt.legend(legends, loc='upper left')\n    plt.grid()\n\n\ndef performacecompare(history1,history2):\n    plt.figure(figsize=(15, 22))\n\n    plt.subplot(421)\n    y1 = history1.history['loss']\n    y2 = history1.history['val_loss']\n    plotresult(y1,y2,'Loss','VGG16 train and validation loss',['Train','Validation'])\n\n    plt.subplot(422)\n    y1 = history1.history['accuracy']\n    y2 = history1.history['val_accuracy']\n    plotresult(y1,y2,'Accuracy','VGG16 train and validation accuracy',['Train','Validation'])\n\n    plt.subplot(423)\n    y1 = history2.history['loss']\n    y2 = history2.history['val_loss']\n    plotresult(y1,y2,'Loss','InceptionV3 train and validation loss',['Train','Validation'])\n\n    plt.subplot(424)\n    y1 = history2.history['accuracy']\n    y2 = history2.history['val_accuracy']\n    plotresult(y1,y2,'Accuracy','InceptionV3 train and validation accuracy',['Train','Validation'])\n\n    plt.subplot(425)\n    y1 = history1.history['loss']\n    y2 = history2.history['loss']\n    plotresult(y1,y2,'Loss','VGG16 and InceptionV3 train loss',['VGG16','InceptionV3'])\n\n    plt.subplot(426)\n    y1 = history1.history['accuracy']\n    y2 = history2.history['accuracy']\n    plotresult(y1,y2,'accuracy','VGG16 and InceptionV3 train accuracy',['VGG16','InceptionV3'])\n\n    plt.subplot(427)\n    y1 = history1.history['val_loss']\n    y2 = history2.history['val_loss']\n    plotresult(y1,y2,'Loss','VGG16 and InceptionV3 validation loss',['VGG16','InceptionV3'])\n\n    plt.subplot(428)\n    y1 = history1.history['val_accuracy']\n    y2 = history2.history['val_accuracy']\n    plotresult(y1,y2,'accuracy','VGG16 and InceptionV3 validation accuracy',['VGG16','InceptionV3'])\n\n    plt.show()","51b49a8a":"def testandcm(model,x_test,y_test,modelname=\"\"):\n    predict = model.predict(x_test)\n    predict = np.argmax(predict,axis=1)\n    acuracy = accuracy_score(y_test,predict)\n    f1score = f1_score(y_test,predict)\n    print(modelname+'Test accuracy = {}% and F1-Score = {}'.format(round(acuracy*100.0,2),round(f1score,2)))\n\n    cm = confusion_matrix(y_test,predict)\n    ax= plt.subplot()\n    sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n\n    # labels, title and ticks\n    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n    ax.set_title(modelname+'Confusion Matrix'); \n    ax.xaxis.set_ticklabels(['benign', 'malignant']); ax.yaxis.set_ticklabels(['benign', 'malignant']);","2e3f21a8":"vgg1 = vgg()\nvgg1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nvgg1.summary()\nvgg1_hist = vgg1.fit(x_train1,to_categorical(y_train1), validation_data=(x_val1, to_categorical(y_val1)),verbose=2, epochs=100)","54de8367":"inception1 = inception()\ninception1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\ninception1.summary()\ninception1_hist = inception1.fit(x_train1,to_categorical(y_train1), validation_data=(x_val1, to_categorical(y_val1)),verbose=2, epochs=100)","6ed77606":"# train performance comparision vgg and inception\nperformacecompare(vgg1_hist,inception1_hist)","e451a89e":"#VGG16 test for 100 test data\ntestandcm(vgg1,x_test1,y_test1,\"VGG16 \")","4ed4702a":"#InceptionV3 test for 100 test data\ntestandcm(inception1,x_test1,y_test1,\"InceptionV3 \")","0f0efbf6":"vgg2 = vgg()\nvgg2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nvgg2.summary()\nvgg2_hist = vgg2.fit(x_train2,to_categorical(y_train2), validation_data=(x_val2, to_categorical(y_val2)),verbose=2, epochs=100)","a5f1f475":"inception2 = inception()\ninception2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\ninception2.summary()\ninception2_hist = inception2.fit(x_train2,to_categorical(y_train2), validation_data=(x_val2, to_categorical(y_val2)),verbose=2, epochs=100)","1a301465":"# train performance comparision vgg and inception\nperformacecompare(vgg2_hist,inception2_hist)","65fe9854":"#VGG16 test for 52 test data\ntestandcm(vgg2,x_test2,y_test2,\"VGG16 \")","53d16d0a":"#InceptionV3 test for 100 test data\ntestandcm(inception2,x_test2,y_test2,\"InceptionV3 \")","ffd933d6":"# Vgg16 and InceptionV3 training for 400 data","f48808d4":"# Test and confusion matrix function","63ee5077":"# Vgg16 and InceptionV3 training for 256 data","35834a3e":"# Ploting all training results and comparision funcion","3c3ebb13":"# VGG16 and InceptionV3 model function","5c7f5887":"# Data loading"}}