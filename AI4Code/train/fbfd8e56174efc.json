{"cell_type":{"172d0921":"code","4c8493ba":"code","059f8236":"code","90894184":"code","2b723b21":"code","1c0fe7b9":"code","55196966":"code","94ed39a8":"code","4b5378d0":"code","c714bc0f":"code","14fa63ec":"code","038bc8a7":"code","a3ebe8e7":"code","83782d6b":"code","84147b3f":"code","0d5667d0":"code","ab75d57d":"code","4313b92a":"code","054a5e43":"code","f105c442":"code","3d132124":"code","14e8c3de":"code","4fdf082f":"code","f87938c8":"code","f1ea6f1e":"code","2fd0f193":"code","fa602218":"code","0ddb135e":"code","cc4bc21f":"code","819ce242":"code","2cc6b706":"code","7629f6b2":"code","a9fc32a7":"code","4e652f8e":"code","b58de00a":"code","95a6bfa4":"code","61b959b4":"code","c22c707a":"code","0cd34d8a":"markdown","4cba3422":"markdown","b83097ae":"markdown","63f40aed":"markdown","3ef73cea":"markdown","400139af":"markdown","e6466710":"markdown","53ee2443":"markdown","de8b64f1":"markdown","a2f49143":"markdown","0f3c8004":"markdown","e5a070e0":"markdown","a27a5398":"markdown","c93a3b35":"markdown","4c54abd2":"markdown","c85ebbfa":"markdown","490cc742":"markdown","8d0aa679":"markdown","81e2bf1d":"markdown","654a4a92":"markdown","266d1231":"markdown","1a2c0569":"markdown","d046ed9f":"markdown","3c93a197":"markdown","0fcf5eba":"markdown","581a127c":"markdown","43e03a8d":"markdown","1c13231d":"markdown","85cea82f":"markdown","280d7492":"markdown","f2a9c240":"markdown","4efd6c75":"markdown","0152d0a9":"markdown","2499673e":"markdown","5acb66ff":"markdown","befd1ba0":"markdown","4c9d0c54":"markdown","911edc1d":"markdown","78a55acd":"markdown","d3131ec5":"markdown"},"source":{"172d0921":"import pandas as pd\nimport os\nfrom sklearn import preprocessing, svm\nimport numpy as np\nfrom sklearn.metrics import recall_score, precision_score, f1_score, confusion_matrix\nfrom imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\nfrom imblearn.under_sampling import ClusterCentroids, RandomUnderSampler\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.linear_model import SGDClassifier, SGDRegressor, LogisticRegression\nfrom sklearn.kernel_approximation import RBFSampler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils import resample\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.neural_network import BernoulliRBM, MLPClassifier\nfrom sklearn.feature_selection import RFE\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_regression\nimport sklearn\nimport seaborn as sb\nimport matplotlib.pyplot as plt","4c8493ba":"# Read CSV file\nfilename = \"train_set.csv\"\ndata_train = pd.read_csv(filename)\nfilename = \"test_set.csv\"\ndata_test = pd.read_csv(filename)\n\n# Split dataset into x and y\nfea_col = data_train.columns[2:]\ndata_Y = data_train['target']\ndata_X = data_train[fea_col]","059f8236":"x_train, x_val, y_train, y_val = train_test_split(data_X, data_Y, test_size = 0.2)","90894184":"scaler = StandardScaler()\nscaler = scaler.fit(x_train,y_train)\nx_train = scaler.transform(x_train)\nx_val = scaler.transform(x_val)","2b723b21":"selector = SelectKBest(f_classif, k=30)\nselector = selector.fit(x_train, y_train)\nx_train = selector.transform(x_train)\nx_val = selector.transform(x_val)\n","1c0fe7b9":"rfe = RFE(estimator=clf, n_features_to_select=30)\nrfe = rfe.fit(x_train,y_train)\nx_train = rfe.transform(x_train)\nx_val = rfe.transform(x_val)","55196966":"imp = SimpleImputer(missing_values=-1, strategy='median')\nx_train = imp.fit_transform(x_train,y_train)","94ed39a8":"rus = RandomUnderSampler(random_state=0)\nx_train, y_train = rus.fit_resample(x_train,y_train)","4b5378d0":"ros = RandomOverSampler(random_state=0)\nx_train, y_train = ros.fit_resample(x_train,y_train)","c714bc0f":"smote = SMOTE(sampling_strategy='auto', random_state=0)\nx_train, y_train = smote.fit_resample(x_train,y_train)","14fa63ec":"adasyn = ADASYN(random_state=0)\nx_train, y_train = adasyn.fit_resample(x_train,y_train)","038bc8a7":"scaler = preprocessing.MinMaxScaler()\ndata_X = scaler.fit_transform(data_X, data_Y)","a3ebe8e7":"x_train = preprocessing.normalize(x_train, norm='l2')","83782d6b":"clf = LogisticRegression(C=1,  max_iter=5000,  class_weight=None)","84147b3f":"clf = SGDClassifier(loss=\"modified_huber\",penalty=\"l2\",max_iter=5000, class_weight='balanced')","0d5667d0":"clf = MLPClassifier(random_state=1, max_iter=5000, hidden_layer_sizes=(100,100,100))","ab75d57d":"clf = svm.SVR(kernel='linear')\n# too slow","4313b92a":"clf = sklearn.svm.SVC(class_weight='balanced')","054a5e43":"clf = RandomForestClassifier(class_weight={0:1,1:25}, max_depth=15, min_samples_leaf=40, max_features=10, n_jobs=-1, n_estimators=500)","f105c442":"clf = SGDClassifier(loss=\"log\",penalty=\"l1\",max_iter=5000, class_weight='balanced')\nparameters = {'loss':('log','modified_huber', 'hinge'), 'penalty':('l1', 'l2', 'elasticnet')}\ngrid = GridSearchCV(clf, parameters, scoring='f1_macro', return_train_score=True)\ngrid.fit(data_X, data_Y)","3d132124":"clf = LogisticRegression(max_iter=5000)\n\nparameters = {'C':(1e-9, 1e-6, 1e-3, 1e0, 1e3, 1e6, 1e9), 'class_weight':('balanced',None)}\ngrid = GridSearchCV(clf, parameters, scoring='f1_macro', return_train_score=True)\ngrid.fit(data_X, data_Y)","14e8c3de":"def validate_svc(kernel):\n    clf = sklearn.svm.SVC(kernel=kernel, class_weight='balanced')\n    print(np.mean(cross_val_score(clf,data_X,data_Y, scoring='f1'))*100)\n    \nfor kernel in ['poly', 'rbf', 'sigmoid', 'precomputed']:\n    print(\"Kernel: \", kernel)\n    validate_svc(kernel)\n    print(\"*************\")","4fdf082f":"clf = RandomForestClassifier(class_weight={0:1,1:25}, max_depth=15, min_samples_leaf=40, max_features=10, n_jobs=-1, n_estimators=500)","f87938c8":"parameters = {'max_features':(5,10,13,15,17,20,25)}\ngrid = GridSearchCV(clf, parameters, scoring='f1_macro', return_train_score=True)\ngrid.fit(data_X, data_Y)\nplot_results('max_features')","f1ea6f1e":"parameters = {'n_estimators':(10,100,250,500,1000)}\ngrid = GridSearchCV(clf, parameters, scoring='f1_macro', return_train_score=True)\ngrid.fit(data_X, data_Y)\nplot_results('n_estimators')","2fd0f193":"parameters = {'max_depth':(1,5,10,11,13,15,17,19,20)}\ngrid = GridSearchCV(clf, parameters, scoring='f1_macro', return_train_score=True)\ngrid.fit(data_X, data_Y)\nplot_results('max_depth')","fa602218":"parameters = {'class_weight':('balanced',{0:1,1:35},{0:1,1:30},{0:1,1:25},{0:1,1:20})}\ngrid = GridSearchCV(clf, parameters, scoring='f1_macro', return_train_score=True)\ngrid.fit(data_X, data_Y)\nplot_results('class_weight')","0ddb135e":"parameters = {'min_samples_leaf':(5,10,20,30,40,50)}\ngrid = GridSearchCV(clf, parameters, scoring='f1_macro', return_train_score=True)\ngrid.fit(data_X, data_Y)\nplot_results('min_samples_leaf')","cc4bc21f":"def plot_results(attr, print_results=False):\n    results = np.asarray(list(zip(grid.cv_results_['params'],grid.cv_results_['mean_test_score'])))\n    xs = [None] * results.shape[0]\n    ys = np.empty(results.shape[0])\n    \n    for i,r in enumerate(results):\n        xs[i] = str(r[0][attr])\n        ys[i] = r[1]\n        \n    if print_results:\n        results = np.flip(results[results[:,1].argsort()], axis=0)\n        for r in results:\n            print(\"| \", r[0][attr], \" | \", r[1], \" |\")\n      \n    plt.figure(figsize=(20,10))\n    plt.plot(xs,ys)\n    plt.savefig(attr, bbox_inches='tight')","819ce242":"clf = clf.fit(x_train, y_train)\ny_pred = clf.predict(x_val)","2cc6b706":"score = f1_score(y_val, y_pred, average='macro')\nprint(\"f1:\", score)\nprint(\"recall\", recall_score(y_val, y_pred, average='macro'))\nprint(\"precision:\", precision_score(y_val, y_pred, average='macro'))","7629f6b2":"cm = confusion_matrix(y_val, y_pred)\nplt.figure(figsize=(2,2))\nsb.heatmap(cm, annot=True, fmt=\".0f\", linewidths=.5, square = True, cmap = 'Blues');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Score: {:.4}'.format(score)\nplt.title(all_sample_title, size = 15);","a9fc32a7":"train_pred = clf.predict(x_train)\ncm = confusion_matrix(y_train, train_pred)\ntrain_score = f1_score(y_train, train_pred, average='macro')\nplt.figure(figsize=(2,2))\nsb.heatmap(cm, annot=True, fmt=\".0f\", linewidths=.5, square = True, cmap = 'Blues');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Score: {:.4}'.format(train_score)\nplt.title(all_sample_title, size = 15);","4e652f8e":"data_test_X = data_test.drop(columns=['id'])","b58de00a":"scaler = StandardScaler()\ndata_X = scaler.fit_transform(data_X,data_Y)\ndata_test_X = scaler.fit_transform(data_test_X)","95a6bfa4":"rfe = RFE(estimator=clf, n_features_to_select=30)\nrfe = rfe.fit(data_X,data_Y)\ndata_X = rfe.transform(data_X)\ndata_test_X = rfe.transform(data_test_X)","61b959b4":"imp = SimpleImputer(missing_values=-1, strategy='median')\nimp = imp.fit(data_X,data_Y)\ndata_X = imp.transform(data_X)\ndata_test_X = imp.transform(data_test_X)","c22c707a":"clf = clf.fit(data_X, data_Y)\n\ny_target = clf.predict(data_test_X)\ndata_out = pd.DataFrame(data_test['id'].copy())\ndata_out.insert(1, \"target\", y_target, True) \ndata_out.to_csv('submission.csv',index=False)","0cd34d8a":"### Cross-Validation (parameter tuning) <a name=\"cross-validation\"><\/a>","4cba3422":"### Preprocessing","b83097ae":"#### SGD Tuning","63f40aed":"#### Random Forest Classifier\nThis classifier was used to generate the final results.","3ef73cea":"#### Oversample","400139af":"### Preprocessing <a name=\"preprocessing\"><\/a>","e6466710":"#### Confusion Matrix Test Data","53ee2443":"##### Max Depth","de8b64f1":"#### Confusion Matrix","a2f49143":"#### Split Data","0f3c8004":"#### Replace missing data","e5a070e0":"### Contents\n1. [Preprocessing](#preprocessing)\n1. [Classifiers](#classifiers)\n1. [Cross-Validation (parameter tuning)](#cross-validation)\n4. [Classifier Test](#test)\n5. [Submission](#submission)","a27a5398":"#### MinMax Scale","c93a3b35":"#### Feature Selection","4c54abd2":"### Classifiers <a name=\"classifiers\"><\/a>","c85ebbfa":"#### Scaling","490cc742":" ## Submission <a name=\"submission\"><\/a>","8d0aa679":"#### LR Tuning","81e2bf1d":"#### RFE Feature Selection","654a4a92":"#### Logistic Regression","266d1231":"#### Missing Data","1a2c0569":"##### Class Weight","d046ed9f":"#### Feature Selection","3c93a197":"#### Forest Tuning","0fcf5eba":"### Export Results","581a127c":"#### Stochastic Gradient Descent","43e03a8d":"#### Support Vector Machine","1c13231d":"#### Undersample","85cea82f":"#### Show Validation results","280d7492":"##### Min Samples Leaf","f2a9c240":"#### Normalize","4efd6c75":"#### Support Vector Classifier","0152d0a9":"#### Multi-Layer Perceptron","2499673e":"# Machine Learning Project","5acb66ff":"### Test Classifier <a name=\"test\"><\/a>","befd1ba0":"#### SVC Tuning","4c9d0c54":"### Import Data","911edc1d":"##### Max Features","78a55acd":"##### N Estimators","d3131ec5":"#### Standard Scaling"}}