{"cell_type":{"e3bb4afd":"code","70b5b6f7":"code","3e8e5c07":"code","dccd1d43":"code","aed50500":"code","cc15cf4b":"code","c3f2988e":"code","61ed3498":"code","56777fc3":"code","054cdb14":"code","6ece9da5":"code","3424ea71":"code","e5cce3b3":"code","65d1da00":"code","0c8235fc":"code","acbed8e0":"code","a8976a8b":"code","db56b384":"code","956b2bb5":"code","0d245788":"code","3415ff68":"code","20818d40":"code","8414e402":"code","6593a0b0":"code","4d67bde8":"code","94608e68":"code","9646a8d1":"code","6e4459e6":"code","4a44c880":"code","9b1bdeed":"code","87dec36b":"code","722a225e":"code","8cbb3a17":"markdown","6b44533e":"markdown","e61cd26d":"markdown","a0c90edc":"markdown","788dfcf5":"markdown","af90e1ed":"markdown","3ddf0094":"markdown","2a577ce0":"markdown","7387d545":"markdown","bc33205c":"markdown","82492574":"markdown","3fb97b95":"markdown"},"source":{"e3bb4afd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","70b5b6f7":"# Import libraries for data manipulation and preprocessing\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Import libraries for resampling\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import BorderlineSMOTE\nfrom imblearn.over_sampling import SVMSMOTE\nfrom imblearn.over_sampling import ADASYN\nfrom imblearn.combine import SMOTETomek\nfrom imblearn.under_sampling import TomekLinks\nfrom imblearn.combine import SMOTEENN","3e8e5c07":"# Import libraries for classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\n\n# Import libraries for visualization and set the display\nimport seaborn as sns\nimport matplotlib.pyplot as plt\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\nsns.set(color_codes=True)\n%matplotlib inline\n%config InlineBackend.figure_formats = {'png', 'retina'}","dccd1d43":"# Suppressing Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","aed50500":"# Read the dataset as pandas dataframe\ndf = pd.read_csv('\/kaggle\/input\/telecom-users-dataset\/telecom_users.csv')\n\n# Show the shape and the first 5 rows\nprint('Shape of the data', df.shape)\ndf.head()","cc15cf4b":"# Let's see the type of each column\ndf.info()","c3f2988e":"# Drop \"customerID\" from the dataset\ndf.drop(['Unnamed: 0','customerID'],axis=1, inplace=True)\n\n# Delete the rows with ' ' values from \"TotalCharges\" and convert it to float type\ndf=df[df['TotalCharges']!=' ']\ndf['TotalCharges']=df['TotalCharges'].astype('float')","61ed3498":"# Convert the 3 unique labels (\"Yes\", \"No\", \"No internet\") into 2 binary labels: \"Yes\", \"No\".\n\n# Create a list of new binary labels\nbinary={'No':0,'No phone service':0,'No internet service':0,'Yes':1}\n\n# Creata a list of variables to be converted to binary ones.\ncols = ['Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n        'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling', 'Churn']\n\nfor i in cols:\n    df[i]=df[i].map(binary)","56777fc3":"# Create dummy variables of the focal variables\ndf=pd.get_dummies(data=df, columns=['InternetService', 'Contract', 'PaymentMethod','gender'],drop_first=True)","054cdb14":"# Separate the dataset into features and target\nX=df.drop(['Churn'],axis=1)\ny=df['Churn']","6ece9da5":"y.value_counts()","3424ea71":"fig, axes = plt.subplots(7, 3, figsize=(20, 30))\n\nfig.suptitle('Churn Rate by Categories')\n\nsns.barplot(ax=axes[0, 0], data=df, x='SeniorCitizen', y='Churn')\nsns.barplot(ax=axes[0, 1], data=df, x='Partner', y='Churn')\nsns.barplot(ax=axes[0, 2], data=df, x='Dependents', y='Churn')\nsns.barplot(ax=axes[1, 0], data=df, x='PhoneService', y='Churn')\nsns.barplot(ax=axes[1, 1], data=df, x='MultipleLines', y='Churn')\nsns.barplot(ax=axes[1, 2], data=df, x='OnlineSecurity', y='Churn')\nsns.barplot(ax=axes[2, 0], data=df, x='OnlineBackup', y='Churn')\nsns.barplot(ax=axes[2, 1], data=df, x='DeviceProtection', y='Churn')\nsns.barplot(ax=axes[2, 2], data=df, x='TechSupport', y='Churn')\nsns.barplot(ax=axes[3, 0], data=df, x='StreamingTV', y='Churn')\nsns.barplot(ax=axes[3, 1], data=df, x='StreamingMovies', y='Churn')\nsns.barplot(ax=axes[3, 2], data=df, x='PaperlessBilling', y='Churn')\nsns.barplot(ax=axes[4, 0], data=df, x='InternetService_Fiber optic', y='Churn')\nsns.barplot(ax=axes[4, 1], data=df, x='InternetService_No', y='Churn')\nsns.barplot(ax=axes[4, 2], data=df, x='Contract_One year', y='Churn')\nsns.barplot(ax=axes[5, 0], data=df, x='Contract_Two year', y='Churn')\nsns.barplot(ax=axes[5, 1], data=df, x='PaymentMethod_Credit card (automatic)', y='Churn')\nsns.barplot(ax=axes[5, 2], data=df, x='PaymentMethod_Electronic check', y='Churn')\nsns.barplot(ax=axes[6, 0], data=df, x='PaymentMethod_Mailed check', y='Churn')\nsns.barplot(ax=axes[6, 1], data=df, x='gender_Male', y='Churn')","e5cce3b3":"cols = ['tenure','MonthlyCharges','TotalCharges']\nfig, axes = plt.subplots(ncols=len(cols), nrows=1, figsize=(18, 7))\nfor col, ax in zip(cols, axes):\n    sns.boxenplot(data=df, x='Churn', y=col, linewidth=0.05, ax=ax)\n    ax.set_title(col)\n    ax.set_ylabel('')\nplt.subplots_adjust(wspace=0.4, hspace=0.6)\nplt.suptitle('Churn vs Non-Churn by Numerical Variables')\nplt.show()","65d1da00":"# Split data into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","0c8235fc":"# Apply rebalancing\n\n# Random Oversampling\nover_X_train, over_y_train = RandomOverSampler(sampling_strategy='minority').fit_resample(X_train, y_train)\n# SMOTE\nsmote_X_train, smote_y_train = SMOTE().fit_resample(X_train,y_train)\n# Boderline-SMOTE\nbdlsmote_X_train, bdlsmote_y_train = BorderlineSMOTE().fit_resample(X_train, y_train)\n# Boderline-SMOTE SVM\nbdlSVMsmote_X_train, bdlSVMsmote_y_train = SVMSMOTE().fit_resample(X_train, y_train)\n# ADASYN\nadasyn_X_train, adasyn_y_train = ADASYN().fit_resample(X_train, y_train)\n# SMOTE-TomekLinks\nsmotetomek_X_train, smotetomek_y_train = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority')).fit_resample(X_train, y_train)\n# SMOTE-ENN\nsmoteenn_X_train, smoteenn_y_train = SMOTEENN().fit_resample(X_train, y_train)","acbed8e0":"# Check the results of rebalancing\n\n# Random Oversampling\nprint(\"Random Oversampling\\n\", over_y_train.value_counts())\n# SMOTE\nprint(\"SMOTE\\n\", smote_y_train.value_counts())\n# Boderline-SMOTE\nprint(\"Borderline-SMOTE\\n\", bdlsmote_y_train.value_counts())\n# Boderline-SMOTE SVM\nprint(\"Borderline-SMOTE SVM\\n\", bdlSVMsmote_y_train.value_counts())\n# ADASYN\nprint(\"ADASYN\\n\", adasyn_y_train.value_counts())\n# SMOTE-TomekLinks\nprint(\"SMOTE-TomekLinks\\n\", smotetomek_y_train.value_counts())\n# SMOTE-ENN\nprint(\"SMOTE-ENN\\n\", smoteenn_y_train.value_counts())","a8976a8b":"datasets = [X_train, y_train, over_X_train, over_y_train, smote_X_train, smote_y_train,\n            bdlsmote_X_train, bdlsmote_y_train, bdlSVMsmote_X_train, bdlSVMsmote_y_train, \n            adasyn_X_train, adasyn_y_train, smotetomek_X_train, smotetomek_y_train, \n            smoteenn_X_train, smoteenn_y_train]\n\nfor dataset in datasets:\n    pd.DataFrame(dataset)","db56b384":"# Concatenate training and test sets for each resampled datasets\ntrain_concat = pd.concat([X_train, y_train], axis=1)\nover_train_concat = pd.concat([over_X_train, over_y_train], axis=1)\nsmote_train_concat = pd.concat([smote_X_train, smote_y_train], axis=1)\nbdlsmote_train_concat = pd.concat([bdlsmote_X_train, bdlsmote_y_train], axis=1)\nbdlSVMsmote_train_concat = pd.concat([bdlSVMsmote_X_train, bdlSVMsmote_y_train], axis=1)\nadasyn_train_concat = pd.concat([adasyn_X_train, adasyn_y_train], axis=1)\nsmotetomek_train_concat = pd.concat([smotetomek_X_train, smotetomek_y_train], axis=1)\nsmoteenn_train_concat = pd.concat([smoteenn_X_train, smoteenn_y_train], axis=1)","956b2bb5":"# Visualize resampling results\nfig, axes = plt.subplots(4, 2, figsize=(20, 20),squeeze=True)\nplt.subplots_adjust(wspace=0.2, hspace=0.4)\nfig.suptitle('Resampling Result')\n\nsns.scatterplot(ax=axes[0, 0], data=train_concat, x='tenure', y='MonthlyCharges', hue='Churn')\nsns.scatterplot(ax=axes[0, 1], data=over_train_concat, x='tenure', y='MonthlyCharges', hue='Churn', legend=False)\nsns.scatterplot(ax=axes[1, 0], data=smote_train_concat, x='tenure', y='MonthlyCharges', hue='Churn',legend=False)\nsns.scatterplot(ax=axes[1, 1], data=bdlsmote_train_concat, x='tenure', y='MonthlyCharges', hue='Churn',legend=False)\nsns.scatterplot(ax=axes[2, 0], data=bdlSVMsmote_train_concat, x='tenure', y='MonthlyCharges', hue='Churn',legend=False)\nsns.scatterplot(ax=axes[2, 1], data=adasyn_train_concat, x='tenure', y='MonthlyCharges', hue='Churn',legend=False)\nsns.scatterplot(ax=axes[3, 0], data=smotetomek_train_concat, x='tenure', y='MonthlyCharges', hue='Churn',legend=False)\nsns.scatterplot(ax=axes[3, 1], data=smoteenn_train_concat, x='tenure', y='MonthlyCharges', hue='Churn',legend=False)\n\naxes[0, 0].set_title(\"Imbalanced Data\")\naxes[0, 1].set_title(\"Random Oversampling\")\naxes[1, 0].set_title(\"SMOTE\")\naxes[1, 1].set_title(\"Borderline-SMOTE\")\naxes[2, 0].set_title(\"Borderline-SMOTE SVM\")\naxes[2, 1].set_title(\"ADASYN\")\naxes[3, 0].set_title(\"SMOTE-TomekLinks\")\naxes[3, 1].set_title(\"SMOTE-ENN\")","0d245788":"# Standardization\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","3415ff68":"# Apply rebalancing to standardized data\n\n# Random Oversampling\nover_X_train, over_y_train = RandomOverSampler(sampling_strategy='minority').fit_resample(X_train, y_train)\n# SMOTE\nsmote_X_train, smote_y_train = SMOTE().fit_resample(X_train,y_train)\n# Boderline-SMOTE\nbdlsmote_X_train, bdlsmote_y_train = BorderlineSMOTE().fit_resample(X_train, y_train)\n# Boderline-SMOTE SVM\nbdlSVMsmote_X_train, bdlSVMsmote_y_train = SVMSMOTE().fit_resample(X_train, y_train)\n# ADASYN\nadasyn_X_train, adasyn_y_train = ADASYN().fit_resample(X_train, y_train)\n# SMOTE-TomekLinks\nsmotetomek_X_train, smotetomek_y_train = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority')).fit_resample(X_train, y_train)\n# SMOTE-ENN\nsmoteenn_X_train, smoteenn_y_train = SMOTEENN().fit_resample(X_train, y_train)","20818d40":"# Check the results of rebalancing\n\n# Random Oversampling\nprint(\"Random Oversampling\\n\", over_y_train.value_counts())\n# SMOTE\nprint(\"SMOTE\\n\", smote_y_train.value_counts())\n# Boderline-SMOTE\nprint(\"Borderline-SMOTE\\n\", bdlsmote_y_train.value_counts())\n# Boderline-SMOTE SVM\nprint(\"Borderline-SMOTE SVM\\n\", bdlSVMsmote_y_train.value_counts())\n# ADASYN\nprint(\"ADASYN\\n\", adasyn_y_train.value_counts())\n# SMOTE-TomekLinks\nprint(\"SMOTE-TomekLinks\\n\", smotetomek_y_train.value_counts())\n# SMOTE-ENN\nprint(\"SMOTE-ENN\\n\", smoteenn_y_train.value_counts())","8414e402":"# Create a model dictionary\nmodels = {\"Logistic Regression   \": LogisticRegression(),\n          \"K-Nearest Neighbors   \": KNeighborsClassifier(),\n          \"Support Vector Machine\": SVC(probability=True),\n          \"Decision Tree         \": DecisionTreeClassifier(),\n          \"Random Forest         \": RandomForestClassifier(),\n          \"Ada Boost             \": AdaBoostClassifier(),\n          \"XGBoost               \": XGBClassifier(),\n          \"LightGBM              \": LGBMClassifier(),\n          \"CatBoost              \": CatBoostClassifier(verbose=0),\n          \"Neural Network        \": MLPClassifier()\n         }","6593a0b0":"# Fit the models on imbalanced data\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n\n# Print AUC score\nprint(\"Imbalanced Data: AUC score\")\nfor name, model in models.items():\n    print(name + \": {:.3f}\".format(roc_auc_score(y_test, model.predict(X_test))))","4d67bde8":"# Fit the models: Random Oversampling\nfor name, model in models.items():\n    model.fit(over_X_train, over_y_train)\n\n# Print AUC score\nprint(\"Random Oversampling: AUC score\")\nfor name, model in models.items():\n    print(name + \": {:.3f}\".format(roc_auc_score(y_test, model.predict(X_test))))","94608e68":"# Fit the models: SMOTE\nfor name, model in models.items():\n    model.fit(smote_X_train, smote_y_train)\n\n# Print AUC score\nprint(\"SMOTE: AUC score\")\nfor name, model in models.items():\n    print(name + \": {:.3f}\".format(roc_auc_score(y_test, model.predict(X_test))))","9646a8d1":"# Fit the models: Borderline-SMOTE\nfor name, model in models.items():\n    model.fit(bdlsmote_X_train, bdlsmote_y_train)\n\n# Print AUC score\nprint(\"Borderline-SMOTE: AUC score\")\nfor name, model in models.items():\n    print(name + \": {:.3f}\".format(roc_auc_score(y_test, model.predict(X_test))))","6e4459e6":"# Fit the models: Borderline-SMOTE SVM\nfor name, model in models.items():\n    model.fit(bdlSVMsmote_X_train, bdlSVMsmote_y_train)\n\n# Print AUC score\nprint(\"Borderlin-SMOTE SVM: AUC score\")\nfor name, model in models.items():\n    print(name + \": {:.3f}\".format(roc_auc_score(y_test, model.predict(X_test))))","4a44c880":"# Fit the models: ADASYN\nfor name, model in models.items():\n    model.fit(adasyn_X_train, adasyn_y_train)\n\n# Print AUC score\nprint(\"ADASYN: AUC score\")\nfor name, model in models.items():\n    print(name + \": {:.3f}\".format(roc_auc_score(y_test, model.predict(X_test))))","9b1bdeed":"# Fit the models: SMOTE-TomekLinks\nfor name, model in models.items():\n    model.fit(smotetomek_X_train, smotetomek_y_train)\n\n# Print AUC score\nprint(\"SMOTE-TomekLinks: AUC score\")\nfor name, model in models.items():\n    print(name + \": {:.3f}\".format(roc_auc_score(y_test, model.predict(X_test))))","87dec36b":"# Fit the models: SMOTE-ENN\nfor name, model in models.items():\n    model.fit(smoteenn_X_train, smoteenn_y_train)\n\n# Print AUC\nprint(\"SMOTE-ENN: AUC score\")\nfor name, model in models.items():\n    print(name + \": {:.3f}\".format(roc_auc_score(y_test, model.predict(X_test))))","722a225e":"# Confusin matrix\nfrom sklearn.metrics import confusion_matrix\n\nlog_reg = LogisticRegression().fit(smote_X_train, smote_y_train)\ny_pred = log_reg.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\n\n# Transform to df for easier plotting\ncm_df = pd.DataFrame(cm,\n                     index = ['Negative','Positive'], \n                     columns = ['Negative','Positive'])\n\nplt.figure(figsize=(10,8))\nsns.heatmap(cm_df, annot=True, cmap='Blues')\nplt.title('Logistic Regression \\nAUC:{0:.3f}'.format(roc_auc_score(y_test, y_pred)))\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","8cbb3a17":"# Load and Explore Data","6b44533e":"### Oversampling Methods\n\n#### Random Oversampling\n- It duplicates the minority class examples randomly, and added them to the training set.\n- Since it is based on simple duplications, it does not provide any additional information to the model.\n- Duplication is implemented with replacement, so it's likely to result in overfitting.\n\n#### SMOTE (Synthetic Minority Oversampling Technique)\n- Instead of simply duplicating existing minority class, SMOTE oversample the minority class by generating synthetic data.\n- Synthesizing new data is based on feature space similarity between exisitng minority class examples.\n- It randomly selects minority class cases, and generate new minority class cases by interpolations based on KNN.\n\n#### Borderline-SMOTE\n- An extension of SMOTE\n- While SMOTE randomly selects minority datapoints for synthesizing, Borderline-SMOTE selects them along the decion boundary between the classes.\n- It deals with the datapoints that are likely to be misclassified.\n\n#### Borderline-SMOTE SVM\n- An variation of Borderline-SMOTE\n- It uses SVM to approximately identify the borderline.\n- Then it randomly creates synthetic data along the borderline.\n- Datapoints far from the borderline are synthesized preferentially.\n\n#### ADASYN (Adaptive Synthetic sampling )\n- An variation of SMOTE\n- It oversamples the minority class based on the data density distributions.\n- It generates synthetic data more in areas where minority class is less dense. ","e61cd26d":"## Logistic Regression with SMOTE achieved the highest AUC.","a0c90edc":"# Data Preparation","788dfcf5":"- There are no missing values.\n- Only 4 are numerical, and others are object.","af90e1ed":"# Classification","3ddf0094":"### Hybrid Methods\n\nThese methods combines undersampling and oversampling methods.\n\n#### SMOTE-TomekLinks\n- Tomek Links is a method for identifying pairs of nearest neighbors each of them belong to different classes. \n- By removing one or both of these pairs, we can make the decision boundary clearer and less noisy.\n- SMOTE-TomekLink oversamples the minority class by SMOTE, and then, remove the majority class cases in Tomek Links.\n\n#### SMOTE-ENN (SMOTE Edited Nearest Neighbors)\n- ENN is an undersampling method that identify and remove any misclassifed examples based on KNN (k=3).\n- ENN can be applied to all classes or just examples in the majority class.\n- SMOTE-ENN oversamples the minority class by SMOTE, and then, remove the cases by ENN.","2a577ce0":"## Rebalancing Samples","7387d545":"## Overview of the Resampling Methods","bc33205c":"The data is imbalanced.","82492574":"# Import Libraries","3fb97b95":"- Customer churn prediction is a binary classification problem to be solved by supervised learning.\n- Let's use major supervised learning algorithm and compare the results.\n   - Logistic Regression\n   - KNN\n   - SVM\n   - Decision Tree\n   - Random Forest\n   - AdaBoost\n   - XGBoost\n   - LightGBM\n   - CatBoost\n   - Neural Network\n- The data is imbalanced, so apply rebalancing methods and compare their results with those of baseline models.\n   - Baseline models: Imbalanced data\n   - Random Oversampling\n   - SMOTE\n   - Borderline-SMOTE\n   - Borderline-SMOTE SVM\n   - ADASYN\n   - SMOTE-TomekLinks\n   - SMOTE-ENN\n- Performance measure\n   - AUC score"}}