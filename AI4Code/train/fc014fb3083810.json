{"cell_type":{"4a7ba3b6":"code","288f7344":"code","65658652":"code","c5d01ddd":"code","26d96a5a":"code","4c12c239":"code","58c45105":"code","326c4146":"code","b30d4549":"code","32b10e58":"code","46b7eb60":"code","e7e57a99":"code","f84332fe":"code","9ec91a60":"code","c9b4aed6":"code","296f9d55":"code","d0b11f72":"markdown","cc713f26":"markdown","1f9975d9":"markdown","73493bdf":"markdown","d97c1cde":"markdown","7310a30e":"markdown","c781eb61":"markdown"},"source":{"4a7ba3b6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","288f7344":"''' Import Modules '''\n\nimport sys\nimport warnings\n\nfrom pandas import set_option\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n        \nif not sys.warnoptions:\n    warnings.simplefilter('ignore')","65658652":"nRowsRead = 1000 # specify 'None' if want to read whole file\ndf = pd.read_csv('..\/input\/cusersmarildownloadsgermancsv\/german.csv', delimiter=';', encoding = \"ISO-8859-2\", nrows = nRowsRead)\ndf.dataframeName = 'german.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\ndf.head().style.set_properties(**{'background-color':'LightBlue',\n                                     'color': 'purple'})","c5d01ddd":"!pip install seaborn --upgrade","26d96a5a":"import seaborn as sns\nprint(sns.__version__)","4c12c239":"# Plot Correlation to Target Variable only\ndef corrMat(df,target='Creditability',figsize=(9,0.5),ret_id=False):\n    \n    corr_mat = df.corr().round(2);shape = corr_mat.shape[0]\n    corr_mat = corr_mat.transpose()\n    corr = corr_mat.loc[:, df.columns == target].transpose().copy() \n    \n    if(ret_id is False):\n        f, ax = plt.subplots(figsize=figsize)\n        sns.heatmap(corr,vmin=-0.3,vmax=0.3,center=0, \n                     cmap='viridis',square=False,lw=2,annot=True,cbar=False)\n        plt.title(f'Feature Correlation to {target}')\n    \n    if(ret_id):\n        return corr","58c45105":"corrMat(df,'Duration_of_Credit_monthly',figsize=(7,0.5))","326c4146":"lst_vars = df.columns.to_list();lst_vars","b30d4549":"df_grp = df.groupby([\"Creditability\",\"Duration_of_Credit_monthly\"])[[\"Credit_Amount\",\"Account_Balance\",\"Age_years\"]].sum().reset_index()\ndf_grp.head()","32b10e58":"''' Draw a Bivariate Seaborn Pairgrid \/w KDE density w\/ '''\ndef snsPairGrid(df):\n\n    sns.set(style='whitegrid')\n    g = sns.PairGrid(df,diag_sharey=False,height=4)\n    g.fig.set_size_inches(15,15)\n    g.map_diag(sns.kdeplot, lw=2)\n    g.map_lower(sns.scatterplot,s=25,edgecolor=\"k\",linewidth=0.5,alpha=0.4)\n    g.map_lower(sns.kdeplot,cmap='plasma',n_levels=6,alpha=0.5)\n    plt.tight_layout()","46b7eb60":"snsPairGrid(df_grp)","e7e57a99":"def plotRel(ldf):\n    sns.set(style='whitegrid')\n    g = sns.relplot(x='Duration_of_Credit_monthly',y='Creditability',col='Credit_Amount',row='Account_Balance',data=ldf,\n                kind='line',legend='full',hue='Age_years',palette='jet_r',height=4)","f84332fe":"''' Create Data Subsets for different airfoil sizes '''\nsns.set(style='whitegrid')\npdlst_creditability = [] # list of pd subset data storing all unique 'l_chord'\nlst_creditability_unique = df_grp['Creditability'].unique().tolist();lst_creditability_unique.sort() # get unique 'l_chord'&sort()\nfor i in lst_creditability_unique:\n    ldf = df_grp[df_grp['Creditability']==i].copy()\n    pdlst_creditability.append(ldf)    # add all unique subsets to list","9ec91a60":"# lets plot two cases, they are ordered so smaller one on top.\nplotRel(pdlst_creditability[0])\nplotRel(pdlst_creditability[1])","c9b4aed6":"sns.set(style='whitegrid')\nlst = [0,2]\ndef relplot1(Creditability):\n    for i in Creditability:\n        g = sns.relplot(x='Duration_of_Credit_monthly',y='Creditability',col='Credit_Amount',row='Creditability',\n                    hue='Age_years',sizes='Account_Balance',palette='jet_r',\n                    kind='scatter',legend='full',data=pdlst_creditability[1])\n        g.fig.set_size_inches(13,3)\n        leg = g._legend\n        leg.set_bbox_to_anchor([1.06,1])  # coordinates of lower left of bounding box\n        leg._loc = 1  # if required you can set the loc","296f9d55":"relplot1(lst)\n#plt.xticks(rotation=45)","d0b11f72":"#Code by Andrey Shtrauss https:\/\/www.kaggle.com\/shtrausslearning\/airfoil-noise-prediction-modeling-using-gpr","cc713f26":"#EDA: PairGrids","1f9975d9":"#I didn't expect for those \"charts\" above. The original was \n\nplotRel(pdlst_creditability[0])\n\nplotRel(pdlst_creditability[2])","73493bdf":"#I changed (i to 1) in data=pdlst_creditability[i]) to avoid error \"list out of index\". Though the messy \"chart\" below.","d97c1cde":"#Frequency Domain Creditability Data Analysis","7310a30e":"#I gave up since the charts are not what I expected.","c781eb61":"#I grouped since the charts were very messy with all data. Now, the charts are clear with less features."}}