{"cell_type":{"7718ca8e":"code","69f9f62d":"code","421d6ea3":"code","7a7a1275":"code","bdd5f145":"code","32e4bd95":"code","2dba40d9":"code","68ef6392":"code","3a6fcbba":"code","878cef2b":"code","7b694252":"code","373ebb09":"code","425d45ca":"code","6da4569d":"code","2ffb4a9f":"code","fa38a24d":"code","d7d65c02":"code","c813b8ae":"code","41555e62":"code","d63381ac":"code","b3ab51b4":"code","1a2d1648":"code","d347c70c":"code","8a604be0":"code","3c05ed12":"code","8070543e":"code","e808ac56":"code","b036f4de":"code","69205e6d":"code","7feaedb3":"code","cba5862a":"code","6ef2cb36":"code","eb1f822e":"code","2adb62cc":"code","df77bc9f":"code","847c64a9":"code","e77b19bc":"code","943ef9b4":"markdown","20236199":"markdown","a9b1beb7":"markdown","ea5b54d5":"markdown","dd15efe1":"markdown","66fe3722":"markdown","a30948df":"markdown","8b03fefc":"markdown","fd78e7e6":"markdown","f2d021f6":"markdown","5be7a6f0":"markdown","dd63a8b1":"markdown","ff5de314":"markdown","809dfab2":"markdown","61a6e1aa":"markdown","b2c95b47":"markdown","3a51bf1e":"markdown","b66e5b5d":"markdown","b29e514b":"markdown","2655d097":"markdown","e8700bbe":"markdown","2adf068c":"markdown","257ff6e4":"markdown","2087d0ac":"markdown","d2fc288c":"markdown","67e8b6d0":"markdown","2a5f7f8c":"markdown","8b85e471":"markdown","ed537d4b":"markdown","38728630":"markdown","fe0ecf83":"markdown","7f87a747":"markdown","24c91d9a":"markdown"},"source":{"7718ca8e":"import os \nimport torch\nimport numpy as np \nimport pandas as pd \nimport datatable as dt\nimport seaborn as sns \nimport matplotlib.pyplot as plt # ploting\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nimport torch.optim as optim\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(\"Packages Imported \")","69f9f62d":"train_data= pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/train.csv')\ntest_data= pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/test.csv')\nprint(\"Data imported\")","421d6ea3":"# shout out to this discussion (((https:\/\/www.kaggle.com\/c\/tabular-playground-series-oct-2021\/discussion\/275854)))\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df\n","7a7a1275":"train = reduce_mem_usage(train_data)\ntest = reduce_mem_usage(test_data)","bdd5f145":"train_data.head()","32e4bd95":"\n\nprint(f'Number of rows: {train_data.shape[0]};  Number of columns: {train_data.shape[1]}; No of missing values: {sum(train_data.isna().sum())}')","2dba40d9":"Counter(train_data.info())","68ef6392":"train_data.describe().style.background_gradient(cmap='coolwarm')","3a6fcbba":"# variables variaition   \ndf_var=train.var().reset_index()\ndf_var.columns =['feature', 'variation']\ndf_var.sort_values(\"variation\",ascending = False)","878cef2b":"# Correlationmatrix\ncorrMatrix =train_data.corr(method='pearson', min_periods=1)\ncorrMatrix","7b694252":"cor_targ = train.corrwith(train[\"target\"]).reset_index()\ncor_targ.columns =['feature', 'CorrelatioWithTarget']\ncor_targ.sort_values('CorrelatioWithTarget',ascending = False)\n","373ebb09":"print('percentage of claim values:')\npercent_value = pd.DataFrame(train_data['target'].value_counts()\/len(train_data))\npercent_value.T","425d45ca":"countplt, ax = plt.subplots(figsize = (8,5))\nax =sns.countplot(train_data['target'],palette=\"GnBu_r\")","6da4569d":"test_data.head()","2ffb4a9f":"print(f'Number of rows: {test_data.shape[0]};  Number of columns: {test_data.shape[1]}; No of missing values: {sum(test_data.isna().sum())}')","fa38a24d":"print('Info about test data: ')\ntest_data.info()","d7d65c02":"test_data.describe().style.background_gradient(cmap='YlOrRd')","c813b8ae":"plt.figure(figsize=(15,8))\nfeatures = train.columns.values[2:286]\nsns.distplot(train[features].mean(axis=1),color=\"green\", kde=True,bins=120, label='train')\nsns.distplot(test[features].mean(axis=1),color=\"darkblue\", kde=True,bins=120, label='test')\nplt.title(\"Distribution of mean values per row in the train and test data\")\nplt.legend()\nplt.show()","41555e62":"plt.figure(figsize=(15,5))\nsns.distplot(train[features].mean(axis=0),color=\"orange\",kde=True,bins=120, label='train')\nsns.distplot(test[features].mean(axis=0),color=\"blue\", kde=True,bins=120, label='test')\nplt.title(\"Distribution of mean values per column in the train and test set\")\nplt.legend()\nplt.show()","d63381ac":"plt.figure(figsize=(15,5))\nsns.distplot(train[features].std(axis=1),color=\"#2F4F4F\", kde=True,bins=120, label='train')\nsns.distplot(test[features].std(axis=1),color=\"#FF6347\", kde=True,bins=120, label='test')\nplt.title(\"Distribution of std per row in the train and test data \")\nplt.legend()\nplt.show()","b3ab51b4":"plt.figure(figsize=(15,5))\nsns.distplot(train[features].std(axis=0),color=\"#778899\",kde=True,bins=120, label='train')\nsns.distplot(test[features].std(axis=0),color=\"#800080\", kde=True,bins=120, label='test')\nplt.title(\"Distribution of std per column in the train and test data\")\nplt.legend()\nplt.show()","1a2d1648":"features = train.iloc[:,1:138] # loc features \ni = 1\nplt.figure()\nfig, ax = plt.subplots(figsize=(28, 28))\nfor feature in features:\n    plt.subplot(28, 5,i)\n    sns.distplot(train[feature],color=\"blue\", kde=True,bins=120, label='train')\n    sns.distplot(test[feature],color=\"orange\", kde=True,bins=120, label='test')\n    i += 1\n    \nplt.legend()\nplt.show()","d347c70c":"features = train.iloc[:,138:286] # loc features \ni = 1\nplt.figure()\nfig, ax = plt.subplots(figsize=(28, 28))\nfor feature in features:\n    plt.subplot(30, 5,i)\n    sns.distplot(train[feature],color=\"blue\", kde=True,bins=120, label='train')\n    sns.distplot(test[feature],color=\"orange\", kde=True,bins=120, label='test')\n    i += 1\n    \nplt.legend()\nplt.show()","8a604be0":"#install tabnet \n!pip install pytorch-tabnet","3c05ed12":"# import tabnetmodules \nfrom pytorch_tabnet.pretraining import TabNetPretrainer\nfrom pytorch_tabnet.tab_model import TabNetRegressor ","8070543e":"# delete unused df\ndel train_data\ndel test_data ","e808ac56":"#Data preparation \ny = train[\"target\"]\nignore_id = 'id'\nfeatures = [ col for col in train.columns if col not in [\"id\",\"target\"]]\nX = train [[*features]]\ntest = test[[*features]]","b036f4de":"scaler = MinMaxScaler(feature_range=(-1, 1))\nX_norma =  scaler.fit_transform(X)\ntest_norma = scaler.transform(test)","69205e6d":"X_train, X_valid, y_train, y_valid= train_test_split(X_norma, y, test_size=0.25, random_state=42)","7feaedb3":"# preparing tabnet input values\n#X_train  = X_train.to_numpy()  \n#X_valid = X_valid.to_numpy()\ny_train = y_train.to_numpy().reshape(-1, 1) \ny_valid = y_valid.to_numpy().reshape(-1,1)\n# labelencoder for target when using Tabnet classifier \n#y_train= LabelEncoder().fit_transform(np.ravel(y_train))\n#y_valid = LabelEncoder().fit_transform(np.ravel(y_valid))","cba5862a":"# TabNetPretrainer definition \npretrainer = TabNetPretrainer(\n    n_d=8, \n    n_a=8,\n    n_steps=1,\n    optimizer_fn=torch.optim.Adam,\n    optimizer_params=dict(lr=2e-3),\n    mask_type='entmax', \n    n_shared=1, \n    n_independent=1, \n)","6ef2cb36":"# fit tabnet pretrainer \npretrainer.fit(\n    X_train=X_train,\n    eval_set=[X_valid],\n    max_epochs=100 , patience=10,\n    batch_size=1024, virtual_batch_size=64,\n    num_workers=0,\n    drop_last=False,\n    pretraining_ratio=0.55,\n\n)","eb1f822e":"# tabnet cllassifier definition \nmax_epochs = 100\nBs = 2048*10\nvBs = 256*10\nclf = TabNetRegressor( \n                       gamma = 1.5 ,\n                       lambda_sparse=1e-2,\n                       optimizer_fn=torch.optim.Adam,\n                       optimizer_params=dict(lr=2e-2,weight_decay=1e-5),\n                       scheduler_params={\"step_size\":5,\n                                         \"gamma\":0.9},\n                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n                       mask_type='entmax' \n                      )","2adb62cc":"# training ,validating and predicting \nclf.fit( \n        X_train=X_train, y_train=y_train,\n        eval_set=[(X_valid, y_valid)],\n        eval_name=['valid'],\n        max_epochs=max_epochs,\n        patience=10,\n        batch_size=Bs, virtual_batch_size=vBs,\n        num_workers=0,\n        drop_last=False,\n        from_unsupervised = pretrainer # loading weights from pretrainer model \n           )","df77bc9f":"plt.plot(clf.history['valid_mse'])","847c64a9":"#  predictions  for the test data \n#test = test.to_numpy()\npredictions =  clf.predict(test_norma)","e77b19bc":"sample = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/sample_submission.csv' ) # read sample submission \npredictions = pd.DataFrame(predictions) # from array to dataframe\nsample['target'] = predictions\nsample.to_csv('tabnet_submission.csv',index=False) # save submission\nsample.head() # check submision header.\n","943ef9b4":"For this competition we will use  pytorch-tabnet from [Dreamquark](https:\/\/github.com\/dreamquark-ai\/tabnet) , you can read about the original paper [Here](https:\/\/arxiv.org\/pdf\/1908.07442.pdf). \n\nPlease refer to [Selfsupervised tabnet notebook](https:\/\/www.kaggle.com\/optimo\/selfsupervisedtabnet) if you want to learn about tabnetPretrainer. Even though this is a classification problem for this version i will treat it as a regressor problem using TabnetRegressor which appears to give more high public score ( in a typical classifaction problem you would use TabnetClassifer. Check the first five versions )  \n\n\n","20236199":"#### Predictions ","a9b1beb7":"#### Basic summary statistic","ea5b54d5":"\n#### basic summary statistics ","dd15efe1":"#### Data preparation ","66fe3722":"##### valid mse history","a30948df":"<a id=\"1\"><\/a>\n<h2 style='background:#1777C4; border:0; color:white'> <center> Load data<\/center><\/h2>","8b03fefc":"Kaggle competitions are incredibly fun and rewarding, but they can also be intimidating for people who are relatively new in their data science journey. In the past, kaggle team have launched many Playground competitions that are more approachable than Featured competitions and thus, more beginner-friendly.\n<p> \nFor this competition, we will be predicting a binary target based on a number of feature columns given in the data. The columns are a mix of scaled continuous features and binary features.","fd78e7e6":"#### Read Data ","f2d021f6":"#### Reduce memory usage","5be7a6f0":"<a id=\"1\"><\/a>\n<h2 style='background:#1777C4; border:0; color:white'><center>About the data<\/center><\/h2>\n\n  The data consists of three files :\n* train.csv - the training data with the target column\n* test.csv - the test set; you will be predicting the target for each row in this file (the probability of the binary target)\n* sample_submission.csv - a sample submission file in the correct format","dd63a8b1":"#### dara type ","ff5de314":"#### Submission ","809dfab2":"we can see that train and test features have similar distribution.\n","61a6e1aa":"### Final thoughts\n* This is just a baseline submission over which a lot of improvement can be made including model parameters tuning and using Kfold training.\n* There is always need for Feature Engineering and  feature Selection in order to achieve high score.\n* TabnetRegressor does better then TabnetClassifer even this is a classification problem ( diffrence of 0.8 auc score .. ) ","b2c95b47":"We have a balanced class problem.","3a51bf1e":"#### Feature Distribution ","b66e5b5d":"#### Features Variation","b29e514b":"The test data has 500000 rows , 286 columns ( what did you thought xD) and zero missing values ","2655d097":"<div class=\"alert alert-info\">\n  <h2><center>  I hope you find this useful , Thank you \ud83d\ude4f <\/h2><\/center>\n<\/div>","e8700bbe":"#### Correlation with the target","2adf068c":"<a id=\"1\"><\/a>\n<h2 style='background:#1777C4; border:0; color:white'><center>TabNet : Attentive Interpretable Tabular Learning<\/center><\/h2>","257ff6e4":"<a id=\"1\"><\/a>\n<h2 style='background:#1777C4; border:0; color:white'><center>Overview<\/center><\/h2>\n","2087d0ac":"# <h1> <center> Tabular Playground Series - Oct 2021<\/center><\/h1>\n\n   ![Capture.jpg](attachment:c907bb1d-04b6-4744-a126-3508b29d2168.jpg)","d2fc288c":"The train data has 1000000 rows , 287 columns ( we have quite a lot of features ) and no missing values ","67e8b6d0":"<a id=\"1\"><\/a>\n<h2 style='background:#1777C4; border:0; color:white'><center> Notebook Set Up<\/center><\/h2>","2a5f7f8c":"#### Target variable \nThe target for this Competition is binary valued, let's check the distribution of values \n\n","8b85e471":"#### Correlation matrix","ed537d4b":"Some features have very low variation maybe we will consider removing them.\n","38728630":"There 46 Boolean values , 240 float16 and one int32 ","fe0ecf83":"<a id=\"1\"><\/a>\n<h2 style='background:#1777C4; border:0; color:white'> <center> Explorotary Data Analysis<\/center><\/h2>\nWe first take a look at our dataframes ( train and test ). after that we will establish a baseline. \n<h3> Train data First look  <h3> ","7f87a747":"#### Distribution of mean and std\nwe want to see the distribution of the mean and standard deviation values per row and column in the train and test data .","24c91d9a":"### Test Data First look"}}