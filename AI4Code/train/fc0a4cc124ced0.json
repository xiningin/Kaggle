{"cell_type":{"8a05209e":"code","e3162e65":"code","1128c2fd":"code","ab9031c3":"code","9b6e2aaf":"code","45d4a1fb":"code","fa652e14":"code","6ded7e43":"code","269fec71":"code","89f244d2":"code","fbf78504":"code","97967b0d":"code","79128509":"code","3e0bd755":"code","dce290a5":"code","5cd68a0b":"code","09019cb9":"code","dcadf67c":"code","7c60023a":"code","6d2a1a62":"code","744dbb15":"code","ad39f72e":"code","437ccfc6":"code","4793fe9e":"code","7d679b4d":"code","868f8fb7":"code","6908a2a8":"code","9419cf87":"code","eb5e1050":"code","d664891f":"code","6d2440e7":"code","c5b1ee0f":"code","f224757e":"code","79a17fcb":"code","8de86835":"code","dda54c0a":"code","e25d19cf":"code","b5f5b3d2":"code","688447b1":"code","5415e20e":"code","c2625f0e":"code","e375b91d":"code","edac638a":"code","a4d81b73":"code","7c8ee883":"code","dbf5a2f0":"code","5b57a87f":"code","1125c2ab":"code","9e714882":"code","0898d93d":"markdown","a753dc1e":"markdown","3b3465bf":"markdown","8be1940d":"markdown","22726093":"markdown","9de3777d":"markdown","c6057ff6":"markdown","e12f8f65":"markdown","95845acc":"markdown","b345532f":"markdown","ae0e90f2":"markdown","f1b0014e":"markdown","33e4fe2e":"markdown","f9bfa325":"markdown"},"source":{"8a05209e":"import tensorflow as tf\nimport tensorflow_hub as hub\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nprint(\"TensorFlow Version:\", tf.__version__)","e3162e65":"!nvidia-smi","1128c2fd":"import os\n\nfor dirpath, dirname, images in os.walk(\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\"):\n    print(f\"There are {len(dirname)} directories with {len(images)} images in {dirpath}\")","ab9031c3":"import random\nimport matplotlib.image as mpimg\n\ndef view_random_images(target_path, target_class):\n    \n    target_folder = target_path + \"\/\" + target_class\n    \n    random_image = random.sample(os.listdir(target_folder),1)\n    print(random_image)\n    \n    # Read image\n    image = mpimg.imread(target_folder+\"\/\"+ random_image[0])\n    plt.imshow(image)\n    plt.title(target_class)\n    plt.axis('off')\n    plt.show()\n    \n    return image\n    \n    ","9b6e2aaf":"dir_path = \"..\/input\/chest-xray-pneumonia\/chest_xray\/train\"\n\n# Let's look at Normal image\nimg = view_random_images(dir_path, 'NORMAL')\n\n# Let's look at Pneumonia image\nimg = view_random_images(dir_path, \"PNEUMONIA\")","45d4a1fb":"IMAGE_SIZE= (224, 224)\nBATCH_SIZE = 32\n\n\nprint(\"Training Dataset.....\")\ntrain_dir = tf.keras.preprocessing.image_dataset_from_directory(dir_path,\n                                                               image_size=IMAGE_SIZE,\n                                                               batch_size=BATCH_SIZE,\n                                                               label_mode='binary')\n\nval_dir_path = \"..\/input\/chest-xray-pneumonia\/chest_xray\/val\"\n\nprint(\"Val Dataset....\")\nval_dir = tf.keras.preprocessing.image_dataset_from_directory(val_dir_path,\n                                                             image_size=IMAGE_SIZE,\n                                                             batch_size=BATCH_SIZE,\n                                                             label_mode='binary')\n\ntest_dir_path = \"..\/input\/chest-xray-pneumonia\/chest_xray\/test\"\nprint(\"Test Datast...\")\ntest_dir = tf.keras.preprocessing.image_dataset_from_directory(test_dir_path,\n                                                              image_size=IMAGE_SIZE,\n                                                              batch_size=BATCH_SIZE,\n                                                              label_mode='binary')","fa652e14":"# Check the Class names\nclass_names = train_dir.class_names\nclass_names","6ded7e43":"# Checking the images and labels in train_dir\nfor images, labels in train_dir.take(1):\n    images = images[0]\/255.\n    print(images)","269fec71":"# Pretech to our required directories\ntrain_ds = train_dir.prefetch(tf.data.AUTOTUNE)\nval_ds = val_dir.prefetch(tf.data.AUTOTUNE)\ntest_ds = test_dir.prefetch(tf.data.AUTOTUNE)","89f244d2":"train_ds","fbf78504":"# Early Stopping Callbacks\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n                                                 patience=3)","97967b0d":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n\n# Baseline model\nmodel_0 = Sequential([\n    Conv2D(16, 3, activation='relu', input_shape=(224,224,3)),\n    MaxPool2D(),\n    Dropout(0.5),\n    Conv2D(16, 3, activation='relu'),\n    MaxPool2D(),\n    Dropout(0.5),\n    Flatten(),\n    Dense(1, activation='sigmoid')\n])\n\n# Compile the model\nmodel_0.compile(loss='binary_crossentropy',\n               optimizer='adam',\n               metrics=['accuracy'])\n\n# Get the summary\nmodel_0.summary()","79128509":"# fit the model\nhistory_model_0 = model_0.fit(train_ds,\n                           epochs=5,\n                           validation_data=val_ds,\n                           callbacks=[early_stopping])","3e0bd755":"# Plot the loss curves\ndef plot_loss_curves(history):\n    \n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(acc) + 1)\n\n\n    plt.plot(epochs, acc,  label='Training acc')\n    plt.plot(epochs, val_acc,  label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n    plt.figure()\n\n\n    plt.plot(epochs, loss,  label='Training loss')\n    plt.plot(epochs, val_loss, label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n    plt.show()","dce290a5":"plot_loss_curves(history_model_0)","5cd68a0b":"model_1 = Sequential([\n    Conv2D(16, 3, activation='relu', input_shape=(224,224,3)),\n    MaxPool2D(),\n    Dropout(0.5),\n    Conv2D(16,3,activation='relu'),\n    MaxPool2D(),\n    Dropout(0.5),\n    Flatten(),\n    Dense(1, 'sigmoid')\n])\n\n# compile\nmodel_1.compile(loss='binary_crossentropy',\n               optimizer='adam',\n               metrics=['accuracy'])\n\n# Get summary\n\nmodel_1.summary()","09019cb9":"# Fit the model\nhistory_model_1 = model_1.fit(train_ds, \n                             epochs=5,\n                             validation_data=val_ds,\n                             callbacks=[early_stopping])","dcadf67c":"plot_loss_curves(history_model_1)","7c60023a":"# use mobilnet model\nbaseline_model = tf.keras.applications.mobilenet.MobileNet(include_top=False)\nbaseline_model.training = False\n\n# Input Shape\ninputs = tf.keras.Input(shape=(224,224,3), name='Input_shape')\n\n# Pass Input shape to our Baseline_model\nx = baseline_model(inputs)\n\n# Resscaling\nx = tf.keras.layers.experimental.preprocessing.Rescaling(1\/255.)(x)\n\n# Dropout\nx = tf.keras.layers.Dropout(0.5)(x)\n\n# GlobalAveragePooling2D\nx = tf.keras.layers.GlobalAveragePooling2D(name='global_average_pooling_2d')(x)\n\n# Dense layer\noutputs = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')(x)\n\n# Build model\nmodel_2 = tf.keras.Model(inputs, outputs)\n\n# compile the model\nmodel_2.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n               optimizer=tf.keras.optimizers.Adam(),\n               metrics=['accuracy'])\n\n# summary\nmodel_2.summary()","6d2a1a62":"history_model_2 = model_2.fit(train_ds,\n                             epochs=5,\n                             validation_data=val_ds,\n                             callbacks=[early_stopping])","744dbb15":"plot_loss_curves(history_model_2)","ad39f72e":"# use another model\nbaseline_model = tf.keras.applications.efficientnet.EfficientNetB0(include_top=False)\nbaseline_model.trainable = False\ninputs = tf.keras.Input(shape=(224,224,3)) # Input shape\nx = baseline_model(inputs) # Pass inputs to baseline_model\nx = tf.keras.layers.GlobalMaxPooling2D()(x) \nx = tf.keras.layers.Dropout(0.6)(x)\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(x) # outputs\nmodel_3 = tf.keras.Model(inputs, outputs) # Build model\nmodel_3.compile(loss='binary_crossentropy',\n               optimizer='adam',\n               metrics=['accuracy'])\nmodel_3.summary() # summary\n","437ccfc6":"history_model_3  = model_3.fit(train_ds,\n                              epochs=5,\n                              validation_data=val_ds,\n                              callbacks=[early_stopping])","4793fe9e":"plot_loss_curves(history_model_3)","7d679b4d":"# model_3 layers\nmodel_3.layers","868f8fb7":"baseline_model.layers","6908a2a8":"# Checking our baseline_model layers (trainable or not)\nfor layer_number, layer in enumerate(baseline_model.layers):\n    print(layer_number, layer.name, layer.trainable)","9419cf87":"# UnFreeze all layers in 'EfficientNetB0'\nbaseline_model.trainable = True\n\n# Freeze last 15 layers\nfor layer in baseline_model.layers[:-15]:\n    layer.trainable = False\n","eb5e1050":"# Check again layers\nfor layer_number, layer in enumerate(baseline_model.layers):\n    print(layer_number, layer.name, layer.trainable)","d664891f":"# Recompile the model\nmodel_3.compile(loss='binary_crossentropy',\n               optimizer='adam',\n               metrics=['accuracy'])","6d2440e7":"# Summary\nmodel_3.summary()","c5b1ee0f":"# Refit the model\nhistory_model_3_fine_tune = model_3.fit(train_ds,\n                                       epochs=10,\n                                       validation_data=val_ds,\n                                       initial_epoch=history_model_3.epoch[-1],\n                                       callbacks=[early_stopping])","f224757e":"# Get helper functions\n!wget https:\/\/raw.githubusercontent.com\/mrdbourke\/tensorflow-deep-learning\/main\/extras\/helper_functions.py","79a17fcb":"from helper_functions import compare_historys","8de86835":"compare_historys(history_model_3, history_model_3_fine_tune)","dda54c0a":"# Evaluate on Test Dataset\nmodel_3.evaluate(test_ds)","e25d19cf":"# Custom image\n!wget https:\/\/media.sciencephoto.com\/image\/c0272491\/800wm\/C0272491-Pneumonia,_Chest_X-ray.jpg\n    ","b5f5b3d2":"pneumonia = plt.imread(\"C0272491-Pneumonia,_Chest_X-ray.jpg\")\nplt.imshow(pneumonia)\nplt.axis(False);","688447b1":"pneumonia.shape","5415e20e":"def load_and_prep_image(filename, img_shape=224,scale=True):\n    \n  # Read in target file (an image)\n    img = tf.io.read_file(filename)\n\n  # Decode the read file into a tensor & ensure 3 colour channels \n  # (our model is trained on images with 3 colour channels and sometimes images have 4 colour channels)\n    img = tf.image.decode_image(img, channels=3)\n\n  # Resize the image (to the same size our model was trained on)\n    img = tf.image.resize(img, size = [img_shape, img_shape])\n\n  # Rescale the image (get all values between 0 and 1)\n    img = img\/255.\n    return img","c2625f0e":"pneumonia = load_and_prep_image(\"C0272491-Pneumonia,_Chest_X-ray.jpg\")","e375b91d":"pneumonia","edac638a":"# Add extra dimension\nprint(f\"Shape before new dimension: {pneumonia.shape}\")\npneumonia = tf.expand_dims(pneumonia, axis=0) # add an extra dimension at axis 0\nprint(f\"Shape after new dimension : {pneumonia.shape}\")\npneumonia","a4d81b73":"# Make Predictions\npred = model_3.predict(pneumonia)\npred","7c8ee883":"# Prediction Class Names\npred_class = class_names[int(tf.round(pred))]\npred_class","dbf5a2f0":"def pred_and_plot(model, filename, class_names):\n    \n    \"\"\"\n    Imports an image located at filename, makes a prediction on it with\n    a trained model and plots the image with the predicted class as the title.\n    \"\"\"\n    # Import the target image and preprocess it\n    img = load_and_prep_image(filename)\n\n    # Make a prediction\n    pred = model.predict(tf.expand_dims(img, axis=0))\n\n    # Get the predicted class\n    pred_class = class_names[int(tf.round(pred))]\n\n    # Plot the image and predicted class\n    plt.imshow(img)\n    plt.title(f\"Prediction: {pred_class}\")\n    plt.axis(False);","5b57a87f":"pred_and_plot(model_3, \"C0272491-Pneumonia,_Chest_X-ray.jpg\", 'PNEUMONIA')","1125c2ab":"pred_class = class_names[int(tf.round(pred))]\npred_class","9e714882":"# Make preds on a series of random images\nimport os\nimport random\n\nplt.figure(figsize=(17, 10))\nfor i in range(3):\n     \n    # Choose a random image from a random class \n    class_name = random.choice(class_names)\n    test_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/test\"\n    filename = random.choice(os.listdir(test_dir + \"\/\" + class_name))\n    filepath = test_dir + '\/' + class_name + \"\/\" + filename\n\n    # Load the image and make predictions\n    \n    img = load_and_prep_image(filepath, scale=False) # don't scale images for EfficientNet predictions\n    pred_prob = model_3.predict(tf.expand_dims(img, axis=0)) # model accepts tensors of shape [None, 224, 224, 3]\n    pred_class = class_names[pred_prob.argmax()] # find the predicted class \n\n    # Plot the image(s)\n    plt.subplot(1, 3, i+1)\n    img = img\/255.\n    img = mpimg.imread(filepath)\n    plt.imshow(img)\n    if class_name == pred_class: # Change the color of text based on whether prediction is right or wrong\n      title_color = \"g\"\n    else:\n      title_color = \"r\"\n    plt.title(f\"actual: {class_name}, pred: {pred_class}, prob: {pred_prob.max():.2f}\", c=title_color)\n    plt.axis(False);","0898d93d":"## Visualize the Images","a753dc1e":"## GPU Setup","3b3465bf":"## Build Model_1","8be1940d":"## Visualize It On Test Data","22726093":"## EficientNetB0","9de3777d":"## Split the dataset","c6057ff6":"## Custom Image Downloaded From Google Images","e12f8f65":"## Setup","95845acc":"## Build Model_0","b345532f":"## Use Transfer Learning With MobileNet","ae0e90f2":"# Make Predictions and Visualize It On Custom Image","f1b0014e":"## Fine-tuning With last 15 layers of the model","33e4fe2e":"## Walk throug Directories","f9bfa325":"## Prefetch Dataset"}}