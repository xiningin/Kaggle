{"cell_type":{"762c3b4c":"code","95152f52":"code","ddb0cca9":"code","306f8504":"code","64454bf4":"code","4d7203b8":"code","fc22360e":"code","3996c75f":"code","cd11300d":"code","4ab036fd":"code","3f318054":"code","e3fa6f9a":"code","0d1564b3":"code","8579944a":"code","34e4c129":"code","5207ecdc":"code","4d82eede":"code","5c0b806a":"code","47a9c71e":"code","32b815dc":"code","8ebb42a4":"code","bc048495":"code","db461c7b":"code","817e5a4b":"code","bf79c371":"code","483d7f69":"code","857e57c9":"code","f5b17829":"code","45376041":"code","688c0e4d":"code","37d0008b":"code","e2191f1d":"code","f7e051da":"code","e02ca2d8":"code","f026d4e0":"code","4940dd15":"code","34fe518b":"code","e9cea6a1":"code","91eb2152":"code","50009788":"code","97d9eb0b":"code","e2064201":"code","fd3391c2":"code","542e1310":"code","483479f1":"code","a56614ce":"markdown","99dff719":"markdown","6cf42d38":"markdown","c8252ba4":"markdown","84e1c377":"markdown","79836dfa":"markdown","1314feb2":"markdown","2956d96b":"markdown","1067898b":"markdown","2f9e3d4f":"markdown","6e659a71":"markdown","68696552":"markdown","6f26864a":"markdown","0670f7f2":"markdown","826c58b1":"markdown","046c192f":"markdown","1483731a":"markdown","deca96c1":"markdown","a76828fe":"markdown","a9e6d5e1":"markdown","edbb625c":"markdown","44801fb0":"markdown","6c6fe652":"markdown","fde4c281":"markdown"},"source":{"762c3b4c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Using Fake and Real news datasets\nimport pandas as pd\nimport re\ndata_true =pd.read_csv(\"..\/input\/fake-and-real-news-dataset\/True.csv\")\ndata_fake =pd.read_csv(\"..\/input\/fake-and-real-news-dataset\/Fake.csv\")","95152f52":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer","ddb0cca9":"print(data_true.shape)\nprint(data_true.columns)\ndata_true[\"Target\"]=\"True\"","306f8504":"data_true.head(2)","64454bf4":"print(data_fake.shape)\nprint(data_fake.columns)\ndata_fake[\"Target\"]=\"Fake\"","4d7203b8":"data_fake.head(2)","fc22360e":" df=pd.concat([data_true, data_fake], ignore_index=True)\nprint(df.shape)\ndf.head()","3996c75f":"fig=plt.figure(figsize=[12,9])\nfig.patch.set_facecolor('#E0E0E0')\nfig.patch.set_alpha(0.7)\n\nplt.title(\"Subjects\",size=18)\nsns.countplot(data=df, x=\"subject\",hue=\"Target\")","cd11300d":"print(df[\"subject\"].unique())","4ab036fd":"def encode_subject(label):\n    if label  in [\"politicsNews\",'politics' ,'Government News','left-news']:\n        return \"politics\"\n    elif label  in ['worldnews' ,'News']:\n        return \"world news\"\n    else:\n        return \"US_News\"\n\ndf[\"subject\"]=df[\"subject\"].apply(encode_subject) ","3f318054":"fig=plt.figure(figsize=[10,7])\nfig.patch.set_facecolor('#E0E0E0')\nfig.patch.set_alpha(0.7)\n\nplt.title(\"Subjects\",size=18)\nsns.countplot(data=df, x=\"subject\",hue=\"Target\", palette=\"Set3\",edgecolor=\"black\")","e3fa6f9a":"df=df.loc[df[\"subject\"]!=\"US_News\"]","0d1564b3":"import nltk\n\ndef count_words(title):\n    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n    new_words = tokenizer.tokenize(title)\n    return len(new_words)\ndf[\"n_words in title\"]=df[\"title\"].apply(count_words)\n","8579944a":"fig=plt.figure(figsize=[8,5])\nfig.patch.set_facecolor('#E0E0E0')\nfig.patch.set_alpha(0.7)\n\nplt.title(\"Number of words in the title.\",size=18)\nsns.boxplot(data=df, x=\"Target\",y=\"n_words in title\",showfliers=False,width=0.4,color=\"#a5acce\")","34e4c129":"df[\"n_words in text\"]=df[\"text\"].apply(count_words)","5207ecdc":"fig=plt.figure(figsize=[8,5])\nfig.patch.set_facecolor('#E0E0E0')\nfig.patch.set_alpha(0.7)\n\nplt.title(\"Number of words in the text.\",size=18)\nsns.boxplot(data=df, x=\"Target\",y=\"n_words in text\",showfliers=False,width=0.4,color=\"#a5acce\")\nplt.grid()","4d82eede":"def get_sample(N,df):\n    n =df.shape[0]\n    p =N\/n\n    sample=df.sample(frac=p, replace=True)\n    print(\"A {} rows sample as been extracted.\".format(N))\n    return sample\nsample=get_sample(6000,df)","5c0b806a":"sample.head(2)","47a9c71e":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n\ny=sample[\"Target\"]\nX=sample.drop(columns=[\"Target\"])\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","32b815dc":"from nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\n\n\ndef a_number(word):\n    for letter in word:\n        if str(letter)in [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]:\n            return True\ndef not_a_word(word):\n    if len(word)==1:\n        return True\n    elif a_number(word):\n        return True\n    else:\n        return False\n\ndef extract_corpus(col,df):\n    snowstem = SnowballStemmer(language=\"english\")\n    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n    stop_words = set(stopwords.words(\"english\"))\n    \n    stop_word2=[\"for\",\"is\",\"a\",\"of\",\"no\",\"not\",\"he\",\"she\",\n                \"this\",\"on\",\"it\",\"to\",\"in\",\"at\",\"is\", \"or\",\n                \"in\",\"not\",\"by\",\"if\",\"in\"]\n    stop_words= stop_words.union(stop_word2)\n    corpus = []\n    text_list=df[col].values\n    \n    for text in text_list:\n        text=tokenizer.tokenize(text)\n        review = [snowstem.stem(word.lower()) for word in text if not word in stop_words]\n        review=[word for word in review if not_a_word(word)==False]\n        review = ' '.join(review)\n        \n        corpus.append(review)\n    return corpus\n\n","8ebb42a4":"from sklearn import decomposition\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\ndef nbr_of_pca(features):\n    scaler=StandardScaler() \n    Xs=scaler.fit_transform(features)\n    \n\n    # apply PCA\n    pca = decomposition.PCA(n_components=min(features.shape[1],\n                                             features.shape[0])).fit(Xs)\n    nbr_pca=0\n    scree = pca.explained_variance_ratio_\n    for i in range(features.shape[1]):\n        a = scree.cumsum()[i]\n        if a >= 0.6:\n            print(\"{} principal components explaines  60% of the total variance\".format(i))\n            print(\"Sum of variance explained :{}%\".format(round(a*100,2)))\n            nbr_pca=i\n            break\n    pca = decomposition.PCA(n_components=nbr_pca)\n    \n    return pca,nbr_pca","bc048495":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport scipy.sparse\n\ndef preprocess_train_set(train):\n    ref=train[[\"subject\",\"n_words in title\",\"n_words in text\"]]\n    \n    #create corpus to fit vectorizer\n    corpus=extract_corpus(\"title\",train)\n    vectorizer = TfidfVectorizer()\n    features = vectorizer.fit_transform(corpus)\n    #features to pandas data frame\n    features=pd.DataFrame(features.todense())\n    \n    #Apply PCA with the right number of component to keep \n    #60% of de explained variance\n    scaler=StandardScaler() \n    Xs=scaler.fit_transform(features)\n    pca,N=nbr_of_pca(features)\n    d=pca.fit_transform(Xs)\n    \n    d=pd.DataFrame(d, columns=[\"Title PCA n\u00b0{}\".format(i+1) for i in range(0,N) ])\n    for i in d.columns:\n        ref[i]=d[i].values\n    ref=pd.get_dummies(data=ref, columns=[\"subject\"])\n    #Return the pca and vectoriver fitted ,\n    # + the number of principal component and the data preprocessed\n    return pca,N,vectorizer, ref\n    ","db461c7b":"def preprocess_test(vectorizer,pca,N,test):\n    ref=test[[\"subject\",\"n_words in title\",\"n_words in text\"]]\n    corpus=extract_corpus(\"title\",test)\n    #Vectorizer already fitted on the train set \n    features = vectorizer.transform(corpus)\n    features=pd.DataFrame(features.todense())\n    \n    scaler=StandardScaler() \n    Xs=scaler.fit_transform(features)\n    #PCA already fitted on the train set\n    d=pca.transform(Xs)\n    \n    d=pd.DataFrame(d, columns=[\"Title PCA n\u00b0{}\".format(i+1) for i in range(0,N) ])\n    for i in d.columns:\n        ref[i]=d[i].values\n    ref=pd.get_dummies(data=ref, columns=[\"subject\"])\n    return ref","817e5a4b":"pca,N,vectorizer, Xtrain=preprocess_train_set(X_train)","bf79c371":"\nXtest=preprocess_test(vectorizer,pca,N,X_test)","483d7f69":"print(\"Trainning set:\")\nprint(Xtrain.shape[0],'Rows',Xtrain.shape[1],\"columns\")","857e57c9":"print(\"Testing set:\")\nprint(Xtest.shape[0],'Rows',Xtest.shape[1],\"columns\")","f5b17829":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\n\ndef lets_try(train, y):\n    results = {}\n    ss=StandardScaler()\n    scaled_train=ss.fit_transform(train)\n    \n   \n    def test_model(clf):\n        cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n        scores = cross_val_score(clf, train, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n        return scores\n\n    #for the model which needed standardized data \n    def test_model_scaler(clf):\n    \n        cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n        scores = cross_val_score(clf, scaled_train, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n        return scores\n    \n    clf = SVC(kernel=\"linear\")\n    results[\"SVC\"] = test_model_scaler(clf)\n    print(\"SVC done\")\n    \n    clf = LogisticRegression()\n    results[\"Logistic Regression\"] = test_model_scaler(clf)\n    print(\"Logistic Regression done\")\n\n    clf = KNeighborsClassifier()\n    results[\"Kneighbors\"] = test_model(clf)\n    print(\"Kneighbors done\")\n\n    clf = SVC(kernel=\"poly\")\n    results[\"SVC poly\"] = test_model_scaler(clf)\n    print(\"SVC poly done.\")\n\n    clf = RandomForestClassifier()\n    results[\"Random Forest Classifier\"] = test_model(clf)\n    print(\"Random Forest Classifier done\")\n\n\n    clf =SVC(kernel='rbf')\n    results[\"SVC RBF\"] = test_model_scaler(clf)\n    print(\"SVC rbf done\")\n\n   \n    return results ","45376041":"dic_results=lets_try(Xtrain, y_train)","688c0e4d":"fig=plt.figure(figsize=[10,10])\nfig.patch.set_facecolor('#E0E0E0')\nfig.patch.set_alpha(0.7)\nplt.title(\"Distribution of Cross-validation score  on the trainning set. \\n 10 folds\",size=16)\nplt.boxplot(dic_results.values(),labels=dic_results.keys(),showmeans=True)\nplt.ylabel(\"  Scores CV \\n (Accuracy)\",size=14)\nplt.ylim(0.4,1)\nplt.xticks(rotation=90)\nplt.grid()","37d0008b":"ss=StandardScaler()\nscaled_test=ss.fit_transform(Xtest)\nscaled_train=ss.fit_transform(Xtrain)","e2191f1d":"from sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nmodel0=RandomForestClassifier()\nmodel0.fit(Xtrain,y_train)\n\nfig, ax = plt.subplots(figsize=(8, 6))\ndisp=plot_confusion_matrix(model0,Xtest, y_test\n                           , normalize='true', cmap=plt.cm.Blues, ax=ax)\ndisp.ax_.set_title(\"Results of the Random forest on the testing set\",size=14)\nplt.show()","f7e051da":"model1=LogisticRegression()\nmodel1.fit(scaled_train,y_train)\n\nfig, ax = plt.subplots(figsize=(8, 6))\ndisp=plot_confusion_matrix(model1,scaled_test, y_test\n                           , normalize='true', cmap=plt.cm.Blues, ax=ax)\ndisp.ax_.set_title(\"Results of logistic regression on the testing set\",size=14)\nplt.show()","e02ca2d8":"model=SVC(kernel='rbf')\n\nmodel.fit(scaled_train,y_train) \n\nfig, ax = plt.subplots(figsize=(8, 6))\ndisp=plot_confusion_matrix(model, scaled_test, y_test\n                           , normalize='true', cmap=plt.cm.Blues, ax=ax)\ndisp.ax_.set_title(\"Results of the SVC(rbf kernel) on the testing set\",size=14)\nplt.show()","f026d4e0":"model=SVC(kernel='linear')\n\nmodel.fit(scaled_train,y_train) \n\nfig, ax = plt.subplots(figsize=(8, 6))\ndisp=plot_confusion_matrix(model, scaled_test, y_test\n                           , normalize='true', cmap=plt.cm.Blues, ax=ax)\ndisp.ax_.set_title(\"Results of the SVC( linear) on the testing set\",size=14)\nplt.show()","4940dd15":"def convert_y_test(test):\n    y_list=[]\n    for i in test:\n        if i==\"True\":\n            y_list.append(0)\n        else:\n            y_list.append(1)\n    return pd.Series(y_list)\nY=convert_y_test(y_test)","34fe518b":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score,auc\n#reg logistic\npred_prob1 = model1.predict_proba(scaled_test)\nfpr1, tpr1, thresh1 = roc_curve(Y, pred_prob1[:,1])\n\n#random forest\npred_prob0 = model0.predict_proba(Xtest)\nfpr0, tpr0, thresh0 = roc_curve(Y, pred_prob0[:,1])\nauc0= auc(tpr0,fpr0 )\nauc1= auc(tpr1,fpr1 )","e9cea6a1":"fig=plt.figure(figsize=[6,6])\nfig.patch.set_facecolor('#E0E0E0')\nfig.patch.set_alpha(0.7)\nplt.title(\"ROC curve\",size=16)\nplt.plot(tpr1,fpr1,  linestyle='--', label='Logistic regression')\nplt.plot(tpr0,fpr0,  marker='.', label='RandomForest')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.text(0.75,0.18,\"AUC log:{} \\n AUC RF:{}\".format(round(auc1,3),round(auc0,3)))\nplt.legend()\n# show the plot\nplt.show()","91eb2152":"from sklearn.metrics import accuracy_score\n    \ndef get_processed_set(n_rows):\n    sample=get_sample(n_rows,df)\n    y=sample[\"Target\"]\n    X=sample.drop(columns=[\"Target\"])\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n    pca,N,vectorizer, Xtrain=preprocess_train_set(X_train)\n    Xtest=preprocess_test(vectorizer,pca,N,X_test)\n    return Xtrain, Xtest, y_train, y_test\n\ndef get_cv_score(train, test,y_train, y_test):\n    model=LogisticRegression()\n    ss=StandardScaler()\n    scaled_test=ss.fit_transform(test)\n    scaled_train=ss.fit_transform(train)\n    def test_model_scaled(clf):\n        cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n        scores = cross_val_score(clf,scaled_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n        return scores.mean()\n    \n    cv_score=test_model_scaled(model)\n    model.fit(scaled_train,y_train)\n    test_pred=model.predict(scaled_test)\n    score_test=accuracy_score(y_test,test_pred)\n    return cv_score, score_test\n\n    ","50009788":"train_score=[]\ntest_score=[]\nlist_n=[200,500,1000,1500,3000,4500,6000,7000,8000]\ntrain_shape=[]\nfor n in list_n:\n    #get the sets\n    Xtrain, Xtest, y_train, y_test=get_processed_set(n)\n    N=Xtrain.shape[0]\n    #Get scores values  \n    cv_score, score_test=get_cv_score(Xtrain, Xtest, y_train, y_test)\n    train_shape.append(N)\n    train_score.append(cv_score)\n    test_score.append(score_test)\n","97d9eb0b":"#Display scores\nfig=plt.figure(figsize=[10,6])\nfig.patch.set_facecolor('#E0E0E0')\nfig.patch.set_alpha(0.7)\nplt.title(\"Accuracy score according of the number \\n of rows in the trainning set \",size=16)\nplt.plot(train_shape,train_score,  linestyle='--', label='Train set ')\nplt.plot(train_shape,test_score,  marker='.', label='Test set')\nplt.xlabel(\"Number of rows\")\nplt.ylabel(\"Accuracy \")\nplt.ylim(0.7,1)\nplt.text(2500,0.72,\"The testing set represent 1\/3 of the total dataset\")\nplt.grid()\nplt.legend()","e2064201":"def convert_y_color(test):\n    y_list=[]\n    for i in test:\n        if i==\"True\":\n            y_list.append(\"#a11d31\")\n        else:\n            y_list.append(\"#4277b2\")\n    return pd.Series(y_list)\nY=convert_y_color(y_train)","fd3391c2":"from sklearn.manifold import TSNE\ntsne = TSNE(n_components=2,learning_rate=100)\nx_new=tsne.fit_transform(Xtrain)\n\nplt.scatter(x_new[:,0],x_new[:,1],c=Y)\nplt.show()","542e1310":"tsne = TSNE(n_components=3,learning_rate=100)\nx_new=tsne.fit_transform(Xtrain)\n","483479f1":"from mpl_toolkits.mplot3d import Axes3D\nfig = plt.figure(1, figsize=(8, 6))\nplt.title(\"3D Visualisation with t-SNE\")\nax = Axes3D(fig, elev=-150, azim=110)\nax.scatter(x_new[:,0],x_new[:,1],x_new[:,2], c=Y)","a56614ce":"# 3.2 Compare the best models on the testing set","99dff719":"This function is **preprocessing the train** Set and returns the **pca and the Vectorizer** fitted on this set + the processed train set","6cf42d38":"\n4 models seem very efficient on the training set:\n\n> *  **Random forest**\n> * **logistic regression**\n> * **SVC kernel rbf**\n> * **SVC kernel linear**\n\nlet's evaluate these models on the test set","c8252ba4":"The fake publications seems to have  longer titles than the true ones.","84e1c377":"Re-encode the label of the Subjects","79836dfa":" # 3.1 Compare model on the trainning set","1314feb2":"This function take the **pca and vectorizer** already fitted on the train set and returns de processed testing set .","2956d96b":"**Bonus: T-SNE visualisation .**","1067898b":"* **\"Subject\" analysis**","2f9e3d4f":"the following function tests the models on the trainning set and returns the results as a dictionary.\nWe apply a cross validation with 10 splits","6e659a71":"# 1.  Exploring the data","68696552":"# **Personal project:** Create a Fake News detector\n\nI'm going to use the two sets of fake-and-real-news-dataset to train models and detect fake new ones.\n\nI would mainly use newspaper article headlines.\n\nThis notebook consists of 3 parts\n\n**1. Exploring the Dataset**\n\n**2. feature engineering and preprocessing**\n\n**3. Classification**\n> * Compare models on the trainning set\n> * Compare the best models on the testing set\n> \n\n*I hope you will enjoy reading!!*","6f26864a":"# Upload the data sets.","0670f7f2":"we remove the rows whose subject is US_News\n","826c58b1":"# 2. Feature engineering","046c192f":"In this section i'll be worked with a 6000 rows sample.\n \nWe extract feature form the titles by using **TfidfVectorizer** .We only fit this algorithme on the trainning set, thus the test set is not used to build the model or the preprocessing methods.\n\nwe extract a large number of variables, so we apply a dimensional reduction with **PCA**\n\nFinnaly we encode the subject with **.get_dummies()**","1483731a":"#  3.  Classification .","deca96c1":"the following function returns the cleaned text corpus. remove punctuation and stopwords","a76828fe":"* **Titles and texts lenght  analysis**","a9e6d5e1":"Same approach with the all **text**","edbb625c":"# Conclusions :\nThe random Forest and the logistique regression are the most efficient models. The **logistic regression** being much faster we recommend to use it.\n\nFor the training set A sample of 4000 lines is enough to fit the TfidfVectorizer ,so that the models can then generalize in an efficient way.\n\n\nCross validation scores are much low on smaller samples","44801fb0":"> **Question:** Is there a link between the title length and the target variable?","6c6fe652":"* **HoW large have to be de train to obtain good prediction performance ?**","fde4c281":"\nthe function determines the number of principal components to generate to keep  **60% of the explained variance** \n\nReturns a PCA instance with de good number of PC."}}