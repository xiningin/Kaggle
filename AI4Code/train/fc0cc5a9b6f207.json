{"cell_type":{"29ea0730":"code","7a8dcdc3":"code","9c4c0d50":"code","658032ce":"code","fa0ccf6b":"code","dd58124b":"code","2b55c0d2":"code","c9711e4b":"code","bbea8c70":"code","d3778560":"code","bf526655":"code","2ecd3cc3":"code","afc48579":"code","a685ee01":"code","e23b39f3":"code","3078e3fc":"code","5a19f711":"code","43470791":"code","6f7496bb":"code","c381b4ab":"code","18856e03":"code","17a5c90e":"code","a923f976":"code","b1c6e76c":"code","205b3c99":"code","1013abfc":"code","aa48061e":"code","ba6c30a8":"code","d7726e21":"code","5a3d2697":"code","e3e7f336":"code","acbdbfa7":"code","5685706c":"code","025a5f04":"code","15c8feb9":"code","79745438":"markdown","1410ff2d":"markdown","828a2f4d":"markdown","c9681b69":"markdown","bad9d064":"markdown"},"source":{"29ea0730":"#import library\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport nltk\nnltk.download('stopwords')\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport re\nimport string\nstring.punctuation\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, SimpleRNN, Dense, Dropout\nfrom sklearn import metrics","7a8dcdc3":"df = pd.read_csv('..\/input\/ok-computer-reviews\/ok_computer_reviews.csv')","9c4c0d50":"df.shape","658032ce":"df.head()","fa0ccf6b":"df.describe()","dd58124b":"df.info()","2b55c0d2":"#handling missing value\ndf.dropna(inplace = True)","c9711e4b":"#selection data\ndf1 = df[['Review']]\ndf1.head()","bbea8c70":"#setting lower case\ndf1['Review_Lower'] = df1['Review'].apply(lambda x: x.lower())\ndf1.head()","d3778560":"#defining the function to remove punctuation\ndef remove_punctuation(text):\n    punctuationfree = \"\".join([i for i in text if i not in string.punctuation])\n    return punctuationfree\n\n#storing the puntuation free text\ndf1['Review_Punctual'] = df1['Review_Lower'].apply(lambda x:remove_punctuation(x))\ndf1.head()","bf526655":"#defining function for tokenization\ndef tokenization(text):\n    tokens = re.split('W+', text)\n    return tokens\n\n#applying function to the column\ndf1['Review_Tokenied'] = df1['Review_Punctual'].apply(lambda x: tokenization(x))\ndf1.head()","2ecd3cc3":"#stop words present in the library\nstopwords = nltk.corpus.stopwords.words('english')\nstopwords[0:10]","afc48579":"#defining the function to remove stopwords from tokenized text\ndef remove_stopwords(text):\n    output= [i for i in text if i not in stopwords]\n    return output\n\n#applying the function\ndf1['No_Stopwords'] = df1['Review_Tokenied'].apply(lambda x:remove_stopwords(x))\ndf1.head()","a685ee01":"#defining the object for stemming\nporter_stemmer = PorterStemmer()\n\n#defining a function for stemming\ndef stemming(text):\n    stem_text = [porter_stemmer.stem(word) for word in text]\n    return stem_text\n\n#applying the function\ndf1['Review_Stemmed'] = df1['No_Stopwords'].apply(lambda x: stemming(x))\ndf1.head()","e23b39f3":"#defining the object for lemmatizing\nword_net_lemmatizer = WordNetLemmatizer()\n\n#defining a function for stemming\ndef lemmatizing(text):\n    lemmatize_text = [word_net_lemmatizer.lemmatize(word) for word in text]\n    return lemmatize_text\n\n#applying the function\ndf1['Review_Lemmatized'] = df1['Review_Stemmed'].apply(lambda x: lemmatizing(x))\ndf1.head()","3078e3fc":"#selection data\ndf2 = df1[['Review']]\ndf2.head()","5a19f711":"#create function to get subjectivity\ndef getSubjectivity(text):\n    return TextBlob(text).sentiment.subjectivity\n\n#create function to get polarity\ndef getPolarity(text):\n    return TextBlob(text).sentiment.polarity\n\n#apply function to data \ndf2['Subjectivity'] = df2['Review'].apply(getSubjectivity)\ndf2['Polarity'] = df2['Review'].apply(getPolarity)\ndf2.head()","43470791":"#create function to get sentiment data\ndef getSentiment(score):\n    if score < 0:\n        return 'Negative'\n    elif score == 0:\n        return 'Neutral'\n    else:\n        return 'Positive'\n\n#apply function to data\ndf2['Sentiment'] = df2['Polarity'].apply(getSentiment)\ndf2.head()","6f7496bb":"#visualize positive review\npositive = \" \".join(df2[df2.Sentiment == 'Positive']['Review'].values)\nw = WordCloud(width = 700, height = 400, random_state = 10, max_font_size = 100, background_color = 'white').generate(positive)\n\nplt.figure(figsize = (10,6))\nplt.imshow(w, interpolation = \"bilinear\")\nplt.title(\"Wordcloud of Positive Review\")\nplt.axis('off')\nplt.show()","c381b4ab":"#visualize neutral review\nneutral = \" \".join(df2[df2.Sentiment == 'Neutral']['Review'].values)\nw = WordCloud(width = 700, height = 400, random_state = 10, max_font_size = 100, background_color = 'white').generate(neutral)\n\nplt.figure(figsize = (10,6))\nplt.imshow(w, interpolation = \"bilinear\")\nplt.title(\"Wordcloud of Neutral Review\")\nplt.axis('off')\nplt.show()","18856e03":"#visualize negative review\nnegative = \" \".join(df2[df2.Sentiment == 'Negative']['Review'].values)\nw = WordCloud(width = 700, height = 400, random_state = 10, max_font_size = 100, background_color = 'white').generate(negative)\n\nplt.figure(figsize = (10,6))\nplt.imshow(w, interpolation = \"bilinear\")\nplt.title(\"Wordcloud of Negative Review\")\nplt.axis('off')\nplt.show()","17a5c90e":"#visualize sentiment\nplt.figure(figsize = (10,6))\nplt.xlabel('Sentiment')\nplt.ylabel('Count')\ndf2['Sentiment'].value_counts().plot(kind = 'bar')\nplt.title(\"Sentiment Analysis of Review\")\nplt.show()","a923f976":"#selection data\ndf.head()","b1c6e76c":"#transform rating value to integer\ndf['Rating'] = df['Rating'].astype('int')\ndf.head()","205b3c99":"#apply sentiment variable\ndf['Sentiment'] = [1 if x > 4 else 0 for x in df.Rating]\ndf.head()","1013abfc":"#data preprocessing\nX, y = (df['Review'].values, df['Sentiment'].values)\n\n#feature scaling\ntk = Tokenizer(lower = True)\ntk.fit_on_texts(X)\nX_seq = tk.texts_to_sequences(X)\nX_pad = pad_sequences(X_seq, maxlen = 100, padding = 'post')\nX_pad","aa48061e":"#split data\nX_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size = 0.3, random_state = 0)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","ba6c30a8":"#check validation\nbatch_size = 64\nX_train1 = X_train[batch_size:]\ny_train1 = y_train[batch_size:]\n\nX_test = X_train[:batch_size]\ny_test = y_train[:batch_size]","d7726e21":"#build model\nvocabulary_size = len(tk.word_counts.keys()) + 1\nmax_words = 100\n\nembedding_size = 32\nregressor = Sequential()\nregressor.add(Embedding(vocabulary_size, embedding_size, input_length = max_words))\nregressor.add(SimpleRNN(200))\nregressor.add(Dense(1, activation = 'sigmoid'))\nregressor.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","5a3d2697":"#fitting model\nregressor.fit(X_train1, y_train1, validation_data = (X_test, y_test), batch_size = 32, epochs = 100)","e3e7f336":"#result of summary model\nregressor.summary()","acbdbfa7":"#prediction\ny_pred = regressor.predict(X_test, verbose = 0)\ny_pred = (y_pred > 0.5)\nprint(y_pred)","5685706c":"#accuracy score\nscore = regressor.evaluate(X_test, y_test, verbose = 0)\nprint('Accuracy Score : ', score[1])","025a5f04":"#confusion matrix\nmatrix = metrics.confusion_matrix(y_test, y_pred)\nprint(matrix)\n\n#heatmap matrix\nplt.figure(figsize = (10,6))\nsns.heatmap(matrix, annot = True, cmap = 'Blues')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"Actual\")\nplt.show()","15c8feb9":"#classification report\nreport = metrics.classification_report(y_test, y_pred)\nprint(report)","79745438":"## Reccurent Neural Network Model","1410ff2d":"# Sentiment Analysis of Reviews Radiohead's OK Computer","828a2f4d":"## Sentiment Analysis","c9681b69":"## Text Processing","bad9d064":"## Data Extaction"}}