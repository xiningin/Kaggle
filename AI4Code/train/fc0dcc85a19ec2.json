{"cell_type":{"7d225e51":"code","2328a73a":"code","5ade25ea":"code","e38d5a48":"code","de04c7d6":"code","da63b21a":"code","62cd93b8":"code","51af1404":"code","c5f0c7f2":"code","a5d97338":"code","373ea216":"code","63bdea4f":"code","d57f77bd":"code","147a7d1a":"code","736e8b95":"code","121d2f68":"code","7f75c576":"code","1c135bf3":"code","e806d2a0":"code","602111a9":"code","512c8946":"code","46441f77":"code","7bbb1e02":"code","532da1db":"code","c3c2a82c":"code","739af1ce":"code","6ba58812":"code","257221bc":"code","5dc4e4dc":"code","9952297a":"code","588de908":"code","1f447e06":"code","163e0a64":"code","f7212cd4":"markdown","b5845c12":"markdown","a7ca3f52":"markdown","cb8688a3":"markdown","890e792a":"markdown","2402899e":"markdown","2fcc483d":"markdown","6c7998fd":"markdown","6f4cdc55":"markdown","a3b5c562":"markdown"},"source":{"7d225e51":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n\n","2328a73a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","5ade25ea":"train = pd.read_csv(\"..\/input\/av-janatahack-machine-learning-in-agriculture\/train_yaOffsB.csv\")\ntest = pd.read_csv(\"..\/input\/av-janatahack-machine-learning-in-agriculture\/test_pFkWwen.csv\")\ntrain.head()","e38d5a48":"train.shape","de04c7d6":"def get_summary(df):\n  summary = pd.DataFrame(index = df.columns)\n  summary['data_types'] = df.dtypes \n  summary['null_values'] = df.isnull().sum()\n  summary['unique_values'] = df.nunique()\n  return summary","da63b21a":"summary = get_summary(train)\nsummary","62cd93b8":"# Dependent and independent variable\n# Train data\nx = train.drop(['Crop_Damage','ID'], axis = 1) # independent variable\ny = train['Crop_Damage']  # dependent variable\n\n# Test Data\nx_test = test # independent variable\n\n\n\noriginal = train","51af1404":"# plt.figure()\n# x['Estimated_Insects_Count'].plot.hist(bins = 10)\n# x['Estimated_Insects_Count'].plot.bar()\nplt.figure(1)\nplt.subplot(121)\nsns.distplot((x['Estimated_Insects_Count']))\n\nplt.subplot(122)\nx['Estimated_Insects_Count'].plot.box(figsize=(16,5))\nplt.show()","c5f0c7f2":"\n# Right Skewness can be removed by using square root transformation\nplt.figure(1)\nplt.subplot(121)\nsns.distplot((np.sqrt(x['Estimated_Insects_Count'])))\n\nplt.subplot(122)\nnp.sqrt(x['Estimated_Insects_Count']).plot.box(figsize=(16,5))\nplt.show()","a5d97338":"plt.figure()\nx['Number_Doses_Week'].plot.hist()\n# x['Estimated_Insects_Count'].plot.bar()\n\nplt.figure(1)\nplt.subplot(121)\nsns.distplot(x['Number_Doses_Week'])\n\nplt.subplot(122)\nx['Number_Doses_Week'].plot.box(figsize=(16,5))\nplt.show()","373ea216":"plt.figure(1)\nplt.subplot(121)\nsns.distplot((np.sqrt(x['Number_Doses_Week'])))\n\nplt.subplot(122)\nnp.sqrt(x['Number_Doses_Week']).plot.box(figsize=(16,5))\nplt.show()","63bdea4f":"# plt.figure()\n# x['Number_Weeks_Used'].plot.hist()\n\nplt.figure(1)\nplt.subplot(121)\nsns.distplot(x['Number_Weeks_Used'])\n\nplt.subplot(122)\nx['Number_Weeks_Used'].plot.box(figsize=(16,5))\nplt.show()","d57f77bd":"# plt.figure()\n# x['Number_Weeks_Quit'].plot.hist()\n\n\n\nplt.figure(1)\nplt.subplot(121)\nsns.distplot(x['Number_Weeks_Quit'])\n\nplt.subplot(122)\nx['Number_Weeks_Quit'].plot.box(figsize=(16,5))\nplt.show()","147a7d1a":"\nplt.figure(1)\nplt.subplot(121)\nsns.distplot(np.power((x['Number_Weeks_Quit']+0.1)*100,1\/2))\n\nplt.subplot(122)\nnp.log((x['Number_Weeks_Quit']+0.1)*100).plot.box(figsize=(16,5))\nplt.show()","736e8b95":"# x['Estimated_Insects_Count'] = np.sqrt(x['Estimated_Insects_Count'])\n# x['Number_Doses_Week'] = np.sqrt(x['Number_Doses_Week'])\n# x['Number_Weeks_Quit'] = np.log((x['Number_Weeks_Quit']+0.1)*100)","121d2f68":"summary","7f75c576":"x['Number_Weeks_Used'] = x['Number_Weeks_Used'].fillna(x['Number_Weeks_Used'].mode()[0]) ","1c135bf3":"get_summary(x)","e806d2a0":"test['Number_Weeks_Used'] = test['Number_Weeks_Used'].fillna(x['Number_Weeks_Used'].mode()[0]) ","602111a9":"get_summary(test)","512c8946":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\n\nct = ColumnTransformer([('standard',StandardScaler(),[0,4,5,6])], remainder = 'passthrough')\ncolumns = x.columns\nnew_indices = [0,4,5,6,1,2,3,7]\nnew_columns = [columns[index] for index in new_indices]\nx_scaled = pd.DataFrame(ct.fit_transform(x),columns = new_columns)","46441f77":"test_copy = test.drop(['ID'], axis = 1)","7bbb1e02":"# Feature Scaling the test data\ntest_scaled = pd.DataFrame(ct.transform(test_copy),columns = new_columns)","532da1db":"# # Getting the dummy variable\n# train_objs_num = len(x_scaled)\n# dataset = pd.concat(objs=[x_scaled, test], axis=0)\n# dataset_preprocessed = pd.get_dummies(dataset,columns = ['Crop_Type','Soil_Type','Pesticide_Use_Category','Season'])\n# train_preprocessed = dataset_preprocessed[:train_objs_num]\n# test_preprocessed = dataset_preprocessed[train_objs_num:]","c3c2a82c":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier","739af1ce":"from sklearn.metrics import accuracy_score\ndef get_score(model,x_train, x_test, y_train, y_test):\n    model.fit(x_train,y_train)\n    y_predict = model.predict(x_test)\n    accuracy = accuracy_score(y_test, y_predict)\n    return accuracy\n    ","6ba58812":"# from sklearn.model_selection import KFold\n# kf = KFold(n_splits = 6)\n# score_l = []\n# score_svm = []\n# score_rf  = []\n# for train_index, test_index in kf.split(x):\n#     x_train, x_test, y_train, y_test = x.iloc[train_index],x.iloc[test_index],y.iloc[train_index],y.iloc[test_index]\n#     score_l.append(get_score(LogisticRegression(max_iter = 1000),x_train, x_test, y_train, y_test))\n#     score_svm.append(get_score(SVC(),x_train, x_test, y_train, y_test))\n#     score_rf.append(get_score(RandomForestClassifier(),x_train, x_test, y_train, y_test))\n    \n    \n        \n        ","257221bc":"from sklearn.ensemble import GradientBoostingClassifier\ngbc = GradientBoostingClassifier()\ngbc.fit(x_scaled,y)\n\n","5dc4e4dc":"test_scaled","9952297a":"y_predict = gbc.predict(test_scaled)","588de908":"print(y_predict)\n","1f447e06":"predict = pd.DataFrame()\npredict['ID'] = x_test['ID']\npredict['Crop_Damage'] = y_predict\npredict","163e0a64":"predict.to_csv(\"Submission_7.csv\", index = False)","f7212cd4":"## Inference \n* 'Crop_Damage' is the dependent variable\n* The variable 'ID' can be removed\n* Missing values are found at 'Number_Weeks_Used'. Hence imputation should be performed\n* Following variables should be categorical:\n    - Crop_Type : One Hot Encode\n    - Soil_Type : One Hot Encode\n    - Pesticide_Use_Category : One Hot Encode?? (since the categories are (never, previously used, currently using),should be checked)\n    - Season : One Hot Encode\n    \n","b5845c12":"# Missing Value treatment","a7ca3f52":"Most of the estimated insects counts are of between 12500 and 5000. The distribution is right skewed","cb8688a3":"## Categorical Variables\n   * Crop_Type \n   * Soil_Type \n   * Pesticide_Use_Category \n   * Season ","890e792a":"## Continuous variable\n\n* Estimated_Insects_Count\n* Number_Doses_Week\n* Number_Weeks_Used\n* Number_Weeks_Quit","2402899e":"# Univariate Analysis","2fcc483d":"# Model Building","6c7998fd":"Distribution is somewhat normal. Some outliers are present for values above 60","6f4cdc55":"# Summary of the train data","a3b5c562":"- Import the models\n- Split the train data by cross validation\n- Check the performance using each  model\n- Get the best model\n"}}