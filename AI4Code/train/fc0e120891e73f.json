{"cell_type":{"06f75252":"code","6b86318b":"code","bc3f8d57":"code","7c793756":"code","70ffb221":"code","303c1648":"code","4b116d61":"code","f8499aa1":"code","22e8d410":"code","17792e8b":"code","174f71ee":"code","8e34b43f":"code","b35c0df5":"code","6c5cc8bd":"code","5d81b867":"code","e7eb0337":"code","bf0d90f5":"code","d2df62b4":"code","82343d80":"code","e2daf34f":"code","54c4e844":"code","a6c47f64":"code","c7112127":"code","78ce8e33":"code","657a443c":"code","9ab8c0ad":"code","2bd4b4bd":"code","8cf24af7":"code","f8cb83fd":"code","49468369":"code","d2137059":"code","e13f1f03":"code","808fd9d3":"code","713624dd":"code","9027d82d":"code","5537761d":"code","9ad426f0":"code","35da9d25":"code","78543b35":"code","ed496f09":"code","2f70c44b":"code","977912fe":"code","69eaf360":"code","573b0960":"code","c37057c4":"code","53d7299b":"code","c86bf79f":"code","a9ac0ff8":"code","720aaab0":"code","6f452796":"code","f87badd4":"code","48ea774f":"code","d14730ff":"code","55e6bdb7":"code","eaec7eec":"code","61e7a706":"code","1ef59f49":"code","2e54e932":"code","dfd98fbe":"code","9cae676c":"code","1d9239a7":"code","dea6f9f9":"code","ec266d3e":"code","6b513bae":"code","cd375b06":"code","39602d50":"code","fb49200d":"code","b0bd3957":"code","15dc1906":"code","ea003b71":"code","d849c708":"code","77f95bf4":"code","88c788b6":"code","47216aaa":"code","03ba0128":"code","f5848693":"code","24449b8d":"code","8deaf512":"code","395fa3c9":"code","d12ab82f":"code","ea673abd":"code","9ecfd5c8":"code","b9c39f7d":"code","959ab761":"code","8dacf405":"code","13b9014e":"code","5dc029a0":"code","96d0e4d0":"code","6a99220e":"code","a7048e11":"code","de94d357":"code","b0c7833b":"code","9d772860":"code","850e78da":"code","eacda96e":"code","e3ae9fda":"code","29685ffd":"code","c0bc03fa":"code","89ed4a17":"code","862de746":"code","4ea7dc3a":"code","0f3e4a21":"code","2dffaabb":"code","b279bad1":"code","36a55af7":"code","f19dc6e0":"code","3ba343c4":"code","0d6eb64d":"code","edfe8d6d":"code","f5beee3f":"code","469641ce":"code","3e678a16":"code","49785538":"code","5479243b":"code","4e0c8b07":"code","f429ed49":"code","a7b223d3":"code","764229a7":"code","8b1c2aee":"markdown","7d3d5f36":"markdown","5c6178f3":"markdown","56ed8077":"markdown"},"source":{"06f75252":"#importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","6b86318b":"#reading the csv file\ndf=pd.read_csv('..\/input\/train.csv')","bc3f8d57":"df.head()","7c793756":"#dropping irrelivent columns from dataframe.\ndf.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)","70ffb221":"df.head()","303c1648":"#for getting information about different columns\ndf.info()","4b116d61":"#Rounding off Fare column to one decimal place\ndf.Fare=df.Fare*10\ndf.Fare=df.Fare.astype(int)\ndf.Fare=df.Fare\/10","f8499aa1":"df.head()","22e8d410":"#converting text data of sex column into numeric\npd.get_dummies(df.Sex,prefix='Sex').head()","17792e8b":"#converting text data of embarked column into numeric\npd.get_dummies(df.Embarked).head()","174f71ee":"#creating new dataframe with numeric features for sex and embarked\ndf_new=pd.concat([df,pd.get_dummies(df.Sex,prefix='Sex'),pd.get_dummies(df.Embarked,prefix='Embarked')],axis=1)","8e34b43f":"df_new.head()","b35c0df5":"#dropping the text column for sex and embarked along with one extra column from sex and embarked, \n#as they does not give any additional information i.e they are highly correlated\ndf_new.drop(['Sex','Embarked','Sex_female','Embarked_Q'],axis=1,inplace=True)","6c5cc8bd":"df_new.head()","5d81b867":"#filling the NaN value of cabin with 0\ndf_new.Cabin.fillna(value=0,inplace=True)","e7eb0337":"df_new.head()","bf0d90f5":"#replacing all other values with 1 usin regular expression\ndf_new.Cabin=df_new.Cabin.str.replace('[A-Z].*','1')","d2df62b4":"df_new.Cabin.fillna(value=0,inplace=True)\ndf_new.head()","82343d80":"#converting the value of cabin from string to int\ndf_new.Cabin=df_new.Cabin.astype(int)","e2daf34f":"#getting info about all column.we can see that all column is now converted into int\ndf_new.info()","54c4e844":"#seperating the response and feature vector,here X is feature\nX=df_new.drop(['Survived'],axis=1)","a6c47f64":"X.head()","c7112127":"#here y is response\ny=df_new.Survived","78ce8e33":"y.head()","657a443c":"#importing train_test_split from sklearn.linear model\nfrom sklearn.model_selection import train_test_split","9ab8c0ad":"#splitting into training and testing data\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)","2bd4b4bd":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","8cf24af7":"#getting info about training set\nX_train.info()","f8cb83fd":"#filling the value of nan value in age column with mean of age.\ntemp=X_train.Age.mean()\ntemp","49468369":"X_train.Age.fillna(value=29,inplace=True)","d2137059":"#new X_trtain\nX_train.head()","e13f1f03":"X_train.info()","808fd9d3":"#filling the nan value in test data with mean of age\ntemp=X_test.Age.mean()\ntemp","713624dd":"X_test.Age.fillna(value=31,inplace=True)","9027d82d":"X_test.info()","5537761d":"#converting age from float to int\nX_train.Age=X_train.Age.astype(int)\nX_test.Age=X_test.Age.astype(int)","9ad426f0":"#final x_train with no NaN and all numeric value\nX_train.head()","35da9d25":"#final x_train with no NaN and all numeric value\nX_test.head()","78543b35":"#importing random forest classifier\nfrom sklearn.ensemble import RandomForestClassifier","ed496f09":"#instantiating random forest classifier\nrn=RandomForestClassifier()","2f70c44b":"#fitting the random forest classifier\nrn.fit(X_train,y_train)","977912fe":"#predicting the result\npred=rn.predict(X_test)","69eaf360":"#importing accuracy score from metrics to evaluate the accuracy of the model\nfrom sklearn.metrics import accuracy_score","573b0960":"score=accuracy_score(y_test,pred)","c37057c4":"#accuracy given by randomforest\nscore","53d7299b":"X.info()","c86bf79f":"#filling the nan value of age\nX.Age.mean()","a9ac0ff8":"X.Age=X.Age.fillna(value=30)","720aaab0":"X.head()","6f452796":"#converting age to int from float\nX.Age=X.Age.astype(int)\nX.info()","f87badd4":"y.shape","48ea774f":"#calculating the accuracy of random forest foe different value of hyperparameter n_estimator\nfrom sklearn.model_selection import cross_val_score\nn_estimator_list=list(range(5,50,5))\na=[]\nfor i in n_estimator_list:\n    rn=RandomForestClassifier(n_estimators=i)\n    scores=cross_val_score(rn,X,y,cv=10)\n    a.append(scores.mean())\nprint(a)    ","d14730ff":"#plotting a graph to show relation between n_estimator and accuracy score\nplt.plot(n_estimator_list,a)","55e6bdb7":"#calculating the accuracy of random forest for different value of hyperparameter max_depth\ndepth_list=list(range(2,10,1))\nb=[]\nfor i in depth_list:\n    rn=RandomForestClassifier(n_estimators=10,max_depth=i)\n    scores=cross_val_score(rn,X,y,cv=10)\n    b.append(scores.mean())\nprint(b)   ","eaec7eec":"#plotting a graph to show relation between n_estimator and accuracy score\nplt.plot(depth_list,b)","61e7a706":"#instantiating random forest with optimal value of n_estimator and max_depth found by two upper plots\nrn=RandomForestClassifier(n_estimators=10,max_depth=6)","1ef59f49":"#fitting random forest\nrn.fit(X,y)","2e54e932":"#reading the test data to which we have to submit the results\ntest_df=pd.read_csv('..\/input\/test.csv')","dfd98fbe":"#first five rows of test data\ntest_df.head()","9cae676c":"#shape of test data\ntest_df.shape","1d9239a7":"temp=test_df","dea6f9f9":"#dropping irrelevent columns which might not be useful in predicting the response\ntest_df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)","ec266d3e":"#getting info about test data\ntest_df.info()","6b513bae":"#we have some inf value in fare and age columns,which can't be handled by fillna function of pandas \n#so first we will have to convert that inf into nan,that's what \"use_inf_as_null\" does\nwith pd.option_context('mode.use_inf_as_null', True):\n   test_df.Fare.fillna(value=test_df.Fare.mean(),inplace=True)","cd375b06":"test_df.info()","39602d50":"#doing the same thing toage column\nwith pd.option_context('mode.use_inf_as_null', True):\n   test_df.Age.fillna(value=test_df.Age.mean(),inplace=True)","fb49200d":"test_df.info()","b0bd3957":"#rounding fare to one decimal place\ntest_df.Fare=test_df.Fare*10\ntest_df.Fare=test_df.Fare.astype(int)\ntest_df.Fare=test_df.Fare\/10","15dc1906":"#converting age from float to int\ntest_df.Age=test_df.Age.astype(int)","ea003b71":"test_df.head()","d849c708":"##creating new dataframe with numeric features for sex and embarked\ntest_df=pd.concat([test_df,pd.get_dummies(test_df.Sex,prefix='Sex'),pd.get_dummies(test_df.Embarked,prefix='Embarked')],axis=1)","77f95bf4":"test_df.head()","88c788b6":"##dropping the text column for sex and embarked along with one extra column from sex and embarked, \n#as they does not give any additional information i.e they are highly correlated\ntest_df.drop(['Sex','Sex_female','Embarked','Embarked_Q'],axis=1,inplace=True)","47216aaa":"test_df.head()","03ba0128":"##replacing all other values with 1 usin regular expression\ntest_df.Cabin=test_df.Cabin.str.replace('[A-Z].*','1')\ntest_df.Cabin=test_df.Cabin.fillna(value=0)","f5848693":"test_df.head(10)","24449b8d":"#cheking the no. of one and zeros\ntest_df.Cabin.value_counts()","8deaf512":"#predicting result using random_forest\npred_class_rn=rn.predict(test_df)","395fa3c9":"temp=pd.read_csv('..\/input\/test.csv')","d12ab82f":"#converting the predicted response into detaframe for submission\npredictions=pd.DataFrame({'PassengerId':temp.PassengerId,'Survived':pred_class_rn}).to_csv('predictions_rn_11.csv',index=False)","ea673abd":"#importing gradient boosting clasifier\nfrom sklearn.ensemble import GradientBoostingClassifier","9ecfd5c8":"X.head()","b9c39f7d":"X.info()","959ab761":"#creating a new feature named family by adding parents,children ans siblings\nX['family']=X.SibSp+X.Parch","8dacf405":"X.head()","13b9014e":"#predicting results by gradientboosting using k_fold cross validation\ngb=GradientBoostingClassifier()\nscores=cross_val_score(gb,X,y,cv=5)\nprint(scores.mean())","5dc029a0":"#predicting the result excluding family feature to check if accuracy is incresing or not\ngb=GradientBoostingClassifier()\nscores=cross_val_score(gb,X.drop(['family'],axis=1),y,cv=5)\nprint(scores.mean())","96d0e4d0":"#trying different combinations of features this time keeping family and dropping sibsp and parch.\ngb=GradientBoostingClassifier()\nscores=cross_val_score(gb,X.drop(['SibSp','Parch'],axis=1),y,cv=5)\nprint(scores.mean())","6a99220e":"#dropping three columns and then finding the accuracy\ngb=GradientBoostingClassifier()\nscores=cross_val_score(gb,X.drop(['SibSp','Parch','Cabin'],axis=1),y,cv=5)\nprint(scores.mean())","a7048e11":"#splitting into training and testing data.\ntrain_x,test_x,train_y,test_y=train_test_split(X,y,test_size=0.2,random_state=42)","de94d357":"print(train_x.shape)\nprint(test_x.shape)\nprint(train_y.shape)","b0c7833b":"#using Grid searchCV to find the best hyperparameter learning rate for Gradient Boosting\nlr=[0.01,0.05,0.10,0.15,0.20,0.25,0.30,0.35,0.40,0.45,0.50,0.55,0.60,0.65,0.70,0.85,0.90,0.95,1.0]\nfrom sklearn.model_selection import GridSearchCV\ngb=GradientBoostingClassifier(n_estimators=100)\nparam_grid=dict(learning_rate=lr)\ngrid=GridSearchCV(gb,param_grid,cv=10,scoring='accuracy',return_train_score=True)\ngrid.fit(train_x.drop(['SibSp','Parch'],axis=1),train_y)","9d772860":"#finding the best score\ngrid.best_score_","850e78da":"#finding the best parameter used in finding that best score\ngrid.best_params_","eacda96e":"#finding best value of two hyperparameters this time using grid search.learning_rate and max_depth\nmax_depth=list(range(2,8,1))\nparam_grid=dict(learning_rate=lr,max_depth=max_depth)\ngb=GradientBoostingClassifier(n_estimators=100)\ngrid=GridSearchCV(gb,param_grid,cv=10,scoring='accuracy',return_train_score=True)\ngrid.fit(train_x.drop(['SibSp','Parch'],axis=1),train_y)","e3ae9fda":"#finding the best score\ngrid.best_score_","29685ffd":"#finding the best parameter used to calculate this best score\ngrid.best_params_","c0bc03fa":"#evaluating the result on testing set using the best parameters learned.\ngb=GradientBoostingClassifier(n_estimators=100,learning_rate=0.05,max_depth=3)\ngb.fit(train_x.drop(['SibSp','Parch'],axis=1),train_y)\npred_clas=gb.predict(test_x.drop(['SibSp','Parch'],axis=1))\naccuracy_score(test_y,pred_clas)","89ed4a17":"#first five of the testing data to which we have to submit the results\ntest_df.head()","862de746":"#creating family feature from sibsp and parch\ntest_df['family']=test_df.SibSp+test_df.Parch","4ea7dc3a":"# before predicting on the test dataframe we should first train our best model on whole data available.\nX.head()","0f3e4a21":"#training our GradientBoosing model on whole dataset\ngb.fit(X.drop(['SibSp','Parch'],axis=1),y)","2dffaabb":"#test df with new added feature 'family'.\ntest_df.head()","b279bad1":"#predicting the final response from gradientboosting \nfinal_pred=gb.predict(test_df.drop(['SibSp','Parch'],axis=1))","36a55af7":"#converting the response into Dataframe or csv file to submit it to kaggle.\npredictions=pd.DataFrame({'PassengerId':temp.PassengerId,'Survived':final_pred}).to_csv('predictions_gb_13.csv',index=False)","f19dc6e0":"from sklearn.linear_model import LogisticRegression","3ba343c4":"X.head()","0d6eb64d":"#checking the accuracy of logisticregression on training data\nlg=LogisticRegression(C=1.0)\nscores=cross_val_score(lg,X.drop(['SibSp','Parch'],axis=True),y,cv=10)\nprint(scores.mean())","edfe8d6d":"#training lg on whole data\nlg.fit(X.drop(['SibSp','Parch'],axis=1),y)","f5beee3f":"#predicting the final response using logistic regression\npred_class_lg=lg.predict(test_df.drop(['SibSp','Parch'],axis=1))","469641ce":"#predicted response by logisticregression\npred_class_lg","3e678a16":"#predicted response by Gradient Boosting\npred_class_gb=final_pred\npred_class_gb","49785538":"#predictyed response by random forest\npred_class_rn","5479243b":"#converting all the responses from three models into dataframe to apply maxVoting ensambling technique\npredicted_df=pd.DataFrame({'pred_class_gb':pred_class_gb,'pred_class_rn':pred_class_rn,'pred_class_lg':pred_class_lg})","4e0c8b07":"predicted_df.head(5)","f429ed49":"#generating new predicted response by takin response which is in majority.i.e takin the mode value of the predicted response\nfinal_pred_clas=predicted_df.mode(axis=1,numeric_only=True)\nfinal_pred_clas.head()  ","a7b223d3":"#finally converting into numpy array to submit it to kaggle\nfinal_pred_arr=np.resize(final_pred_clas,(418,))\nfinal_pred_arr","764229a7":"#converting numpy array into csv file or dataFrame.this file we can submit as our final response to kaggle.\npredictions=pd.DataFrame({'PassengerId':temp.PassengerId,'Survived':final_pred_arr}).to_csv('predictions_max_voting_14.csv',index=False)","8b1c2aee":"#### ---","7d3d5f36":"#### After the submission i got an accuracy of 0.77990 which is top 50% score.\n#### rank comes out to be 5126 out of 10,416 teams.","5c6178f3":"### Now preparing the original dataframe to be used for k_fold_crossvalidation","56ed8077":"#### some guidelines and suggestion on how to increse the accuracy score will be very helpful.\n#### thanks"}}