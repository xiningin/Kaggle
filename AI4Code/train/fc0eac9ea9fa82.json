{"cell_type":{"1796775d":"code","4eaddce4":"code","00a8be51":"code","fb9c572b":"code","add7bf2b":"code","68418f48":"code","f2e8b187":"code","9a87b192":"code","3e60537a":"code","2da5015c":"markdown","7da5d30a":"markdown","4464a7e9":"markdown","86de94a0":"markdown","dde3fd6e":"markdown"},"source":{"1796775d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nos.listdir('\/kaggle\/input\/coleridgeinitiative-show-us-the-data')\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4eaddce4":"traindf=pd.read_csv('\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/train.csv')\nprint(traindf.shape)\ntraindf.head()","00a8be51":"sample_sub_df=pd.read_csv('\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/sample_submission.csv')\nprint(sample_sub_df.shape)\nsample_sub_df.head()","fb9c572b":"len(traindf['dataset_title'].unique())","add7bf2b":"len(traindf['dataset_label'].unique())","68418f48":"len(traindf['cleaned_label'].unique())","f2e8b187":"traindf['cleaned_label'].equals(traindf['dataset_label'].str.lower())","9a87b192":"import json\nwith open('..\/input\/coleridgeinitiative-show-us-the-data\/train\/0007f880-0a9b-492d-9a58-76eb0b0e0bd7.json') as f:\n    sample = json.load(f)\n    \n    \njsondf= pd.json_normalize(sample)\njsondf","3e60537a":"with open('..\/input\/coleridgeinitiative-show-us-the-data\/train\/0008656f-0ba2-4632-8602-3017b44c2e90.json') as f:\n    sample = json.load(f)\n    \n    \njsondf= pd.json_normalize(sample)\njsondf","2da5015c":"Columns description\n1. id (publication id) - note that there are multiple rows for some training documents, indicating multiple mentioned datasets\n1. pub_title -  publication title (a small number of publications have the same title)\n1. dataset_title - the title of the dataset that is mentioned within the publication\n1. dataset_label - a portion of the text that indicates the dataset\n1. cleaned_label - the dataset_label, as passed through the clean_text function from the Evaluation page\n","7da5d30a":"# 1. Data Exploration","4464a7e9":"Picking up couple of json file and analyzing them","86de94a0":"cleaned_label and dataset_label values are not same","dde3fd6e":"cleaned_label and dataset_label values looks similar and number of unique values are same too, cross verifying it"}}