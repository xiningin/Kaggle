{"cell_type":{"b520b8cf":"code","bc7b5c87":"code","0f9d0f3d":"code","3885c2c8":"code","cb09b95c":"code","2bf86b2b":"code","ae457154":"code","0805afc8":"code","3d6eb582":"code","d0339dab":"markdown","f7dd67f6":"markdown","9c2608ca":"markdown","8337eef4":"markdown"},"source":{"b520b8cf":"# Import libraries\nimport pandas as pd\nimport numpy as np\nimport os\n\nimport spacy\nfrom tqdm import tqdm","bc7b5c87":"con = open('..\/input\/samsung\/Samsung.txt', 'r', encoding='utf-8')\nsamsung_reviews = con.read()\ncon.close()","0f9d0f3d":"print(\"Length of Reviews : \", len(samsung_reviews.split(\"\\n\")))","3885c2c8":"nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])","cb09b95c":"nouns = []\n\ndoc_count = 2500\n\nfor review in tqdm(samsung_reviews.split('\\n')[:doc_count]):\n    doc = nlp(review)\n    \n    for tok in doc:\n        if tok.pos == 'NOUN':\n            nouns.append(tok.lemma_.lower())","2bf86b2b":"review =\" \".join(samsung_reviews.split(\"\\n\")[:doc_count])\nreview = nlp(review)","ae457154":"# Convert each token into its lemma and identify the PoS tags.\npos = []\nlemma = []\ntext = []\nfor tok in tqdm(review):\n    pos.append(tok.pos_)\n    lemma.append(tok.lemma_)\n    text.append(tok.text)\n\n# Convert the data into a dataframe object.\nnlp_table = pd.DataFrame({'text':text,'lemma':lemma,'pos':pos})\nnlp_table.head()\n\n# Get most frequent lemma forms of nouns\nnlp_table[nlp_table['pos']=='NOUN']['lemma'].value_counts()","0805afc8":"import re\n\ndef get_context(reviews, keyword):\n    pattern = re.compile(f'\\w+\\s{keyword}\\s\\w+')\n    \n    prefixes_suffixes = re.findall(pattern, samsung_reviews)\n    \n    prefixes = []\n    suffixes = []\n    \n    for ps in tqdm(prefixes_suffixes):\n        l = ps.split(\" \")\n    \n        prefixes.append(l[0].lower())\n        suffixes.append(l[-1].lower())\n\n    stop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n\n    prefixes = [p for p in prefixes if p not in stop_words]\n    suffixes = [s for s in suffixes if s not in stop_words]\n    \n    prefixes = pd.Series(prefixes).value_counts().head(5).index\n    suffixes = pd.Series(suffixes).value_counts().head(5).index\n    \n    return pd.DataFrame({'prefixes' : prefixes, 'keyword' : [f'{keyword}'] * len(prefixes), 'suffixes' : suffixes})\n\nget_context(samsung_reviews, 'battery')","3d6eb582":"get_context(samsung_reviews, 'screen')","d0339dab":"## POS Parsing","f7dd67f6":"## Read Reviews Data","9c2608ca":"## Simple Hueristic","8337eef4":"## Importing libraries"}}