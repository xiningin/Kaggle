{"cell_type":{"c0c46f15":"code","4ae404ff":"code","37d4eac9":"code","429df1a5":"code","95355650":"code","e60f6ec2":"code","26e7477f":"code","f9fcdf3e":"code","9eadc831":"code","aa80ceb8":"code","abc55793":"code","a1438201":"code","77cd34e1":"markdown","d1e089bd":"markdown","21888ae3":"markdown","6f96ca3f":"markdown","4f7f776d":"markdown","dcd91a6e":"markdown","43fcbb46":"markdown"},"source":{"c0c46f15":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom itertools import cycle\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# import iris data set\nfrom sklearn.datasets import load_iris\n\n\n# import Kmeans\nfrom sklearn.cluster import KMeans\n\n\n\n# Evaluating Models\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n","4ae404ff":"# loading the iris dataset\niris= load_iris()\n# iris.data\n# iris.target","37d4eac9":"type(iris)","429df1a5":"# understanding the Data Set\nnSamples, nFeatures = iris.data.shape\nprint(nSamples)\nprint(nFeatures)\nprint(iris.target_names)","95355650":"X= iris.data","e60f6ec2":"# Elbow Method\n\nwcss= []\nfor i in range(1,11):\n    kmeans=KMeans(n_clusters=i, init='k-means++',random_state=0)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\n\nplt.plot(range(1,11),wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of Clusters')\nplt.ylabel('WCSS')\nplt.show()\n\n# X= iris.data","26e7477f":"from sklearn.metrics import silhouette_samples, silhouette_score\n\nimport matplotlib.cm as cm\n\nprint(__doc__)\n\nrange_n_clusters = [2, 3, 4, 5, 6, 7 ,8,9,10]\n\nfor n_clusters in range_n_clusters:\n    # Create a subplot with 1 row and 2 columns\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    fig.set_size_inches(18, 7)\n\n    # The 1st subplot is the silhouette plot\n    # The silhouette coefficient can range from -1, 1 but in this example all\n    # lie within [-0.1, 1]\n    ax1.set_xlim([-0.1, 1])\n    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n    # plots of individual clusters, to demarcate them clearly.\n    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n\n    # Initialize the clusterer with n_clusters value and a random generator\n    # seed of 10 for reproducibility.\n    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n    cluster_labels = clusterer.fit_predict(X)\n\n    # The silhouette_score gives the average value for all the samples.\n    # This gives a perspective into the density and separation of the formed\n    # clusters\n    silhouette_avg = silhouette_score(X, cluster_labels)\n    print(\"For n_clusters =\", n_clusters,\n          \"The average silhouette_score is :\", silhouette_avg)\n\n    # Compute the silhouette scores for each sample\n    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n\n    y_lower = 10\n    for i in range(n_clusters):\n        # Aggregate the silhouette scores for samples belonging to\n        # cluster i, and sort them\n        ith_cluster_silhouette_values = \\\n            sample_silhouette_values[cluster_labels == i]\n\n        ith_cluster_silhouette_values.sort()\n\n        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n        y_upper = y_lower + size_cluster_i\n\n        color = cm.nipy_spectral(float(i) \/ n_clusters)\n        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n                          0, ith_cluster_silhouette_values,\n                          facecolor=color, edgecolor=color, alpha=0.7)\n\n        # Label the silhouette plots with their cluster numbers at the middle\n        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n\n        # Compute the new y_lower for next plot\n        y_lower = y_upper + 10  # 10 for the 0 samples\n\n    ax1.set_title(\"The silhouette plot for the various clusters.\")\n    ax1.set_xlabel(\"The silhouette coefficient values\")\n    ax1.set_ylabel(\"Cluster label\")\n\n    # The vertical line for average silhouette score of all the values\n    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n\n    ax1.set_yticks([])  # Clear the yaxis labels \/ ticks\n    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n\n    # 2nd Plot showing the actual clusters formed\n    colors = cm.nipy_spectral(cluster_labels.astype(float) \/ n_clusters)\n    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n                c=colors, edgecolor='k')\n\n    \n   # Styling applied to please viewer\n\n    # Labeling the clusters\n    centers = clusterer.cluster_centers_\n    # Draw white circles at cluster centers\n    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n                c=\"white\", alpha=1, s=200, edgecolor='k')\n\n    for i, c in enumerate(centers):\n        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n                    s=50, edgecolor='k')\n\n    ax2.set_title(\"The visualization of the clustered data.\")\n    ax2.set_xlabel(\"Feature space for the 1st feature\")\n    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n\n    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n                  \"with n_clusters = %d\" % n_clusters),\n                 fontsize=14, fontweight='bold')\n\nplt.show()","f9fcdf3e":"kmeans=KMeans(n_clusters=3)","9eadc831":"KModel = kmeans.fit(X)","aa80ceb8":"KModel.labels_","abc55793":"KModel.cluster_centers_","a1438201":"pd.crosstab(iris.target, KModel.labels_)","77cd34e1":"- Seeing graph from Elbow method we can say we have **3 no of clusters**\n- But for cross validation we will use Silhouette.  \n\n[Source for code](https:\/\/scikit-learn.org\/stable\/auto_examples\/cluster\/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py)","d1e089bd":"<a id=\"4\"><\/a>\n<p style = \"font-size : 20px; color : black ; font-family : 'Comic Sans MS'; text-align : center; background-color : #F4E0FF; border-radius: 5px 5px;\"><strong>Checking Accuracy<\/strong><\/p>\n\n* Since K-Means is a clustering algorithm, using \u201caccuracy\u201d may not be very helpful. You can evaluate the purity of the clustering algorithm itself.\n\n[If want to understand in detail here is the link to standford's....](https:\/\/nlp.stanford.edu\/IR-book\/html\/htmledition\/evaluation-of-clustering-1.html)","21888ae3":"<p style = \"font-size : 20px; color : white ; font-family : 'Comic Sans MS'; text-align : center; background-color : #339966; border-radius: 5px 5px;\"><strong>Finding no of Cluster<\/strong><\/p>\n\n* Finding No of Clusters using **Elbow Method**\n* Validating it with **Silhoutte**","6f96ca3f":"<p style = \"font-size : 20px; color : black ; font-family : 'Comic Sans MS'; text-align : center; background-color : #F4E0FF; border-radius: 5px 5px;\"><strong>Using K-means<\/strong><\/p>\n","4f7f776d":"# Silhoutte\n* Generally valued betweet -1 to +1","dcd91a6e":"* Only k =2 and 3 don't have any -ve value in silhoutte.\n* Silhouette is used for validating crustering models.\n* it can be of great help in case there is some ambiguity while selecting K value from Elbow method.\n\n[Silhouette Score for clustering Explained ](https:\/\/www.youtube.com\/watch?v=_jg1UFoef1c)","43fcbb46":"<p style = \"font-size : 15px; color : black ; font-family : 'Comic Sans MS'; text-align : center; background-color : #ccff66; border-radius: 5px 5px;\"><strong>Seeing Silhouette result we can choose either k=2 or 3 but since we have already run Elbow Method and we got K = 3. Thus we will proceed with k=3. <\/strong><\/p>\n"}}