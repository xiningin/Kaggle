{"cell_type":{"55873710":"code","7eb36207":"code","7e0b85c4":"code","a99f3555":"code","e7132fd3":"code","ed7d0d71":"code","2d75135e":"code","b71c32d2":"code","0a830374":"code","dbe1952c":"code","4bf568f9":"code","9156f375":"code","d73ef0d7":"code","2a013a19":"code","412a90cc":"code","88c49b6c":"code","8149aee3":"code","1f9a11bd":"code","ff5c2d31":"code","5e8ac75f":"code","cfcfd7ee":"code","e30064e6":"code","c3eb8c54":"code","9b884d3f":"code","e8c1d57c":"code","7f7a2270":"code","23fcf4ea":"code","5d19e63d":"code","0baec6b5":"code","1d6633a9":"code","3db62f8a":"code","556deeed":"code","a2f5c21c":"code","e70d4413":"code","a6134df7":"code","3099861e":"markdown","ce93fb42":"markdown","19b0bab2":"markdown","aa673564":"markdown","7e01fbb0":"markdown","d4255b06":"markdown","bb3fa516":"markdown","6a449dd0":"markdown","24e3c5d2":"markdown","ae3eb791":"markdown","3b073b64":"markdown","76decb20":"markdown","345cc035":"markdown","db89edb0":"markdown","6d141921":"markdown","c1fd3788":"markdown","d88c16b0":"markdown","e256f550":"markdown","f4c7bee0":"markdown","54fb6ac8":"markdown","6f078737":"markdown","bdbeecc0":"markdown","397a7b3b":"markdown","1b49016b":"markdown","f1790a5e":"markdown","00378bcc":"markdown","dd660877":"markdown","a7a249cf":"markdown","d749b266":"markdown"},"source":{"55873710":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","7eb36207":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","7e0b85c4":"train.head()","a99f3555":"test.head()","e7132fd3":"print(train.info())\nprint(\"=\"*50)\nprint(test.info())","ed7d0d71":"pd.crosstab(train.Pclass,train.Survived,margins=True)","2d75135e":"pd.crosstab(train.Sex,train.Survived,margins=True)","b71c32d2":"train.Embarked.fillna('C',inplace=True)","0a830374":"pd.crosstab(train.Embarked,train.Survived,margins=True)","dbe1952c":"def graph_bar(category):\n        \n    train_survived = train[train[\"Survived\"]==1]\n    nb_train_survived=train_survived.groupby(category)['PassengerId'].nunique()\n\n    train_not_survived = train[train[\"Survived\"]==0]\n    nb_train_not_survived=train_not_survived.groupby(category)['PassengerId'].nunique()\n    \n    Survived = list(nb_train_survived)\n    Notsurvived = list(nb_train_not_survived)\n\n    N = range(len(Survived))\n\n    p1=plt.bar(N, Survived,color='#BCF0C6')\n    p2=plt.bar(N, Notsurvived,bottom=Survived,color='#F98888')\n\n    groups=(list(train[category].unique()))\n    groups.sort()        \n    plt.xticks(N, groups)\n    plt.title(\"Survivors by the {} variable\".format(category))\n    plt.xlabel(\"{}\".format(category))\n    plt.ylabel(\"Number of persons\")\n    plt.legend((p1[0], p2[0]), ('Survived', 'Not Survived'))","4bf568f9":"plt.figure(figsize=(12,12))\nplt.subplot(2, 2, 1)  \ngraph_bar(\"Embarked\")\nplt.subplot(2, 2, 2)\ngraph_bar(\"Sex\")\nplt.subplot(2, 1, 2)  \ngraph_bar(\"Pclass\")\nplt.show()","9156f375":"def name_sep(data):\n    titles=[]\n    for i in range(len(data)):\n        title=data.iloc[i]\n        title=title.split('.')[0].split(' ')[-1]\n        titles.append(title)\n    return titles","d73ef0d7":"train['Title']=name_sep(train.Name)\ntest['Title']=name_sep(test.Name)","2a013a19":"train.Title.value_counts()","412a90cc":"train=train.replace(['female','male'],[0,1])\ntest=test.replace(['female','male'],[0,1])","88c49b6c":"train=pd.concat((\n    train,\n    pd.get_dummies(train.Embarked,drop_first=False),\n),axis=1)\n\ntest=pd.concat((\n    test,\n    pd.get_dummies(test.Embarked,drop_first=False),\n),axis=1)","8149aee3":"train=pd.concat((\n    train,\n    pd.get_dummies(train.Pclass,drop_first=False),\n),axis=1)\n\ntest=pd.concat((\n    test,\n    pd.get_dummies(test.Pclass,drop_first=False),\n),axis=1)","1f9a11bd":"for i in range(len(train)) :\n    if train.loc[train.index[i], 'Title'] not in [\"Mr\",\"Miss\",\"Mrs\",\"Master\"]:\n        train.loc[train.index[i], 'Title']=\"Autre\"\nfor i in range(len(test)) :\n    if test.loc[test.index[i], 'Title'] not in [\"Mr\",\"Miss\",\"Mrs\",\"Master\"]:\n        test.loc[test.index[i], 'Title']=\"Autre\"","ff5c2d31":"pd.crosstab(train.Title,train.Survived,margins=True)","5e8ac75f":"graph_bar('Title')","cfcfd7ee":"train=pd.concat((\n    train,\n    pd.get_dummies(train.Title,drop_first=False),\n),axis=1)\n\ntest=pd.concat((\n    test,\n    pd.get_dummies(test.Title,drop_first=False),\n),axis=1)","e30064e6":"train.pivot_table(\n    values='SibSp',\n    index='Survived',\n    columns='Pclass',\n    aggfunc=np.mean)","c3eb8c54":"train.pivot_table(\n    values='Parch',\n    index='Survived',\n    columns='Pclass',\n    aggfunc=np.mean)","9b884d3f":"train.pivot_table(\n    values='Fare',\n    index='Survived',\n    columns='Pclass',\n    aggfunc=np.mean)","e8c1d57c":"test['Fare'].fillna(test['Fare'].mean(),inplace=True )","7f7a2270":"train.pivot_table(\n    values='Age',\n    index='Survived',\n    columns='Pclass',\n    aggfunc=np.mean)","23fcf4ea":"for i in range(len(train)) :\n    if train.loc[train.index[i], 'Age'] <10:\n        train.loc[train.index[i], 'Age2']=\"[0-10[\"\n    elif train.loc[train.index[i], 'Age'] <20:\n        train.loc[train.index[i], 'Age2']=\"[10-20[\"\n    elif train.loc[train.index[i], 'Age'] <30:\n        train.loc[train.index[i], 'Age2']=\"[20-30[\"\n    elif train.loc[train.index[i], 'Age'] <40:\n        train.loc[train.index[i], 'Age2']=\"[30-40[\"\n    elif train.loc[train.index[i], 'Age'] <50:\n        train.loc[train.index[i], 'Age2']=\"[40-50[\"\n    elif train.loc[train.index[i], 'Age'] <60:\n        train.loc[train.index[i], 'Age2']=\"[50-60[\"\n    else: \n        train.loc[train.index[i], 'Age2']=\"[60 et +\"","5d19e63d":"graph_bar(\"Age2\")","0baec6b5":"from sklearn.linear_model import LinearRegression\n#We extract the persons where we know their age :\ntrain_age=train[~train[\"Age\"].isnull()]\n#We split in two parts : the dependants variables and the independant variable.\ntrain_x_age=train_age[[\"Sex\",\"Parch\",\"SibSp\",\"Fare\",\"C\",\"Q\",\"S\",\"Autre\",\"Master\",\"Miss\",\"Mr\",\"Mrs\"]]\ntrain_y_age=train_age[\"Age\"]\n#This is the datasets where we will apply the age prediction \ntrain1=train[[\"Sex\",\"Parch\",\"SibSp\",\"Fare\",\"C\",\"Q\",\"S\",\"Autre\",\"Master\",\"Miss\",\"Mr\",\"Mrs\"]]\n\nmodel = LinearRegression()\nmodel.fit(train_x_age, train_y_age)\nage_pred = model.predict(train1)\n\n#We concat the orinal dataset with the age and the new colomn: the age predict  \ndf=pd.DataFrame(list(age_pred),columns=[\"Age3\"])\ntrain2=pd.concat((\n    train1,\n    df,\n    train[\"Age\"]\n),axis=1)\n\n# if we known the age then we let it, but if we don't known the age, we take the age predict. \nfor i in range(len(train2)) :\n    if train2.loc[train2.index[i], 'Age']>=0:\n        train.loc[train2.index[i], 'Age']=train2.loc[train2.index[i], 'Age']\n    else: \n        train2.loc[train2.index[i], 'Age']=train2.loc[train2.index[i], 'Age3']","1d6633a9":"#We extract the persons where we know their age :\ntest_age=test[~test[\"Age\"].isnull()]\n#We split in two parts : the dependants variables and the independant variable.\ntest_x_age=test_age[[\"Sex\",\"Parch\",\"SibSp\",\"Fare\",\"C\",\"Q\",\"S\",\"Autre\",\"Master\",\"Miss\",\"Mr\",\"Mrs\"]]\ntest_y_age=test_age[\"Age\"]\n#This is the datasets where we will apply the age prediction \ntest1=test[[\"Sex\",\"Parch\",\"SibSp\",\"Fare\",\"C\",\"Q\",\"S\",\"Autre\",\"Master\",\"Miss\",\"Mr\",\"Mrs\"]]\n\nmodel = LinearRegression()\nmodel.fit(test_x_age, test_y_age)\nage_pred = model.predict(test1)\n\n#We concat the orinal dataset with the age and the new colomn: the age predict  \ndf=pd.DataFrame(list(age_pred),columns=[\"Age3\"])\ntest2=pd.concat((\n    test1,\n    df,\n    test[\"Age\"]\n),axis=1)\n\n# if we known the age then we let it, but if we don't known the age, we take the age predict. \nfor i in range(len(test2)) :\n    if test2.loc[test2.index[i], 'Age']>=0:\n        test2.loc[test2.index[i], 'Age']=test2.loc[test2.index[i], 'Age']\n    else: \n        test2.loc[test2.index[i], 'Age']=test2.loc[test2.index[i], 'Age3']","3db62f8a":"train_X=train2[['Sex','Parch', \"SibSp\",'Fare', 'Q', 'S','Autre','Master','Miss','Mrs','Age']]\ntrain_Y=train[['Survived']]\ntest_X=test2[['Sex','Parch',\"SibSp\",'Fare', 'Q', 'S','Autre','Master','Miss','Mrs','Age']]","556deeed":"from sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression(solver=\"liblinear\", random_state=42)\nlog_reg.fit(train_X, train_Y)","a2f5c21c":"y_proba = log_reg.predict_proba(test_X)\nsurvived=[]\nfor i in y_proba:\n    if i[0]<0.5:\n        survived.append(1)\n    else :\n        survived.append(0)\n        \nsurvived=pd.DataFrame(survived,columns=[\"Survived\"])\n\ntitanic=pd.concat((\n    test['PassengerId'],\n    survived\n),axis=1)","e70d4413":"titanic.head()","a6134df7":"titanic.to_csv('titanic.csv',index=False)","3099861e":"We're going to fill the missing values by values predicted by a linear regression.","ce93fb42":"# Overview","19b0bab2":"### The <code>Name<\/code> variable\n","aa673564":"### The <code>Pclass<\/code> variable","7e01fbb0":"We create a function who allows to doing diagrams who distinc the suvived and the not survived ","d4255b06":"For the train dataset : ","bb3fa516":"### The <code>Age<\/code> variable","6a449dd0":"## The quantitative variables ","24e3c5d2":"We transform the variable <code>Sex<\/code> in dummies.","ae3eb791":"<p>We're not going to take into account the <code>Cabin<\/code> and <code>Ticket<\/code> variables.<\/p>\n<p>We're going to analysis the variables following:<\/p>\n    <ul>\n        <li><code>Pclass<\/code><\/li>\n        <li><code>Sex<\/code><\/li> \n        <li><code>Embarked<\/code><\/li>\n        <li><code>Name<\/code> : We're going to extract the honorary title.<\/li>\n        <li><code>SibSp<\/code><\/li>\n        <li><code>Parch<\/code><\/li>\n        <li><code>Fare<\/code> : There are one only missing value in the test dataset. We can to replace it by the mean.<\/li>\n        <li><code>Age<\/code> : We're going to fill the missing values by values predicted by a linear regression.<\/li>\n    <\/ul>  ","3b073b64":"### The <code>SibSp<\/code> variable","76decb20":"### The changes","345cc035":"For the test datatest:","db89edb0":"We transform the variable <code>Pclass<\/code> in dummies.","6d141921":"### The <code>Embarked<\/code> variable","c1fd3788":"Firtly we can import the libraries and the two datasets (train.csv and test.csv)","d88c16b0":"### The <code>Parch<\/code> variable","e256f550":"We're going to extract the honorary title.","f4c7bee0":"<div style=\"background-color:#84E1FB\">\n<br><br><br>\n<div align=\"center\"><span style=\"font-size:36px;color:#003BA3\"><b>Titanic: Machine Learning from Disaster<\/b><\/span><\/div>\n<br>\n<div align=\"center\"><span style=\"font-size:30px;color:#003BA3\"><b>Regression logistic<\/b><\/span><\/div>\n<br><br><br>\n<\/div>","54fb6ac8":"Now, we are going to apply the logistic regression. ","6f078737":"## The qualitative variables ","bdbeecc0":"# Precdiction ","397a7b3b":"### The <code>Fare<\/code> variable","1b49016b":"### Chart","f1790a5e":"We group together the honorary titles that are few in number","00378bcc":"# Data cleaning","dd660877":"We transform the variable Title in dummies.","a7a249cf":"### The <code>Sex<\/code> variable","d749b266":"# Logistic regression"}}