{"cell_type":{"de22efee":"code","01836662":"code","306b1f6f":"code","3b15dbc6":"code","2e7547ed":"code","ee19d259":"code","3f6d7097":"code","ffbb3d71":"code","ea6738d3":"code","50fa1327":"code","fda1629b":"markdown","6cf5429a":"markdown","fe36d885":"markdown","5507741a":"markdown","61999169":"markdown","2b9f9e48":"markdown","795aba08":"markdown","ce396c5e":"markdown"},"source":{"de22efee":"# pip install spacy==2.2.0\n# or\n# pip install spacy==3.1.4 ","01836662":"!python -m spacy info","306b1f6f":"# import library\nimport spacy \nnlp1 = spacy.load('en_core_web_sm')","3b15dbc6":"# convert unstructured text into spacy input format\ntext = \"im learning awesome python, machine learning and nlp\"\ndoc1 = nlp1(text)","2e7547ed":"for token in doc1:\n    # Print the token and its part-of-speech tag\n    print(token.text, \"-->\", token.pos_)","ee19d259":"## to add colors to words and respective entity\nfrom spacy import displacy\ntext = 'Raju regulary go to the school. His mother is Vandana who is working as maid in Pune. Raju want to go to trip at Lavasa. His teacher Anna want him to come to class.'\ndoc3=nlp1(text)\nfor ent in doc3.ents:\n    print(ent.text, ent.label_)","3f6d7097":"##  Visually we can observe how entities looks\ndisplacy.render(doc3,style=\"ent\",jupyter=True)","ffbb3d71":"nlp2 = spacy.load('en_core_web_lg')\ndoc4=nlp2(text)\n##  Visually we can observe how entities looks\ndisplacy.render(doc4,style=\"ent\",jupyter=True)","ea6738d3":"text2 = 'Google is top tech company and ceo of google is Sundar Pichai, amazon ceo is Jeff'\ndoc=nlp2(text2)\n##  Visually we can observe how entities looks\ndisplacy.render(doc,style=\"ent\",jupyter=True)","50fa1327":"doc2=nlp1(text)\nfor token in doc2:\n    print(token, token.lemma_)","fda1629b":"# 2. Lemmatization:\nStemming and lemmatization are the techniques used to reducing a word into root word.\ne.g.==> Running= run, waiting ==> wait,etc\n\nBut stemming have its own drawbacks . like Stemming just removes or stems the last few characters of a word.\ne.g. Studies => Studi\n\nWe can see that using stemming those words are also generated who have no meaning.\n\nIn spacy only Lemmatization is present.","6cf5429a":"# 2. Named Entity Recognition using spaCy\n\nNamed entity recognition is a natural language processing technique that can automatically scan entire articles and pull out some fundamental entities in a text and classify them into predefined categories.\nWhen we read a text, we naturally recognize named entities like people, values, locations, and so on.\n\ne.g Narendra Modi born and raised in Vadnagar, a small town in northeastern Gujarat. Here we can understand that\n- Narendra Modi: person name\n- Vadnagar: Location\n- Gujarat: Location\n\nWe can tech same thing to computers using named entity recognition.\n\nIn spaCy there are many things\n\nThere are many types of entities like Organizations,Quantities,Monetary values,People\u2019s names,Company names,Geographic locations (Both physical and political),Product names,Dates and times,Amounts of money\n\nIt is also known as entity identification or entity extraction or entity chunking.\nHere is one examples of Named entity recognition.\n\n![image.png](attachment:f9fbc5ca-2281-4444-a1f2-e4fd8cce640f.png)","fe36d885":"# Top interesting NLP libraries\n\n1. SpaCy [Learn Spacy](https:\/\/github.com\/aishweta\/NLP-Specialization\/tree\/main\/Spacy)\n2. NLTK\n3. TextBlob\n4. Gensim\n5. Spark NLP\n6. HuggingFace\n7. RASA NLU","5507741a":"### Different spaCy\u2019s Statistical Models\n\nThere are three statistical models .\n\n1. en_core_web_sm: English multi-task CNN trained on OntoNotes. Size \u2013 11 MB\n2. en_core_web_md: English multi-task CNN trained on OntoNotes, with GloVe vectors trained on Common Crawl. Size \u2013 91 MB\n3. en_core_web_lg: English multi-task CNN trained on OntoNotes, with GloVe vectors trained on Common Crawl. Size \u2013 789 MB\n\nThese models are the power engines of spaCy. These models enable spaCy to perform several NLP related tasks, such as part-of-speech tagging, named entity recognition, and dependency parsing.\n\n![image.png](attachment:bf1c81aa-09e5-4029-852d-7b46c74144bf.png)]","61999169":"### How to Install spaCy??\n","2b9f9e48":"## spacy library uses:\n1. pos tagging\n2. enityt recognition\n   - in-built library based entity recognition\n   - custom entity extraction (train model on own data)\n3. lemmatization\n\n\n# 1. Part-of-Speech (POS) Tagging using spaCy\n1. What is POS Tagging?\n- It is a process of converting a sentence to forms \u2013 list of words, list of tuples (where each tuple is having a form (word, tag)). The tag in case of is a part-of-speech tag, and signifies whether the word is a noun, adjective, verb, and so on.\n\n2. Why POS tags is used?\n- Some words can function in more than one way when used in different circumstances.\n- The POS Tagging here plays a crucial role to understand in what context the word is used in the sentence.\n- POS Tagging is useful in sentence parsing, information retrieval, sentiment analysis, etc.","795aba08":"# 1. SpaCY\n\nLet's drive deep into Spacy Library.  Have Fun!!\n\nspaCy is a free and open-source library for Natural Language Processing (NLP) in Python with a lot of in-built capabilities. It\u2019s built for production use and provides a concise and user-friendly API.\n\n![image.png](attachment:b88e269f-24a8-4379-b13c-d13402f2169b.png)!","ce396c5e":"#### Lets try large version of model of spacy"}}