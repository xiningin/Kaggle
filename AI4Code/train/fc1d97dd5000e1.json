{"cell_type":{"e77ef012":"code","807254ad":"code","da108754":"code","d53296b1":"code","61bec972":"code","69b8f22a":"code","901fd3b2":"code","eb77bb24":"code","8f9a69be":"code","4115f2d6":"code","5a34bca6":"code","f766c821":"code","1f5da1cf":"code","c65fbad2":"code","ae6962dd":"code","b9a8dd96":"code","9f25aa32":"code","b4f4bee6":"code","73467f01":"code","804b2c4d":"code","204bc59a":"code","d7482d77":"code","ed155517":"code","bdac1c74":"code","aa18b93e":"code","7ae91494":"code","aa824f94":"code","c519b1f0":"code","4504621b":"code","10b1dd4e":"code","4c7c9e72":"code","5ea532a7":"code","857a23d1":"code","67426d00":"code","07161877":"code","05893f49":"code","576752ff":"code","0c916b6a":"code","23a17689":"code","d1b146dc":"code","ba714650":"code","d5895a19":"code","3be1a3c9":"code","d2dd6992":"code","ef628ff5":"code","551f3a51":"markdown","70360f08":"markdown","eee98003":"markdown","f0374a44":"markdown","54dc52ca":"markdown","0e79c1b5":"markdown","1c70faf0":"markdown","625b70b4":"markdown","e0c0d740":"markdown","7612b0b1":"markdown","af163552":"markdown","3e787da7":"markdown","c45dfb3d":"markdown","ff7f5540":"markdown","b85b12b4":"markdown","e2723019":"markdown","ee629225":"markdown","fdb82ffd":"markdown","9607481a":"markdown","a1922c12":"markdown","70543526":"markdown","f2d61522":"markdown","e6e959ef":"markdown","684e9416":"markdown","1b0ad839":"markdown","b625eecf":"markdown"},"source":{"e77ef012":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","807254ad":"import matplotlib.pyplot as plt\nimport seaborn as sns","da108754":"df=pd.read_csv('\/kaggle\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv')","d53296b1":"df.head()","61bec972":"### Checking data types of all columns\ndf.dtypes","69b8f22a":"### Checking data shapes\ndf.shape","901fd3b2":"df.describe()","eb77bb24":"#Checking null values\ndf.isnull().sum()","8f9a69be":"df.drop(['id','host_name','last_review'], axis = 1,inplace=True) ","4115f2d6":"df.reviews_per_month.fillna(value=0,inplace=True)\ndf.name.fillna(\"NoName\", inplace=True)","5a34bca6":"df.isnull().sum()","f766c821":"df[\"price\"].describe()","1f5da1cf":"plt.figure(figsize=(16, 6))\nsns.barplot(df.neighbourhood_group,df.price,hue=df.room_type,ci=None)","c65fbad2":"plt.figure(figsize=(16, 6))\nsns.countplot(df.neighbourhood_group,hue=df.room_type)","ae6962dd":"corrmat = df.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corrmat, vmax=0.9, square=True)","b9a8dd96":"#extracting the most popular neighbourhoods.\nmost_popular_neighbourhoods=df.neighbourhood.value_counts().head(13)","9f25aa32":"most_popular_neighbourhoods","b4f4bee6":"plt.figure(figsize=(16, 6))\nmost_popular_neighbourhoods.plot(kind='bar')","73467f01":"plt.figure(figsize=(15, 6))\nsns.scatterplot(x=df.neighbourhood_group,y=df.number_of_reviews,ci=False)","804b2c4d":"plt.figure(figsize=(15, 6))\nsns.barplot(x=df.neighbourhood_group,y=df.calculated_host_listings_count,ci=False)","204bc59a":"plt.figure(figsize=(15, 6))\nsns.barplot(x=df.neighbourhood_group,y=df.availability_365,hue=df.room_type,ci=False)","d7482d77":"plt.figure(figsize=(15, 6))\nsns.scatterplot(x=df.longitude,y=df.latitude,hue=df.room_type)","ed155517":"# importing necessary tools\n\nimport wordcloud\nimport functools\nimport nltk\n\n# words that won't add anything apart from what we already know from the other data.\nUNWANTED_WORDS = set(['manhattan', 'queen', 'brooklyn', 'nyc'])\n\n# drawing a graph\n\nfig, ax = plt.subplots(figsize=(12,8))\n\ntext = functools.reduce(lambda a,b: a + \" \" + str(b), df.sample(frac=0.3)['name'])\ntext = ' '.join([w for w in nltk.word_tokenize(text) if w.lower() not in UNWANTED_WORDS])\n\nwc = wordcloud.WordCloud(max_font_size=40).generate(text)\nax.imshow(wc, interpolation='bilinear')\nax.set_title(\"Most used words in the names\")\nplt.axis(\"off\")\nfig.show()","bdac1c74":"df.drop([\"name\",\"latitude\",\"longitude\", \"host_id\", \"neighbourhood\"], axis=1, inplace=True)","aa18b93e":"df.head()","7ae91494":"dataset_new = pd.get_dummies(df, columns=['neighbourhood_group',\"room_type\"], prefix = ['ng',\"rt\"],drop_first=True)","aa824f94":"from sklearn import metrics\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import train_test_split\nimport statsmodels.api as sm\nfrom scipy import stats","c519b1f0":"X1= dataset_new.loc[:, dataset_new.columns != 'price']","4504621b":"Y1 = dataset_new[\"price\"]","10b1dd4e":"x_train1, x_test1, y_train1, y_test1 = train_test_split(X1, Y1, test_size=0.20, random_state=42)","4c7c9e72":"### Fitting Linear regression\nreg1 = LinearRegression().fit(x_train1, y_train1)","5ea532a7":"### R squared value\nreg1.score(x_train1, y_train1)","857a23d1":"### Predicting \ny_pred1 = reg1.predict(x_test1)","67426d00":"### Calculate RMSE\nrmse1 = np.sqrt(metrics.mean_squared_error(y_test1, y_pred1))\nrmse1","07161877":"### Coefficients\nCoeff1 = pd.DataFrame(columns=[\"Variable\",\"Coefficient\"])\nCoeff1[\"Variable\"]=x_train1.columns\nCoeff1[\"Coefficient\"]=reg1.coef_\nCoeff1.sort_values(\"Coefficient\")","05893f49":"### Taking a closer look at the estimates\nX2 = sm.add_constant(x_train1)\nest = sm.OLS(y_train1, X2)\nest2 = est.fit()\nprint(est2.summary())","576752ff":"XL1= dataset_new.loc[:, dataset_new.columns != 'price']\nYL1 = dataset_new[\"price\"]\nx_trainL11, x_testL11, y_trainL11, y_testL11 = train_test_split(XL1, YL1, test_size=0.20, random_state=42)","0c916b6a":"regL1 = Lasso(alpha=0.01)\nregL1.fit(x_trainL11, y_trainL11)","23a17689":"### R squared\nregL1.score(x_trainL11, y_trainL11)","d1b146dc":"### RMSE\n### Smaller value than earlier\ny_predL1= regL1.predict(x_testL11)\nprint(np.sqrt(metrics.mean_squared_error(y_testL11,y_predL1)))","ba714650":"CoeffLS1 = pd.DataFrame(columns=[\"Variable\",\"Coefficients\"])\nCoeffLS1[\"Variable\"]=x_trainL11.columns\nCoeffLS1[\"Coefficients\"]=regL1.coef_\nCoeffLS1.sort_values(\"Coefficients\", ascending = False)","d5895a19":"from sklearn.tree import DecisionTreeRegressor\nDTree=DecisionTreeRegressor(min_samples_leaf=.0001)\nDTree.fit(x_train1,y_train1)\n\nprint('R-squared score (training): {:.3f}'.format(DTree.score(x_train1,y_train1)))\nprint('R-squared score (test): {:.3f}'.format(DTree.score(x_test1, y_test1)))","3be1a3c9":"### loading tools\n\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nimport matplotlib.image as pltimg\nfrom sklearn.metrics import accuracy_score","d2dd6992":"### instantiating the DecisionTreeClassifier model with criterion gini index\n\nclf_gini = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n\n\n### fit the model\nclf_gini.fit(x_train1, y_train1)","ef628ff5":"### visualizing tree\n\nimport graphviz \ndot_data = tree.export_graphviz(clf_gini, out_file = None, feature_names = x_train1.columns)\n\ngraph = graphviz.Source(dot_data) \n\ngraph","551f3a51":"# Modeling","70360f08":"Importing necessary packages","eee98003":"# Decision Tree experiment","f0374a44":"# Model Interpretation\n\nWe have the results of our Linear Regression Model, lets try to interpret it in details.\n\n1. We first look at the Adjusted R square value since this is a Multiple linear regression. It tell us that our independent variables can explain 8,9% of variations in our dependent variable. This is quite low.\n2. The constant or the y intercept has a value of 142.24. This means that putting all other x variables at zero, an Entire Apt\/Home in Bronx will have a predicted price of 142.24. When we created dummy variables, we dropped one dummy from each column which we use as reference.\n3. Let's now look at the coefficients. The coefficient of ng_Manhattan is 89.04. We interpret as: Everything else being constant, an Entire Apt\/ Home in Manhattan will cost 89.04 more that same in Bronx. \n4. We can similarly interpret coefficient of minimum night as: with everything else being constant, with every one unit increase in minimum number of nights, the predicted price decreases by 0.02. But this indicator depicted statistical insignifance. \n5. P values suggests how significant these estimates are. Considering alpha of 0.05, all variables, except minimum_nights, ng_Queens, ng_Staten Island, are statistically significant.","54dc52ca":"The above plot infers that:\n\nWords such as *Beautiful, Private Room, Studio, Apartment, Apt, Room, Spacious* are most frequently utilized in names of airbnb entries .","0e79c1b5":"The above graph presents the correlation level among data variables. We can observe that none of the variables are strictly correlated between each other. ","1c70faf0":"The above plot concludes:\n\n1. Staten Island properties remain mostly unoccupied as they are available most of the days.\n2. Manhattan properties are most occupied, since their availability are lower compared to others","625b70b4":"**Splitting into training and testing data**","e0c0d740":"We can observe that the average price is 152. Price varies between 0 to 10K","7612b0b1":"# Graphical explorations","af163552":"**After considering for futher prediction analysis, some variables wont help us. Thus we drop them**","3e787da7":"# Loading the data","c45dfb3d":"The above plot shows that :\n\nThe number of private rooms and entire homes\/apartments are much more than shared rooms.","ff7f5540":"After a quick analysis, I deiced to drop less effective variables such as the last_review, id, host_name as some values are missing. I have also filled the NaN values of reviews_per_month with zero and name by NoName.","b85b12b4":"**The above plot describes the number of reviews per each region of neighbourhood group.**\n\nIf we assume and consider number_of_reviews as the number of people who have stayed and provided their reviews, then Queens , Manhattan and Brooklyn are the most preferred places.","e2723019":"**The above count plot concludes:**\n\n1. Staten Island and Bronx have the least number of entries in the listings.\n2. Shared rooms are less available in the listings.\n3. Manhattan and Brooklyn neighbourhoods have far more entries in the listings.","ee629225":"The above plot tells that:\n\nManhattan has the most entries in data.","fdb82ffd":"# The most popular words in descriptions","9607481a":"This plot concludes that:\n\nWilliamsburg and Bedford-Stuyvesant are the most popular neighbourhood of all.","a1922c12":"# Lasso Regression Model","70543526":"# Decision Tree Regressor","f2d61522":"# Exploring data","e6e959ef":"**The above bar plot concludes that:**\n\n1. Manhattan is the most expensive region in neighbourhood group\n2. The price of entire home\/apt is more than any other room type.\n3. Bronx is the cheapest amoung neighbourhood groups.","684e9416":"Making dummies for neighbourhood_group and room_type","1b0ad839":"# Linear Regression Model","b625eecf":"We will use **Lasso regression** because it has the ability to eliminate the parameters that do not improve the model."}}