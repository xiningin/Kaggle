{"cell_type":{"ed6b4843":"code","b8798fcc":"code","031c8395":"code","3eef3adc":"code","70eaa216":"code","a4567f9f":"code","d57f1623":"code","970cbe7c":"code","624bef21":"code","13ff7e65":"code","0c776231":"code","b8c77261":"code","fb8f1e86":"code","bde55d6c":"code","3d6038c8":"code","217f3b93":"code","b9dba752":"code","f8b9383c":"code","84358249":"code","b43ee6aa":"code","72a5bb67":"code","ff14545a":"code","bdf20ba0":"code","ed55a779":"code","65f0cbd8":"code","a4c51f81":"code","5cf275a1":"code","b421f29e":"code","86cb3012":"markdown","b3486919":"markdown","d1f0a787":"markdown","bd358a7b":"markdown"},"source":{"ed6b4843":"import pandas as pd\nimport numpy as np\nimport seaborn as sns","b8798fcc":"base_Dataset = pd.read_csv(\"..\/input\/Credit_Card.csv\")","031c8395":"base_Dataset.describe().columns","3eef3adc":"base_Dataset=base_Dataset.sample(1000)","70eaa216":"base_Dataset.reset_index(inplace=True)","a4567f9f":"base_Dataset.drop(['index','ID'],axis=1,inplace=True)","d57f1623":"base_Dataset.shape","970cbe7c":"def nullvalue_function(base_dataset,percentage):\n    \n    # Checking the null value occurance\n    \n    print(base_dataset.isna().sum())\n\n    # Printing the shape of the data \n    \n    print(base_dataset.shape)\n    \n    # Converting  into percentage table\n    \n    null_value_table=pd.DataFrame((base_dataset.isna().sum()\/base_dataset.shape[0])*100).sort_values(0,ascending=False )\n    \n    null_value_table.columns=['null percentage']\n    \n    # Defining the threashold values \n    \n    null_value_table[null_value_table['null percentage']>percentage].index\n    \n    # Drop the columns that has null values more than threashold \n    base_dataset.drop(null_value_table[null_value_table['null percentage']>percentage].index,axis=1,inplace=True)\n    \n    # Replace the null values with median() # continous variables \n    for i in base_dataset.describe().columns:\n        base_dataset[i].fillna(base_dataset[i].median(),inplace=True)\n    # Replace the null values with mode() #categorical variables\n    #for i in base_dataset.describe(include='object').columns:\n     #   base_dataset[i].fillna(base_dataset[i].value_counts().index[0],inplace=True)\n  \n    print(base_dataset.shape)\n    \n    return base_dataset","624bef21":"base_dataset_null_value = nullvalue_function(base_Dataset, 30)","13ff7e65":"y=base_dataset_null_value['LIMIT_BAL']\nx=base_dataset_null_value.drop(['LIMIT_BAL'],axis=1)\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1)\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","0c776231":"from sklearn.ensemble import RandomForestRegressor\nlm=RandomForestRegressor()\nlm.fit(x_train,y_train)\nlm.predict(x_test)\npred_values_1=lm.predict(x_test)","b8c77261":"import numpy as np\ndef regression_model(predicted_values,y_test):\n    \n    from sklearn.metrics import mean_absolute_error,r2_score\n    from sklearn.metrics import mean_squared_error\n    total_error=sum(abs(predicted_values-y_test.values))\n    MAE=mean_absolute_error(y_test.values,predicted_values)\n    MSE=mean_squared_error(y_test.values,predicted_values)\n    RMSE=np.sqrt(mean_squared_error(y_test.values,predicted_values))\n    MAPE=sum(abs((y_test.values-predicted_values)\/(y_test.values)))\/x_test.shape[0]\n    r2=r2_score(predicted_values,y_test)\n    print(\"total error\",total_error)\n    print(\"MSE\",MSE)\n    print(\"MAE\",MAE)\n    print(\"RMSE\",RMSE)\n    print(\"MAPE\",MAPE)\n    print(\"R2\",r2)\n    return [MSE, MAE,RMSE,MAPE,r2]","fb8f1e86":"regression_model(pred_values_1,y_test)","bde55d6c":"from sklearn.linear_model import LinearRegression\nlm=LinearRegression()\nlm.fit(x_train,y_train)\nlm.predict(x_test)\npred_values_2=lm.predict(x_test)","3d6038c8":"import numpy as np\ndef regression_model(predicted_values,y_test):\n    \n    from sklearn.metrics import mean_absolute_error,r2_score\n    from sklearn.metrics import mean_squared_error\n    total_error=sum(abs(predicted_values-y_test.values))\n    MAE=mean_absolute_error(y_test.values,predicted_values)\n    MSE=mean_squared_error(y_test.values,predicted_values)\n    RMSE=np.sqrt(mean_squared_error(y_test.values,predicted_values))\n    MAPE=sum(abs((y_test.values-predicted_values)\/(y_test.values)))\/x_test.shape[0]\n    r2=r2_score(predicted_values,y_test)\n    print(\"total error\",total_error)\n    print(\"MSE\",MSE)\n    print(\"MAE\",MAE)\n    print(\"RMSE\",RMSE)\n    print(\"MAPE\",MAPE)\n    print(\"R2\",r2)\n    return [MSE, MAE,RMSE,MAPE,r2]","217f3b93":"regression_model(pred_values_2,y_test)","b9dba752":"from sklearn.neighbors import KNeighborsRegressor\nlm=KNeighborsRegressor(n_neighbors=3)\nlm.fit(x_train,y_train)\nlm.predict(x_test)\npred_values_3=lm.predict(x_test)","f8b9383c":"import numpy as np\ndef regression_model(predicted_values,y_test):\n    from sklearn.metrics import mean_absolute_error,r2_score\n    from sklearn.metrics import mean_squared_error\n    total_error=sum(abs(predicted_values-y_test.values))\n    MAE=mean_absolute_error(y_test.values,predicted_values)\n    MSE=mean_squared_error(y_test.values,predicted_values)\n    RMSE=np.sqrt(mean_squared_error(y_test.values,predicted_values))\n    MAPE=sum(abs((y_test.values-predicted_values)\/(y_test.values)))\/x_test.shape[0]\n    r2=r2_score(predicted_values,y_test)\n    print(\"total error\",total_error)\n    print(\"MSE\",MSE)\n    print(\"MAE\",MAE)\n    print(\"RMSE\",RMSE)\n    print(\"MAPE\",MAPE)\n    print(\"R2\",r2)\n    return [MSE, MAE,RMSE,MAPE,r2]","84358249":"regression_model(pred_values_3,y_test)","b43ee6aa":"from sklearn.ensemble import BaggingRegressor\nlm=BaggingRegressor(n_estimators=10)\nlm.fit(x_train,y_train)\nlm.predict(x_test)\npred_values_4=lm.predict(x_test)\n\nimport numpy as np\ndef regression_model(predicted_values,y_test):\n    \n    from sklearn.metrics import mean_absolute_error,r2_score\n    from sklearn.metrics import mean_squared_error\n    total_error=sum(abs(predicted_values-y_test.values))\n    MAE=mean_absolute_error(y_test.values,predicted_values)\n    MSE=mean_squared_error(y_test.values,predicted_values)\n    RMSE=np.sqrt(mean_squared_error(y_test.values,predicted_values))\n    MAPE=sum(abs((y_test.values-predicted_values)\/(y_test.values)))\/x_test.shape[0]\n    r2=r2_score(predicted_values,y_test)\n    print(\"total error\",total_error)\n    print(\"MSE\",MSE)\n    print(\"MAE\",MAE)\n    print(\"RMSE\",RMSE)\n    print(\"MAPE\",MAPE)\n    print(\"R2\",r2)\n    return [MSE, MAE,RMSE,MAPE,r2]","72a5bb67":"regression_model(pred_values_4,y_test)","ff14545a":"from sklearn.tree import DecisionTreeRegressor\nlm=DecisionTreeRegressor()\nlm.fit(x_train,y_train)\nlm.predict(x_test)\npred_values_5=lm.predict(x_test)\n\nimport numpy as np\ndef regression_model(predicted_values,y_test):\n    \n    from sklearn.metrics import mean_absolute_error,r2_score\n    from sklearn.metrics import mean_squared_error\n    total_error=sum(abs(predicted_values-y_test.values))\n    MAE=mean_absolute_error(y_test.values,predicted_values)\n    MSE=mean_squared_error(y_test.values,predicted_values)\n    RMSE=np.sqrt(mean_squared_error(y_test.values,predicted_values))\n    MAPE=sum(abs((y_test.values-predicted_values)\/(y_test.values)))\/x_test.shape[0]\n    r2=r2_score(predicted_values,y_test)\n    print(\"total error\",total_error)\n    print(\"MSE\",MSE)\n    print(\"MAE\",MAE)\n    print(\"RMSE\",RMSE)\n    print(\"MAPE\",MAPE)\n    print(\"R2\",r2)\n    return [MSE, MAE,RMSE,MAPE,r2]","bdf20ba0":"regression_model(pred_values_5,y_test)","ed55a779":"comparision=pd.DataFrame(pred_values_1,pred_values_4)","65f0cbd8":"comparision.reset_index(inplace=True)","a4c51f81":"comparision.columns=['Linear','Bagging']","5cf275a1":"comparision","b421f29e":"comparision['actual']=y_test.values","86cb3012":"********Model building","b3486919":"****EDA Analysis","d1f0a787":"With the above all algorithms, Bagging regressor is the more efficient aalgorithm to make prediction of the credit card limit balance.","bd358a7b":" **Credit card makes use of a variety of alternative data--including telco and transactional information--to predict their clients' credit balance spending and limit balance. While Credit card is currently using various statistical and machine learning methods to make these predictions, they're challenging Kagglers to help them unlock the full potential of their data. Doing so will ensure that clients capable of repayment are at time and provide more limitt balance.**"}}