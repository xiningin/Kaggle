{"cell_type":{"3c8986b1":"code","4f61b4b1":"code","15b7a976":"code","cddc9127":"code","2ecf4a11":"code","03a426e9":"code","9426fba5":"code","d3d4d3a3":"code","35f58de4":"code","6d56d87d":"code","944d3dec":"code","0c5fb20f":"code","cb7fc486":"code","933140dc":"code","73fca36f":"code","e6094c2a":"code","125a2f1d":"code","98cd07a2":"code","1cfd4d80":"code","8f2a6ae0":"code","7dc9925f":"code","eee7f069":"code","c556b695":"code","0c360a3c":"code","c40669fc":"code","f10784c5":"code","b8dbc68e":"code","8dc423b0":"code","c8732c7e":"code","22e8e7fe":"code","efcc4c6c":"code","816524a4":"code","cf6edde0":"code","a9800fbd":"code","1d9578c4":"code","8e68ae0a":"code","79c76e06":"code","82650d08":"code","a0ef0d56":"code","29aa9df1":"code","54a3a62b":"markdown","2d379f7a":"markdown","a5c45e74":"markdown","c3fafbc9":"markdown","1e14af32":"markdown","005742f0":"markdown","e4e28e74":"markdown","572d0ed8":"markdown","647e0172":"markdown","7dd0401b":"markdown","fee206e1":"markdown"},"source":{"3c8986b1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4f61b4b1":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","15b7a976":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","cddc9127":"\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","2ecf4a11":"train_data.head()","03a426e9":"train_data.info()","9426fba5":"# Pclass\ng = sns.catplot(\"Survived\", col=\"Pclass\", col_wrap=3,\n\n                data=train_data,\n\n                kind=\"count\", height=2.5, aspect=.8)","d3d4d3a3":"train_data['Name_clean'] = train_data['Name'].apply(lambda x: x.split(',')[1].lstrip())\ntrain_data['MrMs'] =  train_data['Name_clean'].apply(lambda x: x.split(' ')[0].strip())\ntrain_data.loc[~train_data['MrMs'].isin(['Mr.', 'Miss.', 'Mrs.', 'Master.']), 'MrMs'] = 'Other'\ntrain_data['MrMs'].value_counts()","35f58de4":"# # MrMs\ng = sns.catplot(\"Survived\", col=\"MrMs\", col_wrap=3,\n\n                data=train_data,\n\n                kind=\"count\", height=2.5, aspect=.8)\n","6d56d87d":"mrms = train_data.groupby('MrMs').agg(\n    survivors = ('Survived', 'sum'),\n    total = ('Survived', 'count')\n).reset_index()\nmrms['pct_survive'] = mrms['survivors']\/mrms['total']\nmrms.plot(\n    x='MrMs', y='pct_survive'\n)","944d3dec":"# Sex'\ng = sns.catplot(\"Survived\", col=\"Sex\", col_wrap=3,\n\n                data=train_data,\n\n                kind=\"count\", height=2.5, aspect=.8)","0c5fb20f":"# Sex\ntrain_data['Sex_mod'] = train_data['Sex']\ntrain_data.loc[train_data['Age'] <= 12, 'Sex_mod'] = 'children'\ng = sns.catplot(\"Survived\", col=\"Sex_mod\", col_wrap=3,\n\n                data=train_data,\n\n                kind=\"count\", height=2.5, aspect=.8)","cb7fc486":"# Age\nsns.distplot(train_data[train_data['Survived']==1][\"Age\"] , color=\"green\", label=\"Survived\")\nsns.distplot(train_data[train_data['Survived']==0]['Age'] , color=\"red\", label=\"Died\")\nplt.show()","933140dc":"# How many are inputed and how many are real ages\ntrain_data['Age_imputed'] = (train_data['Age']%1)>0\n\nfig, ax = plt.subplots(figsize=(6,4))\ntrain_data.groupby('Age_imputed').size().plot(\n    ax=ax, kind='bar'\n)\nplt.show()","73fca36f":"# SibSp\ng = sns.catplot(\"Survived\", col=\"SibSp\", col_wrap=3,\n\n                data=train_data,\n\n                kind=\"count\", height=2.5, aspect=.8)","e6094c2a":"# Grouping all users who have at least 1 sibiling\/spouses in Titanic\ntrain_data['SibSp_1'] = (train_data['SibSp']>0).astype(int)\ng = sns.catplot(\"Survived\", col=\"SibSp_1\", col_wrap=3,\n                data=train_data,\n                kind=\"count\", height=2.5, aspect=.8)","125a2f1d":"# Parch: # of parents \/ children aboard the Titanic\ng = sns.catplot(\"Survived\", col=\"Parch\", col_wrap=3,\n                data=train_data,\n                kind=\"count\", height=2.5, aspect=.8)","98cd07a2":"# Grouping Parch: # of parents \/ children aboard the Titanic\ntrain_data['Parch_1'] = (train_data['Parch']>0).astype(int)\ng = sns.catplot(\"Survived\", col=\"Parch_1\", col_wrap=3,\n                data=train_data,\n                kind=\"count\", height=2.5, aspect=.8)","1cfd4d80":"# Ticket number\ntrain_data['Ticket']\n# Data has to be formatted","8f2a6ae0":"ticket = pd.DataFrame(train_data['Ticket'].str.split(' '))\nticket['len'] =  ticket['Ticket'].apply(lambda x: len(x))\nticket['element_0'] = np.where(ticket['len']==1, 'NA', ticket['Ticket'].apply(lambda x: x[0]))\nticket['element_0'].value_counts()","7dc9925f":"ticket","eee7f069":"# Fare\nsns.distplot(train_data[train_data['Survived']==1][\"Fare\"] , color=\"green\", label=\"Survived\")\nsns.distplot(train_data[train_data['Survived']==0]['Fare'] , color=\"red\", label=\"Died\")\nplt.show()","c556b695":"print('Survived-----')\nprint(train_data[train_data['Survived']==1]['Fare'].describe())\nprint('Died-----')\nprint(train_data[train_data['Survived']==0]['Fare'].describe())","0c360a3c":"sns.boxplot(x=\"Survived\", y=\"Fare\", data=train_data)\nplt.show()","c40669fc":"g = sns.catplot(x=\"Survived\", y=\"Fare\", data=train_data,\n                height=5, aspect=.8)","f10784c5":"# Transforming fare (log)\ntrain_data['Fare_log'] = np.log(train_data['Fare']+1)\nsns.distplot(train_data[train_data['Survived']==1][\"Fare_log\"] , color=\"green\", label=\"Survived\")\nsns.distplot(train_data[train_data['Survived']==0]['Fare_log'] , color=\"red\", label=\"Died\")\nplt.show()","b8dbc68e":"# Cabin: A lot of nulls so no looking in here for now\n# Can I infer cabin from fare?\ntrain_data['Cabin_category'] = train_data['Cabin'].str[0]\ntrain_data['Cabin_category'].value_counts()","8dc423b0":"g = sns.catplot(\"Survived\", col=\"Cabin_category\", col_wrap=3,\n                data=train_data.sort_values(by='Cabin_category'),\n                kind=\"count\", height=2.5, aspect=.8)","c8732c7e":"cabin_categories = train_data.groupby('Cabin_category').agg(\n    survivors = ('Survived', 'sum'),\n    total = ('Survived', 'count')\n).reset_index()\ncabin_categories['pct_survive'] = cabin_categories['survivors']\/cabin_categories['total']\ncabin_categories.plot(\n    x='Cabin_category', y='pct_survive'\n)","22e8e7fe":"g = sns.FacetGrid(train_data[train_data['Cabin_category']!='T'].sort_values(by='Cabin_category')\n                  , col=\"Cabin_category\", palette=\"Set1\", sharey=False, col_wrap=1,\n                 aspect = 3)\ng.map(sns.distplot, 'Fare')\nplt.show()","efcc4c6c":"# Embarked: Port of Embarkation \tC = Cherbourg, Q = Queenstown, S = Southampton\ng = sns.catplot(\"Survived\", col=\"Embarked\", col_wrap=3,\n                data=train_data,\n                kind=\"count\", height=2.5, aspect=.8)","816524a4":"sns.heatmap(data=train_data.isnull(), cbar=False)\nplt.show()","cf6edde0":"sns.heatmap(\n    data=train_data[['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Embarked', 'Age', 'Cabin']].isna().sort_values(by=['Age', 'Cabin']),\n    cbar=False)\nplt.show()","a9800fbd":"# Age and SibSp_1\nprint('Without Sib')\nsns.distplot(train_data[(train_data['Survived']==1) & (train_data['Sex']=='male')][\"Age\"] , color=\"green\", label=\"Survived\")\nsns.distplot(train_data[(train_data['Survived']==0) & (train_data['Sex']=='male')]['Age'] , color=\"red\", label=\"Died\")\nplt.show()\nprint('With Sib')\nsns.distplot(train_data[(train_data['Survived']==1) & (train_data['Sex']=='female')][\"Age\"] , color=\"green\", label=\"Survived\")\nsns.distplot(train_data[(train_data['Survived']==0) & (train_data['Sex']=='female')]['Age'] , color=\"red\", label=\"Died\")\nplt.show()","1d9578c4":"# Feature engineering\ntest_data['SibSp_1'] = (test_data['SibSp']>0).astype(int)\ntest_data['Parch_1'] = (test_data['Parch']>0).astype(int)\ntest_data['Name_clean'] = test_data['Name'].apply(lambda x: x.split(',')[1].lstrip())\ntest_data['MrMs'] =  test_data['Name_clean'].apply(lambda x: x.split(' ')[0].strip())\ntest_data.loc[~test_data['MrMs'].isin(['Mr.', 'Miss.', 'Mrs.', 'Master.']), 'MrMs'] = 'Other'\ntest_data['Sex_mod'] = test_data['Sex']\ntest_data.loc[test_data['Age'] <= 12, 'Sex_mod'] = 'children'\ntest_data.head()","8e68ae0a":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test_kaggle = pd.get_dummies(test_data[features])\n\n# Model to test locally ----\nmodel_small = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nscores_cv = cross_val_score(model_small, X, y, cv=5, scoring='accuracy')\nprint('Accuracy: ')\nprint(np.mean(scores_cv))\n\n\n# Final model ----\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test_kaggle)\n\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission_v0.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n","79c76e06":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp_1\", \"Parch_1\", \"Embarked\"]\nX = pd.get_dummies(train_data[features])\nX_test_kaggle = pd.get_dummies(test_data[features])\n\n# Model to test locally ----\nmodel_small = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nscores_cv = cross_val_score(model_small, X, y, cv=5, scoring='accuracy')\nprint('Accuracy: ')\nprint(np.mean(scores_cv))\n\n\n# Final model ----\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test_kaggle)\n\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission_v0.csv', index=False)\nprint(\"Your submission was successfully saved!\")","82650d08":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp_1\", \"Parch_1\", \"Embarked\"]\nX = pd.get_dummies(train_data[features])\nX['Age'] = train_data['Age'].fillna(train_data['Age'].mean())\nX_test_kaggle = pd.get_dummies(test_data[features])\nX_test_kaggle['Age'] = test_data['Age'].fillna(test_data['Age'].mean())\n\n# Model to test locally ----\nmodel_small = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nscores_cv = cross_val_score(model_small, X, y, cv=5, scoring='accuracy')\nprint('Accuracy: ')\nprint(np.mean(scores_cv))\n\n\n# Final model ----\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test_kaggle)\n\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission_v2.csv', index=False)\nprint(\"Your submission was successfully saved!\")","a0ef0d56":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"Sex_mod\", \"SibSp_1\", \"Parch_1\", \"Embarked\", 'MrMs']\nX = pd.get_dummies(train_data[features])\nX['Age'] = train_data['Age'].fillna(train_data['Age'].mean())\nX['Fare'] = train_data['Fare'].fillna(train_data['Fare'].mean())\nX_test_kaggle = pd.get_dummies(test_data[features])\nX_test_kaggle['Age'] = test_data['Age'].fillna(test_data['Age'].mean())\nX_test_kaggle['Fare'] = test_data['Fare'].fillna(test_data['Fare'].mean())\n\n# Model to test locally ----\nmodel_small = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nscores_cv = cross_val_score(model_small, X, y, cv=5, scoring='accuracy')\nprint('Accuracy: ')\nprint(np.mean(scores_cv))\n\n\n# Final model ----\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test_kaggle)\n\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission_v4.csv', index=False)\nprint(\"Your submission was successfully saved!\")","29aa9df1":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"Sex_mod\", \"SibSp_1\", \"Parch_1\", \"Embarked\", 'MrMs']\nX = pd.get_dummies(train_data[features])\nX['Age'] = train_data['Age'].fillna(train_data['Age'].mean())\n# X['Fare'] = train_data['Fare'].fillna(train_data['Fare'].mean())\nX_test_kaggle = pd.get_dummies(test_data[features])\nX_test_kaggle['Age'] = test_data['Age'].fillna(test_data['Age'].mean())\n# X_test_kaggle['Fare'] = test_data['Fare'].fillna(test_data['Fare'].mean())\n\n# Model to test locally ----\nmodel_small = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nscores_cv = cross_val_score(model_small, X, y, cv=5, scoring='accuracy')\nprint('Accuracy: ')\nprint(np.mean(scores_cv))\n\n# Final model ----\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test_kaggle)\n\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission_v4.csv', index=False)\nprint(\"Your submission was successfully saved!\")","54a3a62b":"## Testing submissions","2d379f7a":"## Feature engineering","a5c45e74":"Including age and fare","c3fafbc9":"## First stupid model with variables we dont have to format\n\n - Y: Survived\n - Pclass\n - Sex\n - Age * \n - SibSp_1\n - Parch_1\n - Ticket  (x)\n - Fare (x)\n - Cabin (x)\n - Embarked\n \n### Dummy model","1e14af32":"**Including age (Imputation of NA with mean)**","005742f0":"## Patterns in missing data\n- ","e4e28e74":"Which information is available in ticket?","572d0ed8":"Almost all users with missing age have also missing cabin\n\n## Correlation between variables\n","647e0172":"Exploring variables individually","7dd0401b":"### First model (Adding non-processed variables)","fee206e1":"## EDA\n\n**Variable Notes**\n\npclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower\n\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nparch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.\n\nsibsp \t# of siblings \/ spouses aboard the Titanic \t\nparch \t# of parents \/ children aboard the Titanic"}}