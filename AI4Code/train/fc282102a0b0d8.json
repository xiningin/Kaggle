{"cell_type":{"6688554c":"code","cb991b82":"code","de351e84":"code","73940d60":"code","d9c5e598":"code","b233c5dc":"code","76ad4c04":"code","af2c5ebc":"code","bee3a817":"code","ab9513dc":"code","94e08ac2":"code","a81fdfb4":"code","6d5fba7c":"code","aa20a274":"code","dc256d66":"markdown","0a6ce4ce":"markdown","e29eba3c":"markdown","11ab03db":"markdown","e9434727":"markdown"},"source":{"6688554c":"from argparse import Namespace\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport numpy as np\n\nfrom sklearn import model_selection\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score","cb991b82":"args = Namespace(\n    data_csv = '\/kaggle\/input\/parbin\/data.csv',\n    data_2_csv = '\/kaggle\/input\/parbin\/data_2.csv',\n    data_3_csv = '\/kaggle\/input\/parbin\/data_3.csv',\n\n\n    truth_csv = '\/kaggle\/input\/parbin\/truth.csv',\n    truth_2_csv = '\/kaggle\/input\/parbin\/truth.csv',\n    truth_3_csv = '\/kaggle\/input\/parbin\/truth.csv',\n)","de351e84":"reading_df = pd.read_csv(args.data_csv)\ndel reading_df['Unnamed: 12']\nreading_2_df = pd.read_csv(args.data_2_csv)\n\n\ntruth_df = pd.read_csv(args.truth_csv)\ntruth_2_df = pd.read_csv(args.truth_2_csv)","73940d60":"reading_df","d9c5e598":"def take_n_sec_samples(\n    sensor_df:pd.DataFrame, label_df:pd.DataFrame, n:int, head:bool = True\n):\n    \"\"\"\n    Args:\n        sensor_df: sensor reading df\n        label_df: df containing label for every minute\n        n: number of seconds to take, if not enough, takes as much as possible\n        head: Take n rows from the head, else take n rows from the tail\n    Returns:\n        df: pd.DataFrame with every n seconds labelled samples. \n            Uses sql join, hence contains all columns from both df. \n            Unrequired columns should be dropped manually.\n    \"\"\"\n    sensor_df['time'] = sensor_df.Time.map(lambda x: pd.to_datetime(x).strftime(\"%H:%M\"))\n    label_df['time'] = label_df.Time.map( lambda x: pd.to_datetime(x).strftime(\"%H:%M\"))\n    \n    merge_df = pd.merge(sensor_df,label_df, on='time')    \n    minutes = sorted(list(set(sensor_df['time'])))\n    \n    df = None\n    \n    for minute in minutes:\n        if not head:\n            _temp = merge_df[merge_df.time == minute].tail(n).copy()\n        else:\n            _temp = merge_df[merge_df.time == minute].head(n).copy()\n        \n        if not isinstance(df,pd.DataFrame):\n            df = _temp.copy()\n        else:\n            df = pd.concat([df,_temp],axis=0)\n    df =  df.reset_index()\n    return df\n    ","b233c5dc":"x = take_n_sec_samples(reading_df, truth_df, 2, True)\nx","76ad4c04":"sns.heatmap(x.corr())","af2c5ebc":"#select whatever features that you want\n_df = x.copy()\n_df = _df[['time','22_Temp','22_humidity','21_Temp','21_humidity']].copy()\n_df\n","bee3a817":"# df1 = df.groupby('a')['b'].apply(list).reset_index(name='new')","ab9513dc":"cols = list(_df.columns)\ncols.remove('time') # we are gonna group everything else on 'time'\n\ngroup_cols = []\ngrouped_df = None\n\nfor col in cols:\n    c = _df.groupby('time')[col].apply(list).reset_index(name=col)\n    if not isinstance(grouped_df,pd.DataFrame):\n        grouped_df = c\n    else:\n        grouped_df = pd.merge(grouped_df, c, on='time')","94e08ac2":"grouped_df #grouped for every 2 seconds","a81fdfb4":"_df.groupby('time')['22_Temp'].apply(list)","6d5fba7c":"#whatever ground truth you want, i am using number of people\n_t = x.drop_duplicates(subset=['time'], keep='first')[['time','number of people']]","aa20a274":"pd.merge(grouped_df, _t)","dc256d66":"# Take N sec samples","0a6ce4ce":"# Read the data","e29eba3c":"# Creating grouped lists","11ab03db":"# attach ground truth to the grouped df","e9434727":"!ls"}}