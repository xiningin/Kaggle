{"cell_type":{"2c90756e":"code","493e9f58":"code","c61ca95e":"code","321c0ca8":"code","a922d634":"code","3aa8bd32":"code","21624a61":"code","16b98883":"code","81fa5b02":"code","a5ccf232":"code","02085145":"code","4d7f304b":"code","a1562255":"code","60add569":"code","9d4fb645":"code","e5a02a75":"code","b090c5ea":"code","e3ed15d7":"code","02a47ef9":"code","335f9fc3":"code","65ed3f85":"code","d9847a46":"code","d4c1dbd9":"code","b1a2dab5":"code","942a8b76":"code","46b77e4d":"code","466f63b9":"code","f87186fd":"code","40fcd11b":"code","86c57287":"code","580a4706":"code","3cfe4f96":"code","3f4c7bc6":"code","30bd7efa":"code","03a43e35":"code","052c89dd":"code","95c65536":"code","87cd04be":"code","5da8b351":"code","ec8ab699":"code","67fd214c":"code","8c9e4912":"code","02d5a50e":"code","35e614ce":"code","d50fd0e8":"code","9f1da22e":"code","00ab9c08":"code","ea84bcc4":"code","cfc039c3":"code","7d9c30bc":"code","f4794df4":"code","d20e4893":"code","54fdc70c":"code","e31f35dd":"code","04784108":"code","4705d703":"code","996e1dc0":"code","3ceacd7c":"code","f229d716":"code","2b0997ba":"code","29775793":"code","92c3e0a3":"code","af5af96d":"code","02839243":"code","7dbda740":"code","e6fcd0d2":"code","a1884543":"code","b686007a":"code","1e2bafc8":"code","c968c396":"code","35088c8f":"code","999052a8":"code","a72ed852":"code","d6faa191":"code","6746696a":"code","2654e96f":"code","49b4ce5f":"code","d9075acf":"code","9bdd52c3":"code","eb1d448f":"code","49e4d483":"code","8e6b1365":"code","8c9d5fae":"code","82e535fe":"code","ce8da240":"code","bbd399c8":"code","097aa29f":"code","cdd7b6f5":"markdown","ca2143a0":"markdown","424f1c26":"markdown","5e6ff012":"markdown","2e338ff5":"markdown","1cf0fd83":"markdown","b0385e33":"markdown","5c667c05":"markdown","ebc2d74c":"markdown","e28d2c70":"markdown","3054c671":"markdown","a6204125":"markdown","8e6a5ab6":"markdown","ceb23fa8":"markdown","772c1205":"markdown","d5f05848":"markdown","eee2a574":"markdown","4a3668b8":"markdown","b91ad78e":"markdown","54401fb0":"markdown","0d0ee333":"markdown","4772e827":"markdown","c4d53266":"markdown","2a684106":"markdown","bf602f4b":"markdown","1a4bd124":"markdown","97d8e16c":"markdown","d2df1347":"markdown","273e1d29":"markdown","d0c80a47":"markdown","7df34107":"markdown","2b1799aa":"markdown","c0b440ad":"markdown","282165ab":"markdown","54b9e5fb":"markdown","9d6a8074":"markdown","3700c308":"markdown","e95842fa":"markdown","61794db1":"markdown","b3b58049":"markdown","db7ef9a6":"markdown","e12fa2a4":"markdown","3bfa5b34":"markdown","8f66620c":"markdown","ae37b2f1":"markdown"},"source":{"2c90756e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","493e9f58":"import plotly as py\nimport plotly.graph_objs as go\nimport seaborn as sns\nimport matplotlib.pyplot as plt","c61ca95e":"test=pd.read_csv('..\/input\/hr-analytics-job-change-of-data-scientists\/aug_test.csv')\ntrain=pd.read_csv('..\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv')","321c0ca8":"train.head()","a922d634":"test.head()","3aa8bd32":"print (\"The training data set has {a} rows and {b} columns\".format(a=train.shape[0], b=train.shape[1]))\nprint (\"The testing data set has {a} rows and {b} columns\".format(a=test.shape[0], b=test.shape[1]))","21624a61":"(train.isna().sum()\/train.shape[0])*100","16b98883":"(test.isna().sum()\/test.shape[0])*100","81fa5b02":"print (\"we have {} number of 'NAN' values in experinece column\".format (train.experience.isna().sum()))","a5ccf232":"# get the 'nan' values from experience column\ntrain[train.experience.isna()]","02085145":"from scipy.stats import chi2_contingency\nfor items in list(train.columns):\n    chi_res = chi2_contingency(pd.crosstab(train['experience'], train[items]))\n    print('{} ===> Chi2 Statistic: {}, p-value: {}'.format(items, round(chi_res[0],3), round(chi_res[1], 4)))","4d7f304b":"train.experience.fillna('<1', inplace=True)\ntest.experience.fillna('<1', inplace=True)\nprint(\"Null values of test and train data in experience column are {} and {}, respectively\".format(test.experience.isna().sum(), test.experience.isna().sum()))","a1562255":"train.experience.unique()","60add569":"test.experience.unique()","9d4fb645":"train.experience[train.experience=='>20']='21'\ntrain.experience[train.experience=='<1']='0'\npd.to_numeric(train.experience)\ntest.experience[test.experience=='>20']='21'\ntest.experience[test.experience=='<1']='0'\npd.to_numeric(test.experience)","e5a02a75":"print (\"we have {} number of 'NAN' values in experinece column\".format (train.enrolled_university.isna().sum()))","b090c5ea":"train.education_level.unique()","e3ed15d7":"train[train.education_level.isna()]","02a47ef9":"a=train[(train.enrolled_university=='no_enrollment') & (train.education_level=='High School')].shape [0]\nb=train[(train.enrolled_university=='no_enrollment') & (train.education_level=='Primary School')].shape [0]\nprint(\"number of no_enrollment with High School: {}\".format(a))\nprint(\"number of no_enrollment with High School: {}\".format(b))","335f9fc3":"train.education_level[(train.enrolled_university=='no_enrollment') & (train.education_level.isna())] = \"High School\"","65ed3f85":"train[train.education_level.isna()]","d9847a46":"train.enrolled_university.unique()","d4c1dbd9":"a=train[(train.enrolled_university=='Full time course') & (train.education_level=='Masters')].shape [0]\nb=train[(train.enrolled_university=='Full time course') & (train.education_level=='Phd')].shape [0]\nc=train[(train.enrolled_university=='Full time course') & (train.education_level=='Graduate')].shape [0]\nprint(\"number of 'Full time course' with Masters degree: {}\".format(a))\nprint(\"number of 'Full time course' with PhD degree: {}\".format(b))\nprint(\"number of 'Full time course' with Graduate degree: {}\".format(c))","b1a2dab5":"a=train[(train.enrolled_university=='Part time course') & (train.education_level=='Masters')].shape [0]\nb=train[(train.enrolled_university=='Part time course') & (train.education_level=='Phd')].shape [0]\nc=train[(train.enrolled_university=='Part time course') & (train.education_level=='Graduate')].shape [0]\nprint(\"number of 'Part time course' with Masters degree: {}\".format(a))\nprint(\"number of 'Part time course' with PhD degree: {}\".format(b))\nprint(\"number of 'Part time course' with Graduate degree: {}\".format(c))","942a8b76":"train.education_level[(train.enrolled_university=='Full time course') & (train.education_level.isna())] = \"Graduate\"\ntrain.education_level[(train.enrolled_university=='Full time course') & (train.education_level.isna())] = \"Graduate\"\ntest.education_level[(test.enrolled_university=='Full time course') & (test.education_level.isna())] = \"Graduate\"\ntest.education_level[(test.enrolled_university=='Full time course') & (test.education_level.isna())] = \"Graduate\"","46b77e4d":"train.drop((train.education_level[train.education_level.isna()]).index, inplace=True)\ntest.drop((test.education_level[test.education_level.isna()]).index, inplace=True)","466f63b9":"train.enrolled_university.unique()","f87186fd":"sns.countplot(x='enrolled_university', hue='education_level', data=train)","40fcd11b":"train.enrolled_university[train.enrolled_university.isna()]=\"no_enrollment\"\ntest.enrolled_university[test.enrolled_university.isna()]=\"no_enrollment\"","86c57287":"train.last_new_job.unique()","580a4706":"train.last_new_job[(train.last_new_job.isna()) & (train.relevent_experience=='No relevent experience')]='never'\ntest.last_new_job[(test.last_new_job.isna()) & (test.relevent_experience=='No relevent experience')]='never'","3cfe4f96":"train.drop((train.last_new_job[train.last_new_job.isna()]).index, inplace=True)\ntest.drop((test.last_new_job[test.last_new_job.isna()]).index, inplace=True)","3f4c7bc6":"train.last_new_job[train.last_new_job=='>4']='5'\ntrain.last_new_job[train.last_new_job=='never']='0'\npd.to_numeric(train.last_new_job)\ntest.last_new_job[test.last_new_job=='>4']='5'\ntest.last_new_job[test.last_new_job=='never']='0'\npd.to_numeric(test.last_new_job)","30bd7efa":"(train.isna().sum()\/train.shape[0])*100","03a43e35":"train2=train.fillna('nan')\nfig=go.Figure(data=[go.Pie(labels=['Male', 'nan', 'Female', 'Other'], values=train2.gender.value_counts())])\nfig.update_traces( hole= 0.3, hoverinfo='label+percent', textinfo='value', textfont_size=20)\nfig.show()","052c89dd":"M=train[(train.gender=='Male') & (train.target==1.0)].shape[0]\/train[(train.gender=='Male') & (train.target==0.0)].shape[0]\nF=train[(train.gender=='Female') & (train.target==1.0)].shape[0]\/train[(train.gender=='Female') & (train.target==0.0)].shape[0]\nO=train[(train.gender=='Other') & (train.target==1.0)].shape[0]\/train[(train.gender=='Other') & (train.target==0.0)].shape[0]\nN=train[(train.gender.isna()) & (train.target==1.0)].shape[0]\/train[(train.gender.isna()) & (train.target==0.0)].shape[0]\n# if we add all'nan' values to 'Male'\nM_and_NAN=train[((train.gender=='Male') | (train.gender.isna())) & (train.target==1.0)].shape[0]\/train[((train.gender=='Male') | (train.gender.isna())) & (train.target==0.0)].shape[0]","95c65536":"fig, axs = plt.subplots(1,2, figsize=(12,5))\nsns.countplot(x='gender', hue='target', data=train, ax=axs[0])\nsns.barplot(x=['Male', 'Female', 'Other', 'NAN', 'Male+NAN'], y=[M, F, O, N, M_and_NAN], ax=axs[1])","87cd04be":"train.gender[train.gender.isna()]=\"Male\"\ntest.gender[test.gender.isna()]=\"Male\"","5da8b351":"train.major_discipline.value_counts()","ec8ab699":"train[train.major_discipline.isna()]","67fd214c":"train.major_discipline[(train.major_discipline.isna()) & ((train.education_level=='High School') | (train.education_level=='Primary School'))]='Not Applicable'\ntest.major_discipline[(test.major_discipline.isna()) & ((test.education_level=='High School') | (test.education_level=='Primary School'))]='Not Applicable'","8c9e4912":"plt.figure(figsize=(10,5))\nsns.countplot(x='education_level', hue='major_discipline', data=train)","02d5a50e":"train.major_discipline[train.major_discipline.isna()]='STEM'\ntest.major_discipline[test.major_discipline.isna()]='STEM'","35e614ce":"train[(train.company_type.isna()) & (train.company_size.isna())].shape[0]\/train.shape[0]","d50fd0e8":"train.company_type.value_counts()","9f1da22e":"fig, ax =plt.subplots(6,1, figsize=(15,20))\nsns.countplot(train.company_type, ax=ax[0])\nsns.countplot(x='company_type', hue='major_discipline', data=train, ax=ax[1])\nsns.countplot(x='company_type', hue='education_level', data=train, ax=ax[2])\nsns.countplot(x='company_type', hue='relevent_experience', data=train, ax=ax[3])\nsns.boxplot(x=train.company_type, y=train.training_hours, ax=ax[4])\nsns.countplot(x='company_type', hue='company_size', data=train, ax=ax[5])","00ab9c08":"train.company_type[(train.major_discipline!=\"STEM\") & (train.company_type.isna())]=\"Pvt Ltd\"\ntest.company_type[(test.major_discipline!=\"STEM\") & (test.company_type.isna())]=\"Pvt Ltd\"\ntrain.company_type[(train.major_discipline==\"Not Applicable\") & (train.company_type.isna())]=\"Pvt Ltd\"\ntest.company_type[(test.major_discipline==\"Not Applicable\") & (test.company_type.isna())]=\"Pvt Ltd\"\ntrain.company_type[(train.education_level==\"Masters\") & (train.company_type.isna())]=\"Pvt Ltd\"\ntest.company_type[(test.education_level==\"Masters\") & (test.company_type.isna())]=\"Pvt Ltd\"\ntrain.company_type[(train.relevent_experience==\"No relevent experience\") & (train.company_type.isna())]=\"Public Sector\"\ntest.company_type[(test.relevent_experience==\"No relevent experience\") & (test.company_type.isna())]=\"Public Sector\"\n# the percentages of null values is reduced from 30% to 8% by these methods","ea84bcc4":"train2=train.drop(['company_size'], axis=1).dropna()\ntest2=test.drop(['company_size'], axis=1).dropna()","cfc039c3":"train2.shape","7d9c30bc":"test2.shape","f4794df4":"fig=go.Figure(data=[go.Pie(labels=['Not looking for job change', 'Looking for a job change'], values=train.target.value_counts())])\nfig.update_traces( hole= 0.3, hoverinfo='label+percent', textinfo='value+percent', textfont_size=20)\nfig.show()","d20e4893":"sns.countplot(x='target', hue='education_level', data=train)","54fdc70c":"P=100*train[(train.education_level=='Phd') & (train.target==1.0)].shape[0]\/train[(train.education_level=='Phd') & (train.target==0.0)].shape[0]\nG=100*train[(train.education_level=='Graduate') & (train.target==1.0)].shape[0]\/train[(train.education_level=='Graduate') & (train.target==0.0)].shape[0]\nM=100*train[(train.education_level=='Masters') & (train.target==1.0)].shape[0]\/train[(train.education_level=='Masters') & (train.target==0.0)].shape[0]\nH=100*train[(train.education_level=='High School') & (train.target==1.0)].shape[0]\/train[(train.education_level=='High School') & (train.target==0.0)].shape[0]\nP=100*train[(train.education_level=='Primary School') & (train.target==1.0)].shape[0]\/train[(train.education_level=='Primary School') & (train.target==0.0)].shape[0]","e31f35dd":"from plotly.offline import iplot, init_notebook_mode\nfigu=go.Figure(data=go.Bar( x = ['Phd', 'Graduate','Masters','High School','Primary School' ],\n                y = [P, G, M, H, P],\n                \n                marker = dict(color = 'rgba(255, 174, 255, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5))),\n              layout=dict(title = \"The Percentage of ['not looking for a job' \/ 'looking for a job']\",\n              yaxis= dict(title= 'Percentage',ticklen= 5,zeroline= False)\n             ))\niplot(figu)","04784108":"figu = go.Figure(data=go.Box(x=train['target'], y=train['city_development_index'],\n                         notched=True,\n                         fillcolor='rgba(0,255,0,0.5)'), \n                 layout=dict(title = \"City development index vs. Target\",\n                 yaxis= dict(title= 'City development index',ticklen= 5,zeroline= False),\n                 xaxis= dict(title= 'Target',ticklen= 5,zeroline= False)\n                            ))\n\niplot(figu)","4705d703":"M=train[(train.gender=='Male') & (train.target==1.0)].shape[0]\/train[(train.gender=='Male') & (train.target==0.0)].shape[0]\nF=train[(train.gender=='Female') & (train.target==1.0)].shape[0]\/train[(train.gender=='Female') & (train.target==0.0)].shape[0]\nO=train[(train.gender=='Other') & (train.target==1.0)].shape[0]\/train[(train.gender=='Other') & (train.target==0.0)].shape[0]\nfig, ax=plt.subplots(1,2, figsize=(15,5))\nsns.countplot(x='target', hue='gender', data=train, ax=ax[0])\nsns.barplot(x=['Male','Female','Other'], y=[M, F, O], ax=ax[1])","996e1dc0":"train.major_discipline.unique()","3ceacd7c":"M=[]\nvalues=['STEM', 'Business Degree', 'Not Applicable', 'Arts', 'Humanities','No Major', 'Other']\nfor items in values:\n    M.append(train[(train.major_discipline==items) & (train.target==1.0)].shape[0]\/train[(train.major_discipline==items) & (train.target==0.0)].shape[0])\nfigu=go.Figure(data=(go.Bar(x=values, y=M, \n                           marker=dict(color = 'rgba(355, 50, 55, 1.0)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)))),\n              layout=dict(title= 'Likelihood of seeking new job vs. major discipline',yaxis= dict(title= 'Likelihood of seeking a new job',ticklen= 5,zeroline= False)))\n\n\niplot(figu)","f229d716":"train.enrolled_university.unique()","2b0997ba":"E=[]\nvalues=['no_enrollment', 'Full time course', 'Part time course']\nfor items in values:\n    E.append(train[(train.enrolled_university==items) & (train.target==1.0)].shape[0]\/train[(train.enrolled_university==items) & (train.target==0.0)].shape[0])\nfigu=go.Figure(data=(go.Bar(x=values, y=E, \n                           marker=dict(color = 'rgba(55, 50, 100, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)))),\n              layout=dict(title= 'Likelihood of seeking new job vs. enrolled_university',yaxis= dict(title= 'Likelihood of seeking a new job',ticklen= 5,zeroline= False)))\n\n\niplot(figu)","29775793":"train.relevent_experience.unique()","92c3e0a3":"R=[]\nvalues=['Has relevent experience', 'No relevent experience']\nfor items in values:\n    R.append(train[(train.relevent_experience==items) & (train.target==1.0)].shape[0]\/train[(train.relevent_experience==items) & (train.target==0.0)].shape[0])\nfigu=go.Figure(data=(go.Bar(x=values, y=E, \n                           marker=dict(color = 'rgba(55, 50, 200, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)))),\n              layout=dict(title= 'Likelihood of seeking new job vs. relevent_experience',yaxis= dict(title= 'Likelihood of seeking a new job',ticklen= 5,zeroline= False)))\n\n\niplot(figu)","af5af96d":"figu = go.Figure(data=go.Box(x=train['target'], y=train['experience'],\n                         notched=True,\n                         fillcolor='rgba(0,255,0,0.5)'), \n                 layout=dict(title = \"experience vs. Target\",\n                 yaxis= dict(title= 'experience',ticklen= 5,zeroline= False),\n                 xaxis= dict(title= 'Target',ticklen= 5,zeroline= False)\n                            ))\n\niplot(figu)","02839243":"train.head()","7dbda740":"train.city=train.city.str.strip('city_')\ntest.city=test.city.str.strip('city_')","e6fcd0d2":"train=pd.concat([train, pd.get_dummies(train['relevent_experience'], drop_first=True)], axis=1).drop(['relevent_experience'], axis=1)\ntest=pd.concat([test, pd.get_dummies(test['relevent_experience'], drop_first=True)], axis=1).drop(['relevent_experience'], axis=1)","a1884543":"train.shape","b686007a":"train.isna().sum()","1e2bafc8":"train.major_discipline[train.major_discipline=='Other']='Another'","c968c396":"from sklearn.preprocessing import OneHotEncoder\nCat_c=['gender', 'enrolled_university','major_discipline', 'education_level']\nfor items in Cat_c:\n    le=OneHotEncoder()\n    t=le.fit_transform(train[[items]]).toarray()\n    a=train[items].unique()\n    indexs=np.unique(a, return_index=True)[1]\n    col=[a[indexs] for index in sorted(indexs)]\n    new=pd.DataFrame(t, columns=col[1])\n    train=pd.concat([train, new], axis=1, join='inner')","35088c8f":"from sklearn.preprocessing import OneHotEncoder\nCat_c=['gender', 'enrolled_university','major_discipline', 'education_level']\nfor items in Cat_c:\n    le=OneHotEncoder()\n    t=le.fit_transform(test[[items]]).toarray()\n    a=test[items].unique()\n    indexs=np.unique(a, return_index=True)[1]\n    col=[a[indexs] for index in sorted(indexs)]\n    new=pd.DataFrame(t, columns=col[1])\n    test=pd.concat([test, new], axis=1, join='inner')","999052a8":"train.columns","a72ed852":"train.drop(['gender', 'enrolled_university','major_discipline','company_size','company_type', 'education_level'], axis=1, inplace=True)\ntest.drop(['gender', 'enrolled_university','major_discipline','company_size','company_type', 'education_level'], axis=1, inplace=True)","d6faa191":"train.head()","6746696a":"test.head()","2654e96f":"train.columns","49b4ce5f":"X=train.drop(['target'], axis=1)\ny=train['target']","d9075acf":"test.last_new_job.value_counts()","9bdd52c3":"X.city=pd.to_numeric(X.city)\nX.experience=pd.to_numeric(X.experience)\nX.last_new_job=pd.to_numeric(X.last_new_job)\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","eb1d448f":"from sklearn.linear_model import LogisticRegression\nmodel=LogisticRegression()\nmodel.fit(X_train,y_train)\nprediction=model.predict(X_test)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(prediction, y_test)","49e4d483":"from sklearn.tree import DecisionTreeClassifier\nmodel=DecisionTreeClassifier()\nmodel.fit(X_train,y_train)\nprediction=model.predict(X_test)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(prediction, y_test)","8e6b1365":"from sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nn_est=[50, 100, 150, 200, 250]\nfor items in n_est:\n    model=RandomForestClassifier(items)\n    model.fit(X_train,y_train)\n    prediction=model.predict(X_test)\n    print('{} : {}'.format(items, accuracy_score(prediction, y_test)))","8c9d5fae":"from xgboost import XGBClassifier\nmodel=XGBClassifier()\nmodel.fit(X_train,y_train)\nprediction=model.predict(X_test)\naccuracy_score(prediction, y_test)","82e535fe":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(prediction, y_test)","ce8da240":"from sklearn.linear_model import LogisticRegression\nmodel=LogisticRegression()\nmodel.fit(X,y)\nprediction=model.predict(test)\noutput=pd.DataFrame({'enrollee_id':test.enrollee_id, 'target':prediction})\noutput\n#pd.DataFrame.to_csv(output)","bbd399c8":"from sklearn.tree import DecisionTreeClassifier\nmodel=DecisionTreeClassifier()\nmodel.fit(X,y)\nprediction=model.predict(test)\noutput=pd.DataFrame({'enrollee_id':test.enrollee_id, 'target':prediction})\noutput","097aa29f":"from sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier(n_estimators=250)\nmodel.fit(X,y)\nprediction=model.predict(test)\noutput=pd.DataFrame({'enrollee_id':test.enrollee_id, 'target':prediction})\noutput","cdd7b6f5":"# Data Cleaning ==================================================","ca2143a0":"As can be seen from the figures, we have relatively the same portion of target 0 and target 1 for all genders if we add all NAN's to Male. Hence, it is better to replace null values with 'Male'. In general, as can be seen from the barplot, the gender does not have a significant effect on the target and we may want to drop the whole column. ","424f1c26":"We are going to drop the rest of the 'NAN' values for \"education_level\":","5e6ff012":"One last thing before moving to another column, the experience column is 'object' data type. However, we need it as a number so lets change the data type to 'int'. The only problem would be '>20' and '<1' values. We are going to replace them with '21'and '0', respectively. Then will change the data type to 'int'. ","2e338ff5":"So, it is more likely to have \"High School\" than \"Primary School\" education for no_enrollment.","1cf0fd83":"I am going to drop the remaining 'nan' values.","b0385e33":"Employee's in the cities with higher development index have more tendency to do not change their job. ","5c667c05":"Based on the p-values, except enrollee_id and training_hours, other features can affect the experience. Hence, chi2 feature selection does not help us. We are going to replace 'nan' values with '<1', as it most probably is zero. ","ebc2d74c":"As can be seen from the countplot, the most common term in the enrolled_university column is \"no_enrollment\" regardless of education level. Hence, we are going to replace 'NAN' values with \"no_enrollment\".","e28d2c70":"Since we have 'Other' in gender column, we are going to change \"Other\" in major_discipline to \"Another\"","3054c671":"Those who does not have any relevant experience, looking for a new job more often. Maybe they did not have too much idea about their job and they are not too interested.","a6204125":"Now, going to convert categorical data:","8e6a5ab6":"3. RandomForest:","ceb23fa8":"We are going to discover the relation btw different features and \"target\" feature. Lets start from the target data:","772c1205":"# Feature Engineering","d5f05848":"Now it is time to fill the 'NAN' values of 'enrolled_university' column:","eee2a574":"# Data Visulization =============================================","4a3668b8":"# Model Section","b91ad78e":"We have many NAN values in both training and test datasets. We are going to check the columns with NAN values one by one to see how should we deal with them:\nI am going to start from the columns with the lower number of 'NAN' values:","54401fb0":"Almost 1\/4 of the employees are looking for a job change. Lets see which groups are mainly trying to change their jobs :)","0d0ee333":"It seems \"Graduate\"s are more likely to look for a new job compared to other education levels. \"Phd\"s are less likely to change their job (look for new job), maybe they are already making a good money :)","4772e827":"As previously talked, gender does not have a significant effect on target. All genders have btw 30-35% tendency to change their jobs.","c4d53266":"It is very difficult to guess the remaining Null values in the Company_type, hence, we are going to use the mode method to replace the remaining null values. However, we are going to edit them in the new dataset to use it in the modeling after visulization. I am also going to drop the company_size for now. If you find a better way to fill the null values in these two columns please let me know in the comment :)","2a684106":"We know that if \"enrolled_university\" is \"no_enrollment\", then the education can be 'Primary School' or 'High School'. Now lets see which one is most dominant:","bf602f4b":"It has a great chance that the one who has no relevent experience, the difference in years between previous job and current job be 'never'. ","1a4bd124":"As can be seen from the pie-plot, we are dealing with an extremly unbalanced data. The majority of the data are 'Male', while small percentage are \"Female\" or \"Other\". Now, lets check if this column has a significant effect on \"target\" column or not:","97d8e16c":"1. Logestic Regression:","d2df1347":"If we have \"Full time course\" or \"Part time course\" in \"enrolled_university\" column, it means we may have \"education_level\" of ['Phd', 'Graduate', or 'Masters' ]","273e1d29":"Features:\n\n* enrollee_id : Unique ID for candidate\n* city: City code\n* city_ development _index : Developement index of the city (scaled)\n* gender: Gender of candidate\n* relevent_experience: Relevant experience of candidate\n* enrolled_university: Type of University course enrolled if any\n* education_level: Education level of candidate\n* major_discipline :Education major discipline of candidate\n* experience: Candidate total experience in years\n* company_size: No of employees in current employer's company\n* company_type : Type of current employer\n* lastnewjob: Difference in years between previous job and current job\n* training_hours: training hours completed\n* target: 0 \u2013 Not looking for job change, 1 \u2013 Looking for a job change","d0c80a47":"Conclusion: The majority of company_types are \"Pvt Ltd\". If one's major is not \"STEM\", he\/she most probably is hired in the \"Pvt Ltd\" companies. \"no relevant experience\" got a job mainly in either \"Pvt Ltd\" or \"Public Sector\".","7df34107":"Now it is time to model :)","2b1799aa":"Now, we have 4 columns with a high number of 'nan' values: \"gender\", \"major_discipline\", \"company_size\", and \"company_type\"","c0b440ad":"2. Decision Tree:","282165ab":"First we are going to edit city column. We are going to remove \"city_\"","54b9e5fb":"Those who enrolled a \"Full time course\"s in the university are more likely to seek for a new job. Why?!","9d6a8074":"The null values of company types and company size are very challanging to fill. On the other hand we want to have these columns for our prediction.","3700c308":"It seems the educational level has a significant effect on the major_discipline. Obviously, there is no discipline for \"High School\" and \"Primary School\". Therefore, Null values in this column is not missed values but means \"not applicable\". So we are going to replace null values with \"Not applicable\" when the dicipline is \"High School\" or \"Primary School","e95842fa":"Now, lets check \"enrolled_university\" column:","61794db1":"in the almost 28% of the data, we do not have any information about company type and company size. ","b3b58049":"First we are going to check our training and testing datasets:","db7ef9a6":"Now trying to replace \"NAN\" values of \"last_new_job\" column:","e12fa2a4":"Lets check how many NAN values do we have and how to deal with them:","3bfa5b34":"As can be seen from the above graph, we can replace the remaining Null values with STEM as it is most likely.","8f66620c":"Now, trying to fill the null values of major_discipline  column:","ae37b2f1":"Those who do not have any discipline, Arts, and Humanities are less likely to seek for a new job compared to other disciplines."}}