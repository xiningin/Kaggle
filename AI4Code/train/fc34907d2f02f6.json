{"cell_type":{"fcf6c3f7":"code","713bfe34":"code","97b3dc12":"code","3ad47ba8":"code","4e307132":"code","c6714251":"code","b8293f96":"code","2271021b":"code","a779766a":"code","3029c45f":"code","4636b634":"code","af57f8da":"code","7ca99158":"code","a775cfa4":"code","62de17ab":"code","086f5a7f":"code","aa6fe20d":"code","70866917":"code","0014ecaa":"code","7c0782de":"code","7aeac6a2":"code","fb062ff3":"code","c2d3c570":"code","b4791a47":"code","41afec31":"code","de5ff1b4":"code","b56e7439":"code","012d924f":"code","1f283fb7":"code","2b0dd5c0":"code","8cae26f3":"code","ed203f74":"markdown","3ec5bfd3":"markdown","6da7f894":"markdown","598d0459":"markdown","2eb1fb09":"markdown","dcc20ab1":"markdown","8d902aad":"markdown","6b5c5d1e":"markdown","cd3e07e1":"markdown","92cb7316":"markdown","165cf3c9":"markdown","99fc39bf":"markdown","3ef28559":"markdown","2825f5d7":"markdown","1dd924d0":"markdown","9f313398":"markdown","077c0d3f":"markdown","112a0eef":"markdown","c60ca738":"markdown","62d1b6aa":"markdown","da2d0226":"markdown","50ebb27a":"markdown","1da8fb39":"markdown","8dac0e3d":"markdown","3be31f53":"markdown"},"source":{"fcf6c3f7":"!pip install pycaret","713bfe34":"#import the dataset from pycaret repository\nfrom pycaret.datasets import get_data\ndata = get_data('anomaly')\n\n#import anomaly detection module\nfrom pycaret.anomaly import *\n\n#intialize the setup\nexp_ano = setup(data)","97b3dc12":"knn_model = create_model('knn') #k nearest neighbour\n\n# assign a model \nknn_df = assign_model(knn_model) ","3ad47ba8":"plot_model(knn_model)","4e307132":"# generate predictions using trained model\nknn_predictions = predict_model(knn_model, data = data)\nknn_predictions","c6714251":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","b8293f96":"data = pd.read_csv(\"\/kaggle\/input\/creditcardfraud\/creditcard.csv\")\n","2271021b":"from pycaret.classification import *","a779766a":"data.head()","3029c45f":"data.info()","4636b634":"import matplotlib.pyplot as plt \nplt.figure(figsize=(16,6))\n\nimport seaborn as sns\nsns.set_style('darkgrid')\nsns.countplot(x='Class',data=data)","af57f8da":"print(len(data[data['Class']==1]))\nprint(len(data[data['Class']==0]))","7ca99158":"!pip install imbalanced-learn","a775cfa4":"x=data.drop('Class',axis=1)\ny=data.Class","62de17ab":"from imblearn.under_sampling import NearMiss\nunder_sampler = NearMiss()\nx_res,y_res = under_sampler.fit_sample(x,y)\n","086f5a7f":"from collections import Counter\nprint(\"before oversampling:\",Counter(y))\nprint(\"after oversampling:\",Counter(y_res))","aa6fe20d":"y_res","70866917":"x_res=pd.concat([x_res,y_res],axis=1)\nx_res.head()","0014ecaa":"import matplotlib.pyplot as plt \nplt.figure(figsize=(10,6))\n\nimport seaborn as sns\nsns.set_style('darkgrid')\nsns.countplot(x='Class',data=x_res)","7c0782de":"classifier = setup(data=x_res,target='Class')","7aeac6a2":"!pip install scikit-learn==0.23.1","fb062ff3":"compare_models()","c2d3c570":"#creating the model\nlightgbm_model= create_model('lightgbm')","b4791a47":"print(lightgbm_model)","41afec31":"plot_model(lightgbm_model,plot='learning')","de5ff1b4":"plot_model(lightgbm_model,plot='feature')","b56e7439":"plot_model(lightgbm_model,plot='confusion_matrix')","012d924f":"plot_model(lightgbm_model,plot='class_report')","1f283fb7":"plot_model(lightgbm_model,plot='error')","2b0dd5c0":"interpret_model(lightgbm_model, plot ='correlation', feature = None, observation = None)","8cae26f3":"interpret_model(lightgbm_model)","ed203f74":"## First instal Pycaret","3ec5bfd3":"## Set up our dataset","6da7f894":"## Create  Model\n\ncreate_model():\nThis function creates a model on the dataset passed as a data param during the setup stage. setup() function must be called before using create_model(). This function returns a trained model object.","598d0459":"1 = Fradulent, \n0 = not Fradulent","2eb1fb09":"## Plot the model","dcc20ab1":"## Balancing the data\nWe can clearly see , the dataset is very imbalanced. I am going to apply undersampling technique to balance the dataset\n#### Under Sampling\n<b>Over sampling<\/b> and <b>under sampling<\/b> are techniques used in data mining and data analytics to modify unequal data classes to create balanced data sets. If a class of data is the overrepresented majority class, under sampling may be used to balance it with the minority class. Under sampling is used when the amount of collected data is sufficient. Common methods of under sampling include cluster centroids and Tomek links, both of which target potential overlapping characteristics within the collected data sets to reduce the amount of majority data.","8d902aad":"## Classification Report","6b5c5d1e":"## Part 1 : Anomaly Detection","cd3e07e1":"# Interpretation","92cb7316":"This function initializes the environment in pycaret. setup() must called before executing any other function in pycaret. It takes one mandatory parameter: dataframe {array-like, sparse matrix}   ","165cf3c9":"## confusion matrix","99fc39bf":"## Reading our Data","3ef28559":"# Thank you for reading my notebook,please upvote it if you like it","2825f5d7":"<center><h1> Pycaret Introduction<\/h1><\/center>\n\n\n\nYou can reach pycaret website and documentation from https:\/\/pycaret.org\n\nPyCaret is an open source, low-code machine learning library in Python that allows you to go from preparing your data to deploying your model within seconds in your choice of notebook environment.\n\nPyCaret being a low-code library makes you more productive. With less time spent coding, you and your team can now focus on business problems.\n\nPyCaret is simple and easy to use machine learning library that will help you to perform end-to-end ML experiments with less lines of code.\n\nPyCaret is a business ready solution. It allows you to do prototyping quickly and efficiently from your choice of notebook environment.","1dd924d0":"# Let's predict it!","9f313398":"## Class Prediction Error","077c0d3f":"## Import whole Classification","112a0eef":"## Learning curve","c60ca738":"## Part 2: Credit Card Fraudulent detection","62d1b6aa":"## Correlation","da2d0226":"## Compare the models","50ebb27a":"<h2>This notebook consists 2 parts<\/h2>\n<p> Anomaly Detection with pycaret inbuild_data {Clustering}<\/p>\n<p> Use case: Credit Card Fraudulent detection {Classification}<\/p>","1da8fb39":"## Feature importance","8dac0e3d":"From the above results , we can clearly see with Light Gradient Boosting Machine algorithm we got the highest accuracy, I am going to create a model with the LGBM","3be31f53":"# Understanding the Data"}}