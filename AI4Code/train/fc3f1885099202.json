{"cell_type":{"8707e142":"code","463d115f":"code","e78e58ce":"code","f773bdf5":"code","63555640":"code","ef36da0d":"code","0a58ca2b":"code","df8c9dab":"code","c5778470":"code","3d5b2a17":"code","823cc943":"code","b022608d":"code","618545be":"code","aef504cb":"code","a16ac752":"code","19df4fd7":"code","3ada7ef0":"code","29124dce":"code","19a2d9c9":"code","8052388e":"code","6d48b875":"code","510090a7":"code","38a72197":"code","f788711b":"code","546a9570":"code","58fcefb1":"code","3e3bbfdc":"code","df815b90":"markdown","caffc564":"markdown","de1186e1":"markdown","17db09d9":"markdown","acd239c3":"markdown","5a592fec":"markdown"},"source":{"8707e142":"import pandas as pd\nimport numpy as np\ndata_train=pd.read_csv('..\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv')\ndata_test=pd.read_csv('..\/input\/hr-analytics-job-change-of-data-scientists\/aug_test.csv')\ndata_train.head()","463d115f":"data_train.duplicated().sum()","e78e58ce":"data_train.info()","f773bdf5":"data_train.isna().sum()","63555640":"import matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\nsns.countplot(data_train['education_level'],hue=data_train['relevent_experience'])","ef36da0d":"plt.figure()\nsns.countplot(x = data_train['gender'])\nplt.show()","0a58ca2b":"sns.countplot(x=data_train['target'], hue=data_train['gender'])","df8c9dab":"for i in data_train:\n    if data_train[i].dtype == 'object':\n        print(i,data_train[i].unique())","c5778470":"from sklearn.impute import SimpleImputer\nimport numpy as np\nfor i in data_train:\n    if data_train[i].isna().sum()>0:\n        imr=SimpleImputer(missing_values=np.nan,strategy='most_frequent')\n        imr=imr.fit(data_train[[i]])\n        imputed_data=imr.transform(data_train[[i]])\n        data_train[i]=imputed_data","3d5b2a17":"from sklearn.preprocessing import LabelEncoder\nfor c in data_train.columns:\n    le = LabelEncoder()\n    if data_train.dtypes[c] == object:\n        le.fit(data_train[c].astype(str))\n        data_train[c] = le.transform(data_train[c].astype(str))","823cc943":"y=data_train['target']\nX=data_train.drop(['target','enrollee_id'],axis=1)\nprint(y.value_counts())","b022608d":"from sklearn import preprocessing\nnorm = preprocessing.StandardScaler()\nndf=norm.fit_transform(X)\nX = pd.DataFrame(ndf, index=X.index, columns=X.columns)\nX.head(10)","618545be":"from imblearn.over_sampling import ADASYN \nX_resampled, y_resampled = ADASYN().fit_resample(X, y)","aef504cb":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test =train_test_split(X_resampled,y_resampled,train_size=0.7, random_state=42)","a16ac752":"from sklearn.model_selection import RandomizedSearchCV\nimport lightgbm as lgb\nparams = {\n    'learning_rate': [0.05],\n    'num_leaves': [90,140,200],\n    'boosting_type' : ['gbdt'],\n    'objective' : ['binary'],\n    'max_depth' : [3,4,5,6,7,8],\n    'random_state' : [42], \n    'colsample_bytree' : [0.5,0.6,0.7,0.8,1.0],\n    'subsample' : [0.5,0.6,0.7,0.8,1.0],\n    'min_split_gain' : [0.01],\n    'min_data_in_leaf':[10],\n    'metric':['auc']\n    }\nclf = lgb.LGBMClassifier()\nRSCV = RandomizedSearchCV(clf,params,verbose=3,cv=10,n_jobs = -1,n_iter=10)\nRSCV.fit(X_train,y_train)\n","19df4fd7":"y_pred=RSCV.predict(X_test)\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","3ada7ef0":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)","29124dce":"from sklearn.metrics import roc_auc_score\nroc_auc_score(y_test,y_pred)","19a2d9c9":"data_test.info()","8052388e":"data_test.isna().sum()","6d48b875":"from sklearn.impute import SimpleImputer\nimport numpy as np\nfor i in data_test:\n    if data_test[i].isna().sum()>0:\n        imr=SimpleImputer(missing_values=np.nan,strategy='most_frequent')\n        imr=imr.fit(data_test[[i]])\n        imputed_data=imr.transform(data_test[[i]])\n        data_test[i]=imputed_data","510090a7":"from sklearn.preprocessing import LabelEncoder\nfor c in data_test.columns:\n    le = LabelEncoder()\n    if data_test.dtypes[c] == object:\n        le.fit(data_test[c].astype(str))\n        data_test[c] = le.transform(data_test[c].astype(str))","38a72197":"data_test['target']=''\nX=data_test.drop(['target','enrollee_id'],axis=1)","f788711b":"from sklearn import preprocessing\nnorm = preprocessing.StandardScaler()\nndf=norm.fit_transform(X)\nX = pd.DataFrame(ndf, index=X.index, columns=X.columns)\nX.head(10)","546a9570":"data_test['target']=RSCV.predict(X)","58fcefb1":"subm=data_test[['enrollee_id','target']]\nsubm.head(5)","3e3bbfdc":"subm.to_csv('.\/subm.csv',index=False)","df815b90":"Let's look at the unique values of each categorical attribute","caffc564":"I decided to fill in the missing values with the most common ones. And categorical variables are processed using Label Encoder","de1186e1":"I decided to conduct a fairly simple data analysis, and also built a simple model.","17db09d9":"We can clearly see the imbalance in the classes. I decided to choose the ADASYN sampling algorithm, since instead of the entire sample being linearly correlated with the parent, they have a slightly larger variance in them, meaning they are slightly scattered and similar to the real data.","acd239c3":"So we don't have any duplicates, also we can see 10 categorical features, and we have a lot of missing values. Below is a graphical analysis.","5a592fec":"Please UPVOTE, if you like it :D"}}