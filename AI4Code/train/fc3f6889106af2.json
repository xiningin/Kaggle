{"cell_type":{"86ba96cc":"code","3b2febb2":"code","50581fc4":"code","57e1bd9e":"code","be549cf4":"code","6d792448":"code","0d98c596":"code","e7178d06":"code","c589f831":"code","80836f55":"code","a3e19f6c":"code","2ce79bd8":"code","c8b2f16c":"code","5a9045d1":"code","b937441d":"code","b56d95c2":"code","0e1dd3cd":"code","5b554c15":"code","5d2dbe59":"code","af807680":"code","2acc2ca6":"code","5cb340cb":"code","b6a0f97a":"code","d4b753f2":"code","67550101":"code","b6f9aa2e":"code","76c7a2fe":"code","dbff6c3a":"code","70268af7":"code","c0f8ebd7":"code","4e50099e":"code","4058eaa3":"code","7033e8df":"code","9b303615":"code","7a06c098":"code","59d0796b":"code","6ff33508":"code","eb9a0703":"code","914d50c0":"code","3bce71d5":"code","7bfac450":"code","e41c41e4":"code","dc794190":"code","3c486717":"code","ccb37417":"code","13d0a26e":"code","38445b82":"code","825056d1":"code","2640635a":"code","cbfbbc5f":"code","9f81c94e":"code","6cd897c2":"code","14e57aa7":"code","538b47eb":"code","04d6d345":"code","c4c17b2a":"markdown","f4232912":"markdown","d8aa2f9d":"markdown","d71fed5d":"markdown","6a0e415f":"markdown","26f9d923":"markdown","49631822":"markdown","a4669966":"markdown","9e1cc084":"markdown","279d1505":"markdown","1edbc1d0":"markdown","2853f40f":"markdown","c84d0359":"markdown","a64627fd":"markdown","faa06965":"markdown","68d902ec":"markdown","cbd995e4":"markdown","ca95adcb":"markdown","c99870cd":"markdown","1104bb72":"markdown","44e7266a":"markdown","92501e0c":"markdown","058ddd83":"markdown","430b9e86":"markdown","fa8bc481":"markdown","b7161a5c":"markdown","da0b635c":"markdown","cc14e365":"markdown","54787048":"markdown","28be6222":"markdown","17484ac2":"markdown","7f6bac66":"markdown","e502b196":"markdown"},"source":{"86ba96cc":"pip install dicom","3b2febb2":"#EDIT HERE##############################\n\n#File paths\nmetadatapath=\"..\/input\/lungnoduleclassif\/LungNoduleDetectionClassification-master\/LungNoduleDetectionClassification-master\/LIDC\/LIDC-IDRI_MetaData.csv\"\nlist32path=\"..\/input\/lungnoduleclassif\/LungNoduleDetectionClassification-master\/LungNoduleDetectionClassification-master\/LIDC\/list3.2.csv\"\nDOIfolderpath='..\/input\/lidc-idridcom\/LIDC-IDRI\/LIDC-IDRI'\ndatafolder='.\/'\n\n########################################\n#from google.colab import files\n#src = list(files.upload().values())[0]\n#('..\/input\/lungnoduleclassif\/LungNoduleDetectionClassification-master\/LungNoduleDetectionClassification-master\/cell_magic_wand.py','wb').write(src)\n#import mylib\nimport sys\nsys.path.insert(1, \"..\/input\/lungnoduleclassif\/LungNoduleDetectionClassification-master\/LungNoduleDetectionClassification-master\/cell_magic_wand.py\")\n\nimport utilityscript as cmw\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport dicom\nimport os\nimport scipy.ndimage\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport time\n\nfrom skimage import measure, morphology\n#from mpl_toolkits.mplot3d.art3d import Poly3DCollection\nfrom sklearn.cluster import KMeans\nfrom skimage.transform import resize\nfrom skimage.draw import circle\n#Load metadata\nmeta=pd.read_csv(metadatapath)\nmeta=meta.drop(meta[meta['Modality']!='CT'].index)\nmeta=meta.reset_index()\n\n#Get folder names of CT data for each patient\npatients=[DOIfolderpath+'\/'+meta['Patient Id'][i] for i in range(len(meta))]\ndatfolder=[]\n#if(len(meta)-1!=28):\nfor i in range(0,len(meta)-1):\n   if (i!=28):  \n #if os.path.exists(patients[i]):\n    for path in os.listdir(patients[i]):\n        print(path)\n        if os.path.exists(patients[i]+'\/'+path+'\/'+meta['Series UID'][i]):\n            datfolder.append(patients[i]+'\/'+path+'\/'+meta['Series UID'][i])\npatients=datfolder\n#On Error Resume Next\nprint(patients)\n#Load nodules locations\nnodulelocations=pd.read_csv(list32path)","50581fc4":"# Load the scans in given folder path\n# code sourced from https:\/\/www.kaggle.com\/gzuidhof\/full-preprocessing-tutorial\ndef load_scan(path):\n    slices = [dicom.read_file(path + '\/' + s, force=True) for s in os.listdir(path) if s.endswith('.dcm')]\n    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]), reverse=True)\n    try:\n        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n    except:\n        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n        \n    for s in slices:\n        s.SliceThickness = slice_thickness\n        \n    return slices\n\n#convert to ndarray\ndef get_pixels_hu(slices):\n    image = np.stack([s.pixel_array for s in slices])\n    # Convert to int16 (from sometimes int16), \n    # should be possible as values should always be low enough (<32k)\n    image = image.astype(np.int16)\n\n    # Set outside-of-scan pixels to 0\n    # The intercept is usually -1024, so air is approximately 0\n    image[image == -2000] = 0\n    \n    # Convert to Hounsfield units (HU)\n    for slice_number in range(len(slices)):\n        \n        intercept = slices[slice_number].RescaleIntercept\n        slope = slices[slice_number].RescaleSlope\n        \n        if slope != 1:\n            image[slice_number] = slope * image[slice_number].astype(np.float64)\n            image[slice_number] = image[slice_number].astype(np.int16)\n            \n        image[slice_number] += np.int16(intercept)\n    \n    return np.array(image, dtype=np.int16)\n\ndef largest_label_volume(im, bg=-1):\n    vals, counts = np.unique(im, return_counts=True)\n\n    counts = counts[vals != bg]\n    vals = vals[vals != bg]\n\n    if len(counts) > 0:\n        return vals[np.argmax(counts)]\n    else:\n        return None\n    \ndef segment_lung_mask(image, fill_lung_structures=True, dilate=False):\n    \n    # not actually binary, but 1 and 2. \n    # 0 is treated as background, which we do not want\n    binary_image = np.array(image > -320, dtype=np.int8)+1\n    labels = measure.label(binary_image)\n    \n    # Pick the pixel in the very corner to determine which label is air.\n    #   Improvement: Pick multiple background labels from around the patient\n    #   More resistant to \"trays\" on which the patient lays cutting the air \n    #   around the person in half\n    background_label = labels[0,0,0]\n    \n    #Fill the air around the person\n    binary_image[background_label == labels] = 2\n    \n    # Method of filling the lung structures (that is superior to something like \n    # morphological closing)\n    if fill_lung_structures==True:\n        # For every slice we determine the largest solid structure\n        for i, axial_slice in enumerate(binary_image):\n            axial_slice = axial_slice - 1\n            labeling = measure.label(axial_slice)\n            l_max = largest_label_volume(labeling, bg=0)\n            \n            if l_max is not None: #This slice contains some lung\n                binary_image[i][labeling != l_max] = 1\n\n    \n    binary_image -= 1 #Make the image actual binary\n    binary_image = 1-binary_image # Invert it, lungs are now 1\n    \n    # Remove other air pockets insided body\n    labels = measure.label(binary_image, background=0)\n    l_max = largest_label_volume(labels, bg=0)\n    if l_max is not None: # There are air pockets\n        binary_image[labels != l_max] = 0\n    \n    if dilate==True:\n        for i in range(binary_image.shape[0]):\n            binary_image[i]=morphology.dilation(binary_image[i],np.ones([10,10]))\n    return binary_image","57e1bd9e":"#Let's look at one of the patients\n\nfirst_patient = load_scan(patients[1])\nfirst_patient_pixels = get_pixels_hu(first_patient)\nplt.hist(first_patient_pixels.flatten(), bins=80, color='c')\nplt.xlabel(\"Hounsfield Units (HU)\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\nimport scipy\n# Show some slice in the middle\n#data=scipy.ndimage.interpolation.zoom(first_patient_pixels[41],[200,200])\nplt.figure()\nplt.imshow(first_patient_pixels[42])\nplt.annotate('', xy=(317, 367), xycoords='data',\n             xytext=(0.5, 0.5), textcoords='figure fraction',\n             arrowprops=dict(arrowstyle=\"->\"))\n#plt.savefig(\"images\/test.png\",dpi=300)\nplt.show()\n\n","be549cf4":"os.listdir('.\/')","6d792448":"s22_89=?","0d98c596":"import os\nimport glob\nimport copy\nimport time\n%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n#import dicom\nimport os\nimport scipy.ndimage\nimport matplotlib.pyplot as plt\n\nfrom skimage import measure, morphology\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\n\n# Some constants \n#INPUT_FOLDER = '..\/input\/sample_images\/'\n#patients = os.listdir(INPUT_FOLDER)\n#patients.sort()\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm.notebook import tqdm\nfrom collections import namedtuple\nimport SimpleITK as sitk\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.optim as optim","e7178d06":"print(MASK_PATH)","c589f831":" MASK_PATH= '.\/output\/data\/Mask'","80836f55":"import os\n\npath = META_PATH\n\nisExist = os.path.exists(path)\n\nif not isExist:\n  \n  # Create a new directory because it does not exist \n  os.makedirs(path)","a3e19f6c":"        #MASK_PATH= '..\/output\/data\/Mask'\n        # Directory for images .\/lung.conf\n        IMAGE_PATH='.\/output\/data\/Image'\n        # To save images and mask that doesn't contain any nodule or cancer\n        # These images will be used later to evaluate our model\n        CLEAN_PATH_IMAGE='.\/output\/data\/Clean\/Image'\n        CLEAN_PATH_MASK= '.\/output\/data\/Clean\/Mask'\n        # CSV file containing nodule information, malignancy, train test split\n        META_PATH= '.\/output\/data\/Meta\/'","2ce79bd8":"    from configparser import ConfigParser\n\n#if __name__ == \"__main__\":\n    # This python file creates a configuartion file. Change the below directories for your application\n\n    config = ConfigParser()\n\n    # prepare_dataset.py configuration\n    config['prepare_dataset'] = {\n        #Path To LIDC Dataset\n        'LIDC_DICOM_PATH': '..\/input\/lidc-idridcom\/LIDC-IDRI',\n        # Directory to save the output files\n        # Directory for masks\n        \n        'MASK_PATH': '.\/output\/data\/Mask',\n        # Directory for images\n        'IMAGE_PATH':'.\/output\/data\/Image',\n        # To save images and mask that doesn't contain any nodule or cancer\n        # These images will be used later to evaluate our model\n        'CLEAN_PATH_IMAGE':'.\/output\/data\/Clean\/Image',\n        'CLEAN_PATH_MASK':'.\/output\/data\/Clean\/Mask',\n        # CSV file containing nodule information, malignancy, train test split\n        'META_PATH': '.\/output\/data\/Meta\/',\n        # Mask Threshold is the np.sum(MASK) threshold. Some Masks are too small. We remove these small images,masks as they might act as outliers\n        # The threshold 8 was decided by empirical evaluation.\n        'Mask_Threshold':8\n    }\n\n\n    # This is the configuration file for pylidc library\n    config['pylidc'] = {\n        # Confidence level determines the overlap between the 4 doctors who have made annotation\n        'confidence_level': 0.5,\n        # 512 determines the size of the image\n        'padding_size': 512\n    }\n\n    # Create the configuration file in lung.conf\n    with open('.\/lung.conf', 'w') as f:\n          config.write(f)","c8b2f16c":"pip install pylidc","5a9045d1":"pip install utils","b937441d":"pip install medpy","b56d95c2":"import argparse\nimport os\nimport numpy as np\n\nfrom medpy.filter.smoothing import anisotropic_diffusion\nfrom scipy.ndimage import median_filter\nfrom skimage import measure, morphology\nimport scipy.ndimage as ndimage\nfrom sklearn.cluster import KMeans\n\ndef is_dir_path(string):\n    if os.path.isdir(string):\n        return string\n    else:\n        raise NotADirectoryError(string)\n\ndef segment_lung(img):\n    #function sourced from https:\/\/www.kaggle.com\/c\/data-science-bowl-2017#tutorial\n    \"\"\"\n    This segments the Lung Image(Don't get confused with lung nodule segmentation)\n    \"\"\"\n    mean = np.mean(img)\n    std = np.std(img)\n    img = img-mean\n    img = img\/std\n    \n    middle = img[100:400,100:400] \n    mean = np.mean(middle)  \n    max = np.max(img)\n    min = np.min(img)\n    #remove the underflow bins\n    img[img==max]=mean\n    img[img==min]=mean\n    \n    #apply median filter\n    img= median_filter(img,size=3)\n    #apply anistropic non-linear diffusion filter- This removes noise without blurring the nodule boundary\n    img= anisotropic_diffusion(img)\n    \n    kmeans = KMeans(n_clusters=2).fit(np.reshape(middle,[np.prod(middle.shape),1]))\n    centers = sorted(kmeans.cluster_centers_.flatten())\n    threshold = np.mean(centers)\n    thresh_img = np.where(img<threshold,1.0,0.0)  # threshold the image\n    eroded = morphology.erosion(thresh_img,np.ones([4,4]))\n    dilation = morphology.dilation(eroded,np.ones([10,10]))\n    labels = measure.label(dilation)\n    label_vals = np.unique(labels)\n    regions = measure.regionprops(labels)\n    good_labels = []\n    for prop in regions:\n        B = prop.bbox\n        if B[2]-B[0]<475 and B[3]-B[1]<475 and B[0]>40 and B[2]<472:\n            good_labels.append(prop.label)\n    mask = np.ndarray([512,512],dtype=np.int8)\n    mask[:] = 0\n    #\n    #  The mask here is the mask for the lungs--not the nodes\n    #  After just the lungs are left, we do another large dilation\n    #  in order to fill in and out the lung mask \n    #\n    for N in good_labels:\n        mask = mask + np.where(labels==N,1,0)\n    mask = morphology.dilation(mask,np.ones([10,10])) # one last dilation\n    # mask consists of 1 and 0. Thus by mutliplying with the orginial image, sections with 1 will remain\n    return mask*img\n\ndef count_params(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)","0e1dd3cd":"import sys\nimport os\nfrom pathlib import Path\nimport glob\nfrom configparser import ConfigParser\nimport pandas as pd\nimport numpy as np\nimport warnings\nimport pylidc as pl\nfrom tqdm import tqdm\nfrom statistics import median_high\n\n#from utils import is_dir_path,segment_lung\nfrom pylidc.utils import consensus\nfrom PIL import Image\n\nwarnings.filterwarnings(action='ignore')\n\n# Read the configuration file generated from config_file_create.py\nparser = ConfigParser()\nparser.read('.\/lung.conf')\n\n#Get Directory setting\nDICOM_DIR = is_dir_path(parser.get('prepare_dataset','LIDC_DICOM_PATH'))\nMASK_DIR = is_dir_path(parser.get('prepare_dataset','MASK_PATH'))\nIMAGE_DIR = is_dir_path(parser.get('prepare_dataset','IMAGE_PATH'))\nCLEAN_DIR_IMAGE = is_dir_path(parser.get('prepare_dataset','CLEAN_PATH_IMAGE'))\nCLEAN_DIR_MASK = is_dir_path(parser.get('prepare_dataset','CLEAN_PATH_MASK'))\nMETA_DIR = is_dir_path(parser.get('prepare_dataset','META_PATH'))\n\n#Hyper Parameter setting for prepare dataset function\nmask_threshold = parser.getint('prepare_dataset','Mask_Threshold')\n\n#Hyper Parameter setting for pylidc\nconfidence_level = parser.getfloat('pylidc','confidence_level')\npadding = parser.getint('pylidc','padding_size')\n\nclass MakeDataSet:\n    def __init__(self, LIDC_Patients_list, IMAGE_DIR, MASK_DIR,CLEAN_DIR_IMAGE,CLEAN_DIR_MASK,META_DIR, mask_threshold, padding, confidence_level=0.5):\n        self.IDRI_list = LIDC_Patients_list\n        self.img_path = IMAGE_DIR\n        self.mask_path = MASK_DIR\n        self.clean_path_img = CLEAN_DIR_IMAGE\n        self.clean_path_mask = CLEAN_DIR_MASK\n        self.meta_path = META_DIR\n        self.mask_threshold = mask_threshold\n        self.c_level = confidence_level\n        self.padding = [(padding,padding),(padding,padding),(0,0)]\n        self.meta = pd.DataFrame(index=[],columns=['patient_id','nodule_no','slice_no','original_image','mask_image','malignancy','is_cancer','is_clean'])\n\n\n    def calculate_malignancy(self,nodule):\n        # Calculate the malignancy of a nodule with the annotations made by 4 doctors. Return median high of the annotated cancer, True or False label for cancer\n        # if median high is above 3, we return a label True for cancer\n        # if it is below 3, we return a label False for non-cancer\n        # if it is 3, we return ambiguous\n        list_of_malignancy =[]\n        for annotation in nodule:\n            list_of_malignancy.append(annotation.malignancy)\n\n        malignancy = median_high(list_of_malignancy)\n        if  malignancy > 3:\n            return malignancy,True\n        elif malignancy < 3:\n            return malignancy, False\n        else:\n            return malignancy, 'Ambiguous'\n    def save_meta(self,meta_list):\n        \"\"\"Saves the information of nodule to csv file\"\"\"\n        tmp = pd.Series(meta_list,index=['patient_id','nodule_no','slice_no','original_image','mask_image','malignancy','is_cancer','is_clean'])\n        self.meta = self.meta.append(tmp,ignore_index=True)\n\n    def prepare_dataset(self):\n        # This is to name each image and mask\n        prefix = [str(x).zfill(3) for x in range(1000)]\n\n        # Make directory\n        if not os.path.exists(self.img_path):\n            os.makedirs(self.img_path)\n        if not os.path.exists(self.mask_path):\n            os.makedirs(self.mask_path)\n        if not os.path.exists(self.clean_path_img):\n            os.makedirs(self.clean_path_img)\n        if not os.path.exists(self.clean_path_mask):\n            os.makedirs(self.clean_path_mask)\n        if not os.path.exists(self.meta_path):\n            os.makedirs(self.meta_path)\n\n        IMAGE_DIR = Path(self.img_path)\n        MASK_DIR = Path(self.mask_path)\n        CLEAN_DIR_IMAGE = Path(self.clean_path_img)\n        CLEAN_DIR_MASK = Path(self.clean_path_mask)\n\n\n\n        for patient in tqdm(self.IDRI_list):\n            pid = patient #LIDC-IDRI-0001~\n            print(pid)\n            scan = pl.query(pl.Scan).filter(pl.Scan.patient_id == pid).first()\n            nodules_annotation = scan.cluster_annotations()\n            vol = scan.to_volume()\n            print(\"Patient ID: {} Dicom Shape: {} Number of Annotated Nodules: {}\".format(pid,vol.shape,len(nodules_annotation)))\n\n            patient_image_dir = IMAGE_DIR \/ pid\n            patient_mask_dir = MASK_DIR \/ pid\n            Path(patient_image_dir).mkdir(parents=True, exist_ok=True)\n            Path(patient_mask_dir).mkdir(parents=True, exist_ok=True)\n\n            if len(nodules_annotation) > 0:\n                # Patients with nodules\n                for nodule_idx, nodule in enumerate(nodules_annotation):\n                # Call nodule images. Each Patient will have at maximum 4 annotations as there are only 4 doctors\n                # This current for loop iterates over total number of nodules in a single patient\n                    mask, cbbox, masks = consensus(nodule,self.c_level,self.padding)\n                    lung_np_array = vol[cbbox]\n\n                    # We calculate the malignancy information\n                    malignancy, cancer_label = self.calculate_malignancy(nodule)\n\n                    for nodule_slice in range(mask.shape[2]):\n                        # This second for loop iterates over each single nodule.\n                        # There are some mask sizes that are too small. These may hinder training.\n                        if np.sum(mask[:,:,nodule_slice]) <= self.mask_threshold:\n                            continue\n                        # Segment Lung part only\n                        lung_segmented_np_array = segment_lung(lung_np_array[:,:,nodule_slice])\n                        # I am not sure why but some values are stored as -0. <- this may result in datatype error in pytorch training # Not sure\n                        lung_segmented_np_array[lung_segmented_np_array==-0] =0\n                        # This itereates through the slices of a single nodule\n                        # Naming of each file: NI= Nodule Image, MA= Mask Original\n                        nodule_name = \"{}_NI{}_slice{}\".format(pid[-4:],prefix[nodule_idx],prefix[nodule_slice])\n                        mask_name = \"{}_MA{}_slice{}\".format(pid[-4:],prefix[nodule_idx],prefix[nodule_slice])\n                        meta_list = [pid[-4:],nodule_idx,prefix[nodule_slice],nodule_name,mask_name,malignancy,cancer_label,False]\n\n                        self.save_meta(meta_list)\n                        np.save(patient_image_dir \/ nodule_name,lung_segmented_np_array)\n                        np.save(patient_mask_dir \/ mask_name,mask[:,:,nodule_slice])\n            else:\n                print(\"Clean Dataset\",pid)\n                patient_clean_dir_image = CLEAN_DIR_IMAGE \/ pid\n                patient_clean_dir_mask = CLEAN_DIR_MASK \/ pid\n                Path(patient_clean_dir_image).mkdir(parents=True, exist_ok=True)\n                Path(patient_clean_dir_mask).mkdir(parents=True, exist_ok=True)\n                #There are patients that don't have nodule at all. Meaning, its a clean dataset. We need to use this for validation\n                for slice in range(vol.shape[2]):\n                    if slice >50:\n                        break\n                    lung_segmented_np_array = segment_lung(vol[:,:,slice])\n                    lung_segmented_np_array[lung_segmented_np_array==-0] =0\n                    lung_mask = np.zeros_like(lung_segmented_np_array)\n\n                    #CN= CleanNodule, CM = CleanMask\n                    nodule_name = \"{}\/{}_CN001_slice{}\".format(pid,pid[-4:],prefix[slice])\n                    mask_name = \"{}\/{}_CM001_slice{}\".format(pid,pid[-4:],prefix[slice])\n                    meta_list = [pid[-4:],slice,prefix[slice],nodule_name,mask_name,0,False,True]\n                    self.save_meta(meta_list)\n                    np.save(patient_clean_dir_image \/ nodule_name, lung_segmented_np_array)\n                    np.save(patient_clean_dir_mask \/ mask_name, lung_mask)\n\n\n\n        print(\"Saved Meta data\")\n        self.meta.to_csv(self.meta_path+'meta_info.csv',index=False)\n\n\n\nif __name__ == '__main__':\n    # I found out that simply using os.listdir() includes the gitignore file \n    LIDC_IDRI_list= [f for f in os.listdir(DICOM_DIR) if not f.startswith('.')]\n    LIDC_IDRI_list.sort()\n\n\n    test= MakeDataSet(LIDC_IDRI_list,IMAGE_DIR,MASK_DIR,CLEAN_DIR_IMAGE,CLEAN_DIR_MASK,META_DIR,mask_threshold,padding,confidence_level)\n    test.prepare_dataset()","5b554c15":"print(pid)","5d2dbe59":"df_annotations = pd.read_csv('\/kaggle\/input\/luna16\/annotations.csv')\ndf_annotations.head()","af807680":"df_annotations.shape","2acc2ca6":"df_candidates = pd.read_csv('\/kaggle\/input\/luna16\/candidates_V2\/candidates_V2.csv')\ndf_candidates.head()","5cb340cb":"df_candidates['class'].unique()","b6a0f97a":"df_candidates.shape","d4b753f2":"print(f'Total annotations: {df_annotations.shape[0]}, Unique CT scans: {len(df_annotations.seriesuid.unique())}')\nprint(f'Total candidates: {df_candidates.shape[0]}, Unique CT scans: {len(df_candidates.seriesuid.unique())}')","67550101":"# The `diameters` dict will have each `seriesuid` as a key.\n# The value will be a list of all center coorinates in the CT scan with that `seriesuid`\ndiameters = {}\n\n# Loop through every annotation\nfor _, row in df_annotations.iterrows():\n    \n    # Create a tuple to represent the center\n    center_xyz = (row.coordX, row.coordY, row.coordZ)\n    \n    # Append the center to the corresponding `seriesuid`\n    diameters.setdefault(row.seriesuid, []).append(\n        (center_xyz, row.diameter_mm)\n    )","b6f9aa2e":"%%time\n\n# Using a namedtuple makes it easy to access values in a tuple\n# using indexes or field names\nCandidateInfoTuple = namedtuple(\n    'CandidateInfoTuple',\n    ['is_nodule', 'diameter_mm', 'series_uid', 'center_xyz']\n)\n\n# A list to store all candidates in the dataset\ncandidates = []\n\nfor _, row in df_candidates.iterrows():\n    \n    # Create a tuple to represent the candidate center\n    # We suffix the name with `_xyz` to make it clear that we're using the\n    # patient coordinate system: http:\/\/dicomiseasy.blogspot.com\/2013\/06\/getting-oriented-using-image-plane.html\n    candidate_center_xyz = (row.coordX, row.coordY, row.coordZ)\n\n    # We begin by assuming the candidate doesn't have a corresponding annotation.\n    # If this is the case, then the candidate will have a diameter of 0.\n    candidate_diameter = 0.0\n    \n    # We then fetch the diameters of the CT scan we're looking at currently,\n    # and loop over them to find a match for the candidate\n    for annotation in diameters.get(row.seriesuid, []):\n        \n        # Extract the center and diameter of the annotation from the tuple\n        annotation_center_xyz, annotation_diameter = annotation\n        \n        # For each of the coordinates - X, Y and Z, we check if\n        # the candidate and the annotation are \"close by\"\n        # (remember the really long and complicated sentence above?)\n        \n        # Since we've stored coordinates as tuples, we can index into them\n        for i in range(3):\n            \n            # Find the absolute difference between the two coordinates\n            delta = abs(candidate_center_xyz[i] - annotation_center_xyz[i])\n            \n            # If the coorindate of the candidate is more than half the radius away,\n            # we don't consider it the same nodule as the annotation we're currently looking at\n            if delta > annotation_diameter \/ 4:\n                    break\n            \n        # The `else` block of a for loop in Python executes if the loop ends \"naturally\"\n        # i.e. if it terminates because all iterations are complete, and not by a break statement\n        # So if we go into this else block, then all 3 coordinates are within half the radius,\n        # and we can consider the candidate and the annotation as the same nodule\n        else:\n            candidate_diameter = annotation_diameter\n            \n            # We don't need to look at any other remaining annotations,\n            # because we've already found a match!\n            break\n            \n            \n    \n    candidates.append(CandidateInfoTuple(\n        bool(row['class']),\n        candidate_diameter,\n        row.seriesuid,\n        candidate_center_xyz\n    ))","76c7a2fe":"candidates.sort(reverse=True)","dbff6c3a":"# %%time\n\n# from concurrent.futures import ThreadPoolExecutor\n\n# def find_missing_and_multiple(startidx, endidx):\n    \n#     missing_cts = []\n#     multiple_cts = []\n    \n#     for c in tqdm(candidates[startidx: endidx]):\n#         filepaths = glob.glob(f'\/kaggle\/input\/luna16\/subset*\/*\/{c.series_uid}.mhd')\n#         if len(filepaths) == 0:\n#             missing_cts.append(c.series_uid)\n#         elif len(filepaths) > 1:\n#             multiple_cts.append(c.series_uid)\n    \n#     return missing_cts, multiple_cts\n\n\n# all_missing = []\n# all_multiple = []\n\n# with ThreadPoolExecutor() as executor:\n\n#     total = len(candidates)\n#     middle = total \/\/ 2\n#     quarter = middle \/\/ 2\n    \n#     startidx = [0, quarter, middle, middle + quarter]\n#     endidx = [quarter, middle, middle + quarter, total]\n    \n#     for res in executor.map(find_missing_and_multiple, startidx, endidx):\n#         all_missing += res[0]\n#         all_multiple += res[1]\n\n# missing_uids = {uid for uid in all_missing}","70268af7":"with open('\/kaggle\/input\/luna16missingcandidates\/missing.txt', 'r') as f:\n    missing_uids = {uid.split('\\n')[0] for uid in f}\n    \nlen(missing_uids)","c0f8ebd7":"candidates_clean = list(filter(lambda x: x.series_uid not in missing_uids, candidates))\n\nprint(f'All candidates in dataset: {len(candidates)}')\nprint(f'Candidates with CT scan  : {len(candidates_clean)}')","4e50099e":"candidate = candidates_clean[0]\n\ncandidate","4058eaa3":"# Look for the file `<series_uid>.mhd` inside the `subset` folders\nfilepaths = glob.glob(f'\/kaggle\/input\/luna16\/subset*\/*\/{candidate.series_uid}.mhd')\n\n# We removed all candidates that don't have corresponding CT scan files\n# This line is another fail-safe to know when a CT scan doesn't exist\nassert len(filepaths) != 0, f'CT scan with seriesuid {candidate.series_uid} not found!'\n\nfilepaths","7033e8df":"mhd_file_path = filepaths[0]\n\nmhd_file_path","9b303615":"mhd_file = sitk.ReadImage(mhd_file_path)","7a06c098":"ct_scan = np.array(sitk.GetArrayFromImage(mhd_file), dtype=np.float32)","59d0796b":"#first_patient = load_scan(ct_scan)\n#first_patient_pixels = get_pixels_hu(ct_scan)\nplt.hist(ct_scan.flatten(), bins=80, color='c')\nplt.xlabel(\"Hounsfield Units (HU)\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n# Show some slice in the middle\nplt.imshow(ct_scan[80], cmap=plt.cm.gray)\nplt.show()","6ff33508":"ct_scan.clip(-1000, 1000, ct_scan)","eb9a0703":"origin_xyz = mhd_file.GetOrigin()\nvoxel_size_xyz = mhd_file.GetSpacing()\ndirection_matrix = np.array(mhd_file.GetDirection()).reshape(3, 3)","914d50c0":"origin_xyz_np = np.array(origin_xyz)\nvoxel_size_xyz_np = np.array(voxel_size_xyz)","3bce71d5":"# Convert the coordinates of the center of the candidate\n# from the patient coordinate system to column, row, index\ncri = ((center_xyz - origin_xyz_np) @ np.linalg.inv(direction_matrix)) \/ voxel_size_xyz_np\n\n# Since we'll be using column, row and index values to index into arrays,\n# we round them to the nearest integer.\ncri = np.round(cri)\n\n# Going forward, we'll need the scan to be in the order index, row, column\nirc = (int(cri[2]), int(cri[1]), int(cri[0]))","7bfac450":"ct_scan.shape","e41c41e4":"dims_irc = (10, 18, 18)","dc794190":"# We will create three slices - one for each direction - to use to extract\n# a region of interest from the CT scan\nslice_list = []\n\nfor axis, center_val in enumerate(irc):\n    \n    # Get start and end index for the dimension so that the\n    # nodule center is at the center of the 3d array we extract\n    start_index = int(round(center_val - dims_irc[axis]\/2))\n    end_index = int(start_index + dims_irc[axis])\n\n    # Adjust the indexes if the start_index is out of the CT scan array\n    if start_index < 0:\n        start_index = 0\n        end_index = int(dims_irc[axis])\n    \n    # Do the same check for the end_index\n    if end_index > ct_scan.shape[axis]:\n        end_index = ct_scan.shape[axis]\n        start_index = int(ct_scan.shape[axis] - dims_irc[axis])\n        \n    slice_list.append(slice(start_index, end_index))\n    \ntuple(slice_list)","3c486717":"ct_scan_chunk = ct_scan[tuple(slice_list)]\nct_scan_chunk.shape","ccb37417":"# Create a tensor from the NumPy array of the CT scan chunk\nct_scan_chunk_tensor = torch.from_numpy(ct_scan_chunk)\n\n# convert it to a tensor of float32\nct_scan_chunk_tensor = ct_scan_chunk_tensor.to(torch.float32)\n    \n# Add an extra dimension to represent a single channel in the 3d image\nct_scan_chunk_tensor = ct_scan_chunk_tensor.unsqueeze(0)\n\nct_scan_chunk_tensor.shape","13d0a26e":"candidate.is_nodule","38445b82":"torch.tensor([\n    not candidate.is_nodule,\n    candidate.is_nodule,\n], dtype=torch.long)","825056d1":"# We need to change the imports and use some other libraries for caching to work\n# See: https:\/\/github.com\/deep-learning-with-pytorch\/dlwpt-code\/issues\/27\n\n!pip install diskcache cassandra-driver","2640635a":"# The code in this cell is from the Deep Learning with PyTorch book's GitHub repository\n# https:\/\/github.com\/deep-learning-with-pytorch\/dlwpt-code\/blob\/master\/util\/disk.py\n\n# The imports have slightly been modified to make the code work\n\n\nimport gzip\n\nfrom cassandra.cqltypes import BytesType\nfrom diskcache import FanoutCache, Disk, core\nfrom diskcache.core import io, MODE_BINARY\nfrom io import BytesIO\n\nclass GzipDisk(Disk):\n    def store(self, value, read, key=None):\n        \"\"\"\n        Override from base class diskcache.Disk.\n\n        Chunking is due to needing to work on pythons < 2.7.13:\n        - Issue #27130: In the \"zlib\" module, fix handling of large buffers\n          (typically 2 or 4 GiB).  Previously, inputs were limited to 2 GiB, and\n          compression and decompression operations did not properly handle results of\n          2 or 4 GiB.\n\n        :param value: value to convert\n        :param bool read: True when value is file-like object\n        :return: (size, mode, filename, value) tuple for Cache table\n        \"\"\"\n        # pylint: disable=unidiomatic-typecheck\n        if type(value) is BytesType:\n            if read:\n                value = value.read()\n                read = False\n\n            str_io = BytesIO()\n            gz_file = gzip.GzipFile(mode='wb', compresslevel=1, fileobj=str_io)\n\n            for offset in range(0, len(value), 2**30):\n                gz_file.write(value[offset:offset+2**30])\n            gz_file.close()\n\n            value = str_io.getvalue()\n\n        return super(GzipDisk, self).store(value, read)\n\n\n    def fetch(self, mode, filename, value, read):\n        \"\"\"\n        Override from base class diskcache.Disk.\n\n        Chunking is due to needing to work on pythons < 2.7.13:\n        - Issue #27130: In the \"zlib\" module, fix handling of large buffers\n          (typically 2 or 4 GiB).  Previously, inputs were limited to 2 GiB, and\n          compression and decompression operations did not properly handle results of\n          2 or 4 GiB.\n\n        :param int mode: value mode raw, binary, text, or pickle\n        :param str filename: filename of corresponding value\n        :param value: database value\n        :param bool read: when True, return an open file handle\n        :return: corresponding Python value\n        \"\"\"\n        value = super(GzipDisk, self).fetch(mode, filename, value, read)\n\n        if mode == MODE_BINARY:\n            str_io = BytesIO(value)\n            gz_file = gzip.GzipFile(mode='rb', fileobj=str_io)\n            read_csio = BytesIO()\n\n            while True:\n                uncompressed_data = gz_file.read(2**30)\n                if uncompressed_data:\n                    read_csio.write(uncompressed_data)\n                else:\n                    break\n\n            value = read_csio.getvalue()\n\n        return value\n\ndef getCache(scope_str):\n    return FanoutCache('data-unversioned\/cache\/' + scope_str,\n                       disk=GzipDisk,\n                       shards=64,\n                       timeout=1,\n                       size_limit=3e11,\n                       )\n\nraw_cache = getCache('ct_scan_raw')\n\n@raw_cache.memoize(typed=True)\ndef getCtScanChunk(series_uid, center_xyz, dims_irc):\n\n        filepaths = glob.glob(f'\/kaggle\/input\/luna16\/subset*\/*\/{series_uid}.mhd')\n        assert len(filepaths) != 0, f'CT scan with seriesuid {series_uid} not found!'\n        mhd_file_path = filepaths[0]\n        \n        mhd_file = sitk.ReadImage(mhd_file_path)\n        ct_scan = np.array(sitk.GetArrayFromImage(mhd_file), dtype=np.float32)\n        ct_scan.clip(-1000, 1000, ct_scan)\n        \n        origin_xyz = mhd_file.GetOrigin()\n        voxel_size_xyz = mhd_file.GetSpacing()\n        direction_matrix = np.array(mhd_file.GetDirection()).reshape(3, 3)\n        \n        origin_xyz_np = np.array(origin_xyz)\n        voxel_size_xyz_np = np.array(voxel_size_xyz)\n        \n        cri = ((center_xyz - origin_xyz_np) @ np.linalg.inv(direction_matrix)) \/ voxel_size_xyz_np\n        cri = np.round(cri)\n        irc = (int(cri[2]), int(cri[1]), int(cri[0]))\n        \n        slice_list = []\n        for axis, center_val in enumerate(irc):\n            \n            start_index = int(round(center_val - dims_irc[axis]\/2))\n            end_index = int(start_index + dims_irc[axis])\n            \n            if start_index < 0:\n                start_index = 0\n                end_index = int(dims_irc[axis])\n                \n            if end_index > ct_scan.shape[axis]:\n                end_index = ct_scan.shape[axis]\n                start_index = int(ct_scan.shape[axis] - dims_irc[axis])\n\n            slice_list.append(slice(start_index, end_index))\n            \n        ct_scan_chunk = ct_scan[tuple(slice_list)]\n        \n        return ct_scan_chunk","cbfbbc5f":"class LunaDataset(Dataset):\n    \n    def __init__(self, is_validation_set=False, validation_stride=0):\n        '''Create a PyTorch dataset for the CT scans\n        \n        If `is_validation_set` is `True` then every `validation_stride` item is kept.\n        Otherwise, every `validation_stride` item is deleted\n        '''\n        \n        # Make a copy of all the candidates.\n        # Pick every 350th candidate so that we have about 1k candidates in the dataset\n        # It takes agonizingly long to load more data!\n        self.candidates = copy.copy(candidates_clean[::350])\n        \n        # If this is the validation set, keep every `validation_stride` item\n        if is_validation_set:\n            self.candidates = self.candidates[::validation_stride]\n        \n        # If this is the training set, delete every `validation_stride` item\n        else:\n            del self.candidates[::validation_stride]\n            \n    def __len__(self):\n        '''Returns the number of items in the dataset'''\n        return len(self.candidates)\n    \n    def __getitem__(self, i):\n        '''Get the `i`the item in the dataset'''\n        \n        # Get the `i`th candidate\n        candidate = self.candidates[i]\n        \n        # We want to resize each CT scan to the following dimensions\n        dims_irc = (10, 18, 18)\n        \n        # Use the utility function to fetch the CT scan\n        ct_scan_np = getCtScanChunk(candidate.series_uid, candidate.center_xyz, dims_irc)\n        \n        # Convert the CT scan to a tensor\n        ct_scan_tensor = torch.from_numpy(ct_scan_np).to(torch.float32).unsqueeze(0)\n        \n        # Convert the target to a tensor\n        label_tensor = torch.tensor([\n            not candidate.is_nodule,\n            candidate.is_nodule\n        ], dtype=torch.long)\n        \n        return ct_scan_tensor, label_tensor","9f81c94e":"VALIDATION_STRIDE=10\nBS=16\n\ntrain_ds = LunaDataset(is_validation_set=False, validation_stride=VALIDATION_STRIDE)\nval_ds = LunaDataset(is_validation_set=True, validation_stride=VALIDATION_STRIDE)\n\ntrain_dl = DataLoader(train_ds, batch_size=BS, num_workers=0)\nval_dl = DataLoader(val_ds, batch_size=BS, num_workers=0)","6cd897c2":"def train_loop(model, dataloader, criterion, optimizer, ds_size):\n    '''Train the model for one epoch'''\n    \n    # Put the model in training mode to activate dropout\n    model.train()\n    \n    # Keep a track of the loss and correct predictions for the epoch\n    running_loss = 0.0\n    running_corrects = 0\n    \n    # Track the total number of positives and true positives\n    running_pos = 0\n    running_pos_correct = 0\n    \n    # Track the total number of negatives and true negatives\n    running_neg = 0\n    running_neg_correct = 0\n    \n    for inputs, labels in tqdm(dataloader):\n        \n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        # --- Standard PyTorch training process ---\n        optimizer.zero_grad()\n        \n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n        \n        loss = criterion(outputs, labels[:,1])\n        loss.backward()\n        \n        optimizer.step()\n        # -----------------------------------------\n        \n        # Calculate loss and correct predictions in batch\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data[:,1])\n        \n        # Calculate positives and true positives in batch\n        running_pos += labels.data[:,1].sum()\n        running_pos_correct += ((preds == labels.data[:,1]) & (labels.data[:,1] == 1)).sum()\n        \n        # Calculate negatives and true negatives in batch\n        running_neg += labels.data[:,0].sum()\n        running_neg_correct += ((preds == labels.data[:,1]) & (labels.data[:,1] == 0)).sum()\n\n    epoch_loss = running_loss \/ ds_size\n    epoch_acc = running_corrects.double() \/ ds_size\n    \n    return epoch_loss, epoch_acc, (running_pos_correct, running_pos), (running_neg_correct, running_neg)\n    \n    \n\ndef eval_loop(model, dataloader, criterion, ds_size):\n    '''Evaluate the model performance for one epoch'''\n\n    # Put the model in evaluation mode to deactivate dropout\n    model.eval()\n\n    # Keep track of loss, predictions, and other numbers we are interested in\n    # just like in the training loop\n    running_loss = 0.0\n    running_corrects = 0\n    \n    running_pos = 0\n    running_pos_correct = 0\n    running_neg = 0\n    running_neg_correct = 0\n    \n    # Don't calculate gradients\n    with torch.no_grad():\n    \n        for inputs, labels in tqdm(dataloader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n        \n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            loss = criterion(outputs, labels[:,1])\n        \n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data[:,1])\n            \n            running_pos += labels.data[:,1].sum()\n            running_pos_correct += ((preds == labels.data[:,1]) & (labels.data[:,1] == 1)).sum()\n\n            running_neg += labels.data[:,0].sum()\n            running_neg_correct += ((preds == labels.data[:,1]) & (labels.data[:,1] == 0)).sum()\n        \n    epoch_loss = running_loss \/ ds_size\n    epoch_acc = running_corrects.double() \/ ds_size\n    \n    return epoch_loss, epoch_acc, (running_pos_correct, running_pos), (running_neg_correct, running_neg)","14e57aa7":"class LunaModel(nn.Module):\n    \n    def __init__(self):\n        \n        super().__init__()\n        \n        self.conv1 = nn.Conv3d(1, 32, kernel_size=3, padding=1, bias=True)\n        self.relu1 = nn.ReLU()\n        self.maxpool1 = nn.MaxPool3d(2)\n        \n        self.conv2 = nn.Conv3d(32, 64, kernel_size=3, padding=1, bias=True)\n        self.relu2 = nn.ReLU()\n        self.maxpool2 = nn.MaxPool3d(2)\n        \n        self.flatten = nn.Flatten()\n        \n        self.fc1 = nn.Linear(2048, 1024)\n        self.relu3 = nn.ReLU()\n        \n        self.dropout = nn.Dropout(0.2)\n        \n        self.fc2 = nn.Linear(1024, 2)\n    \n    def forward(self, X):\n        \n        # Dimensions of X => [BS, 1, 10, 18, 18]\n        \n        X = self.maxpool1(self.relu1(self.conv1(X)))\n        X = self.maxpool2(self.relu2(self.conv2(X)))\n        \n        X = self.flatten(X)\n\n        X = self.relu3(self.fc1(X))\n        X = self.dropout(X)\n        \n        return self.fc2(X)","538b47eb":"# Create an instance of the model\nmodel = LunaModel()\n\n# Use the GPU if it is available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Use the cross-entropy loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Use the AdamW optimizer\noptimizer = optim.AdamW(model.parameters(), weight_decay=0.1)","04d6d345":"EPOCHS = 5\n\nfor epoch in range(EPOCHS):\n\n    epoch_start = time.time()\n\n    train_loss, train_acc, train_pos, train_neg = train_loop(\n        model, train_dl, criterion,\n        optimizer, len(train_ds)\n    )\n\n    val_loss, val_acc, val_pos, val_neg = eval_loop(\n        model, val_dl, criterion, len(val_ds)\n    )\n\n    time_elapsed = time.time() - epoch_start\n    print(f'Epoch: {epoch+1:02} | Epoch Time: {time_elapsed \/\/ 60:.0f}m {time_elapsed % 60:.0f}s')\n    print()\n    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n    print(f'\\tTrain - correct pos: {train_pos[0]}\/{train_pos[1]} | correct neg: {train_neg[0]}\/{train_neg[1]}')\n    print()\n    print(f'\\tVal. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n    print(f'\\tVal. - correct pos: {val_pos[0]}\/{val_pos[1]} | correct neg: {val_neg[0]}\/{val_neg[1]}')\n    print()","c4c17b2a":"We can now train the model.","f4232912":"We will first group all annotations that are part of the same CT scan (i.e. have the same `seriesuid`).\n\nThis will allow us to easily access the **centers** and respective **diameters** of all nodules in a particular CT scan.","d8aa2f9d":"The first epoch takes a long time, but once the data is cached, the other epochs are super fast!\n\n## Conclusion\n\nWe've got an accuracy of over 99% on the validation set! Time to pop the champagne!\n\nBut hang on... That's not the entire story. The numbers below the accuracy give us a clearer picture of what is going on.\n\nThe model predicted all negatives correctly, but didn't make any correct predictions for the positive data points. So this model is not very useful right now.\n\nThis probably happened because we don't have enough positive samples in the training and validation set. It would be unrealistic to expect the model to learn how to predict positive samples with just a couple of data points.\n\nAlso, because our dataset is highly imbalanced, we need a better strategy to train our model and also a better indication of model performance instead of accuracy.\n\nI guess we'll have to keep that champagne on the ice for a little longer...","d71fed5d":"We lost almost 50% of the data! *PANIC!!!*\n\nWell, we'd panic if this wasn't something we're just playing with.\n\nFor now, we'll try not to worry about this and move on with the data that we have left.\n\n## Load the data\n\nWe'll now walk through how we want to convert the data we have into a format that we can consume with PyTorch.\n\nWe will walk through and understand all the steps using a single candidate before putting the code together into utility functions and a PyTorch `Dataset`.","6a0e415f":"There are over 750k candidates.\n\nThe huge difference between candidates and annotations tells us that we will have many candidates for which we won't have a diameter in the annotations file. However, if fine for now as we won't be using the diameter information when building this simple model.\n\nAnother thing to note is that there can be multiple annotations and candidates in a single CT scan.","26f9d923":"## Introduction\n\nThis notebook was created as a part of the [Weights & Biases PyTorch Book Reading Group](https:\/\/community.wandb.ai\/c\/community-events\/pytorch-book\/32) hosted by [Sanyam Butani](https:\/\/www.kaggle.com\/init27).\n\nThe idea was to find a notebook on Kaggle with a TensorFlow model trained on the Luna16 dataset and try to convert it to PyTorch.\n\nThis notebook is my attempt to train the model that [Sentdex](https:\/\/www.kaggle.com\/sentdex) built in his notebook [First pass through Data w\/ 3D ConvNet](https:\/\/www.kaggle.com\/sentdex\/first-pass-through-data-w-3d-convnet) in PyTorch.\n\nMost of the code used to read the data comes from the amazing book we're reading in the group - [Deep Learning with PyTorch](https:\/\/www.manning.com\/books\/deep-learning-with-pytorch).\n\n## Load required libraries","49631822":"The entire CT scan is currently very large for us to work with.","a4669966":"There are 443 `seriesuid`s in the annotations and candidates CSV files that don't have corresponding .mhd files.\n\nWe now remove from our list of candidates those that don't have a CT scan.","9e1cc084":"The `glob` package can return multiple files that match the pattern specified.\n\nHowever, for simplicity we'll assume that the dataset contains only one `.mhd` file for a given `seriesuid`.\n\nThat path will be available at index 0 of the result.","279d1505":"With the utility function and caching set up, we can now create a PyTorch datset.","1edbc1d0":"Now, let's put it all together in a few utility functions and a `Dataset` class.\n\nFirst, let us set up some utility functions for caching the dataset. As we'll see later, this will significantly speed up training after the first epoch.\n\nThe code used to set up caching is from the Deep Learning with PyTorch book, and can be found in the book's [GitHub repository](https:\/\/github.com\/deep-learning-with-pytorch\/dlwpt-code\/blob\/master\/util\/disk.py).","2853f40f":"We also get the following information:\n\n - Center point of reference of the CT scan (also known as the origin)\n - Size of each voxel (short for volume pixel) since each CT scan can have a different size of voxels\n - Direction matrix that has a direction vector for of each axis in the CT scan","c84d0359":"We convert the origin and voxel size to NumPy arrays so that they are easier to use in calculations.","a64627fd":"The `SimpleITK` package has a very simple API that we'll use to get details about the CT scan. They have [great documentation](https:\/\/simpleitk.org\/SimpleITK-Notebooks\/01_Image_Basics.html) available if you want to read more.\n\nWe read the CT scan and store it as a NumPy array.","faa06965":"We now have a CT scan chunk `ct_scan_chunk`. The center of the nodule is at index `irc` in the complete scan `ct_scan`.\n\nThe next step would be to convert this chunk of CT scan to a PyTorch tensor.","68d902ec":"## Understand the Dataset\n\nThe Luna16 (Lung Nodule Analysis 2016) dataset contains chest CT scans and annotations indicating where there are nodules in each CT scan and their diameters.\n\nMore information: https:\/\/luna16.grand-challenge.org\/\n\nThe model we will build will try to predict whether a particular region of a CT scan has a nodule or not.\n\nThere are two CSV files that we'll be working with: **annotations.csv** and **candidates_V2.csv**.\n\n### Annotations\n\nThe annotations file contains the center and diameter of each mass in CT scans.","cbd995e4":"dddddddddddddddddd","ca95adcb":"We can now load this file using the `SimpleITK` package.","c99870cd":"Next, we create `DataLoader`s out of our datasets.\n\nWe use a `VALIDATION_STRIDE` of 10 which means every 10th CT scan will be in the validation set.","1104bb72":"We now create an instance of the model, the loss function, and an optimizer to train the model.","44e7266a":"That's equivalent to 41 RGB color images of resolution 512x512 for a single CT scan!\n\nSince most of the CT scan doesn't contain any interesting to us, we will extract 3-dimensional chunks of the CT scan that contain nodules as input for our model.\n\nLet's say we want to extract a chunk of size 10 along the index column, and 18 rows and columns.","92501e0c":"We now have three slices we can use in each direction to extract the chunk we need.","058ddd83":"There are 1,186 total annotations available.\n\n### Candidates\n\nThe candidates file contains a `class` flag for each mass in the CT scans.\n\n`seriesuid` is the unique identifer of the CT scan.\n\n`coordX`, `coordY` and `coordZ` are coorindates of the center of the mass.\n\n`class` is 0 if the mass isn't a nodule, and 1 if it is a nodule (both malignant and benign).","430b9e86":"We need to also convert the output we want from the model (`is_nodule`) into a PyTorch tensor.","fa8bc481":"We will extract a chunk by getting a list of three slices - one for each direction - and then using that to extract the actual values from the CT scan.","b7161a5c":"The actual values in the CT scan are in [Hounsfield units (HU)](https:\/\/radiopaedia.org\/articles\/hounsfield-unit) which goes from -1000 to 3000.\n\nWe use a range of -1000 or 1000 to remove extremely dense materials from the CT scan.\n\n[This notebook](https:\/\/www.kaggle.com\/gzuidhof\/full-preprocessing-tutorial) has a great walkthrough and visualization of this data format.","da0b635c":"## Missing data\n\nThere are some `seriesuid`s in the dataset that don't have corresponding CT scans in the dataset.\n\nThe cell below finds all such `seriesuid`s. Since it takes about 10 minutes to run, I have made those `seriesuid`s available as a separate dataset: https:\/\/www.kaggle.com\/mashruravi\/luna16missingcandidates. We'll load data from this dataset to save precious GPU time on Kaggle.","cc14e365":"Similarly, we group the candidates that are part of the same CT scan and then use the diameters dictionary we created above to fetch each candidate's diameter.\n\nThe X, Y and Z coordinates of the center can be slightly different in the annotations and candidate files.\n\nTherefore, when looking for a candidate's diameter from the `diameters` dict, we'll assume that if the center coordinates of the candidate are less than half the radius of the annotated nodule away from the center coordinates of the annotated nodule, then they are the same nodule.\n\nThat sentence was a mouthful! Maybe this diagram will be easier to understand:\n\n![image.png](attachment:93cf076d-063b-4b3f-90d4-1a1ab3f6fe04.png)\n\nWe will create a `namedtuple` to store the information that we combine from the candidates and annotations.","54787048":"We now convert the origin and voxel size from the patient coorindate system previously mentioned to coordinates that we can use to index into the NumPy array representing the CT scan.","28be6222":"We use the `glob` module to find the `.mhd` and `.raw` files associated with the candidate.\n\nThe files could be in any one of the `subset` folders in the dataset. The `glob` module allows us to find the file by using patterns instead of manually looking inside each of the folders.","17484ac2":"We will be using the [cross-entropy loss](https:\/\/ravimashru.dev\/blog\/2021-07-18-understanding-cross-entropy-loss\/) function to train our model so we need two columns for the output - one-hot encoded values of the boolean `is_nodule` value we're interested in.","7f6bac66":"## Train the Model\n\nThis model is a PyTorch version of [Sentdex](https:\/\/www.kaggle.com\/sentdex)'s TensorFlow model in [this notebook](https:\/\/www.kaggle.com\/sentdex\/first-pass-through-data-w-3d-convnet).","e502b196":"We then sort the list of candidates in reverse order. Since the list contains tuples, the order of fields will determine the way the list is sorted.\n\nIn particular, after sorting, we'll have all candidates with the value of `is_nodule` as `True` at the beginning of the list. Among these candidates, those with the largest diameter will come before those with smaller diameters. All candidates with a diameter of zero (recall this happens when the candidate coordinates are not \"close enough\" to any annotation coordinates, or there is no corresponding annotation for the particular candidate) will come after these.\n\nCandidates that have a value of `False` for `is_nodule` will come last in the list with the same relative order of diameters as above.\n\n![image.png](attachment:b9b5d21a-10c2-437e-bc94-383e0182f2c5.png)"}}