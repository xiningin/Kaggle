{"cell_type":{"2d904381":"code","02268d26":"code","5fae96b9":"code","bd4a7553":"code","5350fdac":"code","a1f44b54":"code","dd18e6fe":"code","c7bde9d8":"code","bc8e9509":"code","2d93e17b":"code","6b9e0be0":"code","a760bb34":"code","d95f1003":"code","2cde199c":"code","ad41039b":"code","7decbc88":"code","eaf00c87":"code","e0591c9f":"markdown","e1d8e419":"markdown","160a46e5":"markdown"},"source":{"2d904381":"import numpy as np \nimport matplotlib.pyplot as plt \nimport matplotlib.colors as mcolors\nimport pandas as pd \nimport random\nimport math\nimport time\nfrom sklearn.linear_model import LinearRegression, BayesianRidge\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport datetime\nimport operator \nplt.style.use('fivethirtyeight')\n%matplotlib inline ","02268d26":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5fae96b9":"ts_us_confirmed = pd.read_csv('\/kaggle\/input\/covidak\/time_series_covid19_confirmed_US.csv')\nts_us_deaths = pd.read_csv('\/kaggle\/input\/covidak\/time_series_covid19_deaths_US.csv')\nts_global_confirmed_ak = pd.read_csv('\/kaggle\/input\/covidak\/time_series_covid19_confirmed_global.csv')\nts_global_deaths_ak = pd.read_csv('\/kaggle\/input\/covidak\/time_series_covid19_deaths_global.csv')\nts_global_confirmed = pd.read_csv('\/kaggle\/input\/covid-19-cssegisanddata\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_confirmed_global.csv')\nts_global_deaths = pd.read_csv('\/kaggle\/input\/covid-19-cssegisanddata\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_deaths_global.csv')","bd4a7553":"ts_us_confirmed.head()\nts_us_deaths.head()\nts_global_confirmed.head()\nts_global_deaths.head()","5350fdac":"ts_global_deaths_ak.head()","a1f44b54":"#ts_global_deaths.groupby([\"Country\/Region\"])[\"1\/22\/20\", \"1\/23\/20\"].sum()","dd18e6fe":"# Find top deaths\n\ndef findDateStart(keys, field=None):\n    i =0\n    if (field == None):\n        field = 'Population'\n    for k in keys:\n        i += 1\n        if k == field:\n            break;\n    return i\n\ndef plot_ts_values(df, number, func=None, title=None):\n    ts_us_deaths_sorted_raw = df.sort_values(by=['5\/3\/20'], ascending=False)\n    ts_us_deaths_sorted = ts_us_deaths_sorted_raw.copy()\n    ts_us_deaths_sorted['key'] = ts_us_deaths_sorted['Admin2']  + ':' + ts_us_deaths_sorted['Province_State'] \n    ts_us_deaths_sorted = ts_us_deaths_sorted.set_index('key')\n    cols = ts_us_deaths_sorted.keys()\n    ts_us_deaths_sorted = ts_us_deaths_sorted.loc[:,cols[findDateStart(cols)]:cols[-1]]\n    if (func != None):\n        ts_us_deaths_sorted = ts_us_deaths_sorted.apply(func)\n    ts_us_deaths_sorted_100 = ts_us_deaths_sorted.head(number)\n    ts_us_deaths_sorted_100 = ts_us_deaths_sorted_100.T\n    plt.figure(figsize=(16, 9))\n    cols = ts_us_deaths_sorted_100.keys()\n    days = list(range(ts_us_deaths_sorted_100.index.size))\n    dfc = ts_us_deaths_sorted_100.replace([np.inf, -np.inf, np.NaN], 0)\n    for c in cols:\n        #plt.plot(ts_us_deaths_sorted_100.index, ts_us_deaths_sorted_100[c])\n        plt.plot(days[40:-1], dfc[c][40:-1])\n    if (title == None):\n        title = 'Top # of Cases'\n    plt.title(title, size=30)\n    plt.xlabel('Days Since 1\/22\/2020', size=30)\n    plt.ylabel('# of Cases', size=30)\n    plt.legend(cols, prop={'size': 10})\n    plt.xticks(size=20)\n    plt.yticks(size=20)\n    plt.show()\n    #print(ts_us_deaths_sorted_100)","c7bde9d8":"def computeGroupBy(df, gcField = \"Country\/Region\", lastField=\"Long\"):\n    cols = df.keys()\n    c = findDateStart(cols, field=lastField)\n    dateCols = cols[c:-1]\n    dfc = df.groupby(gcField)[dateCols].sum()\n    return dfc","bc8e9509":"ts_global_confirmed_g = computeGroupBy(ts_global_confirmed)\nts_global_confirmed_g.head()\nts_global_deaths_g = computeGroupBy(ts_global_deaths)\nts_global_deaths_g.head()\n","2d93e17b":"plot_ts_values(ts_us_deaths, 20, title = 'Top # of Cases by Area(log)')\nplot_ts_values(ts_us_deaths, 20, np.log, title = 'Top # of Cases by Area(log)')","6b9e0be0":"def adjustForPopulation(df):\n    dfc = df.copy()\n    cols = dfc.keys()\n    k = findDateStart(cols)\n    for c in cols[k:-1]:\n        dfc[c] = dfc[c] * 1000000 \/ dfc['Population']\n    dfc = dfc.replace([np.inf, -np.inf], 0)\n    return dfc","a760bb34":"ts_us_deaths_adj = adjustForPopulation(ts_us_deaths)\nplot_ts_values(ts_us_deaths_adj, 20, title='# of Cases by Area\/1M')\nplot_ts_values(ts_us_deaths_adj, 20, np.log, title='# of Cases by Area\/1M (log)')","d95f1003":"ts_us_deaths_bigger = ts_us_deaths[ts_us_deaths['Population'] > 200000]\nplot_ts_values(ts_us_deaths_bigger, 20, title='# of Cases by Area (pop>200K)')\nplot_ts_values(ts_us_deaths_bigger, 20, np.log, title='# of Cases by Area (pop>200K) (log)')\n","2cde199c":"ts_us_deaths_bigger_adj = adjustForPopulation(ts_us_deaths_bigger)\nplot_ts_values(ts_us_deaths_bigger_adj, 20, title='# of Cases\/1M (pop>200K)')\nplot_ts_values(ts_us_deaths_bigger_adj, 20, np.log, title='# of Cases\/1M -log (pop>200K)')","ad41039b":"# get dataframe sorted by life Expectancy in each continent\ndef findTopByState(df, number):\n    g = df.groupby([\"Province_State\"]).apply(lambda x: x.sort_values([\"4\/22\/20\"], ascending = False)).reset_index(drop=True)\n    # select top N rows within each continent\n    g=g.groupby('Province_State').head(number)\n    return g","7decbc88":"ts_us_deaths_top = findTopByState(ts_us_deaths, 2)\nplot_ts_values(ts_us_deaths_top, 30, title = 'Top 2 # of Cases by State(log)')\nplot_ts_values(ts_us_deaths_top, 30, np.log, title = 'Top 2 # of Cases by State(log)')","eaf00c87":"ts_us_deaths_top_bigger_adj = findTopByState(ts_us_deaths_bigger_adj, 2)\nplot_ts_values(ts_us_deaths_top_bigger_adj, 20, title = 'Top 2 # of Cases by State\/1M')\nplot_ts_values(ts_us_deaths_top_bigger_adj, 20, np.log, title = 'Top 2 # of State\/1M(log)')","e0591c9f":"Source: https:\/\/github.com\/CSSEGISandData\/COVID-19 - covidak\n","e1d8e419":"> **US DATA ANALYSIS**","160a46e5":"confirmed_df = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_confirmed_global.csv')\ndeaths_df = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_deaths_global.csv')\nrecoveries_df = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_recovered_global.csv')\nlatest_data = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_daily_reports\/04-21-2020.csv')"}}