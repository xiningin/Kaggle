{"cell_type":{"0dab8b3f":"code","0df9f4a1":"code","8f74f826":"code","fde9db3f":"code","85964860":"code","41f4c007":"code","2cf5dffd":"code","e757e67a":"code","bd04bd59":"code","c6fdf01d":"code","36b7b869":"code","d2b802a2":"code","080af21e":"code","471c5512":"code","b6cb449c":"code","641c4e69":"code","0ccb38ef":"code","c93acb95":"code","b8bce5f1":"code","d07ba183":"code","10bcb478":"markdown","d293b83e":"markdown","e8d31a9f":"markdown","763cf4fa":"markdown"},"source":{"0dab8b3f":"!pip install opencv-contrib-python","0df9f4a1":"! pip install imutils\n! git clone https:\/\/github.com\/AliaksandrSiarohin\/first-order-model\n! pip install demo-package\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nimport time\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nimport imageio\nfrom IPython.display import Image\nimport matplotlib.image as mpimg\nfrom skimage.transform import resize\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\nimport zipfile\nfrom io import BytesIO\nfrom nibabel import FileHolder\nfrom nibabel.analyze import AnalyzeImage\nimport PIL\nfrom IPython import display\nfrom skimage.morphology import convex_hull_image, erosion\nfrom skimage.morphology import square\nfrom skimage.feature import hessian_matrix, hessian_matrix_eigvals\nfrom skimage import data, io, filters\nimport skimage\nimport imutils\nfrom IPython.display import HTML\nimport matplotlib.animation as animation\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","8f74f826":"prev_path = os.getcwd()\nos.chdir(\".\/first-order-model\")\nfrom demo import load_checkpoints, make_animation","fde9db3f":"import yaml\nfilterwarnings(\"ignore\", category=yaml.YAMLLoadWarning)\nyaml.warnings({'YAMLLoadWarning': False})","85964860":"config_path = \"config\/vox-256.yaml\"\ncheckpoint_path = \"..\/..\/input\/first-order-motion\/vox-cpk.pth.tar\"","41f4c007":"def reading_image(image_path,size=(256,256)):\n    \n    Target_Image = cv2.imread(image_path)\n    #Target_Image = cv2.imdecode(Target_Image, cv2.IMREAD_COLOR)\n    Reading_Image = cv2.cvtColor(Target_Image,cv2.COLOR_BGR2RGB)\n    Resized_Image = cv2.resize(Reading_Image,size)\n    Target_Image = Resized_Image \/ 255.\n    \n    return Target_Image","2cf5dffd":"def reading_video(video_path,size=(256,256)):\n    \n    Video_Capturing = cv2.VideoCapture(video_path)\n    \n    Frames_List = []\n    \n    while Video_Capturing.isOpened():\n        \n        _,frame = Video_Capturing.read()\n        \n        if _ != True:\n            break\n            \n        if Video_Capturing.isOpened():\n            \n            Transformed_Image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n            Resized_Image = cv2.resize(Transformed_Image,size)\n            Target_Image = Resized_Image \/ 255.\n            Frames_List.append(Target_Image)\n            \n    Video_Capturing.release()\n    \n    return Frames_List","e757e67a":"def saving_frames(save_path,frame_list,fps=32,size=(256,256)):\n    \n    frame_list = np.array(frame_list) * 255.\n    frame_list = frame_list.astype(np.uint8)\n    Writing_Function = cv2.VideoWriter(save_path,cv2.VideoWriter_fourcc(*\"MJPG\"),fps,size)\n    \n    for frames in frame_list:\n        Writing_Function.write(cv2.cvtColor(frames,cv2.COLOR_BGR2RGB))\n        \n    Writing_Function.release()","bd04bd59":"def displaying_video(source, driving, generated=None):\n    figure = plt.figure(figsize=(8 + 4 * (generated is not None), 6))\n\n    Image_List = []\n    for indexing in range(len(driving)):\n        columns_target = [source]\n        columns_target.append(driving[indexing])\n        if generated is not None:\n            columns_target.append(generated[indexing])\n        Read_IMG = plt.imshow(np.concatenate(columns_target, axis=1), animated=True)\n        plt.axis('off')\n        Image_List.append([Read_IMG])\n\n    Animation_Func = animation.ArtistAnimation(figure, Image_List, interval=50, repeat_delay=1000)\n    plt.close()\n    return Animation_Func","c6fdf01d":"def grid_displaying(image_target):\n    \n    plt.title(\"PLOT\")\n    plt.axis(\"off\")\n    plt.imshow(np.concatenate(image_target,axis=1))","36b7b869":"Generator_Deep, Key_Point_Detector = load_checkpoints(config_path=config_path,checkpoint_path=checkpoint_path)","d2b802a2":"Testing_Image_Path = \"..\/..\/input\/first-order-motion\/05.png\"\nTesting_Video = \"..\/..\/input\/first-order-motion\/10.mp4\"","080af21e":"Creating_Image_Label = reading_image(Testing_Image_Path)\nCreating_Video_Label = reading_video(Testing_Video)","471c5512":"HTML(displaying_video(Creating_Image_Label, Creating_Video_Label).to_html5_video())","b6cb449c":"Prediction_Patch = make_animation(Creating_Image_Label, Creating_Video_Label, Generator_Deep, Key_Point_Detector, relative=True,adapt_movement_scale=True)","641c4e69":"HTML(displaying_video(Creating_Image_Label,Creating_Video_Label,Prediction_Patch).to_html5_video())","0ccb38ef":"Image_Path = \"..\/..\/input\/ddeep-fake-test\/DeepFake\/IMG_20210715_141335.jpg\"","c93acb95":"Image_Label = reading_image(Image_Path)","b8bce5f1":"Prediction_Output = make_animation(Image_Label, Creating_Video_Label, Generator_Deep, Key_Point_Detector, relative=True,adapt_movement_scale=True)","d07ba183":"HTML(displaying_video(Image_Label,Creating_Video_Label,Prediction_Output).to_html5_video())","10bcb478":"# PACKAGES AND LIBRARIES","d293b83e":"# GENERATOR PROCESS","e8d31a9f":"#### THANK YOU SO MUCH!\n\n#### YES, IT IS ME! I WILL CONTINUE TO ANALYSIS\n#### STAY WITH SCIENCE","763cf4fa":"# READING AND DISPLAYING FUNCTIONS"}}