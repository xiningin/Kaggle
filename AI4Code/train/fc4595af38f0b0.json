{"cell_type":{"73ca8c69":"code","5bff6294":"code","4df1a485":"code","90e3b9df":"code","4f8986da":"code","a4dd8cbd":"code","4f2b5a71":"code","b8aa185f":"code","62d8d96e":"code","d1e75faf":"code","6f47acc3":"code","54fe6362":"code","cfb723d2":"code","ec137b8d":"code","dfa8f55b":"code","a89598c4":"code","84b1d1d9":"code","9d3e6f02":"code","acd4e18c":"markdown","bc8a8805":"markdown","2dafad6c":"markdown","a03639be":"markdown","1dce347e":"markdown","c25b6ee4":"markdown","274d193a":"markdown","08bbea95":"markdown","0e418537":"markdown","3acb5ce6":"markdown","0346aeab":"markdown","66e3b0d5":"markdown","4dc5eda3":"markdown","d8eefaef":"markdown","a423697f":"markdown","427b3319":"markdown","36235edc":"markdown","9a138700":"markdown","4329e004":"markdown","1baa1791":"markdown","fa368955":"markdown","4029e663":"markdown"},"source":{"73ca8c69":"import numpy as np \nimport pandas as pd \nimport os\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport PIL\nfrom PIL import Image","5bff6294":"train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\ntraining_set = train_datagen.flow_from_directory(\n        '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/',\n        target_size=(64,64),\n        batch_size=32,\n        class_mode='binary')","4df1a485":"val_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\nval_set = train_datagen.flow_from_directory(\n        '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val\/',\n        target_size=(64,64),\n        batch_size=32,\n        class_mode='binary')","90e3b9df":"test_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\ntest_set = train_datagen.flow_from_directory(\n        '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\/',\n        target_size=(64,64),\n        batch_size=32,\n        class_mode='binary')","4f8986da":"image=\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\/person1011_bacteria_2942.jpeg\"\nPIL.Image.open(image)","a4dd8cbd":"image=\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\/IM-0151-0001.jpeg\"\nPIL.Image.open(image)\n","4f2b5a71":"cnn = tf.keras.models.Sequential()","b8aa185f":"cnn.add(tf.keras.layers.Conv2D(filters=32 , kernel_size=3 ,\n                               activation='relu',input_shape=[64,64,3]))\n#features = no.of feature detectors\n#kernelsize = size of feature det array\n#input_shape = when we add first ip layer we specify shape ... 3 = rgb","62d8d96e":"cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides = 2))\n#pool size = size of matrix, stride = shift by no. of pixels ","d1e75faf":"cnn.add(tf.keras.layers.Conv2D(filters=32 , kernel_size=3 ,\n                               activation='relu'))\n#remove input_shape this is used to connect 1st layer to input layer\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))","6f47acc3":"cnn.add(tf.keras.layers.Flatten())","54fe6362":"cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))\n#128 hidden neurons","cfb723d2":"cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))","ec137b8d":"cnn.compile(optimizer='adam',loss = 'binary_crossentropy',metrics=['accuracy'])","dfa8f55b":"cnn.fit(x = training_set , validation_data=test_set , epochs = 30 )","a89598c4":"print(\"Loss of the model is - \" , cnn.evaluate(test_set)[0]*100 , \"%\")\nprint(\"Accuracy of the model is - \" , cnn.evaluate(test_set)[1]*100 , \"%\")","84b1d1d9":"import numpy as np\nfrom keras.preprocessing import image\ntest_image = image.load_img('..\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA\/person100_bacteria_477.jpeg',target_size=(64,64)) \n#we change size to 64,64 same as in training and test set\n#convert PIL into array as predict accept 2d array\ntest_image = image.img_to_array(test_image)\n#in data pre. our network is trained in batches even if we apply predicion on single image we need to specify as image\ntest_image = np.expand_dims(test_image, axis=0)\n#we are adding dim which is batch ... batch is first dim because first we have dim then in batch we have image color etc.. so axis-0\nresult = cnn.predict(test_image)\nif result[0][0]== 1 :\n  prediciton = 'PNEUMONIA'\nelse:\n  predicion = 'NORMAL'\nprint(prediciton)\n#WE TOOK PNEUMONIC IMAGE FROM TEST ... LET'S CHECK WHAT IT PREDICTS","9d3e6f02":"cnn.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","acd4e18c":"**THE IMAGE OF PNEUMONIC LUNG**","bc8a8805":"# **DATA PREPROCESSING**","2dafad6c":"**TRAINING THE CNN ON TRAINING SET AND EVALUATING ON VALIDATION SET**","a03639be":"# TRAINING THE CNN","1dce347e":"![neural_net2.jpeg](attachment:neural_net2.jpeg)","c25b6ee4":"**STEP-2 POOLING**","274d193a":"**COMPILING THE CNN**","08bbea95":"![download%20%281%29.jpg](attachment:download%20%281%29.jpg)","0e418537":"**MAKING A SINGLE PREDICITION**","3acb5ce6":"> WE WILL APPLY TRANSFORMATIONS ON ALL IMAGES TO AVOID OVERFITTING","0346aeab":"**STEP-4 FULL CONNECTION**","66e3b0d5":"# BUILDING THE CNN","4dc5eda3":"![download.jpg](attachment:download.jpg)","d8eefaef":"![73_blog_image_1.png](attachment:73_blog_image_1.png)","a423697f":"**INITIALISING THE CNN**","427b3319":"![unnamed.png](attachment:unnamed.png)","36235edc":"**STEP-5 OUTPUT LAYER**","9a138700":"**ADDING SECOND CONVOLUTION LAYER**","4329e004":"**STEP-4 FLATTENING**","1baa1791":"**STEP-1 CONVOLUTION LAYER**","fa368955":"**THE IMAGE OF NORMAL LUNG**","4029e663":"# **PREVEIWING THE IMAGES**"}}