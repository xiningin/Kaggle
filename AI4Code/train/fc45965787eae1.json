{"cell_type":{"9857d642":"code","55faa5cb":"code","88e176ea":"code","98d8a135":"code","7b7dd5ef":"code","dfd8811d":"code","7d5227ad":"code","117de51b":"code","87becf12":"code","be144b94":"code","b0e4f0e7":"code","cd6d3611":"code","7152f7f3":"code","e2edb854":"code","b58f19ce":"code","db5cb948":"code","b7af5a68":"code","222f9908":"code","f534a6e1":"code","696c0c2b":"code","fd09ed01":"code","b5bed6db":"code","dedb62da":"code","73999fb1":"code","622be14c":"code","ee96e4ae":"code","9817a272":"code","00d0a92c":"code","5d1ea168":"code","a3a86488":"code","3ffe3f19":"code","075493ac":"code","f847fa1f":"code","20bafbba":"code","f0de3626":"code","fb15b755":"code","c3a9ed3b":"markdown","7eeac493":"markdown","8a9e626a":"markdown","0207769c":"markdown","b428084a":"markdown","26b942ae":"markdown","e35da051":"markdown","54968fd5":"markdown","8b2a6a9b":"markdown","bb29d029":"markdown","74bef3b1":"markdown","231b4b35":"markdown","8c984c69":"markdown","563763a3":"markdown","1b8b7f0e":"markdown","216cbac2":"markdown","e0653aed":"markdown","251986d6":"markdown","0ae281fb":"markdown","6cd528e6":"markdown","6d064ebc":"markdown","25507efd":"markdown","ae30cc82":"markdown","fc390ecc":"markdown"},"source":{"9857d642":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import GridSearchCV,train_test_split\nfrom sklearn.metrics import r2_score\nimport xgboost as xgb\nimport time","55faa5cb":"df = pd.read_csv('..\/input\/housesalesprediction\/kc_house_data.csv')\ndf.head()","88e176ea":"df.describe()","98d8a135":"zips = df['zipcode'].unique()\nzips.shape","7b7dd5ef":"fig = plt.figure(figsize=(15,6))\ndf_98023 = df[df['zipcode']==98023]\ndf_98198 = df[df['zipcode']==98198]\nplt.boxplot([df_98023['price'],df_98198['price']])\nplt.xlabel('zipcode')\nplt.ylabel('Price dollars');","dfd8811d":"fig = plt.figure(figsize=(10,6))\nbins = np.linspace(0,2000000,20)\nplt.hist(df['price'],bins=bins,color='skyblue', edgecolor='gray',linewidth=2)\nplt.xlabel('Price Dollars')\nplt.ylabel('count')\nax = plt.gca()\nax.set_facecolor('lightgray')\nax.tick_params(direction='out', length=6, width=2, colors='black',grid_color='gray', grid_alpha=0.5,left=True,bottom=True)\n#plt.grid(color='lightgray', linestyle='-', linewidth=2)\nx_ticks = np.linspace(0,2000000,20)\nx_labels = ['0','','','','','500000','','','','','1000000','','','','','1500000','','','','','2000000','']\nplt.xticks(x_ticks,x_labels);\nplt.xlim([0,2000000]);","7d5227ad":"# calculate correlation coefficient and plot as heatmap\ncols = ['price', 'bedrooms','bathrooms','sqft_lot','sqft_living','floors']\n\nimport numpy as np\ncm = np.corrcoef(df[cols].values.T)\nsns.set(font_scale=1.5)\nhm = sns.heatmap(cm,\n                cbar=True,\n                annot=True,\n                square = True,\n                fmt='.2f',\n                annot_kws={'size':15},\n                yticklabels=cols,\n                xticklabels=cols)\nplt.show()","117de51b":"cols = ['price','waterfront','view','condition','grade','sqft_above']\n\nimport numpy as np\ncm = np.corrcoef(df[cols].values.T)\nsns.set(font_scale=1.5)\nhm = sns.heatmap(cm,\n                cbar=True,\n                annot=True,\n                square = True,\n                fmt='.2f',\n                annot_kws={'size':15},\n                yticklabels=cols,\n                xticklabels=cols)\nplt.show()","87becf12":"cols = ['price','sqft_basement','yr_built','yr_renovated','zipcode','lat']\n\nimport numpy as np\ncm = np.corrcoef(df[cols].values.T)\nsns.set(font_scale=1.5)\nhm = sns.heatmap(cm,\n                cbar=True,\n                annot=True,\n                square = True,\n                fmt='.2f',\n                annot_kws={'size':15},\n                yticklabels=cols,\n                xticklabels=cols)\nplt.show()","be144b94":"cols = ['price','long','sqft_living15','sqft_lot15']\n\nimport numpy as np\ncm = np.corrcoef(df[cols].values.T)\nsns.set(font_scale=1.5)\nhm = sns.heatmap(cm,\n                cbar=True,\n                annot=True,\n                square = True,\n                fmt='.2f',\n                annot_kws={'size':15},\n                yticklabels=cols,\n                xticklabels=cols)\nplt.show()","b0e4f0e7":"df_pred = df[['price','bathrooms', 'sqft_living','grade','sqft_above']]\ndf_pred.head()","cd6d3611":"fig = plt.figure(figsize=(10,6))\nplt.scatter(df_pred['bathrooms'],df_pred['price']\/1000,s=4)\nplt.xlabel('bathrooms')\nplt.ylabel('Price thousands of dollars');","7152f7f3":"fig = plt.figure(figsize=(10,6))\nplt.scatter(df_pred['sqft_living'],df_pred['price']\/1000,s=4)\nplt.xlabel('sqft_living')\nplt.ylabel('Price thousands of dollars');","e2edb854":"fig = plt.figure(figsize=(10,6))\nplt.scatter(df_pred['grade'],df_pred['price']\/1000,s=4)\nplt.xlabel('grade')\nplt.ylabel('Price thousands of dollars');","b58f19ce":"fig = plt.figure(figsize=(10,6))\nplt.scatter(df_pred['sqft_above'],df_pred['price']\/1000,s=4)\nplt.xlabel('sqft_above')\nplt.ylabel('Price thousands of dollars');","db5cb948":"# multiple regression with traing and test data\nX = df_pred.iloc[:,1:].values\ny = df_pred['price'].values\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\nslr = LinearRegression()\nslr.fit(X_train,y_train)\ny_train_pred = slr.predict(X_train)\ny_test_pred = slr.predict(X_test)","b7af5a68":"# plot results using a residual plot\nfig = plt.figure(figsize=(10,6))\nplt.scatter(y_train_pred,y_train_pred - y_train,c='steelblue',\n           marker='o',edgecolor='white',label='Training data')\nplt.scatter(y_test_pred,y_test_pred - y_test,c='limegreen',\n           marker='s',edgecolor='white',label='Test data')\nplt.xlabel('Predicted values')\nplt.ylabel('Residuals')\nplt.legend(loc='lower left')\nplt.hlines(y=0,xmin=-10,xmax=3e6,color='black',lw=2)\nplt.xlim([-10,3e6])\nplt.show()","222f9908":"# coefficient of determination calculation\nprint('R^2 train: {0:.3f}, test: {1:.3f}'.format(r2_score(y_train, y_train_pred),\nr2_score(y_test, y_test_pred)))","f534a6e1":"#df_zipcode = df.groupby('zipcode')['price'].mean()\ndf_98023 = df[df['zipcode']==98023]\ndf_pred = df_98023[['price','bathrooms', 'sqft_living','grade','sqft_above']]\ndf_pred.head()","696c0c2b":"# multiple regression with traing and test data\nX = df_pred.iloc[:,1:].values\ny = df_pred['price'].values\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\nslr = LinearRegression()\nslr.fit(X_train,y_train)\ny_train_pred = slr.predict(X_train)\ny_test_pred = slr.predict(X_test)","fd09ed01":"# plot results using a residual plot\nfig = plt.figure(figsize=(10,6))\nplt.scatter(y_train_pred,y_train_pred - y_train,c='steelblue',\n           marker='o',edgecolor='white',label='Training data')\nplt.scatter(y_test_pred,y_test_pred - y_test,c='limegreen',\n           marker='s',edgecolor='white',label='Test data')\nplt.xlabel('Predicted values')\nplt.ylabel('Residuals')\nplt.legend(loc='lower left')\nplt.hlines(y=0,xmin=-10,xmax=3e6,color='black',lw=2)\nplt.xlim([-10,1e6])\nplt.show()","b5bed6db":"# coefficient of determination calculation\nprint('R^2 train: {0:.3f}, test: {1:.3f}'.format(r2_score(y_train, y_train_pred),r2_score(y_test, y_test_pred)))","dedb62da":"df_zipcode_mean = df.groupby('zipcode')['price'].mean()\ndf_zipcode_std = df.groupby('zipcode')['price'].std()\nzipcodes = df_zipcode_mean.index\ndf_zipcode_mean.head()","73999fb1":"# plot error bar plot with mean and std\nx = df_zipcode_mean.index\ny = df_zipcode_mean.values\nyerr = df_zipcode_std.values\nfig = plt.figure(figsize=(10,6))\nplt.xlabel('Zipcode')\nplt.ylabel('mean and std deviation range for prices')\nplt.errorbar(x,y,yerr,marker='s',ecolor='b',markerfacecolor='b',ls='none');","622be14c":"fig = plt.figure(figsize=(10,6))\nplt.xlabel('Zipcode')\nplt.ylabel('r2_score')\nfor z in zipcodes:\n    X = df[df['zipcode'] == z][['bathrooms', 'sqft_living','grade','sqft_above']]\n    y = df[df['zipcode'] == z][['price']]\n    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n    slr = LinearRegression()\n    slr.fit(X_train,y_train)\n    y_train_pred = slr.predict(X_train)\n    y_test_pred = slr.predict(X_test)\n    plt.plot(z,(r2_score(y_test, y_test_pred))**0.5,marker='s',markerfacecolor='r',ls='none')\n    plt.plot(z,(r2_score(y_train, y_train_pred))**0.5,marker='o',markerfacecolor='b',ls='none');","ee96e4ae":"df_prediction = df[['price','bathrooms', 'sqft_living','grade','sqft_above','zipcode']]\n\ndf_zip = pd.get_dummies(df_prediction['zipcode'],prefix='zip',drop_first=True)\ndf_pred = pd.concat([df_prediction,df_zip],axis=1)\ndf_pred = df_pred.drop('zipcode',axis=1)\ndf_pred.head()","9817a272":"# multiple regression with traing and test data\nX = df_pred.iloc[:,1:].values\ny = df_pred['price'].values\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\nslr = LinearRegression()\nslr.fit(X_train,y_train)\ny_train_pred = slr.predict(X_train)\ny_test_pred = slr.predict(X_test)","00d0a92c":"# plot results using a residual plot\nfig = plt.figure(figsize=(10,6))\nplt.scatter(y_train_pred,y_train_pred - y_train,c='steelblue',\n           marker='o',edgecolor='white',label='Training data')\nplt.scatter(y_test_pred,y_test_pred - y_test,c='limegreen',\n           marker='s',edgecolor='white',label='Test data')\nplt.xlabel('Predicted values')\nplt.ylabel('Residuals')\nplt.legend()\nplt.hlines(y=0,xmin=-10,xmax=3e6,color='black',lw=2)\nplt.xlim([-10,1e6])\nplt.show()","5d1ea168":"# coefficient of determination calculation\nprint('R^2 train: {0:.3f}, test: {1:.3f}'.format(r2_score(y_train, y_train_pred),r2_score(y_test, y_test_pred)))","a3a86488":"# xgboost with traing and test data\nX = df_pred.iloc[:,1:].values\ny = df_pred['price'].values\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\nregressor = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0,\n             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n             max_depth=4, min_child_weight=1, missing=None, n_estimators=150,\n             n_jobs=6, nthread=None, objective='reg:squarederror',\n             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n             seed=None, silent=None, subsample=0.5, verbosity=1)","3ffe3f19":"regressor.fit(X_train, y_train)\ny_train_pred = regressor.predict(X_train)\ny_test_pred = regressor.predict(X_test)\n# plot results using a residual plot\nfig = plt.figure(figsize=(10,6))\nplt.scatter(y_train_pred,y_train_pred - y_train,c='steelblue',\n           marker='o',edgecolor='white',label='Training data')\nplt.scatter(y_test_pred,y_test_pred - y_test,c='limegreen',\n           marker='s',edgecolor='white',label='Test data')\nplt.xlabel('Predicted values')\nplt.ylabel('Residuals')\nplt.legend()\nplt.hlines(y=0,xmin=-10,xmax=3e6,color='black',lw=2)\nplt.xlim([-10,1e6])\nplt.show()","075493ac":"# coefficient of determination calculation\nprint('R^2 train: {0:.3f}, test: {1:.3f}'.format(r2_score(y_train, y_train_pred),r2_score(y_test, y_test_pred)))","f847fa1f":"n_est_vec = [50,100,150,200,250,300,350,400]\nscore_test = []\nscore_train = []\nfor k in n_est_vec:\n    # xgboost with traing and test data\n    # X = df_pred.iloc[:,1:].values\n    # y = df_pred['price'].values\n    # X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n    regressor = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=1,\n             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n             max_depth=3, min_child_weight=6, missing=None, n_estimators=k,\n             n_jobs=6, nthread=None, objective='reg:squarederror',\n             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n             seed=None, silent=None, subsample=0.5, verbosity=1)\n\n    regressor.fit(X_train, y_train)\n    y_train_pred = regressor.predict(X_train)\n    y_test_pred = regressor.predict(X_test)\n    # coefficient of determination calculation\n    score_train.append(r2_score(y_train, y_train_pred))\n    score_test.append(r2_score(y_test, y_test_pred))\n    \nfig = plt.figure(figsize=(10,6))\nplt.scatter(n_est_vec,score_test,c='steelblue',label=\"test\")\nplt.scatter(n_est_vec,score_train,c='red',label=\"train\")\nplt.xlabel('n_estimators')\nplt.ylabel('r2_score')\nplt.legend()\nplt.title(\"test score and training score as function of n_estimators\")\nplt.show()","20bafbba":"max_d = 8\nscore_test = []\nscore_train = []\nfor k in range(1,max_d):\n    # xgboost with traing and test data\n    # X = df_pred.iloc[:,1:].values\n    # y = df_pred['price'].values\n    # X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n    regressor = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=1,\n             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n             max_depth=k, min_child_weight=6, missing=None, n_estimators=250,\n             n_jobs=6, nthread=None, objective='reg:squarederror',\n             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n             seed=None, silent=None, subsample=0.5, verbosity=1)\n\n    regressor.fit(X_train, y_train)\n    y_train_pred = regressor.predict(X_train)\n    y_test_pred = regressor.predict(X_test)\n    # coefficient of determination calculation\n    score_train.append(r2_score(y_train, y_train_pred))\n    score_test.append(r2_score(y_test, y_test_pred))\n    \nfig = plt.figure(figsize=(10,6))\nplt.scatter(list(range(1,max_d)),score_test,c='steelblue',label=\"test\")\nplt.scatter(list(range(1,max_d)),score_train,c='red',label=\"train\")\nplt.xlabel('max depth')\nplt.ylabel('r2_score')\nplt.legend()\nplt.title(\"test score and training score as function of max_depth\")\nplt.show()","f0de3626":"# 'max_depth and min_child_weight\n\n# xgboost with traing and test data\n# X = df_pred.iloc[:,1:].values\n# y = df_pred['price'].values\n# X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n\nparams = {'gamma':[i\/10.0 for i in range(0,1)],\n         'min_child_weight':range(4,6,1)}\n\nregressor = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0,\n             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n             max_depth=3, min_child_weight=0.5, missing=None, n_estimators=250,\n             n_jobs=1, objective='reg:squarederror',\n             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n             seed=None, silent=None, subsample=0.5, verbosity=1)\n\ngrid = GridSearchCV(regressor, params)\n\nstart = time.time()\ngrid.fit(X_train, y_train)\nelapsed = time.time() - start\nprint(\"time elapsed grid search: {0:12.3f}\".format(elapsed))\n\n# Print the r2 score\nprint('train score: {0:12.3f}'.format(r2_score(y_train, grid.best_estimator_.predict(X_train)))) \nprint('test score: {0:12.3f}'.format(r2_score(y_test, grid.best_estimator_.predict(X_test))))\ngrid.best_params_","fb15b755":"# xgboost with traing and test data\nX = df_pred.iloc[:,1:].values\ny = df_pred['price'].values\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\nregressor = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0,\n             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n             max_depth=3, min_child_weight=4, missing=None, n_estimators=250,\n             n_jobs=6, nthread=None, objective='reg:squarederror',\n             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n             seed=None, silent=None, subsample=0.5, verbosity=1)\n\nregressor.fit(X_train, y_train)\ny_train_pred = regressor.predict(X_train)\ny_test_pred = regressor.predict(X_test)\n# coefficient of determination calculation\nprint('R^2 train: {0:.3f}, test: {1:.3f}'.format(r2_score(y_train, y_train_pred),r2_score(y_test, y_test_pred)))","c3a9ed3b":"### Histogram of all home prices","7eeac493":"### Unique zip codes in dataset","8a9e626a":"### check  test score and training score as function of max_depth<br>use n_estimator = 250","0207769c":"### There are outliers on the high end of the price range","b428084a":"### Create dataframe for multi regression","26b942ae":"### Read king county housing dataset into pandas dataframe","e35da051":"### Work on parameter tuning for XGBRegressor","54968fd5":"grid check gamma and min_child_weight\nmax_depth = 3, n_estimator = 250\u00b6","8b2a6a9b":"### XGBRegressor with encoded zipcodes","bb29d029":"### Multiple regression with encoded zipcodes","74bef3b1":"### Calculate model r2_score using data for each  zipcode in King county","231b4b35":"### Histogram confirms high end price range outliers","8c984c69":"### Look at couple  zipcode price data with box plots","563763a3":"### There are 70 zipcodes in king county dataset","1b8b7f0e":"### check r2_score vs n_estimators","216cbac2":"### Basic stats","e0653aed":"### Encode zipcode data","251986d6":"### Predict king county home prices","0ae281fb":"### Multiple regression analysis","6cd528e6":"### Examine cross corelation prices with  independent variables using heatmap","6d064ebc":"### Scatter plot to examine independent varibles used for regression analysis","25507efd":"### Group by zipcode and get mean and standard deviation of price data","ae30cc82":"max_depth 3\nn_estimator = 250\ngamma = 0\nmin_child_weight=4","fc390ecc":"### Multiple regression useing only data from zipcode 98023"}}