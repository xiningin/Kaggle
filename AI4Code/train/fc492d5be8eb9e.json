{"cell_type":{"9d803c50":"code","35c1fcf9":"code","d13665b4":"code","858dc5fb":"code","ed2ae53b":"code","9bc006ac":"code","1179686e":"code","76462c52":"code","e23706a4":"code","4d07db0f":"code","e807798a":"code","b251d888":"markdown","e825750d":"markdown","62ef7cec":"markdown","ef7e0539":"markdown","4d3f5412":"markdown","cb3adbd8":"markdown","9bb8a209":"markdown"},"source":{"9d803c50":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport librosa\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport IPython.display as ipd\nfrom IPython.display import Audio, IFrame, display\nimport plotly.graph_objects as go\nimport librosa\nimport librosa.display\nplt.style.use(\"ggplot\")\n","35c1fcf9":"train = pd.read_csv(\"..\/input\/birdsong-recognition\/train.csv\")\nspecies=train.species.value_counts()\nfig = go.Figure(data=[\n    go.Bar(y=species.values, x=species.index,marker_color='deeppink')\n])\n\nfig.update_layout(title='Distribution of Bird Species')\nfig.show()","d13665b4":"file_path='..\/input\/birdsong-resampled-train-audio-04\/wooscj2\/XC67042.wav'\nx , sr = librosa.load(file_path)\nlibrosa.display.waveplot(x, sr=sr)\nAudio(x, rate=sr)","858dc5fb":"def noise(data, noise_factor):\n    noise = np.random.randn(len(data))\n    augmented_data = data + noise_factor * noise\n    # Cast back to same data type\n    augmented_data = augmented_data.astype(type(data[0]))\n    return augmented_data","ed2ae53b":"n=noise(x,0.01)\nlibrosa.display.waveplot(n, sr=sr)","9bc006ac":"def shifting_time(data, sampling_rate, shift_max, shift_direction):\n    shift = np.random.randint(sampling_rate * shift_max)\n    if shift_direction == 'right':\n        shift = -shift\n    elif self.shift_direction == 'both':\n        direction = np.random.randint(0, 2)\n        if direction == 1:\n            shift = -shift\n    augmented_data = np.roll(data, shift)\n    # Set to silence for heading\/ tailing\n    if shift > 0:\n        augmented_data[:shift] = 0\n    else:\n        augmented_data[shift:] = 0\n    return augmented_data","1179686e":"s=shifting_time(x,sr,1,'right')\nlibrosa.display.waveplot(s, sr=sr)","76462c52":"def speed(data, speed_factor):\n    return librosa.effects.time_stretch(data, speed_factor)","e23706a4":"v=speed(x,2)\nlibrosa.display.waveplot(v, sr=sr)","4d07db0f":"def pitch(data, sampling_rate, pitch_factor):\n    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)","e807798a":"p=pitch(x,sr,2)\nlibrosa.display.waveplot(p, sr)","b251d888":"## 1. Noise Injection\nIt simply add some random value into data","e825750d":"## <center>Augmentation methods for audio\nIntuitively, lack of data is one of the common issue in actual data science problem. Data augmentation helps to generate synthetic data from existing data set such that generalisation capability of model can be improved.\n  <p> <b>Data augmentation definition :<\/b>\n<ul>\n  <li>Data augmentation is the process by which we create new synthetic training samples by adding small perturbations on our initial training set.<\/li>\n  <li>The objective is to make our model invariant to those perturbations and enhace its ability to generalize.<\/li>\n  <li>In images data augmention can be performed by shifting the image, zooming, rotating ...<\/li>\n    <li>In our case we will add noise, stretch and roll, pitch shift ...<\/li>\n<\/ul>\n","62ef7cec":"## Take Away\n<ul>\n  <li>Data augmentation cannot replace real training data. It just help to generate synthetic data to make the model better.\n<\/li>\n  <li>Do not blindly generate synthetic data. You have to understand your data pattern and selecting a appropriate way to increase training data volume.<\/li>\n<\/ul>\n","ef7e0539":"## 4. Changing Pitch","4d3f5412":"Please do upvote if you find it useful \ud83d\udc4d\ud83c\udffc","cb3adbd8":"## 3. Speed tuning\nslightly change the speed of the audio, then pad or slice it.","9bb8a209":"## 2. Time shifting\nslightly shift the starting point of the audio, then pad it to original length."}}