{"cell_type":{"abe95500":"code","a5c40cdc":"code","2d81c95e":"code","ace7a19d":"code","c8172f12":"code","cf753b5f":"code","ec2548c1":"code","8da5df84":"code","17e18b67":"code","cd277e96":"code","3422dc27":"code","ab17d3f8":"code","acd7d049":"code","1b6c92d8":"code","68cd4531":"code","aad73cee":"code","fc1f4c60":"code","e8183ca6":"markdown","66e3aab4":"markdown","53c5e7c3":"markdown","482b6192":"markdown","0841728c":"markdown","b73a14e3":"markdown","c7ace47a":"markdown","12312256":"markdown","c0002227":"markdown","073cfec4":"markdown","25b90a7a":"markdown","5ddfb907":"markdown","9309f1b6":"markdown"},"source":{"abe95500":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.sparse import load_npz\nimport gc\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.metrics import average_precision_score, roc_auc_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","a5c40cdc":"torch.cuda.set_device(0)\ntorch.cuda.manual_seed_all(42)","2d81c95e":"data_folder = '\/kaggle\/input\/sparse-data-v3\/'\nX_train = load_npz(data_folder+'\/train.npz')\nX_test = load_npz(data_folder+'\/test.npz')\ny_train = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/train_transaction.csv', usecols=['isFraud', 'TransactionDT']).sort_values('TransactionDT')['isFraud']\nprint(X_train.shape, X_test.shape, y_train.shape)","ace7a19d":"def from_csr_to_tensor(X, y):\n    x_batch = X.tocoo()\n    x_batch = torch.sparse_coo_tensor(indices = torch.cuda.LongTensor([x_batch.row.tolist(), x_batch.col.tolist()]),\n                            values = torch.cuda.FloatTensor(x_batch.data), size=[X.shape[0], X_train.shape[1]])\n    y_batch = torch.from_numpy(y.values)\n    x_batch = x_batch.type(torch.cuda.FloatTensor)\n    y_batch = y_batch.type(torch.cuda.FloatTensor)\n    \n    return x_batch, y_batch","c8172f12":"rows = X_train.shape[0]\nrows_split = int(rows*0.8)\nprint(rows, rows_split)","cf753b5f":"X_valid = X_train[rows_split:]\ny_valid = y_train[rows_split:]\nX_fit = X_train[:rows_split]\ny_fit = y_train[:rows_split]","ec2548c1":"x_batch_valid, y_batch_valid = from_csr_to_tensor(X_valid, y_valid)","8da5df84":"class MyClassifier(nn.Module):\n    def __init__(self):\n        super(MyClassifier,self).__init__()\n        self.fc1 = nn.Linear(X_train.shape[1], 1024)\n        self.relu1 = nn.ReLU()\n        self.dout1 = nn.Dropout(0.25)\n        self.fc2 = nn.Linear(1024, 2048)\n        self.relu2 = nn.ReLU()\n        self.dout2 = nn.Dropout(0.25)\n        self.fc3 = nn.Linear(2048, 512)\n        self.relu3 = nn.ReLU()\n        self.dout3 = nn.Dropout(0.2)\n        self.fc4 = nn.Linear(512, 64)\n        self.prelu = nn.PReLU(1)\n        self.out = nn.Linear(64, 1)\n        self.out_act = nn.Sigmoid()\n        \n    def forward(self, input_):\n        a1 = self.fc1(input_)\n        h1 = self.relu1(a1)\n        dout1 = self.dout1(h1)\n        a2 = self.fc2(dout1)\n        h2 = self.relu2(a2)\n        dout2 = self.dout2(h2)\n        a3 = self.fc3(dout2)\n        h3 = self.relu3(a3)\n        dout3 = self.dout3(h3)\n        a4 = self.fc4(dout3)\n        h4 = self.prelu(a4)\n        a5 = self.out(h4)\n        y = self.out_act(a5)\n        return y\n              \n    def predict(self, x):\n        #Apply softmax to output. \n        pred = F.softmax(self.forward(x))\n        return torch.tensor(pred)","17e18b67":"#Initialize the model        \nmodel = MyClassifier()\nmodel.cuda()\n#Define loss criterion\ncriterion = nn.BCELoss()\n#Define the optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=0.004)","cd277e96":"#Number of epochs\nepochs = 50\n#Batch size\nbatch_size = 16368\n#Losses\nlosses = []\n#Early-Stopping\nbest_epoch = 0\nlast_score = 0\nes_rounds = 2\n#Range\nRango = range(0, X_fit.shape[0], batch_size)\nlen_Rango = len(list(Rango))\n\nfor i in range(1, epochs+1):\n    print('Training epoch {}'.format(i))\n    loss_epoch = 0\n    loss_valid = 0\n    loss_aps = 0\n    loss_auc = 0\n    loss_auc_valid = 0\n    loss_aps_valid = 0\n    model.train()\n    for j in Rango:\n        x_batch, y_batch = from_csr_to_tensor(X_fit[j:j+batch_size], y_fit[j:j+batch_size])\n        #Clear the previous gradients\n        optimizer.zero_grad()\n        #Precit the output for Given input\n        y_pred = model(x_batch)\n        #Compute Cross entropy loss\n        loss = criterion(y_pred, y_batch)\n        del x_batch\n        del y_batch\n        torch.cuda.empty_cache()\n        gc.collect()\n        #Compute gradients\n        loss.backward()\n        #Adjust weights\n        optimizer.step()\n        \n    #Validate data with model.eval()    \n    model.eval()\n    y_pred_valid = model(x_batch_valid)\n    loss_val = criterion(y_pred_valid, y_batch_valid)\n    loss_valid += loss_val.item()\n    loss_auc_valid += roc_auc_score(y_batch_valid.data.cpu().numpy(), y_pred_valid.data.cpu().numpy())\n    loss_aps_valid += average_precision_score(y_batch_valid.data.cpu().numpy(), y_pred_valid.data.cpu().numpy())\n        \n    losses.append([loss_epoch, loss_valid, loss_auc, loss_auc_valid, loss_aps, loss_aps_valid])\n    print(f'trains loss: {loss_epoch}, trains AUC: {loss_auc}, trains APS: {loss_aps}')\n    print(f'tests loss: {loss_valid}, tests AUC: {loss_auc_valid}, tests APS: {loss_aps_valid}')\n        \n    if last_score <= loss_auc_valid:\n        last_score = loss_auc_valid\n        best_epoch = i\n        es_rounds = 2\n    else:\n        if es_rounds > 0:\n            es_rounds -=1\n        else:\n            print('EARLY-STOPPING !')\n            print('Best epoch found: n\u00ba {}'.format(best_epoch))\n            print('Exiting. . .')\n            break\n\n\nplt.figure(figsize=(16,12))\nplt.subplot(3, 1, 1)\nplt.title('Score per epoch')\nplt.ylabel('Binary Cross-entropy')\n# plt.plot(list(range(len(losses))), [x[0] for x in losses], label=['Trains BCE loss'])\nplt.plot(list(range(len(losses))), [x[1] for x in losses], label=['Valids BCE loss'])\nplt.legend()\nplt.subplot(3, 1, 2)\nplt.ylabel('ROC-AUC Score')\n# plt.plot(list(range(len(losses))), [x[2] for x in losses], label=['Trains ROC_AUC'])\nplt.plot(list(range(len(losses))), [x[3] for x in losses], label=['Valids ROC_AUC'])\nplt.legend()\nplt.subplot(3, 1, 3)\nplt.xlabel('Epoch')\nplt.ylabel('PR-AUC Score')\n# plt.plot(list(range(len(losses))), [x[4] for x in losses], label=['Trains PR_AUC'])\nplt.plot(list(range(len(losses))), [x[5] for x in losses], label=['Valids PR_AUC'])\nplt.legend()\nplt.show()","3422dc27":"model = MyClassifier()\nmodel.cuda()\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.004)","ab17d3f8":"model.train()\nfor i in range(1, best_epoch+1):\n    print('Training epoch {}'.format(i))\n    loss_epoch = 0\n    loss_aps = 0\n    loss_auc = 0\n    for j in Rango:\n        x_batch, y_batch = from_csr_to_tensor(X_train[j:j+batch_size], y_train[j:j+batch_size])\n        #Clear the previous gradients\n        optimizer.zero_grad()\n        #Precit the output for Given input\n        y_pred = model(x_batch)\n        #Compute Cross entropy loss\n        loss = criterion(y_pred, y_batch)\n        #Compute gradients\n        loss.backward()\n        #Adjust weights\n        optimizer.step()\n        \n    del x_batch\n    del y_batch\n    torch.cuda.empty_cache()\n    gc.collect()","acd7d049":"del x_batch_valid\ndel y_batch_valid\ndel X_fit\ndel y_fit\ndel X_valid\ndel y_valid\ntorch.cuda.empty_cache()\ngc.collect()","1b6c92d8":"batch_size = 16368\ny_dummy = pd.Series(np.array([1,1]))\nRango = range(0, X_test.shape[0], batch_size)\nlen_Rango = len(list(Rango))\n\nmodel.eval()\n\nfinal_preds = np.array([])\n\nfor j in Rango:\n    x_batch_valid, _ = from_csr_to_tensor(X_test[j:j+batch_size], y_dummy)\n    y_pred_valid = model(x_batch_valid)\n    y_pred_valid = y_pred_valid.data.cpu().numpy()\n    \n    final_preds = np.concatenate((final_preds, y_pred_valid), axis=None)\n\n    del x_batch_valid\n    del y_pred_valid\n    torch.cuda.empty_cache()\n    gc.collect()\n","68cd4531":"submission = pd.read_csv('\/kaggle\/input\/ieee-fraud-detection\/sample_submission.csv')\nsubmission['isFraud'] = final_preds","aad73cee":"submission.head(10)","fc1f4c60":"submission.to_csv('submission.csv', sep=',', header=True, index=None)","e8183ca6":"## Neuronal Network","66e3aab4":"# IEEE-CIS Fraud Detection","53c5e7c3":"### Test\n\nTest set predictions in batches to avoid CUDA Memory Errors.","482b6192":"Save final submission","0841728c":"## Libraries","b73a14e3":"Split data in 80% train, 20% test, sorted by TransactionDT","c7ace47a":"### Train\n\nTrain the NN with Time Series 80\/20 split to determine which is the optimal epoch.","12312256":"Re-fitting with all train data and the best number of epochs.","c0002227":"In this notebook we show a very simple example of PyTorch on sparse data in the competition IEEE-CIS Fraud Detection.","073cfec4":"Select cuda device and set a seed.","25b90a7a":"Transform valid data to sparse tensor. Fit data will be transformed into each mini-batch.","5ddfb907":"## Data\nWe load the data on npz compressed format (~20 MB train and test sets). For now, data is omitted.\n\nBrief data description:\n\n- dummies on categorical data.\n- split in 512 bins continuous data and dummies.\n\nFinally, we have about 13k columns.","9309f1b6":"A function to transform data from csr_matrix format to PyTorch sparse tensor."}}