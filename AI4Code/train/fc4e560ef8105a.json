{"cell_type":{"c0e18c28":"code","a0cc2795":"code","7b6432d7":"code","0b5e22fa":"code","3f9d5ba9":"code","7e8103d3":"code","a09917d4":"code","ebedc51f":"code","e587f3cc":"code","0cd201ac":"code","4c86b195":"code","20c4f5ca":"code","db26b279":"code","06c5f602":"code","a8c0e1be":"code","18631227":"code","f3118e9f":"code","072cfbe7":"markdown","d860d86b":"markdown","66180051":"markdown","87960ef6":"markdown","32850b02":"markdown","9252de4c":"markdown","1bdd6214":"markdown","9c9df178":"markdown","5b097302":"markdown","c88e2504":"markdown"},"source":{"c0e18c28":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a0cc2795":"# Import required libraries\n\n# EDA\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Basic ML Libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n# Deep Learning libraries\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D, Dropout, Flatten, Dense, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\n\n%matplotlib inline\nplt.style.use('ggplot')\nsns.set_style('whitegrid')","7b6432d7":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\ndisplay(train.info())\n\ndisplay(test.info())\n\ndisplay(train.head(n = 2))\ndisplay(test.head(n = 2))","0b5e22fa":"# Split the train dataset into features and labels\n\nfeatures_train = train.iloc[:, 1:]\nlabels_train = train.iloc[:, 0:1].values","3f9d5ba9":"# Normalize the data and reshape it\n\nfeatures_train = features_train \/ 255.0\ntest = test \/ 255.0\n\n# features_train.iloc[1, :].values.shape -> 1D array with shape (784,)\n\nsampleImageIndex = 1010\n\nsampleImagePixelMap = features_train.iloc[sampleImageIndex, :].values.reshape(28, 28)\nprint(sampleImagePixelMap.shape)\n\nprint(\"The below Image should be a \", labels_train[sampleImageIndex])\ng = plt.imshow(sampleImagePixelMap)","7e8103d3":"# Reshaping Contd.\n\nfeatures_train = features_train.values.reshape(-1, 28, 28, 1)\ntest = test.values.reshape(-1, 28, 28, 1)\n\nprint(features_train.shape)\nprint(test.shape)\n","a09917d4":"print(\"The below Image should still be a \", labels_train[sampleImageIndex])\ng = plt.imshow(features_train[sampleImageIndex, :, :, 0])","ebedc51f":"# Lets look at the label distribution in our training data set\n\nsns.countplot(x = \"label\", data = train)\nfig = plt.gcf()\nfig.set_size_inches(10, 8)\nplt.xlabel(\"Number\")\nplt.ylabel(\"Total Count\")\nplt.show()","e587f3cc":"labels_train = to_categorical(labels_train, num_classes = 10)\nprint(labels_train[0])","0cd201ac":"# Split the train data set into train and test\n\nX_train, X_valid, y_train, y_valid = train_test_split(features_train, labels_train, test_size = 0.1)","4c86b195":"digitNet = Sequential()\n\ndigitNet.add(BatchNormalization(input_shape = (28, 28, 1)))\ndigitNet.add(Conv2D(filters = 16, kernel_size = 3, kernel_initializer = 'he_normal', activation = 'relu', padding = 'same'))\ndigitNet.add(MaxPool2D(pool_size = 2))\ndigitNet.add(BatchNormalization())\n\ndigitNet.add(Conv2D(filters = 32, kernel_size = 3, kernel_initializer= 'he_normal', activation = 'relu', padding = 'same'))\ndigitNet.add(MaxPool2D(pool_size = 2))\ndigitNet.add(BatchNormalization())\n\ndigitNet.add(Conv2D(filters = 64, kernel_size = 3, kernel_initializer = 'he_normal', activation = 'relu', padding = 'same'))\ndigitNet.add(MaxPool2D(pool_size = 2))\ndigitNet.add(BatchNormalization())\n\ndigitNet.add(Conv2D(filters = 128, kernel_size = 3, kernel_initializer = 'he_normal', activation = 'relu', padding = 'same'))\ndigitNet.add(MaxPool2D(pool_size = 2))\ndigitNet.add(BatchNormalization())\n\ndigitNet.add(GlobalAveragePooling2D())\n\ndigitNet.add(Dense(10, activation = 'softmax'))\ndigitNet.summary()","20c4f5ca":"# Compile the model\ndigitNet.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])","db26b279":"# Lets use a Data augmentor\n\ndatagen = ImageDataGenerator(\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        zoom_range = 0.1,\n        rotation_range=10,\n        horizontal_flip = False,\n        vertical_flip = False,\n)\n\ndatagen.fit(X_train)\n\ncheckpointer = ModelCheckpoint(filepath = 'bestModel.hdf5', \n                               verbose=1, save_best_only = True)\n\nreduce = LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n\ndigitNet.fit_generator(datagen.flow(X_train, y_train, batch_size = 32), \n                       steps_per_epoch = X_train.shape[0] \/\/ 32, \n          validation_data = (X_valid, y_valid), epochs = 64,\n          callbacks=[checkpointer, reduce], verbose=1)","06c5f602":"digitNet.load_weights(\"bestModel.hdf5\")","a8c0e1be":"# Lets plot a confusion matrix\nvalidationPredictions = digitNet.predict(X_valid)\nv = np.argmax(validationPredictions, axis = 1) \na = np.argmax(y_valid, axis = 1) \n\ncm = confusion_matrix(a, v)\ncm_df = pd.DataFrame(cm, index = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], columns = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"])\nsns.heatmap(cm_df, annot = True, cmap = 'RdYlGn', linewidths = 0.2)\nfig = plt.gcf()\nfig.set_size_inches(12, 12)\nplt.tight_layout()\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","18631227":"results = digitNet.predict(test)\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","f3118e9f":"print(\"Done\")","072cfbe7":"As said in the challenge, the dataset is pretty clean. We won't have to worry about  any missing\/ incorrect pixel values","d860d86b":"**This is a very basic notebook. Any suggestions and improvements are welcomed.\nThe proposed CNN will yield an accuracy of around 99.4%, putting you in the overall 25 percentile.\nI will improve on the CNN\/ tuning as I learn more**","66180051":"Further Improvements?\n    1. Using transfer learning to do the same task.\n    2. TODO","87960ef6":"When using tensorflow as a backend with keras, the keras CNN's require a 4D array or tensor with the following shape:\n\n(n_samples, row, columns, channels)\n\nIn our case, rows = colums = 28 and channels = 1 since we are dealing with grayscale images.","32850b02":"## Data Preprocessing, EDA","9252de4c":"## CNN Application","1bdd6214":"## Import Libraries, Datasets","9c9df178":"### > Train the model","5b097302":"There is a fairly even distribution for each of the digit in our dataset which is actually good since there will be no bias to a particular digit when our CNN is trained.","c88e2504":"### > Create and Compile the model"}}