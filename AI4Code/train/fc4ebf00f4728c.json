{"cell_type":{"82eafdc8":"code","a5b70146":"code","77335d22":"code","b1e46ba0":"code","58d9c860":"code","8b2ee921":"code","9e7969db":"code","21a7428c":"code","cde68ec9":"code","71e90c50":"code","3603d609":"code","5d267791":"code","56f91b63":"code","491edd56":"markdown","374f2039":"markdown","c74b26a3":"markdown","4cc6fc19":"markdown","f1ffe005":"markdown","758497ba":"markdown","e9e99c67":"markdown","9b4533dc":"markdown","321184a8":"markdown","623a7fa4":"markdown","3c310845":"markdown","d6446ebc":"markdown","c1909ff5":"markdown","cc22e81b":"markdown"},"source":{"82eafdc8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)","a5b70146":"data = pd.read_csv('..\/input\/Breast_cancer_data.csv')\ndata.head()","77335d22":"data.info()","b1e46ba0":"data.describe()","58d9c860":"data.corr()","8b2ee921":"data['diagnosis'].value_counts()","9e7969db":"y = data.diagnosis.values\nx = data.drop('diagnosis', axis=1)\nx.head(3)","21a7428c":"x = (x-np.min(x))\/(np.max(x)-np.min(x))\nx.describe()","cde68ec9":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)","71e90c50":"print('x_train.shape:', x_train.shape)\nprint('y_train.shape:', y_train.shape)\nprint('x_test.shape :', x_test.shape)\nprint('y_test.shape :', x_test.shape)","3603d609":"from sklearn.linear_model import LogisticRegression\n\n# Creating the model:\nlr = LogisticRegression() \n\n# Training the model with the training datas:\nlr.fit(x_train, y_train)\n\nprint('Scenario_1 score of the logistic regression: ', lr.score(x_test, y_test))","5d267791":"from sklearn.model_selection import GridSearchCV\n\ngrid = {'C': np.logspace(-3,3,7), 'penalty': ['l1', 'l2']}\n# C and penalty are logistic regression regularization parameters\n# If C is too small model is underfitted, if C is too big model is overfitted.\n# l1 and l2 are regularization loss functions (l1=lasso, l2=ridge)\n\n# Creating the model:\nlr = LogisticRegression() \n\n# Creating GridSearchCV model:\nlr_cv = GridSearchCV(lr, grid, cv=10) # Using lr model, grid parameters and cross validation of 10 (10 times of accuracy calculation will be applied) \n\n# Training the model:\nlr_cv.fit(x_train, y_train)\n\nprint('best paremeters for logistic regression: ', lr_cv.best_params_)\nprint('best score for logistic regression after grid search cv:', lr_cv.best_score_)","56f91b63":"lr_tuned = LogisticRegression(C=100.0, penalty='l1')\n\nlr_tuned.fit(x_train, y_train)\n\nprint('Scenario_2 (tuned) logistic regression score: ', lr_tuned.score(x_test, y_test))","491edd56":"Let's see how many of the dataset inputs are diagnosed as malignant (1) or belign (0):","374f2039":"**2. Now I will implement normalization process to my x values.**","c74b26a3":"In this kernel my aim is to investigate two different scenerios;\n*     Scenario_1: Apply Logistic Regression Classification and examine the accuracy of the model,\n*     Scenario_2: Apply Grid Search Cross Validation and use these parameters in Logistic Regression Class. in order to improve accuracy.\n\n\n","4cc6fc19":"**Analysis of the Dataset:**","f1ffe005":"After the grid search cross validation for logistic regression I found that logistic regression regularization parameters should be;\n* C = 100\n* penalty = l1\n\nfor the best scored logistic regression model.","758497ba":"I can see there is no NaN value in this dataset. So I don't need to clean it before use.","e9e99c67":"From dataset statistics I can see that later I will need to normalize values. Because the features' values range in a big scale.","9b4533dc":"**CONCLUSION:**\n\nIn order to improve our models accuracy we should apply grid search cross validation before to find the best parameters. \n\nThen we can use these regularization parameters to improve our logistic regression classification model. ","321184a8":"**LEARNING TO APPLY GRID SEARCH CROSS VALIDATION FOR LOGISTIC REGRESSION CLASSIFICATION MODELS**\n\nIn this kernel I am using breast cancer dataset to create a logistic regression machine learning model.\n\nTo improve my model I will use grid search cross validation.\n\nGrid search cross validation method will give me the best parameters, so I will use these parameters to improve my logistic regression model.\n","623a7fa4":"**1. First of all I will separete diagnosis feature from the dataset. Diagnosis values will be my target (y).**","3c310845":"From the dataset correlation statistics I can easly see that 'radius', 'perimeter' and 'area' features are strongly related.","d6446ebc":"**4. Scenerio_1 Applying Logistic Regression Classification Algorithm Directly:**","c1909ff5":"**3. Divide the dataset into train and test:**","cc22e81b":"**5. Scenario_2 Apply Grid Search Cross Validation for Logistic Regression:**"}}