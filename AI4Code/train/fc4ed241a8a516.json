{"cell_type":{"a6522258":"code","f2bb1176":"code","a0c76c72":"code","99609197":"code","298c4bdc":"code","32db3aa8":"code","6e3a563c":"code","7bd1660a":"code","55e919a0":"code","1b4e1893":"code","a3af4454":"code","3681bada":"code","27eca83c":"code","38c560a1":"code","8b629b09":"code","95d7143e":"code","5f981912":"code","a0aed769":"code","4102ef0d":"code","3efb4a5f":"code","bad25640":"code","5d98b4ef":"code","cb5afe93":"code","001266ec":"code","bcf219ae":"code","6c69bad9":"code","cdad7ec5":"code","e6b4297b":"code","b7fb239e":"code","c3325de7":"code","179186f7":"code","592122ca":"code","d82aca82":"code","f84e7424":"code","9727266e":"code","430d55ed":"code","afdaffb8":"code","e7551c68":"code","ead43f6c":"code","bf8004f7":"code","d6d9e12a":"code","7bc72ced":"code","6474d599":"code","f54bc134":"code","5b36ef38":"code","359a09a6":"code","30d362f1":"code","4f95cf45":"code","f79c92cd":"code","61a8b2d0":"code","e3b7bfab":"code","90a9223c":"code","be847847":"code","bf009b04":"code","50c80088":"code","b7aae06d":"code","05c3014e":"code","1178004b":"code","46c482e3":"code","00ab465c":"code","b4050bcc":"code","b7106f24":"code","cf28c253":"code","a1a55f78":"code","2647b17f":"code","5da1a2b3":"code","1a1d112b":"code","58c9a290":"code","c7d5e3e6":"code","a8f1ef39":"code","d776d0ac":"code","e00ec72b":"code","cfbf6dee":"code","234003dd":"code","da69614e":"code","40984b64":"code","cb19c013":"code","8801f739":"code","99024a59":"code","2387eea7":"code","a7a83ca4":"code","f20f7d3a":"code","530e48a0":"code","a7f47950":"code","b20ca472":"code","c29c800b":"code","412c9e87":"code","38c2fe0f":"code","75c2581f":"markdown","9289e426":"markdown","42a36bb9":"markdown","b863e3cd":"markdown","6e496ae8":"markdown","dd554842":"markdown","000aeeb6":"markdown","06357452":"markdown","31b5484f":"markdown","7220d769":"markdown","0e0f7080":"markdown","a87a34f8":"markdown","e19747ba":"markdown"},"source":{"a6522258":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n       \n\n# Any results you write to the current directory are saved as output.","f2bb1176":"ad=pd.read_csv('..\/input\/adult.csv')\nad","a0c76c72":"ad.hist()","99609197":"ad.dtypes","298c4bdc":"import seaborn as sns\nsns.catplot(x=\"capital.loss\", y=\"sex\",  hue=\"sex\",data=ad)","32db3aa8":"sns.catplot(x=\"education.num\", y=\"sex\",  hue=\"sex\",data=ad)","6e3a563c":"import matplotlib.pyplot as plt\nfig_dims = (15, 5)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.barplot(x=\"hours.per.week\", y=\"education\",  hue=\"sex\",data=ad,ax=ax)","7bd1660a":"fig_dims = (15, 5)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.barplot(x=\"age\", y=\"race\",  hue=\"sex\",data=ad,ax=ax)","55e919a0":"fig_dims = (15, 5)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.barplot(x=\"age\", y=\"income\",  hue=\"sex\",data=ad,ax=ax)","1b4e1893":"fig_dims = (15, 5)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.barplot(x=\"capital.gain\", y=\"income\",  hue=\"sex\",data=ad,ax=ax)","a3af4454":"fig_dims = (15, 5)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.barplot(x=\"fnlwgt\", y=\"education\",  hue=\"sex\",data=ad,ax=ax)","3681bada":"sns.violinplot(x=ad['fnlwgt'],y=ad['income'],hue='sex',data=ad)","27eca83c":"sns.violinplot(x=ad['workclass'],y=ad['age'],data=ad)","38c560a1":"plt.scatter(x=ad['age'],y=ad['race'])","8b629b09":"sns.violinplot(x=ad['education.num'],y=ad['sex'],data=ad)","95d7143e":"sns.violinplot(x=ad['age'],y=ad['income'],data=ad)","5f981912":"plt.rcParams[\"figure.figsize\"] = 12,8\nplt.scatter(ad['age'],ad['native.country'])","a0aed769":"sns.pairplot(ad)","4102ef0d":"sns.heatmap(ad.corr(), annot=True)","3efb4a5f":"ad = ad[(ad.astype(str) != '?').all(axis=1)]\nad=ad.reset_index(drop=True)\nad","bad25640":"ad.isna().sum().sum()","5d98b4ef":"ad['education']=ad.education.str.replace('-','')","cb5afe93":"ad['marital.status'] =  ad['marital.status'].str.replace('-','')","001266ec":"ad['occupation'] =  ad['occupation'].str.replace('-','')","bcf219ae":"ad['relationship'] =  ad['relationship'].str.replace('-','')","6c69bad9":"ad['native.country'] =  ad['native.country'].str.replace('-','')","cdad7ec5":"ad","e6b4297b":"ad.workclass.value_counts()","b7fb239e":"ad.education.value_counts()","c3325de7":"from sklearn import preprocessing\n#label Encoder\ncategory_col =['workclass', 'race', 'education','Marital_Status', 'occupation',\n               'relationship', 'sex', 'native.country'] \nlabelEncoder = preprocessing.LabelEncoder()","179186f7":"ad= ad.rename(columns={'marital.status':'Marital_Status','education.num':'education_num'})\nad","592122ca":"mapping_dict={}\nfor col in category_col:\n    ad[col] = labelEncoder.fit_transform(ad[col])\n    le_name_mapping = dict(zip(labelEncoder.classes_, labelEncoder.transform(labelEncoder.classes_)))\n    mapping_dict[col]=le_name_mapping\nprint(mapping_dict)","d82aca82":"ad","f84e7424":"plt.rcParams[\"figure.figsize\"] = 12,8\nimport matplotlib.pyplot as plt\nfig,axes = plt.subplots(2,3)\n\n\naxes[0,0].set_title(\"fnlwgt\")\naxes[0,0].boxplot(ad['fnlwgt'])\naxes[0,1].set_title(\"capital.loss\")\naxes[0,1].boxplot(ad['capital.loss'])\naxes[0,2].set_title(\"hours.per.week\")\naxes[0,2].boxplot(ad['hours.per.week'])\n\n\n\naxes[1,0].set_title(\"education\")\naxes[1,0].boxplot(ad['education'])\naxes[1,1].set_title(\"occupation\")\naxes[1,1].boxplot(ad['occupation'])\naxes[1,2].set_title(\"native.country\")\naxes[1,2].boxplot(ad['native.country'])","9727266e":"\na=ad\na=a.select_dtypes(exclude=\"object\")\na = a.drop(['sex'],axis=1)","430d55ed":"from sklearn.preprocessing import PowerTransformer\npt = PowerTransformer()\na=pt.fit_transform(a)\na","afdaffb8":"a = pd.DataFrame(a)\na","e7551c68":"a = a.rename(columns={0:'age',1:'workclass',2:'fnlwgt',3:'education',4:'education_num',5:'Marital_Status',6:'occupation',7:'relationship',8:'race',9:'Capital_gain',10:'Capital_loss',11:'hours_per_week',12:'native_country'})\na","ead43f6c":"dd=ad['income']\ndd = pd.DataFrame(dd)\ndd","bf8004f7":"a = pd.concat([a,dd],axis=1)\na","d6d9e12a":"a.dtypes","7bc72ced":"a.income.value_counts()","6474d599":"def encode_target(x):\n    if x == \"<=50K\":\n        return 1\n    elif x == \">50K\":\n        return 0\na['income']=a['income'].apply(encode_target)\na","f54bc134":"plt.rcParams[\"figure.figsize\"] = 12,8\nimport matplotlib.pyplot as plt\nfig,axes = plt.subplots(2,3)\n\n\naxes[0,0].set_title(\"fnlwgt\")\naxes[0,0].boxplot(a['fnlwgt'])\naxes[0,1].set_title(\"capital.loss\")\naxes[0,1].boxplot(a['Capital_loss'])\naxes[0,2].set_title(\"hours_per_week\")\naxes[0,2].boxplot(a['hours_per_week'])\n\n\n\naxes[1,0].set_title(\"education\")\naxes[1,0].boxplot(a['education'])\naxes[1,1].set_title(\"occupation\")\naxes[1,1].boxplot(a['occupation'])\naxes[1,2].set_title(\"native_country\")\naxes[1,2].boxplot(a['native_country'])","5b36ef38":"def outlier(x):\n    high=0\n    q1 = x.quantile(.25)\n    q3 = x.quantile(.75)\n    iqr = q3-q1\n    low = q1-1.5*iqr\n    high += q3+1.5*iqr\n    outlier = (x.loc[(x < low) | (x > high)])\n    return(outlier)","359a09a6":"outlier(a['hours_per_week']).count()\n","30d362f1":"outlier(a['fnlwgt']).count()","4f95cf45":"outlier(a['native_country']).count()","f79c92cd":"outlier(a['income']).count()","61a8b2d0":"q1 =a.quantile(.25)\nq3 =a.quantile(.75)\niqr = q3-q1","e3b7bfab":"df_new = a[~((a < (q1 - 1.5 *iqr))  |  (a > (q3+ 1.5 * iqr)))]","90a9223c":"df_new.isna().sum()","be847847":"modeval=int(df_new['workclass'].mode())\ndf_new.workclass = df_new.workclass.fillna(modeval)","bf009b04":"modeval=int(df_new['fnlwgt'].mode())\ndf_new.fnlwgt = df_new.fnlwgt.fillna(modeval)","50c80088":"modeval=int(df_new['education'].mode())\ndf_new.education = df_new.education.fillna(modeval)","b7aae06d":"modeval=int(df_new['education_num'].mode())\ndf_new.education_num = df_new.education_num.fillna(modeval)","05c3014e":"modeval=int(df_new['race'].mode())\ndf_new.race = df_new.race.fillna(modeval)","1178004b":"modeval=int(df_new['Capital_gain'].mode())\ndf_new.Capital_gain = df_new.Capital_gain.fillna(modeval)","46c482e3":"modeval=int(df_new['Capital_loss'].mode())\ndf_new.Capital_loss = df_new.Capital_loss.fillna(modeval)","00ab465c":"modeval=int(df_new['hours_per_week'].mode())\ndf_new.hours_per_week = df_new.hours_per_week.fillna(modeval)","b4050bcc":"modeval=int(df_new['native_country'].mode())\ndf_new.native_country = df_new.native_country.fillna(modeval)","b7106f24":"df_new=df_new.fillna(0)","cf28c253":"\ndf_new.isna().sum()","a1a55f78":"df_new.shape","2647b17f":"plt.rcParams[\"figure.figsize\"] = 12,8\nimport matplotlib.pyplot as plt\nfig,axes = plt.subplots(2,3)\n\n\naxes[0,0].set_title(\"fnlwgt\")\naxes[0,0].boxplot(df_new['fnlwgt'])\naxes[0,1].set_title(\"capital.loss\")\naxes[0,1].boxplot(df_new['Capital_loss'])\naxes[0,2].set_title(\"hours_per_week\")\naxes[0,2].boxplot(df_new['hours_per_week'])\n\n\n\naxes[1,0].set_title(\"education\")\naxes[1,0].boxplot(df_new['education'])\naxes[1,1].set_title(\"occupation\")\naxes[1,1].boxplot(df_new['occupation'])\naxes[1,2].set_title(\"native_country\")\naxes[1,2].boxplot(df_new['native_country'])","5da1a2b3":"df_new.income = df_new.income.astype(int)\n\ndf_new","1a1d112b":"x = df_new.drop(['income'],axis=1)\ny = df_new['income']","58c9a290":"from sklearn.model_selection import train_test_split","c7d5e3e6":"x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=42)","a8f1ef39":"from sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","d776d0ac":"pipeline_lr=Pipeline([('lr_classifier',LogisticRegression(random_state=0))])\npipeline_dt=Pipeline([('dt_classifier',DecisionTreeClassifier())])\npipeline_rf=Pipeline([('rf_classifier',RandomForestClassifier())])\npipeline_Nb=Pipeline([('Nb_Gaussion',GaussianNB())])\npipeline_XGb=Pipeline([('XGb_classifier',XGBClassifier())])","e00ec72b":"pipelines = [pipeline_lr, pipeline_dt, pipeline_rf,pipeline_Nb,pipeline_XGb]","cfbf6dee":"best_accuracy=0.0\nbest_classifier=0\nbest_pipeline=\"\"\npipe_dict = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'RandomForest',3:'GaussianNB',4:'XGBClassifier'}","234003dd":"for pipe in pipelines:\n    pipe.fit(x_train, y_train)","da69614e":"for i,model in enumerate(pipelines):\n    print(\"{} Test Accuracy: {}\".format(pipe_dict[i],model.score(x_test,y_test)))","40984b64":"for i,model in enumerate(pipelines):\n    if model.score(x_test,y_test)>best_accuracy:\n        best_accuracy=model.score(x_test,y_test)\n        best_pipeline=model\n        best_classifier=i\nprint('Classifier with best accuracy:{}'.format(pipe_dict[best_classifier]))","cb19c013":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE()\nx_train_smote, y_train_smote = smote.fit_sample(x_train.astype('float'),y_train)\n\nfrom collections import Counter\nprint(\"Before smote:\",Counter(y_train))\nprint(\"After smote:\",Counter(y_train_smote))","8801f739":"pipeline_lr1=Pipeline([('lr_classifier',LogisticRegression(random_state=0))])\npipeline_dt1=Pipeline([('dt_classifier',DecisionTreeClassifier())])\npipeline_rf1=Pipeline([('rf_classifier',RandomForestClassifier())])\npipeline_Nb1=Pipeline([('Nb_Gaussion',GaussianNB())])\npipeline_XGb1=Pipeline([('XGb_classifier',XGBClassifier())])","99024a59":"pipelines1 = [pipeline_lr1, pipeline_dt1, pipeline_rf1,pipeline_Nb1,pipeline_XGb1]","2387eea7":"best_accuracy1=0.0\nbest_classifier1=0\nbest_pipeline1=\"\"\npipe_dict1 = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'RandomForest',3:'GaussianNB',4:'XGBClassifier'}","a7a83ca4":"for pipe in pipelines1:\n    pipe.fit(x_train_smote, y_train_smote)","f20f7d3a":"from sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfor i,model in enumerate(pipelines1):\n    print(\"{} Test Accuracy: {}\".format(pipe_dict1[i],model.score(x_test,y_test)))","530e48a0":"for i,model in enumerate(pipelines1):\n    if model.score(x_test,y_test)>best_accuracy1:\n        best_accuracy1=model.score(x_test,y_test)\n        best_pipeline1=model\n        best_classifier1=i\nprint('Classifier with best accuracy:{}'.format(pipe_dict1[best_classifier1]))","a7f47950":"Logisclassifier = LogisticRegression(random_state = 95)\nLogisclassifier.fit(x_train_smote, y_train_smote)\nLOGy_pred = Logisclassifier.predict(x_test)\nprint(\"LG:\",classification_report(LOGy_pred,y_test),confusion_matrix(y_test, LOGy_pred))","b20ca472":"Desclassifier = DecisionTreeClassifier()\nDesclassifier.fit(x_train,y_train)\ny_preddtree = Desclassifier.predict(x_test)\nprint(\"DTREE:\",classification_report(y_preddtree,y_test),confusion_matrix(y_test, y_preddtree))","c29c800b":"Classmodel = RandomForestClassifier(n_estimators = 100, random_state = 42)\nClassmodel.fit(x_train_smote, y_train_smote)\ny_pred = Classmodel.predict(x_test)\nprint(\"RF:\",classification_report(y_pred,y_test),confusion_matrix(y_test, y_pred))","412c9e87":"classifier = GaussianNB()\nclassifier.fit(x_train_smote, y_train_smote)\ny_predNB = classifier.predict(x_test)\nprint(\"NB:\",classification_report(y_predNB,y_test),confusion_matrix(y_test, y_predNB))","38c2fe0f":"XGBModel = XGBClassifier(n_estimators=110,learning_rate=0.05,max_depth=3)\nXGBModel.fit(x_train_smote, y_train_smote)\ny_predXg = XGBModel.predict(x_test)\nprint(\"XGB:\",classification_report(y_predXg,y_test),confusion_matrix(y_test, y_predXg))","75c2581f":"# Model PipeLine After SMOTE","9289e426":"# Separation Of x and y","42a36bb9":"# Classification Report","b863e3cd":"# Power Transformation","6e496ae8":"# Removing Outliers","dd554842":"# Import Data","000aeeb6":"## Finding Outliers","06357452":"# Over Sampling With SMOTE","31b5484f":"# Train Test Split","7220d769":"# Data Preprocessing","0e0f7080":"# Data Visualization","a87a34f8":"# Model PipeLine","e19747ba":"### Label Encoding"}}