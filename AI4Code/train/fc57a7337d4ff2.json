{"cell_type":{"9e00b978":"code","4dbbffad":"code","cdbcc275":"code","e38ac4b1":"code","70283f9b":"code","a7a35de8":"code","970315e0":"code","dc03c816":"code","f8a5dad0":"code","3176d64b":"code","40f2ff99":"code","86cc68d8":"code","18208694":"code","1234fd76":"code","f353265a":"code","19ff621e":"code","d10bda78":"code","c4316e71":"code","dbe41585":"code","35d2a66b":"code","570fbc52":"code","3087304b":"code","0c1ce365":"code","4c9988fe":"code","0eb922ca":"code","3867fcf6":"code","2360f5db":"code","e5341a44":"code","ec5e575d":"code","c26f7bd2":"code","ba4e63dc":"code","da8c1e1e":"code","ab127756":"code","07935f63":"code","70e022e8":"code","100c2888":"code","e40abf67":"code","fa5bd5df":"code","b02a95fe":"code","599d27f5":"code","99f598e8":"markdown","f0c2324d":"markdown","ce6a46c5":"markdown","0e8a47ee":"markdown","c6377baa":"markdown","8c5c7dee":"markdown","f3cae852":"markdown","6997feda":"markdown","67ae4727":"markdown","c182590e":"markdown","43423770":"markdown","f4b0227c":"markdown","4092524c":"markdown","09c24504":"markdown","a6fbd73b":"markdown","383334e3":"markdown","2a22b78e":"markdown","4b9a8a77":"markdown","a0a27b5c":"markdown","7a2e004f":"markdown","fbe8e07d":"markdown","40a96058":"markdown","306a9b82":"markdown","268e999e":"markdown","1ed76281":"markdown","c7068ed9":"markdown","80404dac":"markdown","663b1c2c":"markdown","550d4821":"markdown","d38ed8d7":"markdown","d2d741d2":"markdown","95227dff":"markdown","ea73c4c2":"markdown","d9831a45":"markdown","22cb8a2b":"markdown","7785cda1":"markdown","c49f38d2":"markdown","8cdd607a":"markdown","c597e9a8":"markdown","ed526a3e":"markdown","063e9b47":"markdown","8f489023":"markdown","133e788a":"markdown","b8c43bb2":"markdown","e678c222":"markdown","7b0f55b1":"markdown"},"source":{"9e00b978":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor","4dbbffad":"df = pd.read_csv(\"..\/input\/yeh-concret-data\/Concrete_Data_Yeh.csv\")","cdbcc275":"df.head()","e38ac4b1":"df.shape","70283f9b":"df.info()","a7a35de8":"df.describe().T","970315e0":"df.isna().sum()","dc03c816":"df.duplicated().sum()","f8a5dad0":"df.drop_duplicates(inplace=True)","3176d64b":"sns.set_theme()\nsns.pairplot(df)","40f2ff99":"for col in df.columns:\n    plt.figure(figsize=(10,8))\n    sns.distplot(df[col])\n    plt.show()","86cc68d8":"sns.set(style=\"whitegrid\")\n\ncols_without_y = df.drop(\"csMPa\", axis=1).columns\nfor col in cols_without_y:\n    sns.jointplot(x=df[col], y=df[\"csMPa\"], kind=\"kde\", cmap=\"Blues\", fill=True)\n    plt.show()","18208694":"plt.figure(figsize=(12,8))\nsns.heatmap(df.corr(), annot=True, cmap=\"RdBu\")\nplt.title(\"Correlations Between Variables\", size=16)\nplt.show()","1234fd76":"X = df.drop(\"csMPa\", axis=1)\ny = df[\"csMPa\"]","f353265a":"scaler = StandardScaler()\nX = scaler.fit_transform(X)","19ff621e":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","d10bda78":"def rmse_cv(model):\n    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=5)).mean()\n    return rmse\n\ndef evaluate(y, predictions):\n    mae = mean_absolute_error(y, predictions)\n    mse = mean_squared_error(y, predictions)\n    r_squared = r2_score(y, predictions)\n    return mae, mse, r_squared","c4316e71":"models = pd.DataFrame(columns=[\"Model\", \"MAE\", \"MSE\", \"r2 Score\", \"RMSE (Cross Validated)\"])","dbe41585":"lin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)\npredictions = lin_reg.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(lin_reg)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"r2 Score:\", r2)\nprint(\"RMSE (Cross Validated):\", rmse)\n\nnew_row = {\"Model\": \"LinearRegression\",\"MAE\": mae, \"MSE\": mse, \"r2 Score\": r2, \"RMSE (Cross Validated)\": rmse}\nmodels = models.append(new_row, ignore_index=True)","35d2a66b":"lasso = Lasso()\nlasso.fit(X_train, y_train)\npredictions = lasso.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(lasso)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"r2 Score:\", r2)\nprint(\"RMSE (Cross Validated):\", rmse)\n\nnew_row = {\"Model\": \"Lasso\",\"MAE\": mae, \"MSE\": mse, \"r2 Score\": r2, \"RMSE (Cross Validated)\": rmse}\nmodels = models.append(new_row, ignore_index=True)","570fbc52":"ridge = Ridge()\nridge.fit(X_train, y_train)\npredictions = ridge.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(ridge)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"r2 Score:\", r2)\nprint(\"RMSE (Cross Validated):\", rmse)\n\nnew_row = {\"Model\": \"Ridge\",\"MAE\": mae, \"MSE\": mse, \"r2 Score\": r2, \"RMSE (Cross Validated)\": rmse}\nmodels = models.append(new_row, ignore_index=True)","3087304b":"elastic_net = ElasticNet()\nelastic_net.fit(X_train, y_train)\npredictions = elastic_net.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(elastic_net)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"r2 Score:\", r2)\nprint(\"RMSE (Cross Validated):\", rmse)\n\nnew_row = {\"Model\": \"ElasticNet\",\"MAE\": mae, \"MSE\": mse, \"r2 Score\": r2, \"RMSE (Cross Validated)\": rmse}\nmodels = models.append(new_row, ignore_index=True)","0c1ce365":"svr = SVR()\nsvr.fit(X_train, y_train)\npredictions = svr.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(svr)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"r2 Score:\", r2)\nprint(\"RMSE (Cross Validated):\", rmse)\n\nnew_row = {\"Model\": \"SVR\",\"MAE\": mae, \"MSE\": mse, \"r2 Score\": r2, \"RMSE (Cross Validated)\": rmse}\nmodels = models.append(new_row, ignore_index=True)","4c9988fe":"rfr = RandomForestRegressor()\nrfr.fit(X_train, y_train)\npredictions = rfr.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(rfr)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"r2 Score:\", r2)\nprint(\"RMSE (Cross Validated):\", rmse)\n\nnew_row = {\"Model\": \"RandomForestRegressor\",\"MAE\": mae, \"MSE\": mse, \"r2 Score\": r2, \"RMSE (Cross Validated)\": rmse}\nmodels = models.append(new_row, ignore_index=True)","0eb922ca":"xgb = XGBRegressor()\nxgb.fit(X_train, y_train)\npredictions = xgb.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(xgb)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"r2 Score:\", r2)\nprint(\"RMSE (Cross Validated):\", rmse)\n\nnew_row = {\"Model\": \"XGBRegressor\",\"MAE\": mae, \"MSE\": mse, \"r2 Score\": r2, \"RMSE (Cross Validated)\": rmse}\nmodels = models.append(new_row, ignore_index=True)","3867fcf6":"models.sort_values(by=\"RMSE (Cross Validated)\")","2360f5db":"plt.figure(figsize=(12,8))\nsns.barplot(x=models[\"Model\"], y=models[\"RMSE (Cross Validated)\"])\nplt.title(\"Models' RMSE Scores\", size=16)\nplt.xticks(rotation=30)\nplt.show()","e5341a44":"tuned_models = pd.DataFrame(columns=[\"Tuned Model\", \"MAE\", \"MSE\", \"r2 Score\", \"RMSE (Cross Validated)\"])","ec5e575d":"lasso_grid_params = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n\nlasso_grid = GridSearchCV(Lasso(), lasso_grid_params, cv=5, scoring=\"neg_mean_squared_error\", verbose=0, n_jobs=-1)\n\nlasso_grid.fit(X_train, y_train)","c26f7bd2":"lasso_params = lasso_grid.best_params_\n\ntuned_lasso = Lasso(**lasso_params)\ntuned_lasso.fit(X_train, y_train)\npredictions = tuned_lasso.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(tuned_lasso)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"r2 Score:\", r2)\nprint(\"RMSE (Cross Validated):\", rmse)\n\nnew_row = {\"Tuned Model\": \"Lasso\",\"MAE\": mae, \"MSE\": mse, \"r2 Score\": r2, \"RMSE (Cross Validated)\": rmse}\ntuned_models = tuned_models.append(new_row, ignore_index=True)","ba4e63dc":"ridge_grid_params = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n\nridge_grid = GridSearchCV(Ridge(), ridge_grid_params, cv=5, scoring=\"neg_mean_squared_error\", verbose=0, n_jobs=-1)\n\nridge_grid.fit(X_train, y_train)","da8c1e1e":"ridge_params = ridge_grid.best_params_\n\ntuned_ridge = Ridge(**ridge_params)\ntuned_ridge.fit(X_train, y_train)\npredictions = tuned_ridge.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(tuned_ridge)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"r2 Score:\", r2)\nprint(\"RMSE (Cross Validated):\", rmse)\n\nnew_row = {\"Tuned Model\": \"Ridge\",\"MAE\": mae, \"MSE\": mse, \"r2 Score\": r2, \"RMSE (Cross Validated)\": rmse}\ntuned_models = tuned_models.append(new_row, ignore_index=True)","ab127756":"elasticnet_grid_params = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10],\n                    \"l1_ratio\": np.arange(0, 1, 0.05)}\n\nelasticnet_grid = GridSearchCV(ElasticNet(), elasticnet_grid_params, cv=5, scoring=\"neg_mean_squared_error\", verbose=0, n_jobs=-1)\n\nelasticnet_grid.fit(X_train, y_train)","07935f63":"elasticnet_params = elasticnet_grid.best_params_\n\ntuned_elasticnet = ElasticNet(**elasticnet_params)\ntuned_elasticnet.fit(X_train, y_train)\npredictions = tuned_elasticnet.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(tuned_elasticnet)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"r2 Score:\", r2)\nprint(\"RMSE (Cross Validated):\", rmse)\n\nnew_row = {\"Tuned Model\": \"Elastic Net\",\"MAE\": mae, \"MSE\": mse, \"r2 Score\": r2, \"RMSE (Cross Validated)\": rmse}\ntuned_models = tuned_models.append(new_row, ignore_index=True)","70e022e8":"svr_grid_params = {\"kernel\": [\"linear\", \"rbf\"],\n                   \"C\": [1, 10, 100, 1000],\n                   \"epsilon\": [0.001, 0.01, 0.1, 1, 10, 100],\n                   \"gamma\": [0.001, 0.01, 0.1, 1]}\n\nsvr_grid = GridSearchCV(SVR(), svr_grid_params, cv=5, scoring=\"neg_mean_squared_error\", verbose=0, n_jobs=-1)\n\nsvr_grid.fit(X_train, y_train)","100c2888":"svr_params = svr_grid.best_params_\n\ntuned_svr = SVR(**svr_params)\ntuned_svr.fit(X_train, y_train)\npredictions = tuned_svr.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(tuned_svr)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"r2 Score:\", r2)\nprint(\"RMSE (Cross Validated):\", rmse)\n\nnew_row = {\"Tuned Model\": \"SVR\",\"MAE\": mae, \"MSE\": mse, \"r2 Score\": r2, \"RMSE (Cross Validated)\": rmse}\ntuned_models = tuned_models.append(new_row, ignore_index=True)","e40abf67":"rfr_grid_params = {\"n_estimators\": [100, 200, 500],\n                   \"max_depth\": [None, 2, 3, 5],\n                   \"min_samples_split\": [2, 5, 10],\n                   \"min_samples_leaf\": [1, 2, 5]}\n\nrfr_grid = GridSearchCV(RandomForestRegressor(), rfr_grid_params, cv=5, scoring=\"neg_mean_squared_error\", verbose=0, n_jobs=-1)\n\nrfr_grid.fit(X_train, y_train)","fa5bd5df":"rfr_params = rfr_grid.best_params_\n\ntuned_rfr = RandomForestRegressor(**rfr_params)\ntuned_rfr.fit(X_train, y_train)\npredictions = tuned_rfr.predict(X_test)\n\nmae, mse, r2 = evaluate(y_test, predictions)\nrmse = rmse_cv(tuned_rfr)\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"r2 Score:\", r2)\nprint(\"RMSE (Cross Validated):\", rmse)\n\nnew_row = {\"Tuned Model\": \"RandomForestRegressor\",\"MAE\": mae, \"MSE\": mse, \"r2 Score\": r2, \"RMSE (Cross Validated)\": rmse}\ntuned_models = tuned_models.append(new_row, ignore_index=True)","b02a95fe":"tuned_models.sort_values(by=\"RMSE (Cross Validated)\")","599d27f5":"plt.figure(figsize=(12,8))\nsns.barplot(x=tuned_models[\"Tuned Model\"], y=tuned_models[\"RMSE (Cross Validated)\"])\nplt.title(\"Models' RMSE Scores After Hyperparameter Tuning\", size=16)\nplt.xticks(rotation=30)\nplt.show()","99f598e8":"<h2 style=\"font-family: Times New Roman\">Ridge (L2 Regularization)<\/h2>","f0c2324d":"<h2 style=\"font-family: Times New Roman\">Lasso (L1 Regularization)<\/h2>","ce6a46c5":"# Model Comparison","0e8a47ee":"<h2 style=\"font-family: Times New Roman\">Tuning the Elastic Net<\/h2>","c6377baa":"# <center>Concrete Compressive Strength Prediction \ud83e\uddf1<center>","8c5c7dee":"<h2 style=\"font-family: Times New Roman;\">After Model Building and Hyperparameter Tuning processes, we can observe that even though we didn't apply Hyperparameter Tuning to XGBRegressor model, that is the one which yields the least RMSE score and the most R2 score.<\/h2>","f3cae852":"***Standardizing the numerical columns in X dataset. StandardScaler() adjusts the mean of the features as 0 and standard deviation of features as 1. Formula that StandardScaler() uses is as follows:***","6997feda":"***Checking for duplicates in data and it can easily seen that there are 25 duplicated values.***","67ae4727":"<h2 style=\"font-family: Times New Roman\">XGBoost<\/h2>","c182590e":"<h2 style=\"font-family: Times New Roman\">Elastic Net<\/h2>","43423770":"# Handling Missing Values and Duplicates","f4b0227c":"# Conclusion","4092524c":"# Data Standardization","09c24504":"# X, y Split","a6fbd73b":"# Loading the Data","383334e3":"# Exploratory Data Analysis","2a22b78e":"<center><img width=\"270px\" src=\"https:\/\/www.thoughtco.com\/thmb\/gItmqGd5HlnhyPIiLm1YHXOlTnw=\/330x242\/filters:fill(auto,1)\/zscore-56a8fa785f9b58b7d0f6e87b.GIF\"><\/center>","4b9a8a77":"***Visualizing the Correlation between the numerical variables using pairplot visualization.***","a0a27b5c":"# About the Dataset","7a2e004f":"***It seems that there is no missing value in the columns.***","fbe8e07d":"***Dropping all the duplicated values from the dataset.***","40a96058":"<h2 style=\"font-family: Times New Roman\">Tuning the Support Vector Machines<\/h2>","306a9b82":"# Machine Learning Models","268e999e":"# Train-Test Split","1ed76281":"***Visualizing the linear correlations between variables using Heatmap visualization. The measure used for finding the linear correlation between each variable is Pearson Correlation Coefficient.***","c7068ed9":"<h2 style=\"font-family: Times New Roman\">Tuning the Random Forest<\/h2>","80404dac":"<h2 style=\"font-family: Times New Roman\">Linear Regression<\/h2>","663b1c2c":"<h2 style=\"font-family: Times New Roman\">Tuning the Ridge<\/h2>","550d4821":"***Taking a look at the first 5 rows of the dataset.***","d38ed8d7":"# Data Visualization","d2d741d2":"<center><img width=\"750px\" src=\"https:\/\/cdn.pixabay.com\/photo\/2015\/03\/27\/18\/30\/crack-695010_960_720.jpg\"><\/center>","95227dff":"<h2 style=\"font-family: Times New Roman\">Distribution of Each Variable<\/h2>","ea73c4c2":"<h3 style=\"font-family: Times New Roman\">Thank you so much for reading notebook. Preparing notebooks are taking a great deal of time. If you liked it, please do not forget to give upvote. Peace Out \u270c\ufe0f ...<\/h3>","d9831a45":"<h2 style=\"font-family: Times New Roman\">Random Forest<\/h2>","22cb8a2b":"# Hyperparameter Tuning","7785cda1":"<h2 style=\"font-family: Times New Roman\">Tuning the Lasso<\/h2>","c49f38d2":"***Learning the dtypes of columns' and how many non-null values are there in those columns.***","8cdd607a":"***Checking the shape\u2014i.e. size\u2014of the data.***","c597e9a8":"* **Cement** (component 1) -- quantitative -- kg in a m3 mixture -- *Input Variable*\n* **Blast** Furnace Slag (component 2) -- quantitative -- kg in a m3 mixture -- *Input Variable*\n* **Fly Ash** (component 3) -- quantitative -- kg in a m3 mixture -- *Input Variable*\n* **Water** (component 4) -- quantitative -- kg in a m3 mixture -- *Input Variable*\n* **Superplasticizer** (component 5) -- quantitative -- kg in a m3 mixture -- *Input Variable*\n* **Coarse Aggregate** (component 6) -- quantitative -- kg in a m3 mixture -- *Input Variable*\n* **Fine Aggregate** (component 7) -- quantitative -- kg in a m3 mixture -- *Input Variable*\n* **Age** -- quantitative -- Day (1~365) -- *Input Variable*\n* **Concrete Compressive Strength** -- quantitative -- MPa -- *Output Variable*","ed526a3e":"***Defining several evaluation functions for convenience.***","063e9b47":"<h2 style=\"font-family: Times New Roman\">Relationship Between Each Variable and Target Variable (csMPa)<\/h2>","8f489023":"<h2 style=\"font-family: Times New Roman\">Support Vector Machines<\/h2>","133e788a":"***Getting the statistical summary of dataset.***","b8c43bb2":"***Splitting the data into Train and Test chunks for better evaluation.***","e678c222":"# Model Comparison After Hyperparameter Tuning","7b0f55b1":"# Importing the Essential Libraries, Metrics and Models"}}