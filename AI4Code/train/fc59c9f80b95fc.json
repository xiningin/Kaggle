{"cell_type":{"60588795":"code","082186f6":"code","eba1110f":"code","04727b46":"code","db4b543d":"code","4f3a5753":"code","0181aebe":"code","1e1fbb0d":"code","0b99253f":"code","1a907916":"code","fbb4b379":"code","58634690":"code","f4f65ac1":"code","800687de":"code","fb806309":"code","c8b50dbf":"code","691fc7c7":"code","617d1559":"code","4102f9f8":"code","994ba845":"code","f2d99376":"code","67e696d0":"code","67ab8c08":"code","08867978":"code","c1c0e078":"code","de1afbbf":"code","b0eb3897":"code","a987e121":"code","0034c37d":"code","d2dbdd92":"code","0f166608":"code","bef61884":"code","00043412":"code","f902e551":"code","c65f4517":"markdown"},"source":{"60588795":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport pandas \ntrain_data = pandas.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_data = pandas.read_csv('..\/input\/titanic\/test.csv')","082186f6":"train_data.isnull().sum()","eba1110f":"# fill NA \ntrain_data[\"Age\"] = train_data[\"Age\"].fillna(train_data[\"Age\"].median())\ntrain_data[\"Embarked\"] = train_data[\"Embarked\"].fillna('S')\n\n# S\u21920\uff1bC\u21921\uff1bQ\u21922\ntrain_data.loc[train_data[\"Embarked\"] == \"S\", \"Embarked\"] = 0\ntrain_data.loc[train_data[\"Embarked\"] == \"C\", \"Embarked\"] = 1\ntrain_data.loc[train_data[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n\n# male\u21920\uff0cfemale\u21921\ntrain_data.loc[train_data[\"Sex\"] == \"male\", \"Sex\"] = 0\ntrain_data.loc[train_data[\"Sex\"] == \"female\", \"Sex\"] = 1\n\n# ignore cabin ","04727b46":"train_data.isnull().sum()","db4b543d":"test_data.isnull().sum()","4f3a5753":"# fill NA\ntest_data[\"Age\"] = test_data[\"Age\"].fillna(test_data[\"Age\"].median())\ntest_data[\"Fare\"] = test_data[\"Fare\"].fillna(test_data[\"Fare\"].median())\n\n# S\u21920\uff1bC\u21921\uff1bQ\u21922\ntest_data.loc[test_data[\"Embarked\"] == \"S\", \"Embarked\"] = 0\ntest_data.loc[test_data[\"Embarked\"] == \"C\", \"Embarked\"] = 1\ntest_data.loc[test_data[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n\n# male\u21920\uff0cfemale\u21921\ntest_data.loc[test_data[\"Sex\"] == \"male\", \"Sex\"] = 0\ntest_data.loc[test_data[\"Sex\"] == \"female\", \"Sex\"] = 1","0181aebe":"test_data.isnull().sum()","1e1fbb0d":"import numpy as np\nimport matplotlib.pyplot as plt","0b99253f":"import seaborn as sns\nsns.barplot(x='Sex',y='Survived',data=train_data)\nplt.show()\n\n# The survival rate of female is higher than that of male","1a907916":"sns.barplot(x=\"Pclass\", y=\"Survived\", data=train_data)\n\n# print percentage of people by Pclass that survived\nprint(\"Percentage of Pclass = 1 who survived:\", train_data[\"Survived\"][train_data[\"Pclass\"] == 1].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of Pclass = 2 who survived:\", train_data[\"Survived\"][train_data[\"Pclass\"] == 2].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of Pclass = 3 who survived:\", train_data[\"Survived\"][train_data[\"Pclass\"] == 3].value_counts(normalize = True)[1]*100)\n\n# First class has the highest survival rate","fbb4b379":"# draw a bar plot for SibSp vs. survival\nsns.barplot(x=\"SibSp\", y=\"Survived\", data=train_data)\n\nprint(\"Percentage of SibSp = 0 who survived:\", train_data[\"Survived\"][train_data[\"SibSp\"] == 0].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of SibSp = 1 who survived:\", train_data[\"Survived\"][train_data[\"SibSp\"] == 1].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of SibSp = 2 who survived:\", train_data[\"Survived\"][train_data[\"SibSp\"] == 2].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of SibSp = 3 who survived:\", train_data[\"Survived\"][train_data[\"SibSp\"] == 3].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of SibSp = 4 who survived:\", train_data[\"Survived\"][train_data[\"SibSp\"] == 4].value_counts(normalize = True)[1]*100)\n\n#One sibling had the highest survival rate, while no sibling or too many siblings had the lowest survival rate.","58634690":"import matplotlib.pyplot as plt\nsns.barplot(x=\"Parch\", y=\"Survived\", data=train_data)\nplt.show()\n\n# The survival rate of children with old people is high\n# The survival rate of traveling alone in disaster is relatively low","f4f65ac1":"from sklearn.preprocessing import StandardScaler\n\n# predict the features of train_data\npredictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\nx_data = train_data[predictors]\ny_data = train_data[\"Survived\"]\n\nx2_data = test_data[predictors]\n\n\n# Data standardization\nscaler = StandardScaler()\nx_data = scaler.fit_transform(x_data)\nx2_data = scaler.fit_transform(x2_data)\n","800687de":"import numpy as np\nimport matplotlib.pyplot as plt","fb806309":"#LogisticRegression\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\n\nparams = [1,10,15,20,25,30,40,50,60,70]\nfor param in params:\n    LR = LogisticRegression()\n    scores = model_selection.cross_val_score(LR, x_data, y_data, cv=10)\n\nplt.plot(params,scores,c='r')\nprint(scores.mean()) ","c8b50dbf":"#nural_network\nfrom sklearn.neural_network import MLPClassifier\n\nparams = [1,10,15,20,25,30,40,50,60,70]\nfor param in params:\n    mlp = MLPClassifier(hidden_layer_sizes=(50,20,10),max_iter=1000)\n    scores = model_selection.cross_val_score(mlp, x_data, y_data, cv=10)\n    \nplt.plot(params,scores,c='r')\nplt.show()\nprint(scores.mean())","691fc7c7":"#KNN\nfrom sklearn import neighbors\n\nparams = [1,10,15,20,25,30,40,50,60,70]\nfor param in params:\n    # k=20\n    knn = neighbors.KNeighborsClassifier(20)\n    scores = model_selection.cross_val_score(knn,x_data,y_data,cv=10)\n    \nplt.plot(params,scores,c='r')\nprint(scores.mean())   ","617d1559":"# decision tree\nfrom sklearn import tree\n\nparams = [1,10,15,20,25,30,40,50,60,70]\n\nfor param in params:\n    dtree = tree.DecisionTreeClassifier(max_depth=3,min_samples_split=4)\n    scores = model_selection.cross_val_score(dtree,x_data,y_data,cv=10)\n\nplt.plot(params,scores,c='r')\nprint(scores.mean())   ","4102f9f8":"# Random Foreset\nfrom sklearn.ensemble import RandomForestClassifier\n\nparams = [1,10,15,20,25,30,40,50,60,70]\n\nfor param in params:\n    RF1 = RandomForestClassifier(random_state=1,n_estimators=100,min_samples_split=2)\n    scores = model_selection.cross_val_score(RF1,x_data,y_data,cv=10)\n    \nplt.plot(params,scores,c='r')\nprint(scores.mean())   ","994ba845":"# Bagging\nfrom sklearn.ensemble import BaggingClassifier\n\nparams = [1,10,15,20,25,30,40,50,60,70]\nfor param in params:\n    bagging_clf = BaggingClassifier(RF1,n_estimators=params)\n    scores = model_selection.cross_val_score(RF1, x_data, y_data, cv=10)\n    \nplt.plot(params,scores,c='r')\nprint(scores.mean()) ","f2d99376":"# Adaboost\nfrom sklearn.ensemble import AdaBoostClassifier\n\nparams = [1,10,15,20,25,30,40,50,60,70]\nfor param in params:\n    adaboost = AdaBoostClassifier(bagging_clf,n_estimators=10)\n    scores = model_selection.cross_val_score(RF1, x_data, y_data, cv=10)\n    \nplt.plot(params,scores,c='r')\nprint(scores.mean())  ","67e696d0":"# deal with train_data(x2_data)\n\nprint(x_data.shape)\nprint(x2_data.shape)","67ab8c08":"zero = np.zeros((473,7))\nx2_data = np.concatenate((x2_data,zero),axis=0)\nprint(x2_data.shape)","08867978":"zero = np.zeros((473,11))\ntest_data_2 = np.concatenate((test_data,zero),axis=0)","c1c0e078":"print(x_data.ndim)\nprint(x2_data.ndim)","de1afbbf":"from sklearn.metrics import classification_report","b0eb3897":"#Logistic Regression\n\nLR.fit(x_data,y_data)\npredictions = LR.predict(x2_data)\nprint(classification_report(y_data,predictions))\n# precision is very low T.T","a987e121":"#nural_network\n\nmlp.fit(x_data,y_data)\npredictions_1 = mlp.predict(x2_data)\nprint(classification_report(y_data,predictions_1))\n# precision is very low T.T","0034c37d":"# KNN\nknn.fit(x_data,y_data)\npredictions_2 = knn.predict(x2_data)\nprint(classification_report(y_data,predictions_2))\n# precision is very low T.T","d2dbdd92":"# Decision tree\ndtree.fit(x_data,y_data)\npredictions_3 = dtree.predict(x2_data)\nprint(classification_report(y_data,predictions_3))","0f166608":"# Random_Forest\nRF1.fit(x_data,y_data)\npredictions_4 = RF1.predict(x2_data)\nprint(classification_report(y_data,predictions_4))","bef61884":"# Bagging\nbagging_clf = BaggingClassifier(knn,n_estimators=100)\nbagging_clf.fit(x_data,y_data)\npredictions_5 = bagging_clf.predict(x2_data)\nprint(classification_report(y_data,predictions_5))","00043412":"# Adaboost\nadaboost = AdaBoostClassifier(LR,n_estimators=10)\nadaboost.fit(x_data,y_data)\npredictions_6 = adaboost.predict(x2_data)\nprint(classification_report(y_data,predictions_6))","f902e551":"import pandas as pd\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions_6[:418]})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","c65f4517":"## import test_data to trained models\n"}}