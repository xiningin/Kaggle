{"cell_type":{"ff3a540c":"code","6e094f68":"code","1b4bca70":"code","68fc41aa":"code","0119b831":"code","17c95096":"code","0be87e6c":"code","067a2088":"code","43b5310b":"code","ead556a5":"code","1037dc95":"code","4bf3bfbb":"code","e634af6e":"code","a34f5553":"code","7d651399":"code","12deeaa4":"code","ba994cd2":"code","7496c045":"code","3f1f5987":"code","43405102":"code","749155bb":"code","23a807b9":"code","dda7415d":"code","60d4a0f9":"code","547611c0":"code","ddd0b575":"code","49a6ac0b":"code","5c7f253c":"code","fac2d62a":"code","8e8dfd19":"code","b5d58102":"code","9185f78a":"code","26cd2383":"code","2804eb4d":"code","4f82e3fe":"code","77d3fa95":"code","f4726a2a":"code","0092c0a0":"code","6a49be66":"code","867af489":"code","50de161e":"code","39be1dfe":"code","2fb5f3da":"code","b69bd4d9":"code","893b8ad4":"code","9054a2ef":"code","ad4c7f4d":"code","1616f619":"code","4033225c":"code","62dee9cf":"code","320b6c1d":"code","978de290":"code","eff31942":"code","ba18e9e2":"code","c4d195b2":"code","dc77ff23":"code","2faf7983":"code","3e0312c9":"code","44c4d52b":"code","775c6ac3":"code","4d60e358":"code","30c94dd3":"code","1e5b5d11":"code","53093e1c":"code","c16bf7ba":"code","7f322dc8":"code","ada195c4":"code","24a58a80":"code","59ff2c45":"code","649b465c":"code","8420d12b":"code","06a67884":"code","b87aa096":"code","e680dcb7":"code","305780f9":"code","be777198":"code","31738b57":"code","b2b39ceb":"code","8da14a63":"code","593643fb":"code","40a50dc0":"code","e00f6b9a":"code","fbc20d42":"code","9b8a86b0":"code","84a9990f":"code","92b24ded":"code","f7db3607":"code","fde57db7":"code","edb0e43c":"code","64507df8":"code","c6ab806a":"code","6b0c9395":"code","76f86e37":"code","0be69dfd":"code","dc32e347":"code","0dfd0d61":"code","56d37854":"code","4c2e7246":"code","8ec57e43":"code","7aeed0b8":"code","0006d6ed":"code","7b34886e":"code","5d886685":"code","8d4d53f6":"code","0746afcd":"code","0cde9318":"code","737a76bd":"code","cf79865b":"code","3747ee54":"code","7c5768b2":"code","edd234b6":"code","3ba6cede":"code","e0a6c316":"code","4d44e1c1":"code","56baca1f":"code","073d4d3e":"code","943f9998":"code","addfac99":"code","4e4764ce":"code","223027ce":"code","29bb1e65":"code","a797a55f":"code","7ffb4818":"code","1edfd00b":"code","f63a0d58":"code","fc62d16f":"code","92f15ade":"code","a26d82ab":"code","918ba3ca":"code","a233eef0":"code","3744e592":"code","2cce3c8a":"code","ab041f1f":"code","98054236":"code","ca40aa15":"code","db540baf":"code","304b5765":"code","0b081a8e":"code","7220d043":"code","eb7f0437":"code","6a66fee9":"code","71abb386":"code","3e90ab9a":"code","d5bafbad":"code","6a421745":"code","e46db9ed":"code","1f41f538":"code","b2155122":"code","ae9180f1":"code","add877f5":"code","113b5f31":"code","c23f965b":"code","0d5e6886":"code","2457bdb0":"code","1cb342d6":"code","5f48f059":"code","24fdaa3f":"code","e816fd43":"code","4030815b":"code","09eefd55":"code","f82f9d7d":"code","332d9a30":"code","9d7c42bf":"code","7b4fa004":"code","0a6d6c0f":"code","6603d831":"code","9172a224":"code","1a95da5a":"code","cd7e473e":"code","61df1c45":"code","970ece7c":"code","469500b6":"code","f3d3ba3e":"code","bd53b029":"code","e64df0bf":"code","2004337f":"code","b33807a6":"code","600788c9":"code","d3015bfc":"code","efde0447":"code","933fd79a":"code","13a870d3":"code","e88f2887":"code","5cf070a9":"code","b7eb4797":"code","235c2bd1":"code","84da6369":"code","5934810f":"code","3f151337":"code","d112ae98":"code","f03813cf":"code","1b5f0746":"code","35ab4168":"markdown","2af37356":"markdown","52ea94e1":"markdown","9c9bfd11":"markdown","43a19248":"markdown","2644c876":"markdown","d415ceb1":"markdown","6691a9f4":"markdown","241cf462":"markdown","72f64a42":"markdown","359f3297":"markdown","4f40197e":"markdown","75fe8319":"markdown","981be086":"markdown","d0dcf1f8":"markdown","31320051":"markdown","89e056cd":"markdown"},"source":{"ff3a540c":"# Data analysis and wragling\nimport pandas as pd\nimport numpy as np","6e094f68":"# Visualisation\nimport seaborn as sns\nimport matplotlib.pyplot as plt \nimport missingno","1b4bca70":"# Statistics\nfrom statistics import stdev\nfrom scipy.stats import t","68fc41aa":"# Dates\nimport matplotlib.dates as mdates","0119b831":"# Remove warnings\nimport warnings\nwarnings.filterwarnings('ignore')","17c95096":"# Import data\n\ndata = pd.read_csv('..\/input\/qvi-data\/QVI_data.csv')","0be87e6c":"data.head()","067a2088":"data.shape","43b5310b":"# Check for null \n\nmissingno.matrix(data)","ead556a5":"# Create 'YEARMONTH' feature\n\ndata['YEARMONTH'] = [''.join(x.split('-')[0:2]) for x in data.DATE]\ndata['YEARMONTH'] = pd.to_numeric(data['YEARMONTH'])\ndata['YEARMONTH'].head()","1037dc95":"# Check to see if 'YEARMONTH' is 'int'\n\ndata.info()","4bf3bfbb":"# Monthly store total sales\n# Sum up total sales\n\ntotSales = data.groupby(['STORE_NBR', 'YEARMONTH']).TOT_SALES.sum()\ntotSales","e634af6e":"# Monthly store number of customers\n# Count the unique loyalty card number for each store in each month\n\nnCustomers = data.groupby(['STORE_NBR', 'YEARMONTH']).LYLTY_CARD_NBR.nunique()\nnCustomers","a34f5553":"# Monthly store number of transactions per customer\n# Divided unique transaction ID by unique loyalty card number\n\nnTxnPerCust = data.groupby(['STORE_NBR', 'YEARMONTH']).TXN_ID.nunique() \/ data.groupby(['STORE_NBR', 'YEARMONTH']).LYLTY_CARD_NBR.nunique()\nnTxnPerCust","7d651399":"# Monthly store number of chips per transaction\n# Sum up product quantity and divided that by number of unique transactions\n\nnChipsPerTxn = data.groupby(['STORE_NBR', 'YEARMONTH']).PROD_QTY.sum() \/ data.groupby(['STORE_NBR', 'YEARMONTH']).TXN_ID.nunique()\nnChipsPerTxn","12deeaa4":"# Monthly store average price per unit\n# Sum up total sales and divide that by sum of product quantity\n\navgPricePerUnit = data.groupby(['STORE_NBR', 'YEARMONTH']).TOT_SALES.sum() \/ data.groupby(['STORE_NBR', 'YEARMONTH']).PROD_QTY.sum()\navgPricePerUnit","ba994cd2":"# Concatenate into a new dataframe called 'measureOverTime'\n\ndf = [totSales, nCustomers, nTxnPerCust, nChipsPerTxn, avgPricePerUnit]\nmeasureOverTime = pd.concat(df, join = 'outer', axis = 1)\nmeasureOverTime","7496c045":"# Rename the columns\n\nmeasureOverTime.rename(columns = {'TOT_SALES': 'totSales', 'LYLTY_CARD_NBR': 'nCustomers', 0: 'nChipsPerCust', 1: 'nChipsPerTxn', 2: 'avgPricePerUnit'}, inplace = True)\nmeasureOverTime.head()","3f1f5987":"# Which stores do not have full observation i.e. have months where there is no transaction for chips\n\na = pd.pivot_table(data, index = 'STORE_NBR', columns = 'YEARMONTH', values = 'TXN_ID', aggfunc = 'count')\na","43405102":"a.isnull().sum()","749155bb":"# Let's visualise the null values\n\nmissingno.matrix(a)","23a807b9":"# Store numbers that do not have full observation periods\n\nnull_store = a[a.isnull().any(axis=1)].index.tolist()\nnull_store","dda7415d":"len(null_store)\n\n# Comment: There are 12 stores with incomplete observation period","60d4a0f9":"# Let's drop these stores from 'measureOverTime'\n\nmeasureOverTime.head()","547611c0":"len(measureOverTime)","ddd0b575":"measureOverTime.reset_index(inplace = True)\nmeasureOverTime.head()","49a6ac0b":"# Drop 'null_store' from 'measureOverTime' dataframe\n\nmeasureOverTime = measureOverTime[~measureOverTime['STORE_NBR'].isin(null_store)]\nlen(measureOverTime)","5c7f253c":"# Create new dataframe 'preTrialMeasures' \n# Filter to pre-trial period i.e. before 201902\n\npreTrialMeasures = measureOverTime.loc[measureOverTime['YEARMONTH'] < 201902, :]\nlen(preTrialMeasures)","fac2d62a":"preTrialMeasures.head()","8e8dfd19":"# Create a function which calculates the correlation between trial store and other stores based on a single metric\n\ndef calculateCorrelation(inputTable, metric, trial_store):\n    output = pd.DataFrame({'Store1': [], 'Store2': [], 'Correlation': []})\n    a = inputTable.loc[inputTable['STORE_NBR'] == trial_store, metric]\n    a.reset_index(drop = True, inplace = True)\n    storeNumbers = inputTable['STORE_NBR'].unique()\n    for i in storeNumbers:\n        b = inputTable.loc[inputTable['STORE_NBR'] == i, metric]\n        b.reset_index(drop = True, inplace = True)\n        output = output.append({'Store1': trial_store, 'Store2': i, 'Correlation': b.corr(a)}, ignore_index = True)\n    return output","b5d58102":"# Create another function which calculates a standardised magnitude difference \n\ndef calculateMagnitudeDistance(inputTable, metric, trial_store):\n    output = pd.DataFrame({'Store1': [], 'Store2': [], 'Magnitude' : []})\n    a = inputTable.loc[inputTable['STORE_NBR'] == trial_store, metric]\n    a.reset_index(drop = True, inplace = True)\n    storeNumbers = inputTable['STORE_NBR'].unique()\n    for i in storeNumbers:\n        b = inputTable.loc[inputTable['STORE_NBR'] == i, metric]\n        b.reset_index(drop = True, inplace = True)\n        c = abs(a-b)\n        d = np.mean(1-(c-min(c))\/(max(c)-min(c)))\n        output = output.append({'Store1': trial_store, 'Store2': i, 'Magnitude': d}, ignore_index = True)\n    return output","9185f78a":"# Now let's use those two functions to find the control store\n\n# Compute correlation with trial store 77\ntrial_store = 77\ncorr_nSales = calculateCorrelation(preTrialMeasures, 'totSales', trial_store)\ncorr_nCustomers = calculateCorrelation(preTrialMeasures, 'nCustomers', trial_store)\n\n# Compute magnitude with trial store 77\nmagnitude_nSales = calculateMagnitudeDistance(preTrialMeasures, 'totSales', trial_store)\nmagnitude_nCustomers = calculateMagnitudeDistance(preTrialMeasures, 'nCustomers', trial_store)\n","26cd2383":"# Let's see what they look like\n\ncorr_nSales.head()","2804eb4d":"magnitude_nSales.head()","4f82e3fe":"# Concatenate the scores together for 'nSales'\n\nscore_nSales = pd.concat([corr_nSales, magnitude_nSales['Magnitude']], axis = 1)","77d3fa95":"# Add an additional column which calculates the weighted average\n\ncorr_weight = 0.5\nscore_nSales['scoreNSales'] = corr_weight * score_nSales['Correlation'] + (1 - corr_weight) * score_nSales['Magnitude']\nscore_nSales.head()","f4726a2a":"# Now do the same for 'nCustomers'\n\nscore_nCustomers = pd.concat([corr_nCustomers, magnitude_nCustomers['Magnitude']], axis = 1)\nscore_nCustomers.head()","0092c0a0":"# Again add a new column for weighted average\n\nscore_nCustomers['scoreNCust'] = corr_weight * score_nCustomers['Correlation'] + (1 - corr_weight) * score_nCustomers['Magnitude']\nscore_nCustomers.head()","6a49be66":"# Index both 'score_nSales' and 'score_nCustomers' dataframe\n\nscore_nSales.set_index(['Store1', 'Store2'], inplace = True)\nscore_nCustomers.set_index(['Store1', 'Store2'], inplace = True)","867af489":"# Create a new dataframe 'score_Control' which takes the average of 'scoreNSales' and 'scoreNCust'\n\nscore_Control = pd.concat([score_nSales['scoreNSales'], score_nCustomers['scoreNCust']], axis = 1)\nscore_Control","50de161e":"# Add a new column to 'score_Control' which computes the average of 'scoreNSales' and 'scoreNCust'\n\nscore_Control['finalControlScore'] = 0.5 * (score_Control['scoreNSales'] + score_Control['scoreNCust'])\nscore_Control.head()","39be1dfe":"# Let's see the top 5 stores with highest 'finalControlScore'\n\nscore_Control.sort_values(by = 'finalControlScore', ascending = False).head()\n\n# Comment: store 233 matches trial store 77 the most ","2fb5f3da":"# Now that we have found a control store, let's check visually if the drivers are indeed similar to store 77 before the trial period\n# Set store 233 as 'control_store'\n\ncontrol_store = 233","b69bd4d9":"# Create a new dataframe 'pastSales'\npastSales = preTrialMeasures\n\n# Create a new column within 'pastSales' which categorises store type\nstore_type = []\n\nfor i in pastSales['STORE_NBR']:\n    if i == trial_store:\n        store_type.append('Trial Store')\n    elif i == control_store:\n        store_type.append('Control Store')\n    else:\n        store_type.append('Other Stores')\n\npastSales['store_type'] = store_type\npastSales.head()","893b8ad4":"# Check the unique values under 'store_type' column\n\npastSales['store_type'].unique()","9054a2ef":"pastSales.info() ","ad4c7f4d":"# Currently 'YEARMONTH' is an int64 so we need to turn it into a datetime variable to able to plot\n# Create a new column 'TransactionMonth'\n\npastSales['TransactionMonth'] = pd.to_datetime(pastSales['YEARMONTH'].astype(str), format = '%Y%m')\npastSales.head()","1616f619":"# Now create 'totSales' visualisation for control store, trial store and other stores\n\n# First create relevant dataframes \ncontrolSalesPlot = pastSales.loc[pastSales['store_type'] == 'Control Store', ['TransactionMonth', 'totSales']]\ncontrolSalesPlot.set_index('TransactionMonth', inplace = True)\ncontrolSalesPlot.rename(columns = {'totSales': 'Control Store'}, inplace = True)\ntrialSalesPlot = pastSales.loc[pastSales['store_type'] == 'Trial Store', ['TransactionMonth', 'totSales']]\ntrialSalesPlot.set_index('TransactionMonth', inplace = True)\ntrialSalesPlot.rename(columns = {'totSales': 'Trial Store'}, inplace = True)\notherSalesPlot = pastSales.loc[pastSales['store_type'] == 'Other Stores', ['TransactionMonth', 'totSales']]\notherSalesPlot = pd.DataFrame(otherSalesPlot.groupby('TransactionMonth').totSales.mean())\notherSalesPlot.rename(columns = {'totSales': 'Other Stores'}, inplace = True)\n\n# Concatenate\ncombineSalesPlot = pd.concat([controlSalesPlot, trialSalesPlot, otherSalesPlot], axis = 1)\ncombineSalesPlot","4033225c":"# Plot total sales by month for all 3 types of stores\n\nplt.figure(figsize = (10, 5))\nplt.plot(combineSalesPlot)\nplt.title('Total Sales by Month')\nplt.xlabel('Month of Operation')\nplt.ylabel('Total Sales')\nplt.legend(['Control Store', 'Trial Store', 'Other Stores'], loc = 5)","62dee9cf":"# Do the same for 'nCustomers' \n\n# First create relevant dataframes \ncontrolCustomersPlot = pastSales.loc[pastSales['store_type'] == 'Control Store', ['TransactionMonth', 'nCustomers']]\ncontrolCustomersPlot.set_index('TransactionMonth', inplace = True)\ncontrolCustomersPlot.rename(columns = {'nCustomers': 'Control Store'}, inplace = True)\ntrialCustomersPlot = pastSales.loc[pastSales['store_type'] == 'Trial Store', ['TransactionMonth', 'nCustomers']]\ntrialCustomersPlot.set_index('TransactionMonth', inplace = True)\ntrialCustomersPlot.rename(columns = {'nCustomers': 'Trial Store'}, inplace = True)\notherCustomersPlot = pastSales.loc[pastSales['store_type'] == 'Other Stores', ['TransactionMonth', 'nCustomers']]\notherCustomersPlot = pd.DataFrame(otherCustomersPlot.groupby('TransactionMonth').nCustomers.mean())\notherCustomersPlot.rename(columns = {'nCustomers': 'Other Stores'}, inplace = True)\n\n# Concatenate\ncombineCustomersPlot = pd.concat([controlCustomersPlot, trialCustomersPlot, otherCustomersPlot], axis = 1)\ncombineCustomersPlot","320b6c1d":"# Plot total number of customers for all 3 types of stores\n\nplt.figure(figsize = (10, 5))\nplt.plot(combineCustomersPlot)\nplt.title('Total Number of Customers by Month')\nplt.xlabel('Month of Operation')\nplt.ylabel('Number of Customers')\nplt.legend(['Control Store', 'Trial Store', 'Other Stores'], loc = 5)","978de290":"preTrialMeasures.head()","eff31942":"# First we need to work out a scaling factor to applied to the control store\n# We compute this by dividing sum of 'totSales' for trial store by sum of 'totSales' for control store\n# Let's call this variable 'scalingFactorSales'\n\ntrial_sum = preTrialMeasures.loc[preTrialMeasures['store_type'] == 'Trial Store' , 'totSales'].sum()\ncontrol_sum = preTrialMeasures.loc[preTrialMeasures['store_type'] == 'Control Store', 'totSales'].sum()\nscalingFactorSales = trial_sum \/ control_sum\nscalingFactorSales","ba18e9e2":"# Create a new dataframe 'scaledControlSales'\n# Recall our dataframe before filtering out the trial period is called 'measureOverTime'\n\nmeasureOverTime.head()","c4d195b2":"# Create dataframe and reset index\n\nscaledControlSales = measureOverTime\nscaledControlSales.head()","dc77ff23":"# We only want control store i.e. store 233\n\nscaledControlSales = scaledControlSales.loc[scaledControlSales['STORE_NBR'] == control_store]\nscaledControlSales","2faf7983":"# Create 'controlSales' which applies 'scalingFactorSales' to 'totSales' column\n\nscaledControlSales['controlSales'] = scaledControlSales['totSales'] * scalingFactorSales\nscaledControlSales.head()","3e0312c9":"# Create 'percentageDiff' dataframe\npercentageDiff = scaledControlSales[['YEARMONTH', 'controlSales']]\npercentageDiff.reset_index(drop = True, inplace = True)\n\n# Concatenate with trial store 'totSales'\ntrialSales = measureOverTime.loc[measureOverTime['STORE_NBR'] == trial_store, 'totSales']\ntrialSales.reset_index(drop = True, inplace = True)\npercentageDiff = pd.concat([percentageDiff, trialSales], axis = 1)\npercentageDiff.rename(columns = {'totSales': 'trialSales'}, inplace = True)\n\npercentageDiff","44c4d52b":"# Calculate percentage difference and put it in a new column\n\npercentageDiff['percentageDiff'] = abs(percentageDiff.controlSales - percentageDiff.trialSales) \/ percentageDiff.controlSales\npercentageDiff","775c6ac3":"# Our null hypothesis is such that the trial period is the same as the pre-trial period\n# Let's take the standard deviation based on the scaled percentage difference in the pre-trial period\n\nstdDev = stdev(percentageDiff.loc[percentageDiff['YEARMONTH'] < 201902, 'percentageDiff'])\nstdDev","4d60e358":"# Define the degrees of freedom\n# Since we have 8 pre-trial months, dof = 8 - 1 = 7\n\ndof = 7","30c94dd3":"# We will test with a null hypothesis of there being 0 difference between trial and control stores\n# Create a new column for 'tValue'\n\npercentageDiff['tValue'] = (percentageDiff['percentageDiff'] - 0) \/ stdDev\npercentageDiff.loc[(percentageDiff['YEARMONTH'] > 201901) & (percentageDiff['YEARMONTH'] < 201905), 'tValue']","1e5b5d11":"# Find the 95th percentile of the t distribution with dof = 7\n\nt.isf(0.05, dof)\n\n# Comment: We can see that the t-value is much larger than the 95th percentile value of the t-distribution for March and April","53093e1c":"# Recall our 'scaledControlSales' dataframe\n\nscaledControlSales.head()","c16bf7ba":"# Add a new column 'TransactionMonth' to 'scaledControlSales'\n\nscaledControlSales['TransactionMonth'] = pd.to_datetime(scaledControlSales['YEARMONTH'].astype(str), format = '%Y%m')\nscaledControlSales","7f322dc8":"# Time for some visualisation\n# First we need to create the appropriate dataframe\n# Extract 'controlSales' from 'scaledControlSales' dataframe for control store \n\ncontrolSales = scaledControlSales.loc[:, ['TransactionMonth', 'controlSales']]\ncontrolSales.set_index('TransactionMonth', inplace = True)\ncontrolSales.rename(columns = {'controlSales': 'Control Sales'}, inplace = True)\ncontrolSales","ada195c4":"# Recall 'measureOverTime' dataframe\n\nmeasureOverTime.head()","24a58a80":"# Create a new column 'TransationMonth' under 'measureOverTime' dataframe\n\nmeasureOverTime['TransactionMonth'] = pd.to_datetime(measureOverTime['YEARMONTH'].astype(str), format = '%Y%m')\nmeasureOverTime.head()","59ff2c45":"# Extract 'totSales' for trial store from 'measureOverTime'\n\ntrialSales = measureOverTime.loc[measureOverTime['STORE_NBR'] == trial_store, ['TransactionMonth', 'totSales']]\ntrialSales.set_index('TransactionMonth', inplace = True)\ntrialSales.rename(columns = {'totSales': 'Trial Sales'}, inplace = True)\ntrialSales","649b465c":"# Create two new columns under 'controlSales' which calculates the 5% and 95% confidence interval\n\ncontrolSales['Control 5% Confidence Interval'] = controlSales['Control Sales'] * (1 - stdDev*2)\ncontrolSales['Control 95% Confidence Interval'] = controlSales['Control Sales'] * (1 + stdDev*2)\ncontrolSales","8420d12b":"# Merge the two dataframes together 'controlSales' and 'trialSales'\n\ncombineSales = pd.merge(controlSales, trialSales, left_index = True, right_index = True)\ncombineSales","06a67884":"plt.plot(combineSales)","b87aa096":"# Let's embellish the plot\n\n# Make it bigger\nplt.figure(figsize = (12, 8))\nplt.plot(combineSales)\n\n# Set graph title and axis title\nplt.title('Total Sales by Month')\nplt.xlabel('Month of Operation')\nplt.ylabel('Total Sales')\n\n# Set legend\nplt.legend(['Control Sales', 'Control 5% Confidence Interval', 'Control 95% Confidence Interval', 'Trial Store'], loc = 2)\n\n# Set new y-axis limit\nplt.ylim((0, 400))\n\n# Highlight trial period\nplt.axvspan(*mdates.datestr2num(['2019-02-01', '2019-04-01']), color = 'grey', alpha = 0.2)\n\n# Set grid\nplt.grid()\nplt.show()\n","e680dcb7":"# Now let's move on to 'nCustomers'\n# First, compute scaling factor\n# Let's call this variable 'scalingFactorCustomers'\n\ntrial_customers = preTrialMeasures.loc[preTrialMeasures['store_type'] == 'Trial Store' , 'nCustomers'].sum()\ncontrol_customers = preTrialMeasures.loc[preTrialMeasures['store_type'] == 'Control Store', 'nCustomers'].sum()\nscalingFactorCustomers = trial_customers \/ control_customers\nscalingFactorCustomers","305780f9":"scaledControlCustomers = measureOverTime\nscaledControlCustomers.head()","be777198":"scaledControlCustomers = scaledControlCustomers.loc[scaledControlCustomers['STORE_NBR'] == control_store]\nscaledControlCustomers.head()","31738b57":"scaledControlCustomers['controlCustomers'] = scaledControlCustomers['nCustomers'] * scalingFactorCustomers\nscaledControlCustomers.head()","b2b39ceb":"# Create 'percentageDiff' dataframe\npercentageDiff = scaledControlCustomers[['YEARMONTH', 'controlCustomers']]\npercentageDiff.reset_index(drop = True, inplace = True)\n\n# Concatenate with trial store 'nCustomers'\ntrialCustomers = measureOverTime.loc[measureOverTime['STORE_NBR'] == trial_store, 'nCustomers']\ntrialCustomers.reset_index(drop = True, inplace = True)\npercentageDiff = pd.concat([percentageDiff, trialCustomers], axis = 1)\npercentageDiff.rename(columns = {'nCustomers': 'trialCustomers'}, inplace = True)\n\npercentageDiff","8da14a63":"# Calculate percentage difference and put it in a new column\n\npercentageDiff['percentageDiff'] = abs(percentageDiff.controlCustomers - percentageDiff.trialCustomers) \/ percentageDiff.controlCustomers\npercentageDiff","593643fb":"# Our null hypothesis is such that the trial period is the same as the pre-trial period\n# Let's take the standard deviation based on the scaled percentage difference in the pre-trial period\n\nstdDev = stdev(percentageDiff.loc[percentageDiff['YEARMONTH'] < 201902, 'percentageDiff'])\nstdDev","40a50dc0":"# Define the degrees of freedom\n# Since we have 8 pre-trial months, dof = 8 - 1 = 7\n\ndof = 7","e00f6b9a":"# We will test with a null hypothesis of there being 0 difference between trial and control stores\n# Create a new column for 'tValue'\n\npercentageDiff['tValue'] = (percentageDiff['percentageDiff'] - 0) \/ stdDev\npercentageDiff.loc[(percentageDiff['YEARMONTH'] > 201901) & (percentageDiff['YEARMONTH'] < 201905), 'tValue']","fbc20d42":"# Find the 95th percentile of the t distribution with dof = 7\n\nt.isf(0.05, dof)\n\n# Comment: We can see that the t-value is much larger than the 95th percentile value of the t-distribution for March and April","9b8a86b0":"# Time for some visualisation\n# First we need to create the appropriate dataframe\n# Extract 'controlCustomers' from 'scaledControlCustomers' dataframe for control store \n\ncontrolCustomers = scaledControlCustomers.loc[:, ['TransactionMonth', 'controlCustomers']]\ncontrolCustomers.set_index('TransactionMonth', inplace = True)\ncontrolCustomers.rename(columns = {'controlCustomers': 'Control Customers'}, inplace = True)\ncontrolCustomers","84a9990f":"# Extract 'nCustomers' for trial store from 'measureOverTime'\n\ntrialCustomers = measureOverTime.loc[measureOverTime['STORE_NBR'] == trial_store, ['TransactionMonth', 'nCustomers']]\ntrialCustomers.set_index('TransactionMonth', inplace = True)\ntrialCustomers.rename(columns = {'nCustomers': 'Trial Customers'}, inplace = True)\ntrialCustomers","92b24ded":"# Create two new columns under 'controlCustomers' which calculates the 5% and 95% confidence interval\n\ncontrolCustomers['Control 5% Confidence Interval'] = controlCustomers['Control Customers'] * (1 - stdDev*2)\ncontrolCustomers['Control 95% Confidence Interval'] = controlCustomers['Control Customers'] * (1 + stdDev*2)\ncontrolCustomers","f7db3607":"# Merge the two dataframes together 'controlSales' and 'trialSales'\n\ncombineCustomers = pd.merge(controlCustomers, trialCustomers, left_index = True, right_index = True)\ncombineCustomers","fde57db7":"plt.plot(combineCustomers)","edb0e43c":"# Let's embellish the plot\n\n# Make it bigger\nplt.figure(figsize = (12, 8))\nplt.plot(combineCustomers)\n\n# Set graph title and axis title\nplt.title('Total Number of Customers by Month')\nplt.xlabel('Month of Operation')\nplt.ylabel('Total Number of Customers')\n\n# Set legend\nplt.legend(['Control Store', 'Control 5% Confidence Interval', 'Control 95% Confidence Interval', 'Trial Store'], loc = 6)\n\n# Set new y-axis limit\nplt.ylim((0, 60))\n\n# Highlight trial period\nplt.axvspan(*mdates.datestr2num(['2019-02-01', '2019-04-01']), color = 'grey', alpha = 0.2)\n\n# Set grid\nplt.grid()\nplt.show()\n","64507df8":"# Compute correlation with trial store 86\ntrial_store = 86\ncorr_nSales = calculateCorrelation(preTrialMeasures, 'totSales', trial_store)\ncorr_nCustomers = calculateCorrelation(preTrialMeasures, 'nCustomers', trial_store)\n\n# Compute magnitude with trial store 86\nmagnitude_nSales = calculateMagnitudeDistance(preTrialMeasures, 'totSales', trial_store)\nmagnitude_nCustomers = calculateMagnitudeDistance(preTrialMeasures, 'nCustomers', trial_store)","c6ab806a":"# Concatenate the scores together for 'nSales'\n\nscore_nSales = pd.concat([corr_nSales, magnitude_nSales['Magnitude']], axis = 1)","6b0c9395":"# Add an additional column which calculates the weighted average\n\ncorr_weight = 0.5\nscore_nSales['scoreNSales'] = corr_weight * score_nSales['Correlation'] + (1 - corr_weight) * score_nSales['Magnitude']\nscore_nSales.head()","76f86e37":"# Now do the same for 'nCustomers'\n\nscore_nCustomers = pd.concat([corr_nCustomers, magnitude_nCustomers['Magnitude']], axis = 1)\nscore_nCustomers.head()","0be69dfd":"# Again add a new column for weighted average\n\nscore_nCustomers['scoreNCust'] = corr_weight * score_nCustomers['Correlation'] + (1 - corr_weight) * score_nCustomers['Magnitude']\nscore_nCustomers.head()","dc32e347":"# Index both 'score_nSales' and 'score_nCustomers' dataframe\n\nscore_nSales.set_index(['Store1', 'Store2'], inplace = True)\nscore_nCustomers.set_index(['Store1', 'Store2'], inplace = True)","0dfd0d61":"# Create a new dataframe 'score_Control' which takes the average of 'scoreNSales' and 'scoreNCust'\n\nscore_Control = pd.concat([score_nSales['scoreNSales'], score_nCustomers['scoreNCust']], axis = 1)\nscore_Control","56d37854":"# Add a new column to 'score_Control' which computes the average of 'scoreNSales' and 'scoreNCust'\n\nscore_Control['finalControlScore'] = 0.5 * (score_Control['scoreNSales'] + score_Control['scoreNCust'])\nscore_Control.head()","4c2e7246":"# Let's see the top 5 stores with highest 'finalControlScore'\n\nscore_Control.sort_values(by = 'finalControlScore', ascending = False).head()\n\n# Comment: store 155 matches trial store 86 the most","8ec57e43":"# Set control store 135 as 'control_store'\n\ncontrol_store = 155","7aeed0b8":"# Create a new dataframe 'pastSales'\npastSales = preTrialMeasures\n\n# Create a new column within 'pastSales' which categorises store type\nstore_type = []\n\nfor i in pastSales['STORE_NBR']:\n    if i == trial_store:\n        store_type.append('Trial Store')\n    elif i == control_store:\n        store_type.append('Control Store')\n    else:\n        store_type.append('Other Stores')\n\npastSales['store_type'] = store_type\npastSales.head()","0006d6ed":"# Currently 'YEARMONTH' is an int64 so we need to turn it into a datetime variable to able to plot\n# Create a new column 'TransactionMonth'\n\npastSales['TransactionMonth'] = pd.to_datetime(pastSales['YEARMONTH'].astype(str), format = '%Y%m')\npastSales.head()","7b34886e":"# Now create 'totSales' visualisation for control store, trial store and other stores\n\n# First create relevant dataframes \ncontrolSalesPlot = pastSales.loc[pastSales['store_type'] == 'Control Store', ['TransactionMonth', 'totSales']]\ncontrolSalesPlot.set_index('TransactionMonth', inplace = True)\ncontrolSalesPlot.rename(columns = {'totSales': 'Control Store'}, inplace = True)\ntrialSalesPlot = pastSales.loc[pastSales['store_type'] == 'Trial Store', ['TransactionMonth', 'totSales']]\ntrialSalesPlot.set_index('TransactionMonth', inplace = True)\ntrialSalesPlot.rename(columns = {'totSales': 'Trial Store'}, inplace = True)\notherSalesPlot = pastSales.loc[pastSales['store_type'] == 'Other Stores', ['TransactionMonth', 'totSales']]\notherSalesPlot = pd.DataFrame(otherSalesPlot.groupby('TransactionMonth').totSales.mean())\notherSalesPlot.rename(columns = {'totSales': 'Other Stores'}, inplace = True)\n\n# Concatenate\ncombineSalesPlot = pd.concat([controlSalesPlot, trialSalesPlot, otherSalesPlot], axis = 1)\ncombineSalesPlot","5d886685":"# Plot total sales by month for all 3 types of stores\n\nplt.figure(figsize = (10, 5))\nplt.plot(combineSalesPlot)\nplt.title('Total Sales by Month')\nplt.xlabel('Month of Operation')\nplt.ylabel('Total Sales')\nplt.legend(['Control Store', 'Trial Store', 'Other Stores'], loc = 5)","8d4d53f6":"# Do the same for 'nCustomers' \n\n# First create relevant dataframes \ncontrolCustomersPlot = pastSales.loc[pastSales['store_type'] == 'Control Store', ['TransactionMonth', 'nCustomers']]\ncontrolCustomersPlot.set_index('TransactionMonth', inplace = True)\ncontrolCustomersPlot.rename(columns = {'nCustomers': 'Control Store'}, inplace = True)\ntrialCustomersPlot = pastSales.loc[pastSales['store_type'] == 'Trial Store', ['TransactionMonth', 'nCustomers']]\ntrialCustomersPlot.set_index('TransactionMonth', inplace = True)\ntrialCustomersPlot.rename(columns = {'nCustomers': 'Trial Store'}, inplace = True)\notherCustomersPlot = pastSales.loc[pastSales['store_type'] == 'Other Stores', ['TransactionMonth', 'nCustomers']]\notherCustomersPlot = pd.DataFrame(otherCustomersPlot.groupby('TransactionMonth').nCustomers.mean())\notherCustomersPlot.rename(columns = {'nCustomers': 'Other Stores'}, inplace = True)\n\n# Concatenate\ncombineCustomersPlot = pd.concat([controlCustomersPlot, trialCustomersPlot, otherCustomersPlot], axis = 1)\ncombineCustomersPlot","0746afcd":"# Plot total number of customers for all 3 types of stores\n\nplt.figure(figsize = (10, 5))\nplt.plot(combineCustomersPlot)\nplt.title('Total Number of Customers by Month')\nplt.xlabel('Month of Operation')\nplt.ylabel('Number of Customers')\nplt.legend(['Control Store', 'Trial Store', 'Other Stores'], loc = 5)","0cde9318":"# First we need to work out a scaling factor to applied to the control store\n# We compute this by dividing sum of 'totSales' for trial store by sum of 'totSales' for control store\n# Let's call this variable 'scalingFactorSales'\n\ntrial_sum = preTrialMeasures.loc[preTrialMeasures['store_type'] == 'Trial Store' , 'totSales'].sum()\ncontrol_sum = preTrialMeasures.loc[preTrialMeasures['store_type'] == 'Control Store', 'totSales'].sum()\nscalingFactorSales = trial_sum \/ control_sum\nscalingFactorSales","737a76bd":"# Create a new dataframe 'scaledControlSales'\n# Recall our dataframe before filtering out the trial period is called 'measureOverTime'\n\nmeasureOverTime.head()","cf79865b":"# Create dataframe and reset index\n\nscaledControlSales = measureOverTime\nscaledControlSales.head()","3747ee54":"# We only want control store i.e. store 155\n\nscaledControlSales = scaledControlSales.loc[scaledControlSales['STORE_NBR'] == control_store]\nscaledControlSales","7c5768b2":"# Create 'controlSales' which applies 'scalingFactorSales' to 'totSales' column\n\nscaledControlSales['controlSales'] = scaledControlSales['totSales'] * scalingFactorSales\nscaledControlSales.head()","edd234b6":"# Create 'percentageDiff' dataframe\npercentageDiff = scaledControlSales[['YEARMONTH', 'controlSales']]\npercentageDiff.reset_index(drop = True, inplace = True)\n\n# Concatenate with trial store 'totSales'\ntrialSales = measureOverTime.loc[measureOverTime['STORE_NBR'] == trial_store, 'totSales']\ntrialSales.reset_index(drop = True, inplace = True)\npercentageDiff = pd.concat([percentageDiff, trialSales], axis = 1)\npercentageDiff.rename(columns = {'totSales': 'trialSales'}, inplace = True)","3ba6cede":"# Calculate percentage difference and put it in a new column\n\npercentageDiff['percentageDiff'] = abs(percentageDiff.controlSales - percentageDiff.trialSales) \/ percentageDiff.controlSales\npercentageDiff","e0a6c316":"# Our null hypothesis is such that the trial period is the same as the pre-trial period\n# Let's take the standard deviation based on the scaled percentage difference in the pre-trial period\n\nstdDev = stdev(percentageDiff.loc[percentageDiff['YEARMONTH'] < 201902, 'percentageDiff'])\nstdDev","4d44e1c1":"# Recall our 'scaledControlSales' dataframe\n\nscaledControlSales.head()","56baca1f":"# Add a new column 'TransactionMonth' to 'scaledControlSales'\n\nscaledControlSales['TransactionMonth'] = pd.to_datetime(scaledControlSales['YEARMONTH'].astype(str), format = '%Y%m')\nscaledControlSales","073d4d3e":"# Time for some visualisation\n# First we need to create the appropriate dataframe\n# Extract 'controlSales' from 'scaledControlSales' dataframe for control store \n\ncontrolSales = scaledControlSales.loc[:, ['TransactionMonth', 'controlSales']]\ncontrolSales.set_index('TransactionMonth', inplace = True)\ncontrolSales.rename(columns = {'controlSales': 'Control Sales'}, inplace = True)","943f9998":"# Create a new column 'TransationMonth' under 'measureOverTime' dataframe\n\nmeasureOverTime['TransactionMonth'] = pd.to_datetime(measureOverTime['YEARMONTH'].astype(str), format = '%Y%m')\nmeasureOverTime.head()","addfac99":"# Extract 'totSales' for trial store from 'measureOverTime'\n\ntrialSales = measureOverTime.loc[measureOverTime['STORE_NBR'] == trial_store, ['TransactionMonth', 'totSales']]\ntrialSales.set_index('TransactionMonth', inplace = True)\ntrialSales.rename(columns = {'totSales': 'Trial Sales'}, inplace = True)\ntrialSales","4e4764ce":"# Create two new columns under 'controlSales' which calculates the 5% and 95% confidence interval\n\ncontrolSales['Control 5% Confidence Interval'] = controlSales['Control Sales'] * (1 - stdDev*2)\ncontrolSales['Control 95% Confidence Interval'] = controlSales['Control Sales'] * (1 + stdDev*2)\ncontrolSales","223027ce":"# Merge the two dataframes together 'controlSales' and 'trialSales'\n\ncombineSales = pd.merge(controlSales, trialSales, left_index = True, right_index = True)\ncombineSales","29bb1e65":"plt.plot(combineSales)","a797a55f":"# Let's embellish the plot\n\n# Make it bigger\nplt.figure(figsize = (12, 8))\nplt.plot(combineSales)\n\n# Set graph title and axis title\nplt.title('Total Sales by Month')\nplt.xlabel('Month of Operation')\nplt.ylabel('Total Sales')\n\n# Set legend\nplt.legend(['Control Sales', 'Control 5% Confidence Interval', 'Control 95% Confidence Interval', 'Trial Store'], loc = 2)\n\n# Set new y-axis limit\nplt.ylim((0, 1400))\n\n# Highlight trial period\nplt.axvspan(*mdates.datestr2num(['2019-02-01', '2019-04-01']), color = 'grey', alpha = 0.2)\n\n# Set grid\nplt.grid()\nplt.show()\n","7ffb4818":"# Now let's move on to 'nCustomers'\n# First, compute scaling factor\n# Let's call this variable 'scalingFactorCustomers'\n\ntrial_customers = preTrialMeasures.loc[preTrialMeasures['store_type'] == 'Trial Store' , 'nCustomers'].sum()\ncontrol_customers = preTrialMeasures.loc[preTrialMeasures['store_type'] == 'Control Store', 'nCustomers'].sum()\nscalingFactorCustomers = trial_customers \/ control_customers\nscalingFactorCustomers","1edfd00b":"scaledControlCustomers = measureOverTime\nscaledControlCustomers.head()","f63a0d58":"scaledControlCustomers = scaledControlCustomers.loc[scaledControlCustomers['STORE_NBR'] == control_store]\nscaledControlCustomers.head()","fc62d16f":"scaledControlCustomers['controlCustomers'] = scaledControlCustomers['nCustomers'] * scalingFactorCustomers\nscaledControlCustomers.head()","92f15ade":"# Create 'percentageDiff' dataframe\npercentageDiff = scaledControlCustomers[['YEARMONTH', 'controlCustomers']]\npercentageDiff.reset_index(drop = True, inplace = True)\n\n# Concatenate with trial store 'nCustomers'\ntrialCustomers = measureOverTime.loc[measureOverTime['STORE_NBR'] == trial_store, 'nCustomers']\ntrialCustomers.reset_index(drop = True, inplace = True)\npercentageDiff = pd.concat([percentageDiff, trialCustomers], axis = 1)\npercentageDiff.rename(columns = {'nCustomers': 'trialCustomers'}, inplace = True)\n\npercentageDiff","a26d82ab":"# Calculate percentage difference and put it in a new column\n\npercentageDiff['percentageDiff'] = abs(percentageDiff.controlCustomers - percentageDiff.trialCustomers) \/ percentageDiff.controlCustomers\npercentageDiff","918ba3ca":"# Our null hypothesis is such that the trial period is the same as the pre-trial period\n# Let's take the standard deviation based on the scaled percentage difference in the pre-trial period\n\nstdDev = stdev(percentageDiff.loc[percentageDiff['YEARMONTH'] < 201902, 'percentageDiff'])\nstdDev","a233eef0":"# Define the degrees of freedom\n# Since we have 8 pre-trial months, dof = 8 - 1 = 7\n\ndof = 7","3744e592":"# We will test with a null hypothesis of there being 0 difference between trial and control stores\n# Create a new column for 'tValue'\n\npercentageDiff['tValue'] = (percentageDiff['percentageDiff'] - 0) \/ stdDev\npercentageDiff.loc[(percentageDiff['YEARMONTH'] > 201901) & (percentageDiff['YEARMONTH'] < 201905), 'tValue']","2cce3c8a":"# Find the 95th percentile of the t distribution with dof = 7\n\nt.isf(0.05, dof)\n\n# Comment: We can see that the t-value is larger than the 95th percentile value of the t-distribution ","ab041f1f":"# Time for some visualisation\n# First we need to create the appropriate dataframe\n# Extract 'controlCustomers' from 'scaledControlCustomers' dataframe for control store \n\ncontrolCustomers = scaledControlCustomers.loc[:, ['TransactionMonth', 'controlCustomers']]\ncontrolCustomers.set_index('TransactionMonth', inplace = True)\ncontrolCustomers.rename(columns = {'controlCustomers': 'Control Customers'}, inplace = True)\ncontrolCustomers","98054236":"# Extract 'nCustomers' for trial store from 'measureOverTime'\n\ntrialCustomers = measureOverTime.loc[measureOverTime['STORE_NBR'] == trial_store, ['TransactionMonth', 'nCustomers']]\ntrialCustomers.set_index('TransactionMonth', inplace = True)\ntrialCustomers.rename(columns = {'nCustomers': 'Trial Customers'}, inplace = True)\ntrialCustomers","ca40aa15":"# Create two new columns under 'controlCustomers' which calculates the 5% and 95% confidence interval\n\ncontrolCustomers['Control 5% Confidence Interval'] = controlCustomers['Control Customers'] * (1 - stdDev*2)\ncontrolCustomers['Control 95% Confidence Interval'] = controlCustomers['Control Customers'] * (1 + stdDev*2)\ncontrolCustomers","db540baf":"plt.plot(combineCustomers)","304b5765":"# Let's embellish the plot\n\n# Make it bigger\nplt.figure(figsize = (12, 8))\nplt.plot(combineCustomers)\n\n# Set graph title and axis title\nplt.title('Total Number of Customers by Month')\nplt.xlabel('Month of Operation')\nplt.ylabel('Total Number of Customers')\n\n# Set legend\nplt.legend(['Control Store', 'Control 5% Confidence Interval', 'Control 95% Confidence Interval', 'Trial Store'], loc = 2)\n\n# Set new y-axis limit\nplt.ylim((0, 130))\n\n# Highlight trial period\nplt.axvspan(*mdates.datestr2num(['2019-02-01', '2019-04-01']), color = 'grey', alpha = 0.2)\n\n# Set grid\nplt.grid()\nplt.show()\n","0b081a8e":"# Now let's use those two functions to find the control store\n\n# Compute correlation with trial store 88\ntrial_store = 88\ncorr_nSales = calculateCorrelation(preTrialMeasures, 'totSales', trial_store)\ncorr_nCustomers = calculateCorrelation(preTrialMeasures, 'nCustomers', trial_store)\n\n# Compute magnitude with trial store 88\nmagnitude_nSales = calculateMagnitudeDistance(preTrialMeasures, 'totSales', trial_store)\nmagnitude_nCustomers = calculateMagnitudeDistance(preTrialMeasures, 'nCustomers', trial_store)\n","7220d043":"# Let's see what they look like\n\ncorr_nSales.head()","eb7f0437":"magnitude_nSales","6a66fee9":"# Concatenate the scores together for 'nSales'\n\nscore_nSales = pd.concat([corr_nSales, magnitude_nSales['Magnitude']], axis = 1)","71abb386":"# Add an additional column which calculates the weighted average\n\ncorr_weight = 0.5\nscore_nSales['scoreNSales'] = corr_weight * score_nSales['Correlation'] + (1 - corr_weight) * score_nSales['Magnitude']\nscore_nSales.head()","3e90ab9a":"# Now do the same for 'nCustomers'\n\nscore_nCustomers = pd.concat([corr_nCustomers, magnitude_nCustomers['Magnitude']], axis = 1)\nscore_nCustomers.head()","d5bafbad":"# Again add a new column for weighted average\n\nscore_nCustomers['scoreNCust'] = corr_weight * score_nCustomers['Correlation'] + (1 - corr_weight) * score_nCustomers['Magnitude']\nscore_nCustomers.head()","6a421745":"# Index both 'score_nSales' and 'score_nCustomers' dataframe\n\nscore_nSales.set_index(['Store1', 'Store2'], inplace = True)\nscore_nCustomers.set_index(['Store1', 'Store2'], inplace = True)","e46db9ed":"# Create a new dataframe 'score_Control' which takes the average of 'scoreNSales' and 'scoreNCust'\n\nscore_Control = pd.concat([score_nSales['scoreNSales'], score_nCustomers['scoreNCust']], axis = 1)\nscore_Control","1f41f538":"# Add a new column to 'score_Control' which computes the average of 'scoreNSales' and 'scoreNCust'\n\nscore_Control['finalControlScore'] = 0.5 * (score_Control['scoreNSales'] + score_Control['scoreNCust'])\nscore_Control.head()","b2155122":"# Let's see the top 5 stores with highest 'finalControlScore'\n\nscore_Control.sort_values(by = 'finalControlScore', ascending = False).head()","ae9180f1":"# After doing some visualisations, found that stores 178, 14 and 134 do not match trial store so set store 237 as control store\n\ncontrol_store = 237","add877f5":"# Create a new dataframe 'pastSales'\npastSales = preTrialMeasures\n\n# Create a new column within 'pastSales' which categorises store type\nstore_type = []\n\nfor i in pastSales['STORE_NBR']:\n    if i == trial_store:\n        store_type.append('Trial Store')\n    elif i == control_store:\n        store_type.append('Control Store')\n    else:\n        store_type.append('Other Stores')\n\npastSales['store_type'] = store_type\npastSales.head()","113b5f31":"# Currently 'YEARMONTH' is an int64 so we need to turn it into a datetime variable to able to plot\n# Create a new column 'TransactionMonth'\n\npastSales['TransactionMonth'] = pd.to_datetime(pastSales['YEARMONTH'].astype(str), format = '%Y%m')\npastSales.head()","c23f965b":"# Now create 'totSales' visualisation for control store, trial store and other stores\n\n# First create relevant dataframes \ncontrolSalesPlot = pastSales.loc[pastSales['store_type'] == 'Control Store', ['TransactionMonth', 'totSales']]\ncontrolSalesPlot.set_index('TransactionMonth', inplace = True)\ncontrolSalesPlot.rename(columns = {'totSales': 'Control Store'}, inplace = True)\ntrialSalesPlot = pastSales.loc[pastSales['store_type'] == 'Trial Store', ['TransactionMonth', 'totSales']]\ntrialSalesPlot.set_index('TransactionMonth', inplace = True)\ntrialSalesPlot.rename(columns = {'totSales': 'Trial Store'}, inplace = True)\notherSalesPlot = pastSales.loc[pastSales['store_type'] == 'Other Stores', ['TransactionMonth', 'totSales']]\notherSalesPlot = pd.DataFrame(otherSalesPlot.groupby('TransactionMonth').totSales.mean())\notherSalesPlot.rename(columns = {'totSales': 'Other Stores'}, inplace = True)\n\n# Concatenate\ncombineSalesPlot = pd.concat([controlSalesPlot, trialSalesPlot, otherSalesPlot], axis = 1)\ncombineSalesPlot","0d5e6886":"# Plot total sales by month for all 3 types of stores\n\nplt.figure(figsize = (10, 5))\nplt.plot(combineSalesPlot)\nplt.title('Total Sales by Month')\nplt.xlabel('Month of Operation')\nplt.ylabel('Total Sales')\nplt.legend(['Control Store', 'Trial Store', 'Other Stores'], loc = 5)","2457bdb0":"# Do the same for 'nCustomers' \n\n# First create relevant dataframes \ncontrolCustomersPlot = pastSales.loc[pastSales['store_type'] == 'Control Store', ['TransactionMonth', 'nCustomers']]\ncontrolCustomersPlot.set_index('TransactionMonth', inplace = True)\ncontrolCustomersPlot.rename(columns = {'nCustomers': 'Control Store'}, inplace = True)\ntrialCustomersPlot = pastSales.loc[pastSales['store_type'] == 'Trial Store', ['TransactionMonth', 'nCustomers']]\ntrialCustomersPlot.set_index('TransactionMonth', inplace = True)\ntrialCustomersPlot.rename(columns = {'nCustomers': 'Trial Store'}, inplace = True)\notherCustomersPlot = pastSales.loc[pastSales['store_type'] == 'Other Stores', ['TransactionMonth', 'nCustomers']]\notherCustomersPlot = pd.DataFrame(otherCustomersPlot.groupby('TransactionMonth').nCustomers.mean())\notherCustomersPlot.rename(columns = {'nCustomers': 'Other Stores'}, inplace = True)\n\n# Concatenate\ncombineCustomersPlot = pd.concat([controlCustomersPlot, trialCustomersPlot, otherCustomersPlot], axis = 1)\ncombineCustomersPlot","1cb342d6":"# Plot total number of customers for all 3 types of stores\n\nplt.figure(figsize = (10, 5))\nplt.plot(combineCustomersPlot)\nplt.title('Total Number of Customers by Month')\nplt.xlabel('Month of Operation')\nplt.ylabel('Number of Customers')\nplt.legend(['Control Store', 'Trial Store', 'Other Stores'], loc = 5)","5f48f059":"# First we need to work out a scaling factor to applied to the control store\n# We compute this by dividing sum of 'totSales' for trial store by sum of 'totSales' for control store\n# Let's call this variable 'scalingFactorSales'\n\ntrial_sum = preTrialMeasures.loc[preTrialMeasures['store_type'] == 'Trial Store' , 'totSales'].sum()\ncontrol_sum = preTrialMeasures.loc[preTrialMeasures['store_type'] == 'Control Store', 'totSales'].sum()\nscalingFactorSales = trial_sum \/ control_sum\nscalingFactorSales","24fdaa3f":"# Create a new dataframe 'scaledControlSales'\n# Recall our dataframe before filtering out the trial period is called 'measureOverTime'\n\nmeasureOverTime.head()","e816fd43":"# Create dataframe and reset index\n\nscaledControlSales = measureOverTime\nscaledControlSales.head()","4030815b":"# We only want control store i.e. store 237\n\nscaledControlSales = scaledControlSales.loc[scaledControlSales['STORE_NBR'] == control_store]\nscaledControlSales","09eefd55":"# Create 'controlSales' which applies 'scalingFactorSales' to 'totSales' column\n\nscaledControlSales['controlSales'] = scaledControlSales['totSales'] * scalingFactorSales\nscaledControlSales.head()","f82f9d7d":"# Create 'percentageDiff' dataframe\npercentageDiff = scaledControlSales[['YEARMONTH', 'controlSales']]\npercentageDiff.reset_index(drop = True, inplace = True)\n\n# Concatenate with trial store 'totSales'\ntrialSales = measureOverTime.loc[measureOverTime['STORE_NBR'] == trial_store, 'totSales']\ntrialSales.reset_index(drop = True, inplace = True)\npercentageDiff = pd.concat([percentageDiff, trialSales], axis = 1)\npercentageDiff.rename(columns = {'totSales': 'trialSales'}, inplace = True)\n\npercentageDiff","332d9a30":"# Calculate percentage difference and put it in a new column\n\npercentageDiff['percentageDiff'] = abs(percentageDiff.controlSales - percentageDiff.trialSales) \/ percentageDiff.controlSales\npercentageDiff","9d7c42bf":"# Our null hypothesis is such that the trial period is the same as the pre-trial period\n# Let's take the standard deviation based on the scaled percentage difference in the pre-trial period\n\nstdDev = stdev(percentageDiff.loc[percentageDiff['YEARMONTH'] < 201902, 'percentageDiff'])\nstdDev","7b4fa004":"# Define the degrees of freedom\n# Since we have 8 pre-trial months, dof = 8 - 1 = 7\n\ndof = 7","0a6d6c0f":"# We will test with a null hypothesis of there being 0 difference between trial and control stores\n# Create a new column for 'tValue'\n\npercentageDiff['tValue'] = (percentageDiff['percentageDiff'] - 0) \/ stdDev\npercentageDiff.loc[(percentageDiff['YEARMONTH'] > 201901) & (percentageDiff['YEARMONTH'] < 201905), 'tValue']","6603d831":"# Find the 95th percentile of the t distribution with dof = 7\n\nt.isf(0.05, dof)","9172a224":"# Recall our 'scaledControlSales' dataframe\n\nscaledControlSales.head()","1a95da5a":"# Add a new column 'TransactionMonth' to 'scaledControlSales'\n\nscaledControlSales['TransactionMonth'] = pd.to_datetime(scaledControlSales['YEARMONTH'].astype(str), format = '%Y%m')\nscaledControlSales","cd7e473e":"# Time for some visualisation\n# First we need to create the appropriate dataframe\n# Extract 'controlSales' from 'scaledControlSales' dataframe for control store \n\ncontrolSales = scaledControlSales.loc[:, ['TransactionMonth', 'controlSales']]\ncontrolSales.set_index('TransactionMonth', inplace = True)\ncontrolSales.rename(columns = {'controlSales': 'Control Sales'}, inplace = True)\ncontrolSales","61df1c45":"# Recall 'measureOverTime' dataframe\n\nmeasureOverTime.head()","970ece7c":"# Create a new column 'TransationMonth' under 'measureOverTime' dataframe\n\nmeasureOverTime['TransactionMonth'] = pd.to_datetime(measureOverTime['YEARMONTH'].astype(str), format = '%Y%m')\nmeasureOverTime.head()","469500b6":"# Extract 'totSales' for trial store from 'measureOverTime'\n\ntrialSales = measureOverTime.loc[measureOverTime['STORE_NBR'] == trial_store, ['TransactionMonth', 'totSales']]\ntrialSales.set_index('TransactionMonth', inplace = True)\ntrialSales.rename(columns = {'totSales': 'Trial Sales'}, inplace = True)\ntrialSales","f3d3ba3e":"# Create two new columns under 'controlSales' which calculates the 5% and 95% confidence interval\n\ncontrolSales['Control 5% Confidence Interval'] = controlSales['Control Sales'] * (1 - stdDev*2)\ncontrolSales['Control 95% Confidence Interval'] = controlSales['Control Sales'] * (1 + stdDev*2)\ncontrolSales","bd53b029":"# Merge the two dataframes together 'controlSales' and 'trialSales'\n\ncombineSales = pd.merge(controlSales, trialSales, left_index = True, right_index = True)\ncombineSales","e64df0bf":"plt.plot(combineSales)","2004337f":"# Let's embellish the plot\n\n# Make it bigger\nplt.figure(figsize = (12, 8))\nplt.plot(combineSales)\n\n# Set graph title and axis title\nplt.title('Total Sales by Month')\nplt.xlabel('Month of Operation')\nplt.ylabel('Total Sales')\n\n# Set legend\nplt.legend(['Control Sales', 'Control 5% Confidence Interval', 'Control 95% Confidence Interval', 'Trial Store'], loc = 2)\n\n# Set new y-axis limit\nplt.ylim((0, 2000))\n\n# Highlight trial period\nplt.axvspan(*mdates.datestr2num(['2019-02-01', '2019-04-01']), color = 'grey', alpha = 0.2)\n\n# Set grid\nplt.grid()\nplt.show()\n","b33807a6":"# Now let's move on to 'nCustomers'\n# First, compute scaling factor\n# Let's call this variable 'scalingFactorCustomers'\n\ntrial_customers = preTrialMeasures.loc[preTrialMeasures['store_type'] == 'Trial Store' , 'nCustomers'].sum()\ncontrol_customers = preTrialMeasures.loc[preTrialMeasures['store_type'] == 'Control Store', 'nCustomers'].sum()\nscalingFactorCustomers = trial_customers \/ control_customers\nscalingFactorCustomers","600788c9":"scaledControlCustomers = measureOverTime\nscaledControlCustomers.head()","d3015bfc":"scaledControlCustomers = scaledControlCustomers.loc[scaledControlCustomers['STORE_NBR'] == control_store]\nscaledControlCustomers.head()","efde0447":"scaledControlCustomers['controlCustomers'] = scaledControlCustomers['nCustomers'] * scalingFactorCustomers\nscaledControlCustomers.head()","933fd79a":"# Create 'percentageDiff' dataframe\npercentageDiff = scaledControlCustomers[['YEARMONTH', 'controlCustomers']]\npercentageDiff.reset_index(drop = True, inplace = True)\n\n# Concatenate with trial store 'nCustomers'\ntrialCustomers = measureOverTime.loc[measureOverTime['STORE_NBR'] == trial_store, 'nCustomers']\ntrialCustomers.reset_index(drop = True, inplace = True)\npercentageDiff = pd.concat([percentageDiff, trialCustomers], axis = 1)\npercentageDiff.rename(columns = {'nCustomers': 'trialCustomers'}, inplace = True)\n\npercentageDiff","13a870d3":"# Calculate percentage difference and put it in a new column\n\npercentageDiff['percentageDiff'] = abs(percentageDiff.controlCustomers - percentageDiff.trialCustomers) \/ percentageDiff.controlCustomers\npercentageDiff","e88f2887":"# Our null hypothesis is such that the trial period is the same as the pre-trial period\n# Let's take the standard deviation based on the scaled percentage difference in the pre-trial period\n\nstdDev = stdev(percentageDiff.loc[percentageDiff['YEARMONTH'] < 201902, 'percentageDiff'])\nstdDev","5cf070a9":"# Define the degrees of freedom\n# Since we have 8 pre-trial months, dof = 8 - 1 = 7\n\ndof = 7","b7eb4797":"# We will test with a null hypothesis of there being 0 difference between trial and control stores\n# Create a new column for 'tValue'\n\npercentageDiff['tValue'] = (percentageDiff['percentageDiff'] - 0) \/ stdDev\npercentageDiff.loc[(percentageDiff['YEARMONTH'] > 201901) & (percentageDiff['YEARMONTH'] < 201905), 'tValue']","235c2bd1":"# Find the 95th percentile of the t distribution with dof = 7\n\nt.isf(0.05, dof)\n\n# Comment: We can see that the t-value is larger than the 95th percentile value of the t-distribution ","84da6369":"# Time for some visualisation\n# First we need to create the appropriate dataframe\n# Extract 'controlCustomers' from 'scaledControlCustomers' dataframe for control store \n\ncontrolCustomers = scaledControlCustomers.loc[:, ['TransactionMonth', 'controlCustomers']]\ncontrolCustomers.set_index('TransactionMonth', inplace = True)\ncontrolCustomers.rename(columns = {'controlCustomers': 'Control Customers'}, inplace = True)\ncontrolCustomers","5934810f":"# Extract 'nCustomers' for trial store from 'measureOverTime'\n\ntrialCustomers = measureOverTime.loc[measureOverTime['STORE_NBR'] == trial_store, ['TransactionMonth', 'nCustomers']]\ntrialCustomers.set_index('TransactionMonth', inplace = True)\ntrialCustomers.rename(columns = {'nCustomers': 'Trial Customers'}, inplace = True)\ntrialCustomers","3f151337":"# Create two new columns under 'controlCustomers' which calculates the 5% and 95% confidence interval\n\ncontrolCustomers['Control 5% Confidence Interval'] = controlCustomers['Control Customers'] * (1 - stdDev*2)\ncontrolCustomers['Control 95% Confidence Interval'] = controlCustomers['Control Customers'] * (1 + stdDev*2)\ncontrolCustomers","d112ae98":"# Merge the two dataframes together 'controlSales' and 'trialSales'\n\ncombineCustomers = pd.merge(controlCustomers, trialCustomers, left_index = True, right_index = True)\ncombineCustomers","f03813cf":"plt.plot(combineCustomers)","1b5f0746":"# Let's embellish the plot\n\n# Make it bigger\nplt.figure(figsize = (12, 8))\nplt.plot(combineCustomers)\n\n# Set graph title and axis title\nplt.title('Total Number of Customers by Month')\nplt.xlabel('Month of Operation')\nplt.ylabel('Total Number of Customers')\n\n# Set legend\nplt.legend(['Control Store', 'Control 5% Confidence Interval', 'Control 95% Confidence Interval', 'Trial Store'], loc = 2)\n\n# Set new y-axis limit\nplt.ylim((0, 160))\n\n# Highlight trial period\nplt.axvspan(*mdates.datestr2num(['2019-02-01', '2019-04-01']), color = 'grey', alpha = 0.2)\n\n# Set grid\nplt.grid()\nplt.show()\n","35ab4168":"# Libraries","2af37356":"The results show that the trial in store 88 is significantly different to its control store in the trial period. The trial store performance lies outside the 5% to 95% confidence interval of the control store in two of the three trial months.","52ea94e1":"# Selecting control store for trial 86","9c9bfd11":"Now we need to repeat the process of finding the control store and assessing the impact of the trial for the two remaining trial stores, 86 and 88.","43a19248":"# Select control stores\n\nThe client has selected stores 77, 86 and 88 as trial stores and want control stores to be established stores that are operational for the entire observation period.\n\nWe would want to match trial stores to control stores that are similar to the trial store prior to the trial period of Feb 2019 in terms of:\n\n- Monthly overall sales revenue\n- Monthly number of customers\n- Monthly number of transactions per customer\n\nLet's first create the metrics of interest and filter out stores that are present throughout the pre-trial period.","2644c876":"# Assessment of trial for trial strore 77\n\nThe trial period goes from the start of February 2019 to end of April 2019. We now want to see if there has been an uplift in overall chip sales. ","d415ceb1":"It looks like the number of customers is significantly higher in all of the three months. This seems to suggest that the trial had a significant impact on increasing the number of customers in trial store 86 but as we saw, sales were not significantly higher. We should check with the Category Manager if there were special deals in the trial store that were may have resulted in lower prices, impacting the results.","6691a9f4":"Total number of customers in the trial period for the trial store is significantly higher than the control store for two out of three months, which indicates a positive trial effect.","241cf462":"# Selecting control store for trial store 77","72f64a42":"# Load data","359f3297":"# Selecting control store for trial store 88","4f40197e":"For each month and store, calculate:\n\n1. Total sales\n2. Number of customers\n3. Transaction per customer\n4. Chips per transaction\n5. Average price per unit\n\nCreate individual dataframe and then concatenate all of them together at the end.","75fe8319":"# Assessment for trial for trial store 86","981be086":"The results show that the trial in store 86 is not significantly different to its control store in the trial period. The trial store performance lies inside the 5% to 95% confidence interval of the control store in two of the three trial months.","d0dcf1f8":"# Assessment of trial for trial strore 88\n\nThe trial period goes from the start of February 2019 to end of April 2019. We now want to see if there has been an uplift in overall chip sales. ","31320051":"# Conclusion for Module 2\n\nIt looks like the number of customers is significantly higher in all of the three months. This seems to\nsuggest that the trial had a significant impact on increasing the number of customers in trial store 86 but\nas we saw, sales were not significantly higher. We should check with the Category Manager if there were\nspecial deals in the trial store that were may have resulted in lower prices, impacting the results.","89e056cd":"The results show that the trial in store 77 is significantly different to its control store in the trial period. The trial store performance lies outside the 5% and 95% confidence intervals in the two of the 3 trial months."}}