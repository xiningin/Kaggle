{"cell_type":{"372c96fe":"code","2a94a5f8":"code","425e53b1":"code","735c5b10":"code","0caaccc7":"code","811dcf12":"code","7f0a1bbe":"code","5089f28f":"code","e070c1d9":"code","d6e94ff9":"code","e2b05fa5":"code","15b41bf8":"code","b17081db":"code","0ad4711b":"code","0c8b476e":"code","2c1ca595":"markdown"},"source":{"372c96fe":"# import libraries\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nprint(os.listdir(\"..\/input\"))\n","2a94a5f8":"data = pd.read_csv('..\/input\/column_2C_weka.csv')","425e53b1":"# view data\ndata.head()","735c5b10":"data['class'].unique()","0caaccc7":"data.info()","811dcf12":"# you split class as abnormal and normal\nA = data[data['class'] == 'Abnormal']\nN = data[data['class'] == 'Normal']","7f0a1bbe":"N.info()","5089f28f":"#visualization\nplt.scatter(A.pelvic_incidence, A.pelvic_radius, color = 'purple', label = 'Abnormal',alpha = 0.5)\nplt.scatter(N.pelvic_incidence, N.pelvic_radius, color = 'orange', label = 'Normal', alpha = 0.5)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('pelvic_radius')\nplt.legend()\nplt.show()","e070c1d9":"# abnormal and normal are string. So you transform integer or float.\ndata['class'] = [0 if each == 'Abnormal' else 1 for each in data['class']]","d6e94ff9":"# determine feature and feature class.\ny = data['class'].values\nx_data = data.drop(['class'], axis=1)","e2b05fa5":"# normalization\nx = (x_data-np.min(x_data))\/(np.max(x_data)-np.min(x_data))\n# (x-min(x))\/(max(x)-min(x))","15b41bf8":"#train test split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 1)","b17081db":"#knn model\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 4)\nknn.fit(x_train,y_train)\nprediction = knn.predict(x_test)","0ad4711b":"print('{} n\u0131n score: {}'.format(3,knn.score(x_test,y_test)))","0c8b476e":"# find the most appropriate k value\nscore_list = []\nfor each in range(1,15):\n    knn2 = KNeighborsClassifier(n_neighbors=each)\n    knn2.fit(x_train, y_train)\n    score_list.append(knn2.score(x_test,y_test))\n    \nplt.plot(range(1,15),score_list,color='purple')\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.show()","2c1ca595":"# KNN ALGOR\u0130THM\n* This algorithm used to classification.\n* Suppose you have a new property and you want classification this property. You should look nearest neighbors and you must make classification according to nearest neighbors. \n* This algorithm has to k value. The value of k tells you how many nearest neighbors you should look. For example: If k=3, you should look nearest three neigbors. Assume, first neigbor classified as X, second neigbor classified as Y and third neigbor classified as X. You should make classification according this classicification results. And you can tell 'New property should classification as X' \n"}}