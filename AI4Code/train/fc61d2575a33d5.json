{"cell_type":{"f916a722":"code","e265fd9c":"code","b0f68b32":"code","9ce45a6b":"code","f5d15bf3":"code","6fcae5dc":"code","bcc4d945":"code","e425542e":"code","8b7a0fd2":"code","9e0149db":"code","9aa58c76":"code","fd399255":"code","9b00a8c9":"code","c82ec267":"code","2d6cbe82":"markdown"},"source":{"f916a722":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport xgboost\nfrom sklearn.metrics import classification_report,accuracy_score,confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import SelectKBest,chi2\nfrom sklearn.linear_model import LogisticRegression\nfrom imblearn.over_sampling import RandomOverSampler\nfrom collections import Counter\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e265fd9c":"df = pd.read_csv('\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv')","b0f68b32":"df.head()","9ce45a6b":"corrmat = df.corr()\ntop = corrmat.index\nplt.figure(figsize=(10,10))\nsns.heatmap(df[top].corr(),annot=True,cmap='RdYlGn')","f5d15bf3":"x = df.drop('Outcome',axis=1)\ny = df['Outcome']","6fcae5dc":"os = RandomOverSampler(ratio=1)\nxos,yos = os.fit_sample(x,y)","bcc4d945":"xg = xgboost.XGBClassifier(criterion='entropy')\ndt = DecisionTreeClassifier(random_state=1,criterion='entropy')\nrf = RandomForestClassifier(random_state=1,criterion='entropy')\nlr = LogisticRegression()","e425542e":"score = cross_val_score(rf,xos,yos,cv=5)\nscore.mean()","8b7a0fd2":"a = [xg,dt,lr,rf]\nacc = []\nfor i in a:\n    i.fit(xos,yos)\n    pred = i.predict(xos)\n    acc.append(accuracy_score(pred,yos))\nprint(acc)","9e0149db":"rf.fit(xos,yos)","9aa58c76":"pred = rf.predict(xos)","fd399255":"accuracy_score(pred,yos)","9b00a8c9":"confusion_matrix(yos,pred)","c82ec267":"print(classification_report(yos,pred))","2d6cbe82":"**Best result is shown by random forest**"}}