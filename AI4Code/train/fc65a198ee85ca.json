{"cell_type":{"d3b03f2d":"code","d032c605":"code","ed842a5d":"code","c57a37b1":"code","3beb8759":"code","ed44031c":"code","6cc9aaa9":"code","7e359e3d":"code","2f2fbd73":"code","86909dbe":"code","199fd811":"code","40daa7c7":"code","13026a66":"code","e5f108a2":"code","a72db5d2":"code","490836f1":"code","63187bcb":"code","e305b78d":"code","c21159fb":"code","7fc9c855":"code","b536f090":"code","f5a247e7":"code","dfc04b34":"code","6346ecf3":"code","b6884253":"code","3ac3603b":"code","32856aa2":"code","118378b3":"code","3f0bed2e":"code","16949c0a":"code","11ba0d7b":"code","1d716ecd":"code","446a1fd3":"code","e84065a9":"code","76adc63e":"code","94935ae2":"code","a837ec4b":"code","10176a89":"code","594f2052":"code","2098f44c":"code","dd22c888":"code","505cd019":"code","31eec79c":"code","81993c64":"code","73fe4c87":"code","2f968390":"code","707477f6":"code","48d1d39a":"code","0eb2f4f4":"code","cb9a47bb":"code","fb6ce795":"code","a092a5c3":"code","bec46216":"code","63924699":"code","6c08ea2b":"code","e2dd7eab":"code","ad653a09":"code","34984ca1":"code","c5696d82":"code","5eacc724":"code","d1b43f58":"code","9b5b3148":"code","6ae24c10":"code","72bf1c4e":"code","49f941f0":"code","badddf04":"code","6bc1c819":"code","4108d8f7":"markdown","cf985703":"markdown","cf6300e4":"markdown","7859022b":"markdown","aa078272":"markdown","796455ea":"markdown","5e3ea765":"markdown","9d3ae782":"markdown","5ec53243":"markdown","24cfcb1a":"markdown","3dabab33":"markdown","4b7f2aa8":"markdown","b78f35c8":"markdown","38b2a7f4":"markdown","56f021ce":"markdown","14c1ceb8":"markdown","278fe0c6":"markdown","d2882742":"markdown","16f344e7":"markdown","5bfbcc08":"markdown","9348fa55":"markdown","878f624e":"markdown","773de8a1":"markdown","e0bc4ab7":"markdown","35df0713":"markdown","97a55a60":"markdown","df3041f4":"markdown","42a7a957":"markdown","60c94f72":"markdown"},"source":{"d3b03f2d":"import tensorflow as tf\nimport os\n\ntry:\n    tf.get_logger().propagate = False\n    if 'COLAB_TPU_ADDR' in os.environ: #colab\n        resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu = 'grpc:\/\/' + os.environ['COLAB_TPU_ADDR'])\n    else: #kaggle\n        resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(resolver)\n    tf.tpu.experimental.initialize_tpu_system(resolver)\n    strategy = tf.distribute.experimental.TPUStrategy(resolver)\n    print('TPU initialized, num of accelerators:', strategy.num_replicas_in_sync)\nexcept (ValueError, KeyError):\n    print('TPU not found, using CPU\/GPU')\n    strategy = tf.distribute.get_strategy()","d032c605":"#\u0434\u043b\u044f Colab: \u043d\u0443\u0436\u0435\u043d \u0444\u0430\u0439\u043b kaggle.json, \u0435\u0433\u043e \u043c\u043e\u0436\u043d\u043e \u0441\u043a\u0430\u0447\u0430\u0442\u044c \u0441 \u0441\u043a\u0430\u0439\u0442\u0430 kaggle.com, \u0440\u0430\u0437\u0434\u0435\u043b\u0430 My account, \u043a\u043d\u043e\u043f\u043a\u0430 \"Create New API Token\"\n#\u0437\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u044d\u0442\u043e\u0442 \u0444\u0430\u0439\u043b \u0432 Colab\n\nfrom google.colab import files\nfiles.upload();","ed842a5d":"#\u0434\u043b\u044f Colab: \u0441\u043a\u0430\u0447\u0438\u0432\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 https:\/\/www.kaggle.com\/c\/sf-dl-2-car-classification\n!mkdir -p ~\/.kaggle\n!mv kaggle.json ~\/.kaggle\/\n!chmod 600 \/root\/.kaggle\/kaggle.json\n!kaggle competitions download -c sf-dl-car-classification\n!mkdir -p \/kaggle\/input\/sf-dl-car-classification\n!mv \/content\/* \/kaggle\/input\/sf-dl-car-classification","c57a37b1":"!ls \/kaggle\/input\/sf-dl-car-classification","3beb8759":"import zipfile\nzip_folder = '\/kaggle\/input\/sf-dl-car-classification\/'\nout_folder = '\/kaggle\/working\/'\nwith zipfile.ZipFile(zip_folder + 'train.zip', 'r') as z:\n    z.extractall(out_folder)\nwith zipfile.ZipFile(zip_folder + 'test.zip', 'r') as z:\n    z.extractall(out_folder)","ed44031c":"!ls \/kaggle\/working","6cc9aaa9":"import tensorflow as tf\nimport random\n\nwith tf.device('\/job:localhost\/replica:0\/task:0\/device:CPU:0'): #\u043d\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u043a\u043b\u0430\u0441\u0442\u0435\u0440 TPU, \u0434\u0430\u0436\u0435 \u0435\u0441\u043b\u0438 \u043e\u043d \u0434\u043e\u0441\u0442\u0443\u043f\u0435\u043d, \u0442\u0430\u043a \u043a\u0430\u043a \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u043c \u0441 \u043b\u043e\u043a\u0430\u043b\u044c\u043d\u044b\u043c\u0438 \u0444\u0430\u0439\u043b\u0430\u043c\u0438\n    \n    #\u0437\u0430\u0434\u0430\u0435\u043c \u043f\u0443\u0442\u0438 \u043a \u0444\u0430\u0439\u043b\u0430\u043c\n    paths = tf.io.gfile.glob('\/kaggle\/working\/train\/*\/*.jpg')\n    random.shuffle(paths)\n\n    #\u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u043a\u043b\u0430\u0441\u0441\u044b\n    classes = [int(path.split('\/')[-2]) for path in paths]\n    \n    #\u043f\u043e \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0431\u0443\u0434\u0435\u043c \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u0432 \u043e\u0434\u0438\u043d \u0444\u0430\u0439\u043b?\n    shard_size = 1000\n\n    #\u0441\u043e\u0437\u0434\u0430\u0435\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0431\u0443\u0434\u0435\u0442 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0442\u044c \u043f\u043e 1000 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0438 \u043a\u043b\u0430\u0441\u0441\u043e\u0432\n    dataset = tf.data.Dataset.from_tensor_slices((paths, classes))\n    dataset = dataset.map(\n        lambda path, class_idx: (tf.io.read_file(path), class_idx)\n    ).batch(shard_size)\n\n    #\u0441\u043e\u0437\u0434\u0430\u0435\u043c \u043f\u0430\u043f\u043a\u0443 \u0434\u043b\u044f \u0444\u0430\u0439\u043b\u043e\u0432 .tfrec\n    import shutil, pathlib\n    out_folder = '\/kaggle\/working\/train_tfrec'\n    shutil.rmtree(out_folder, ignore_errors = True) #\u0443\u0434\u0430\u043b\u044f\u0435\u043c \u043f\u0430\u043f\u043a\u0443 \u0441\u043e \u0441\u0442\u0430\u0440\u044b\u043c\u0438 \u0444\u0430\u0439\u043b\u0430\u043c\u0438\n    pathlib.Path(out_folder).mkdir(parents = True, exist_ok = True)\n\n    images_processed = 0\n    for batch_index, (images, classes_idx) in enumerate(dataset):\n        filename = out_folder + '\/%d.tfrec' % batch_index\n        \n        images_ndarray = images.numpy() #tf.io.read_file \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u0431\u0430\u0439\u0442\u044b, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 images - \u043d\u0430\u0431\u043e\u0440 \u0431\u0430\u0439\u0442, \u0442. \u0435. \u0442\u0435\u043d\u0437\u043e\u0440 \u0442\u0438\u043f\u0430 tf.string\n        classes_ndarray = classes_idx.numpy()\n        \n        examples_count = images_ndarray.shape[0] #\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043e? (\u0432 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u043c \u043c\u0430\u0441\u0441\u0438\u0432\u0435 \u0438\u0445 \u0431\u0443\u0434\u0435\u0442 \u043c\u0435\u043d\u044c\u0448\u0435 shard_size)\n        \n        print('Writing file: %s [images %d-%d]' % (filename, images_processed, images_processed + examples_count))\n        images_processed += examples_count\n        \n        with tf.io.TFRecordWriter(filename) as out_file:\n            for i in range(examples_count):\n                tfrecord = tf.train.Example(features = tf.train.Features(feature = {\n                    'image': tf.train.Feature(bytes_list = tf.train.BytesList(value = [images_ndarray[i]])),\n                    'class': tf.train.Feature(int64_list = tf.train.Int64List(value = [classes_ndarray[i]]))\n                }))\n                out_file.write(tfrecord.SerializeToString())","7e359e3d":"# \u0430\u043d\u0430\u043b\u043e\u0433\u0438\u0447\u043d\u043e \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n\nwith tf.device('\/job:localhost\/replica:0\/task:0\/device:CPU:0'):\n    \n    paths = tf.io.gfile.glob('\/kaggle\/working\/test_upload\/*.jpg')\n\n    filenames = [path.split('\/')[-1] for path in paths]\n    \n    shard_size = 1000\n\n    dataset = tf.data.Dataset.from_tensor_slices((paths, filenames))\n    dataset = dataset.map(\n        lambda path, filename: (tf.io.read_file(path), filename)\n    ).batch(shard_size)\n\n    out_folder = '\/kaggle\/working\/test_tfrec'\n    shutil.rmtree(out_folder, ignore_errors = True) #\u0443\u0434\u0430\u043b\u044f\u0435\u043c \u043f\u0430\u043f\u043a\u0443 \u0441\u043e \u0441\u0442\u0430\u0440\u044b\u043c\u0438 \u0444\u0430\u0439\u043b\u0430\u043c\u0438\n    pathlib.Path(out_folder).mkdir(parents = True, exist_ok = True)\n\n    images_processed = 0\n    for batch_index, (images, img_filenames) in enumerate(dataset):\n        filename = out_folder + '\/%d.tfrec' % batch_index\n        \n        images_ndarray = images.numpy()\n        img_filenames_ndarray = img_filenames.numpy()\n        \n        examples_count = images_ndarray.shape[0]\n        \n        print('Writing file: %s [images %d-%d]' % (filename, images_processed, images_processed + examples_count))\n        images_processed += examples_count\n        \n        with tf.io.TFRecordWriter(filename) as out_file:\n            for i in range(examples_count):\n                tfrecord = tf.train.Example(features = tf.train.Features(feature = {\n                    'image': tf.train.Feature(bytes_list = tf.train.BytesList(value = [images_ndarray[i]])),\n                    'filename': tf.train.Feature(bytes_list = tf.train.BytesList(value = [img_filenames_ndarray[i]]))\n                }))\n                out_file.write(tfrecord.SerializeToString())","2f2fbd73":"#\u0434\u043b\u044f Colab (\u043d\u0443\u0436\u043d\u043e \u0432\u0432\u0435\u0441\u0442\u0438 \u043a\u043e\u0434 \u0430\u043a\u0442\u043e\u0440\u0438\u0437\u0430\u0446\u0438\u0438)\n!gcloud auth login\n!gsutil -m cp -r \/kaggle\/working\/train_tfrec\/ gs:\/\/oleg-zyablov\/car-classification\/train_tfrec\/\n!gsutil -m cp -r \/kaggle\/working\/test_tfrec\/ gs:\/\/oleg-zyablov\/car-classification\/test_tfrec\/","86909dbe":"#\u0434\u043b\u044f Kaggle (\u043c\u0435\u043d\u044e -> Add-ons -> Google Cloud SDK, \u043d\u0443\u0436\u043d\u043e \u0432\u0432\u0435\u0441\u0442\u0438 \u043a\u043e\u0434 \u0430\u0432\u0442\u043e\u0440\u0438\u0437\u0430\u0446\u0438\u0438)\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)\n\nfor path in tf.io.gfile.glob('\/kaggle\/working\/train_tfrec\/*.tfrec'):\n    dst = 'gs:\/\/oleg-zyablov\/car-classification\/train_tfrec\/' + path.split('\/')[-1]\n    tf.io.gfile.copy(path, dst, overwrite = True)\n    print('Copied', path, '->', dst)\nfor path in tf.io.gfile.glob('\/kaggle\/working\/test_tfrec\/*.tfrec'):\n    dst = 'gs:\/\/oleg-zyablov\/car-classification\/test_tfrec\/' + path.split('\/')[-1]\n    tf.io.gfile.copy(path, dst, overwrite = True)\n    print('Copied', path, '->', dst)","199fd811":"import matplotlib.pyplot as plt\n\nclass_names = [\n  '\u041f\u0440\u0438\u043e\u0440\u0430', #0\n  'Ford Focus', #1\n  '\u0421\u0430\u043c\u0430\u0440\u0430', #2\n  '\u0412\u0410\u0417-2110', #3\n  '\u0416\u0438\u0433\u0443\u043b\u0438', #4\n  '\u041d\u0438\u0432\u0430', #5\n  '\u041a\u0430\u043b\u0438\u043d\u0430', #6\n  '\u0412\u0410\u0417-2109', #7\n  'Volkswagen Passat', #8\n  '\u0412\u0410\u0417-21099' #9\n]\n\ndef visualize_dataset(pairs, grayscale = False): #pair = (image, title)\n    images_count = len(pairs)\n    fig = plt.figure(figsize = (min(24, images_count * 4), 4))\n    for img_index in range(images_count):\n        ax = fig.add_subplot(1, images_count, img_index + 1)\n        img, title = pairs[img_index]\n        if tf.is_tensor(img): img = img.numpy()\n        if tf.is_tensor(title): title = title.numpy()\n        ax.imshow(img, cmap = 'gray' if grayscale else None)\n        ax.set_title(title)\n        ax.axis('off')\n    plt.show()","40daa7c7":"#\u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n\nwith strategy.scope():\n    \n    def read_train_tfrecord(serialized_example):\n        example = tf.io.parse_single_example(serialized_example, features = {\n            'image': tf.io.FixedLenFeature([], tf.string), #tf.string - \u0431\u0430\u0439\u0442\u043e\u0432\u0430\u044f \u0441\u0442\u0440\u043e\u043a\u0430; [] \u043e\u0437\u043d\u0430\u0447\u0430\u0435\u0442 \u0441\u043a\u0430\u043b\u044f\u0440, \u0442. \u0435. \u0442\u043e\u043b\u044c\u043a\u043e \u043e\u0434\u043d\u0430 \u0441\u0442\u0440\u043e\u043a\u0430\n            'class': tf.io.FixedLenFeature([], tf.int64)\n        })\n        return tf.image.decode_jpeg(example['image'], channels = 3), example['class']\n\n    # \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u043a\u043e\u043d\u0432\u0435\u0439\u0435\u0440\n    \n    raw_train_dataset = tf.data.TFRecordDataset(\n        ['gs:\/\/oleg-zyablov\/car-classification\/train_tfrec\/%d.tfrec' % i for i in range(16)],\n        num_parallel_reads = 16\n        #\u0441\u043e\u0437\u0434\u0430\u0435\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442 (\u043a\u043e\u043d\u0432\u0435\u0439\u0435\u0440), \u043f\u043e\u043b\u0443\u0447\u0430\u044e\u0449\u0438\u0439 \u0434\u0430\u043d\u043d\u044b\u0435 \u0438\u0437 \u0443\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0445 \u0444\u0430\u0439\u043b\u043e\u0432\n    ).map(\n       read_train_tfrecord\n    ) #.shuffle(300) #\u043a\u043e\u043d\u0432\u0435\u0439\u0435\u0440 \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0435\u0442 \u0431\u0443\u0444\u0435\u0440 \u0438\u0437 300 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432, \u0430 \u0437\u0430\u0442\u0435\u043c \u0431\u0435\u0440\u0435\u0442 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0435 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u044b \u0438\u0437 \u0431\u0443\u0444\u0435\u0440\u0430\n\npairs = list(raw_train_dataset.take(6))\nvisualize_dataset([(img, class_names[label]) for img, label in pairs])","13026a66":"# \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n\nwith strategy.scope():\n    \n    def read_test_tfrecord(serialized_example):\n        example = tf.io.parse_single_example(serialized_example, features = {\n            'image': tf.io.FixedLenFeature([], tf.string),\n            'filename': tf.io.FixedLenFeature([], tf.string)\n        })\n        return tf.image.decode_jpeg(example['image'], channels = 3), example['filename']\n    \n    raw_test_dataset = tf.data.TFRecordDataset(\n        ['gs:\/\/oleg-zyablov\/car-classification\/test_tfrec\/%d.tfrec' % i for i in range(7)],\n        num_parallel_reads = 7\n    ).map(\n       read_test_tfrecord\n    )\n    \npairs = list(raw_test_dataset.take(6))\nvisualize_dataset([(img, filename.numpy().decode('utf-8')) for img, filename in pairs])","e5f108a2":"from tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nimport time, gc\n\ndef test_xception(optimizer, lr, resizing_func, size, preprocess_func_train, preprocess_func_val, global_pooling, dense_layer,\n                  val_data_percent = 0.5, epochs = 1, batch_size = 64, message = '', verbose = 0, optimizer_ready = None, callbacks = [],\n                  reuse_model = None, return_model = None):\n  with strategy.scope():\n    total_count = 15561\n    val_count = int(total_count * val_data_percent)\n    train_count = total_count - val_count\n    steps_per_epoch = train_count \/\/ batch_size\n\n    raw_train_dataset_shuffled = raw_train_dataset\n\n    resizing_func_tuple = lambda img, label: (resizing_func(img), label)\n    preprocess_func_tuple_train = lambda img, label: (preprocess_func_train(img), label)\n    preprocess_func_tuple_val = lambda img, label: (preprocess_func_val(img), label)\n\n    val_dataset = raw_train_dataset_shuffled.take(val_count).map(resizing_func_tuple).map(preprocess_func_tuple_val)\n\n    train_dataset = raw_train_dataset_shuffled.skip(val_count).shuffle(300).repeat().map(resizing_func_tuple).map(preprocess_func_tuple_train)\n\n    #\u0444\u0443\u043d\u043a\u0446\u0438\u044f get_real_metrics \u043d\u0443\u0436\u043d\u0430 \u043f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443 keras callback \u043d\u0430 \u043a\u0430\u0436\u0434\u043e\u043c \u0431\u0430\u0442\u0447\u0435 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043f\u043e \u044d\u043f\u043e\u0445\u0435, \u043d\u0443\u0436\u043d\u043e \u043d\u0430\u0439\u0442\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043d\u0430 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u043c \u0431\u0430\u0442\u0447\u0435\n    total_batches = 0 #\u0441\u0447\u0435\u0442\u0447\u0438\u043a \u0431\u0430\u0442\u0447\u0435\u0439\n    prev_sum_metrics = None\n    def get_real_metrics(batch, logs, metrics = 'accuracy'):\n      nonlocal prev_sum_metrics, total_batches\n      total_batches += 1\n      if batch == 0:\n        prev_sum_metrics = logs.get(metrics)\n        return prev_sum_metrics\n      current_averaged_metrics = logs.get(metrics)\n      current_sum_metrics = current_averaged_metrics * (batch + 1)\n      real_metrics = current_sum_metrics - prev_sum_metrics\n      prev_sum_metrics = current_sum_metrics\n      return real_metrics\n\n    #\u0444\u0443\u043d\u043a\u0446\u0438\u044f on_epoch_end \u0431\u0443\u0434\u0435\u0442 \u0441\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438 \u043f\u043e\u0441\u043b\u0435 \u043a\u0430\u0436\u0434\u043e\u0439 \u044d\u043f\u043e\u0445\u0438\n    val_acc_batches_history = [] #\u043a\u043e\u043b-\u0432\u043e \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u044b\u0445 \u0431\u0430\u0442\u0447\u0435\u0439 \u043f\u043e\u0441\u043b\u0435 \u043a\u0430\u0436\u0434\u043e\u0439 \u044d\u043f\u043e\u0445\u0438\n    val_acc_history = [] #\u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u043f\u043e\u0441\u043b\u0435 \u043a\u0430\u0436\u0434\u043e\u0439 \u044d\u043f\u043e\u0445\u0438\n    def on_epoch_end(epoch, logs):\n      val_acc_batches_history.append(total_batches)\n      val_acc_history.append(logs.get('val_accuracy'))\n\n    acc_history = [] #\u0438\u0441\u0442\u043e\u0440\u0438\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0431\u0430\u0442\u0447\u0430\n    #print('constructing model')\n    gc.collect()\n\n    if not reuse_model:\n      xception = tf.keras.applications.xception.Xception(\n          weights = 'imagenet',\n          include_top = False,\n          input_shape = (size[0], size[1], 3)\n      )\n\n      x = xception.output\n\n      if global_pooling == 'average':\n        x = GlobalAveragePooling2D()(x)\n      elif global_pooling == 'max':\n        x = GlobalMaxPooling2D()(x)\n      else:\n        assert(0)\n      x = BatchNormalization()(x)\n      x = Dropout(0.3)(x)\n\n      if dense_layer == '128':\n        x = Dense(128, activation = 'relu')\n        x = BatchNormalization()(x)\n      elif type(dense_layer) == int:\n        x = Dense(dense_layer, activation = 'relu')(x)\n        x = BatchNormalization()(x)\n      elif dense_layer != None:\n        assert(0)\n\n      predictions = Dense(10)(x)\n\n      model = tf.keras.Model(inputs = xception.input, outputs = predictions)\n    else:\n      model = reuse_model\n\n    model.compile(\n      loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n      optimizer = optimizer(learning_rate = lr) if not optimizer_ready else optimizer_ready,\n      metrics = ['accuracy']\n    )\n\n    start_time = time.time()\n    model.fit(\n        train_dataset.batch(batch_size),\n        steps_per_epoch = steps_per_epoch,\n        epochs = epochs,\n        validation_data = val_dataset.batch(batch_size),\n        callbacks = [\n            tf.keras.callbacks.LambdaCallback(on_batch_end = lambda batch, logs: acc_history.append(get_real_metrics(batch, logs))),\n            tf.keras.callbacks.LambdaCallback(on_epoch_end = on_epoch_end)\n        ] + callbacks,\n        verbose = verbose\n    )\n    \n  elapsed_time = time.time() - start_time\n  print(message, 'validation accuracy = %g, seconds elapsed: %.1f' % (val_acc_history[-1], elapsed_time))\n\n  if return_model:\n    return model, acc_history, val_acc_batches_history, val_acc_history\n  del model, x, xception\n  return acc_history, val_acc_batches_history, val_acc_history","a72db5d2":"def stretch(image, size): #uint8 0-255 -> float32 0-255\n  return tf.image.resize(image, size, preserve_aspect_ratio = False)\n\ndef crop(image, size):\n  # if image.shape[0] == None: #Tensor(\"args_0:0\", shape=(None, None, 3), dtype=uint8)\n  #   return tf.image.resize(image, size)\n  # print(image)\n  ratio = tf.shape(image)[1] \/ tf.shape(image)[0]\n  target_ratio = size[1] \/ size[0]\n  if target_ratio > ratio:\n    h = size[1]\n    w = int(size[1] \/ ratio)\n  else:\n    w = size[0]\n    h = int(size[0] * ratio)\n  image = tf.image.resize(image, (w, h))\n  return tf.image.resize_with_crop_or_pad(image, size[0], size[1])\n\ndef pad(image, size):\n  image = tf.image.resize(image, size, preserve_aspect_ratio = True)\n  return tf.image.resize_with_pad(image, *size)\n\ndef multipad(image, side_size, ratio = 0.64):\n  h1 = int(side_size * ratio)\n  h2 = side_size - h1\n  w1 = int(h2 \/ ratio)\n  w2 = side_size - w1\n  h3 = int(w2 * ratio)\n  h4 = h2 - h3\n  result = tf.constant(0.0, shape = (h4, w2, 3))\n  result = tf.concat((pad(image, (h3, w2)), result), axis = 0)\n  result = tf.concat((pad(image, (h2, w1)), result), axis = 1)\n  result = tf.concat((pad(image, (h1, side_size)), result), axis = 0)\n  return result\n\npairs_train = list(raw_train_dataset.skip(18).take(6))\nprint('\u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f')\nvisualize_dataset([(img, '') for img, label in pairs_train])\nprint('stretch')\nvisualize_dataset([(tf.cast(stretch(img, (384, 512)), tf.uint8), '') for img, label in pairs_train])\nprint('crop')\nvisualize_dataset([(tf.cast(crop(img, (384, 512)), tf.uint8), '') for img, label in pairs_train])\nprint('pad')\nvisualize_dataset([(tf.cast(pad(img, (384, 512)), tf.uint8), '') for img, label in pairs_train])\nprint('multipad')\nvisualize_dataset([(tf.cast(multipad(img, 512), tf.uint8), '') for img, label in pairs_train])","490836f1":"normalize = lambda img: img \/ 128 - 1.0\n\ntest_epochs = 4\ntest_examples = 4\n\nstretch_acc = [test_xception(optimizer = Adam, lr = 0.001, resizing_func = lambda img: stretch(img, (384, 512)), size = (384, 512),\n    preprocess_func_train = normalize, preprocess_func_val = normalize, global_pooling = 'average',\n    dense_layer = 128, message = 'stretch:', epochs = test_epochs) for _ in range(test_examples)]\n\ncrop_acc = [test_xception(optimizer = Adam, lr = 0.001, resizing_func = lambda img: crop(img, (384, 512)), size = (384, 512),\n    preprocess_func_train = normalize, preprocess_func_val = normalize, global_pooling = 'average',\n    dense_layer = 128, message = 'crop:', epochs = test_epochs) for _ in range(test_examples)]\n\npad_acc = [test_xception(optimizer = Adam, lr = 0.001, resizing_func = lambda img: pad(img, (384, 512)), size = (384, 512),\n    preprocess_func_train = normalize, preprocess_func_val = normalize, global_pooling = 'average',\n    dense_layer = 128, message = 'pad:', epochs = test_epochs) for _ in range(test_examples)]\n\nmultipad_acc = [test_xception(optimizer = Adam, lr = 0.001, resizing_func = lambda img: multipad(img, 444), size = (444, 444), #444*444 ~ 384*512\n    preprocess_func_train = normalize, preprocess_func_val = normalize, global_pooling = 'average',\n    dense_layer = 128, message = 'multipad:', epochs = test_epochs) for _ in range(test_examples)]","63187bcb":"import numpy as np\n\nsteps_per_epoch = len(stretch_acc[0][0]) \/ test_epochs\n\nfig = plt.figure(figsize = (17, 8))\n\ndef ax_settings(ax):\n  ax.set_yscale('logit')\n  ax.set_xscale('logit')\n  ax.set_xlim(0.8, 0.97)\n  ax.set_ylim(0.2, 0.95)\n  ax.set_xlabel('train accuracy')\n  ax.set_ylabel('test accuracy')\n\nax = fig.add_subplot(1, 2, 1)\nax_settings(ax)\nax.set_title('all results')\nfor data_idx, (data, data_label) in enumerate(zip([stretch_acc, crop_acc, pad_acc, multipad_acc], ['stretch', 'crop', 'pad', 'multipad'])):\n  color = 'C%d' % data_idx\n  for data_tuple_idx, data_tuple in enumerate(data):\n    acc_history = data_tuple[0]\n    val_acc_batches_history = data_tuple[1]\n    val_acc_history = data_tuple[2]\n    train_acc_history_smoothed = [np.mean(np.array(acc_history[int(steps_per_epoch * (epoch - 0.5)):int(steps_per_epoch * (epoch + 0.5))])) for epoch in range(1, test_epochs)]\n    ax.plot(train_acc_history_smoothed, val_acc_history[:-1], color = color, label = data_label if data_tuple_idx == 0 else None, linewidth = 1.5)\n    ax.scatter(train_acc_history_smoothed, val_acc_history[:-1], color = color, s = 20)\nax.legend()\n\nax = fig.add_subplot(1, 2, 2)\nax_settings(ax)\nax.set_title('averaged results')\nfor data, data_label in zip([stretch_acc, crop_acc, pad_acc, multipad_acc], ['stretch', 'crop', 'pad', 'multipad']):\n  acc_history = np.mean(np.array([i[0] for i in data]), axis = 0)\n  val_acc_batches_history = np.mean(np.array([i[1] for i in data]), axis = 0)\n  val_acc_history = np.mean(np.array([i[2] for i in data]), axis = 0)\n  train_acc_history_smoothed = [np.mean(np.array(acc_history[int(steps_per_epoch * (epoch - 0.5)):int(steps_per_epoch * (epoch + 0.5))])) for epoch in range(1, test_epochs)]\n  ax.plot(train_acc_history_smoothed, val_acc_history[:-1], label = data_label, linewidth = 3)\n  ax.scatter(train_acc_history_smoothed, val_acc_history[:-1], s = 50)\nax.legend()\n\nplt.show()","e305b78d":"normalize = tf.image.per_image_standardization\n\ntest_epochs = 4\n\ntest_xception(optimizer = Adam, lr = 0.001, resizing_func = lambda img: stretch(img, (384, 512)), size = (384, 512),\n    preprocess_func_train = normalize, preprocess_func_test = normalize, global_pooling = 'average',\n    dense_layer = 128, message = 'stretch:', epochs = test_epochs, verbose = 1)","c21159fb":"import random, numpy as np\n\ndef zoom(x, size): #zooming an image (\u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0432\u0437\u044f\u0442\u0430 \u0438\u0437 \u0438\u043d\u0442\u0435\u0440\u043d\u0435\u0442\u0430)\n    scales = list(np.arange(0.6, 1.2, 0.01))\n    boxes = np.zeros((len(scales), 4))\n\n    for i, scale in enumerate(scales):\n        x1 = y1 = 0.5 - (0.5 * scale)\n        x2 = y2 = 0.5 + (0.5 * scale)\n        boxes[i] = [x1, y1, x2, y2]\n\n    def random_crop(img):\n        # Create different crops for an image\n        crops = tf.image.crop_and_resize([img], boxes=boxes, box_indices=np.zeros(len(scales)), crop_size=size)\n        # Return a random crop\n        return crops[tf.random.uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n\n    choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n\n    # Only apply cropping 50% of the time\n    return random_crop(x)\n    #return tf.cond(choice < 0.5, lambda: x, lambda: random_crop(x))\n\n#\u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u0442\u0441\u044f \u043a \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u043c\u0443 \u043d\u0430\u0431\u043e\u0440\u0443\ndef preprocess_train(image):\n    image = tf.image.random_hue(image, 0.1)\n    image = tf.image.random_saturation(image, 0.6, 1.6)\n    image = tf.image.random_brightness(image, 0.05)\n    #image = tf.image.random_contrast(image, 0.7, 1.3)\n    #image = tf.keras.preprocessing.image.random_rotation(image, 15, row_axis = 0, col_axis = 1, channel_axis = 2)\n    image = zoom(image, size = tf.shape(image)[:2])\n    return image \/ 128 - 1\n\n#\u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u0442\u0441\u044f \u043a \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c\u0443 \u043d\u0430\u0431\u043e\u0440\u0443\ndef preprocess_val(image):\n    image = tf.cast(image, tf.float32)\n    return image \/ 128 - 1\n\n#\u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u0442\u0441\u044f \u0434\u043b\u044f \u043e\u0442\u0440\u0438\u0441\u043e\u0432\u043a\u0438\ndef back_to_uint8(image):\n    return tf.cast((image + 1) * 128, tf.uint8)\n\npairs_train = list(raw_train_dataset.skip(18).take(6))\nprint('\u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f')\nvisualize_dataset([(img, '') for img, label in pairs_train])\nprint('pad + augmentation')\nvisualize_dataset([(back_to_uint8(preprocess_train(pad(img, (384, 512)))), '') for img, label in pairs_train])","7fc9c855":"test_epochs = 10\nlr = lambda: tf.keras.optimizers.schedules.ExponentialDecay(0.0005, decay_steps = 100, decay_rate = 0.9)\n\nsize = (384, 512)\nacc_512 = test_xception(optimizer = Adam, lr = lr(), resizing_func = lambda img: pad(img, size), size = size,\n    preprocess_func_train = preprocess_train, preprocess_func_val = preprocess_val, global_pooling = 'average',\n    dense_layer = 128, message = '512:', epochs = test_epochs, verbose = 1)\n\nsize = (256, 384)\nacc_384 = test_xception(optimizer = Adam, lr = lr(), resizing_func = lambda img: pad(img, size), size = size,\n    preprocess_func_train = preprocess_train, preprocess_func_val = preprocess_val, global_pooling = 'average',\n    dense_layer = 128, message = '384:', epochs = test_epochs, verbose = 1)\n\nsize = (192, 256)\nacc_256 = test_xception(optimizer = Adam, lr = lr(), resizing_func = lambda img: pad(img, size), size = size,\n    preprocess_func_train = preprocess_train, preprocess_func_val = preprocess_val, global_pooling = 'average',\n    dense_layer = 128, message = '256:', epochs = test_epochs, verbose = 1)\n\nsize = (128, 192)\nacc_192 = test_xception(optimizer = Adam, lr = lr(), resizing_func = lambda img: pad(img, size), size = size,\n    preprocess_func_train = preprocess_train, preprocess_func_val = preprocess_val, global_pooling = 'average',\n    dense_layer = 128, message = '192:', epochs = test_epochs, verbose = 1)","b536f090":"import numpy as np\n\nsteps_per_epoch = len(acc_512[0]) \/ test_epochs\n\nfig = plt.figure(figsize = (17, 8))\n\ndef ax_settings(ax):\n  ax.set_yscale('logit')\n  ax.set_xscale('logit')\n  ax.set_xlim(0.5, 0.992)\n  ax.set_ylim(0.4, 0.975)\n  ax.set_xlabel('train accuracy')\n  ax.set_ylabel('test accuracy')\n\nax = fig.add_subplot(1, 2, 2)\nax_settings(ax)\nax.set_title('all results')\nfor data, data_label in zip([acc_512, acc_384, acc_256, acc_192], ['512x384', '384x256', '256x192', '192x128']):\n  acc_history = np.array(data[0])\n  val_acc_batches_history = np.array(data[1])\n  val_acc_history = np.array(data[2])\n  train_acc_history_smoothed = [np.mean(np.array(acc_history[int(steps_per_epoch * (epoch - 0.5)):int(steps_per_epoch * (epoch + 0.5))])) for epoch in range(1, test_epochs)]\n  ax.plot(train_acc_history_smoothed, val_acc_history[:-1], label = data_label, linewidth = 3)\n  ax.scatter(train_acc_history_smoothed, val_acc_history[:-1], s = 50)\nax.legend()\n\nplt.show()","f5a247e7":"test_epochs = 15\nsize = (256, 384)\n\noptimizer = Adam(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0005, decay_steps = 100, decay_rate = 0.9))\ncallbacks = []\ntest1 = test_xception(None, None, resizing_func = lambda img: pad(img, (size)), size = size,\n    preprocess_func_train = preprocess_train, preprocess_func_val = preprocess_val, global_pooling = 'average',\n    dense_layer = 128, message = 'Adam decay:', epochs = test_epochs, verbose = 1, optimizer_ready = optimizer, callbacks = callbacks)\n\noptimizer = Nadam(learning_rate = 0.0005)\ncallbacks = []\ntest2 = test_xception(None, None, resizing_func = lambda img: pad(img, (size)), size = size,\n    preprocess_func_train = preprocess_train, preprocess_func_val = preprocess_val, global_pooling = 'average',\n    dense_layer = 128, message = 'Nadam:', epochs = test_epochs, verbose = 1, optimizer_ready = optimizer, callbacks = callbacks)\n\noptimizer = Adam(learning_rate = 0.0005)\ncallbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', factor = 0.7, patience = 1, verbose = 1, cooldown = 3, min_lr = 0.00001)]\ntest3 = test_xception(None, None, resizing_func = lambda img: pad(img, (size)), size = size,\n    preprocess_func_train = preprocess_train, preprocess_func_val = preprocess_val, global_pooling = 'average',\n    dense_layer = 128, message = 'Adam plateau:', epochs = test_epochs, verbose = 1, optimizer_ready = optimizer, callbacks = callbacks)\n\noptimizer = SGD(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.05, decay_steps = 100, decay_rate = 0.8), momentum = 0.9)\ncallbacks = []\ntest4 = test_xception(None, None, resizing_func = lambda img: pad(img, (size)), size = size,\n    preprocess_func_train = preprocess_train, preprocess_func_val = preprocess_val, global_pooling = 'average',\n    dense_layer = 128, message = 'SGD momentum decay:', epochs = test_epochs, verbose = 1, optimizer_ready = optimizer, callbacks = callbacks)","dfc04b34":"import numpy as np\n\nsteps_per_epoch = len(test1[0]) \/ test_epochs\n\nfig = plt.figure(figsize = (17, 8))\n\ndef ax_settings(ax):\n  ax.set_yscale('logit')\n  ax.set_xscale('logit')\n  ax.set_xlim(0.7, 0.995)\n  ax.set_ylim(0.3, 0.975)\n  ax.set_xlabel('train accuracy')\n  ax.set_ylabel('test accuracy')\n\nax = fig.add_subplot(1, 2, 2)\nax_settings(ax)\nax.set_title('all results')\nfor data, data_label in zip([test1, test2, test3, test4], ['Adam decay', 'Nadam', 'Adam plateau reduce', 'SGD momentum decay']):\n  acc_history = np.array(data[0])\n  val_acc_batches_history = np.array(data[1])\n  val_acc_history = np.array(data[2])\n  train_acc_history_smoothed = [np.mean(np.array(acc_history[int(steps_per_epoch * (epoch - 0.5)):int(steps_per_epoch * (epoch + 0.5))])) for epoch in range(1, test_epochs)]\n  ax.plot(train_acc_history_smoothed, val_acc_history[:-1], label = data_label, linewidth = 3)\n  ax.scatter(train_acc_history_smoothed, val_acc_history[:-1], s = 50)\nax.legend()\n\nplt.show()","6346ecf3":"global_pooling_index = 132 #\u0438\u043d\u0434\u0435\u043a\u0441 \u0441\u043b\u043e\u044f global average pooling \u0432 Xception\n\nlayer_groups = [\n  (\n    max(0, global_pooling_index-5*(i+1)),\n    max(0, global_pooling_index-1-5*i)\n  )\n  for i in range(27)\n] + [None] * 23\nprint(len(layer_groups))\nprint(layer_groups)\n\ndef set_untrainable_all(model):\n  for layer in model.layers[:global_pooling_index]:\n    layer.trainable = False\n\ndef set_trainable_group(model, group):\n  if group:\n    print('set_trainable_group(): unlocking layers %d-%d' % (group[0], group[1]))\n    for layer in model.layers[group[0]:group[1] + 1]:\n      layer.trainable = True\n  else:\n    print('set_trainable_group(): do nothing')","b6884253":"test_params = {\n    'SGD nesterov decay': {\n        'optimizer': SGD(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.06, decay_steps = 100, decay_rate = 0.85), momentum = 0.97, nesterov = True),\n        'on_start': None,\n        'on_epoch_end': None\n    },\n    'adam decay': {\n        'optimizer': Adam(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0008, decay_steps = 100, decay_rate = 0.9)),\n        'on_start': None,\n        'on_epoch_end': None\n    },\n    'adam decay TEST': {\n        'optimizer': Adam(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0008, decay_steps = 100, decay_rate = 0.9)),\n        'on_start': set_untrainable_all,\n        'on_epoch_end': (lambda model, epoch: set_trainable_group(model, layer_groups[epoch]))\n    },\n    'SGD decay TEST': {\n        'optimizer': SGD(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.06, decay_steps = 100, decay_rate = 0.85), momentum = 0.9),\n        'on_start': set_untrainable_all,\n        'on_epoch_end': (lambda model, epoch: set_trainable_group(model, layer_groups[epoch]))\n    },\n}\n\ndef test_with_params(params_name, epochs):\n  params = test_params[params_name]\n  size = (192, 256)\n  with strategy.scope():\n    batch_size = 64\n    total_count = 15561\n    val_count = int(total_count * 0.5)\n    train_count = total_count - val_count\n    steps_per_epoch = train_count \/\/ batch_size\n\n    raw_train_dataset_shuffled = raw_train_dataset.shuffle(300)\n\n    resizing_func_tuple = lambda img, label: (pad(img, (size)), label)\n    preprocess_func_tuple_train = lambda img, label: (preprocess_train(img), label)\n    preprocess_func_tuple_val = lambda img, label: (preprocess_val(img), label)\n\n    val_dataset = raw_train_dataset_shuffled.take(val_count).map(resizing_func_tuple).map(preprocess_func_tuple_val)\n\n    train_dataset = raw_train_dataset_shuffled.skip(val_count).repeat().map(resizing_func_tuple).map(preprocess_func_tuple_train)\n\n    #\u0444\u0443\u043d\u043a\u0446\u0438\u044f get_real_metrics \u043d\u0443\u0436\u043d\u0430 \u043f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443 keras callback \u043d\u0430 \u043a\u0430\u0436\u0434\u043e\u043c \u0431\u0430\u0442\u0447\u0435 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043f\u043e \u044d\u043f\u043e\u0445\u0435, \u043d\u0443\u0436\u043d\u043e \u043d\u0430\u0439\u0442\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043d\u0430 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u043c \u0431\u0430\u0442\u0447\u0435\n    total_batches = 0 #\u0441\u0447\u0435\u0442\u0447\u0438\u043a \u0431\u0430\u0442\u0447\u0435\u0439\n    prev_sum_metrics = None\n    def get_real_metrics(batch, logs, metrics = 'accuracy'):\n      global prev_sum_metrics, total_batches\n      total_batches += 1\n      if batch == 0:\n        prev_sum_metrics = logs.get(metrics)\n        return prev_sum_metrics\n      current_averaged_metrics = logs.get(metrics)\n      current_sum_metrics = current_averaged_metrics * (batch + 1)\n      real_metrics = current_sum_metrics - prev_sum_metrics\n      prev_sum_metrics = current_sum_metrics\n      return real_metrics\n\n    #\u0444\u0443\u043d\u043a\u0446\u0438\u044f on_epoch_end \u0431\u0443\u0434\u0435\u0442 \u0441\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u043f\u043e\u0441\u043b\u0435 \u043a\u0430\u0436\u0434\u043e\u0439 \u044d\u043f\u043e\u0445\u0438\n    val_acc_batches_history = [] #\u043a\u043e\u043b-\u0432\u043e \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u044b\u0445 \u0431\u0430\u0442\u0447\u0435\u0439 \u043f\u043e\u0441\u043b\u0435 \u043a\u0430\u0436\u0434\u043e\u0439 \u044d\u043f\u043e\u0445\u0438\n    val_acc_history = [] #\u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u043f\u043e\u0441\u043b\u0435 \u043a\u0430\u0436\u0434\u043e\u0439 \u044d\u043f\u043e\u0445\u0438\n    def on_epoch_end(epoch, logs):\n      val_acc_batches_history.append(total_batches)\n      val_acc_history.append(logs.get('val_accuracy'))\n\n    acc_history = [] #\u0438\u0441\u0442\u043e\u0440\u0438\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0431\u0430\u0442\u0447\u0430\n    print(params_name, '- constructing model')\n    gc.collect()\n\n    xception = tf.keras.applications.xception.Xception(\n        weights = 'imagenet',\n        include_top = False,\n        input_shape = (size[0], size[1], 3)\n    )\n\n    x = xception.output\n\n    x = GlobalAveragePooling2D()(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.3)(x)\n\n    x = Dense(128, activation = 'relu')(x)\n    x = BatchNormalization()(x)\n\n    predictions = Dense(10)(x)\n\n    model = tf.keras.Model(inputs = xception.input, outputs = predictions)\n\n    model.compile(\n      loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n      optimizer = params['optimizer'],\n      metrics = ['accuracy']\n    )\n\n    start_time = time.time()\n\n    if params['on_start']:\n      params['on_start'](model)\n\n    for epoch in range(epochs):\n      model.fit(\n          train_dataset.batch(batch_size),\n          steps_per_epoch = steps_per_epoch,\n          epochs = 1,\n          validation_data = val_dataset.batch(batch_size),\n          callbacks = [\n              tf.keras.callbacks.LambdaCallback(on_batch_end = lambda batch, logs: acc_history.append(get_real_metrics(batch, logs))),\n              tf.keras.callbacks.LambdaCallback(on_epoch_end = on_epoch_end)\n          ],\n          verbose = 1\n      )\n      if params['on_epoch_end']:\n        params['on_epoch_end'](model, epoch)\n    \n    elapsed_time = time.time() - start_time\n    print(params_name, '- validation accuracy = %g, seconds elapsed: %.1f' % (val_acc_history[-1], elapsed_time))\n\n    del model, x, xception\n\n    return {\n        'epochs': epochs,\n        'acc_history': acc_history,\n        'val_acc_batches_history': val_acc_batches_history,\n        'val_acc_history': val_acc_history\n    }","3ac3603b":"results = {}\nepochs = 32\nresults['SGD nesterov decay'] = test_with_params('SGD nesterov decay', epochs)\nresults['adam decay'] = test_with_params('adam decay', epochs)\nresults['adam decay TEST'] = test_with_params('adam decay TEST', epochs)\nresults['SGD decay TEST'] = test_with_params('SGD decay TEST', epochs)","32856aa2":"# #@title Code\nimport numpy as np\n\nfig = plt.figure(figsize = (29, 8))\n\ndef ax_settings(ax):\n  ax.set_yscale('logit')\n  ax.set_xscale('logit')\n  ax.set_xlim(0.5, 0.999)\n  ax.set_ylim(0.5, 0.975)\n  ax.set_xlabel('train accuracy')\n  ax.set_ylabel('test accuracy')\n\nax = fig.add_subplot(1, 2, 2)\nax_settings(ax)\nax.set_title('all results')\nfor title, result in results.items():\n  epochs = result['epochs']\n  acc_history = result['acc_history']\n  val_acc_history = result['val_acc_history']\n  steps_per_epoch = len(acc_history) \/ epochs\n  train_acc_history_smoothed = [np.mean(np.array(acc_history[int(steps_per_epoch * (epoch - 0.5)):int(steps_per_epoch * (epoch + 0.5))])) for epoch in range(1, epochs)]\n  ax.plot(train_acc_history_smoothed, val_acc_history[:-1], linewidth = 2, label = title)\n  ax.scatter(train_acc_history_smoothed[-1:], val_acc_history[-2:-1], s = 50)\n\nplt.legend()\nplt.show()","118378b3":"optimizer = Adam()\nsize = (192, 256)\ncallbacks = [tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.001 \/ (epoch % 10 + 1))]\ntest1 = test_xception(None, None, resizing_func = lambda img: pad(img, (size)), size = size,\n    preprocess_func_train = preprocess_train, preprocess_func_val = preprocess_val, global_pooling = 'average',\n    dense_layer = 128, message = 'test 1:', epochs = 30, verbose = 1, optimizer_ready = optimizer, callbacks = callbacks)","3f0bed2e":"optimizer = Adam()\nsize = (192, 256)\ncallbacks = [tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.0005 \/ (epoch % 10 + 1))]\ntest2 = test_xception(None, None, resizing_func = lambda img: pad(img, (size)), size = size,\n    preprocess_func_train = preprocess_train, preprocess_func_val = preprocess_val, global_pooling = 'average',\n    dense_layer = 128, message = 'test 1:', epochs = 30, verbose = 1, optimizer_ready = optimizer, callbacks = callbacks)","16949c0a":"import numpy as np\n\nfig = plt.figure(figsize = (17, 8))\n\ndef ax_settings(ax):\n  ax.set_yscale('logit')\n  ax.set_xscale('logit')\n  ax.set_xlim(0.6, 0.995)\n  ax.set_ylim(0.1, 0.98)\n  ax.set_xlabel('train accuracy')\n  ax.set_ylabel('test accuracy')\n\nax = fig.add_subplot(1, 2, 2)\nax_settings(ax)\nax.set_title('all results')\nfor test, title in zip([test1, test2], ['Adam lr = 0.001 \/ (epoch % 10 + 1)', 'Adam lr = 0.0005 \/ (epoch % 10 + 1)']):\n  epochs = 30\n  acc_history, val_acc_batches_history, val_acc_history = test\n  steps_per_epoch = len(acc_history) \/ epochs\n  train_acc_history_smoothed = [np.mean(np.array(acc_history[int(steps_per_epoch * (epoch - 0.5)):int(steps_per_epoch * (epoch + 0.5))])) for epoch in range(1, epochs)]\n  ax.plot(train_acc_history_smoothed, val_acc_history[:-1], linewidth = 2, label = title)\n  ax.scatter(train_acc_history_smoothed[-1:], val_acc_history[-2:-1], s = 50)\n\nplt.legend()\nplt.show()","11ba0d7b":"def visualize_channels(img, title = None): #float, 0-255\n  total_channels = img.shape[2]\n  fig = plt.figure(figsize = (6*total_channels, 4))\n  for channel in range(total_channels):\n    ax = fig.add_subplot(1, total_channels, 1 + channel)\n    ax.imshow(img[..., channel], cmap = 'gray')\n    ax.set_title('%s channel %d' % (title or '', channel))\n    ax.axis('off')\n  plt.show()\n\n#\u043e\u043f\u0435\u0440\u0430\u0442\u043e\u0440 \u0441\u043e\u0431\u0435\u043b\u044f\n\ndef sobel(img_uint8, one_output_channel = True, downscaling = 1): #float, 0-255\n    img = tf.cast(img_uint8, tf.float32)\n    size = tf.shape(img)[:2]\n    if downscaling != 1:\n      new_size = tf.math.floordiv(size, downscaling)\n      img = tf.image.resize(img, new_size)\n    img = tf.expand_dims(img, 0)\n    img = tf.image.sobel_edges(img)\n    img = img[0]\n    img = tf.math.reduce_max(img, axis = 2)\n    if one_output_channel:\n      img = tf.math.sqrt(img[..., 0]*img[..., 0] \/ 9 + img[..., 1]*img[..., 1] \/ 9)\n      img = tf.expand_dims(img, 2)\n    img = tf.math.minimum(img, 255)\n    img = tf.math.maximum(img, 0)\n    if downscaling != 1:\n      img = tf.image.resize(img, size)\n    return img\n\nimg = list(raw_train_dataset.take(1))[0][0]\nvisualize_channels(img, 'RGB')\nvisualize_channels(sobel(img, one_output_channel = True), 'Sobel (by both axes)')\nvisualize_channels(sobel(img, one_output_channel = False), 'Sobel (by X and by Y)')\nvisualize_channels(sobel(img, one_output_channel = True, downscaling = 3), 'Sobel (by both axes, scaled)')","1d716ecd":"def RGB(img_uint8): #float, 0-255\n  return tf.cast(img_uint8, tf.float32)\n\ndef Gray(img_uint8): #float, 0-255\n  channel = tf.cast(tf.image.rgb_to_grayscale(img_uint8), tf.float32) #float, 0-255\n  return tf.concat((channel, channel, channel), axis = 2)\n\ndef Gray_Sobel_Sobel3(img_uint8): #float, 0-255\n  channel1 = tf.cast(tf.image.rgb_to_grayscale(img_uint8), tf.float32) #float, 0-255\n  channel2 = sobel(img_uint8, one_output_channel = True) #float, 0-255\n  channel3 = sobel(img_uint8, one_output_channel = True, downscaling = 3) #float, 0-255\n  return tf.concat((channel1, channel2, channel3), axis = 2)\n\ndef Gray_SobelX_SobelY(img_uint8): #float, 0-255\n  channel1 = tf.cast(tf.image.rgb_to_grayscale(img_uint8), tf.float32) #float, 0-255\n  channels2_3 = sobel(img_uint8, one_output_channel = False) #float, 0-255\n  return tf.concat((channel1, channels2_3), axis = 2)\n\nvisualize_channels(Gray(img))\nvisualize_channels(Gray_Sobel_Sobel3(img))\nvisualize_channels(Gray_SobelX_SobelY(img))","446a1fd3":"get_lr = lambda: tf.keras.optimizers.schedules.ExponentialDecay(0.0008, decay_steps = 100, decay_rate = 0.9)\nsize = (192, 256)\n\ndef preprocess_train_norescale(image):\n    image = tf.image.random_hue(image, 0.1)\n    image = tf.image.random_saturation(image, 0.6, 1.6)\n    image = tf.image.random_brightness(image, 0.05)\n    #image = tf.image.random_contrast(image, 0.7, 1.3)\n    #image = tf.keras.preprocessing.image.random_rotation(image, 15, row_axis = 0, col_axis = 1, channel_axis = 2)\n    image = zoom(image, size = tf.shape(image)[:2])\n    return image\n\n#\u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u0442\u0441\u044f \u043a \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c\u0443 \u043d\u0430\u0431\u043e\u0440\u0443\ndef preprocess_val_norescale(image):\n    image = tf.cast(image, tf.float32)\n    return image","e84065a9":"# \u044d\u0442\u043e \u043d\u0430\u0433\u0440\u043e\u043c\u043e\u0436\u0434\u0435\u043d\u0438\u0435 \u043a\u043e\u0434\u0430 \u043a\u043e\u043d\u0435\u0447\u043d\u043e \u0432\u044b\u0433\u043b\u044f\u0434\u0438\u0442 \u043d\u0435 \u043e\u0447\u0435\u043d\u044c \u0445\u043e\u0440\u043e\u0448\u043e, \u043d\u043e \u0434\u043b\u044f \u043f\u0430\u0440\u044b \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u043e\u0432 \u043f\u043e\u0434\u043e\u0439\u0434\u0435\u0442\n# \u0441\u043b\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u0435\u0449\u0435 \u0438 \u0432 \u0442\u043e\u043c, \u0447\u0442\u043e \u0440\u0430\u0437\u043d\u044b\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 tensorflow \u043f\u0440\u0438\u043d\u0438\u043c\u0430\u044e\u0442 \u0438 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u044e\u0442 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432 \u0440\u0430\u0437\u043d\u044b\u0445 \u0444\u043e\u0440\u043c\u0430\u0442\u0430\u0445\n# \u0444\u043e\u0440\u043c\u0430\u0442\u044b \u0431\u044b\u0432\u0430\u044e\u0442 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0435: uint8 \u043e\u0442 0 \u0434\u043e 255, float \u043e\u0442 0 \u0434\u043e 255, float \u043e\u0442 0 \u0434\u043e 1, float \u043e\u0442 -1 \u0434\u043e 1\n\nchannels_func = Gray\npreprocess_func_train = lambda img: channels_func(preprocess_train_norescale(img)) \/ 128 - 1\npreprocess_func_val = lambda img: channels_func(preprocess_val_norescale(img)) \/ 128 - 1\ntest_Gray = test_xception(Adam, get_lr(), resizing_func = lambda img: pad(img, (size)), size = size,\n    preprocess_func_train = preprocess_func_train,\n    preprocess_func_val = preprocess_func_val,\n    global_pooling = 'average', dense_layer = 128, message = 'Gray:', epochs = 30, verbose = 1, return_model = True)\n\nchannels_func = RGB\npreprocess_func_train = lambda img: channels_func(preprocess_train_norescale(img)) \/ 128 - 1\npreprocess_func_val = lambda img: channels_func(preprocess_val_norescale(img)) \/ 128 - 1\ntest_RGB = test_xception(Adam, get_lr(), resizing_func = lambda img: pad(img, (size)), size = size,\n    preprocess_func_train = preprocess_func_train,\n    preprocess_func_val = preprocess_func_val,\n    global_pooling = 'average', dense_layer = 128, message = 'RGB:', epochs = 30, verbose = 1, return_model = True)\n\nchannels_func = Gray_Sobel_Sobel3\npreprocess_func_train = lambda img: channels_func(preprocess_train_norescale(img)) \/ 128 - 1\npreprocess_func_val = lambda img: channels_func(preprocess_val_norescale(img)) \/ 128 - 1\ntest_Gray_Sobel_Sobel3 = test_xception(Adam, get_lr(), resizing_func = lambda img: pad(img, (size)), size = size,\n    preprocess_func_train = preprocess_func_train,\n    preprocess_func_val = preprocess_func_val,\n    global_pooling = 'average', dense_layer = 128, message = 'Gray_Sobel_Sobel3:', epochs = 30, verbose = 1, return_model = True)\n\nchannels_func = Gray_SobelX_SobelY\npreprocess_func_train = lambda img: channels_func(preprocess_train_norescale(img)) \/ 128 - 1\npreprocess_func_val = lambda img: channels_func(preprocess_val_norescale(img)) \/ 128 - 1\ntest_Gray_SobelX_SobelY = test_xception(Adam, get_lr(), resizing_func = lambda img: pad(img, (size)), size = size,\n    preprocess_func_train = preprocess_func_train,\n    preprocess_func_val = preprocess_func_val,\n    global_pooling = 'average', dense_layer = 128, message = 'Gray_SobelX_SobelY:', epochs = 30, verbose = 1, return_model = True)","76adc63e":"fig = plt.figure(figsize = (17, 8))\n\ndef ax_settings(ax):\n  ax.set_yscale('logit')\n  ax.set_xscale('logit')\n  ax.set_xlim(0.6, 0.998)\n  ax.set_ylim(0.3, 0.98)\n  ax.set_xlabel('train accuracy')\n  ax.set_ylabel('test accuracy')\n\nax = fig.add_subplot(1, 2, 2)\nax_settings(ax)\nax.set_title('all results')\nfor test, title, epochs in zip([test_Gray, test_RGB, test_Gray_Sobel_Sobel3, test_Gray_SobelX_SobelY], ['Gray', 'RGB', 'Gray_Sobel_Sobel3', 'Gray_SobelX_SobelY'], [30, 30, 30, 30]):\n  model, acc_history, val_acc_batches_history, val_acc_history = test\n  steps_per_epoch = len(acc_history) \/ epochs\n  train_acc_history_smoothed = [np.mean(np.array(acc_history[int(steps_per_epoch * (epoch - 0.5)):int(steps_per_epoch * (epoch + 0.5))])) for epoch in range(1, epochs)]\n  ax.plot(train_acc_history_smoothed, val_acc_history[:-1], linewidth = 2, label = title)\n  ax.scatter(train_acc_history_smoothed[-1:], val_acc_history[-2:-1], s = 50)\n\nplt.legend()\nplt.show()","94935ae2":"channels_func = Gray\npreprocess_func_train = lambda img: channels_func(preprocess_train_norescale(img)) \/ 128 - 1\npreprocess_func_val = lambda img: channels_func(preprocess_val_norescale(img)) \/ 128 - 1\ntest_Gray = test_xception(Adam, get_lr(), resizing_func = lambda img: pad(img, (size)), size = size,\n    preprocess_func_train = preprocess_func_train,\n    preprocess_func_val = preprocess_func_val,\n    global_pooling = 'average', dense_layer = 128, message = 'Gray:', epochs = 20, verbose = 1, return_model = True)","a837ec4b":"test_Gray[0].save('\/gray.h5')","10176a89":"!gcloud auth login","594f2052":"!gsutil cp \/gray.h5 gs:\/\/oleg-zyablov\/car-classification\/models\/gray.h5","2098f44c":"channels_func = RGB\npreprocess_func_train = lambda img: channels_func(preprocess_train_norescale(img)) \/ 128 - 1\npreprocess_func_val = lambda img: channels_func(preprocess_val_norescale(img)) \/ 128 - 1\ntest_RGB = test_xception(Adam, get_lr(), resizing_func = lambda img: pad(img, (size)), size = size,\n    preprocess_func_train = preprocess_func_train,\n    preprocess_func_val = preprocess_func_val,\n    global_pooling = 'average', dense_layer = 128, message = 'RGB:', epochs = 20, verbose = 1, return_model = True)","dd22c888":"test_RGB[0].save('\/rgb.h5')","505cd019":"!gsutil cp \/rgb.h5 gs:\/\/oleg-zyablov\/car-classification\/models\/rgb.h5","31eec79c":"!gsutil cp gs:\/\/oleg-zyablov\/car-classification\/models\/gray.h5 \/gray.h5\n!gsutil cp gs:\/\/oleg-zyablov\/car-classification\/models\/rgb.h5 \/rgb.h5","81993c64":"val_data_percent = 0.5\nbatch_size = 64\ntotal_count = 15561\nval_count = int(total_count * val_data_percent)\ntrain_count = total_count - val_count\nsteps_per_epoch = train_count \/\/ batch_size\n\nraw_train_dataset_shuffled = raw_train_dataset #.shuffle(300)\n\nchannels_func = Gray\n#preprocess_func_train = lambda img: channels_func(preprocess_train_norescale(img)) \/ 128 - 1\npreprocess_func_val = lambda img: channels_func(preprocess_val_norescale(img)) \/ 128 - 1\n\nresizing_func_tuple = lambda img, label: (pad(img, size = (192, 256)), label)\n#preprocess_func_tuple_train = lambda img, label: (preprocess_func_train(img), label)\npreprocess_func_tuple_val = lambda img, label: (preprocess_func_val(img), label)\n\nval_dataset = raw_train_dataset_shuffled.take(val_count).map(resizing_func_tuple).map(preprocess_func_tuple_val)\n#train_dataset = raw_train_dataset_shuffled.skip(val_count).repeat().map(resizing_func_tuple).map(preprocess_func_tuple_train)\n\nlogits_gray = tf.keras.models.load_model('\/gray.h5').predict(val_dataset.batch(64))","73fe4c87":"channels_func = RGB\n#preprocess_func_train = lambda img: channels_func(preprocess_train_norescale(img)) \/ 128 - 1\npreprocess_func_val = lambda img: channels_func(preprocess_val_norescale(img)) \/ 128 - 1\n\nresizing_func_tuple = lambda img, label: (pad(img, size = (192, 256)), label)\n#preprocess_func_tuple_train = lambda img, label: (preprocess_func_train(img), label)\npreprocess_func_tuple_val = lambda img, label: (preprocess_func_val(img), label)\n\nval_dataset = raw_train_dataset_shuffled.take(val_count).map(resizing_func_tuple).map(preprocess_func_tuple_val)\n#train_dataset = raw_train_dataset_shuffled.skip(val_count).repeat().map(resizing_func_tuple).map(preprocess_func_tuple_train)\n\nlogits_rgb = tf.keras.models.load_model('\/rgb.h5').predict(val_dataset.batch(64))","2f968390":"correct_answers = [x[1] for x in val_dataset]\ncorrect_answers_count = np.bincount(correct_answers)\nprint(correct_answers_count)","707477f6":"labels_gray = np.argmax(logits_gray, axis = 1)\nlabels_rgb = np.argmax(logits_rgb, axis = 1)","48d1d39a":"confusion_matrix_gray = np.zeros((10, 10))\nconfusion_matrix_rgb = np.zeros((10, 10))\n\nfor i, correct_answer in enumerate(correct_answers):\n  confusion_matrix_gray[labels_gray[i], correct_answer] += 1\n  confusion_matrix_rgb[labels_rgb[i], correct_answer] += 1\n\nprint('confusion matrix gray')\nprint(confusion_matrix_gray)\nprint('confusion matrix rgb')\nprint(confusion_matrix_rgb)","0eb2f4f4":"import matplotlib.pyplot as plt\nfig = plt.figure(figsize = (16, 8))\nax = fig.add_subplot(1, 2, 1)\nax.set_title('Grayscale recognition')\nax.imshow(confusion_matrix_gray, cmap = 'gray', vmin = 0, vmax = 100)\nfor i in range(10):\n  for j in range(10):\n    ax.text(j, i, str(int(confusion_matrix_gray[i][j])), horizontalalignment = 'center',\n            verticalalignment = 'center', color = 'black' if confusion_matrix_gray[i][j] > 50 else 'white')\nax.set_ylabel('prediction')\nax.set_xlabel('correct answer')\nax = fig.add_subplot(1, 2, 2)\nax.set_title('RGB recognition')\nax.imshow(confusion_matrix_rgb, cmap = 'gray', vmin = 0, vmax = 100)\nfor i in range(10):\n  for j in range(10):\n    ax.text(j, i, str(int(confusion_matrix_rgb[i][j])), horizontalalignment = 'center',\n            verticalalignment = 'center', color = 'black' if confusion_matrix_rgb[i][j] > 50 else 'white')\nax.set_ylabel('prediction')\nax.set_xlabel('correct answer')\nplt.show()","cb9a47bb":"pairs = []\nfor i, pair in enumerate(val_dataset):\n  if labels_rgb[i] != correct_answers[i]:\n    title = '\u0418\u043d\u0434\u0435\u043a\u0441: %d\\n\u0420\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u043d\u043e: %s\\n\u041f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e:%s' % (i, class_names[labels_rgb[i]], class_names[correct_answers[i]])\n    pairs.append((tf.cast((pair[0] + 1) * 128, tf.uint8), title))\n  if len(pairs) == 6:\n    visualize_dataset(pairs)\n    pairs = []","fb6ce795":"from tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nimport time, gc\n\ndef test_xception_v2(optimizer, resizing_func, size, preprocess_func_train, preprocess_func_val, top_layers, on_compile = None,\n                  val_data_percent = 0.5, epochs = 1, batch_size = 64, message = '', verbose = 0, callbacks = [],\n                  return_model = False, reuse_model = None):\n  with strategy.scope():\n    total_count = 15561\n    val_count = int(total_count * val_data_percent)\n    train_count = total_count - val_count\n    steps_per_epoch = train_count \/\/ batch_size\n\n    raw_train_dataset_shuffled = raw_train_dataset\n\n    resizing_func_tuple = lambda img, label: (resizing_func(img), label)\n    preprocess_func_tuple_train = lambda img, label: (preprocess_func_train(img), label)\n    preprocess_func_tuple_val = lambda img, label: (preprocess_func_val(img), label)\n\n    val_dataset = raw_train_dataset_shuffled.take(val_count).map(resizing_func_tuple).map(preprocess_func_tuple_val)\n\n    train_dataset = raw_train_dataset_shuffled.skip(val_count).shuffle(300).repeat().map(resizing_func_tuple).map(preprocess_func_tuple_train)\n\n    #\u0444\u0443\u043d\u043a\u0446\u0438\u044f get_real_metrics \u043d\u0443\u0436\u043d\u0430 \u043f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443 keras callback \u043d\u0430 \u043a\u0430\u0436\u0434\u043e\u043c \u0431\u0430\u0442\u0447\u0435 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043f\u043e \u044d\u043f\u043e\u0445\u0435, \u043d\u0443\u0436\u043d\u043e \u043d\u0430\u0439\u0442\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043d\u0430 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u043c \u0431\u0430\u0442\u0447\u0435\n    total_batches = 0 #\u0441\u0447\u0435\u0442\u0447\u0438\u043a \u0431\u0430\u0442\u0447\u0435\u0439\n    prev_sum_metrics = None\n    def get_real_metrics(batch, logs, metrics = 'accuracy'):\n      nonlocal prev_sum_metrics, total_batches\n      total_batches += 1\n      if batch == 0:\n        prev_sum_metrics = logs.get(metrics)\n        return prev_sum_metrics\n      current_averaged_metrics = logs.get(metrics)\n      current_sum_metrics = current_averaged_metrics * (batch + 1)\n      real_metrics = current_sum_metrics - prev_sum_metrics\n      prev_sum_metrics = current_sum_metrics\n      return real_metrics\n\n    #\u0444\u0443\u043d\u043a\u0446\u0438\u044f on_epoch_end \u0431\u0443\u0434\u0435\u0442 \u0441\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438 \u043f\u043e\u0441\u043b\u0435 \u043a\u0430\u0436\u0434\u043e\u0439 \u044d\u043f\u043e\u0445\u0438\n    val_acc_batches_history = [] #\u043a\u043e\u043b-\u0432\u043e \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u044b\u0445 \u0431\u0430\u0442\u0447\u0435\u0439 \u043f\u043e\u0441\u043b\u0435 \u043a\u0430\u0436\u0434\u043e\u0439 \u044d\u043f\u043e\u0445\u0438\n    val_acc_history = [] #\u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u043f\u043e\u0441\u043b\u0435 \u043a\u0430\u0436\u0434\u043e\u0439 \u044d\u043f\u043e\u0445\u0438\n    def on_epoch_end(epoch, logs):\n      val_acc_batches_history.append(total_batches)\n      val_acc_history.append(logs.get('val_accuracy'))\n\n    acc_history = [] #\u0438\u0441\u0442\u043e\u0440\u0438\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0431\u0430\u0442\u0447\u0430\n    #print('constructing model')\n    gc.collect()\n\n    if not reuse_model:\n      xception = tf.keras.applications.xception.Xception(\n          weights = 'imagenet',\n          include_top = False,\n          input_shape = (size[0], size[1], 3)\n      )\n      x = xception.output\n      for layer in top_layers:\n        x = layer(x)\n      predictions = x\n\n      model = tf.keras.Model(inputs = xception.input, outputs = predictions)\n    else:\n      model = reuse_model\n\n    model.compile(\n      loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n      optimizer = optimizer,\n      metrics = ['accuracy']\n    )\n\n    if on_compile:\n      on_compile(model)\n\n    start_time = time.time()\n    model.fit(\n        train_dataset.batch(batch_size),\n        steps_per_epoch = steps_per_epoch,\n        epochs = epochs,\n        validation_data = val_dataset.batch(batch_size),\n        callbacks = [\n            tf.keras.callbacks.LambdaCallback(on_batch_end = lambda batch, logs: acc_history.append(get_real_metrics(batch, logs))),\n            tf.keras.callbacks.LambdaCallback(on_epoch_end = on_epoch_end)\n        ] + callbacks,\n        verbose = verbose\n    )\n    \n  elapsed_time = time.time() - start_time\n  print(message, 'validation accuracy = %g, seconds elapsed: %.1f' % (val_acc_history[-1], elapsed_time))\n\n  if return_model:\n    return model, acc_history, val_acc_batches_history, val_acc_history\n  del model, x, xception\n  return acc_history, val_acc_batches_history, val_acc_history","a092a5c3":"size = (192, 256)\npreprocess_func_train = lambda img: RGB(preprocess_train_norescale(img)) \/ 128 - 1\npreprocess_func_val = lambda img: RGB(preprocess_val_norescale(img)) \/ 128 - 1\n\ndef freeze_output_layer(model): #\u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u043e\u0442\u0432\u0435\u0442\u044b \u043d\u0430\u043f\u0440\u044f\u043c\u0443\u044e \u0438\u0437 \u0441\u043b\u043e\u044f global average pooling\n  dense = model.layers[-1]\n  #dense.trainable = False\n  dense.set_weights((\n      np.concatenate(\n          (np.identity(10), np.zeros((2038, 10))),\n          axis = 0)\n      ,\n      np.zeros(10)\n  ))\n\ntest1 = test_xception_v2(optimizer = Adam(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0008, decay_steps = 100, decay_rate = 0.9)),\n                 resizing_func = lambda img: pad(img, size),\n                 size = size,\n                 preprocess_func_train = preprocess_func_train,\n                 preprocess_func_val = preprocess_func_val,\n                 top_layers = [GlobalAveragePooling2D(), Dense(10, trainable = False)],\n                 on_compile = freeze_output_layer,\n                val_data_percent = 0.5, epochs = 25, batch_size = 64, message = '', verbose = 1, callbacks = [], return_model = True)","bec46216":"#\u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c, \u0447\u0442\u043e \u0432\u044b\u0445\u043e\u0434\u043d\u043e\u0439 \u0441\u043b\u043e\u0439 \u043d\u0435 \u043e\u0431\u0443\u0447\u0430\u043b\u0441\u044f\ntest1[0].layers[-1].get_weights()[0]","63924699":"#\u0443\u0434\u0430\u043b\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u044c\nmodel = test1[0]\ntest1 = test1[1:]\ndel model","6c08ea2b":"acc_history, val_acc_batches_history, val_acc_history = test1\nepochs = 25\nsteps_per_epoch = len(acc_history) \/ epochs\ntrain_acc_history_smoothed = [np.mean(np.array(acc_history[int(steps_per_epoch * (epoch - 0.5)):int(steps_per_epoch * (epoch + 0.5))])) for epoch in range(1, epochs)]\ntest1 = (train_acc_history_smoothed, val_acc_history[:-1])","e2dd7eab":"test2 = test_xception_v2(optimizer = Adam(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0008, decay_steps = 100, decay_rate = 0.9)),\n                 resizing_func = lambda img: pad(img, size),\n                 size = size,\n                 preprocess_func_train = preprocess_func_train,\n                 preprocess_func_val = preprocess_func_val,\n                 top_layers = [GlobalAveragePooling2D(), BatchNormalization(), Dense(10)],\n                 val_data_percent = 0.5, epochs = 25, batch_size = 64, verbose = 1)","ad653a09":"acc_history, val_acc_batches_history, val_acc_history = test2\nepochs = 25\nsteps_per_epoch = len(acc_history) \/ epochs\ntrain_acc_history_smoothed = [np.mean(np.array(acc_history[int(steps_per_epoch * (epoch - 0.5)):int(steps_per_epoch * (epoch + 0.5))])) for epoch in range(1, epochs)]\ntest2 = (train_acc_history_smoothed, val_acc_history[:-1])","34984ca1":"#batchNorm, Dropout(0.3), Dense(100, relu, l2 regularizer), batchNorm, Dense(10)\ntest3 = test_xception_v2(optimizer = Adam(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0008, decay_steps = 100, decay_rate = 0.9)),\n                 resizing_func = lambda img: pad(img, size),\n                 size = size,\n                 preprocess_func_train = preprocess_func_train,\n                 preprocess_func_val = preprocess_func_val,\n                 top_layers = [GlobalAveragePooling2D(), BatchNormalization(), Dropout(0.3), Dense(100, activation = 'relu', kernel_regularizer = 'l2'), BatchNormalization(), Dense(10)],\n                 val_data_percent = 0.5, epochs = 25, batch_size = 64, verbose = 1)","c5696d82":"acc_history, val_acc_batches_history, val_acc_history = test3\nepochs = 25\nsteps_per_epoch = len(acc_history) \/ epochs\ntrain_acc_history_smoothed = [np.mean(np.array(acc_history[int(steps_per_epoch * (epoch - 0.5)):int(steps_per_epoch * (epoch + 0.5))])) for epoch in range(1, epochs)]\ntest3 = (train_acc_history_smoothed, val_acc_history[:-1])","5eacc724":"#batchNorm, Dropout(0.3), Dense(1000, relu, l2 regularizer), batchNorm, Dropout(0.5), Dense(10)\ntest4 = test_xception_v2(optimizer = Adam(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0008, decay_steps = 100, decay_rate = 0.9)),\n                 resizing_func = lambda img: pad(img, size),\n                 size = size,\n                 preprocess_func_train = preprocess_func_train,\n                 preprocess_func_val = preprocess_func_val,\n                 top_layers = [GlobalAveragePooling2D(), BatchNormalization(), Dropout(0.3), Dense(1000, activation = 'relu', kernel_regularizer = 'l2'), BatchNormalization(), Dropout(0.5), Dense(10)],\n                 val_data_percent = 0.5, epochs = 25, batch_size = 64, verbose = 1)","d1b43f58":"acc_history, val_acc_batches_history, val_acc_history = test4\nepochs = 25\nsteps_per_epoch = len(acc_history) \/ epochs\ntrain_acc_history_smoothed = [np.mean(np.array(acc_history[int(steps_per_epoch * (epoch - 0.5)):int(steps_per_epoch * (epoch + 0.5))])) for epoch in range(1, epochs)]\ntest4 = (train_acc_history_smoothed, val_acc_history[:-1])","9b5b3148":"fig = plt.figure(figsize = (18, 12))\n\ndef ax_settings(ax):\n  ax.set_yscale('logit')\n  ax.set_xscale('logit')\n  ax.set_xlim(0.6, 0.999)\n  ax.set_ylim(0.5, 0.96)\n  ax.set_xlabel('train accuracy')\n  ax.set_ylabel('test accuracy')\n\nax = fig.add_subplot(1, 2, 2)\nax_settings(ax)\nax.set_title('all results')\nfor (train_acc_history_smoothed, val_acc_history), title in zip([test1, test2, test3, test4], ['test 1', 'test 2', 'test 3', 'test 4']):\n  ax.plot(train_acc_history_smoothed, val_acc_history, linewidth = 2, label = title)\n  ax.scatter(train_acc_history_smoothed[-1:], val_acc_history[-1:], s = 50)\n\nplt.legend()\nplt.show()","6ae24c10":"size = (384, 512)\npreprocess_func_train = lambda img: RGB(preprocess_train_norescale(img)) \/ 128 - 1\npreprocess_func_val = lambda img: RGB(preprocess_val_norescale(img)) \/ 128 - 1\n\ntest_GlobalAveragePooling2D = test_xception_v2(optimizer = Adam(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0008, decay_steps = 100, decay_rate = 0.9)),\n                 resizing_func = lambda img: pad(img, size),\n                 size = size,\n                 preprocess_func_train = preprocess_func_train,\n                 preprocess_func_val = preprocess_func_val,\n                 top_layers = [GlobalAveragePooling2D(), BatchNormalization(), Dropout(0.3), Dense(100, activation = 'relu', kernel_regularizer = 'l2'), BatchNormalization(), Dense(10)],\n                 val_data_percent = 0.5, epochs = 15, batch_size = 64, verbose = 1)","72bf1c4e":"acc_history, val_acc_batches_history, val_acc_history = test_GlobalAveragePooling2D\nepochs = 15\nsteps_per_epoch = len(acc_history) \/ epochs\ntrain_acc_history_smoothed = [np.mean(np.array(acc_history[int(steps_per_epoch * (epoch - 0.5)):int(steps_per_epoch * (epoch + 0.5))])) for epoch in range(1, epochs)]\ntest_GlobalAveragePooling2D = (train_acc_history_smoothed, val_acc_history[:-1])","49f941f0":"test_GlobalMaxPooling2D = test_xception_v2(optimizer = Adam(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0008, decay_steps = 100, decay_rate = 0.9)),\n                 resizing_func = lambda img: pad(img, size),\n                 size = size,\n                 preprocess_func_train = preprocess_func_train,\n                 preprocess_func_val = preprocess_func_val,\n                 top_layers = [GlobalMaxPooling2D(), BatchNormalization(), Dropout(0.3), Dense(100, activation = 'relu', kernel_regularizer = 'l2'), BatchNormalization(), Dense(10)],\n                 val_data_percent = 0.5, epochs = 15, batch_size = 64, verbose = 1)","badddf04":"acc_history, val_acc_batches_history, val_acc_history = test_GlobalMaxPooling2D\nepochs = 15\nsteps_per_epoch = len(acc_history) \/ epochs\ntrain_acc_history_smoothed = [np.mean(np.array(acc_history[int(steps_per_epoch * (epoch - 0.5)):int(steps_per_epoch * (epoch + 0.5))])) for epoch in range(1, epochs)]\ntest_GlobalMaxPooling2D = (train_acc_history_smoothed, val_acc_history[:-1])","6bc1c819":"fig = plt.figure(figsize = (18, 12))\n\ndef ax_settings(ax):\n  ax.set_yscale('logit')\n  ax.set_xscale('logit')\n  ax.set_xlim(0.7, 0.996)\n  ax.set_ylim(0.2, 0.98)\n  ax.set_xlabel('train accuracy')\n  ax.set_ylabel('test accuracy')\n\nax = fig.add_subplot(1, 2, 2)\nax_settings(ax)\nax.set_title('all results')\nfor (train_acc_history_smoothed, val_acc_history), title in zip([test_GlobalAveragePooling2D, test_GlobalMaxPooling2D], ['GlobalAveragePooling', 'GlobalMaxPooling']):\n  ax.plot(train_acc_history_smoothed, val_acc_history, linewidth = 2, label = title)\n  ax.scatter(train_acc_history_smoothed[-1:], val_acc_history[-1:], s = 50)\n\nplt.legend()\nplt.show()","4108d8f7":"\u0412 \u0438\u0434\u0435\u0430\u043b\u0435 \u0445\u043e\u0442\u0435\u043b\u043e\u0441\u044c \u0431\u044b \u0438\u043c\u0435\u0442\u044c \u0438\u043d\u0442\u0435\u0440\u0430\u043a\u0442\u0438\u0432\u043d\u0443\u044e \u043c\u0430\u0442\u0440\u0438\u0446\u0443 \u043e\u0448\u0438\u0431\u043e\u043a, \u0433\u0434\u0435 \u043c\u043e\u0436\u043d\u043e \u0431\u044b\u043b\u043e \u0431\u044b \u0441\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u043d\u0435\u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u043d\u043d\u044b\u0435 \u043f\u0440\u0438\u043c\u0435\u0440\u044b \u0438 \u0432 \u0440\u0435\u0430\u043b\u044c\u043d\u043e\u043c \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0438\u0437\u043c\u0435\u043d\u044f\u0442\u044c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435, \u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u044f \u043e\u0442\u043a\u043b\u0438\u043a \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0438.\n\n\u041f\u043e \u043c\u0430\u0442\u0440\u0438\u0446\u0435 \u043e\u0448\u0438\u0431\u043e\u043a \u0432\u0438\u0434\u043d\u043e, \u0447\u0442\u043e \u0431\u043e\u043b\u044c\u0448\u0430\u044f \u0447\u0430\u043a\u0441\u0442\u044c \u043e\u0448\u0438\u0431\u043e\u043a \u0441\u0434\u0435\u043b\u0430\u043d\u0430 \u043c\u0435\u0436\u0434\u0443 \u043a\u043b\u0430\u0441\u0441\u0430\u043c\u0438 7 \u0438 9. \u041e\u0442\u043b\u0438\u0447\u0438\u0435 \u044d\u0442\u0438\u0445 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0442\u043e\u043b\u044c\u043a\u043e \u0432 \u0444\u043e\u0440\u043c\u0435 \u0437\u0430\u0434\u043d\u0435\u0439 \u0447\u0430\u0441\u0442\u0438 \u043c\u0430\u0448\u0438\u043d\u044b, \u0447\u0442\u043e \u0432\u0438\u0436\u043d\u043e \u043d\u0435 \u043f\u0440\u0438 \u043b\u044e\u0431\u043e\u043c \u0440\u0430\u043a\u0443\u0440\u0441\u0435.","cf985703":"\u041c\u044b \u043f\u043e\u0441\u0442\u0440\u043e\u0438\u043b\u0438 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043e\u0442 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u0439. \u0422\u0430\u043a\u0430\u044f \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c \u043b\u0443\u0447\u0448\u0435 \u043e\u0442\u0440\u0430\u0436\u0430\u0435\u0442 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0432\u044b\u0431\u0440\u0430\u043d\u043d\u043e\u0433\u043e \u043c\u0435\u0442\u043e\u0434\u0430, \u043f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443 \u043c\u044b \u0430\u0431\u0441\u0442\u0440\u0430\u0433\u0438\u0440\u0443\u0435\u043c\u0441\u044f \u043e\u0442 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u044d\u043f\u043e\u0445. \u041c\u043e\u0436\u0435\u0442 \u0441\u043b\u0443\u0447\u0438\u0442\u044c\u0441\u044f \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 \u0442\u0430\u043a, \u0447\u0442\u043e \u0434\u043b\u044f \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u043d\u043e\u0433\u043e \u043c\u0435\u0442\u043e\u0434\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043f\u043e\u0442\u0440\u0435\u0431\u0443\u0435\u0442\u0441\u044f \u0431\u043e\u043b\u044c\u0448\u0435 \u0432\u0440\u0435\u043c\u0435\u043d\u0438, \u043d\u043e \u0442\u0435\u0441\u0442\u043e\u0432\u0430\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0432 \u0438\u0442\u043e\u0433\u0435 \u0431\u0443\u0434\u0435\u0442 \u0432\u044b\u0448\u0435. \u041d\u0430 \u0433\u0440\u0430\u0444\u0438\u043a\u0435 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043e\u0442 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u044d\u043f\u043e\u0445 \u044d\u0442\u043e\u0433\u043e \u043c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \u043d\u0435 \u0432\u0438\u0434\u043d\u043e, \u0430 \u043d\u0430 \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u043d\u043e\u043c \u0432\u044b\u0448\u0435 \u0433\u0440\u0430\u0444\u0438\u043a\u0435 \u0431\u0443\u0434\u0435\u0442 \u0437\u0430\u043c\u0435\u0442\u043d\u043e. \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0441\u043b\u0435\u0434\u0443\u0435\u0442 \u043f\u0440\u0435\u043a\u0440\u0430\u0442\u0438\u0442\u044c \u0442\u043e\u0433\u0434\u0430, \u043a\u043e\u0433\u0434\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u0430\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043f\u0435\u0440\u0435\u0441\u0442\u0430\u043d\u0435\u0442 \u0440\u0430\u0441\u0442\u0438, \u043d\u043e \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u0430\u044f \u043d\u0430\u0432\u0435\u0440\u043d\u044f\u043a\u0430 \u0431\u0443\u0434\u0435\u0442 \u0440\u0430\u0441\u0442\u0438 \u0438 \u0434\u0430\u043b\u0435\u0435, \u0442\u043e \u0435\u0441\u0442\u044c \u0433\u0440\u0430\u0444\u0438\u043a \u0441\u0442\u0430\u043d\u0435\u0442 \u0437\u0430\u0433\u0438\u0431\u0430\u0442\u044c\u0441\u044f \u0432\u043d\u0438\u0437.\n\n\u0420\u0430\u0437 \u043d\u0430 \u043f\u043e\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0445 \u0433\u0440\u0430\u0444\u0438\u043a\u0430\u0445 \u0442\u0430\u043a\u043e\u0433\u043e \u043d\u0435 \u043f\u0440\u043e\u0438\u0441\u0445\u043e\u0434\u0438\u0442, \u0437\u043d\u0430\u0447\u0438\u0442 \u043c\u044b \u0432\u044b\u0431\u0440\u0430\u043b\u0438 \u043d\u0435\u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u044d\u043f\u043e\u0445 \u0438 \u0441\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u0435 \u043c\u0435\u0442\u043e\u0434\u043e\u0432 \u0431\u0443\u0434\u0435\u0442 \u043b\u0438\u0448\u044c \u043e\u0447\u0435\u043d\u044c \u043f\u0440\u0438\u0431\u043b\u0438\u0437\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u043c \u0438 \u043d\u0435\u043d\u0430\u0434\u0435\u0436\u043d\u044b\u043c. \u041d\u043e \u0434\u043b\u044f \u043d\u0430\u0434\u0435\u0436\u043d\u043e\u0439 \u043e\u0446\u0435\u043d\u043a\u0438 \u043f\u043e\u0442\u0440\u0435\u0431\u0443\u0435\u0442\u0441\u044f \u0433\u043e\u0440\u0430\u0437\u0434\u043e \u0431\u043e\u043b\u044c\u0448\u0435 \u0432\u0440\u0435\u043c\u0435\u043d\u0438 (\u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u0431\u043e\u043b\u0435\u0435 \u0441\u0443\u0442\u043e\u043a \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0439 \u0432 Colab, \u0447\u0442\u043e \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u0442\u043e\u043b\u044c\u043a\u043e \u043f\u0440\u0438 \u043f\u043b\u0430\u0442\u043d\u043e\u0439 \u043f\u043e\u0434\u043f\u0438\u0441\u043a\u0435), \u0438 \u043a \u0442\u043e\u043c\u0443 \u0436\u0435 \u043f\u0440\u0438 \u0434\u0440\u0443\u0433\u0438\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u0445 \u0440\u0430\u0441\u043a\u043b\u0430\u0434 \u043c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \u0441\u043e\u0432\u0441\u0435\u043c \u0438\u043d\u043e\u0439. \u041f\u043e\u044d\u0442\u043e\u043c\u0443 \u0435\u0441\u043b\u0438 \u043c\u044b \u043d\u0435 \u0433\u043e\u0442\u043e\u0432\u044b \u0433\u043b\u0443\u0431\u043e\u043a\u043e \u0438\u0437\u0443\u0447\u0430\u0442\u044c \u044d\u0442\u0443 \u0437\u0430\u0434\u0430\u0447\u0443 \u0438 \u043f\u044b\u0442\u0430\u0442\u044c\u0441\u044f \u0442\u0435\u043e\u0440\u0435\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u043e\u0431\u043e\u0441\u043d\u043e\u0432\u044b\u0432\u0430\u0442\u044c \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b, \u0442\u043e \u043f\u0440\u0438\u0434\u0435\u0442\u0441\u044f \u0434\u043e\u0432\u043e\u043b\u044c\u0441\u0442\u0432\u043e\u0432\u0430\u0442\u044c\u0441\u044f \u043b\u0438\u0448\u044c \u043d\u0435\u043d\u0430\u0434\u0435\u0436\u043d\u044b\u043c\u0438 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0430\u043b\u044c\u043d\u044b\u043c\u0438 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430\u043c\u0438.\n\n\u0421 \u0434\u0440\u0443\u0433\u043e\u0439 \u0441\u0442\u043e\u0440\u043e\u043d\u044b \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u043e\u0434\u0438\u043d \u0440\u0430\u0437 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0430\u043b\u044c\u043d\u044b\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u043f\u043e\u0441\u043b\u0443\u0436\u0430\u0442 \u043d\u0430\u043c \u0437\u0430\u0442\u0435\u043c \u0432 \u0442\u0435\u0447\u0435\u043d\u0438\u0435 \u0434\u043e\u043b\u0433\u043e\u0433\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0438 (\u0435\u0441\u043b\u0438 \u043c\u044b \u043a\u043e\u043d\u0435\u0447\u043d\u043e \u043d\u0435 \u0431\u0443\u0434\u0435\u043c \u0434\u0435\u0440\u0436\u0430\u0442\u044c\u0441\u044f \u0437\u0430 \u043d\u0438\u0445 \u043a\u0430\u043a \u0437\u0430 \u0434\u043e\u0433\u043c\u0443 \u0438 \u043f\u043e\u043c\u043d\u0438\u0442\u044c, \u0447\u0442\u043e \u0440\u0430\u0437\u043d\u043e\u043e\u0431\u0440\u0430\u0437\u0438\u0435 \u0437\u0430\u0434\u0430\u0447 \u0438 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440 \u0441\u043b\u0438\u0448\u043a\u043e\u043c \u0432\u0435\u043b\u0438\u043a\u043e, \u0438 \u0432\u0441\u0435 \u043c\u0435\u043d\u044f\u0435\u0442\u0441\u044f \u043e\u0442 \u0441\u043b\u0443\u0447\u0430\u044f \u043a \u0441\u043b\u0443\u0447\u0430\u044e).\n\n**\u0415\u0441\u043b\u0438 \u0441\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u043d\u0430 \u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u0432\u044b\u0448\u0435, \u0442\u043e \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0440\u0430\u0437\u043b\u0438\u0447\u0438\u044f \u0432 \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e\u0441\u0442\u0438 \u043c\u0435\u0442\u043e\u0434\u043e\u0432 \u043d\u0435 \u0432\u0438\u0434\u043d\u043e, \u0430 \u0447\u0442\u043e\u0431\u044b \u0443\u0432\u0438\u0434\u0435\u0442\u044c \u043d\u0435\u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0435 \u0440\u0430\u0437\u043b\u0438\u0447\u0438\u0435, \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a\u0438 \u043d\u0435\u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e. \u042f\u0432\u043d\u043e \u043d\u0435\u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0442\u0430\u043a\u0436\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u044d\u043f\u043e\u0445.**\n\n\u0412\u043e\u0437\u043c\u043e\u0436\u043d\u043e, \u0432\u043c\u0435\u0441\u0442\u043e \u0441\u0430\u043c\u043e\u0441\u0442\u043e\u044f\u0442\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u0430\u043d\u0430\u043b\u0438\u0437\u0430 \u0441\u0442\u043e\u0438\u0442 \u043e\u0431\u0440\u0430\u0442\u0438\u0442\u044c\u0441\u044f \u043a \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c \u0438 \u0441\u0442\u0430\u0442\u044c\u044f\u043c \u0438\u0437 \u0438\u043d\u0442\u0435\u0440\u043d\u0435\u0442\u0430, \u0442\u0430\u043a \u043a\u0430\u043a \u044f\u0441\u043d\u043e, \u0447\u0442\u043e \u0441 \u0442\u0430\u043a\u0438\u043c \u0432\u043e\u043f\u0440\u043e\u0441\u043e\u043c \u0441\u0442\u0430\u043b\u043a\u0438\u0432\u0430\u044e\u0442\u0441\u044f \u043f\u043e\u0447\u0442\u0438 \u0432\u0441\u0435, \u043a\u0442\u043e \u0440\u0435\u0448\u0430\u0435\u0442 \u0437\u0430\u0434\u0430\u0447\u0438 \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0438\u044f.\n\n\u041c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u044b: [1](https:\/\/stackoverflow.com\/questions\/47697622\/cnn-image-resizing-vs-padding-keeping-aspect-ratio-or-not\/49882055#49882055), [2](https:\/\/datascience.stackexchange.com\/questions\/27138\/how-to-correctly-resize-input-images-in-a-cnn), [3](https:\/\/benanne.github.io\/2015\/03\/17\/plankton.html#prepro-augmentation), [4](https:\/\/stackoverflow.com\/questions\/41907598\/how-to-format-the-image-data-for-training-prediction-when-images-are-different-i), [5](https:\/\/forums.fast.ai\/t\/impact-of-image-resizing-on-model-training-time-and-performance\/1980).\n\n\u0412\u0441\u0435-\u0442\u0430\u043a\u0438 \u043a\u0430\u0436\u0435\u0442\u0441\u044f, \u0447\u0442\u043e \u0447\u0442\u043e\u0431\u044b \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u0432\u044b\u0448\u0435 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0430\u043b\u044c\u043d\u044b\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0438\u043c\u0435\u043b\u0438 \u0431\u043e\u043b\u044c\u0448\u0443\u044e \u0446\u0435\u043d\u043d\u043e\u0441\u0442\u044c, \u0441\u0442\u043e\u0438\u043b\u043e \u0431\u044b \u043f\u043e\u0432\u0442\u043e\u0440\u0438\u0442\u044c \u0438\u0445 \u0441 \u0431\u043e\u043b\u044c\u0448\u0438\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e\u043c \u044d\u043f\u043e\u0445 \u0438 \u0441 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0435\u0439 \u0434\u0430\u043d\u043d\u044b\u0445 (\u043a\u043e\u0442\u043e\u0440\u0443\u044e \u043c\u044b \u0435\u0449\u0435 \u043d\u0435 \u0440\u0435\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u043b\u0438). \u0415\u0441\u043b\u0438 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0432\u0441\u0435 \u0440\u0430\u0432\u043d\u043e \u0431\u0443\u0434\u0435\u0442 \u0431\u043b\u0438\u0437\u043a\u0430, \u0442\u043e \u0441\u043b\u0435\u0434\u0443\u0435\u0442 \u043e\u0442\u0434\u0430\u0442\u044c \u043f\u0440\u0435\u0434\u043f\u043e\u0447\u0442\u0435\u043d\u0438\u0435 \u043c\u0435\u0442\u043e\u0434\u0430\u043c pad \u0438\u043b\u0438 multipad, \u043f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443 \u043e\u043d\u0438 \u0434\u0430\u044e\u0442 \u0431\u043e\u043b\u044c\u0448\u0435 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u0435\u0439 \u0434\u043b\u044f \u043f\u043e\u0432\u043e\u0440\u043e\u0442\u043e\u0432 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0434\u043b\u044f \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0431\u0435\u0437 \u043f\u043e\u0442\u0435\u0440\u0438 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438.\n\n\u041c\u0435\u0442\u043e\u0434 pad \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u0434\u0430\u0441\u0442 \u0438 \u0435\u0449\u0435 \u043e\u0434\u043d\u043e \u043f\u0440\u0435\u0438\u043c\u0443\u0449\u0435\u0441\u0442\u0432\u043e. \u0415\u0441\u043b\u0438 \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u043e\u0441\u0443\u0449\u0435\u0441\u0442\u0432\u043b\u044f\u0442\u044c \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f, \u0432\u044b\u0440\u0435\u0437\u0430\u044f \u0438\u0437 \u043d\u0435\u0433\u043e \u043a\u0443\u0441\u043a\u0438 \u0438 \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u044f \u0438\u0445 \u043e\u0434\u043d\u043e\u0446\u0432\u0435\u0442\u043d\u044b\u043c\u0438 \u043a\u0432\u0430\u0434\u0440\u0430\u0442\u0430\u043c\u0438, \u0442\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0430\u044f \u043d\u0430 \u043c\u0435\u0442\u043e\u0434\u0435 pad \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u044c \u0431\u044b\u0441\u0442\u0440\u0435\u0435 \u043f\u043e\u0439\u043c\u0435\u0442, \u0447\u0442\u043e \u0442\u0430\u043a\u0438\u0435 \u043a\u0432\u0430\u0434\u0440\u0430\u0442\u044b \u043d\u0443\u0436\u043d\u043e \u0438\u0433\u043d\u043e\u0440\u0438\u0440\u043e\u0432\u0430\u0442\u044c. \u0414\u0435\u043b\u043e \u0432 \u0442\u043e\u043c, \u0447\u0442\u043e \u0432 \u044d\u0442\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435 \u0442\u0430\u043a\u043e\u0439 \u0436\u0435 \u043c\u043e\u043d\u043e\u0442\u043e\u043d\u043d\u044b\u0439 \u0446\u0432\u0435\u0442 \u043d\u0430\u0445\u043e\u0434\u0438\u0442\u0441\u044f \u043f\u043e \u043a\u0440\u0430\u044f\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f, \u0442\u043e \u0435\u0441\u0442\u044c \u043e\u043d \u0447\u0430\u0449\u0435 \u0432\u0441\u0442\u0440\u0435\u0447\u0430\u0435\u0442\u0441\u044f.\n\n**\u041f\u043e\u044d\u0442\u043e\u043c\u0443 \u043f\u043e\u043a\u0430 \u0447\u0442\u043e \u0432\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u043c\u0435\u0442\u043e\u0434 pad**.\n\n\u041a\u0441\u0442\u0430\u0442\u0438, \u043d\u0443\u0436\u043d\u043e \u043f\u043e\u043c\u043d\u0438\u0442\u044c, \u0447\u0442\u043e \u043c\u0435\u0442\u043e\u0434 \u0440\u0435\u0441\u0430\u0439\u0437\u0438\u043d\u0433\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u043f\u0440\u0438\u043c\u0435\u0440\u0430\u0445 \u0432\u043e\u0432\u0441\u0435 \u043d\u0435 \u043e\u0431\u044f\u0437\u0430\u043d \u0431\u044b\u0442\u044c \u0442\u0430\u043a\u0438\u043c \u0436\u0435, \u043a\u0430\u043a \u0432 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u043f\u0440\u0438\u043c\u0435\u0440\u0430\u0445. \u041d\u043e \u0432 \u0442\u0430\u043a\u0438\u0445 \u0441\u043b\u0443\u0447\u0430\u044f\u0445 \u0447\u0442\u043e\u0431\u044b \u043f\u0435\u0440\u0435\u0431\u0440\u0430\u0442\u044c \u0432\u0441\u0435 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u044b \u043f\u043e\u0442\u0440\u0435\u0431\u0443\u0435\u0442\u0441\u044f \u0433\u043e\u0440\u0430\u0437\u0434\u043e \u0431\u043e\u043b\u044c\u0448\u0435 \u0432\u0440\u0435\u043c\u0435\u043d\u0438.\n\n\u0418 \u0435\u0449\u0435 \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u0442\u0435\u043e\u0440\u0435\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0440\u0430\u0441\u0441\u0443\u0436\u0434\u0435\u043d\u0438\u0439. \u041d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u044c, \u0441\u043e\u0441\u0442\u043e\u044f\u0449\u0430\u044f \u0442\u043e\u043b\u044c\u043a\u043e \u0438\u0437 \u0441\u0432\u0435\u0440\u0442\u043e\u0447\u043d\u044b\u0445 \u0441\u043b\u043e\u0435\u0432, \u043d\u0435 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u0438\u043d\u0432\u0430\u0440\u0438\u0430\u043d\u0442\u043d\u043e\u0439 \u043a \u0440\u0430\u0441\u0442\u044f\u0436\u0435\u043d\u0438\u0435\u043c, \u043d\u043e \u0441\u0432\u0435\u0440\u0442\u043e\u0447\u043d\u0430\u044f \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u044c, \u0441\u043e\u0434\u0435\u0436\u0430\u0449\u0430\u044f \u0441\u043b\u043e\u0438 max pooling, \u0432 \u043a\u0430\u043a\u043e\u0439-\u0442\u043e \u0441\u0442\u0435\u043f\u0435\u043d\u0438 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f. \u0411\u043e\u043b\u044c\u0448\u043e\u0435 \u0440\u0435\u0446\u0435\u043f\u0442\u0438\u0432\u043d\u043e\u0435 \u043f\u043e\u043b\u0435 \u0444\u0438\u043b\u044c\u0442\u0440\u043e\u0432 \u043e\u0431\u0435\u0441\u043f\u0435\u0447\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u0432 \u043e\u0441\u043d\u043e\u0432\u043d\u043e\u043c \u043d\u0430\u043b\u0438\u0447\u0438\u0435\u043c \u0441\u043b\u043e\u0435\u0432 max pooling. \u041a\u0430\u0436\u0434\u044b\u0439 \u0441\u043b\u043e\u0439 max pooling \u0432\u043d\u043e\u0441\u0438\u0442 \u0441\u0432\u043e\u0439 \u0432\u043a\u043b\u0430\u0434 \u0432 \u0438\u043d\u0432\u0430\u0440\u0438\u0430\u043d\u0442\u043d\u043e\u0441\u0442\u044c \u043f\u043e \u0440\u0430\u0441\u0442\u044f\u0436\u0435\u043d\u0438\u044f\u043c: \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f \u0430\u043a\u0442\u0438\u0432\u0430\u0446\u0438\u044f \u043d\u0438\u0436\u0435\u043b\u0435\u0436\u0430\u0449\u0435\u0433\u043e \u0444\u0438\u043b\u044c\u0442\u0440\u0430 \u043a\u0430\u0436\u0434\u044b\u0439 \u0440\u0430\u0437 \u043c\u043e\u0436\u0435\u0442 \u0434\u043e\u0441\u0438\u0433\u0430\u0442\u044c\u0441\u044f \u0447\u0443\u0442\u044c \u0431\u043b\u0438\u0436\u0435 \u0438\u043b\u0438 \u0447\u0443\u0442\u044c \u0434\u0430\u043b\u044c\u0448\u0435 \u043e\u0442 \u0440\u0435\u0446\u0435\u043f\u0442\u0438\u0432\u043d\u043e\u0433\u043e \u043f\u043e\u043b\u044f \u0444\u0438\u043b\u044c\u0442\u0440\u0430, \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0433\u043e \u043f\u043e\u0441\u043b\u0435 \u0441\u043b\u043e\u044f max pooling. \u0412 \u0438\u0442\u043e\u0433\u0435 \u0431\u043e\u043b\u044c\u0448\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u043b\u043e\u0435\u0432 max pooling \u043c\u043e\u0436\u0435\u0442 \u043e\u0431\u0435\u0441\u043f\u0435\u0447\u0438\u0442\u044c \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0441\u0438\u043b\u044c\u043d\u0443\u044e \u043d\u0435\u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c \u0440\u0435\u0448\u0435\u043d\u0438\u044f \u043e\u0442 \u0440\u0430\u0441\u0442\u044f\u0436\u0435\u043d\u0438\u044f \u0438\u043b\u0438 \u0441\u0436\u0430\u0442\u0438\u044f \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u0435\u043c\u043e\u0433\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u0430 \u0438 \u0434\u0430\u0436\u0435 \u043e\u0442 \u0431\u043e\u043b\u0435\u0435 \u0441\u043b\u043e\u0436\u043d\u043e\u0439 \u0435\u0433\u043e \u0434\u0435\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438.","cf6300e4":"**sample-submission.csv** - \u043f\u0440\u0438\u043c\u0435\u0440 \u0434\u0430\u043d\u043d\u044b\u0445, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0443\u0436\u043d\u043e \u0431\u0443\u0434\u0435\u0442 \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u043d\u0430 kaggle \u043f\u043e\u0441\u043b\u0435 \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0438\u044f \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438. \u0424\u043e\u0440\u043c\u0430\u0442: \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f, \u043d\u043e\u043c\u0435\u0440 \u043a\u043b\u0430\u0441\u0441\u0430; \u0432 \u0444\u0430\u0439\u043b\u0435 \u0443 \u0432\u0441\u0435\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u043d\u043e\u043c\u0435\u0440 \u043a\u043b\u0430\u0441\u0441\u0430 0, \u043f\u043e\u0442\u043e\u043c\u0443 \u0447\u0442\u043e \u044d\u0442\u043e \u043b\u0438\u0448\u044c \u043f\u0440\u0438\u043c\u0435\u0440.\n\n**test.zip** \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435, \u0432\u0441\u0435\u0433\u043e 6675 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0440\u0430\u0437\u043d\u044b\u0445 \u0440\u0430\u0437\u043c\u0435\u0440\u043e\u0432.\n\n**train.zip** \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 \u043f\u0430\u043f\u043a\u0438 \u0441 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f\u043c\u0438 0, 1, ..., 9, \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u043c\u0438 \u043d\u043e\u043c\u0435\u0440\u0443 \u043a\u043b\u0430\u0441\u0441\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f. \u0412 \u043a\u0430\u0436\u0434\u043e\u0439 \u043f\u0430\u043f\u043a\u0435 \u043f\u0440\u043e\u043d\u0443\u043c\u0435\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 219226.jpg, \u043d\u043e \u043d\u043e\u043c\u0435\u0440\u0430 \u043d\u0435 \u043d\u0430\u0447\u0438\u043d\u0430\u044e\u0442\u0441\u044f \u0441 \u0435\u0434\u0438\u043d\u0438\u0446\u044b. \u0412\u0441\u0435\u0433\u043e 15561 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435.\n\n**train.csv** \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 \u0441\u043f\u0438\u0441\u043e\u043a \u0432\u0441\u0435\u0445 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439.\n\n\u0412 Kaggle kernel \u043c\u043e\u0436\u043d\u043e \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u0444\u0430\u0439\u043b\u044b \u0442\u043e\u043b\u044c\u043a\u043e \u0432 \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044e `\/kaggle\/working`. \u0420\u0430\u0441\u043f\u0430\u043a\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f: \u043f\u0430\u043f\u043a\u0438 \u0441 \u043a\u043b\u0430\u0441\u0441\u0430\u043c\u0438 \u0438\u0437 train.zip \u0431\u0443\u0434\u0443\u0442 \u043d\u0430\u0445\u043e\u0434\u0438\u0442\u044c\u0441\u044f \u0432 \u043f\u0430\u043f\u043a\u0435 `\/kaggle\/working\/train`, \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0438\u0437 test.zip \u0431\u0443\u0434\u0443\u0442 \u043d\u0430\u0445\u043e\u0434\u0438\u0442\u044c\u0441\u044f \u0432 \u043f\u0430\u043f\u043a\u0435 `\/kaggle\/working\/test_upload`.","7859022b":"# \u0421\u043a\u0430\u0447\u0438\u0432\u0430\u0435\u043c \u0438 \u0440\u0430\u0441\u043f\u0430\u043a\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442\n\n\u0412 Kaggle kernel \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u0434\u043e\u0441\u0442\u0443\u043f\u0435\u043d \u0441\u0440\u0430\u0437\u0443 \u0432 \u043f\u0430\u043f\u043a\u0435 \/kaggle\/input\/sf-dl-car-classification, \u043d\u043e \u0435\u0433\u043e \u043d\u0443\u0436\u043d\u043e \u0440\u0430\u0441\u043f\u0430\u043a\u043e\u0432\u0430\u0442\u044c. \u0412 Colab \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u043d\u0443\u0436\u043d\u043e \u0441\u043d\u0430\u0447\u0430\u043b\u0430 \u0441\u043a\u0430\u0447\u0430\u0442\u044c.","aa078272":"\u0422\u0435\u043f\u0435\u0440\u044c \u0441\u043a\u043e\u043f\u0438\u0440\u0443\u0435\u043c \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u0444\u0430\u0439\u043b\u044b \u0432 Google cloud. \u042f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e \u0441\u0432\u043e\u0439 bucket.","796455ea":"# \u041a\u0430\u043d\u0430\u043b\u044b \u0432\u0445\u043e\u0434\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439\n\n\u0412\u0430\u0440\u0438\u0430\u043d\u0442\u044b:\n* RGB\n* Gray, 0, 0\n* Gray, Sobel X, Sobel Y\n* Gray, Sobel, Sobel(scale=3)\n\n\u0421 \u043e\u0434\u043d\u043e\u0439 \u0441\u0442\u043e\u0440\u043e\u043d\u044b, \u0441\u0432\u0435\u0440\u0442\u043e\u0447\u043d\u044b\u0435 \u0441\u043b\u043e\u0438 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438 \u0441\u0430\u043c\u0438 \u0441\u043f\u043e\u0441\u043e\u0431\u043d\u044b \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0442\u044c \u0442\u0430\u043a\u0438\u0435 \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0438, \u043a\u0430\u043a \u043e\u043f\u0435\u0440\u0430\u0442\u043e\u0440 \u0421\u043e\u0431\u0435\u043b\u044f \u0438\u043b\u0438 \u043e\u0431\u0435\u0441\u0446\u0432\u0435\u0447\u0438\u0432\u0430\u043d\u0438\u0435. \u0421 \u0434\u0440\u0443\u0433\u043e\u0439 \u0441\u0442\u043e\u0440\u043e\u043d\u044b, \u043e\u0431\u0435\u0441\u0446\u0432\u0435\u0447\u0438\u0432\u0430\u043d\u0438\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u043c\u043e\u0436\u0435\u0442 \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u044c \u043e\u0431\u043e\u0431\u0449\u0430\u044e\u0449\u0443\u044e \u0441\u043f\u043e\u0441\u043e\u0431\u043d\u043e\u0441\u0442\u044c \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0438, \u0442\u0430\u043a \u043a\u0430\u043a \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u044c \u043f\u0435\u0440\u0435\u0441\u0442\u0430\u043d\u0435\u0442 \u043e\u0440\u0438\u0435\u043d\u0442\u0438\u0440\u043e\u0432\u0430\u0442\u044c\u0441\u044f \u043d\u0430 \u0446\u0432\u0435\u0442 \u0432 \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0438\u0438. \u0425\u043e\u0442\u044f \u043a\u043e\u043d\u0435\u0447\u043d\u043e \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e, \u0447\u0442\u043e \u0446\u0432\u0435\u0442 \u043a\u0430\u043a-\u0442\u043e \u043f\u043e\u043c\u043e\u0433\u0430\u0435\u0442 \u0440\u0430\u0437\u043b\u0438\u0447\u0430\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u0430\u0432\u0442\u043e\u043c\u043e\u0431\u0438\u043b\u0435\u0439, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 \u0443 \u043e\u0434\u043d\u043e\u0439 \u0438\u0437 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u0444\u0430\u0440\u044b \u043a\u0440\u0430\u0441\u043d\u0435\u0435, \u0447\u0435\u043c \u0443 \u0434\u0440\u0443\u0433\u0438\u0445, \u043d\u043e \u044d\u0442\u043e \u0432\u0441\u0435 \u0440\u0430\u0432\u043d\u043e \u0441\u0438\u0442\u0443\u0430\u0442\u0438\u0432\u043d\u043e \u0438 \u043d\u0435 \u0434\u0430\u0441\u0442 100%-\u044e \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c, \u0442\u043e\u0433\u0434\u0430 \u043a\u0430\u043a \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0438\u0435 \u0444\u043e\u0440\u043c\u044b \u043c\u043e\u0436\u0435\u0442 \u0434\u0430\u0442\u044c (\u0435\u0441\u043b\u0438 \u043a\u043e\u043d\u0435\u0447\u043d\u043e \u0432 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u043d\u0430\u0431\u043e\u0440\u0435 \u043d\u0435\u0442 \u043d\u0435\u0432\u0435\u0440\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445).","5e3ea765":"\u0424\u0430\u0439\u043b\u044b \u0437\u0430\u0433\u0440\u0443\u0436\u0435\u043d\u044b \u0432 Google cloud.","9d3ae782":"\u0418\u0441\u0445\u043e\u0434\u044f \u0438\u0437 [\u0441\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u044f](https:\/\/www.drom.ru\/compare\/lada-2109-vs-lada-21099.html) \u0430\u0432\u0442\u043e\u043c\u043e\u0431\u0438\u043b\u0435\u0439 \u0412\u0410\u0417-2109 \u0438 \u0412\u0410\u0417-21099, \u0432 \u0444\u043e\u0440\u043c\u0435 \u043f\u0435\u0440\u0435\u0434\u043d\u0435\u0439 \u0447\u0430\u0441\u0442\u0438 \u0432\u0441\u0435 \u0436\u0435 \u0435\u0441\u0442\u044c \u043d\u0435\u0431\u043e\u043b\u044c\u0448\u0438\u0435 \u043e\u0442\u043b\u0438\u0447\u0438\u044f. \u0412\u043e\u0437\u043c\u043e\u0436\u043d\u043e, \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u044c \u043d\u0430\u0447\u043d\u0435\u0442 \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u0442\u044c \u044d\u0442\u0438 \u043a\u043b\u0430\u0441\u0441\u044b \u043b\u0443\u0447\u0448\u0435, \u0435\u0441\u043b\u0438 \u0434\u043b\u044f \u044d\u0442\u0438\u0445 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0431\u0443\u0434\u0435\u0442 \u0431\u043e\u043b\u044c\u0448\u0435 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0445 \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432. \u041a\u0441\u0442\u0430\u0442\u0438 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 \u043e \u0446\u0432\u0435\u0442\u0435 \u0443\u043b\u0443\u0447\u0448\u0430\u0435\u0442 \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0438\u0435 \u044d\u0442\u0438\u0445 \u043a\u043b\u0430\u0441\u0441\u043e\u0432.","5ec53243":"# \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u0444\u0430\u0439\u043b\u044b .tfrec \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043d\u0430 TPU\n\n\u041c\u044b \u0431\u0443\u0434\u0435\u043c \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0441 `tf.data.Dataset`. Dataset \u0445\u0440\u0430\u043d\u0438\u0442 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e \u043e \u043a\u043e\u043d\u0435\u0447\u043d\u043e\u043c \u0438\u043b\u0438 \u0431\u0435\u0441\u043a\u043e\u043d\u0435\u0447\u043d\u043e\u043c \u043d\u0430\u0431\u043e\u0440\u0435 \u043a\u043e\u0440\u0442\u0435\u0436\u0435\u0439 (tuple) \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438 \u0438 \u043c\u043e\u0436\u0435\u0442 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0442\u044c \u044d\u0442\u0438 \u043d\u0430\u0431\u043e\u0440\u044b \u043f\u043e \u043e\u0447\u0435\u0440\u0435\u0434\u0438. \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0434\u0430\u043d\u043d\u044b\u043c\u0438 \u043c\u043e\u0433\u0443\u0442 \u0431\u044b\u0442\u044c \u043f\u0430\u0440\u044b (input, target) \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0438. \u0421 \u0434\u0430\u043d\u043d\u044b\u043c\u0438 \u043c\u043e\u0436\u043d\u043e \u043e\u0441\u0443\u0449\u0435\u0441\u0442\u0432\u043b\u044f\u0442\u044c \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043e\u0441\u0443\u0449\u0435\u0441\u0442\u0432\u043b\u044f\u044e\u0442\u0441\u044f \u043f\u043e \u043c\u0435\u0440\u0435 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438 ([lazy evaluation](https:\/\/ru.wikipedia.org\/wiki\/%D0%9B%D0%B5%D0%BD%D0%B8%D0%B2%D1%8B%D0%B5_%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F)).\n\n`tf.data.Dataset.from_tensor_slices(data)` - \u0441\u043e\u0437\u0434\u0430\u0435\u0442 \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u044e\u0442 \u0441\u043e\u0431\u043e\u0439 \u043b\u0438\u0431\u043e \u043c\u0430\u0441\u0441\u0438\u0432, \u043b\u0438\u0431\u043e \u043a\u043e\u0440\u0442\u0435\u0436 \u0438\u0437 \u043c\u0430\u0441\u0441\u0438\u0432\u043e\u0432. \u0414\u0435\u043b\u0435\u043d\u0438\u0435 \u043e\u0441\u0443\u0449\u0435\u0441\u0442\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043f\u043e \u043f\u0435\u0440\u0432\u043e\u043c\u0443 \u0438\u043d\u0434\u0435\u043a\u0441\u0443 \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043c\u0430\u0441\u0441\u0438\u0432\u0430. \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0435\u0441\u043b\u0438 `data = (np.zeros((128, 256, 256)), np.zeros(128))`, \u0442\u043e \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u0431\u0443\u0434\u0435\u0442 \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0442\u044c 128 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432, \u043a\u0430\u0436\u0434\u044b\u0439 \u0438\u0437 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 \u043e\u0434\u0438\u043d \u043c\u0430\u0441\u0441\u0438\u0432 256x256 \u0438 \u043e\u0434\u043d\u043e \u0447\u0438\u0441\u043b\u043e.\n\n`dataset2 = dataset1.map(func)` - \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043a \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0443; \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043e\u043b\u0436\u043d\u0430 \u043f\u0440\u0438\u043d\u0438\u043c\u0430\u0442\u044c \u0441\u0442\u043e\u043b\u044c\u043a\u043e \u0430\u0440\u0433\u0443\u043c\u0435\u043d\u0442\u043e\u0432, \u043a\u0430\u043a\u043e\u0432 \u0440\u0430\u0437\u043c\u0435\u0440 \u043a\u043e\u0440\u0442\u0435\u0436\u0430 \u0432 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435 1 \u0438 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0442\u044c \u0441\u0442\u043e\u043b\u044c\u043a\u043e, \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043d\u0443\u0436\u043d\u043e \u0438\u043c\u0435\u0442\u044c \u0432 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435 2. \u041f\u0443\u0441\u0442\u044c, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0438 \u043c\u0435\u0442\u043a\u0438, \u0430 \u043d\u0430\u043c \u043d\u0443\u0436\u043d\u043e \u0441\u043e\u0437\u0434\u0430\u0442\u044c \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u0442\u043e\u043b\u044c\u043a\u043e \u0438\u0437 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439, \u0442\u043e\u0433\u0434\u0430 \u043c\u044b \u043d\u0430\u043f\u0438\u0448\u0435\u043c \u0442\u0430\u043a: `dataset2 = dataset.map(lambda img, label: img)`.\n\n`dataset2 = dataset1.batch(8)` - \u0433\u0440\u0443\u043f\u043f\u0438\u0440\u043e\u0432\u043a\u0430 \u043f\u043e \u0431\u0430\u0442\u0447\u0430\u043c; \u0435\u0441\u043b\u0438 \u0434\u0430\u0442\u0430\u0441\u0435\u0442 2 \u0434\u043e\u043b\u0436\u0435\u043d \u0432\u0435\u0440\u043d\u0443\u0442\u044c \u043e\u0434\u0438\u043d \u044d\u043b\u0435\u043c\u0435\u043d\u0442, \u0442\u043e \u043e\u043d \u0431\u0435\u0440\u0435\u0442 \u0438\u0437 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 1 \u0432\u043e\u0441\u0435\u043c\u044c \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432, \u0441\u043a\u043b\u0435\u0438\u0432\u0430\u0435\u0442 \u0438\u0445 (\u043d\u0443\u043b\u0435\u0432\u043e\u0439 \u0438\u043d\u0434\u0435\u043a\u0441 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430 - \u043d\u043e\u043c\u0435\u0440 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u0430) \u0438 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442.\n\n`dataset.__iter__()` - \u043f\u0440\u0435\u0432\u0440\u0430\u0449\u0435\u043d\u0438\u0435 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 \u0432 \u0438\u0442\u0435\u0440\u0430\u0442\u043e\u0440, \u0438\u0437 \u043a\u043e\u0442\u043e\u0440\u043e\u0433\u043e \u043c\u043e\u0436\u043d\u043e \u043f\u043e\u043b\u0443\u0447\u0430\u0442\u044c \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u044b \u043c\u0435\u0442\u043e\u0434\u043e\u043c `.__next__()`. \u0418\u0442\u0435\u0440\u0430\u0442\u043e\u0440, \u0432 \u043e\u0442\u043b\u0438\u0447\u0438\u0435 \u043e\u0442 \u0441\u0430\u043c\u043e\u0433\u043e \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430, \u0445\u0440\u0430\u043d\u0438\u0442 \u043f\u043e\u0437\u0438\u0446\u0438\u044e \u0442\u0435\u043a\u0443\u0449\u0435\u0433\u043e \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u0430. \u041c\u043e\u0436\u043d\u043e \u0442\u0430\u043a\u0436\u0435 \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0442\u044c \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u0446\u0438\u043a\u043b\u043e\u043c for.\n\n`dataset2 = dataset1.repeat(X)` - \u0434\u0430\u0442\u0430\u0441\u0435\u0442 2 \u0431\u0443\u0434\u0435\u0442 \u043f\u043e\u0432\u0442\u043e\u0440\u044f\u0442\u044c \u0434\u0430\u0442\u0430\u0441\u0435\u0442 1 X \u0440\u0430\u0437.\n\n\u0415\u0441\u043b\u0438 \u043d\u0430\u043c \u043d\u0443\u0436\u043d\u043e \u0432\u0437\u044f\u0442\u044c \u0438\u0437 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 1000 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432 \u0438 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0438\u0445 \u043a\u0430\u043a \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435, \u0430 \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0435 \u043a\u0430\u043a \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0435, \u0442\u043e \u043c\u044b \u043d\u0430\u043f\u0438\u0448\u0435\u043c \u0442\u0430\u043a:\n\n`test_dataset = dataset.take(1000)\ntrain_dataset = dataset.skip(1000)`\n\n\u0414\u0430\u0442\u0430\u0441\u0435\u0442 \u043f\u043e \u0441\u0443\u0442\u0438 \u043d\u0435\u0438\u0437\u043c\u0435\u043d\u0435\u043d: \u0442\u0430\u043a\u0438\u0435 \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0438, \u043a\u0430\u043a map, batch, repeat, take, skip \u043d\u0438\u043a\u0430\u043a \u043d\u0435 \u0437\u0430\u0442\u0440\u0430\u0433\u0438\u0432\u0430\u044e\u0442 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u044c\u043d\u044b\u0439 \u0434\u0430\u0442\u0430\u0441\u0435\u0442. \u0415\u0441\u043b\u0438 \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u0445\u0440\u0430\u043d\u0438\u0442 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u044b [1, 2, 3], \u0442\u043e \u0432\u044b\u043f\u043e\u043b\u043d\u0438\u0432 3 \u0440\u0430\u0437\u0430 \u043f\u043e\u0434\u0440\u044f\u0434 \u0444\u0443\u043d\u043a\u0446\u0438\u044e dataset.take(1) \u043c\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u043c 3 \u043d\u043e\u0432\u044b\u0445 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430, \u043a\u0430\u0436\u0434\u044b\u0439 \u0438\u0437 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0432\u0435\u0440\u043d\u0435\u0442 \u0447\u0438\u0441\u043b\u043e 1. \u0415\u0441\u043b\u0438 \u0436\u0435 \u043c\u044b \u0432\u044b\u043f\u043e\u043b\u043d\u0438\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044e dataset.skip(1), \u043c\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442, \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u044e\u0449\u0438\u0439 \u0447\u0438\u0441\u043b\u0430 [2, 3], \u043d\u043e \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0439 \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u0432\u0441\u0435 \u0440\u0430\u0432\u043d\u043e \u0431\u0443\u0434\u0435\u0442 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0442\u044c [1, 2, 3] \u043a\u0430\u0436\u0434\u044b\u0439 \u0440\u0430\u0437, \u043a\u043e\u0433\u0434\u0430 \u043c\u044b \u0435\u0433\u043e \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0435\u043c.","24cfcb1a":"\u041f\u043e\u0441\u043b\u0435 15 \u044d\u043f\u043e\u0445 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0438\u043c\u0435\u0440\u043d\u043e \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u0430, \u043d\u043e \u043c\u0435\u0442\u043e\u0434 global max pooling \u0441\u0445\u043e\u0434\u0438\u0442\u0441\u044f \u0431\u044b\u0441\u0442\u0440\u0435\u0435, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0432\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u0435\u0433\u043e.","3dabab33":"\u0421\u043a\u043b\u0430\u0434\u044b\u0432\u0430\u0435\u0442\u0441\u044f \u043e\u0449\u0443\u0449\u0435\u043d\u0438\u0435, \u0447\u0442\u043e \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0438\u043c\u0438 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0430\u043c\u0438 \u0441 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u043e\u043c \u043c\u044b \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u043e\u0431\u044c\u0435\u043c\u0441\u044f. \u0425\u043e\u0442\u044f \u044d\u0442\u043e \u0432\u043f\u0435\u0447\u0430\u0442\u043b\u0435\u043d\u0438\u0435 \u0438 \u043c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \u043e\u0431\u043c\u0430\u043d\u0447\u0438\u0432\u044b\u043c, \u043d\u043e \u043a \u044d\u0442\u043e\u0439 \u0442\u0435\u043c\u0435 \u043c\u044b \u0432\u0441\u0435\u0433\u0434\u0430 \u0443\u0441\u043f\u0435\u0435\u043c \u0432\u0435\u0440\u043d\u0443\u0442\u044c\u0441\u044f.\n\n**\u041f\u043e\u043a\u0430 \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c adam \u0441 \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u044e\u0449\u0438\u043c\u0441\u044f learning rate:**\n\n**Adam(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0008, decay_steps = 100, decay_rate = 0.9))**\n\n\u041d\u0430\u0434\u043e \u0441\u043a\u0430\u0437\u0430\u0442\u044c, \u0447\u0442\u043e \u043c\u043d\u043e\u0433\u043e\u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0435 \u0442\u0435\u0441\u0442\u044b \u0434\u043b\u044f \u043f\u043e\u0434\u0431\u043e\u0440\u0430 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u0430 \u0438 learning rate - \u0434\u043e\u0432\u043e\u043b\u044c\u043d\u043e \u0441\u043a\u0443\u0447\u043d\u043e\u0435 \u0437\u0430\u043d\u044f\u0442\u0438\u0435. \u0412\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u0434\u0430\u043b\u0435\u0435 \u043c\u044b \u043d\u0430\u0439\u0434\u0435\u043c \u0441\u0440\u0435\u0434\u0441\u0442\u0432\u0430 \u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u043f\u043e\u0434\u0431\u043e\u0440\u0430 \u044d\u0442\u0438\u0445 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432.","4b7f2aa8":"\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u043f\u0440\u0438\u043c\u0435\u0440\u0430\u0445 \u0434\u043e\u0441\u0442\u0438\u0433\u043b\u0430 88% \u043f\u043e\u0441\u043b\u0435 4 \u044d\u043f\u043e\u0445, \u0442\u043e \u0435\u0441\u0442\u044c \u0441\u0438\u043b\u044c\u043d\u043e\u0433\u043e \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u044f \u0438\u043b\u0438 \u0443\u0445\u0443\u0434\u0448\u0435\u043d\u0438\u044f \u043d\u0435 \u0432\u0438\u0434\u043d\u043e. \u0412\u043e\u0437\u043c\u043e\u0436\u043d\u043e, \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u044d\u0442\u0443 \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043f\u0440\u0438 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445.","b78f35c8":"# \u0420\u0430\u0431\u043e\u0442\u0430 \u0441 \u0444\u0430\u0439\u043b\u0430\u043c\u0438 \u0432 Google colab \u0438 Kaggle kernel\n\nGoogle Colab \u0438 Kaggle kernel - \u044d\u0442\u043e \u043d\u0435 \u043f\u0440\u043e\u0441\u0442\u043e \u0438\u043d\u0442\u0435\u0440\u043f\u0440\u0435\u0442\u0430\u0442\u043e\u0440\u044b Python, \u0430 \u043f\u043e\u043b\u043d\u043e\u0446\u0435\u043d\u043d\u044b\u0435 \u0432\u0438\u0440\u0442\u0443\u0430\u043b\u044c\u043d\u044b\u0435 \u043c\u0430\u0448\u0438\u043d\u044b \u043d\u0430 Linux, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0432 \u043d\u0438\u0445 \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u044b shell-\u043a\u043e\u043c\u0430\u043d\u0434\u044b \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0439 \u0441\u0438\u0441\u0442\u0435\u043c\u044b. \u0427\u0442\u043e\u0431\u044b \u0437\u0430\u043f\u0443\u0441\u0442\u0438\u0442\u044c shell-\u043a\u043e\u043c\u0430\u043d\u0434\u0443 \u0432 \u044f\u0447\u0435\u0439\u043a\u0435, \u043d\u0443\u0436\u043d\u043e \u043d\u0430\u0447\u0430\u0442\u044c \u0435\u0435 \u0441\u043e \u0437\u043d\u0430\u043a\u0430 `!`. \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440: `!ls \/` - \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0441\u043f\u0438\u0441\u043e\u043a \u0444\u0430\u0439\u043b\u043e\u0432 \u0438 \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u0439. \u0414\u043e\u0441\u0442\u0443\u043f\u043d\u044b \u0442\u0430\u043a\u0436\u0435 \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043a\u043e\u043c\u0430\u043d\u0434\u044b, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 `!pip` \u0434\u043b\u044f \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0438 \u043f\u0430\u043a\u0435\u0442\u043e\u0432 Python, `!gcloud` \u0438 `!gsutil` \u0434\u043b\u044f \u0440\u0430\u0431\u043e\u0442\u044b \u0441 \u043e\u0431\u043b\u0430\u0447\u043d\u044b\u043c \u0444\u0430\u0439\u043b\u043e\u0432\u044b\u043c \u0445\u0440\u0430\u043d\u0438\u043b\u0438\u0449\u0435\u043c Google cloud storage, `!kaggle` \u0434\u043b\u044f \u0441\u043a\u0430\u0447\u0438\u0432\u0430\u043d\u0438\u044f \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u043e\u0432 Kaggle. \u041d\u0438\u0436\u0435 \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u044d\u0442\u0438 \u043a\u043e\u043c\u0430\u043d\u0434\u044b.\n\n\u0412 Colab \u043f\u0435\u0440\u0435\u0437\u0430\u043f\u0443\u0441\u043a \u0441\u0440\u0435\u0434\u044b \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043d\u0435 \u043f\u0435\u0440\u0435\u0441\u043e\u0437\u0434\u0430\u0435\u0442 \u0432\u0438\u0440\u0442\u0443\u0430\u043b\u044c\u043d\u0443\u044e \u043c\u0430\u0448\u0438\u043d\u0443, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0441\u043e\u0437\u0434\u0430\u043d\u043d\u044b\u0435 \u0444\u0430\u0439\u043b\u044b \u0438 \u0441\u043a\u0430\u0447\u0430\u043d\u043d\u044b\u0435 \u043f\u0430\u043a\u0435\u0442\u044b \u043d\u0435 \u0431\u0443\u0434\u0443\u0442 \u0443\u0434\u0430\u043b\u0435\u043d\u044b. \u0427\u0442\u043e\u0431\u044b \u043f\u0435\u0440\u0435\u0441\u043e\u0437\u0434\u0430\u0442\u044c \u0432\u0438\u0440\u0442\u0443\u0430\u043b\u044c\u043d\u0443\u044e \u043c\u0430\u0448\u0438\u043d\u0443, \u043d\u0443\u0436\u043d\u043e \u0432\u044b\u0431\u0440\u0430\u0442\u044c \u0432 \u043c\u0435\u043d\u044e \"\u0421\u0431\u0440\u043e\u0441\u0438\u0442\u044c \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438 \u0441\u0440\u0435\u0434\u044b \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f\".\n\n\u0415\u0441\u043b\u0438 \u0441\u0440\u0430\u0432\u043d\u0438\u0432\u0430\u0442\u044c Colab \u0438 Kaggle, \u0442\u043e \u0432 Kaggle \u0441\u0435\u0441\u0441\u0438\u044f \u043d\u0430 TPU \u043e\u0442\u043a\u043b\u044e\u0447\u0430\u0435\u0442\u0441\u044f \u0447\u0435\u0440\u0435\u0437 10-20 \u043c\u0438\u043d\u0443\u0442 \u0431\u0435\u0437\u0434\u0435\u0439\u0441\u0442\u0432\u0438\u044f, \u0438 \u0432\u0441\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 \u0442\u0435\u0440\u044f\u044e\u0442\u0441\u044f (\u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u044d\u0442\u043e \u0431\u0430\u0433). \u041a\u0440\u043e\u043c\u0435 \u0442\u043e\u0433\u043e \u0432 Kaggle \u0432\u044b\u0432\u043e\u0434\u044b \u044f\u0447\u0435\u0435\u043a \u043d\u0435 \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u044e\u0442\u0441\u044f, \u0438 \u0432 Colab \u043b\u0443\u0447\u0448\u0435 \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u043e\u0432\u0430\u043d\u0430 \u0440\u0430\u0431\u043e\u0442\u0430 \u0441 shell, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 \u0435\u0441\u0442\u044c \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u0432\u0432\u043e\u0434\u0438\u0442\u044c \u043f\u0430\u0440\u043e\u043b\u0438 \u0438 \u043a\u043b\u044e\u0447\u0438 \u0434\u043e\u0441\u0442\u0443\u043f\u0430 \u043f\u043e \u0437\u0430\u043f\u0440\u043e\u0441\u0443. \u041f\u043e\u044d\u0442\u043e\u043c\u0443 \u044f \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0443\u044e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c Colab.\n\n# \u0422\u0435\u043d\u0437\u043e\u0440\u043d\u044b\u0439 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0440 (TPU)\n\nGoogle TPU - \u044d\u0442\u043e \u0441\u043e\u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0440, \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0439 \u0434\u043b\u044f \u0440\u0430\u0441\u0447\u0435\u0442\u0430 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0445 \u0441\u0435\u0442\u0435\u0439, \u043f\u0440\u0435\u0436\u0434\u0435 \u0432\u0441\u0435\u0433\u043e \u0434\u043b\u044f \u043c\u0430\u0442\u0440\u0438\u0447\u043d\u044b\u0445 \u0443\u043c\u043d\u043e\u0436\u0435\u043d\u0438\u0439 \u0438 \u0441\u0432\u0435\u0440\u0442\u043e\u043a. \u041e\u043d \u0434\u043e\u0441\u0442\u0443\u043f\u0435\u043d \u0432 Google colab \u0438 Kaggle kernel \u0431\u0435\u0441\u043f\u043b\u0430\u0442\u043d\u043e. \u0414\u043b\u044f \u0435\u0433\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u043d\u0443\u0436\u043d\u043e \u0441\u043d\u0430\u0447\u0430\u043b\u0430 \u0441\u043c\u0435\u043d\u0438\u0442\u044c \u0441\u0440\u0435\u0434\u0443 \u043d\u0430 TPU \u0432 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430\u0445, \u0430 \u0437\u0430\u0442\u0435\u043c \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c TPU, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u043d\u044b\u0439 \u0434\u0430\u043b\u0435\u0435 \u043a\u043e\u0434.\n\n\u041a\u043b\u0430\u0441\u0442\u0435\u0440 TPU \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u043d\u0430 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e\u0439 \u0432\u0438\u0440\u0442\u0443\u0430\u043b\u044c\u043d\u043e\u0439 \u043c\u0430\u0448\u0438\u043d\u0435. \u041e\u043d \u043d\u0435 \u0438\u043c\u0435\u0435\u0442 \u043d\u0438 \u0441\u0432\u043e\u0435\u0439 \u0444\u0430\u0439\u043b\u043e\u0432\u043e\u0439 \u0441\u0438\u0441\u0442\u0435\u043c\u044b, \u043d\u0438 \u0434\u043e\u0441\u0442\u0443\u043f\u0430 \u043a \u0444\u0430\u0439\u043b\u043e\u0432\u043e\u0439 \u0441\u0438\u0441\u0442\u0435\u043c\u0435 \u0432\u0438\u0440\u0442\u0443\u0430\u043b\u044c\u043d\u043e\u0439 \u043c\u0430\u0448\u0438\u043d\u044b, \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u043e\u0439 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0435\u0442\u0441\u044f \u043a\u043e\u0434 Python, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u043f\u043e\u043f\u044b\u0442\u043a\u0430 \u043f\u0440\u043e\u0447\u0438\u0442\u0430\u0442\u044c \u0434\u0430\u043d\u043d\u044b\u0435 \u0441 \u0434\u0438\u0441\u043a\u0430 \u0432\u043e \u0432\u0440\u0435\u043c\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u0442 \u043a \u043e\u0448\u0438\u0431\u043a\u0435. \u041d\u043e \u043a\u043b\u0430\u0441\u0442\u0435\u0440 TPU \u0443\u043c\u0435\u0435\u0442 \u0447\u0438\u0442\u0430\u0442\u044c \u0434\u0430\u043d\u043d\u044b\u0435 \u0441 Google cloud storage (\u044d\u0442\u043e \u043d\u0435 \u0442\u043e \u0436\u0435 \u0441\u0430\u043c\u043e\u0435, \u0447\u0442\u043e Google \u0434\u0438\u0441\u043a). \u041f\u043e\u044d\u0442\u043e\u043c\u0443 \u043f\u0440\u0438 \u0432\u044b\u0437\u043e\u0432\u0435 `model.fit()` \u0432\u0441\u0435 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043e\u043b\u0436\u043d\u044b \u043d\u0430\u0445\u043e\u0434\u0438\u0442\u044c\u0441\u044f \u043b\u0438\u0431\u043e \u0432 \u043e\u043f\u0435\u0440\u0430\u0442\u0438\u0432\u043d\u043e\u0439 \u043f\u0430\u043c\u044f\u0442\u0438, \u043b\u0438\u0431\u043e \u043d\u0430 Google cloud.\n\n\u041a\u043b\u0430\u0441\u0442\u0435\u0440 TPU \u043d\u0435 \u043c\u043e\u0436\u0435\u0442 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0442\u044c \u043a\u043e\u0434 Python. Tensorflow \u0441\u043e\u0437\u0434\u0430\u0435\u0442 \u0431\u0438\u043d\u0430\u0440\u043d\u044b\u0435 \u0444\u0430\u0439\u043b\u044b \u0434\u043b\u044f \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u0430 TPU \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0441\u043e\u0437\u0434\u0430\u043d\u043d\u043e\u0433\u043e \u0433\u0440\u0430\u0444\u0430 \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0439. \u041d\u0435 \u043b\u044e\u0431\u043e\u0439 \u043a\u043e\u0434 Python \u043c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \u0441\u043a\u043e\u043c\u043f\u0438\u043b\u0438\u0440\u043e\u0432\u0430\u043d \u0434\u043b\u044f \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043d\u0430 TPU, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 \u0444\u0443\u043d\u043a\u0446\u0438\u044f numpy.load \u043d\u0435 \u043c\u043e\u0436\u0435\u0442, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u043d\u0435\u043b\u044c\u0437\u044f \u043d\u0430\u043f\u0440\u044f\u043c\u0443\u044e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u043d\u044b\u0435 \u043d\u0430 \u0434\u0438\u0441\u043a\u0435 \u043c\u0430\u0441\u0441\u0438\u0432\u044b numpy \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438, \u0434\u0430\u0436\u0435 \u0435\u0441\u043b\u0438 \u043e\u043d\u0438 \u043b\u0435\u0436\u0430\u0442 \u0432 Google cloud.\n\n\u0415\u0441\u043b\u0438 \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043d\u0435 \u043f\u043e\u043c\u0435\u0449\u0430\u044e\u0442\u0441\u044f \u0432 \u043e\u043f\u0435\u0440\u0430\u0442\u0438\u0432\u043d\u0443\u044e \u043f\u0430\u043c\u044f\u0442\u044c, \u0442\u043e \u043c\u043e\u0436\u043d\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0445\u0440\u0430\u043d\u044f\u0449\u0438\u0435\u0441\u044f \u0432 Google cloud \u0444\u0430\u0439\u043b\u044b \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0438\u043b\u0438 \u0444\u0430\u0439\u043b\u044b .tfrec - [\u0441\u043f\u0435\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0444\u043e\u0440\u043c\u0430\u0442](https:\/\/www.tensorflow.org\/tutorials\/load_data\/tfrecord?hl=ru) \u0444\u0430\u0439\u043b\u043e\u0432 Tensorflow. \u0422\u0430\u043a\u043e\u0439 \u0444\u0430\u0439\u043b \u0441\u043e\u0441\u0442\u043e\u0438\u0442 \u0438\u0437 \u043d\u0430\u0431\u043e\u0440\u0430 \u0437\u0430\u043f\u0438\u0441\u0435\u0439, \u043a\u0430\u0436\u0434\u0430\u044f \u0438\u0437 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 \u0441\u043e\u0431\u043e\u0439 \u0441\u043b\u043e\u0432\u0430\u0440\u044c - \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0449\u0438\u0439 \u043a\u043b\u044e\u0447\u0438 \"image\" \u0438 \"class\". \u0414\u0430\u043b\u0435\u0435 \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0441 \u0442\u0430\u043a\u0438\u043c\u0438 \u0444\u0430\u0439\u043b\u0430\u043c\u0438. \u041c\u043d\u043e\u0433\u0438\u0435 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u044f Kaggle \u043f\u0440\u0435\u0434\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u044e\u0442 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u0432\u0438\u0434\u0435 \u0440\u0430\u0437\u043c\u0435\u0449\u0435\u043d\u043d\u044b\u0445 \u043d\u0430 Google cloud \u0444\u0430\u0439\u043b\u043e\u0432 .tfrec. \u041f\u0440\u0435\u0438\u043c\u0443\u0449\u0435\u0441\u0442\u0432\u043e \u0444\u0430\u0439\u043b\u043e\u0432 .tfrec \u043f\u0435\u0440\u0435\u0434 \u0444\u0430\u0439\u043b\u0430\u043c\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0432 \u0442\u043e\u043c, \u0447\u0442\u043e \u043f\u0440\u0438 \u0441\u0447\u0438\u0442\u044b\u0432\u0430\u043d\u0438\u0438 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f \u043c\u0435\u043d\u044c\u0448\u0435\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0444\u0430\u0439\u043b\u043e\u0432\u044b\u0445 \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0439, \u0437\u0430 \u0441\u0447\u0435\u0442 \u0447\u0435\u0433\u043e \u043f\u0440\u043e\u0446\u0435\u0441\u0441 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0438\u0434\u0435\u0442 \u0431\u044b\u0441\u0442\u0440\u0435\u0435.\n\n\u0415\u0441\u0442\u044c \u0438 \u0434\u0440\u0443\u0433\u0438\u0435 \u0441\u043b\u043e\u0436\u043d\u043e\u0441\u0442\u0438 \u043f\u0440\u0438 \u0440\u0430\u0431\u043e\u0442\u0435 \u0441 TPU. \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0435\u0441\u043b\u0438 \u0432 Tensorflow, \u0440\u0430\u0431\u043e\u0442\u0430\u044e\u0449\u0435\u043c \u043d\u0430 TPU, \u0441\u043b\u0443\u0447\u0438\u0442\u0441\u044f \u043a\u0430\u043a\u043e\u0435-\u0442\u043e \u0438\u0441\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435 (\u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0441 bucket \u0431\u0443\u0434\u0435\u0442 \u0441\u0447\u0438\u0442\u0430\u043d \u043d\u0435\u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0439 \u0444\u0430\u0439\u043b), \u0442\u043e Tensorflow \u0431\u0443\u0434\u0435\u0442 \u0432\u044b\u0434\u0430\u0432\u0430\u0442\u044c \u044d\u0442\u043e \u0436\u0435 \u0438\u0441\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435 \u0432 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u0432\u0441\u0435 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0435 \u043a\u043e\u043c\u0430\u043d\u0434\u044b. \u0418\u0441\u043f\u0440\u0430\u0432\u0438\u0442\u044c \u044d\u0442\u043e\u0442 \u0431\u0430\u0433 \u043c\u043e\u0436\u043d\u043e \u043a\u043e\u043c\u0430\u043d\u0434\u043e\u0439 `tf.python.eager.context.context().executor.clear_error()`.\n\n\u0412 \u0441\u043b\u0443\u0447\u0430\u0435 \u043d\u0435\u043f\u043e\u043d\u044f\u0442\u043d\u043e\u0439 \u043e\u0448\u0438\u0431\u043a\u0438 \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439\u0442\u0435 \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043a\u043b\u0430\u0441\u0442\u0435\u0440 TPU \u0437\u0430\u043d\u043e\u0432\u043e. \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0443 \u043c\u0435\u043d\u044f \u0441\u043b\u0443\u0447\u0430\u043b\u043e\u0441\u044c \u0442\u0430\u043a, \u0447\u0442\u043e \u044f \u043c\u043e\u0433\u0443 \u043e\u0442\u043d\u044f\u0442\u044c \u043e\u0442 \u0437\u0430\u0433\u0440\u0443\u0436\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u0437 google cloud \u0442\u0435\u043d\u0437\u043e\u0440\u0430-\u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043b\u044e\u0431\u043e\u0435 \u0447\u0438\u0441\u043b\u043e, \u043a\u0440\u043e\u043c\u0435 210. \u0415\u0441\u043b\u0438 \u044f \u043e\u0442\u043d\u0438\u043c\u0430\u044e 210, \u0442\u043e Tensorflow \u043d\u0430 \u0433\u043e\u043b\u0443\u0431\u043e\u043c \u0433\u043b\u0430\u0437\u0443 \u043c\u043d\u0435 \u043f\u0438\u0448\u0435\u0442: \u043e\u0448\u0438\u0431\u043a\u0430 404, \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d\u043e \u043d\u0430 \u0434\u0438\u0441\u043a\u0435. \u0412\u0438\u0434\u0438\u043c\u043e \u0433\u0434\u0435-\u0442\u043e \u0431\u044b\u043b\u043e \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u043e, \u0447\u0442\u043e \u043f\u0440\u0438 \u043e\u0442\u043d\u044f\u0442\u0438\u0438 210 \u043a\u043e\u0433\u0434\u0430-\u0442\u043e \u0432\u043e\u0437\u043d\u0438\u043a\u043b\u0430 \u0442\u0430\u043a\u0430\u044f \u043e\u0448\u0438\u0431\u043a\u0430, \u0438 \u043d\u0443\u0436\u043d\u043e \u0442\u0435\u043f\u0435\u0440\u044c \u043f\u043e\u0432\u0442\u043e\u0440\u044f\u0442\u044c \u0435\u0435 \u0432\u0441\u0435\u0433\u0434\u0430. \u0412 \u043e\u0431\u0449\u0435\u043c, \u0438\u043d\u0441\u0442\u0440\u0443\u043c\u0435\u043d\u0442 \u0435\u0449\u0435 \u0441\u044b\u0440\u043e\u0439, \u0438 \u0432\u0441\u0435 \u043c\u044b \u0438\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u0438 \u0438 \u043f\u0435\u0440\u0432\u043e\u043f\u0440\u043e\u0445\u043e\u0434\u0446\u044b. \u0412 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0435 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u044d\u0442\u043e\u0433\u043e \u043d\u043e\u0443\u0442\u0431\u0443\u043a\u0430 \u0431\u044b\u043b\u043e \u043d\u0430\u043f\u0438\u0441\u0430\u043d\u043e \u0442\u0440\u0438 \u0431\u0430\u0433-\u0440\u0435\u043f\u043e\u0440\u0442\u0430 ([1](https:\/\/github.com\/tensorflow\/tensorflow\/issues\/41542), [2](https:\/\/github.com\/tensorflow\/tensorflow\/issues\/41590), [3](https:\/\/github.com\/tensorflow\/tensorflow\/issues\/41635)), \u043d\u043e \u043e\u043f\u0438\u0441\u0430\u043d\u043d\u044b\u0435 \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u044b \u043d\u0435 \u043a\u0440\u0438\u0442\u0438\u0447\u043d\u044b.\n\n# \u0414\u0430\u0442\u0430\u0441\u0435\u0442\u044b Tensorflow\n\n\u041c\u0435\u0442\u043e\u0434 .fit() \u043c\u043e\u0434\u0435\u043b\u0438 keras \u043c\u043e\u0436\u0435\u0442 \u043f\u0440\u0438\u043d\u0438\u043c\u0430\u0442\u044c \u043b\u0438\u0431\u043e \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u0432\u0438\u0434\u0435 \u043c\u0430\u0441\u0441\u0438\u0432\u043e\u0432 \u0438\u043b\u0438 \u0442\u0435\u043d\u0437\u043e\u0440\u043e\u0432, \u043b\u0438\u0431\u043e \u0440\u0430\u0437\u043d\u043e\u0433\u043e \u0440\u043e\u0434\u0430 \u0438\u0442\u0435\u0440\u0430\u0442\u043e\u0440\u044b, \u0438\u0437 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043d\u0430\u0438\u0431\u043e\u043b\u0435\u0435 \u0441\u043e\u0432\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u043c \u0438 \u0433\u0438\u0431\u043a\u0438\u043c \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f [tf.data.Dataset](https:\/\/www.tensorflow.org\/guide\/data). \u041e\u043d \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 \u0441\u043e\u0431\u043e\u0439 \u043a\u043e\u043d\u0432\u0435\u0439\u0435\u0440, \u0442\u043e \u0435\u0441\u0442\u044c \u043c\u044b \u0443\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c, \u043e\u0442\u043a\u0443\u0434\u0430 \u0431\u0435\u0440\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0438 \u043a\u0430\u043a\u0443\u044e \u0446\u0435\u043f\u043e\u0447\u043a\u0443 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0439 \u0441 \u043d\u0438\u043c\u0438 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0435\u043c. \u0414\u0430\u043b\u0435\u0435 \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0441 tf.data.Dataset.\n\n# Google cloud storage\n\n\u042d\u0442\u043e \u043e\u0431\u043b\u0430\u0447\u043d\u043e\u0435 \u0445\u0440\u0430\u043d\u0438\u043b\u0438\u0449\u0435 \u0434\u0430\u043d\u043d\u044b\u0445, \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u043d\u043e\u0435 \u043d\u0430 bucket'\u044b. \u041a\u0430\u0436\u0434\u044b\u0439 bucket \u0441\u0432\u044f\u0437\u0430\u043d \u0441 \u043f\u0440\u043e\u0435\u043a\u0442\u043e\u043c, \u0430 \u043f\u0440\u043e\u0435\u043a\u0442 \u0441\u0432\u044f\u0437\u0430\u043d \u0441 \u043e\u0434\u043d\u0438\u043c \u0438\u043b\u0438 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u043c\u0438 google-\u0430\u043a\u043a\u0430\u0443\u043d\u0442\u0430\u043c\u0438. \u0420\u0430\u0431\u043e\u0442\u0430 \u0441 \u0444\u0430\u0439\u043b\u0430\u043c\u0438 \u043d\u0430 Google cloud \u043f\u0440\u043e\u0438\u0441\u0445\u043e\u0434\u0438\u0442 \u043a\u0430\u043a \u0441 \u043e\u0431\u044b\u0447\u043d\u044b\u043c\u0438 \u0444\u0430\u0439\u043b\u0430\u043c\u0438 \u0441 \u0430\u0434\u0440\u0435\u0441\u043e\u043c `gs:\/\/bucket_name\/file_path`.\n\nBucket'\u044b \u0431\u044b\u0432\u0430\u044e\u0442 \u043f\u0440\u0438\u0432\u0430\u0442\u043d\u044b\u043c\u0438 \u0438 \u043f\u0443\u0431\u043b\u0438\u0447\u043d\u044b\u043c\u0438. \u0421\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u044f Kaggle \u0447\u0430\u0441\u0442\u043e \u0440\u0430\u0437\u043c\u0435\u0449\u0430\u044e\u0442\u0441\u044f \u043d\u0430 \u043f\u0443\u0431\u043b\u0438\u0447\u043d\u044b\u0445 bucket'\u0430\u0445, \u043f\u0440\u043e\u0431\u043b\u0435\u043c \u0441 \u0434\u043e\u0441\u0442\u0443\u043f\u043e\u043c \u043a \u043d\u0438\u043c \u0441 \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u0430 TPU \u0431\u044b\u0442\u044c \u043d\u0435 \u0434\u043e\u043b\u0436\u043d\u043e.\n\n\u0412 \u0438\u043d\u044b\u0445 \u0441\u043b\u0443\u0447\u0430\u044f\u0445 \u043c\u043e\u0436\u0435\u0442 \u043f\u043e\u0442\u0440\u0435\u0431\u043e\u0432\u0430\u0442\u044c\u0441\u044f \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0439 bucket, \u0435\u0441\u043b\u0438 \u0432\u0430\u043c \u043d\u0443\u0436\u043d\u043e, \u0447\u0442\u043e\u0431\u044b TPU \u0440\u0430\u0431\u043e\u0442\u0430\u043b \u0441 \u0434\u0438\u0441\u043a\u043e\u043c. \u0415\u0441\u043b\u0438 \u0432\u044b \u0434\u0435\u0440\u0436\u0438\u0442\u0435 \u0432 bucket'\u0435 \u043c\u0435\u043d\u044c\u0448\u0435 5 \u0413\u0431 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u043d\u0435 \u0441\u043e\u0432\u0435\u0440\u0448\u0430\u0435\u0442\u0435 \u0441\u043b\u0438\u0448\u043a\u043e\u043c \u043c\u043d\u043e\u0433\u043e \u0444\u0430\u0439\u043b\u043e\u0432\u044b\u0445 \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0439, \u0442\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u0435\u0433\u043e \u0431\u0435\u0441\u043f\u043b\u0430\u0442\u043d\u043e. \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 bucket'\u0430 \u0442\u043e\u0436\u0435 \u0431\u0435\u0441\u043f\u043b\u0430\u0442\u043d\u043e, \u043d\u043e \u043f\u043e\u0442\u0440\u0435\u0431\u0443\u0435\u0442\u0441\u044f \u0443\u043a\u0430\u0437\u0430\u0442\u044c \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u043e\u043f\u043b\u0430\u0442\u044b - \u0441\u0440\u0435\u0434\u0441\u0442\u0432\u0430 \u0441\u043f\u0438\u0448\u0443\u0442, \u0435\u0441\u043b\u0438 \u0432\u044b \u043f\u0440\u0435\u0432\u044b\u0441\u0438\u0442\u0435 [\u043b\u0438\u043c\u0438\u0442\u044b](https:\/\/cloud.google.com\/storage\/pricing#cloud-storage-always-free) \u0431\u0435\u0441\u043f\u043b\u0430\u0442\u043d\u043e\u0433\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f.\n\n\u0421\u043e\u0437\u0434\u0430\u0442\u044c bucket \u043c\u043e\u0436\u043d\u043e \u043d\u0430 [\u044d\u0442\u043e\u0439](console.cloud.google.com\/storage\/browser) \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u0435. \u041d\u0443\u0436\u043d\u043e \u0432\u044b\u0431\u0440\u0430\u0442\u044c \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u043e\u0435 \u0438\u043c\u044f. \u041f\u0440\u0438 \u0432\u044b\u0431\u043e\u0440\u0435 fine-grained access control \u043c\u043e\u0436\u043d\u043e \u043d\u0430\u0441\u0442\u0440\u0430\u0438\u0432\u0430\u0442\u044c \u0443\u0440\u043e\u0432\u0435\u043d\u044c \u0434\u043e\u0441\u0442\u0443\u043f\u0430 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0444\u0430\u0439\u043b\u0430 \u043f\u043e \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u0438. \u0412\u044b \u043c\u043e\u0436\u0435\u0442\u0435 \u0441\u0434\u0435\u043b\u0430\u0442\u044c bucket \u043f\u043e\u043b\u043d\u043e\u0441\u0442\u044c\u044e \u043f\u0443\u0431\u043b\u0438\u0447\u043d\u044b\u043c, \u0434\u043b\u044f \u044d\u0442\u043e\u0433\u043e (\u0432 \u0441\u043b\u0443\u0447\u0430\u0435 uniform access control) \u043d\u0443\u0436\u043d\u043e \u0434\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u043d\u0430 \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u0435 \u0440\u0430\u0437\u0440\u0435\u0448\u0435\u043d\u0438\u0439 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044e allUsers \u0440\u043e\u043b\u044c allUsers, \u043d\u043e \u0442\u043e\u0433\u0434\u0430 \u043b\u044e\u0431\u043e\u0439 \u0441\u043c\u043e\u0436\u0435\u0442\u044c \u043f\u0440\u043e\u0447\u0435\u0441\u0442\u044c \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u043c\u043e\u0435 \u0432\u0430\u0448\u0435\u0433\u043e bucket'\u0430. \u0415\u0441\u043b\u0438 \u0432\u044b \u0441\u0434\u0435\u043b\u0430\u0435\u0442\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u0440\u0438\u0432\u0430\u0442\u043d\u044b\u043c\u0438, \u0442\u043e \u0434\u043b\u044f \u0434\u043e\u0441\u0442\u0443\u043f\u0430 \u043a \u043d\u0438\u043c \u0438\u0437 Colab \u043d\u0443\u0436\u043d\u043e \u043b\u043e\u0433\u0438\u043d\u0438\u0442\u044c\u0441\u044f \u0432 Google-\u0430\u043a\u043a\u0430\u0443\u043d\u0442 \u043a\u043e\u043c\u0430\u043d\u0434\u043e\u0439 `gcloud auth login`, \u043d\u043e \u043f\u0440\u0438 \u043f\u043e\u043f\u044b\u0442\u043a\u0435 \u0434\u043e\u0441\u0442\u0443\u043f\u0430 \u043a \u043d\u0438\u043c \u0438\u0437 \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u0430 TPU \u0431\u0443\u0434\u0435\u0442 \u0432\u044b\u0434\u0430\u043d\u0430 \u043e\u0448\u0438\u0431\u043a\u0430 403 (access denied). \u0412 \u043e\u0448\u0438\u0431\u043a\u0435 \u0431\u0443\u0434\u0435\u0442 \u0443\u043a\u0430\u0437\u0430\u043d email, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442 \u043a\u043b\u0430\u0441\u0442\u0435\u0440 TPU \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 google-\u0430\u043a\u043a\u0430\u0443\u043d\u0442\u0430. \u041d\u0443\u0436\u043d\u043e \u0432\u0440\u0443\u0447\u043d\u0443\u044e \u0434\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u044d\u0442\u043e\u0442 email \u0432 \u0441\u043f\u0438\u0441\u043e\u043a \u0442\u0435\u0445, \u043a\u043e\u043c\u0443 \u0440\u0430\u0437\u0440\u0435\u0448\u0435\u043d \u0434\u043e\u0441\u0442\u0443\u043f, \u043d\u0430 \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u0435 \u0440\u0430\u0437\u0440\u0435\u0448\u0435\u043d\u0438\u0439.\n\n\u0414\u0430\u043b\u0435\u0435 \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c Google cloud \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0445\u0440\u0430\u043d\u0438\u043b\u0438\u0449\u0430 .tfrec \u0444\u0430\u0439\u043b\u043e\u0432. \u042f \u0441\u043e\u0437\u0434\u0430\u043b bucket gs:\/\/oleg-zyablov \u0438 \u0441\u0434\u0435\u043b\u0430\u043b \u0435\u0433\u043e \u043f\u0443\u0431\u043b\u0438\u0447\u043d\u044b\u043c, \u043c\u043e\u0436\u043d\u043e \u0441\u0447\u0438\u0442\u044b\u0432\u0430\u0442\u044c \u043e\u0442\u0442\u0443\u0434\u0430 \u0434\u0430\u043d\u043d\u044b\u0435.\n\n\u0412\u0430\u0436\u043d\u0430\u044f \u0434\u0435\u0442\u0430\u043b\u044c \u0437\u0430\u043a\u043b\u044e\u0447\u0430\u0435\u0442\u0441\u044f \u0432 \u0442\u043e\u043c, \u0447\u0442\u043e \u0445\u043e\u0442\u044f \u043a\u043b\u0430\u0441\u0442\u0435\u0440 TPU \u043d\u0435 \u043c\u043e\u0436\u0435\u0442 \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0441 \u043b\u043e\u043a\u0430\u043b\u044c\u043d\u044b\u043c\u0438 \u0444\u0430\u0439\u043b\u0430\u043c\u0438, \u043d\u043e Tensorflow \u043c\u043e\u0436\u0435\u0442 \u044d\u0442\u043e \u0434\u0435\u043b\u0430\u0442\u044c. \u0414\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u043d\u0443\u0436\u043d\u043e \u044f\u0432\u043d\u043e \u0443\u043a\u0430\u0437\u0430\u0442\u044c, \u0447\u0442\u043e \u043c\u044b \u0445\u043e\u0442\u0438\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u043b\u043e\u043a\u0430\u043b\u044c\u043d\u044b\u0439 CPU, \u0437\u0430\u043a\u043b\u044e\u0447\u0438\u0432 \u043a\u043e\u0434 \u0432 \u0431\u043b\u043e\u043a `with tf.device('\/job:localhost\/replica:0\/task:0\/device:CPU:0')`.\n\n\n# \u041f\u0430\u0440\u0430 \u0441\u043b\u043e\u0432 \u043e Kaggle\n\n\u0412 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u044f\u0445 Kaggle \u043f\u0440\u0435\u0434\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u044e\u0442\u0441\u044f \u0440\u0430\u0437\u043c\u0435\u0447\u0435\u043d\u043d\u044b\u0435 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0438 \u043d\u0435\u0440\u0430\u0437\u043c\u0435\u0447\u0435\u043d\u043d\u044b\u0435 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435. \u041e\u0442 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0431\u0438\u0437\u043d\u0435\u0441-\u0437\u0430\u0434\u0430\u0447 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u044f \u043e\u0442\u043b\u0438\u0447\u0430\u044e\u0442\u0441\u044f \u0442\u0435\u043c, \u0447\u0442\u043e \u0432\u0441\u044f \u0440\u0430\u0431\u043e\u0442\u0430 \u043f\u043e \u0441\u0431\u043e\u0440\u0443, \u043e\u0447\u0438\u0441\u0442\u043a\u0435 \u0438 \u0440\u0430\u0437\u043c\u0435\u0442\u043a\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 \u0443\u0436\u0435 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0430 \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u0430\u0442\u043e\u0440\u0430\u043c\u0438 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u044f, \u043e\u0441\u0442\u0430\u043b\u043e\u0441\u044c \u0442\u043e\u043b\u044c\u043a\u043e \u043e\u0431\u0443\u0447\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c. \u0425\u043e\u0442\u044f \u0432\u044b \u043c\u043e\u0436\u0435\u0442\u0435 \u0441\u0430\u043c\u043e\u0441\u0442\u043e\u044f\u0442\u0435\u043b\u044c\u043d\u043e \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u043c\u0438, \u0441\u043e\u0431\u0440\u0430\u0432, \u043e\u0447\u0438\u0441\u0442\u0438\u0432 \u0438 \u0440\u0430\u0437\u043c\u0435\u0442\u0438\u0432 \u0438\u0445.\n\n\u041e\u0442\u0432\u0435\u0442\u044b \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u043f\u0440\u0438\u043c\u0435\u0440\u044b \u0434\u0435\u0440\u0436\u0430\u0442\u0441\u044f \u0432 \u0441\u0435\u043a\u0440\u0435\u0442\u0435, \u0438 \u0432\u044b \u043c\u043e\u0436\u0435\u0442\u0435 \u0443\u0437\u043d\u0430\u0442\u044c \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0432\u0430\u0448\u0435\u0433\u043e \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f, \u0442\u043e\u043b\u044c\u043a\u043e \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u0432 \u0432\u0430\u0448\u0438 \u043e\u0442\u0432\u0435\u0442\u044b \u043d\u0430 \u0441\u0430\u0439\u0442, \u0433\u0434\u0435 \u043e\u043d\u0438 \u0431\u0443\u0434\u0443\u0442 \u0441\u0440\u0430\u0432\u043d\u0435\u043d\u044b \u0441 \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u043c\u0438. \u041d\u043e \u043f\u043e\u043a\u0430 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u0435 \u043d\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u043e, \u043e\u0446\u0435\u043d\u043a\u0430 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u0442\u0441\u044f \u043d\u0435 \u043d\u0430 \u0432\u0441\u0435\u0445 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u043f\u0440\u0438\u043c\u0435\u0440\u0430\u0445, \u0430 \u0442\u043e\u043b\u044c\u043a\u043e \u043d\u0430 \u0447\u0430\u0441\u0442\u0438, \u043d\u0430\u0437\u044b\u0432\u0430\u0435\u043c\u043e\u0439 \"\u043f\u0443\u0431\u043b\u0438\u0447\u043d\u044b\u043c\u0438\". \u041f\u043e \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430\u043c \u044d\u0442\u0438\u0445 \u043e\u0446\u0435\u043d\u043e\u043a \u0432\u044b \u043f\u043e\u043f\u0430\u0434\u0430\u0435\u0442\u0435 \u0432 \u043f\u0443\u0431\u043b\u0438\u0447\u043d\u044b\u0439 \u0440\u0435\u0439\u0442\u0438\u043d\u0433. \u041a\u043e\u0433\u0434\u0430 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0430\u0435\u0442\u0441\u044f, \u0432\u0441\u0435 \u043e\u0442\u0432\u0435\u0442\u044b \u043e\u0446\u0435\u043d\u0438\u0432\u0430\u044e\u0442\u0441\u044f \u043d\u0430 \u0434\u0440\u0443\u0433\u043e\u0439 \u0447\u0430\u0441\u0442\u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432, \u043d\u0430\u0437\u044b\u0432\u0430\u0435\u043c\u043e\u0439 \"\u043f\u0440\u0438\u0432\u0430\u0442\u043d\u044b\u043c\u0438\". \u041f\u043e \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430\u043c \u044d\u0442\u0438\u0445 \u043e\u0446\u0435\u043d\u043e\u043a \u0432\u044b \u043f\u043e\u043f\u0430\u0434\u0430\u0435\u0442\u0435 \u043d\u0430 \u0432 \u043f\u0440\u0438\u0432\u0430\u0442\u043d\u044b\u0439 \u0440\u0435\u0439\u0442\u0438\u043d\u0433, \u0438 \u043f\u043e \u044d\u0442\u043e\u043c\u0443 \u0440\u0435\u0439\u0442\u0438\u043d\u0433\u0443 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u044e\u0442\u0441\u044f \u043f\u043e\u0431\u0435\u0434\u0438\u0442\u0435\u043b\u0438.\n\n\u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0443 \u0432\u0430\u0441 \u0435\u0441\u0442\u044c 1000 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439, \u0438 \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u0430\u0442\u043e\u0440\u044b \u0441\u043e\u043e\u0431\u0449\u0438\u043b\u0438, \u0447\u0442\u043e 20% \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u0443\u0431\u043b\u0438\u0447\u043d\u044b\u0435, \u0430 80% \u043f\u0440\u0438\u0432\u0430\u0442\u043d\u044b\u0435. \u041a\u043e\u0433\u0434\u0430 \u0432\u044b \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u0442\u0435 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0432\u044b\u0434\u0430\u043b \u0432\u0430\u0448 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c, \u043e\u043d\u0438 \u0431\u0443\u0434\u0443\u0442 \u043e\u0446\u0435\u043d\u0435\u043d\u044b \u0432\u0441\u0435\u0433\u043e \u043f\u043e 200 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u043c (\u0432\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0442\u0435, \u043a\u0430\u043a\u0438\u043c \u0438\u043c\u0435\u043d\u043d\u043e). \u0412\u0430\u043c \u0441\u0442\u0430\u043d\u0435\u0442 \u0438\u0437\u0432\u0435\u0441\u0442\u043d\u0430 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c, \u0434\u043e\u0441\u0442\u0438\u0433\u043d\u0443\u0442\u0430\u044f \u043d\u0430 \u044d\u0442\u0438\u0445 \u043f\u0440\u0438\u043c\u0435\u0440\u0430\u0445. \u041a \u043c\u043e\u043c\u0435\u043d\u0442\u0443 \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u044f \u0432\u044b \u043d\u0430 3 \u043c\u0435\u0441\u0442\u0435 \u0432 \u043f\u0443\u0431\u043b\u0438\u0447\u043d\u043e\u043c \u043b\u0438\u0434\u0435\u0440\u0431\u043e\u0440\u0434\u0435. \u041f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u0442\u0441\u044f \u043e\u0446\u0435\u043d\u043a\u0430 \u0432\u0430\u0448\u0438\u0445 \u043e\u0442\u0432\u0435\u0442\u043e\u0432 \u043d\u0430 \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0435 800 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439, \u0438 \u043f\u043e \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430\u043c \u044d\u0442\u043e\u0439 \u043e\u0446\u0435\u043d\u043a\u0438, \u043e\u0433\u043b\u0430\u0448\u0430\u0435\u0442\u0441\u044f \u043f\u0440\u0438\u0432\u0430\u0442\u043d\u044b\u0439 \u043b\u0438\u0434\u0435\u0440\u0431\u043e\u0440\u0434, \u0438 \u0432\u044b \u043f\u0430\u0434\u0430\u0435\u0442\u0435 \u043d\u0430 30-\u0435 \u043c\u0435\u0441\u0442\u043e. \u0410 \u043c\u043e\u0436\u0435\u0442\u0435 \u043d\u0430\u043e\u0431\u043e\u0440\u043e\u0442 \u043f\u043e\u0434\u043d\u044f\u0442\u044c\u0441\u044f \u0441 30-\u0433\u043e \u043c\u0435\u0441\u0442\u0430 \u043d\u0430 3-\u0435 \u0438 \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0434\u0435\u043d\u0435\u0436\u043d\u044b\u0439 \u043f\u0440\u0438\u0437.\n\n\u0414\u043b\u044f \u0434\u043e\u0441\u0442\u0438\u0436\u0435\u043d\u0438\u044f \u0445\u043e\u0440\u043e\u0448\u0435\u0439 \u043f\u043e\u0437\u0438\u0446\u0438\u0438 \u0432 \u043f\u0440\u0438\u0432\u0430\u0442\u043d\u043e\u043c \u043b\u0438\u0434\u0435\u0440\u0431\u043e\u0440\u0434\u0435 \u0432\u0430\u0448\u0430 \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0435 \u0434\u043e\u043b\u0436\u043d\u0430 \u0431\u044b\u0442\u044c \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0435\u043d\u0430 \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0445 \u0434\u0430\u043d\u043d\u044b\u0445. \u0414\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u044b\u0435 \u0440\u0430\u0437\u043c\u0435\u0447\u0435\u043d\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u0435\u043b\u044f\u0442 \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0435 \u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0435. \u0415\u0441\u043b\u0438 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441\u0442\u0430\u043b\u0430 \u043f\u0430\u0434\u0430\u0442\u044c, \u0430 \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0445 \u043f\u0440\u043e\u0434\u043e\u043b\u0436\u0430\u0435\u0442 \u0440\u0430\u0441\u0442\u0438, \u0437\u043d\u0430\u0447\u0438\u0442 \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0430\u0447\u0430\u043b\u0430 \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0430\u0442\u044c\u0441\u044f, \u0438 \u043d\u0443\u0436\u043d\u043e \u043f\u0440\u0435\u043a\u0440\u0430\u0442\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0442 \u0442\u0430\u043a\u0436\u0435 \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044e, \u043a\u043e\u0433\u0434\u0430 \u0441\u043e\u0437\u0434\u0430\u0435\u0442\u0441\u044f \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0439 \u0440\u0430\u0437\u043c\u0435\u0447\u0435\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0435 \u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0435, \u0438 \u043c\u043e\u0434\u0435\u043b\u044c \u043f\u043e \u043e\u0447\u0435\u0440\u0435\u0434\u0438 \u043e\u0431\u0443\u0447\u0430\u0435\u0442\u0441\u044f \u0438 \u043e\u0446\u0435\u043d\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u043d\u0430 \u043a\u0430\u0436\u0434\u043e\u043c \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0438.\n\n\u0414\u0440\u0443\u0433\u043e\u0439 \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u043e\u0439 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u0442\u043e, \u0447\u0442\u043e \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u043c\u043e\u0433\u0443\u0442 \u043e\u0442\u043b\u0438\u0447\u0430\u0442\u044c\u0441\u044f \u043e\u0442 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0445 \u043f\u043e \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044e \u0438 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a\u0430\u043c, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0432 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0431\u043e\u043b\u044c\u0448\u0435 \u043c\u0443\u0436\u0447\u0438\u043d, \u0430 \u0432 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0431\u043e\u043b\u044c\u0448\u0435 \u0436\u0435\u043d\u0449\u0438\u043d. \u041f\u043e\u044d\u0442\u043e\u043c\u0443 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043c\u043e\u0436\u0435\u0442 \u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043e\u0442\u043b\u0438\u0447\u0430\u0442\u044c\u0441\u044f \u043e\u0442 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445. \u041d\u0430\u043f\u0440\u0430\u0448\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u0438\u0434\u0435\u044f \u043e \u0442\u043e\u043c, \u0447\u0442\u043e\u0431\u044b \u043f\u0440\u043e\u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435. \u041e\u0431\u044b\u0447\u043d\u043e \u0433\u043e\u0432\u043e\u0440\u044f\u0442, \u0447\u0442\u043e \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u043d\u0435\u043b\u044c\u0437\u044f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u043f\u0440\u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438, \u043d\u043e \u044d\u0442\u043e \u0432\u0435\u0440\u043d\u043e \u0442\u043e\u043b\u044c\u043a\u043e \u0435\u0441\u043b\u0438 \u0440\u0435\u0447\u044c \u0438\u0434\u0435\u0442 \u043e \u0440\u0430\u0437\u043c\u0435\u0447\u0435\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445. \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0436\u0435 \u043d\u0435\u0440\u0430\u0437\u043c\u0435\u0447\u0435\u043d\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u043d\u0435 \u043f\u0440\u043e\u0441\u0442\u043e \u043d\u0443\u0436\u043d\u043e, \u0430 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e, \u043f\u043e\u0442\u043e\u043c\u0443 \u0447\u0442\u043e \u0432 \u0440\u0435\u0448\u0430\u0435\u043c\u044b\u0445 \u0441 \u043d\u0443\u043b\u044f \u0437\u0430\u0434\u0430\u0447\u0430\u0445 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u043e\u0434\u0431\u0438\u0440\u0430\u044e\u0442\u0441\u044f \u043a\u0430\u043a \u0440\u0430\u0437 \u0442\u0430\u043a\u0438\u043c\u0438, \u0447\u0442\u043e\u0431\u044b \u0431\u044b\u0442\u044c \u043f\u043e\u0445\u043e\u0436\u0438\u043c\u0438 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435. \u0423\u0447\u0438\u043c \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u0442\u044c \u043f\u0442\u0438\u0446 - \u043e\u0431\u0443\u0447\u0430\u0435\u043c \u043d\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u0445 \u043f\u0442\u0438\u0446, \u0443\u0447\u0438\u043c \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u0442\u044c \u043b\u0438\u0446\u0430 \u0432 \u041a\u0438\u0442\u0430\u0435 - \u043e\u0431\u0443\u0447\u0430\u0435\u043c \u0432 \u043e\u0441\u043d\u043e\u0432\u043d\u043e\u043c \u043d\u0430 \u043b\u0438\u0446\u0430\u0445 \u043a\u0438\u0442\u0430\u0439\u0446\u0435\u0432, \u0438 \u0442\u0430\u043a \u0434\u0430\u043b\u0435\u0435. \u041c\u0435\u0442\u0440\u0438\u043a\u0438 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043c\u044b \u0441\u0442\u0430\u0440\u0430\u0435\u043c\u0441\u044f \u043f\u0440\u0438\u0432\u0435\u0441\u0442\u0438 \u0432 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0438\u0435 \u0441 \u043c\u0435\u0442\u0440\u0438\u043a\u0430\u043c\u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445.\n\n\u0412 kaggle \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0439 \u043d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u0440\u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438 \u0440\u0430\u0437\u0440\u0435\u0448\u0435\u043d\u043e, \u043d\u043e \u0442\u043e\u043b\u044c\u043a\u043e \u0435\u0441\u043b\u0438 \u043e\u043d \u043d\u0435 \u0440\u0430\u0437\u043c\u0435\u0447\u0435\u043d \u0432\u0440\u0443\u0447\u043d\u0443\u044e (\u044d\u0442\u043e \u0437\u0430\u043f\u0440\u0435\u0449\u0435\u043d\u043e). \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u043c\u043e\u0436\u043d\u043e \u0432\u0437\u044f\u0442\u044c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0432\u0430\u0448\u0435\u0439 \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0438 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 (\u043f\u0441\u0435\u0432\u0434\u043e-\u0440\u0430\u0437\u043c\u0435\u0442\u043a\u0443), \u0430 \u0437\u0430\u0442\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0438\u0445 \u043a\u0430\u043a \u0440\u0430\u0437\u043c\u0435\u0447\u0435\u043d\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u0440\u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438. \u0421 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u0432\u0437\u0433\u043b\u044f\u0434\u0430 \u044d\u0442\u043e \u0432\u044b\u0433\u043b\u044f\u0434\u0438\u0442 \u0441\u043e\u0432\u0441\u0435\u043c \u043d\u0435\u0447\u0435\u0441\u0442\u043d\u043e, \u043d\u043e \u0432 \u0441\u043b\u0443\u0447\u0430\u0435, \u0435\u0441\u043b\u0438 \u0440\u0430\u0437\u043c\u0435\u0442\u043a\u0438 \u043f\u0440\u043e\u0441\u0442\u0430\u0432\u0438\u043b \u0432\u0430\u0448 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c, \u0430 \u043d\u0435 \u0432\u044b \u0441\u0430\u043c\u0438, \u0432\u0441\u0435 \u0447\u0435\u0441\u0442\u043d\u043e. \u042d\u0442\u043e \u043c\u043e\u0436\u043d\u043e \u0440\u0430\u0441\u0441\u043c\u0430\u0442\u0440\u0438\u0432\u0430\u0442\u044c \u043a\u0430\u043a \u043c\u043d\u043e\u0433\u043e\u0441\u0442\u0443\u043f\u0435\u043d\u0447\u0430\u0442\u044b\u0439 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439: \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u0435 \u043f\u0441\u0435\u0432\u0434\u043e-\u0440\u0430\u0437\u043c\u0435\u0442\u043a\u0438, \u0434\u043e\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0438 \u043d\u0430 \u043d\u0435\u0439, \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u0435 \u0444\u0438\u043d\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439. \u041a\u0441\u0442\u0430\u0442\u0438, \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0438 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0432\u043e\u0432\u0441\u0435 \u043d\u0435 \u043e\u0431\u044f\u0437\u0430\u0442\u0435\u043b\u044c\u043d\u043e, \u0435\u0441\u0442\u044c \u0438 \u043c\u043d\u043e\u0433\u043e \u0434\u0440\u0443\u0433\u0438\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432. \u041d\u0430 Kaggle \u0435\u0441\u0442\u044c \u0438 \u0435\u0449\u0435 \u043e\u0434\u043d\u043e \u043f\u0440\u0430\u0432\u0438\u043b\u043e: \u0435\u0441\u043b\u0438 \u0432\u044b \u0445\u043e\u0442\u0438\u0442\u0435 \u0441\u043e\u0431\u0440\u0430\u0442\u044c \u0438 \u0440\u0430\u0437\u043c\u0435\u0442\u0438\u0442\u044c \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435, \u0442\u043e \u043d\u0435\u043b\u044c\u0437\u044f \u0431\u0440\u0430\u0442\u044c \u0438\u0445 \u0438\u0437 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u043e\u0432, \u043d\u0435 \u044f\u0432\u043b\u044f\u044e\u0449\u0438\u0445\u0441\u044f \u043f\u0443\u0431\u043b\u0438\u0447\u043d\u043e \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u044b\u043c\u0438 \u0438 \u0441 \u043e\u0442\u043a\u0440\u044b\u0442\u043e\u0439 \u043b\u0438\u0446\u0435\u043d\u0437\u0438\u0435\u0439, \u0438\u043d\u0430\u0447\u0435 \u0432\u0430\u0441 \u043c\u043e\u0433\u0443\u0442 \u0434\u0438\u0441\u043a\u0432\u0430\u043b\u0438\u0444\u0438\u0446\u0438\u0440\u043e\u0432\u0430\u0442\u044c ([\u043f\u0440\u0438\u043c\u0435\u0440](https:\/\/youtu.be\/fg8lKeJZ7vA?t=849)).","38b2a7f4":"# \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u043e\u0448\u0438\u0431\u043e\u043a\n\n\u041f\u043e\u0441\u0442\u0440\u043e\u0438\u043c \u0434\u043b\u044f \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0435\u0439, \u0440\u0430\u0431\u043e\u0442\u0430\u044e\u0449\u0438\u0445 \u0441 \u0446\u0432\u0435\u0442\u043d\u044b\u043c\u0438 \u0438\u043b\u0438 \u0447\u0435\u0440\u043d\u043e-\u0431\u0435\u043b\u044b\u043c\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u043c\u0438, \u0442\u0430\u0431\u043b\u0438\u0446\u0443, \u0432 \u043a\u043e\u0442\u043e\u0440\u043e\u0439 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u0430 \u0432 \u044f\u0447\u0435\u0439\u043a\u0435 \u0441 \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0430\u043c\u0438 X, Y \u043e\u0437\u043d\u0430\u0447\u0430\u0435\u0442 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0438\u043c\u0435\u044e\u0442 \u043a\u043b\u0430\u0441\u0441 X, \u043d\u043e \u0431\u044b\u043b\u0438 \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u043d\u044b \u043a\u0430\u043a Y.","56f021ce":"\u0418\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0438\u043c\u0435\u044e\u0442 \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u0435 \u0440\u0430\u0437\u043c\u0435\u0440\u044b, \u043f\u0438\u043a\u0441\u0435\u043b\u0438 \u0438\u043c\u0435\u044e\u0442 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043e\u0442 0 \u0434\u043e 255 (\u0442\u0438\u043f tf.uint8). \u0412\u0441\u0435 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0435 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f (\u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f, \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u0440\u0430\u0437\u043c\u0435\u0440\u0430, \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438) \u0437\u0430\u0432\u0438\u0441\u044f\u0442 \u043e\u0442 \u0442\u043e\u0433\u043e, \u043a\u0430\u043a\u043e\u0439 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c.","14c1ceb8":"# \u041c\u0430\u0441\u0448\u0442\u0430\u0431\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435\n\n\u0421\u0432\u0435\u0440\u0442\u043e\u0447\u043d\u0430\u044f \u0441\u0435\u0442\u044c \u0432 \u0442\u0435\u043e\u0440\u0438\u0438 \u043c\u043e\u0436\u0435\u0442 \u043f\u0440\u0438\u043d\u0438\u043c\u0430\u0442\u044c \u043d\u0430 \u0432\u0445\u043e\u0434 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0440\u0430\u0437\u043d\u044b\u0445 \u0440\u0430\u0437\u043c\u0435\u0440\u043e\u0432, \u043d\u043e \u043d\u0430 TPU \u0442\u0430\u043a\u0430\u044f \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u043f\u043e\u043a\u0430 \u043d\u0435 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u0438\u0432\u0430\u0435\u0442\u0441\u044f, \u0438 Xception \u0442\u043e\u0436\u0435 \u0442\u0440\u0435\u0431\u0443\u0435\u0442 \u0444\u0438\u043a\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u0432\u0445\u043e\u0434\u0430. \u0417\u0434\u0435\u0441\u044c \u0435\u0441\u0442\u044c \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043f\u043e\u0434\u0445\u043e\u0434\u043e\u0432, \u0438\u0445 \u043f\u0440\u043e\u0449\u0435 \u0431\u0443\u0434\u0435\u0442 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u044c \u043d\u0430 \u043f\u0440\u0438\u043c\u0435\u0440\u0430\u0445.","278fe0c6":"# Xception: \u043d\u0430\u0447\u0438\u043d\u0430\u0435\u043c \u043f\u043e\u0434\u0431\u0438\u0440\u0430\u0442\u044c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b\n\n\u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u044c Xception. \u0427\u0438\u0442\u0430\u0435\u043c [\u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044e](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/applications\/Xception).\n\n\u0421\u043e\u0441\u0442\u0430\u0432\u0438\u043c \u0441\u043f\u0438\u0441\u043e\u043a \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u044b\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 (\u043f\u043e\u0434\u0440\u043e\u0431\u043d\u043e\u0441\u0442\u0438 \u043e\u0431\u0441\u0443\u0434\u0438\u043c \u043f\u043e\u0437\u0436\u0435):\n\n\u041e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u044b:\n* Adam (lr 0.001, \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u0448\u0430\u0433 2.0)\n* RMSprop (lr 0.001, \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u0448\u0430\u0433 2.0)\n* Nadam (lr 0.001, \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u0448\u0430\u0433 2.0)\n* SGD (\u043c\u043e\u043c\u0435\u043d\u0442 0.9, lr 0.05 \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u0448\u0430\u0433 2.0)\n\n\n\n\u041f\u0440\u0438\u043d\u0446\u0438\u043f \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u044f \u0440\u0430\u0437\u043c\u0435\u0440\u0430:\n* \u0440\u0430\u0441\u0442\u044f\u0436\u0435\u043d\u0438\u0435\n* \u043a\u0440\u043e\u043f\n* \u0434\u043e\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u0441\u0435\u0440\u044b\u043c\n* \u0434\u043e\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u043c\u043e\u0433\u043e\n* \u043c\u0443\u043b\u044c\u0442\u0438\u043c\u0430\u0441\u0448\u0442\u0430\u0431\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0441 \u0434\u043e\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435\u043c \u0441\u0435\u0440\u044b\u043c \u0438 \u0441\u043e\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u0435\u043c\n\n\u0420\u0430\u0437\u043c\u0435\u0440 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f:\n* 256*192\n* 384*256\n* 512*384\n\n\u0424\u043e\u0440\u043c\u0430\u0442 \u043a\u0430\u043d\u0430\u043b\u043e\u0432:\n* RGB\n* HSB\n* Gray*3,\n* Gray*3 shifted\n* Sobel+Sobel(scale=3)+B\n\n\u041f\u0440\u043e\u043c\u0435\u0436\u0443\u0442\u043e\u0447\u043d\u044b\u0439 \u0441\u043b\u043e\u0439:\n* global max pooling\n* global average pooling?\n\n\u0421\u043a\u0440\u044b\u0442\u044b\u0439 \u043f\u043e\u043b\u043d\u043e\u0441\u0432\u044f\u0437\u043d\u044b\u0439 \u0441\u043b\u043e\u0439:\n* \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u0435\u0442\n* 128\n* 512\n* 2048\n\n\u0421\u043d\u0430\u0447\u0430\u043b\u0430 \u043d\u0430\u043f\u0438\u0448\u0435\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044e, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0432\u044b\u0431\u0440\u0430\u043d\u043d\u044b\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043a\u043e\u043d\u0441\u0442\u0440\u0443\u0438\u0440\u0443\u0435\u0442 \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u044c, \u043e\u0431\u0443\u0447\u0430\u0435\u0442 \u0435\u0435 \u0438 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c.","d2882742":"# \u041f\u043e\u043b\u043d\u043e\u0441\u0432\u044f\u0437\u043d\u044b\u0435 \u0441\u043b\u043e\u0438: \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0438 \u0440\u0430\u0437\u043c\u0435\u0440\n\n\u0420\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0435 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u044b:\n\n- Dense(10) \u0441 \u0444\u0438\u043a\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c\u0438 \u0432\u0435\u0441\u0430\u043c\u0438 (identity)\n- batchNorm, Dense(10)\n- batchNorm, Dropout(0.3), Dense(100, relu, l2 regularizer), batchNorm, Dense(10)\n- batchNorm, Dropout(0.3), Dense(1000, relu, l2 regularizer), batchNorm, Dropout(0.5), Dense(10)","16f344e7":"\u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0435\u0449\u0435 \u043f\u0440\u0438\u043c\u0435\u043d\u0438\u0442\u044c \u0444\u0443\u043d\u043a\u0446\u0438\u044e tf.image.per_image_standardization \u0432\u043c\u0435\u0441\u0442\u043e \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0434\u0435\u043b\u0435\u043d\u0438\u0435\u043c \u043d\u0430 128 \u0438 \u0432\u044b\u0447\u0438\u0442\u0430\u043d\u0438\u0435\u043c \u0435\u0434\u0438\u043d\u0438\u0446\u044b. \u042d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442:","5bfbcc08":"\u0412\u044b\u0431\u043e\u0440 \u0440\u0430\u0437\u0440\u0435\u0448\u0435\u043d\u0438\u044f \u0432\u0430\u0436\u0435\u043d \u043f\u043e \u0442\u043e\u0439 \u043f\u0440\u0438\u0447\u0438\u043d\u0435, \u0447\u0442\u043e \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u044c Xception \u0443\u0436\u0435 \u043e\u0431\u0443\u0447\u0430\u043b\u0430\u0441\u044c \u043d\u0430 \u043a\u0430\u043a\u0438\u0445-\u0442\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u0445, \u0438 \u043f\u0440\u0438 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0438\u0438 \u0440\u0430\u0437\u043c\u0435\u0440\u043e\u0432 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0438\u044f \u0434\u043e\u043b\u0436\u043d\u0430 \u0431\u044b\u0442\u044c \u0432\u044b\u0448\u0435.\n\n**\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b.** \u0422\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0431\u0443\u0434\u0435\u043c \u043f\u0440\u043e\u0432\u043e\u0434\u0438\u0442\u044c \u043d\u0430 \u0440\u0430\u0437\u0440\u0435\u0448\u0435\u043d\u0438\u0438 256x192, \u043e\u0446\u0435\u043d\u043a\u0443 \u0434\u043b\u044f \u0441\u0430\u0431\u043c\u0438\u0442\u0430 \u043d\u0430 \u0440\u0430\u0437\u0440\u0435\u0448\u0435\u043d\u0438\u0438 512x384 \u0438\u043b\u0438 \u0434\u0430\u0436\u0435 \u0432\u044b\u0448\u0435.","9348fa55":"# \u041f\u043e\u0434\u0431\u043e\u0440 \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n\n\u0420\u0430\u0437\u043c\u0435\u0440 \u0432\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u0440\u0435\u0448\u0430\u044e\u0449\u0435\u0435 \u0432\u043b\u0438\u044f\u043d\u0438\u0435 \u043d\u0430 \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c, \u0430 \u0437\u043d\u0430\u0447\u0438\u0442 \u0438 \u043d\u0430 \u0432\u0440\u0435\u043c\u044f \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u043f\u043e\u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0445 \u0442\u0435\u0441\u0442\u043e\u0432. \u041d\u0430\u043c \u043d\u0443\u0436\u043d\u043e \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u0442\u044c \u043f\u0440\u0438\u0431\u043b\u0438\u0437\u0438\u0442\u0435\u043b\u044c\u043d\u0443\u044e \u0441\u0432\u044f\u0437\u044c \u043c\u0435\u0436\u0434\u0443 \u0440\u0430\u0437\u0440\u0435\u0448\u0435\u043d\u0438\u0435\u043c, \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c\u044e, \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e\u043c \u044d\u043f\u043e\u0445 \u0438 \u0432\u0440\u0435\u043c\u0435\u043d\u0435\u043c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f. \u0421\u043d\u043e\u0432\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c 50% \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432 \u043a\u0430\u043a \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0435 \u0438 50% \u043a\u0430\u043a \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435.","878f624e":"**SGD nesterov decay** - SGD \u0441 \u043c\u043e\u043c\u0435\u043d\u0442\u043e\u043c \u043d\u0435\u0441\u0442\u0435\u0440\u043e\u0432\u0430 \u0438 \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u044e\u0449\u0438\u043c\u0441\u044f learning rate. \u0412\u043e\u0437\u043c\u043e\u0436\u043d\u043e, \u0447\u0442\u043e \u043d\u0435 \u043b\u0443\u0447\u0448\u0438\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u043e\u0431\u044a\u044f\u0441\u043d\u044f\u044e\u0442\u0441\u044f \u043d\u0435\u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u043e \u0432\u044b\u0431\u0440\u0430\u043d\u043d\u044b\u043c\u0438 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438.\n\n**adam decay** - Adam \u0441 \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u044e\u0449\u0438\u043c\u0441\u044f learning rate\n\n**adam decay TEST** - Adam \u0441 \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u044e\u0449\u0438\u043c\u0441\u044f learning rate, \u043f\u0440\u0438 \u043a\u043e\u0442\u043e\u0440\u043e\u043c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043d\u0430\u0447\u0438\u043d\u0430\u043b\u043e\u0441\u044c \u0441 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0445 \u0441\u043b\u043e\u0435\u0432, \u0438 \u0437\u0430\u0442\u0435\u043c \u043f\u043e\u0441\u0442\u0435\u043f\u0435\u043d\u043d\u043e \u043e\u0431\u0443\u0447\u0430\u043b\u0438\u0441\u044c \u0432\u0441\u0435 \u0441\u043b\u043e\u0438.\n\n**SGD decay TEST** - SGD \u0441 \u043c\u043e\u043c\u0435\u043d\u0442\u043e\u043c \u0438 \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u044e\u0449\u0438\u043c\u0441\u044f learning rate, \u043f\u0440\u0438 \u043a\u043e\u0442\u043e\u0440\u043e\u043c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043d\u0430\u0447\u0438\u043d\u0430\u043b\u043e\u0441\u044c \u0441 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0445 \u0441\u043b\u043e\u0435\u0432, \u0438 \u0437\u0430\u0442\u0435\u043c \u043f\u043e\u0441\u0442\u0435\u043f\u0435\u043d\u043d\u043e \u043e\u0431\u0443\u0447\u0430\u043b\u0438\u0441\u044c \u0432\u0441\u0435 \u0441\u043b\u043e\u0438.\n\n\u041f\u0440\u043e\u0432\u0435\u0434\u0435\u043c \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0439 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442: \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u043b\u0438\u043d\u0435\u0439\u043d\u043e \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0442\u044c learning rate \u0441\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0435\u043c \u0432 \u0442\u0435\u0447\u0435\u043d\u0438\u0435 10 \u044d\u043f\u043e\u0445, \u0430 \u0437\u0430\u0442\u0435\u043c \u0441\u043d\u043e\u0432\u0430 \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0432\u0430\u0442\u044c \u0434\u043e \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u0433\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f.","773de8a1":"\u041f\u043e \u043e\u0434\u043d\u043e\u043c\u0443 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0443 SGD \u0441 \u043c\u043e\u043c\u0435\u043d\u0442\u043e\u043c \u0434\u0435\u043c\u043e\u043d\u0441\u0442\u0440\u0438\u0440\u0443\u0435\u0442 \u0445\u043e\u0440\u043e\u0448\u0438\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b, \u043f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443 \u0434\u0430\u0435\u0442 \u0442\u0430\u043a\u0443\u044e \u0436\u0435 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u043c \u043d\u0430\u0431\u043e\u0440\u0435 \u0441 \u0431\u043e\u043b\u0435\u0435 \u043d\u0438\u0437\u043a\u043e\u0439 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c\u044e \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u043d\u0430\u0431\u043e\u0440\u0435, \u0430 \u0437\u043d\u0430\u0447\u0438\u0442 \u0441 \u0431\u043e\u043b\u0435\u0435 \u0432\u044b\u0441\u043e\u043a\u0438\u043c \u043f\u043e\u0442\u0435\u043d\u0446\u0438\u0430\u043b\u043e\u043c \u043a \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044e. \u0425\u043e\u0442\u044f \u043a\u043e\u043d\u0435\u0447\u043d\u043e \u043f\u043e \u043e\u0434\u043d\u043e\u043c\u0443 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0443 \u043d\u0435\u043b\u044c\u0437\u044f \u0434\u0435\u043b\u0430\u0442\u044c \u0432\u044b\u0432\u043e\u0434\u044b.\n\n\u041f\u0440\u043e\u0432\u0435\u0434\u0435\u043c \u0435\u0449\u0435 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0442\u0435\u0441\u0442\u043e\u0432 \u043f\u043e \u0440\u0430\u0437\u0434\u0435\u043b\u044c\u043d\u043e\u043c\u0443 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044e \u0441\u043b\u043e\u0435\u0432.","e0bc4ab7":"\u041d\u0430 \u043e\u0441\u043d\u043e\u0432\u0430\u043d\u0438\u0438 \u0442\u0435\u0441\u0442\u043e\u0432 \u0432\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0443 test3:\n\n**batchNorm, Dropout(0.3), Dense(100, relu, l2 regularizer), batchNorm, Dense(10)**\n\n\u0422\u0435\u043f\u0435\u0440\u044c \u0441\u0440\u0430\u0432\u043d\u0438\u043c global average pooling \u0438 global max pooling \u043d\u0430 \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u043c \u0440\u0430\u0437\u0440\u0435\u0448\u0435\u043d\u0438\u0438.","35df0713":"# \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c TPU\n\n\u0412\u0435\u0441\u044c \u043a\u043e\u0434 \u044d\u0442\u043e\u0433\u043e \u043d\u043e\u0443\u0442\u0431\u0443\u043a\u0430 \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u0442\u0430\u043a\u0436\u0435 \u0438 \u043d\u0430 CPU\/GPU.","97a55a60":"# \u0411\u0430\u0437\u043e\u0432\u0430\u044f \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445\n\n\u0427\u0442\u043e\u0431\u044b \u0438\u0437\u0431\u0435\u0436\u0430\u0442\u044c \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043f\u0440\u0438 \u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0438 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u043f\u0440\u043e\u0441\u0442\u0443\u044e \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044e \u0434\u0430\u043d\u043d\u044b\u0445.","df3041f4":"# \u041f\u043e\u0434\u0431\u043e\u0440 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u0430 \u0438 learning rate\n\n\u041d\u0430\u0438\u0431\u043e\u043b\u0435\u0435 \u0440\u0430\u0437\u0443\u043c\u043d\u044b\u043c \u0437\u0434\u0435\u0441\u044c \u043a\u0430\u0436\u0435\u0442\u0441\u044f \u043f\u043e\u0438\u0441\u043a\u0430\u0442\u044c \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b \u043f\u043e \u0434\u0430\u043d\u043d\u043e\u0439 \u0442\u0435\u043c\u0435 \u0432 \u0438\u043d\u0442\u0435\u0440\u043d\u0435\u0442\u0435 ([1](https:\/\/machinelearningmastery.com\/learning-rate-for-deep-learning-neural-networks\/), [2](http:\/\/www.mva-org.jp\/Proceedings\/2019\/papers\/04-05.pdf), [3](https:\/\/www.kaggle.com\/residentmario\/tuning-your-learning-rate)).\n\n\n\n\n\u041a\u043e\u043d\u0435\u0447\u043d\u043e learning rate \u043d\u0435 \u043e\u0431\u044f\u0437\u0430\u043d \u0431\u044b\u0442\u044c \u0444\u0438\u043a\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c, \u043d\u043e \u0432 \u0442\u0435\u0447\u0435\u043d\u0438\u0435 \u043e\u0434\u043d\u043e\u0439 \u044d\u043f\u043e\u0445\u0438 \u043e\u043d \u043a\u0430\u043a \u043f\u0440\u0430\u0432\u0438\u043b\u043e \u043d\u0435 \u043c\u0435\u043d\u044f\u0435\u0442\u0441\u044f. \u041f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u0440\u0430\u0437\u043d\u044b\u0435 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u044b \u0441 \u0440\u0430\u0437\u043d\u044b\u043c\u0438 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438.","42a7a957":"\u041d\u0430\u043c \u043d\u0443\u0436\u043d\u043e \u0432\u044b\u044f\u0441\u043d\u0438\u0442\u044c, \u043f\u043e\u0447\u0435\u043c\u0443 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 \u043e \u0446\u0432\u0435\u0442\u0430\u0445 \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u0442 \u043f\u0440\u043e\u0446\u0435\u043d\u0442 \u043d\u0435\u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u043d\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439. \u0421\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u043e\u0431\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u043d\u0430 \u0434\u0438\u0441\u043a \u0434\u043b\u044f \u043f\u043e\u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0433\u043e \u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f.\n\n\u041e\u0431\u0443\u0447\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c Gray, \u043c\u044b \u043c\u043e\u0433\u043b\u0438 \u0431\u044b \u043f\u0440\u0438\u043c\u0435\u043d\u0438\u0442\u044c \u0433\u0430\u043c\u043c\u0430-\u043a\u043e\u0440\u0440\u0435\u043a\u0446\u0438\u044e \u043f\u0435\u0440\u0435\u0434 \u043e\u0431\u0435\u0441\u0446\u0432\u0435\u0447\u0438\u0432\u0430\u043d\u0438\u0435\u043c: \u0432 [\u0434\u0430\u043d\u043d\u043e\u0439 \u0441\u0442\u0430\u0442\u044c\u0435](https:\/\/journals.plos.org\/plosone\/article?id=10.1371\/journal.pone.0029740) \u0443\u0442\u0432\u0435\u0440\u0436\u0434\u0430\u0435\u0442\u0441\u044f, \u0447\u0442\u043e \u044d\u0442\u043e\u0442 \u043c\u0435\u0442\u043e\u0434 \u0443\u043b\u0443\u0447\u0448\u0430\u0435\u0442 \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0438\u0435. \u041e\u0434\u043d\u0430\u043a\u043e \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u044f \u0433\u0430\u043c\u043c\u0430-\u043a\u043e\u0440\u0440\u0435\u043a\u0446\u0438\u0438 \u0432\u044b\u0437\u044b\u0432\u0430\u0435\u0442 \u0432 tensorflow \u0442\u0430\u043a\u043e\u0439 \u044d\u0444\u0444\u0435\u043a\u0442, \u0447\u0442\u043e \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0435 \u043e\u0431\u0443\u0447\u0430\u0435\u0442\u0441\u044f \u0432\u043e\u043e\u0431\u0449\u0435 (\u043d\u0430 GPU) \u0438\u043b\u0438 \u0434\u0430\u0435\u0442 loss = NaN (\u043d\u0430 TPU), \u0445\u043e\u0442\u044f \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043b\u0435\u043d\u043e, \u0447\u0442\u043e \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u0432 \u0442\u0435\u043d\u0437\u043e\u0440\u0435 \u043f\u043e\u0441\u043b\u0435 \u0434\u0430\u043d\u043d\u043e\u0439 \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0438 (\u043c\u0438\u043d\u0438\u043c\u0443\u043c, \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c, \u0441\u0440\u0435\u0434\u043d\u0435\u0435) \u043f\u0440\u0438\u043d\u0446\u0438\u043f\u0438\u0430\u043b\u044c\u043d\u043e \u043d\u0435 \u043c\u0435\u043d\u044f\u044e\u0442\u0441\u044f. \u041f\u043e\u044d\u0442\u043e\u043c\u0443 \u0434\u043e \u0440\u0435\u0448\u0435\u043d\u0438\u044f \u044d\u0442\u043e\u0439 \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u044b \u043f\u0440\u0438\u0434\u0435\u0442\u0441\u044f \u043e\u0442 \u043d\u0435\u0435 \u043e\u0442\u043a\u0430\u0437\u0430\u0442\u044c\u0441\u044f.\n\n\u0421\u0432\u043e\u0438 \u0441\u043e\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u043f\u043e \u043f\u043e\u0432\u043e\u0434\u0443 \u0442\u043e\u0433\u043e, \u043f\u043e\u0447\u0435\u043c\u0443 \u0446\u0432\u0435\u0442\u043d\u043e\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0430\u0432\u0442\u043e\u043c\u043e\u0431\u0438\u043b\u0435\u0439 \u043c\u043e\u0436\u0435\u0442 \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u0442\u044c\u0441\u044f \u043b\u0443\u0447\u0448\u0435 \u0447\u0435\u0440\u043d\u043e-\u0431\u0435\u043b\u043e\u0433\u043e, \u044f \u0438\u0437\u043b\u043e\u0436\u0438\u043b [\u0437\u0434\u0435\u0441\u044c](https:\/\/vk.com\/wall-186970284_25).","60c94f72":"# \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u0438\u0437 \u0444\u0430\u0439\u043b\u043e\u0432 .tfrec\n\n\u0422\u0435\u043f\u0435\u0440\u044c, \u043a\u043e\u0433\u0434\u0430 \u0443 \u043d\u0430\u0441 \u0435\u0441\u0442\u044c \u0444\u0430\u0439\u043b\u044b .tfrec \u0432 Google cloud, \u043c\u044b \u0434\u043e\u043b\u0436\u043d\u044b \u0438\u0445 \u0441\u0447\u0438\u0442\u0430\u0442\u044c \u0438 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f. \u041f\u0435\u0440\u0435\u0434 \u044d\u0442\u0438\u043c \u043d\u0443\u0436\u043d\u043e \u043d\u0435 \u0437\u0430\u0431\u044b\u0442\u044c \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c TPU."}}