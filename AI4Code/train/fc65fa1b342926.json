{"cell_type":{"640fdb9e":"code","96e998e8":"code","9fe6b137":"code","1dc9552a":"code","90b5086e":"code","cba188fe":"code","5eded312":"code","7d6259df":"code","410b3013":"code","4373317b":"code","f427306b":"code","d7c91df7":"code","9355502c":"code","9de0fca1":"code","00b26c15":"code","b432378a":"code","d854b19c":"code","d6fea4a0":"code","1c08bc8c":"code","ac448641":"code","47eab90f":"code","bd4401b7":"code","6ba288be":"code","8a372239":"code","1d9629d2":"code","26f6b6bf":"markdown","62b68148":"markdown","dcbaea04":"markdown","0db4c85e":"markdown","e19192d7":"markdown","e555f054":"markdown","cffc3fe6":"markdown","5a931b20":"markdown","43792a3c":"markdown","b229c5b2":"markdown"},"source":{"640fdb9e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport nltk\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk import pos_tag\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nfrom gensim.models import Word2Vec, KeyedVectors\nimport string\nimport matplotlib.pyplot as plt\nimport math\nimport re\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","96e998e8":"sentence_size = 128\nword_vector_size = 128\nword_vector_window = 5\nepochs = 10\nlearning_rate = 0.000035 \nbatch_size = 32\nhidden_size =512\nn_layers=3","9fe6b137":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","1dc9552a":"train_df = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntrain_df.head()","90b5086e":"test_df = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')\ntest_df.head()","cba188fe":"train_df.drop(['id','keyword','location'],axis=1, inplace = True)\ntrain_df.head()","5eded312":"test_df.drop(['keyword','location'],axis=1, inplace = True)\ntest_df.head()","7d6259df":"train_raw_x = train_df['text']\ntest_raw_x = test_df['text']","410b3013":"def processText(text, target_length=None):\n    \n    start_token='<start>'\n    end_token = '<end>'\n    \n    #text = ''.join(char for char in text.lower() if char not in string.punctuation)   #Make all lower case and remove punctuations\n    text = text.lower()\n    \n    text = re.sub(r'[^\\w\\s]','',text) # remove punctuation\n    text = re.sub(\" \\d+\", \" \", text) # remove pure number strings\n    text = re.sub(r'http\\S+','', text)\n    \n    \n    tokens = word_tokenize(text)\n    \n    stopword =  stopwords.words('english')\n    \n    tokens =  [token for token in tokens if token not in stopword]\n    \n    lemmatizer = WordNetLemmatizer()\n    lemmatized_tokens =  [lemmatizer.lemmatize(token) for token in tokens]\n    \n    lemmatized_tokens.insert(0,start_token)\n    lemmatized_tokens.append(end_token)\n    \n    if target_length == None:\n        return lemmatized_tokens\n    \n    while len(lemmatized_tokens) < target_length:\n        lemmatized_tokens.extend(lemmatized_tokens)\n    \n    return lemmatized_tokens[0:target_length]","4373317b":"processed_trained_x = [processText(sentence,sentence_size) for sentence in train_raw_x]\nprocessed_test_x = [processText(sentence,sentence_size) for sentence in test_raw_x]\n","f427306b":"all_x =processed_trained_x + processed_test_x","d7c91df7":"vector_model = Word2Vec(all_x,min_count=1,vector_size=word_vector_size,window=word_vector_window)\nvector =  vector_model.wv","9355502c":"vector_train_x = []\nfor sentence in processed_trained_x:\n    vector_train_x.append([vector[token].tolist() for token in sentence])","9de0fca1":"vector_test_x = []\nfor sentence in processed_test_x:\n    vector_test_x.append([vector[token].tolist() for token in sentence])","00b26c15":"#x_train, x_validation, y_train ,y_validation = train_test_split(vector_train_x, train_df['target'],test_size = .2)\nx_train , y_train = vector_train_x , train_df['target']","b432378a":"class NLPData(Dataset):\n    def __init__(self):\n        self.x_data = torch.tensor(x_train ) #vector_train_x)\n        self.y_data = torch.tensor(list(y_train),dtype=torch.float32)\n        self.n_samples =  len(self.y_data)\n    \n    def __getitem__(self,idx):\n        return self.x_data[idx] , self.y_data[idx]\n    \n    def __len__(self):\n        return self.n_samples\ndataset = NLPData()","d854b19c":"train_loader = DataLoader(dataset = dataset, batch_size = batch_size, shuffle = True )","d6fea4a0":"class LSTMNN(nn.Module):\n    def __init__(self):\n        super(LSTMNN,self).__init__()\n        \n        self.n_layers = n_layers\n        self.hidden_size = hidden_size\n        \n        self.lstm = nn.LSTM(word_vector_size,hidden_size,n_layers,batch_first=True)\n        self.fc1 = nn.Linear(hidden_size,hidden_size)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.2)\n        self.fc2 = nn.Linear(hidden_size,hidden_size)\n        self.fc3 = nn.Linear(hidden_size,1)\n        self.sigmoid = nn.Sigmoid()\n    \n    def forward(self,x):\n        h0 = torch.zeros(self.n_layers, x.size(0), self.hidden_size).to(device)\n        c0 = torch.zeros(self.n_layers, x.size(0), self.hidden_size).to(device)\n        \n        out, _ = self.lstm(x, (h0,c0))\n        out = out[:,-1,:]\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.fc1(out)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.fc2(out)\n        out = self.relu(out)\n        out = self.dropout(out)\n        out = self.fc3(out)\n        out = self.sigmoid(out)\n        \n        return out\n\nmodel = LSTMNN().to(device)","1c08bc8c":"criterion = nn.BCELoss()\noptimizer = torch.optim.RMSprop(model.parameters(),lr=learning_rate)","ac448641":"all_loss =[]\nfor epoch in range(epochs):\n    for x,y in train_loader:\n        x,y = x.to(device), y.to(device).view(-1,1) \n        \n        y_hat =  model(x)\n        \n        loss = criterion(y_hat,y)\n        \n        if(loss.item()<0.2): \n            break\n        all_loss.append(loss.item())\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    print(f'Epoch: {epoch+1} Loss: {loss.item()}')\n    if(loss.item()<0.2): \n            break","47eab90f":"plt.figure(figsize=(24,6))\nplt.plot(all_loss)","bd4401b7":"model.eval()","6ba288be":"x_test = torch.tensor(vector_test_x).to(device)\n#x_validation = torch.tensor(x_validation).to(device)\n#y_pred = model(x_validation)\ny_pred = model(x_test)\nwith torch.no_grad():\n    y_pred =  np.round(y_pred.to('cpu').numpy()).astype(np.int32)","8a372239":"test_df.drop(['text'],axis=1,inplace=True)\ntest_df['target']=y_pred\ntest_df.to_csv('output.csv',index=False)","1d9629d2":"#y_pred = y_pred.reshape(-1)\n#(y_pred == y_validation).sum()\/len(y_pred)","26f6b6bf":"# Training Loop","62b68148":"# Evaluation","dcbaea04":"# Forming word vectors using Word2Vec","0db4c85e":"# Test\/Validation split","e19192d7":"# Device","e555f054":"# Dataset and Data","cffc3fe6":"# Preprocessing","5a931b20":"# Model, loss and optimizer","43792a3c":"# Hyperparameters","b229c5b2":"# Load Data"}}