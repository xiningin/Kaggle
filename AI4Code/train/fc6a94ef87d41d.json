{"cell_type":{"e3543d71":"code","ad4405ac":"code","0693e80b":"code","ea4946fa":"code","fe5db9b6":"code","3827d4f3":"code","7db78f1f":"code","81f80325":"code","540963fb":"code","ecfc02d0":"code","0d5e940f":"code","59f08778":"code","40be86df":"code","4f7c15c8":"code","f8031969":"code","411e0e0e":"code","6d292172":"code","9eca5c47":"code","4ddb6387":"code","f8e2f177":"code","b5f949b4":"code","2cb1b269":"code","20a70e37":"code","b2733eef":"code","0764593e":"code","18b3bb3f":"code","36213057":"code","c36b6ffb":"code","6a8aa55c":"code","2165f526":"code","8f52a660":"markdown","d04c305a":"markdown","1e8469aa":"markdown","4f3a0655":"markdown","dc62e4dc":"markdown","af768db5":"markdown","9c2f922a":"markdown","1ab7c879":"markdown","9accae85":"markdown","06692344":"markdown","d8f5189f":"markdown","2c7e2ac4":"markdown","ddf83f47":"markdown","d5c632bd":"markdown"},"source":{"e3543d71":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\nimport warnings\nwarnings.filterwarnings(\"ignore\")","ad4405ac":"# Some libraries for working in python ................\nimport pandas as pd                 \nimport numpy as np\nimport matplotlib.pyplot as plt   \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import linear_model","0693e80b":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","ea4946fa":"print(\"Train data shape:\", train.shape)\nprint(\"Test data shape:\", test.shape)","fe5db9b6":"print(train.head())","3827d4f3":"plt.style.use(style='ggplot')\nplt.rcParams['figure.figsize'] = (10, 6)\n\nprint (train.SalePrice.describe())","7db78f1f":"print (\"Skew is:\", train.SalePrice.skew())\nplt.hist(train.SalePrice, color='blue')\nplt.show()","81f80325":"target = np.log(train.SalePrice)\nprint (\"\\n Skew is:\", target.skew())\nplt.hist(target, color='blue')\nplt.show()","540963fb":"numeric_features = train.select_dtypes(include=[np.number])\ncorr = numeric_features.corr()\nprint (corr['SalePrice'].sort_values(ascending=False)[:5], '\\n')\nprint (corr['SalePrice'].sort_values(ascending=False)[-5:])","ecfc02d0":"plt.scatter(x=train['GarageArea'], y=target)\nplt.ylabel('Sale Price')\nplt.xlabel('Garage Area')\nplt.show()","0d5e940f":"train = train[train['GarageArea'] < 1200]\n\nplt.scatter(x=train['GarageArea'], y=np.log(train.SalePrice))\nplt.xlim(-200,1600)     # This forces the same scale as before\nplt.ylabel('Sale Price')\nplt.xlabel('Garage Area')\nplt.show()","59f08778":"nulls = pd.DataFrame(train.isnull().sum().sort_values(ascending=False)[:25])\nnulls.columns = ['Null Count']\nnulls.index.name = 'Feature'\n#nulls\nprint(nulls)","40be86df":"categoricals = train.select_dtypes(exclude=[np.number])\n#categoricals.describe()\nprint(categoricals.describe())","4f7c15c8":"print (\"Original: \\n\")\nprint (train.Street.value_counts(), \"\\n\")","f8031969":"train['enc_street'] = pd.get_dummies(train.Street, drop_first=True)\ntest['enc_street'] = pd.get_dummies(test.Street, drop_first=True)","411e0e0e":"print ('Encoded: \\n')\nprint (train.enc_street.value_counts())","6d292172":"condition_pivot = train.pivot_table(index='SaleCondition', values='SalePrice', aggfunc=np.median)\ncondition_pivot.plot(kind='bar', color='blue')\nplt.xlabel('Sale Condition')\nplt.ylabel('Median Sale Price')\nplt.xticks(rotation=0)\nplt.show()","9eca5c47":"def encode(x): return 1 if x == 'Partial' else 0\ntrain['enc_condition'] = train.SaleCondition.apply(encode)\ntest['enc_condition'] = test.SaleCondition.apply(encode)\n\ncondition_pivot = train.pivot_table(index='enc_condition', values='SalePrice', aggfunc=np.median)\ncondition_pivot.plot(kind='bar', color='blue')\nplt.xlabel('Encoded Sale Condition')\nplt.ylabel('Median Sale Price')\nplt.xticks(rotation=0)\nplt.show()","4ddb6387":"data = train.select_dtypes(include=[np.number]).interpolate().dropna()\n\n# sum(data.isnull().sum() != 0)\nprint(sum(data.isnull().sum() != 0))","f8e2f177":"y = np.log(train.SalePrice)\nX = data.drop(['SalePrice', 'Id'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=.33)\nlr = linear_model.LinearRegression()\nmodel = lr.fit(X_train, y_train)","b5f949b4":"print(\"R^2 is: \\n\", model.score(X_test, y_test))","2cb1b269":"predictions = model.predict(X_test)\n\nprint('RMSE is: \\n', mean_squared_error(y_test, predictions))\n\nactual_values = y_test\nplt.scatter(predictions, actual_values, alpha=.75,\n            color='b')  # alpha helps to show overlapping data\nplt.xlabel('Predicted Price')\nplt.ylabel('Actual Price')\nplt.title('Linear Regression Model')\nplt.show()","20a70e37":"for i in range (-2, 3):\n    alpha = 10**i\n    rm = linear_model.Ridge(alpha=alpha)\n    ridge_model = rm.fit(X_train, y_train)\n    preds_ridge = ridge_model.predict(X_test)\n\n    plt.scatter(preds_ridge, actual_values, alpha=.75, color='b')\n    plt.xlabel('Predicted Price')\n    plt.ylabel('Actual Price')\n    plt.title('Ridge Regularization with alpha = {}'.format(alpha))\n    overlay = 'R^2 is: {}\\nRMSE is: {}'.format(\n                    ridge_model.score(X_test, y_test),\n                    mean_squared_error(y_test, preds_ridge))\n    plt.annotate(s=overlay,xy=(12.1,10.6),size='x-large')\n    plt.show()","b2733eef":"from sklearn.model_selection import train_test_split , KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\nX_train, X_test, y_train, y_test = train_test_split(data.drop('SalePrice', axis=1), data['SalePrice'], test_size=0.2, random_state=42)","0764593e":"X_train, X_test, y_train, y_test = train_test_split(data.drop('SalePrice', axis=1), data['SalePrice'], test_size=0.2, random_state=42)","18b3bb3f":"import xgboost\n\nxgb = xgboost.XGBRegressor(colsample_bytree=0.4,\n                 gamma=0,                 \n                 learning_rate=0.07,\n                 max_depth=3,\n                 min_child_weight=1.5,\n                 n_estimators=10000,                                                                    \n                 reg_alpha=0.75,\n                 reg_lambda=0.45,\n                 subsample=0.6,\n                 seed=42)\nxgb.fit(X_train,y_train)\ny_test_pred_2 = xgb.predict(X_test)\ny_train_pred_2= xgb.predict(X_train)","36213057":"print('MSE train: %.3f, test: %.3f' % (\n        mean_squared_error(y_train, y_train_pred_2),\n        mean_squared_error(y_test, y_test_pred_2)))\nprint('R^2 train: %.3f, test: %.3f' % (\n        r2_score(y_train, y_train_pred_2),\n        r2_score(y_test, y_test_pred_2)))\n","c36b6ffb":"submission = pd.DataFrame()\nsubmission['Id'] = test.Id\nfeats = test.select_dtypes(\n    include=[np.number]).drop(['Id'], axis=1).interpolate()\npredictions = model.predict(feats)\nfinal_predictions = np.exp(predictions)\n\nprint(\"Original predictions are: \\n\", predictions[:10], \"\\n\")\nprint(\"Final predictions are: \\n\", final_predictions[:10])\n","6a8aa55c":"submission['SalePrice'] = final_predictions\nprint(submission.head())","2165f526":"submission.to_csv('submission1.csv', index=False)\nprint('Submission saved!')\n","8f52a660":"# Loading Dataset","d04c305a":"## XGBoost","1e8469aa":"## Scatter Plot","4f3a0655":"# Data Preprocessing","dc62e4dc":"## Skewness:\n### Skewness is the measure of how much the probability distribution of a random variable deviates from the normal distribution.","af768db5":"![942318-house-purchase.jpg](https:\/\/cdn.dnaindia.com\/sites\/default\/files\/styles\/full\/public\/2020\/12\/09\/942318-house-purchase.jpg)","9c2f922a":"# House Price Prediction \n![selling-home-coronavirus.jpg?w=800&quality=85](http:\/\/api.time.com\/wp-content\/uploads\/2020\/05\/selling-home-coronavirus.jpg?w=800&quality=85)","1ab7c879":"# Importing Libraries","9accae85":"# Checking the Null Values","06692344":"# Categorical Variable Visualization","d8f5189f":"# Final Prediction analysis","2c7e2ac4":"## Hist Plot","ddf83f47":"# Data Modeling","d5c632bd":"### Handling Categorical Variables"}}