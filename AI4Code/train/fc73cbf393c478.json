{"cell_type":{"b5e6fd37":"code","ffe00aa0":"code","ae77faa7":"code","d0b870dd":"code","7ff3a534":"code","aa18a547":"code","01acf311":"code","e5ef3605":"code","d6b27be9":"code","1df4b0ee":"code","af6e5e4f":"code","1f76809a":"code","e73c6aa2":"code","ce99a30e":"code","dd00f3b2":"code","5c23e458":"code","a6388f40":"markdown","228710d0":"markdown","31b6387e":"markdown","ce247323":"markdown","b3e6156e":"markdown","7ec934e9":"markdown","1d083eb5":"markdown","3acd4db9":"markdown"},"source":{"b5e6fd37":"from PIL import Image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm, trange\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nos.listdir(\"..\/input\")\n\n#Version 5 replaces mean squared error with mean absolute error.","ffe00aa0":"def toArray(k):\n    return np.array(list(k.getdata())).reshape(k.size[1], k.size[0], 3)","ae77faa7":"from sklearn.metrics import mean_absolute_error as mae #Because we won't be able to \nfrom skimage.measure import compare_psnr as psnr\n\nos.listdir(\"..\/input\/images\")\ntrain_data = []\nfor img_path in os.listdir(\"..\/input\/images\"):\n    train_data += [Image.open('..\/input\/images\/'+img_path)]\nfor img_path in os.listdir(\"..\/input\/general100\"):\n    train_data += [Image.open('..\/input\/general100\/'+img_path)]\nfor img_path in os.listdir(\"..\/input\/intel-data-scene\/scene_classification\/scene_classification\/train\")[:3000]:\n    train_data += [Image.open('..\/input\/intel-data-scene\/scene_classification\/scene_classification\/train\/'+img_path)]\n","d0b870dd":"img=train_data[30]\nprint(img.size)\nplot5= plt.imshow(img)","7ff3a534":"x, y = img.size\nimg5=img.resize((100,100), resample = Image.LANCZOS)\nimgp = img5.resize((x,y), resample = Image.LANCZOS)\nimg5=img.resize((200,200), resample = Image.LANCZOS)\nimgq = img5.resize((x,y), resample = Image.LANCZOS)\nprint(psnr(toArray(img), toArray(imgp)), psnr(toArray(img), toArray(imgq)))\nprint(mae(toArray(img).reshape(x*y*3), toArray(imgp).reshape(x*y*3)), mae(toArray(img).reshape(x*y*3), toArray(imgq).reshape(x*y*3)))\ntry:\n    print(psnr(toArray(img), toArray(img)))\nexcept:\n    print(\"PSNR is not continuous so I'll train with MAE\")\ncomp = plt.figure(figsize=(9, 13))\nfirst = comp.add_subplot(3,1,1)\nfirst.imshow(img)\nsecond =comp.add_subplot(3,1,2)\nsecond.imshow(imgp)\nsecond =comp.add_subplot(3,1,3)\nsecond.imshow(imgq)\ncomp.show()","aa18a547":"x, y = img.size\nimg5=img.resize((200,200), resample = Image.LANCZOS)\nimgp = img5.resize((x,y), resample = Image.BICUBIC)\nimg5=img.resize((200,200), resample = Image.LANCZOS)\nimgq = img5.resize((x,y), resample = Image.BILINEAR)\nimg5=img.resize((200,200), resample = Image.LANCZOS)\nimgr = img5.resize((x,y), resample = Image.LANCZOS)\nprint(mae(toArray(img).reshape(x*y*3), toArray(imgp).reshape(x*y*3)), mae(toArray(img).reshape(x*y*3), toArray(imgq).reshape(x*y*3)),mae(toArray(img).reshape(x*y*3), toArray(imgr).reshape(x*y*3)))","01acf311":"def imageListToNiceSamples(images, downscale_factor = 2, img_size = 40, n_convolutions = 4): \n    X = []\n    Y = []\n    for image in tqdm(images):\n        cutoff = n_convolutions+1\n        size = np.array(image.size)\n        samples_from_image = size\/\/img_size\n        newimage = image.resize(size\/\/downscale_factor, resample = Image.LANCZOS).resize(size, resample = Image.LANCZOS)\n        try:\n            image_array = toArray(image)\n            newimage_array = toArray(newimage)\n        except:\n            continue\n        X_temp = []\n        Y_temp = []\n      #  print(size, image.size, samples_from_image)\n        for j in range(samples_from_image[0]):\n            for i in range(samples_from_image[1]):\n                x = newimage_array[i*img_size:(i+1)*img_size,j*img_size:(j+1)*img_size,:]\/130-0.99\n                y = image_array[i*img_size+cutoff:(i+1)*img_size-cutoff,j*img_size+cutoff:(j+1)*img_size-cutoff,:]\/130-0.99 #these fit for tanh\n                x = newimage_array[i*img_size:(i+1)*img_size,j*img_size:(j+1)*img_size,:]\/255+0.005\n                y = image_array[i*img_size+cutoff:(i+1)*img_size-cutoff,j*img_size+cutoff:(j+1)*img_size-cutoff,:]\/255+0.005 #these are for sigmoid or no activation - I've found someone not using it.\n                \n                X_temp+=[x.reshape(1,img_size,img_size,3)]\n                Y_temp+=[y.reshape(1,img_size-2*cutoff,img_size-2*cutoff,3)]\n        X+=[np.concatenate(X_temp, axis=0)] # these may look redundant, but they actually keep memory usage from blowing up and kernel from dying\n        Y+=[np.concatenate(Y_temp, axis=0)]\n    return(np.concatenate(X, axis=0), np.concatenate(Y, axis=0))","e5ef3605":"image_size = 30\nn_convolutions = 4\nX_train, y_train = imageListToNiceSamples(train_data, img_size = image_size, downscale_factor = 4)","d6b27be9":"from keras.models import Sequential, Model\nfrom keras.layers import Conv2D, Dense, Activation, Dropout, Lambda, MaxPooling2D, BatchNormalization, Reshape, Flatten, Input\nfrom keras.optimizers import Nadam\nfrom keras.callbacks import EarlyStopping","1df4b0ee":"def getModel(lr = 0.002, dropout_rate = .2, input_dropout = .2, mid_layer_size = 64, activation = 'sigmoid', image_size =40): # encapsulation to facilitate skopt usage, even though I didn't use it in the end.\n    opt = Nadam(lr)\n\n    \n    model = Sequential()\n    model.add(Dropout(input_dropout, input_shape = (image_size,image_size,3)))\n    model.add(Conv2D(32, (3,3), activation = 'elu', padding = 'valid', \n                     \n                    ))\n #   model.add(Dropout(dropout_rate))\n    model.add(BatchNormalization())\n    model.add(Conv2D(mid_layer_size, (3,3), activation = 'elu', padding = 'valid'))\n #   model.add(Dropout(dropout_rate))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, (3,3), activation = 'elu', padding = 'valid'))\n  #  model.add(Dropout(dropout_rate))\n    model.add(BatchNormalization())\n    \n    # I'll compute size of the dense layer:\n    n= (image_size-6)*(image_size-6)*3\n    model.add(Flatten())\n    model.add(Dense(n, activation = 'elu'))\n    model.add(Reshape((image_size-6, image_size-6, 3)))\n    \n    model.add(Conv2D(3, (5,5), activation = 'relu',  padding = 'valid'))\n    \n    n= (image_size-10)*(image_size-10)*3\n    model.add(Flatten())\n    model.add(Dense(n, activation = 'relu'))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(n, activation = 'relu'))\n    model.add(Dropout(dropout_rate))\n    model.add(Reshape((image_size-10, image_size-10, 3)))\n    \n    model.add(Conv2D(3, (5,5), activation = activation, padding = 'same', name = 'output_layer'))\n    \n    model.compile(loss = 'mean_absolute_error', optimizer = opt)\n    return(model)\n\nprint(X_train.shape)\nprint(y_train.shape)","af6e5e4f":"mae(X_train[:,5:image_size-5,5:image_size-5,:].reshape(-1,((image_size-10)*(image_size-10)*3)), y_train.reshape(-1,(image_size-10)*(image_size-10)*3)) # Because mse takes array of dim <=2","1f76809a":"model = getModel(dropout_rate = .35, input_dropout = 0.0, image_size = image_size, mid_layer_size = 64)\nmodel.summary() #to give overview of number of params\nstop = EarlyStopping(patience=10, restore_best_weights = True)\nmodel.fit(X_train, y_train, batch_size = 32, epochs = 100, validation_split = 0.2, callbacks = [stop], verbose = True)","e73c6aa2":"mae(model.predict(X_train).reshape(-1,(image_size-2-2*n_convolutions)**2*3), y_train.reshape(-1,(image_size-2-2*n_convolutions)**2*3)) ","ce99a30e":"comp = plt.figure(figsize=(9, 13))\nfirst = comp.add_subplot(3,1,1)\nfirst.imshow(y_train[30])\nsecond =comp.add_subplot(3,1,2)\nsecond.imshow(X_train[30])\nsecond =comp.add_subplot(3,1,3)\nsecond.imshow(model.predict(np.array([X_train[30]]))[0])\ncomp.show()","dd00f3b2":"#from skopt import gp_minimize\n#from skopt.space import Real, Integer\n#dropout_rate_space = Real(low = 0.0, high = 0.7)\n#mid_layer_size_space = Integer(low = 16, high = 512)\n#def f(v):\n#    model = getModel(dropout_rate = v[0], mid_layer_size= v[1])\n#    model.fit(X_train, y_train, batch_size = 32, epochs = 100, validation_split = 0.2, callbacks = [stop], verbose = False)\n#    return(mse(model.predict(X_train).reshape(-1,(image_size-2-2*n_convolutions)**2*3), y_train.reshape(-1,(image_size-2-2*n_convolutions)**2*3)) )","5c23e458":"#res = gp_minimize(f, [dropout_rate_space, mid_layer_size_space],\n#                  n_calls = 50, n_random_starts = 6, verbose = True\n#                 )\n#print(res.v)","a6388f40":"**I'll load image data and show a few values:**","228710d0":"Now I'll generate some training samples:","31b6387e":"And graphically:","ce247323":"I'd like to beat lanczos, because otherwise there isn't much point to using any of these methods.\n\nThe only way to have larger output, that I know of, is Conv2DTransposed which may also be worth looking at, but I don't see how it could be better in principle than using lanczos first.\n\nFor the Keras model:","b3e6156e":"The below code was used to tweak hyperparameters but didn't show me anything substantially better.","7ec934e9":"**Comparison of different upsamplings** ","1d083eb5":"It seems to have gone after the identity map and not overfitting.\n\nTweaking input dropout we can discourage it from learning identity, but I'm not convinced it's a local minumum.\n\nLet's have a look at how bad the final result is:","3acd4db9":"This should give an idea about what we want to beat."}}