{"cell_type":{"064f12b6":"code","24a7f468":"code","5a67e93e":"code","bd538c8a":"code","0124b3d8":"code","240f3a86":"code","d3428d0f":"code","1da0c01f":"code","33a9cfe4":"code","978c09ab":"code","a759bca5":"code","450b7842":"code","91bce8b2":"code","4b49da96":"code","59db1d8e":"code","a96b1cc0":"code","547ff5df":"code","cbae9aa6":"markdown","763f1051":"markdown","dd7e2962":"markdown","8ca3e5a5":"markdown","52d20b32":"markdown","e3f678a5":"markdown","6ae15a1e":"markdown","27863e01":"markdown","efe43f22":"markdown","2c6ca882":"markdown","6384a501":"markdown","9ae2ae7a":"markdown"},"source":{"064f12b6":"!pip install note_seq\n!pip install librosa","24a7f468":"import math\nimport os\nimport glob\nimport time\n\nimport numpy as np\nimport librosa\nimport note_seq\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import LSTM, Bidirectional, GRU, Dense, Dropout, BatchNormalization, Input, Flatten, Reshape, GlobalAveragePooling1D\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","5a67e93e":"len_seq = 0.1","bd538c8a":"MIDI_paths = []\nMP3_paths = []\n\nfor name in glob.glob('..\/input\/themaestrodatasetv2\/maestro-v2.0.0\/2004\/*.midi'):\n    MIDI_paths.append(name)\n    MP3_paths.append(name[:-4] + \"mp3\")","0124b3d8":"def preprocess_wave_and_midi(MIDI_path, MP3_path, len_seq):\n    \n    y, sr = librosa.load(MP3_path)\n    \n    ns = note_seq.midi_file_to_sequence_proto(MIDI_path)\n\n    start_len = 0\n    end_len = ns.notes[len(ns.notes) - 1].end_time\n\n    x = [i.pitch for i in ns.notes]\n    min_pitch = min(x)\n    max_pitch = max(x)\n\n    time_step = np.arange(start_len,end_len,0.01)\n\n    onehot = np.zeros((len(time_step),128))\n\n    for i in ns.notes:\n        note = i.pitch\n        for x in range(int(i.start_time*100), int(i.end_time*100)):\n            onehot[x, note] = i.velocity\n\n    num_batches = math.ceil(len(y) \/ (sr * len_seq))\n\n    for _ in range(int(num_batches * len_seq * 100) - len(onehot)):\n        onehot = np.append(onehot, [np.zeros((128))], axis = 0)\n\n    onehot = onehot.reshape(num_batches,int(len_seq * 100),128)\n\n    y = np.pad(y, (0, int(sr * len_seq * num_batches)-len(y) ), 'constant')\n\n    input_data = y.reshape(num_batches, int(len_seq * sr))\n    \n    return input_data, onehot","240f3a86":"N_files = 25\n\nX = []\nY = []\n\nfor a, b in zip(MIDI_paths[:N_files], MP3_paths[:N_files]):\n    input_data, output_data = preprocess_wave_and_midi(a,b, len_seq)\n    X.append(input_data)\n    Y.append(output_data)\n    \nX = np.concatenate(X, axis = 0)\nY = np.concatenate(Y, axis = 0)","d3428d0f":"X = X.reshape(X.shape[0],1,int(22050 * len_seq))","1da0c01f":"model = keras.Sequential()\n\nmodel.add(Input(shape=(1,(int(22050 * len_seq)))))\nmodel.add(LSTM(256, activation='relu', return_sequences=True))\nmodel.add(BatchNormalization())\nmodel.add(LSTM(512, activation='relu', return_sequences=True))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(100 * len_seq * 128))\nmodel.add(Reshape((int(len_seq * 100), 128)))\n\nmodel.summary()\nmodel.compile(loss='MSE', optimizer='adam')","33a9cfe4":"history = model.fit(x = X, y = Y, batch_size = 64, epochs = 20, validation_split=0.05, shuffle=False)","978c09ab":"model.save(\"model_LSTM.h5\")","a759bca5":"def show_history(history):\n    plt.figure()\n    for key in history.history.keys():\n        plt.plot(history.epoch, history.history[key], label=key)\n    plt.legend()\n    plt.tight_layout()","450b7842":"show_history(history)","91bce8b2":"def show_plot(midi_data):\n    sns.heatmap(midi_data)\n    plt.show()\n\ndef load_wav(filename):\n    len_seq = 0.1\n    y, sr = librosa.load(filename)\n    num_batches = math.ceil(len(y) \/ (sr * len_seq))\n    y = np.pad(y, (0, int(sr * len_seq * num_batches) - len(y)), 'constant')\n    input_data = y.reshape(num_batches, 1, int(len_seq * sr))\n    return input_data\n\ndef note_to_bar(X):\n    notes = []\n    for timee, i in enumerate(X):\n        tmp = []\n        for pitch, vel in enumerate(i):\n\n            if math.isnan(vel):\n                vel = 0\n            if vel != 0:\n                tmp.append([timee * 5, vel, pitch])\n        notes.append(tmp)\n    return notes","4b49da96":"X_test_path = MP3_paths[100]\nY_test_path = MIDI_paths[100]\n\nX_test = load_wav(X_test_path)","59db1d8e":"_, Y_test = preprocess_wave_and_midi(Y_test_path,X_test_path, len_seq)\n\nY_test = Y_test.reshape(Y_test.shape[0]*Y_test.shape[1], 128)","a96b1cc0":"prediction = model.predict(X_test)\nlen_in = len(prediction) * 10\nnotes_pred = prediction.reshape(len_in, 128)\nnotes_pred = np.where(notes_pred > 3 , notes_pred, 0)","547ff5df":"fig, (ax,ax2) = plt.subplots(ncols=2, figsize=(12,20))\n\nsns.heatmap(notes_pred[300:1170], ax=ax)\nsns.heatmap(Y_test[300:1170], ax=ax2)\nplt.show()","cbae9aa6":"### Install and import requiements","763f1051":"## AudioTranscription with neural model for dataset Maestrov2 \n\nThe main idea of this notebook is to transfer **audio to MIDI** using neural network. Will be use only small part of dataset Maestrov2. \n\nApproach **without** using **Fast Fourier Transformers** or other **math method**.","dd7e2962":"LSTM requirement different shape (3-dimension)","8ca3e5a5":"Select the number of files that will be converted to a sequence of inputs and outputs and split into one input and one output field. Be careful of memory limitations. TODO -> improve performance","52d20b32":"Saving model for future usage","e3f678a5":"### Heatmap predicted and true notes in time\n127 size array represent 127 keys on piano","6ae15a1e":"#### Train model","27863e01":" ### Neural network model:\n 1) RNN - simple recurent neural network with using LSTM.","efe43f22":"### Prediction","2c6ca882":"#### Prepare data\nCreate list paths for midi and mp3 files.","6384a501":"\nSplit **WAV to chunks** of length sequence and pair with **MIDI sequence** which is represented by **OneHotEncoding**.","9ae2ae7a":"Set the length of sequence"}}