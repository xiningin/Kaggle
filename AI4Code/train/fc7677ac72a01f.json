{"cell_type":{"418f69e6":"code","aeffc884":"code","89bdf66a":"code","7950be29":"code","09fa656f":"code","78f888f2":"code","05a5634b":"code","4ca0816c":"code","9a0631b4":"code","2f69294a":"code","efd01808":"code","aed9bb69":"code","db91aa7b":"code","7ef9d6e9":"code","e3fb51b6":"code","6b0c04d0":"code","de000344":"code","f9cfd961":"code","8ad3871a":"code","338fa5b2":"code","d5f723ee":"code","9ad9852b":"code","b6986ee4":"code","a9945115":"code","7496f98a":"code","24569479":"code","5ddfab1d":"code","f0870bd2":"code","dc7eabc3":"code","a340a3d9":"code","c507ce40":"code","41be2075":"code","0a8a0fb2":"code","ed8cf27c":"code","f0b1ce03":"code","623c9458":"code","b6f820e5":"code","fadf2589":"code","d1c4c2cd":"code","f21c5987":"markdown","5221af93":"markdown","91d4b00a":"markdown","4ec5d7d4":"markdown","11567521":"markdown","a561bdf5":"markdown","87987a46":"markdown","3f8bc463":"markdown","37f77764":"markdown","3da009a3":"markdown","cbf3dfea":"markdown","121c2ce9":"markdown"},"source":{"418f69e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aeffc884":"import json\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\n%matplotlib inline\ninline_rc = dict(mpl.rcParams)","89bdf66a":"print(os.listdir(\"..\/input\"))","7950be29":"# We only use the first 100,000 data in this assignment\nbus = []\nwith open('..\/input\/yelp-dataset\/yelp_academic_dataset_business.json') as fl:\n    for i, line in enumerate(fl):\n        bus.append(json.loads(line))\n        if i+1 >= 100000:\n            break\ndf = pd.DataFrame(bus)\ndf.head()","09fa656f":"df.dropna()","78f888f2":"x=df['stars'].value_counts()\nx=x.sort_index()\n#plot\nplt.figure(figsize=(8,4))\nax= sns.barplot(x.index, x.values, alpha=0.8)\nplt.title(\"Star Rating Distribution\")\nplt.ylabel('# of businesses', fontsize=12)\nplt.xlabel('Star Ratings ', fontsize=12)","05a5634b":"#condition RESTAURANTS ONLY\ncond = df['categories'].str.contains('Restaurants')==True\n","4ca0816c":"newdf = df[cond]\nnewdf","9a0631b4":"#check if correct\nnewdf['categories'].str.contains('Restaurants')\n#correct","2f69294a":"business_catg = newdf.copy()\nbusiness_catg = business_catg.drop(['name','city','state','address','postal_code', 'latitude','longitude','stars','review_count','is_open','attributes', 'hours'], axis=1)\nbusiness_catg","efd01808":"!pip install nltk\n","aed9bb69":"# review data\nrev = []\nwith open('..\/input\/yelp-dataset\/yelp_academic_dataset_review.json') as fl:\n    for i, line in enumerate(fl):\n        rev.append(json.loads(line))\n        if i+1 >= 100000:\n            break\nrev_df = pd.DataFrame(rev)\nrev_df.head()","db91aa7b":"rev_df.dropna()\nrev_df","7ef9d6e9":"print(rev_df.columns)\nprint(rev_df.shape)","e3fb51b6":"!pip install spacy","6b0c04d0":"reviews = rev_df[rev_df.stars!=3] \nreviews['label'] = reviews['stars'].apply(lambda x: 1 if x<3 else 0)#1 = \u0e40\u0e14\u0e32\u0e27\u0e48\u0e32 neg\nreviews = reviews.drop('stars',axis=1)\nreviews","de000344":"#condition to extract only label = 1\nfew_star = reviews['label']==1","f9cfd961":"bad_reviews = reviews[few_star]\nbad_reviews","8ad3871a":"del bad_reviews['label']","338fa5b2":"bad_reviews","d5f723ee":"#bad_reviews x catg_df\nbad_res_rev = pd.merge(bad_reviews, business_catg, how='inner')\nbad_res_rev","9ad9852b":"bad_txt = bad_res_rev.text.values","b6986ee4":"bad_txt[2]","a9945115":"type(bad_txt)","7496f98a":"import re\n#import numpy as np\n#import pandas as pd\nfrom pprint import pprint\n\n# Gensim\nimport gensim\nimport gensim.corpora as corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models import CoherenceModel\n\n# spacy for lemmatization\nimport spacy\n\n# Plotting tools\nimport pyLDAvis\nimport pyLDAvis.gensim  # don't skip this\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Enable logging for gensim - optional\nimport logging\nlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\",category=DeprecationWarning)","24569479":"import nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')\nstop_words.extend(['from', 'subject', 're', 'edu', 'use'])","5ddfab1d":"bad_lst = bad_res_rev.text.values.tolist()\nbad_lst[:2]","f0870bd2":"def sent_to_words(sentences):\n    for sentence in sentences:\n        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n\nbad_words = list(sent_to_words(bad_lst))\nbad_words[:2]","dc7eabc3":"# Build the bigram and trigram models\nbigram = gensim.models.Phrases(bad_words, min_count=5, threshold=100) # higher threshold fewer phrases.\ntrigram = gensim.models.Phrases(bigram[bad_words], threshold=100)  \n\n# Faster way to get a sentence clubbed as a trigram\/bigram\nbigram_mod = gensim.models.phrases.Phraser(bigram)\ntrigram_mod = gensim.models.phrases.Phraser(trigram)\n\n# See trigram example\nprint(trigram_mod[bigram_mod[bad_words[0]]])","a340a3d9":"# Define functions for stopwords, bigrams, trigrams and lemmatization\ndef remove_stopwords(texts):\n    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n\ndef make_bigrams(texts):\n    return [bigram_mod[doc] for doc in texts]\n\ndef make_trigrams(texts):\n    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n\ndef lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n    \"\"\"https:\/\/spacy.io\/api\/annotation\"\"\"\n    texts_out = []\n    for sent in texts:\n        doc = nlp(\" \".join(sent)) \n        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n    return texts_out","c507ce40":"# Remove Stop Words\nbad_words_nostops = remove_stopwords(bad_words)\n\n# Form Bigrams\nbad_words_bigrams = make_bigrams(bad_words_nostops)\n\n# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n# python3 -m spacy download en\nnlp = spacy.load('en', disable=['parser', 'ner'])\n\n# Do lemmatization keeping only noun, adj, vb, adv\nbad_words_lemmatized = lemmatization(bad_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n\nprint(bad_words_lemmatized[:1])","41be2075":"# Create Dictionary\nid2word = corpora.Dictionary(bad_words_lemmatized)\n\n# Create Corpus\ntexts = bad_words_lemmatized\n\n# Term Document Frequency\ncorpus = [id2word.doc2bow(text) for text in texts]\n\n# View\nprint(corpus[:1])","0a8a0fb2":"# Human readable format of corpus (term-frequency)\n[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]","ed8cf27c":"id2word[0]","f0b1ce03":"# Build LDA model\nlda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n                                           id2word=id2word,\n                                           num_topics=20, \n                                           random_state=100,\n                                           update_every=1,\n                                           chunksize=100,\n                                           passes=10,\n                                           alpha='auto',\n                                           per_word_topics=True)","623c9458":"# Print the Keyword in the 10 topics\npprint(lda_model.print_topics())\ndoc_lda = lda_model[corpus]","b6f820e5":"# Compute Perplexity\nprint('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n\n# Compute Coherence Score\ncoherence_model_lda = CoherenceModel(model=lda_model, texts=bad_words_lemmatized, dictionary=id2word, coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nCoherence Score: ', coherence_lda)","fadf2589":"# Visualize the topics\n#clustering of the topics.\npyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\nvis","d1c4c2cd":"#Wordcloud of Top N words in each topic\nfrom matplotlib import pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.colors as mcolors\n\ncols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n\ncloud = WordCloud(stopwords=stop_words,\n                  background_color='white',\n                  width=2500,\n                  height=1800,\n                  max_words=10,\n                  colormap='tab10',\n                  color_func=lambda *args, **kwargs: cols[i],\n                  prefer_horizontal=1.0)\n\ntopics = lda_model.show_topics(formatted=False)\n\nfig, axes = plt.subplots(2, 2, figsize=(10,10), sharex=True, sharey=True)\n\nfor i, ax in enumerate(axes.flatten()):\n    fig.add_subplot(ax)\n    topic_words = dict(topics[i][1])\n    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n    plt.gca().imshow(cloud)\n    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n    plt.gca().axis('off')\n\n\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.axis('off')\nplt.margins(x=0, y=0)\nplt.tight_layout()\nplt.show()","f21c5987":"From the word cloud we can see that top words in negative reviews are badwords, food related words and service related words like toilet. I also assume that topic 3 may be about staffs because there are words describing people.","5221af93":"## Filter Restaurants","91d4b00a":"## Text preprocessing","4ec5d7d4":"## Merge dfs","11567521":"## Conclusion","a561bdf5":"# GENSIM\n> https:\/\/www.machinelearningplus.com\/nlp\/topic-modeling-gensim-python\/#1introduction\n \n> https:\/\/www.machinelearningplus.com\/nlp\/topic-modeling-visualization-how-to-present-results-lda-models\/","87987a46":"# Topic classifier model of restaurant negative reviews and further analysis \nInspired by\n> https:\/\/monkeylearn.com\/topic-analysis\/","3f8bc463":"## LDA: num_topics=20","37f77764":"## Filter reviews with < 3 stars","3da009a3":"## Star Rating Distriution","cbf3dfea":"**Conclusion:** business_catg to be merge with bad_reviews\n","121c2ce9":"## Dataframe contains business_id and categories to be merged with Dataframe contains review data"}}