{"cell_type":{"e28027b6":"code","9bb8abcf":"code","c8312ec5":"code","feeca8e9":"code","580f7227":"code","1e03e646":"code","6c0c3a0c":"code","f5bccb90":"code","b6d32a41":"code","9c16db6a":"code","1fccbb05":"code","76b5d5e0":"code","9ecb7b3c":"code","b1a7b67f":"code","06c4855c":"code","7c811f67":"code","c0a80821":"code","ec0482ed":"code","9b2097e0":"code","a30d8ece":"code","cc7c7174":"code","9c49cd8d":"code","e3fac410":"code","e1b4d509":"code","6108afb1":"code","98dabddd":"code","86a78aeb":"code","ea84c150":"code","26d0edd2":"code","63f401cb":"code","eacfe4a3":"code","553d35da":"code","e84672ce":"code","cbaa95f0":"code","4f8d0f19":"code","cd1b95a0":"code","39c5f1c6":"code","5a68b1a0":"code","38f898a9":"code","36be7815":"code","f11f3f41":"code","6fc742e3":"code","2a749aa3":"code","217d9506":"code","359faf55":"code","8f5e92b0":"code","9e665456":"code","2f570458":"code","f4bd4b97":"code","c3dbcbeb":"code","3f3974f4":"code","addf4084":"code","0c9269e9":"code","0db04de4":"code","a6cdccc2":"markdown","b1237d7d":"markdown","9b8b517f":"markdown","d38fb1bb":"markdown","65aad8f8":"markdown","9b95fb1c":"markdown","a293d91b":"markdown","130f76d8":"markdown","4759900d":"markdown","48f074b0":"markdown","7cfba513":"markdown","f7143bc0":"markdown","4ee5e106":"markdown","033f753e":"markdown","22a1c1b5":"markdown","27eca064":"markdown","8ef8478a":"markdown","ee91a4b2":"markdown","b0a7b63a":"markdown","83c6870f":"markdown","b651de32":"markdown","2ffc06e6":"markdown","77787f7a":"markdown","b7df5981":"markdown","e30f9c52":"markdown","c97e030a":"markdown"},"source":{"e28027b6":"# Data processing\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Manipulation\nfrom math import floor\n\n# Modeling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Evaluation\nfrom sklearn.metrics import accuracy_score","9bb8abcf":"# Get file location\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c8312ec5":"# Input data\nraw_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\nraw_train.shape","feeca8e9":"raw_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nraw_test.shape","580f7227":"# Features\nraw_train.columns","1e03e646":"raw_train.head(20)","6c0c3a0c":"raw_train.Sex.unique()\nraw_train.Ticket.unique()\nraw_train.Cabin.unique()","f5bccb90":"raw_train.describe()","b6d32a41":"raw_test.describe()","9c16db6a":"raw_train.describe(include='O')","1fccbb05":"raw_test.describe(include='O')","76b5d5e0":"# Missing values\nraw_train.isnull().sum()","9ecb7b3c":"raw_test.isnull().sum()","b1a7b67f":"# Correlation between Age and Survival\nage_survival = sns.FacetGrid(raw_train, col=\"Survived\", height=10)\nage_survival.map(plt.hist, \"Age\", bins=40)","06c4855c":"# Correlation between PClass and Survival\npclass_survival = sns.FacetGrid(raw_train, col=\"Survived\", row=\"Pclass\", height=5)\npclass_survival.map(plt.hist, \"Age\", alpha=0.5, bins=20)","7c811f67":"# Correlation between Sex feature and Survival rate\nsex_survival = sns.FacetGrid(raw_train, col=\"Survived\", height=5)\nsex_survival.map(plt.hist, \"Sex\", bins=2)","c0a80821":"# Embarked and Survival\nembarked_survival = sns.FacetGrid(raw_train, col=\"Embarked\", height=5)\nembarked_survival.map(plt.hist, \"Survived\", bins=2)","ec0482ed":"# As discussed above, dropping \"Cabin\" and \"Ticket\" features.\n# Good practice to print the shape of DataFrames before and after the feature dropping.\n\nprint(\"Before drop: Train: {}, Test: {}\".format(raw_train.shape, raw_test.shape))\n\nraw_train = raw_train.drop([\"Cabin\", \"Ticket\"], axis=1)\nraw_test = raw_test.drop([\"Cabin\", \"Ticket\"], axis=1)\n\n# Also, dropping PassengerId and Name features\nraw_train = raw_train.drop([\"PassengerId\", \"Name\"], axis=1)\nraw_test = raw_test.drop([\"Name\"], axis=1)\n\nprint(\"After drop: Train: {}, Test: {}\".format(raw_train.shape, raw_test.shape))","9b2097e0":"raw_train.head(20)","a30d8ece":"# \"Sex\" and \"Embarked\" are alphabetical values\n# Using One-hot encoding for the same. \n# We could also alternatively assign 0,1,2,.. values to each feature value in a map, but the ordering of numbers might be misinterpreted by the model.\n# Example: {S:0, C:1, Q:2} - Q might be considered higher than S by the model, but there may\/moy not be such a relation between these values.\n\nraw_train = pd.get_dummies(raw_train, columns=[\"Sex\", \"Embarked\"], prefix=[\"Sex\", \"Embarked\"])\nraw_test = pd.get_dummies(raw_test, columns=[\"Sex\", \"Embarked\"], prefix=[\"Sex\", \"Embarked\"])","cc7c7174":"raw_train.head(20)","9c49cd8d":"# Training dataset\nraw_train.isnull().sum()","e3fac410":"raw_test.isnull().sum()","e1b4d509":"# Using mean to impute missing \"Age\" values\nraw_train[\"Age\"] = raw_train[\"Age\"].replace(np.NaN, floor(raw_train[\"Age\"].mean()))\nraw_test[\"Age\"] = raw_test[\"Age\"].replace(np.NaN, floor(raw_test[\"Age\"].mean()))\nraw_train.isnull().sum()","6108afb1":"# Test dataset\nraw_test.isnull().sum()","98dabddd":"raw_test[\"Fare\"] = raw_test[\"Fare\"].replace(np.NaN, raw_test[\"Fare\"].median())","86a78aeb":"raw_test.isnull().sum()","ea84c150":"raw_train.head(20)","26d0edd2":"# Exploring if putting Age values in brackets will be a good new feature\n\nraw_train[\"Age_band\"] = pd.cut(raw_train[\"Age\"], 8)\nraw_train[[\"Age_band\", \"Survived\"]].groupby([\"Age_band\"]).mean().sort_values(by=\"Survived\", ascending=False)","63f401cb":"raw_train.head(20)","eacfe4a3":"raw_train.Age.unique()","553d35da":"raw_test.head(20)","e84672ce":"# Replacing Age values with Age_band values\nraw_train.loc[(raw_train[\"Age\"] <= 10), \"Age\"] = 0\nraw_train.loc[((raw_train[\"Age\"] > 10) & (raw_train[\"Age\"] <= 20)), \"Age\"] = 1\nraw_train.loc[((raw_train[\"Age\"] > 20) & (raw_train[\"Age\"] <= 30)), \"Age\"] = 2\nraw_train.loc[((raw_train[\"Age\"] > 30) & (raw_train[\"Age\"] <= 40)), \"Age\"] = 3\nraw_train.loc[((raw_train[\"Age\"] > 40) & (raw_train[\"Age\"] <= 50)), \"Age\"] = 4\nraw_train.loc[((raw_train[\"Age\"] > 50) & (raw_train[\"Age\"] <= 60)), \"Age\"] = 5\nraw_train.loc[((raw_train[\"Age\"] > 60) & (raw_train[\"Age\"] <= 70)), \"Age\"] = 6\nraw_train.loc[(raw_train[\"Age\"] >= 70), \"Age\"] = 7\n\nraw_train.Age.unique()","cbaa95f0":"# Replacing Age values with Age_band values\nraw_test.loc[(raw_test[\"Age\"] <= 10), \"Age\"] = 0\nraw_test.loc[((raw_test[\"Age\"] > 10) & (raw_test[\"Age\"] <= 20)), \"Age\"] = 1\nraw_test.loc[((raw_test[\"Age\"] > 20) & (raw_test[\"Age\"] <= 30)), \"Age\"] = 2\nraw_test.loc[((raw_test[\"Age\"] > 30) & (raw_test[\"Age\"] <= 40)), \"Age\"] = 3\nraw_test.loc[((raw_test[\"Age\"] > 40) & (raw_test[\"Age\"] <= 50)), \"Age\"] = 4\nraw_test.loc[((raw_test[\"Age\"] > 50) & (raw_test[\"Age\"] <= 60)), \"Age\"] = 5\nraw_test.loc[((raw_test[\"Age\"] > 60) & (raw_test[\"Age\"] <= 70)), \"Age\"] = 6\nraw_test.loc[(raw_test[\"Age\"] >= 70), \"Age\"] = 7\n\nraw_test.Age.unique()","4f8d0f19":"# Dropping Age_band from train dataset\nraw_train = raw_train.drop(\"Age_band\", axis=1)\nraw_train.columns","cd1b95a0":"# Checking if the passenger was with a other family member or not\nraw_train[\"Traveling_Solo\"] = 1\nraw_train.loc[((raw_train[\"SibSp\"] + raw_train[\"Parch\"]) > 0), \"Traveling_Solo\"] = 0\nraw_train.head(20)\n\nraw_test[\"Traveling_Solo\"] = 1\nraw_test.loc[((raw_test[\"SibSp\"] + raw_test[\"Parch\"]) > 0), \"Traveling_Solo\"] = 0","39c5f1c6":"# Dropping \"SibSp\" and \"Parch\"\nraw_train = raw_train.drop([\"SibSp\", \"Parch\"], axis=1)\nraw_test = raw_test.drop([\"SibSp\", \"Parch\"], axis=1)\nraw_train.head(20)","5a68b1a0":"print(raw_train.Fare.unique())\nprint(raw_train.Fare.sort_values())","38f898a9":"raw_train[\"Fare_bands\"] = pd.cut(raw_train.Fare, 4)\nraw_train[[\"Fare_bands\", \"Survived\"]].groupby(\"Fare_bands\").mean().sort_values(\"Fare_bands\")","36be7815":"# Using qcut to divide the bins as per the quartile ranges\nraw_train[\"Fare_bands_qcut\"] = pd.qcut(raw_train[\"Fare\"], 4)\nraw_train[[\"Fare_bands_qcut\", \"Survived\"]].groupby(\"Fare_bands_qcut\").mean().sort_values(\"Fare_bands_qcut\")\n\n# 4 bins gives distinct separation in survival rates","f11f3f41":"raw_train.dtypes","6fc742e3":"raw_train.loc[(raw_train.Fare < 8), \"Fare\"] = 0\nraw_train.loc[((raw_train.Fare >= 8) & (raw_train.Fare < 15)), \"Fare\"] = 1\nraw_train.loc[((raw_train.Fare >= 15) & (raw_train.Fare < 31)), \"Fare\"] = 2\nraw_train.loc[(raw_train.Fare >= 31), \"Fare\"] = 3\n\nraw_test.loc[(raw_test.Fare < 8), \"Fare\"] = 0\nraw_test.loc[((raw_test.Fare >= 8) & (raw_test.Fare < 15)), \"Fare\"] = 1\nraw_test.loc[((raw_test.Fare >= 15) & (raw_test.Fare < 31)), \"Fare\"] = 2\nraw_test.loc[(raw_test.Fare >= 31), \"Fare\"] = 3","2a749aa3":"raw_train.head(20)","217d9506":"raw_test.head(20)","359faf55":"# Dropping other fare related columns\nraw_train = raw_train.drop([\"Fare_bands\", \"Fare_bands_qcut\"], axis=1)\nraw_train.head()","8f5e92b0":"raw_test.head()","9e665456":"train_independent_features = raw_train.drop(\"Survived\", axis=1) \ntrain_dependent_feature = raw_train[\"Survived\"]","2f570458":"X_train, X_test, y_train, y_test = train_test_split(train_independent_features, train_dependent_feature, test_size=0.3)","f4bd4b97":"X_train.head()\ny_train.head()","c3dbcbeb":"# Logistic Regression\nmodel_lr = LogisticRegression(solver='liblinear')\nmodel_lr.fit(X_train, y_train)\ny_pred = model_lr.predict(X_test)\nprint(\"Accuracy score - Logistic Regression: \", round(accuracy_score(y_test, y_pred)*100, 2))","3f3974f4":"# Random Forest Classifier\nmodel_rf = RandomForestClassifier()\nmodel_rf.fit(X_train, y_train)\ny_pred = model_rf.predict(X_test)\nprint(\"Accuracy score - Random Forest Classifier: \", round(accuracy_score(y_test, y_pred)*100, 2))","addf4084":"# Submission v1\nraw_test_PassengerId = raw_test.PassengerId\nraw_test = raw_test.drop(\"PassengerId\", axis=1)\n\ntest_dataset_prediction = model_rf.predict(raw_test)","0c9269e9":"test_dataset_prediction_df = pd.DataFrame({\"PassengerId\": raw_test_PassengerId, \"Survived\": test_dataset_prediction})","0db04de4":"test_dataset_prediction_df\n\n# Create submission file\ntest_dataset_prediction_df.to_csv('submission.csv', index=False)","a6cdccc2":"Findings:\n1. Male survival was low which also stems from the high (65%) male ratio in passengers.\n2. Looking beyond the gender ratio, male survival count was half than that of female.","b1237d7d":"#### 2. Convert Categorical values to Numeric values","9b8b517f":"#### 3. Handling missing values","d38fb1bb":"### D. Submission","65aad8f8":"#### 3. Correlations","9b95fb1c":"Findings:\n1. Dataset contains ~40% of actual number of records (Total passengers were 2252 as per the problem statement).\n2. Average Survival rate - 38%. Overall survival rate as per the problem is 32%.\n3. Max age is 80, Min age is hard to understand as it's in fractions - data needs to be cleaned.\n4. Max Fare is 512, and Min is 0.\n5. Gender distribution - Male 65%, Female 35%\n6. Cabin values are duplicate - indicating that passengers shared cabins.\n7. Ticket numbers are also duplicate - which seems strange as ticket numbers should be unique.\n    We'll probably drop it as ticket number should be unique.\n    Also, even if we use regex to extract alphabetical labels, it might not be reliable data.\n8. All names are unique.\n9. Missing data found in:  \n    Train - Age, Cabin, Embarked  \n    Test - Age, Fare, Cabin\n10. We might drop \"Cabin\" feature as it has high number of missing values.\n  ","a293d91b":"#### 1. Features types","130f76d8":"Findings:\n1. Most of the passengers embarked from \"S\".\n2. \"S\" - Survival rate is low - close to 30%.\n3. \"C\" - More than 50% survival rate.\n4. \"Q\" - Close to 50% survival but less survivals.","4759900d":"Findings:\n1. Pclass 3 had a lot of younger passengers and most of them didn't survive.\n2. Most of the infants in Pclass 1 and 2 survived.\n3. 80 year old passengers were in Pclass 1 and all survived.\n4. Pclass 3 had very low survival rate.\n\nActions required:\n1. Good feature and will be included.","48f074b0":"### C. Modeling and Prediciton","7cfba513":"#### Credits:\nHelpful references from this wonderful notebook: https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions","f7143bc0":"#### 1. Drop features","4ee5e106":"Findings:\n1. Age < 5 has more survivals.\n2. Everyone of Age 80 survived.\n3. Low survival for Age between 15 and 30.\n4. High number of passengers between Age 15 to 40.\n\nActions required:\n1. Age has good correlation with survival rate. We should retain this feature.\n2. Age can be put into bins, to make it an ordinal feature.","033f753e":"TODO:\n1. Do more analysis of the features to understand how data can be better transformed.","22a1c1b5":"As per above findings, we need to transform the data.","27eca064":"##### iii. Fare band","8ef8478a":"### B. Data Wrangling","ee91a4b2":"#### 2. Data distribution","b0a7b63a":"### A. Data Exploration","83c6870f":"\nIt seems to have good correlations with survival rate. We can use this new feature.","b651de32":"We can create new features by using the current features for better interpretation (Future revisions).  \nIdeas - age_band, family_size\/not_alone, fare_band","2ffc06e6":"We will divide the training dataset to make 2 smaller datasets - One from which the model learns and the other to evaluate its accuracy.  \nThe actual Test dataset will be used to submit final predictions.","77787f7a":"Feature \"Age\" has missing values\nFew methods to handle it:\n1. Drop records - Not a good solution as the number of records is 177 (20% of the dataset).\n2. Impute missing values using mean or median values - probably.\n3. Generate numbers between mean and standard deviation - probably.\n3. Use other correlated features to guess the missing value - For future revisions.\n4. I believe there are ways to use models to predict missing values - For future revisions.","b7df5981":"##### ii. Family size","e30f9c52":"Looking at the data description page of the problem. Also, for ambiguous features we will look at the unique values of the features.  \n\nSurvived - Categorical (Binary)  \nPclass - Categorical (Ordinal)  \nSex - Categorical (Nominal)  \nCabin - Categorical (Nominal)  \nEmbarked - Categorical (Nominal)  \n\nAge - Numerical (Continuous)  \nFare - Numerical (Continuous)  \nSibSp - Numerical (Discrete)  \nParch - Numerical (Discrete)  \n\nPassengerId - Discrete values  \nName - Discrete values  \n\nTicket - Alphanumeric (To be handled later)","c97e030a":"#### 4. Creating newfeatures"}}