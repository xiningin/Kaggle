{"cell_type":{"f569894a":"code","f243eddb":"code","16d02883":"code","f2505d01":"code","350c833b":"code","16fb26b6":"code","c434ba69":"code","fed377a9":"code","9b84f280":"code","5b9f4c02":"code","95cd5e9e":"code","5e6491ca":"code","86dc0bdd":"code","80199949":"code","a035f661":"markdown","da2d251c":"markdown","1288b21e":"markdown","b9d1cb5f":"markdown","4a590f5a":"markdown","2f5e0987":"markdown","e9eb99a3":"markdown","c4f0bcd1":"markdown","0d9cd829":"markdown","b0cfdd7b":"markdown","33631524":"markdown","0b1c76d4":"markdown","4d6deee0":"markdown","9c76c661":"markdown","a334e4bc":"markdown","88429ff9":"markdown"},"source":{"f569894a":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn import neighbors\nfrom sklearn import tree\nfrom sklearn import linear_model\nimport graphviz\nimport matplotlib.pyplot as plt\nimport pickle\n\ndf = pd.read_csv('..\/input\/dataset2.csv',index_col='country')\ndf.head()","f243eddb":"df = df.drop('Norway',axis=0)\nX = df.drop('max_ev_p',axis=1)\ny = df['max_ev_p']\n\ntrain_X, test_X, train_y, test_y = train_test_split(X,y,random_state=0)","16d02883":"new_X = pd.DataFrame(columns=X.columns)\nnew_X = new_X.append(pd.Series([0,0,0,0,0],index=X.columns,name='zero'))\nnew_X = new_X.append(pd.Series([0,0,0,0,100],index=X.columns,name='worst'))\nnew_X = new_X.append(pd.Series([1,0,100000,100,0],index=X.columns,name='best'))\nnew_X = new_X.append(pd.Series([1,0.56,40000,67,66],index=X.columns,name='country1'))\nnew_X = new_X.append(pd.Series([0,0.28,55000,78,34],index=X.columns,name='country2'))\n\nnew_X","f2505d01":"def add_prediction(df,pred):\n    df2 = df.copy()\n    df2['pred'] = pred\n    return df2","350c833b":"for n in [1,2,3,4,5,10,15]:\n    knn = neighbors.KNeighborsRegressor(n_neighbors=n)\n    knn.fit(train_X,train_y)\n    pred = knn.predict(test_X)\n    print(mean_squared_error(test_y, pred))","16fb26b6":"knn = neighbors.KNeighborsRegressor(n_neighbors=2)\nknn.fit(train_X,train_y)\npred = knn.predict(test_X)\nprint(mean_squared_error(test_y, pred))\nadd_prediction(df.loc[test_X.index], pred)","c434ba69":"add_prediction(new_X, knn.predict(new_X))","fed377a9":"for n in [1,2,3,4,5,10]:\n    dtree = tree.DecisionTreeRegressor(random_state=0,max_depth=n)\n    dtree.fit(train_X,train_y)\n    dtree_pred = dtree.predict(test_X)\n    print(n, mean_squared_error(test_y,dtree_pred))","9b84f280":"dtree = tree.DecisionTreeRegressor(random_state=0,max_depth=2)\ndtree.fit(train_X,train_y)\ndtree_pred = dtree.predict(test_X)\n    \nadd_prediction(df.loc[test_X.index], dtree_pred)","5b9f4c02":"plt.figure(figsize=(3,2))\ngraphviz.Source(tree.export_graphviz(dtree, feature_names=X.columns))\n#graphviz.Source(tree.plot_tree(dtree))","95cd5e9e":"add_prediction(new_X, dtree.predict(new_X))","5e6491ca":"from sklearn.ensemble import RandomForestRegressor\n\nrf = RandomForestRegressor(random_state=0,n_estimators=100)\nrf.fit(train_X,train_y)\nrf_pred = rf.predict(test_X)\n\nprint(mean_squared_error(rf_pred, test_y))\n\nadd_prediction(df.loc[test_X.index],rf_pred)","86dc0bdd":"reg = linear_model.LinearRegression()\n\ncolumns = ['ssm','ppp','nat_p']\n\ntrain_X_reg = train_X[columns].copy()\ntest_X_reg = test_X[columns].copy()\nnew_X_reg = new_X[columns].copy()\n\nreg.fit(train_X_reg,train_y)\nreg_pred = reg.predict(test_X_reg)\n\nprint(\"MSE:\", mean_squared_error(test_y,reg_pred))\n\nprint(reg.coef_,train_X_reg.columns)\n\nadd_prediction(df.loc[test_X.index], reg.predict(test_X_reg))","80199949":"add_prediction(new_X_reg, reg.predict(new_X_reg))","a035f661":"## Unlabeled data","da2d251c":"## Helper functions ","1288b21e":"# Model training","b9d1cb5f":"Norway is an extreme outlier and will therefore not be considered part of the training data. It has an exceptionally high market share of EVs while only having a relatively small population.","4a590f5a":"### Use n = 2","2f5e0987":"## Model 2: Decision trees","e9eb99a3":"## Split data ","c4f0bcd1":"# Choice of model\n\n## Model 1: KNN\n\n* The sample size is too small for KNN to work well\n* For example, the predicted share should not drop after a certain GDP per capita has been reached merely because there is a country with a high GDP per capita that has a low EV market share\n\n## Model 2,3: Decision trees\n\n* The relationships between the predictor and target variables are roughly linear and don't depend on other predictor variables\n* e.g. a higher gini index means a lower market share, higher GDP per capita is correlated with a higher market share\n* Therefore, decision trees, which model non-linear relationships, are not a natural choice here\n\n## Model 4: Regression (Winner!)\n\nA very simple model with many upsides:\n* It is competitive when it comes to MSE (it has 11, while random forests have 12)\n* Its predictions are **consistent with our intuition** (e.g. higher GDP per capita always means higher EV market share) and, thus, are **easily understandable**!\n* Since it is linear, **it is very robust** (e.g. the predicted value does not suddenly drop after a certain level of GDP per capita has been reached)\n* **Its predictions on unlabeled data make sense!** (Which is the end goal!)\n\nIt still has some minor problems:\n* Sometimes produces negative values (e.g. see the 'worst' unlabeled sample above)\n* It is bad at predicting non-European countries (e.g. it predicts China to have a negative EV share, even though it is one of the leaders in the industry!)\n    * But this is because it was trained mostly on European countries!\n* Cannot model complex relationships by nature\n\nHowever, the upsides prevail (especially the last point) and for these reasons, **we will pick the regression model!**","0d9cd829":"KNN is a natural choice. If two countries are similar in wealth and politics, they can expected to have a similar market share of electric vehicles.","b0cfdd7b":"## Model 3: Random forests","33631524":"## Model 1: KNN","0b1c76d4":"### max_depth = 2 is best ","4d6deee0":"This is part of a [larger project](https:\/\/github.com\/maxims94\/electric-mobility-study).","9c76c661":"### Visualize decision tree for n_neighbors = 2","a334e4bc":"## Model 4: Linear Regression","88429ff9":"Some of the features are strongly correlated (e.g. GDP per capita and social progress index), which causes problems with linear regression models. Therefore, we will only train the model on a subset of features."}}