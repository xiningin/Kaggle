{"cell_type":{"0c10edda":"code","b0cbfad9":"code","2877dde3":"code","6949f365":"code","1fa9bd2c":"code","f276091d":"code","bafcec01":"code","ccbb447c":"code","894209da":"code","5f1cda95":"code","bf0fcaba":"code","cccf1064":"code","b6ca0433":"code","fd308542":"code","d09804dd":"code","6c0821d6":"code","ec759213":"code","8cb92c99":"code","a1ba185e":"code","63f68abe":"code","c9b79e8c":"code","bfc58e3c":"code","27eb5285":"code","74bf175d":"markdown","7177a3b1":"markdown","b68cfaee":"markdown","9b6767d7":"markdown","f7a8a0a3":"markdown","aba73c34":"markdown","cc304d58":"markdown","ec9b6c58":"markdown","8edd6891":"markdown","e8dba5b3":"markdown","341a2e0b":"markdown","ce2308ea":"markdown"},"source":{"0c10edda":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, auc, classification_report\nfrom nltk.stem.porter import PorterStemmer\nimport re\nfrom nltk.corpus import stopwords\nimport nltk\nfrom collections import Counter\nimport seaborn as sns","b0cbfad9":"#Read data\ndata = pd.read_csv('\/kaggle\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv')","2877dde3":"data.columns","6949f365":"data[\"sentiment\"].value_counts()","1fa9bd2c":"def cleanHtml(sentence):\n    cleanr = re.compile('<.*?>')\n    cleantxt = re.sub(cleanr, ' ', sentence)\n    return cleantxt\n\ndef cleanpunc(sentence):\n    cleaned = re.sub(r'[?|!|\\'|\"|#]', r'', sentence)\n    cleaned = re.sub(r'[.|,|)|(|\\|\/]', r' ', cleaned)\n    return cleaned","f276091d":"\nsno = nltk.stem.SnowballStemmer(\"english\")\nstop = set(stopwords.words(\"english\"))\nall_positive_words = []\nall_negative_words = []\nfinal_string = []\nstr1 = ''\ni = 0\nfor string in data[\"review\"].values:\n    filtered_sentence = []\n    # Removes html tags from every review\n    sent = cleanHtml(string)\n    for w in sent.split():\n        # For every word in a review clean punctions\n        for cleanwords in cleanpunc(w).split():\n            # if cleaned is alphabet and length og words greater than 2 then proceed\n            if ((cleanwords.isalpha()) and len(cleanwords)>2):\n                # check weather word is stop word or not\n                if cleanwords.lower() not in stop:\n                    # If word is not stop word then append it to filtered sentence\n                    s = (sno.stem(cleanwords.lower())).encode('utf-8')\n                    filtered_sentence.append(s)\n                    if (data[\"sentiment\"].values)[i].lower() == \"positive\":\n                        all_positive_words.append(s)\n                    if (data[\"sentiment\"].values)[i].lower() == \"negative\":\n                        all_negative_words.append(s)\n                else:\n                    continue\n            else:\n                continue\n    # filtered_sentence is list contains all words of a review after preprocessing\n    # join every word in a list to get a string format of the review\n    str1 = b\" \".join(filtered_sentence)\n    #append all the string(cleaned reviews)to final_string\n    final_string.append(str1)\n    i += 1        ","bafcec01":"fig, axis = plt.subplots(1, 2)\nprint(len(all_positive_words))\npos_words_freq = list(Counter(all_positive_words).values())\nprint(len(all_negative_words))\nneg_words_freq = list(Counter(all_negative_words).values())\nsns.distplot(pos_words_freq, ax = axis[0])\nsns.distplot(neg_words_freq, ax = axis[1])\nfig.show()","ccbb447c":"data[\"review\"] = final_string","894209da":"def conv_label(label):\n    if label.lower() == \"positive\":\n        return 1\n    elif label.lower() == \"negative\":\n        return 0\n\ndata[\"sentiment\"] = data[\"sentiment\"].map(conv_label)","5f1cda95":"data.head(10)","bf0fcaba":"freq_pos_words = nltk.FreqDist(all_positive_words)\nfreq_neg_words = nltk.FreqDist(all_negative_words)","cccf1064":"freq_pos_words.most_common(15)","b6ca0433":"freq_neg_words.most_common(15)","fd308542":"#Bag of words vector with bi-grams\ncount_vect = CountVectorizer(ngram_range = (1, 2))\ncount_vect = count_vect.fit(data[\"review\"].values)\nbigram_wrds = count_vect.transform(data[\"review\"].values)","d09804dd":"#TF-Idf vector using bi-grams\ncount_vect_tfidf = TfidfVectorizer(ngram_range = (1, 2))\ncount_vect_tfidf = count_vect_tfidf.fit(data[\"review\"].values)\ntfidf_wrds  = count_vect_tfidf.transform(data[\"review\"].values)","6c0821d6":"bigram_wrds","ec759213":"from sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score \n# change X to bigram_wrds to run classifier on Bag Of Words(BoW)\nX = bigram_wrds\n# X = tfidf_wrds\nY = data[\"sentiment\"]\nx_l, x_test, y_l, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)\nfrom sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB(alpha = 0.7)\nclf.fit(x_l, y_l)\npred = clf.predict(x_test)\nacc = accuracy_score(y_test, pred, normalize = True) * float(100)  \nprint(\"acc is on test data:\", acc)\nsns.heatmap(confusion_matrix(y_test, pred), annot = True, fmt = 'd')\ntrain_acc = accuracy_score(y_l, clf.predict(x_l), normalize = True) * float(100)\nprint(\"train accuracy is:\", train_acc)\nprint(classification_report(y_test, pred))","8cb92c99":"review = [\"This is a worst movie\",\"This is a good movie\"]","a1ba185e":"#initialize BOW vectorizer\n#we already fitted the model for train data on \"count_vect\"(means alredy found probabilities for train data)\nvectorize = CountVectorizer(vocabulary = count_vect.vocabulary_)\n#Use classifier we trained using Bag of words\npolarity = clf.predict(vectorize.transform(review))\n# count_vect_tfidf.transform(review)","63f68abe":"print(polarity)","c9b79e8c":"\nimport pickle as pkl\nf = open('classifier.pickle', 'wb')\npkl.dump(clf, f)\nf.close()","bfc58e3c":"import pickle as pkl\nf = open('vectorizer.pickle', 'wb')\npkl.dump(count_vect, f)\nf.close()","27eb5285":"review = \"You can take from user input\"\nwith open(\"classifier.pickle\", 'rb') as f:\n    classifier = pkl.load(f)\nwith open(\"vectorizer.pickle\", 'rb') as f:\n    vectorizer = pkl.load(f)\nfrom sklearn.feature_extraction.text import CountVectorizer\n#vectorize your review which you used in training\nvector_review = CountVectorizer(vocabulary = vectorizer.vocabulary_)\nvector_review = vector_review.transform(review)\n#predict the vectorized review using your classifier \npredict = classifier.predict(vector_review)\nprint(predict)","74bf175d":"* Distribution of positive & Negative word Frequnecy","7177a3b1":"## checking the frequency of positive and negative reviewes","b68cfaee":"### BOW\n* alpha: 0.7\n* Test accuracy: 88.62 \n* Train accuracy: 99.77\n\n### TF-IDF\n* alpha: 0.7\n* Test accuracy: 88.98\n* Trina accuracy: 98.86","9b6767d7":"You can save models and deploy using following code\n* save your classifier model\n* save your word vectorizer in a pickle file","f7a8a0a3":"### Text Preprocessing\n* Removing stop words from reviews\n* Removing HTML Tags and punctuations\n* Get a stem word","aba73c34":"* This is a Balanced Dataset","cc304d58":"* Replacing the cleaned text to Data Frame\n* Replace lables with int values\n* positive = 1\n* negative = 0","ec9b6c58":"* Here word \"good\" is present in both positive and negative reviews.\n* It's likely contains \"Not good\" in negative a review, but due to uni gram we are loosing this information.\n* So It's better to use n-grams where n>=2","8edd6891":"* Here We are Testing with our own review\n* We Ran our classifier on Tf-Idf, so We use Tf-Idf to convert our reivew to vector","e8dba5b3":"# Deploying Naive Bayes Model","341a2e0b":"We are running our classifier on TF-Idf data here.","ce2308ea":"# Naive Bayes Classifier on IMDB Review Data set"}}