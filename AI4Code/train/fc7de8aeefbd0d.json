{"cell_type":{"2879ef49":"code","33f2ca5d":"code","176e27fb":"code","b06ed2a1":"code","529af42f":"code","d71041a7":"code","0bc0dba3":"code","ad37457e":"code","5fb4950e":"code","ebe4a29c":"code","8f7799d7":"code","1bfcb6a6":"code","4907785a":"code","8ce07ca9":"code","ecd020a2":"code","73f855e7":"code","8c3c57fb":"code","521a1a5d":"code","6439848c":"markdown","084a40d1":"markdown","67412703":"markdown","1d248f19":"markdown","02184ae3":"markdown","5090ecbd":"markdown","1c884661":"markdown"},"source":{"2879ef49":"!pip install timm","33f2ca5d":"!git clone https:\/\/github.com\/lessw2020\/Ranger-Deep-Learning-Optimizer.git","176e27fb":"import sys\nsys.path.append('.\/Ranger-Deep-Learning-Optimizer')","b06ed2a1":"import math\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom collections import defaultdict\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data\nfrom torch.utils.data import Dataset,DataLoader\nimport torch.nn.functional as F\nfrom torch import Tensor\nfrom torch.optim.optimizer import Optimizer, required\n\nfrom transformers import AdamW\nfrom transformers import get_linear_schedule_with_warmup,get_cosine_schedule_with_warmup\nfrom transformers import get_cosine_with_hard_restarts_schedule_with_warmup,get_constant_schedule_with_warmup\n\nimport timm\nfrom ranger.ranger2020 import Ranger","529af42f":"SEED = 1000\ndevice= torch.device('cuda')\nSIZE = 384\n\nROOT_DIR = '..\/input\/seti-breakthrough-listen'\n\n#### DATALOADER #####\nTRAIN_BATCH_SIZE = 16\nVALID_BATCH_SIZE = 32\nNUM_WORKERS=4\n\n### GENERAL ######\nEPOCHS = 20\nLR = 5.0e-06\nMAX_LR = 1e-3\n\n##### \nSCHEDULER = 'linear'\n\n##### Model Params ######\nmodel_params = dict(\n    backbone='tf_efficientnet_b3_ns',\n    in_channels=1,\n    out_dim=1,\n    pretrained=True\n)","d71041a7":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","0bc0dba3":"class AverageMeter(object):\n    def __init__(self):\n        self.reset()\n    \n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n    \n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count","ad37457e":"class RocAucMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.y_true = np.array([0,1])\n        self.y_pred = np.array([0.5,0.5])\n        self.score = 0\n\n    def update(self, y_true, y_pred):\n        y_true = y_true.detach().cpu().numpy().astype(int)\n        y_pred = y_pred.sigmoid().detach().cpu().numpy()\n     \n        self.y_true = np.hstack((self.y_true, y_true))\n        self.y_pred = np.hstack((self.y_pred, y_pred))\n        self.score = roc_auc_score(self.y_true, self.y_pred)\n    \n    @property\n    def avg(self):\n        return self.score","5fb4950e":"def get_train_transform(size=SIZE):\n    return A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=90, p=0.5),\n        A.RandomBrightnessContrast(p=0.25),\n        A.Cutout(p=0.3),\n        A.Resize(size,size,always_apply=True),\n        ToTensorV2()\n    ])\ndef get_valid_transform(size=SIZE):\n    return A.Compose([\n        A.Resize(size,size,always_apply=True),\n        ToTensorV2()\n    ])","ebe4a29c":"class SetiDataset(torch.utils.data.Dataset):\n    def __init__(self,df,transform,read_type='all',selected_dims=None):\n        self.df = df\n        self.transform = transform\n        self.read_type = read_type\n        self.selected_dims = selected_dims\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        \n        id_ = row.id\n        path = f\"{ROOT_DIR}\/train\/{id_[0]}\/{id_}.npy\"\n        label = row.target\n        \n        if self.read_type == 'selected':\n            img = self.read_selected_cadence(path,self.selected_dims)\n        else:\n            img = self.read_all_cadence(path)\n            \n        img = self.transform(image=img)[\"image\"]\n        \n        return img,torch.tensor(label,dtype=torch.float)\n\n    def read_all_cadence(self, path):\n        \"\"\"Read cadence file and reshape\"\"\"\n        img = np.load(path)  # shape: (6, 273, 256)\n        img = np.vstack(img)  # shape: (1638, 256)\n        img = img.transpose(1, 0)  # shape: (256, 1638)\n        img = img.astype(\"f\")[..., np.newaxis]  # shape: (256, 1638, 1)\n        return img\n    \n    def read_selected_cadence(self, path ,selected_dims=[0,2,4]):\n        \"\"\"Read cadence file and reshape\"\"\"\n        img = np.load(path)[selected_dims]  # shape: (3, 273, 256)\n        img = np.vstack(img)  # shape: (819, 256)\n        img = img.transpose(1, 0)  # shape: (256, 819)\n        img = img.astype(\"f\")[..., np.newaxis]  # shape: (256, 819, 1)\n        return img","8f7799d7":"def dataset_checker(dataset):\n    img,label = dataset[9]\n    print(img.shape)\n    print(label)\n    img = img.permute(1,2,0).detach().numpy()\n    fig, ax = plt.subplots(figsize=(16, 8),  nrows=1, ncols=2)\n    ax[0].imshow(img)","1bfcb6a6":"# df = pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\n# d = SetiDataset(df,transform=get_train_transform(),read_type='selected',selected_dims=[0,2,4])\n# dataset_checker(d)\n\n# del d,df","4907785a":"def get_loader(fold):\n    df = pd.read_csv('..\/input\/seti-splits-old-new\/5folds_split_new.csv')\n    \n    train = df[df['fold']!=fold]\n    valid = df[df['fold']==fold]\n    \n    train_dataset = SetiDataset(\n        train,\n        transform=get_train_transform(),\n        read_type='selected',\n        selected_dims=[0,2,4]\n    )\n    \n    valid_dataset = SetiDataset(\n        valid,\n        transform=get_valid_transform(),\n        read_type='selected',\n        selected_dims=[0,2,4]\n    )\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size  = TRAIN_BATCH_SIZE,\n        drop_last   = False,\n        num_workers = NUM_WORKERS,\n        pin_memory  = True,\n    )\n    \n    valid_loader = DataLoader(\n        valid_dataset,\n        batch_size  = VALID_BATCH_SIZE,\n        drop_last   = False,\n        num_workers = NUM_WORKERS,\n        pin_memory  = True,\n    )\n    \n    return train_loader,valid_loader","8ce07ca9":"class enetv2(nn.Module):\n    def __init__(self, backbone,in_channels,out_dim,pretrained=True):\n        super(enetv2, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, 6, 3, stride=1, padding=1, bias=False)\n        self.conv2 = nn.Conv2d(6, 12, 3, stride=1, padding=1, bias=False)\n        self.conv3 = nn.Conv2d(12, 36, 3, stride=1, padding=1, bias=False)\n        self.mybn1 = nn.BatchNorm2d(6)\n        self.mybn2 = nn.BatchNorm2d(12)\n        self.mybn3 = nn.BatchNorm2d(36)\n\n        self.enet = timm.create_model(backbone, pretrained=pretrained,in_chans=in_channels)\n        self.enet.conv_stem.weight = nn.Parameter(self.enet.conv_stem.weight.repeat(1, 36, 1, 1))\n\n        self.dropout = nn.Dropout(0.5)\n        self.enet.blocks[5] = nn.Identity()\n        self.enet.blocks[6] = nn.Sequential(\n            nn.Conv2d(self.enet.blocks[4][2].conv_pwl.out_channels, self.enet.conv_head.in_channels, 1),\n            nn.BatchNorm2d(self.enet.conv_head.in_channels),\n            nn.ReLU6(),\n        )\n        self.myfc = nn.Linear(self.enet.classifier.in_features, out_dim)\n        self.enet.classifier = nn.Identity()\n\n    def extract(self, x):\n        x = F.relu6(self.mybn1(self.conv1(x)))\n        x = F.relu6(self.mybn2(self.conv2(x)))\n        x = F.relu6(self.mybn3(self.conv3(x)))\n        x = self.enet(x)\n        return x\n\n    def forward(self, x):\n        x = self.extract(x)\n        x = self.myfc(self.dropout(x))\n        return x","ecd020a2":"def train_fn(dataloader,model,criterion,optimizer,device,scheduler,epoch):\n    model.train()\n    loss_score = AverageMeter()\n    auc_score = RocAucMeter()\n    \n    tk0 = tqdm(enumerate(dataloader), total=len(dataloader))\n    for bi,d in tk0:\n        \n        batch_size = d[0].shape[0]\n\n        images = d[0]\n        targets = d[1]\n\n        images = images.to(device)\n        targets = targets.to(device)\n\n        optimizer.zero_grad()\n\n        output = model(images)\n        \n        loss = criterion(output,targets.view(-1,1))\n        \n        loss.backward()\n        optimizer.step()\n        \n        loss_score.update(loss.detach().item(), batch_size)\n        auc_score.update(targets,output.squeeze(-1))\n        tk0.set_postfix(Train_Loss=loss_score.avg,Train_AUC=auc_score.avg,Epoch=epoch,LR=optimizer.param_groups[0]['lr'])\n        \n        if scheduler is not None:\n                scheduler.step()\n        \n    return loss_score","73f855e7":"def evaluate(dataloader,model,criterion,device,epoch):\n        model.eval()\n        loss_score = AverageMeter()\n        auc_score = RocAucMeter()\n        \n        tk0 = tqdm(enumerate(dataloader), total=len(dataloader))\n        with torch.no_grad():\n            for bi,d in tk0:\n\n                batch_size = d[0].shape[0]\n \n                image = d[0]\n                labels = d[1]\n\n                image = image.to(device)\n                labels = labels.to(device)\n\n                out = model(image)\n                loss = criterion(out,labels.view(-1,1))\n                \n                loss_score.update(loss.detach().item(), batch_size)\n                auc_score.update(labels,out.squeeze(-1))\n                \n                tk0.set_postfix(Valid_Loss=loss_score.avg,Valid_AUC=auc_score.avg,Epoch=epoch)\n        \n        return loss_score.avg,auc_score.avg","8c3c57fb":"def run(fold):\n    seed_everything(SEED)\n    \n    train_loader,valid_loader = get_loader(fold)\n    \n    seed_everything(SEED)\n    \n    # Defining Model for specific fold\n    model = enetv2(**model_params)\n    model.to(device)\n    \n    #DEfining criterion\n    criterion = nn.BCEWithLogitsLoss()\n    criterion.to(device)\n    \n    #optimizer = torch.optim.Adam(model.parameters(), lr=scheduler_params['lr_start'])\n    optimizer = Ranger(model.parameters(), lr= LR,weight_decay=1.0e-02)\n    \n    #Defining LR SCheduler\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer,\n        steps_per_epoch = len(train_loader),\n        epochs=EPOCHS,\n        max_lr=MAX_LR,\n        pct_start= 0.1,\n        anneal_strategy = 'cos',\n        div_factor = 1.0e+3,\n        final_div_factor= 1.0e+3\n    )\n    \n    # THE ENGINE LOOP\n    best_auc = 0 \n    for epoch in range(EPOCHS):\n        train_loss = train_fn(train_loader, model,criterion, optimizer, device,scheduler=scheduler,epoch=epoch)\n        valid_loss,valid_auc = evaluate(valid_loader, model, criterion,device,epoch=epoch)\n        \n        if valid_auc > best_auc:\n            best_auc = valid_auc\n            torch.save(model.state_dict(),f\"model_{model_params['backbone']}_IMG_SIZE_{SIZE}.bin\")\n            print('best model found for epoch {}'.format(epoch))","521a1a5d":"run(fold=0)","6439848c":"# Dataset","084a40d1":"# Augmentations","67412703":"# Utils","1d248f19":"# Model","02184ae3":"# Training Function","5090ecbd":"# Config","1c884661":"# Engine"}}