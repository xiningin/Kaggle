{"cell_type":{"44b7c88d":"code","5c4496f8":"code","9c7e753d":"code","5badec04":"code","b2d320d2":"code","9b53a6fa":"code","d6bf73d9":"code","627ecce7":"code","319a3aa9":"code","1ede4e9a":"code","58580c5c":"code","dafe3706":"code","f50a77f8":"code","f7102cb4":"code","c17a504c":"code","02a21fab":"code","25a23cb4":"code","91fb5e70":"code","afbbe84e":"code","d179b0bb":"code","601dba72":"code","1642e2d0":"code","a442302d":"code","1cd8860e":"code","71e5bced":"code","7e16497b":"code","c5309371":"code","e58c6bd2":"code","108f7f89":"code","33c514dc":"code","18f4f6b7":"code","2a0fb9bd":"code","4f5e12b5":"code","ce7a1adf":"code","0d5f220e":"code","f3863fd6":"code","b5173ebc":"code","d45cc835":"code","c0bb9079":"markdown","ec2bc217":"markdown","111f1619":"markdown","07cea44a":"markdown","2e5dbd2f":"markdown","c93549fd":"markdown","eb841a06":"markdown","542f7f0e":"markdown","9fae43ce":"markdown","b15d683a":"markdown","22b34a01":"markdown","cc989690":"markdown","0fc94516":"markdown"},"source":{"44b7c88d":"from IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#8F003C','#eb3446','Tourney','Smokum',45,10\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h4 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h4>\"\"\"%string))\n    \n    \ndhtml(' \ud83d\udd25\ud83d\udca5 TPS-08: CB + LGBM + XGB  Starter \ud83d\udca5\ud83d\udd25 ' )","5c4496f8":"from IPython.display import HTML\nHTML(\"\"\"\n<style>\nh1,h2,h3 {\n\tmargin: 1em 0 0.5em 0;\n\tfont-weight: 600;\n\tfont-family: 'Titillium Web', sans-serif;\n\tposition: relative;  \n\tfont-size: 36px;\n\tline-height: 40px;\n\tpadding: 15px 15px 15px 2.5%;\n\tcolor: #00018D;\n\tbox-shadow: \n\t\tinset 0 0 0 1px rgba(97,0,45, 1), \n\t\tinset 0 0 5px rgba(53,86,129, 1),\n\t\tinset -285px 0 35px #F2D8FF;\n\tborder-radius: 0 10px 0 15px;\n\tbackground: #FFD8B2\n    \n}\n<\/style>\n\"\"\")","9c7e753d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directo\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5badec04":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nimport category_encoders as ce\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import model_selection\nimport lightgbm as lgbm\nimport xgboost as xgb\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nimport optuna\nimport tqdm\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)","b2d320d2":"train=pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/train.csv\")\ntest=pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/test.csv\")\n","9b53a6fa":"train.head()","d6bf73d9":"test.head()","627ecce7":"train.isnull().sum()","319a3aa9":"test.isnull().sum()","1ede4e9a":"train.info()","58580c5c":"train.drop(columns=['id']).describe().T.style.bar(subset=['mean'], color='#606ff2')\\\n                            .background_gradient(subset=['std'], cmap='PuBu')\\\n                            .background_gradient(subset=['50%'], cmap='PuBu')","dafe3706":"test.drop(columns=['id']).describe().T.style.bar(subset=['mean'], color='#606ff2')\\\n                            .background_gradient(subset=['std'], cmap='PuBu')\\\n                            .background_gradient(subset=['50%'], cmap='PuBu')","f50a77f8":"def highlight_mean_greater(s):\n    '''\n    highlight blue is value is greater than mean else pink.\n    '''\n    is_max = s > s.mean()\n    return ['background-color: #606ff2' if i else 'background-color: pink' for i in is_max]","f7102cb4":"train.drop(columns=['id']).head(20).style.apply(highlight_mean_greater)","c17a504c":"corr = train.corr()\nmask = np.triu(np.ones_like(corr, dtype = bool))\n\nplt.figure(figsize = (15, 15))\nplt.title('Corelation matrix for Train data')\nsns.heatmap(corr, mask = mask, cmap = 'BuPu', linewidths = .5)\nplt.show()","02a21fab":"corr = test.corr()\nmask = np.triu(np.ones_like(corr, dtype = bool))\n\nplt.figure(figsize = (15, 15))\nplt.title('Corelation matrix for Test data')\nsns.heatmap(corr, mask = mask, cmap = 'BuPu', linewidths = .5)\nplt.show()","25a23cb4":"y = train['loss']\ntrain.drop(['id','loss'],axis=1,inplace=True)\ntest.drop(['id'],axis=1,inplace=True)","91fb5e70":"not_features = ['id', 'loss']\nfeatures = []\nfor feat in train.columns:\n    if feat not in not_features:\n        features.append(feat)\nprint(features)","afbbe84e":"scaler = StandardScaler()\ntrain[features] = scaler.fit_transform(train[features])\ntest[features] = scaler.transform(test[features])","d179b0bb":"x=train","601dba72":"def objective(trial,data=x,target=y):\n    \n    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25,random_state=42)\n    params = {'iterations':trial.suggest_int(\"iterations\", 1000, 20000),\n              'od_wait':trial.suggest_int('od_wait', 500, 2000),\n             'loss_function':'RMSE',\n              'task_type':\"GPU\",\n              'eval_metric':'RMSE',\n              'leaf_estimation_method':'Newton',\n              'bootstrap_type': 'Bernoulli',\n              'learning_rate' : trial.suggest_uniform('learning_rate',0.02,1),\n              'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n              'subsample': trial.suggest_uniform('subsample',0,1),\n              'random_strength': trial.suggest_uniform('random_strength',10,50),\n              'depth': trial.suggest_int('depth',1,15),\n              'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n              'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15),\n               }\n    model = CatBoostRegressor(**params)  \n    model.fit(X_train,y_train,eval_set=[(X_test,y_test)],early_stopping_rounds=100,verbose=False)\n        \n    y_preds = model.predict(X_test)\n    loss = np.sqrt(mean_squared_error(y_test, y_preds))\n    \n    return loss","1642e2d0":"OPTUNA_OPTIMIZATION = True\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=50)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))","a442302d":"if OPTUNA_OPTIMIZATION:\n    display(optuna.visualization.plot_optimization_history(study))\n    display(optuna.visualization.plot_slice(study))\n    display(optuna.visualization.plot_parallel_coordinate(study))","1cd8860e":"cat_params = study.best_trial.params\ncat_params['loss_function'] = 'RMSE'\ncat_params['eval_metric'] = 'RMSE'\ncat_params['bootstrap_type']= 'Bernoulli'\ncat_params['leaf_estimation_method'] = 'Newton'\ncat_params['random_state'] = 42\ncat_params['task_type']='GPU'\ntest_preds=None\n\nprint(\"\\033[93mTraining........\")\n\nkf = StratifiedKFold(n_splits = 10 , shuffle = True , random_state = 42)\nfor fold, (tr_index , val_index) in enumerate(kf.split(x.values , y.values)):\n    \n    print(\"\u2059\" * 10)\n    print(f\"Fold {fold + 1}\")\n    \n    x_train,x_val = x.values[tr_index] , x.values[val_index]\n    y_train,y_val = y.values[tr_index] , y.values[val_index]\n        \n    eval_set = [(x_val, y_val)]\n    \n    model =CatBoostRegressor(**cat_params)\n    model.fit(x_train, y_train, eval_set = eval_set, verbose = False)\n    \n    train_preds = model.predict(x_train)    \n    val_preds = model.predict(x_val)\n    \n    print(np.sqrt(mean_squared_error(y_val, val_preds)))\n    \n    if test_preds is None:\n        test_preds = model.predict(test.values)\n    else:\n        test_preds += model.predict(test.values)\n\nprint(\"-\" * 50)\nprint(\"\\033[95mTraining Done\")\n\ntest_preds \/= 10","71e5bced":"submission = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv\")\n","7e16497b":"submission['loss']=test_preds","c5309371":"submission.to_csv(\"subcat.csv\",index=False)","e58c6bd2":"def objective2(trial,data=x,target=y):\n    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25,random_state=42)\n    params = {\n        \"metric\": \"RMSE\",\n        \"verbosity\": -1,\n        \"boosting_type\": \"gbdt\",\n        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n    }\n    model = lgbm.LGBMRegressor(**params,device = 'gpu',random_state=42)\n    model.fit(X_train,y_train,eval_set=[(X_test,y_test)],verbose = False)\n        \n    y_preds = model.predict(X_test)\n    loss = np.sqrt(mean_squared_error(y_test, y_preds))\n    \n    return loss","108f7f89":"OPTUNA_OPTIMIZATION = True\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective2, n_trials=50)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))","33c514dc":"if OPTUNA_OPTIMIZATION:\n    display(optuna.visualization.plot_optimization_history(study))\n    display(optuna.visualization.plot_slice(study))\n    display(optuna.visualization.plot_parallel_coordinate(study))","18f4f6b7":"params = study.best_trial.params\nparams['metric'] = 'RMSE'\nparams['bootstrap_type']= 'gbdt'\nparams['random_state'] = 42\ntest_preds=None\n\nprint(\"\\033[96mTraining........\")\n\nkf = StratifiedKFold(n_splits = 10 , shuffle = True , random_state = 42)\nfor fold, (tr_index , val_index) in enumerate(kf.split(x.values , y.values)):\n    \n    print(\"\u2059\" * 10)\n    print(f\"Fold {fold + 1}\")\n    \n    x_train,x_val = x.values[tr_index] , x.values[val_index]\n    y_train,y_val = y.values[tr_index] , y.values[val_index]\n        \n    eval_set = [(x_val, y_val)]\n    \n    model =LGBMRegressor(**params,device = 'gpu')\n    model.fit(x_train, y_train, eval_set = eval_set, verbose = False)\n    \n    train_preds = model.predict(x_train)    \n    val_preds = model.predict(x_val)\n    \n    print(np.sqrt(mean_squared_error(y_val, val_preds)))\n    \n    if test_preds is None:\n        test_preds = model.predict(test.values)\n    else:\n        test_preds += model.predict(test.values)\n\nprint(\"-\" * 50)\nprint(\"\\033[91mTraining Done\")\n\ntest_preds \/= 10","2a0fb9bd":"submission = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv\")\nsubmission['loss']=test_preds\nsubmission.to_csv(\"sub2.csv\",index=False)","4f5e12b5":"def objective3(trial,data=x,target=y):\n    \n    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25,random_state=42)\n    params = {\n        \"n_estimators\": trial.suggest_int(\"n_estimators\",200,2000,100),\n        \"subsample\": trial.suggest_discrete_uniform(\"subsample\",0.6,1,0.1),\n        \"colsample_bytree\": trial.suggest_discrete_uniform(\"colsample_bytree\",0.6,1,0.1),\n        \"eta\": trial.suggest_loguniform(\"eta\",1e-3,0.1),\n        \"reg_alpha\": trial.suggest_int(\"reg_alpha\",1,50),\n        \"reg_lambda\": trial.suggest_int(\"reg_lambda\",5,100),\n        \"max_depth\": trial.suggest_int(\"max_depth\",5,20),\n        \"min_child_weight\": trial.suggest_int(\"min_child_weight\",5,20),\n    }\n    model = xgb.XGBRegressor(**params, tree_method='gpu_hist', random_state=42)\n    model.fit(X_train,y_train,eval_set=[(X_test,y_test)],verbose = False,eval_metric='rmse')\n\n    y_preds = model.predict(X_test)\n    loss = np.sqrt(mean_squared_error(y_test, y_preds))\n    \n    return loss","ce7a1adf":"study = optuna.create_study(direction='minimize')\nstudy.optimize(objective3, n_trials=50)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))","0d5f220e":"if OPTUNA_OPTIMIZATION:\n    display(optuna.visualization.plot_optimization_history(study))\n    display(optuna.visualization.plot_slice(study))\n    display(optuna.visualization.plot_parallel_coordinate(study))","f3863fd6":"xgb_params = study.best_trial.params\nxgb_params['tree_method'] = 'gpu_hist'\nxgb_params['random_state'] = 42\ntest_preds=None\n\nprint(\"\\033[91mTraining........\")\n\nkf = StratifiedKFold(n_splits = 10 , shuffle = True , random_state = 42)\nfor fold, (tr_index , val_index) in enumerate(kf.split(x.values , y.values)):\n    \n    print(\"\u2059\" * 10)\n    print(f\"Fold {fold + 1}\")\n    \n    x_train,x_val = x.values[tr_index] , x.values[val_index]\n    y_train,y_val = y.values[tr_index] , y.values[val_index]\n        \n    eval_set = [(x_val, y_val)]\n    \n    model =xgb.XGBRegressor(**xgb_params)\n    model.fit(x_train, y_train, eval_set = eval_set, verbose = False)\n    \n    train_preds = model.predict(x_train)    \n    val_preds = model.predict(x_val)\n    \n    print(np.sqrt(mean_squared_error(y_val, val_preds)))\n    \n    if test_preds is None:\n        test_preds = model.predict(test.values)\n    else:\n        test_preds += model.predict(test.values)\n\nprint(\"-\" * 50)\nprint(\"\\033[97mTraining Done\")\n\ntest_preds \/= 10","b5173ebc":"submission = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv\")\nsubmission['loss']=test_preds\nsubmission.to_csv(\"sub3.csv\",index=False)","d45cc835":"from IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#000CA4','#eb3446','Big Shoulders Inline Text','Smokum',50,10\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h4 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h4>\"\"\"%string))\n    \n    \ndhtml(' Do UPVOTE if you like my work ' )","c0bb9079":"![](https:\/\/www.crownconnect.com\/assets\/ThankYou.jpg)","ec2bc217":"<h1 style=\"background-color:#FF85A3;font-size:20px;color:#00033E;font-weight : bold\">\ud83d\udc68\u200d\ud83d\udcbb LGBM Model Training:<\/h1>","111f1619":"<h1 style=\"background-color:#FF85A3;font-size:20px;color:#00033E;font-weight : bold\">Submission File for LGBM:<\/h1>","07cea44a":"<h1 style=\"background-color:#FF85A3;font-size:20px;color:#00033E;font-weight : bold\"> \u2692 Data Transformation:<\/h1>","2e5dbd2f":"<h1 style=\"background-color:#FF85A3;font-size:20px;color:#00033E;font-weight : bold\">Submission File for Catboost:<\/h1>","c93549fd":"<h1 style=\"background-color:#FF85A3;font-size:20px;color:#00033E;font-weight : bold\"> \ud83d\udd0d Basic Data Exploration:<\/h1>","eb841a06":"<h1 style=\"background-color:#FF85A3;font-size:20px;color:#00033E;font-weight : bold\">\ud83c\udf00 Optuna Objective for XGBoost:<\/h1>","542f7f0e":"<h1 style=\"background-color:#FF85A3;font-size:20px;color:#00033E;font-weight : bold\">\ud83d\udc68\u200d\ud83d\udcbb Catboost Model Training:<\/h1>","9fae43ce":"<h1 style=\"background-color:#FF85A3;font-size:20px;color:#00033E;font-weight : bold\"> \u2705 Importing Required Libraries:<\/h1>","b15d683a":"<h1 style=\"background-color:#FF85A3;font-size:20px;color:#00033E;font-weight : bold\">Submission File for XGBoost:<\/h1>","22b34a01":"<h1 style=\"background-color:#FF85A3;font-size:20px;color:#00033E;font-weight : bold\">\ud83d\udc68\u200d\ud83d\udcbb XGBoost Model Training:<\/h1>","cc989690":"<h1 style=\"background-color:#FF85A3;font-size:20px;color:#00033E;font-weight : bold\"> \ud83c\udf00 Optuna Objective for Catboost:<\/h1>","0fc94516":"<h1 style=\"background-color:#FF85A3;font-size:20px;color:#00033E;font-weight : bold\">\ud83c\udf00 Optuna Objective for LGBM:<\/h1>"}}