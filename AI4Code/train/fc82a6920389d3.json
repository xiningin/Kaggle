{"cell_type":{"81f89e40":"code","89c68f4a":"code","633b35ef":"code","85107c6b":"code","e7335d76":"code","b00584c9":"code","3202d6d9":"code","2255fbf0":"code","ebf70a72":"code","576ee633":"code","4c1eabae":"code","5e3f5128":"code","0ba69f8d":"code","920056c0":"code","bb2ccdfd":"code","4c060b13":"code","9f0e960d":"code","e7c291d4":"code","e01d25c1":"code","968f4664":"code","780e230f":"code","f09cd4b9":"code","75d7d6e5":"code","0bbaa43f":"code","485a34f5":"code","fc4cecf8":"code","49809146":"code","64498e21":"code","adca072d":"code","592340c1":"code","2999ebd0":"code","47a082c9":"code","55249229":"code","731e8ceb":"code","4b2c0110":"code","35593597":"code","79ad429c":"code","b7b5901f":"code","2c3d96ee":"code","60cf79b1":"code","85595989":"code","6b369b1d":"code","2af58aff":"code","62e7beb6":"code","873ae77e":"code","3fce74db":"code","65fad144":"code","73849758":"code","a5e843ac":"code","930962dd":"code","13ef003e":"code","3a72c2bf":"code","ef7e203f":"code","fbf1a2c9":"code","7d5aee51":"code","30f1e27f":"code","4f80ff31":"code","1ef75f99":"code","f4df4907":"code","4ceeb811":"code","6764431e":"markdown","35eeed4f":"markdown","73b0b2a6":"markdown","d574c8dd":"markdown","78ba4afd":"markdown","1ccad246":"markdown","b6671b0a":"markdown","074336f1":"markdown","b952cf16":"markdown","25c9b9cf":"markdown","481a5f0a":"markdown"},"source":{"81f89e40":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","89c68f4a":"#### criando um dataframe exemplo para trabalharmos os conceito\ndf = pd.DataFrame(np.random.randn(7,3))\ndf[3] = ['sim', 'N\u00e3o', 'Sim', 'sim', 'n\u00e3o', 'N\u00e3o', 'SIM']\ndf[4] = ['24\/05\/2021', '25\/05\/2021', '26\/05\/2021', '27\/05\/2021', '28\/05\/2021', '29\/05\/2021', '30\/05\/2021']\ndf.loc[7] = np.random.randn(5)\ndf.loc[7, 3] = 'N\u00c3O'\ndf.loc[7,4] = '31\/05\/2021'\ndf.iloc[:4, 1] = '-'\ndf.iloc[:2, 2] = '-'\ndf.loc[3, 3] = '-'\ndf.columns = ['num_1', 'num_2', 'num_3', 'class', 'date']\ndf = df[['date', 'num_1', 'num_2', 'num_3', 'class']]\ndf","633b35ef":"#  dimens\u00f5es de nosso dataframe\nprint(f'Dataset shape -> {df.shape}')","85107c6b":"# informa\u00e7\u00f5es b\u00e1sicas sobre as colunas\ndf.info()","e7335d76":"# podemos utilizar o dtypes tamb\u00e9m para dataframes\ndf.dtypes","b00584c9":"# nossa \u00faltima coluna \u00e9 formada por texto, e n\u00e3o numeros\ndf['class']","3202d6d9":"# podemos ver que o tipo de dado de nossa coluna tr\u00eas \u00e9 'O', ou seja, object (string ou tipos misturados)\ndf['class'].dtype","2255fbf0":"# para padronizar, podemos deixar tudo min\u00fasculo e retirar os poss\u00edveis espa\u00e7os antes e depois das palavras\ndf['class'] = df['class'].str.strip().str.lower()\ndf","ebf70a72":"# verificando nossa coluna de datas, perceba que o tipo dela n\u00e3o \u00e9 data e sim objeto, string\ndf['date']","576ee633":"# um exemplo bizarro do problema que isso causa\ndf['date'].sum()\n\n# isso n\u00e3o era para \"funcionar\", n\u00e3o se faz soma de datas","4c1eabae":"# n\u00e3o conseguimos selecionar um range de data\ndf.date['26\/05\/2021':'30\/05\/2021']","5e3f5128":"# ou seja, isso est\u00e1 errado, precisamos deixar nossas datas em formato de data!\ndf['date'] = pd.to_datetime(df['date'], format='%d\/%m\/%Y')\ndf","0ba69f8d":"df.info()","920056c0":"# e agora, se colocarmos as datas como index, conseguimos manipul\u00e1-las \ndf.set_index('date', inplace=True)\ndf['2021-05-26':'2021-05-30']","bb2ccdfd":"# vamos tentar ver alguma estat\u00edstica b\u00e1sica de nossos dados, o describe s\u00f3 utiliza colunas num\u00e9ricas\ndf.describe()","4c060b13":"# o que aconteceu? o '-' for\u00e7ou toda a coluna a ser objeto string, pois um n\u00famero pode ser string\n# mas uma string n\u00e3o pode ser um n\u00famero\ndf[['num_1', 'num_2', 'num_3']]","9f0e960d":"# ent\u00e3o, antes de tudo, precisamos entender o que \u00e9 o tracinho, nesse caso, \n#\u00e9 percept\u00edvel que \u00e9 um valor que n\u00e3o temos, por qualquer motivo, apenas n\u00e3o temos\n# e para lidar com isso, antes, teremos que transformar esse tracinho em um n\u00famero qualquer\n\ndf.replace('-', np.nan, inplace=True)#.astype(float)","e7c291d4":"# olhando o tipo de nosso dado\ndf[['num_1', 'num_2', 'num_3']].dtypes","e01d25c1":"# tentando novamente o describe\ndf.describe()","968f4664":"# para facilitar, voltarei resetarei os indices\ndf.reset_index(inplace=True)","780e230f":"# isna() retorna True caso o dado seja NaN, ou False, caso n\u00e3o seja NaN - Not a Number\n# sum() faz a soma desses resultados (lembrando, True = 1 e False = 0)\ndf.isna().sum() # isna() = isnull()","f09cd4b9":"# quais s\u00e3o essas linhas de missing values?\ndf[df.isnull().any(axis=1)]","75d7d6e5":"# porcentagem dos dados que s\u00e3o faltantes\ntotal_cells = np.product(df.shape)          \ntotal_missing = df.isna().sum().sum()\npercent_missing = (total_missing\/total_cells) * 100\nprint('Pct dos dados faltantes: {:.4f}%'.format(percent_missing))","0bbaa43f":"# retira do dataframe todas as linhas que possuem um dado NaN\ndf.dropna() ","485a34f5":"# retira do dataframe todas as colunas que possuem um dado NaN\ndf.dropna(axis=1)","fc4cecf8":"# preencher tudo com zero! faz sentido?\ndf.fillna(0)","49809146":"# preencher de acordo com cada coluna\ndf.fillna({1:0.5, 2:0, 3:'?'})","64498e21":"# preencher usando a m\u00e9dia\ndf.fillna(df.mean())","adca072d":"# preencher usando mediana\ndf.fillna(df.median())","592340c1":"# preencher vari\u00e1veis categ\u00f3ricas usando moda\ndf['class'].fillna(df['class'].mode()[0])\n\n# o mesmo pode ser feito com df[3].value_counts()[0]","2999ebd0":"# e se eu quiser preencher cada coluna com sua m\u00e9dia e a terceira coluna com a moda de uma vez s\u00f3?\ndf.fillna({'num_1':df['num_1'].mean(), \n           'num_2':df['num_2'].mean(),\n           'num_3':df['num_3'].median(),\n           'class':df['class'].mode()[0]})","47a082c9":"# aplicando as mudan\u00e7as na cria\u00e7\u00e3o de outro dataframe\ndf_cleaned = df.fillna({'num_1':df['num_1'].mean(), \n                        'num_2':df['num_2'].mean(),\n                        'num_3':df['num_3'].median(),\n                        'class':df['class'].mode()[0]})\n# se fossemos aplicar ao mesmo data frame, usa o argumento inplace=True\n# df.fillna(modo_de_preencher_nan, inplace=True)","55249229":"# verificando se ainda tem NaN\ndf_cleaned.isna().sum()","731e8ceb":"df_cleaned","4b2c0110":"df.iloc[:, 1:4]","35593597":"# importando a o imputer da biblioteca\nfrom sklearn.impute import SimpleImputer\n\n# instanciando o objeto imputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean') # strategy = ['mean', 'median', 'most_frequent', 'constant']\n\n# aplicando os comandos dados: o m\u00e9todo fit_transform retorna uma matriz numpy\nimputer.fit_transform(df.iloc[:, 1:4].values)","79ad429c":"# retornando os valores transformados ao nosso dataframe original\ndf.iloc[:, 1:4] = imputer.fit_transform(df.iloc[:, 1:4].values)\ndf","b7b5901f":"# baixando os dados\n!wget 'https:\/\/gist.githubusercontent.com\/ktisha\/c21e73a1bd1700294ef790c56c8aec1f\/raw\/819b69b5736821ccee93d05b51de0510bea00294\/pima-indians-diabetes.csv'","2c3d96ee":"# verificando se est\u00e1 no nosso diret\u00f3rio\nos.listdir()","60cf79b1":"# lendo os dados\ndata = pd.read_csv('pima-indians-diabetes.csv', skiprows=9, names=['pregnant', 'glucose', 'diastolic', 'triceps',\n                                                                  'insulin', 'bmi', 'diabetes', 'age', 'class'])","85595989":"# cinco primeiras linhas\ndata.head()","6b369b1d":"# dimens\u00f5es de nossos dados\nprint(f'Dataset shape -> {data.shape}')","2af58aff":"# informa\u00e7\u00f5es b\u00e1sicas sobre as colunas\ndata.info()","62e7beb6":"# visualizando as estat\u00edsticas b\u00e1sicas\ndata.describe()","873ae77e":"# quantidade de NaN por coluna\ndata.isna().sum()","3fce74db":"# analisando os zeros na coluna BMI\ndata.bmi[data.bmi == 0]","65fad144":"# trocando zeros por NaN com replace\n# df[coluna] = df[coluna].replace(valor_a_ser_trocado, valor_novo)\ncolunas_trocar = ['glucose','diastolic','triceps','insulin','bmi'] \ndata = pd.DataFrame([data[coluna].replace(0, np.nan) if coluna in colunas_trocar else data[coluna] for coluna in data.columns]).transpose()","73849758":"# quantidade de NaN por coluna\ndata.isna().sum()","a5e843ac":"# porcentagem dos dados que s\u00e3o faltantes\ntotal_cells = np.product(data.shape)          \ntotal_missing = data.isna().sum().sum()\npercent_missing = (total_missing\/total_cells) * 100\nprint('Porcentagem de missing values: {:.4f}%'.format(percent_missing))","930962dd":"print(f'Porcentagem de missing values por coluna:\\n\\n{data.isnull().mean() * 100}')","13ef003e":"# analisando graficamente\nimport missingno as msno\n\n# barplot\nmsno.bar(data)","3a72c2bf":"# matrix \nmsno.matrix(data)","ef7e203f":"# esse tanto de missing values est\u00e3o relacionados ou s\u00e3o aleat\u00f3rios?\nsorted_data = data.sort_values(by='insulin')\nmsno.matrix(sorted_data)","fbf1a2c9":"# correla\u00e7\u00e3o entre missing values: \n#quanto mais azul, maior a correla\u00e7\u00e3o, quanto mais vermelho, menor a correla\u00e7\u00e3o\n# correla\u00e7\u00e3o \u00e9 o quanto uma vari\u00e1vel influencia outra, o quanto elas est\u00e3o relacionadas\nmsno.heatmap(data)","7d5aee51":"# s\u00f3 \u00e9 recomendado dropar linhas com NaN, caso a quantidade de NaN seja pequena e n\u00e3o v\u00e1 comprometer o dado\n# glucose em poucos NaN e n\u00e3o parece estar relacionado com outras vari\u00e1veis\n# BMI tem seus NaN considerados Missing Completely at Random(MCAR), portanto devemos exclu\u00ed-los.","30f1e27f":"# dropna() com base em apenas uma coluna\ndata.dropna(subset=['glucose', 'bmi'], how='any', inplace=True)","4f80ff31":"# antes de pensar em imputar com a m\u00e9dia ou mediana, vamos verificar qual faz mais sentido\ndata[['insulin', 'triceps']].describe()","1ef75f99":"# podemos imputar valores nas colunas insulin e tricesps\nimputer_intri = SimpleImputer(strategy='median')\n\n#aplicando o fit_transform\ndata.loc[:,['insulin','triceps', 'diastolic']] = imputer_intri.fit_transform(data.loc[:,['insulin','triceps', 'diastolic']].values)","f4df4907":"data.head()","4ceeb811":"data.isna().sum()","6764431e":"## Quarta abordagem: imputation com Sklearn","35eeed4f":"# Problemas de tipos de dados\n\nMuitas vezes temos dados que n\u00e3o s\u00e3o automaticamente identificados corretamente, ou tamb\u00e9m temos dados que s\u00e3o for\u00e7ados a ser de um tipo espec\u00edfico por conta de um erro, e muitos outros casos. Precisamos lidar com esse problema para evitarmos problemas futuros e conseguirmos fazer as an\u00e1lises e os modelos no futuro, al\u00e9m de facilitar a manipula\u00e7\u00e3o e poss\u00edveis c\u00e1lculos","73b0b2a6":"# Segunda abordagem: imputation com fill \n\n![tut2_approach2](https:\/\/i.imgur.com\/4BpnlPA.png)\n\n`df.fillna(algum_valor)`","d574c8dd":"# Terceira abordagem: m\u00e9dia & mediana","78ba4afd":"## Primeira abordagem: drop\n\n![tut2_approach1](https:\/\/i.imgur.com\/Sax80za.png)\n","1ccad246":"# Aplica\u00e7\u00e3o em uma base de dados real\n\n1. N\u00famero de vezes que engravidou\n2. Concentra\u00e7\u00e3o de glicose plasm\u00e1tica\n3. Press\u00e3o arterial diast\u00f3lica (mm Hg)\n4. Espessura da dobra da pele do tr\u00edceps (mm)\n5. Insulina s\u00e9rica de 2 horas (mu U \/ ml)\n6. \u00cdndice de massa corporal (peso em kg \/ (altura em $m^2$))\n7. Fun\u00e7\u00e3o de pedigree de diabetes\n8. Idade (anos)\n9. Vari\u00e1vel de classe (0 ou 1)","b6671b0a":"## Strings que na verdade s\u00e3o n\u00fameros","074336f1":"# Missing data\n\nValores nulos, faltantes, nos fornece uma an\u00e1lise muito interessate e s\u00e3o de extrema import\u00e2ncia! Basicamente, *missing data* s\u00e3o dados que encontram sem valor em nossa base de dados. Esse falta de valor pode se dar por dois motivos principais:\n1. Na vida real, esse dado de fato n\u00e3o existe, portanto tentar trat\u00e1-lo \u00e9 in\u00fatil, ou\n2. O dado existe, mas n\u00e3o foi colocado na base de dado por erro, portanto, \u00e9 poss\u00edvel e aconselhado que se tente encontr\u00e1-lo (veremos como!)\n\nComo descobrir se temos ou n\u00e3o *missing data* em nosso DataFrame?","b952cf16":"## Datas","25c9b9cf":"## Lidando com textos (*strings*)","481a5f0a":"# Por que \"limpeza de dados\"?\n\nNa maioria das vezes nossos dados n\u00e3o vem da forma perfeita, sem erros, inconcist\u00eancias, valores faltantes o \"despadronizado\". O objetivo da limpeza de dados, deixo claro, **n\u00e3o \u00e9 jogar dados fora**, n\u00e3o \u00e9 passar uma vassoura e fazer uma faxina em dados \"errados\", e sim tentar manter o m\u00e1ximo poss\u00edvel. Alguns, conseguimos solucionar, outros infelizmente precisamos jogar fora mesmo (o famoso \"dropar\"). Para decidir quando tratar, limpar, esse dados e quando n\u00e3o trat\u00e1-los, \u00e9 preciso de um conceito chamado *Data Intuition*, ou seja, \u00e9 necess\u00e1rio ter uma intui\u00e7\u00e3o sobre aquele dado espec\u00edfico, veremos mais sobre isso adiante.  \n\nDepois vamos usar de exemplo uma base de dados da covid-19, que consegui atrav\u00e9s do Open Source SUS, uma plataforma que disponibiliza dados gratuitamente sobre a covid-19 e outras doen\u00e7as. Vamos l\u00e1.\n"}}