{"cell_type":{"058af76f":"code","031281a4":"code","bf580410":"code","532c1821":"code","8a6f3ae0":"code","7d9ba063":"code","6c873a7c":"code","2b2d9739":"code","05b9ef20":"code","87e2ff6f":"code","14d7629d":"code","bfb7affe":"code","b8ab6829":"markdown","b6b0edaf":"markdown","a4abff05":"markdown","023cbc5d":"markdown","68fadd1d":"markdown","fc221615":"markdown"},"source":{"058af76f":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom tqdm import tqdm\nfrom copy import deepcopy","031281a4":"# let's define our own stratified validator \"with blackjack and hookers\" :)\nclass CustomStratifiedKFold:\n    \"\"\"\n    Faster (yet memory-heavier) stratified cross-validation split\n    Best suited for longer time-series with many different `y` groups\n    \"\"\"\n    def __init__(\n        self,\n        n_splits: int = 5,\n        shuffle: bool = True,\n        random_state: int = 42\n    ):\n        self.n_splits = n_splits\n        self.shuffle = shuffle\n        self.seed = random_state\n        self.folds_ = [(list(), list()) for _ in range(n_splits)]\n        self.randomizer_ = np.random.RandomState(random_state)\n        self.groups_ = None\n        self.counts_ = None\n        self.s_ = None\n\n    def split(self, X, y):\n        sorted_y = pd.Series(y).reset_index(drop=True).sort_values().astype('category').cat.codes\n        self.s_ = pd.Series(data=sorted_y.index.values, index=sorted_y)\n        self.groups_ = self.s_.index.unique()\n        self.counts_ = np.bincount(self.s_.index)\n\n        if self.n_splits > self.counts_.min():\n            raise ValueError(\n                f'Cannot split {self.counts_.min()} elements in smallest group on {self.n_splits} folds'\n            )\n\n        shift = 0\n        for cnt in tqdm(self.counts_, desc='processing unique strats'):\n            # get array of initial data's indices\n            arr = self.s_.iloc[shift:shift + cnt].values\n            # shuffle data if needed\n            if self.shuffle:\n                self.randomizer_.shuffle(arr)\n            folds = np.array_split(arr, self.n_splits)\n            # extend outer folds by elements from micro-folds\n            for i in range(self.n_splits):\n                cp = deepcopy(folds)\n                # extend val indices\n                val_chunk = cp.pop(i).tolist()\n                self.folds_[i][1].extend(val_chunk)\n                # extend train indices\n                if self.shuffle:\n                    cp = self.randomizer_.permutation(cp)\n                train_chunk = np.hstack(cp).tolist()\n                self.folds_[i][0].extend(train_chunk)\n\n            # shift to the next group\n            shift += cnt\n        assert shift == len(self.s_)\n\n        for (t, v) in self.folds_:\n            yield (\n                np.array(self.randomizer_.permutation(t) if self.shuffle else t, dtype=np.int32),\n                np.array(self.randomizer_.permutation(v) if self.shuffle else v, dtype=np.int32)\n            )","bf580410":"N_FOLDS = 5\nSEED = 42\nSHUFFLE = True\nNUM_UNIQUES = 1000\nN = 7000000\n\nrandomizer = np.random.RandomState(SEED)\nstrat_column = pd.Series(randomizer.randint(0, NUM_UNIQUES, N, dtype=np.int32))\nprint(strat_column.nunique())\nstrat_column.head(10)","532c1821":"%%time\n# let's check usual StratifiedKFold speed\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=SHUFFLE, random_state=SEED)\n\nfolds = list(skf.split(\n    # we don't actually need `X` to produce indices, only `y`\n    X=np.zeros(len(strat_column)),\n    y=strat_column\n))","8a6f3ae0":"# let's check whether class balance is preserved\nprint('train')\nprint(strat_column.iloc[folds[0][0]].value_counts(normalize=True).sort_index())\nprint('val')\nprint(strat_column.iloc[folds[0][1]].value_counts(normalize=True).sort_index())","7d9ba063":"# check all indices are there in joined validation blocks\nassert len(set(np.hstack([v for (tr,v) in folds]).tolist())) == len(strat_column)","6c873a7c":"%%time\n# let's check updated StratifiedKFold speed\nskf = CustomStratifiedKFold(n_splits=N_FOLDS, shuffle=SHUFFLE, random_state=SEED)\n\nfolds = list(skf.split(\n    # we don't actually need `X` to produce indices, only `y`\n    X=None,\n    y=strat_column\n))","2b2d9739":"# let's check whether class balance is preserved also in new method\nprint('train')\nprint(strat_column.iloc[folds[1][0]].value_counts(normalize=True).sort_index())\nprint('val')\nprint(strat_column.iloc[folds[1][1]].value_counts(normalize=True).sort_index())","05b9ef20":"# check all indices are there in joined validation blocks (also for the new strategy)\nassert len(set(np.hstack([v for (tr,v) in folds]).tolist())) == len(strat_column)","87e2ff6f":"N_FOLDS = 5\nSEED = 42\nSHUFFLE = True\nNUM_UNIQUES = 10000\nN = 20000000\n\nstrat_column = pd.Series(randomizer.randint(0, NUM_UNIQUES, N, dtype=np.int32))\nprint(strat_column.nunique())\nstrat_column.head(10)","14d7629d":"%%time\n# let's check updated StratifiedKFold speed on heavier task (however, notice rapid memory peak)\n# don't try to run this with usual `StratifiedKFold` or prepare to wait A LOT\nskf = CustomStratifiedKFold(n_splits=N_FOLDS, shuffle=SHUFFLE, random_state=SEED)\n\nfolds = list(skf.split(\n    # we don't actually need `X` to produce indices, only `y`\n    X=None,\n    y=strat_column\n))","bfb7affe":"# let's check whether class balance is preserved also in new method\nprint('train')\nprint(strat_column.iloc[folds[1][0]].value_counts(normalize=True).sort_index())\nprint('val')\nprint(strat_column.iloc[folds[1][1]].value_counts(normalize=True).sort_index())","b8ab6829":"### Let's create some fake data to test different approaches on","b6b0edaf":"Well, almost as fast (or even faster at commiting mode) as `StratifiedKFold` on much smaller\/less diverse dataset!","a4abff05":"Hi guys!\n<br>I do not know about the scale of the problem, but personally, when I tried to setup validation strategy with 5+ folds and **1000+ **unique groups for this particular dataset of **20+M rows** I stuck with usual `sklearn`-based `StratifiedKFold` - it runs incredibly long to actually return train\/val indices\n<br>That's why I had to spend some time to reduce the speed bottleneck (at the cost of less efficient memory usage)\n<br>In this small kernel I want to share with you faster stratified cross-validator built from scratch.\n<br>**P.s.** small speed tests are also provided. \n<br>**UPD1**: Made it more-or-less generator-like to reduce RAM usage on final stage\n<br>**UPD2**: corrected indexes, now is fully stratified (class balance is preserved as in `StratifiedKFold`)","023cbc5d":"### let's create real-world example","68fadd1d":" Well, even on smaller dataset we get** 3x+** speed improvement","fc221615":"**P.s.** There are a lot that needs polishing in current approach - and one may optimize my script to reduce memory peaks, further improve speed etc. However, it works (almost) as intended to be :)\n<br>Hope you guys found this code useful\n<br>Comments, likes, new ideas are highly welcomed!\n<br>Happy kaggling!\n\n---\nCheck my latest notebooks:\n- [Aligning Temperature Timestamp](https:\/\/www.kaggle.com\/frednavruzov\/aligning-temperature-timestamp)\n- [NaN restoration techniques for weather data](https:\/\/www.kaggle.com\/frednavruzov\/nan-restoration-techniques-for-weather-data\/edit\/run\/22556654)\n"}}