{"cell_type":{"059d6c32":"code","97ee3eb5":"code","eff4bd7a":"code","a85ccc0a":"code","6d335d1b":"code","703b7cbf":"code","b60a68fe":"code","6c372017":"code","93ec2469":"code","d46000a8":"code","c7d45097":"code","6a7a3568":"code","28257219":"code","33c91435":"code","50ca01c2":"code","3a3b8388":"code","b46c01d3":"code","9599ccfa":"code","025ddee6":"markdown","078b1c1c":"markdown","c0615bc0":"markdown","836bb86a":"markdown","b92b6e78":"markdown","d3ac1816":"markdown","06da9587":"markdown","e5da84e2":"markdown","e3ee5ebd":"markdown","69e1128f":"markdown","8792b0a0":"markdown","219d594d":"markdown"},"source":{"059d6c32":"!apt-get install time dos2unix -y -qq  # NOTE: -qq requires using apt-get not apt","97ee3eb5":"!rm -rf \/ai-games\/\n!git clone https:\/\/github.com\/JamesMcGuigan\/ai-games.git \/ai-games\/\n#!git checkout e275d53b40ce499ee670b0c1dd00bef17235affe\n!cd \/ai-games\/; git log -n1 ","eff4bd7a":"!cd \/ai-games\/games\/connectx; \/ai-games\/kaggle_compile.py agents\/MontyCarlo\/MontyCarloBitsquares.py | dos2unix > \/MontyCarloBitsquares.compiled.py","a85ccc0a":"import IPython\n\ndef display_source(code):\n    def _jupyterlab_repr_html_(self):\n        from pygments import highlight\n        from pygments.formatters import HtmlFormatter\n\n        fmt = HtmlFormatter(style='tango')  # https:\/\/overiq.com\/pygments-tutorial\/#style\n        style = \"<style>{}\\n{}<\/style>\".format(\n            fmt.get_style_defs(\".output_html\"), fmt.get_style_defs(\".jp-RenderedHTML\")\n        )\n        return style + highlight(self.data, self._get_lexer(), fmt)\n\n    # Replace _repr_html_ with our own version that adds the 'jp-RenderedHTML' class\n    # in addition to 'output_html'.\n    IPython.display.Code._repr_html_ = _jupyterlab_repr_html_\n    return IPython.display.Code(data=code, language=\"python3\")","6d335d1b":"display_source('\/MontyCarloBitsquares.compiled.py')","703b7cbf":"# Disable tests for other agents\n!perl -p -i -e 's\/^[# ]*(.*(?<!MontyCarloBitsquares)\\(\\).*)$\/#   $1\/' \/ai-games\/games\/connectx\/tests\/fixtures\/agents.py\n!cd \/ai-games\/games\/connectx\/; find \/ai-games\/games\/connectx\/tests -type f -name '*.py' | xargs -I{} bash -c \"echo -e '\\n\\n### {}\\n\\n'; cat {}\" > \/kaggle\/working\/tests.py","b60a68fe":"display_source('\/kaggle\/working\/tests.py')","6c372017":"!cd \/ai-games\/games\/connectx; pytest","93ec2469":"# Copy datafile from previous notebook run | comment out prefer github datafiles\n!cp -f \/kaggle\/input\/*\/data\/*base64.py \/ai-games\/games\/connectx\/data\/","d46000a8":"### NOTE: we are using dill rather than pickle now, so we should (hopefully) be able to train outside of kaggle_compile.py\n# !cd \/ai-games\/games\/connectx; python3 \/ai-games\/kaggle_compile.py .\/training_montycarlo.py > \/kaggle\/working\/training.py\n# !perl -p -i -e 's\/^(for timeout in).*$\/$1 [0.25]:\/' \/kaggle\/working\/training.py                  # Shorten training times during development\n# !cd \/ai-games\/games\/connectx; time -p python3 \/kaggle\/working\/training.py | grep 'save\\|load';   # CWD still relative to data directory\n\n!cd \/ai-games\/games\/connectx; time -p python3 .\/training_montycarlo.py | grep 'save\\|load';        # CWD still relative to data directory","c7d45097":"# BUGFIX: windows lineendings when generated inside kaggle notebook\n!dos2unix \/ai-games\/games\/connectx\/data\/*base64.py 2> \/dev\/null","6a7a3568":"!cd \/ai-games\/games\/connectx; \/ai-games\/kaggle_compile.py agents\/MontyCarlo\/MontyCarloBitsquares.py .\/data\/MontyCarloBitsquaresNode_base64.py > \/kaggle\/working\/submission.py\n\n# BUGFIX: AttributeError: module 'numba' has no attribute 'config'  \n# NOTE:   This doesn't happen when running kaggle_compile.py on localhost, only when running from inside an notebook\n!perl -p -i -e 's\/^(import numba|bitboard_type)\/#$&\/' \/kaggle\/working\/submission.py\n\n!ls -lah \/kaggle\/working\/submission.py","28257219":"%run submission.py","33c91435":"!cp -rf \/ai-games\/games\/connectx\/data \/kaggle\/working\/\n!rm -f  \/kaggle\/working\/data\/__init__.py","50ca01c2":"from kaggle_environments import evaluate, make, utils\n\n%load_ext autoreload\n%autoreload 2","3a3b8388":"# ### Play against yourself without an ERROR or INVALID.\n# ### Note: The first episode in the competition will run this to weed out erroneous agents.\n\nenv = make(\"connectx\", debug=True)\nenv.run([\"\/kaggle\/working\/submission.py\", \"\/kaggle\/working\/submission.py\"])\nprint(\"\\nEXCELLENT SUBMISSION!\" if env.toJSON()[\"statuses\"] == [\"DONE\", \"DONE\"] else \"MAYBE BAD SUBMISSION?\")\nenv.render(mode=\"ipython\", width=500, height=450)","b46c01d3":"env = make(\"connectx\", debug=True)\nenv.run([\"negamax\", \"\/kaggle\/working\/submission.py\"])\nprint(\"\\nEXCELLENT SUBMISSION!\" if env.toJSON()[\"statuses\"] == [\"DONE\", \"DONE\"] else \"MAYBE BAD SUBMISSION?\")\nenv.render(mode=\"ipython\", width=500, height=450)","9599ccfa":"# env = make(\"connectx\")\n# env.configuration.timeout = 2  # Don't make a human wait 8 seconds between moves\n \n# print('Human plays first against the computer')\n# env.play([None, MontyCarloBitsquares()], width=500, height=450)  \n\n# print('Human plays second against the computer')\n# env.play([MontyCarloBitsquares(), None], width=500, height=450)  ","025ddee6":"# Precache Training\n\nRerun the training loop to generate additional cached data. \n\nIdeally should be on a timer, but coincidently the current training config takes 8.3 hours, which is almost perfect.\n\nBUGFIX: `base64_file_load() Exception: No module named 'agents'`: There is a issue with pickle being unable to re-resolve modules after being compiled into a single script. Thus as a workaround, the training script itself should be run through kaggle_compile.py and the training done within a single-file namespace. This can be solved by using dill rather than pickle.","078b1c1c":"# Submission","c0615bc0":"\n# Tests\n## Unit Tests\n- [.\/heuristics\/LibertiesHeuristic_test.py](https:\/\/github.com\/JamesMcGuigan\/ai-games\/tree\/master\/games\/connectx\/.\/heuristics\/LibertiesHeuristic_test.py)\n- [.\/core\/ConnectXBBN_test.py](https:\/\/github.com\/JamesMcGuigan\/ai-games\/tree\/master\/games\/connectx\/.\/core\/ConnectXBBN_test.py)\n- [.\/core\/ConnectX_test.py](https:\/\/github.com\/JamesMcGuigan\/ai-games\/tree\/master\/games\/connectx\/.\/core\/ConnectX_test.py)\n- [.\/core\/ConnectXBitboard_test.py](https:\/\/github.com\/JamesMcGuigan\/ai-games\/tree\/master\/games\/connectx\/.\/core\/ConnectXBitboard_test.py)\n- [.\/util\/base64_file_test.py](https:\/\/github.com\/JamesMcGuigan\/ai-games\/tree\/master\/games\/connectx\/.\/util\/base64_file_test.py)\n\nUnit tests validate that individual functions work as expected.\n\n\n## Integration Tests\n- [tests\/test_board_positions.py](https:\/\/github.com\/JamesMcGuigan\/ai-games\/tree\/master\/games\/connectx\/tests\/test_board_positions.py)\n- [tests\/test_can_win_against.py](https:\/\/github.com\/JamesMcGuigan\/ai-games\/tree\/master\/games\/connectx\/tests\/test_can_win_against.py)\n\nIntegration testing can be applied to AI algorithms by giving them game puzzles to solve, \nespecially in positions where a human can verify that there is only one (or two) winning\/losing moves.\n\nThe simplest is being one move away from connect 4 and seeing if the agent can either find the winning move, \nor block the opponent from that square. More complicated positions include being able to spot a double attack, \nwhich requires a Minimax search depth of 4, or knowing which column to play during an endgame. \n\nA second form of integration tests is a live matchup against the inbuilt kaggle agents: random and negamax.\nAny leaderboard worthy agent should be able score a near 100% winrate against these opponents, \nso a logic mistake in the algorithm will show up as a test failure.","836bb86a":"# Codebase\n\nThis can also be viewed on github: https:\/\/github.com\/JamesMcGuigan\/ai-games\/tree\/master\/games\/connectx","b92b6e78":"# Buildchain\n\nSo here we can just fetch the commit from the github repo, and compile via kaggle_compile.py.\n- https:\/\/www.kaggle.com\/jamesmcguigan\/kaggle-compile-py-python-ide-to-kaggle-compiler\n\nNOTE: Kaggle notebooks only allow a maximum 1Mb of code in a notebook, so using precached base64 data cannot be simply be copy\/pasted into a notebook, but must be generated via a runtime command.\n\nWe can take the existing saved data from the github repo, and make use of additional compute time on the Kaggle servers by rerunning the training script for additional runtime.","d3ac1816":"# ConnectX - MCTS Bitboard + Bitsquares Heuristic\n\nMonty Carlo Tree Search using an precached Object Oriented Tree + Numpy Bitboard Bitshifting Game Model + Bitsquares Heuristic + Precache training\n\n\n\n# Bitboard\n\nFocusing attention back on raw performance resulted in a bitboard implementation. \nA 84 bit number was used, divided into 2 x 42 bit subsections. \nThe first half the bitboard stored if a square was empty or contained a piece (0==empty, 1==filled).\nThe second half the bitboard stored which player's token was in each square (0==p1, 1==p2).\n\nThe gameover\/utility function was implemented by creating bitmasks for all 69 possible win lines,\nfor fast iteration to see if all squares where filled, and then if so where they all filled by the same player. \n\nA simple but fast heuristic was designed that emulated the gameover\/utility methodology, \nbut also matched on empty squares, signifying the number of potential connect4 lines that could be created.\n\nI have written a tutorial on the vectorized bitshifting implementation used in this kernel:\n- https:\/\/www.kaggle.com\/jamesmcguigan\/connectx-vectorized-bitshifting-tutorial\n\n\n\n# Monty Carlo Tree Search\n\nLeaderboard Scores: \n- **1075 (top 6%)** | [MontyCarloPure + Cached Data](https:\/\/www.kaggle.com\/c\/connectx\/submissions?dialog=episodes-submission-16816641)\n- **1065 (top 7%)** | [MontyCarloPure](https:\/\/www.kaggle.com\/c\/connectx\/submissions?dialog=episodes-submission-16779472)\n\nSource:\n- [agents\/MontyCarlo\/MontyCarloPure.py](https:\/\/github.com\/JamesMcGuigan\/ai-games\/tree\/master\/games\/connectx\/agents\/MontyCarlo\/MontyCarloPure.py)\n\nWhereas Minimax \/ Negamax performs a breadth first search of the game state tree, Monty Carlo selectively expands\nthe tree deeper in areas where success is more probable. Tree\/graph expansion follows a similar shape to A* search. \n\nThe algorithm starts with a root node with unexpanded children.\n\nExpansion happens in two parts. First is node selection, where is the tree is traversed from the root node, \nchoosing the child node with the highest UCB score, which includes an additional term to encourage exploration.\nWhen an unexpanded leaf node is reached, a random simulation of the game is run from that position \nwith the score and total counts backpropergated along the tree path.\n\nExpansions are repeatedly run until the timeout expires, and the child of root node with the highest score is chosen \nas the returned as the agent action.\n\n\n# Monty Carlo Heuristic Search\n\nLeaderboard Scores: \n- **1110 (top 4%)** | [MontyCarloHeuristic + BitboardGameoversHeuristic + Cached Data](https:\/\/www.kaggle.com\/c\/connectx\/submissions?dialog=episodes-submission-16832763)\n- **1110 (top 4%)** | [MontyCarloHeuristic + BitboardGameoversHeuristic + Cached Data](https:\/\/www.kaggle.com\/c\/connectx\/submissions?dialog=episodes-submission-16832763)\n- **1070 (top 6%)** | [MontyCarloHeuristic + BitboardGameoversHeuristic](https:\/\/www.kaggle.com\/c\/connectx\/submissions?dialog=episodes-submission-16783457)\n\nSource:\n- [agents\/MontyCarlo\/MontyCarloPure.py](https:\/\/github.com\/JamesMcGuigan\/ai-games\/tree\/master\/games\/connectx\/agents\/MontyCarlo\/MontyCarloPure.py)\n\nThis approach replaces random simulation (producing an integer score of 0|1) with a sigmoided version of \n`bitboard_gameovers_heuristic()` (producing a floating point score between 0 and 1). \n\nScaling the sigmoid by factor of 6 (division), produced the highest winrate compared to other numbers. \nThis means a heuristic value of +6 would return a sigmoid score of +0.73, which is pretty winning. \nSmaller differences in heuristic score would result in a value much closer to 0.5 draw. \nIf a terminal state in the game tree is reached, an integer score of 0|1 is returned.\n\nCompared to random simulation, a heuristic provides more indepth knowledge about a position, and it is significantly \nfaster to compute than running a full game simulation. This means many more expansions can be run within the same time limit.\n\n\n\n\n# Cached Data\n- [util\/base64_file.py](https:\/\/github.com\/JamesMcGuigan\/ai-games\/tree\/master\/games\/connectx\/util\/base64_file.py)\n- [core\/PersistentCacheAgent.py](https:\/\/github.com\/JamesMcGuigan\/ai-games\/tree\/master\/games\/connectx\/core\/PersistentCacheAgent.py)\n\nMuch of the MontyCarlo runtime is spent expanding the tree and computing simulations\/heuristics. \nSome of this could be precomputed to extend the depth of search possible during the 8 second turn timer.\n\nThe state tree needed to be persisted to disk, in a pickle.zip.base64 format suitable for embedding as text \nin a python script, then reloaded upon initialization. \n\nSeveral hours of localhost runtime where spent playing the MontyCarlo agents against themselves and other agents\nincluding hundreds of matches against random_agent. This effectively generated an opening book and precached engdame \nvalues for some expected lines of play.  \n\nIn theory, kaggle allows 100Mb of submission data, but in practice data files larger than 5-10Mb \ncause kaggle submission errors. The original datafile generated by the above process was 47Mb which was too large.\nBy pruning the tree of any nodes that had not been fully expanded, the filesize was reduced to a workable 5Mb.   \n\nThis cached datafile significantly improved winrates on the leaderboard, both for Random Simulation \nand Heuristic versions of Monty Carlo Tree Search.\n\n\n\n# Bitsquares Heuristic \n\nLeaderboard Scores: \n- **(1120)** | [AlphaBetaBitboard + bitsquares_heuristic(reward_bitsquares=1.75)](https:\/\/www.kaggle.com\/c\/connectx\/submissions?dialog=episodes-submission-16964089)\n- **(1120)** | [MontyCarloTreeSearch + bitsquares_heuristic(reward_bitsquares=1.75, sigmoid_width=6.0)](https:\/\/www.kaggle.com\/c\/connectx\/submissions?dialog=episodes-submission-16964089)\n- **(1140)** | [MontyCarloTreeSearch + bitsquares_heuristic(reward_bitsquares=1.75, sigmoid_width=7.0) + 1.25MB precache](https:\/\/www.kaggle.com\/c\/connectx\/submissions?dialog=episodes-submission-16964089)\n\n\n\nCode:\n- [heuristics\/BitsquaresHeuristic.py](https:\/\/github.com\/JamesMcGuigan\/ai-games\/tree\/master\/games\/connectx\/heuristics\/BitsquaresHeuristic.py)\n \nThis takes a similar approach to Bitboard Gameovers Heuristic, in that it checks for every possible connect 4\nbitmask, containing only player owned or empty squares that is not blocked by opponent pieces.\n\nThe score is based counting the number of bits in each line and squaring the bitcount. \n\nHyperparameter tuning discovered that using a power of 1.75 rather than 2 improved the winrate against\n`bitboard_gameovers_heuristic()` from 48% to 94%, without using any `double_attack_score` logic.\n\nOptimal Reward Values given: **n ** 1.75**:\n- 1-in-a-row = 1 \n- 2-in-a-row = 3.4\n- 3-in-a-row = 6.8\n- 4-in-a-row = inf\n\n\nI have tried writing more advanced heuristics, taking into account the odd\/even height of specific squares. These however have not performed quite as well in practice. \nThe main issue is the additional CPU performance cost of the heuristic, which is getting called in a tight loop. Investing more of out CPU budget into a heuristic score for each node, means that MCTS will be able to run less simulations and expand less nodes, thus allowing a cheap heuristic win against a better but more expensive heuristic. The bitsquares heuristic is much faster than simulating an entire game using random agent. \n- [heuristics\/BitboardOddEvenHeuristic.py](https:\/\/github.com\/JamesMcGuigan\/ai-games\/blob\/master\/games\/connectx\/heuristics\/BitboardOddEvenHeuristic.py)\n\n\nA future ideas for research is to combine MCTS with a heuristic designed using a neural network trained through self-play. This mirrors the underlying design of AlphaZero.\nIn preperation for this I have attempted to implement the `is_gameover()` function in pytorch.\n- https:\/\/www.kaggle.com\/jamesmcguigan\/connectx-implementing-functions-in-pytorch\/","06da9587":"This is how we export to a submissions.py file via [kaggle_compile.py](https:\/\/www.kaggle.com\/jamesmcguigan\/kaggle-compile-py-python-ide-to-kaggle-compiler).\n\nNOTE: kaggle_compile.py assumes all codebase import statements are relative to the current directory.","e5da84e2":"# Versus Self","e3ee5ebd":"# Versus Human\n\nUnder leaderboard game conditions, the computer has 8 seconds per move, but this seems very slow from a human interaction standpoint. Thus the timer vs human play has been reduced to 2 seconds.\n\nNOTE: this only seems to work inside the Kaggle Editor, and not in the published HTML version","69e1128f":"Export data files to home directory to be downloadble from kaggle notebook output","8792b0a0":"# Versus Negamax","219d594d":"Test we have no compilation errors\n\nBUG: Notebook is currently experiencing out of memory errors on commit when training is included, so removing the runtime element of this notebook"}}