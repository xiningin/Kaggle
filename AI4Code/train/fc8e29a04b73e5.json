{"cell_type":{"cd630cbd":"code","85fe4959":"code","74dfb49f":"code","18d8c8c0":"code","eadffa8e":"code","e75059ef":"code","0afabd9f":"code","10315ff6":"code","e388d7fb":"code","cb45bdc7":"code","48699b85":"code","9ecbf59b":"code","f8b85534":"code","4643e1a9":"code","97f8070b":"code","21f02457":"code","8cbe6079":"code","d10b9fb5":"code","ba815168":"code","20e7cf21":"code","cdb5fb0e":"code","02cbc96a":"code","a9af1a98":"code","682a42a8":"code","6e069290":"code","977108a1":"code","2d4ed424":"markdown","dfa5c15d":"markdown","647f3215":"markdown","cfbf4ebd":"markdown","10e904df":"markdown","0a5fc333":"markdown","dc31dcfd":"markdown","0b316547":"markdown","472c378d":"markdown","cb30ced2":"markdown","63491c58":"markdown","51391d1b":"markdown","6db56954":"markdown","d6f12790":"markdown"},"source":{"cd630cbd":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tqdm import tqdm_notebook as tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torchvision.transforms as transforms\nfrom torchvision import models\nimport torch.nn.functional as F\nfrom torch.autograd import Function, Variable\nfrom pathlib import Path\nfrom itertools import groupby\nimport time","85fe4959":"\nstart = time.time()\n\ninput_dir = \"..\/input\/severstal-steel-defect-detection\/\"\ntrain_img_dir = \"..\/input\/severstal-steel-defect-detection\/train_images\/\"\ntest_img_dir = \"..\/input\/severstal-steel-defect-detection\/test_images\/\"\n\ncategory_num = 4 + 1\n\nratio = 1\nepoch_num = 1\nbatch_size = 2\ndevice = \"cuda:0\"","74dfb49f":"train_df = pd.read_csv(input_dir + \"train.csv\")\ntrain_df[['ImageId', 'ClassId']] = train_df['ImageId_ClassId'].str.split('_', expand=True)\ntrain_df.head()","18d8c8c0":"train_df.shape","eadffa8e":"def make_mask_img(segment_df):\n    seg_width = 1600\n    seg_height = 256\n    seg_img = np.full(seg_width*seg_height, category_num-1, dtype=np.int32)\n    for encoded_pixels, class_id in zip(segment_df[\"EncodedPixels\"].values, segment_df[\"ClassId\"].values):\n        if pd.isna(encoded_pixels): continue\n        pixel_list = list(map(int, encoded_pixels.split(\" \")))\n        for i in range(0, len(pixel_list), 2):\n            start_index = pixel_list[i] -1 \n            index_len = pixel_list[i+1] \n            seg_img[start_index:start_index+index_len] = int(class_id) \n    seg_img = seg_img.reshape((seg_height, seg_width), order='F')\n   \n    return seg_img","e75059ef":"def train_generator(df, batch_size):\n    img_ind_num = df.groupby(\"ImageId\")[\"ClassId\"].count()\n    index = df.index.values[0]\n    trn_images = []\n    seg_images = []\n    for i, (img_name, ind_num) in enumerate(img_ind_num.items()):\n        img = cv2.imread(train_img_dir + img_name)\n        segment_df = (df.loc[index:index+ind_num-1, :]).reset_index(drop=True)\n        index += ind_num\n        if segment_df[\"ImageId\"].nunique() != 1:\n            raise Exception(\"Index Range Error\")\n        seg_img = make_mask_img(segment_df)\n        \n        # HWC -> CHW\n        img = img.transpose((2, 0, 1))\n        #seg_img = seg_img.transpose((2, 0, 1))\n        \n        trn_images.append(img)\n        seg_images.append(seg_img)\n        if((i+1) % batch_size == 0):\n            yield np.array(trn_images, dtype=np.float32) \/ 255, np.array(seg_images, dtype=np.int32)\n            trn_images = []\n            seg_images = []\n    if(len(trn_images) != 0):\n        yield np.array(trn_images, dtype=np.float32) \/ 255, np.array(seg_images, dtype=np.int32)","0afabd9f":"def test_generator(img_names):\n    for img_name in img_names:\n        img = cv2.imread(test_img_dir + img_name)\n        # HWC -> CHW\n        img = img.transpose((2, 0, 1))\n        yield img_name, np.asarray([img], dtype=np.float32) \/ 255","10315ff6":"def encode(input_string):\n    return [(len(list(g)), k) for k,g in groupby(input_string)]\n\ndef run_length(label_vec):\n    encode_list = encode(label_vec)\n    index = 1\n    class_dict = {}\n    for i in encode_list:\n        if i[1] != category_num-1:\n            if i[1] not in class_dict.keys():\n                class_dict[i[1]] = []\n            class_dict[i[1]] = class_dict[i[1]] + [index, i[0]]\n        index += i[0]\n    return class_dict","e388d7fb":"class double_conv(nn.Module):\n    '''(conv => BN => ReLU) * 2'''\n    def __init__(self, in_ch, out_ch):\n        super(double_conv, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\n\nclass inconv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(inconv, self).__init__()\n        self.conv = double_conv(in_ch, out_ch)\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\n\nclass down(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(down, self).__init__()\n        self.mpconv = nn.Sequential(\n            nn.MaxPool2d(2),\n            double_conv(in_ch, out_ch)\n        )\n\n    def forward(self, x):\n        x = self.mpconv(x)\n        return x\n\n\nclass up(nn.Module):\n    def __init__(self, in_ch, out_ch, bilinear=True):\n        super(up, self).__init__()\n\n        #  would be a nice idea if the upsampling could be learned too,\n        #  but my machine do not have enough memory to handle all those weights\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        else:\n            self.up = nn.ConvTranspose2d(in_ch\/\/2, in_ch\/\/2, 2, stride=2)\n\n        self.conv = double_conv(in_ch, out_ch)\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        diffX = x1.size()[2] - x2.size()[2]\n        diffY = x1.size()[3] - x2.size()[3]\n        x2 = F.pad(x2, (diffX \/\/ 2, int(diffX \/ 2),\n                        diffY \/\/ 2, int(diffY \/ 2)))\n        x = torch.cat([x2, x1], dim=1)\n        x = self.conv(x)\n        return x\n\n\nclass outconv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(outconv, self).__init__()\n        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\n    \nclass UNet(nn.Module):\n    def __init__(self, n_channels, n_classes):\n        super(UNet, self).__init__()\n        self.inc = inconv(n_channels, 64)\n        self.down1 = down(64, 128)\n        self.down2 = down(128, 256)\n        self.down3 = down(256, 512)\n        self.down4 = down(512, 512)\n        self.up1 = up(1024, 256)\n        self.up2 = up(512, 128)\n        self.up3 = up(256, 64)\n        self.up4 = up(128, 64)\n        self.outc = outconv(64, n_classes)\n\n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        x = self.outc(x)\n        return x","cb45bdc7":"# https:\/\/github.com\/usuyama\/pytorch-unet\n\ndef convrelu(in_channels, out_channels, kernel, padding):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n        nn.ReLU(inplace=True),\n    )\n\n\nclass ResNetUNet(nn.Module):\n    def __init__(self, n_class):\n        super().__init__()\n\n        self.base_model = models.resnet18(pretrained=True)\n        self.base_layers = list(self.base_model.children())\n\n        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H\/2, x.W\/2)\n        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H\/4, x.W\/4)\n        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H\/8, x.W\/8)\n        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n        self.layer3 = self.base_layers[6]  # size=(N, 256, x.H\/16, x.W\/16)\n        self.layer3_1x1 = convrelu(256, 256, 1, 0)\n        self.layer4 = self.base_layers[7]  # size=(N, 512, x.H\/32, x.W\/32)\n        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n\n        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n\n        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n\n        self.conv_last = nn.Conv2d(64, n_class, 1)\n\n    def forward(self, input):\n        x_original = self.conv_original_size0(input)\n        x_original = self.conv_original_size1(x_original)\n\n        layer0 = self.layer0(input)\n        layer1 = self.layer1(layer0)\n        layer2 = self.layer2(layer1)\n        layer3 = self.layer3(layer2)\n        layer4 = self.layer4(layer3)\n\n        layer4 = self.layer4_1x1(layer4)\n        x = self.upsample(layer4)\n        layer3 = self.layer3_1x1(layer3)\n        x = torch.cat([x, layer3], dim=1)\n        x = self.conv_up3(x)\n\n        x = self.upsample(x)\n        layer2 = self.layer2_1x1(layer2)\n        x = torch.cat([x, layer2], dim=1)\n        x = self.conv_up2(x)\n\n        x = self.upsample(x)\n        layer1 = self.layer1_1x1(layer1)\n        x = torch.cat([x, layer1], dim=1)\n        x = self.conv_up1(x)\n\n        x = self.upsample(x)\n        layer0 = self.layer0_1x1(layer0)\n        x = torch.cat([x, layer0], dim=1)\n        x = self.conv_up0(x)\n\n        x = self.upsample(x)\n        x = torch.cat([x, x_original], dim=1)\n        x = self.conv_original_size2(x)\n\n        out = self.conv_last(x)\n\n        return out","48699b85":"!mkdir -p \/tmp\/.cache\/torch\/checkpoints\/\n!cp ..\/input\/resnet18\/resnet18.pth \/tmp\/.cache\/torch\/checkpoints\/resnet18-5c106cde.pth","9ecbf59b":"# net = UNet(n_channels=3, n_classes=category_num).to(device)\nnet = ResNetUNet(n_class=category_num).to(device)\n\noptimizer = optim.SGD(\n    net.parameters(),\n    lr=0.1,\n    momentum=0.9,\n    weight_decay=0.0005\n)\n\ncriterion = nn.CrossEntropyLoss()\n","f8b85534":"train_df.shape","4643e1a9":"\ncheckpoint = torch.load(Path('..\/input\/u-net-baseline-by-pytorch-steel\/model-exported'))\nnet.load_state_dict(checkpoint)","97f8070b":"print(\"Total length of train df {}\".format(len(train_df)))","21f02457":"# plt.plot(list(range(epoch_num)), train_loss, color='green')\n# plt.plot(list(range(epoch_num)), valid_loss, color='blue')","8cbe6079":"# torch.save(net.state_dict(), '.\/model-exported')","d10b9fb5":"sample_df = pd.read_csv(input_dir + \"sample_submission.csv\")\nsample_df[['ImageId', 'ClassId']] = sample_df['ImageId_ClassId'].str.split('_', expand=True)\nsample_df.head()","ba815168":"# import torch\n# import gc\n# for obj in gc.get_objects():\n#     try:\n#         if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n#             print(type(obj), obj.size())\n#     except:\n#         pass","20e7cf21":"len(sample_df)","cdb5fb0e":"sub_list = []\nnet.eval()\ntest_images = sample_df[\"ImageId\"].unique()\nfor img_name, img in tqdm(test_generator(test_images), total=len(test_images)):\n    X = torch.tensor(img, dtype=torch.float32).to(device)\n    mask_pred = net(X)\n    mask_pred = mask_pred.cpu().detach().numpy()\n    mask_prob = np.argmax(mask_pred, axis=1)\n    mask_prob = mask_prob.T.ravel(order='F')\n    class_dict = run_length(mask_prob)\n    if len(class_dict) == 0:\n        for i in range(4):\n            sub_list.append([img_name+ \"_\" + str(i+1), ''])\n    else:\n        for key, val in class_dict.items():\n            sub_list.append([img_name + \"_\" + str(key+1), \" \".join(map(str, val))])\n        for i in range(4):\n            if i not in class_dict.keys():\n                sub_list.append([img_name+ \"_\" + str(i+1), ''])\n                \n#print(\"Total len {0}\".format(len(sub_list)))\n#print(sub_list[:5])\n","02cbc96a":"# img_name = '5e581254c.jpg'\n# img = cv2.imread(train_img_dir + img_name)\n# # HWC -> CHW\n# img = img.transpose((2, 0, 1))\n# img = np.asarray([img], dtype=np.float32) \/ 255\n# X = torch.tensor(img, dtype=torch.float32).to(device)\n# mask_pred = net(X)\n# mask_pred = mask_pred.cpu().detach().numpy()\n# mask_prob = np.argmax(mask_pred, axis=1)\n# mask_prob = mask_prob.ravel()\n# mask_prob\n# mask_prob.resize(256, 1600)\n# plt.imshow(mask_prob)\n\n# d = run_length(mask_prob.ravel())\n# nmask = {}\n# nmask['EncodedPixels'] = []\n# nmask['ClassId'] = []\n# for k,v in d.items():\n#     nmask['ClassId'].append(str(k))\n#     nmask['EncodedPixels'].append(' '.join(map(str,v)))\n# for i in range(4):\n#     if str(i) not in nmask['ClassId']:\n#         nmask['ClassId'].append(str(i))\n#         nmask['EncodedPixels'].append(np.nan)\n# nmask = pd.DataFrame.from_dict(nmask)\n# nmask","a9af1a98":"submission_df = pd.DataFrame(sub_list, columns=['ImageId_ClassId', 'EncodedPixels'])","682a42a8":"submission_df.head()","6e069290":"submission_df.to_csv(\"submission.csv\", index=False)","977108a1":"end = time.time()\nhours, rem = divmod(end-start, 3600)\nminutes, seconds = divmod(rem, 60)\nprint(\"Execution Time  {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))","2d4ed424":"# Debug","dfa5c15d":"# Import modules","647f3215":"# Training","cfbf4ebd":"# Previous Model training\nModel training is in this kernel as rule specifies kernel timeout of 1 hr. But, it allows pretrainied model.\n","10e904df":"val_sta = 40000\nval_end = 50000\ntrain_loss = []\nvalid_loss = []\nfor epoch in range(epoch_num):\n    epoch_trn_loss = 0\n    train_len = 0\n    net.train()\n    for iteration, (X_trn, Y_trn) in enumerate(tqdm(train_generator(train_df.iloc[:val_sta, :], batch_size))):\n        X = torch.tensor(X_trn, dtype=torch.float32).to(device)\n        Y = torch.tensor(Y_trn, dtype=torch.long).to(device)\n        train_len += len(X)\n        \n#       #Y_flat = Y.view(-1)\n        mask_pred = net(X)\n#       #mask_prob = torch.softmax(mask_pred, dim=1)\n#       #mask_prob_flat = mask_prob.view(-1)\n        loss = criterion(mask_pred, Y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        epoch_trn_loss += loss.item()\n        \n        if iteration % 100 == 0:\n            print(\"train loss in {:0>2}epoch  \/{:>5}iter:    {:<10.8}\".format(epoch+1, iteration, epoch_trn_loss\/(iteration+1)))\n        \n    train_loss.append(epoch_trn_loss\/(iteration+1))\n    print(\"train {}epoch loss({}iteration):    {:10.8}\".format(epoch+1, iteration, train_loss[-1]))\n    \n    epoch_val_loss = 0\n    val_len = 0\n    net.eval()\n    for iteration, (X_val, Y_val) in enumerate(tqdm(train_generator(train_df.iloc[val_sta:val_end, :], batch_size))):\n        X = torch.tensor(X_val, dtype=torch.float32).to(device)\n        Y = torch.tensor(Y_val, dtype=torch.long).to(device)\n        val_len += len(X)\n        \n#       #Y_flat = Y.view(-1)\n        \n        mask_pred = net(X)\n#       #mask_prob = torch.softmax(mask_pred, dim=1)\n#       #mask_prob_flat = mask_prob.view(-1)\n        loss = criterion(mask_pred, Y)\n        epoch_val_loss += loss.item()\n        \n        if iteration % 100 == 0:\n            print(\"valid loss in {:0>2}epoch  \/{:>5}iter:    {:<10.8}\".format(epoch+1, iteration, epoch_val_loss\/(iteration+1)))\n        \n    valid_loss.append(epoch_val_loss\/(iteration+1))\n    print(\"valid {}epoch loss({}iteration):    {:10.8}\".format(epoch+1, iteration, valid_loss[-1]))","0a5fc333":"# Export File","dc31dcfd":"# Define Network","0b316547":"# This is basic U-Net submission notebook\n\nThis is based on https:\/\/www.kaggle.com\/go1dfish\/u-net-baseline-by-pytorch-in-fgvc6-resize\n\nThis competition doesnot allow internet access in submission. I have trained a U-net model and using its output to create a submission file.\n\n1. How to train U-net model? https:\/\/www.kaggle.com\/nikhilikhar\/u-net-baseline-by-pytorch-steel\n1. How to create necessary labels for training? https:\/\/www.kaggle.com\/nikhilikhar\/steel-create-labels\n1. How to convert RLE to Mask image to RLE required for training? https:\/\/www.kaggle.com\/nikhilikhar\/rle-to-mask-to-rle\n\n## Log\n* LB: 0.82135\n * https:\/\/www.kaggle.com\/nikhilikhar\/u-net-steel-submission?scriptVersionId=19147163 \n* LB: 0.85674\n * https:\/\/www.kaggle.com\/nikhilikhar\/pytorch-u-net-steel-1-submission?scriptVersionId=19286194\n*","472c378d":"# Define utils\nFor simplicity, It focus only category","cb30ced2":"Ignore output `IncompatibleKeys(missing_keys=[], unexpected_keys=[])`","63491c58":"# Unet","51391d1b":"# Test","6db56954":"# Make Submission File","d6f12790":"# ResNet + Unet"}}