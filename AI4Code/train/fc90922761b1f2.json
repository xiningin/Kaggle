{"cell_type":{"117c4245":"code","9fadfc14":"code","31576868":"code","4df6ecda":"code","de0b48c2":"code","3b13b3d0":"code","de428f17":"code","556dfc67":"code","154e058b":"code","21d5efcd":"code","ee4ffb85":"code","3b039420":"code","ea09bed9":"code","21de84f7":"code","3f3d4529":"code","6be595d4":"code","325727f6":"code","790134e0":"code","88a9187a":"code","53249df6":"code","f99bedeb":"code","6dadd6e9":"code","136eb7fd":"code","79681783":"code","5ca7c59c":"code","65de3ee0":"code","5475fa89":"code","063f8dcf":"code","3026728a":"code","2258e534":"code","98fdb015":"code","98b3242e":"code","4e1ac143":"code","e4c48b75":"code","c0a68d55":"code","c5940bba":"markdown","f34d6325":"markdown","9d28efdc":"markdown","ed50094c":"markdown","98dd2851":"markdown","1a28bd3b":"markdown","a84e82a6":"markdown","114bfc9e":"markdown","f688702e":"markdown","21803252":"markdown","3f77d546":"markdown","b87d72be":"markdown","67e0b02d":"markdown","5ff18734":"markdown","2767ecea":"markdown"},"source":{"117c4245":"import os\n\nimport numpy as np\nimport pandas as pd","9fadfc14":"df_train = pd.read_csv('..\/input\/tweet-sentiment-extraction\/train.csv')\ndisplay(len(df_train))\ndf_train.head()","31576868":"df_test = pd.read_csv('..\/input\/tweet-sentiment-extraction\/test.csv')\ndf_test.head()","4df6ecda":"# drop na\nprint(len(df_train))\ndf_train.dropna(axis = 0, how ='any',inplace=True)\nprint(len(df_train))","de0b48c2":"# Add tokes and counts.\ndf_train['text_tokes']   = df_train.text.str.split()\ndf_train['select_tokes'] = df_train.selected_text.str.split()\ndf_train['text_tokes_cnt'] = df_train.text_tokes.str.len()\ndf_train['select_tokes_cnt'] = df_train.select_tokes.str.len()\ndf_train.head(5)","3b13b3d0":"# remove text=2 and neutrals as = self.\ndf_train = df_train[~(df_train.text_tokes_cnt<=2)]\ndf_train = df_train[(df_train.sentiment!='neutral')]\ndisplay(len(df_train))\ndisplay(df_train.sentiment.value_counts())\ndf_train.sample(5)","de428f17":"# Hold out set. Ten percent of total train split evenly between sentiment.\n# num_rows_to_use = int((len(df_train) * .10)\/2) \n# df_valid_pos = df_train[df_train.sentiment=='positive'].sample(num_rows_to_use)\n# df_valid_neg = df_train[df_train.sentiment=='negative'].sample(num_rows_to_use)\n# df_valid = pd.concat([df_valid_pos, df_valid_neg])\n# display(len(df_valid))\n# display(df_valid.sentiment.value_counts())\n# df_valid.sample(5)","556dfc67":"# Drop validation set from training set.\n# display(f\"Train before={len(df_train)}\")\n# df_train.drop(df_valid.index, inplace=True, axis=0)\n# display(f\"Train after={len(df_train)}\") ","154e058b":"# Input & output the same.\n# Seem problematic to me.\ndf_sames = df_train[df_train.text_tokes_cnt==df_train.select_tokes_cnt]\ndisplay(len(df_sames))\ndisplay(df_sames.sentiment.value_counts())\npd.options.display.max_colwidth = 1000\ndf_sames.sample(5)","21d5efcd":"# Spacy model building related.\nimport spacy\nfrom tqdm import tqdm\nimport random\nfrom spacy.util import minibatch, compounding\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","ee4ffb85":"def save_model(output_dir, nlp, new_model_name):\n    ''' This Function Saves model to \n    given output directory'''\n    \n    output_dir = f'..\/working\/{output_dir}'\n    if output_dir is not None:        \n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        nlp.meta[\"name\"] = new_model_name\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)","3b039420":"def get_model_out_path(sentiment):\n    '''\n    Returns Model output path\n    '''\n    model_out_path = None\n    if sentiment == 'positive':\n        model_out_path = 'models\/model_pos'\n    elif sentiment == 'negative':\n        model_out_path = 'models\/model_neg'\n    return model_out_path","ea09bed9":"def get_training_data(sentiment, df_input):\n    '''\n    Returns Training data in the format needed to train spacy NER\n    ID start and end point of the 'selected' text in the text \n    and used as your string entity info for spacy.\n    '''\n    SENTIMENT = ['negative', 'positive']\n    if sentiment not in SENTIMENT:\n        raise ValueError(f\"{sentiment} not in {SENTIMENT})\")\n    train_data = []\n    for index, row in df_input.iterrows():\n        if row.sentiment == sentiment:\n            selected_text = row.selected_text\n            text = row.text\n            start = text.find(selected_text)\n            end = start + len(selected_text)\n            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n    return train_data","21de84f7":"# pass model = nlp if you want to train on top of existing model \n\ndef train(train_data, output_dir, n_iter=20, model=None):\n    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n    \"\"\n    # Uses given model or instantiates a blank model.\n    if model is not None:\n        nlp = spacy.load(output_dir)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n    \n    # create the built-in pipeline components and add them to the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner, last=True)\n    # otherwise, get it so we can add labels\n    else:\n        ner = nlp.get_pipe(\"ner\")\n    \n    # add labels\n    for _, annotations in train_data:\n        for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n\n    # get names of other pipes to disable them during training\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        # sizes = compounding(1.0, 4.0, 1.001)\n        # batch up the examples using spaCy's minibatch\n        if model is None:\n            nlp.begin_training()\n        else:\n            nlp.resume_training()\n\n        for itn in tqdm(range(n_iter)):\n            random.shuffle(train_data)\n            batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n            losses = {}\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts,  # batch of texts\n                            annotations,  # batch of annotations\n                            drop=0.5,   # dropout - make it harder to memorise data\n                            losses=losses, \n                            )\n            print(\"Losses\", losses)\n    save_model(output_dir, nlp, 'st_ner')","3f3d4529":"def train(train_data, output_dir, n_iter=20, model=None):\n    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n    \"\"\n    if model is not None:\n        nlp = spacy.load(output_dir)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n    \n    # create the built-in pipeline components and add them to the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner, last=True)\n    # otherwise, get it so we can add labels\n    else:\n        ner = nlp.get_pipe(\"ner\")\n    \n    # add labels\n    for _, annotations in train_data:\n        for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n\n    # get names of other pipes to disable them during training\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        # sizes = compounding(1.0, 4.0, 1.001)\n        # batch up the examples using spaCy's minibatch\n        if model is None:\n            nlp.begin_training()\n        else:\n            nlp.resume_training()\n\n\n        for itn in tqdm(range(n_iter)):\n            random.shuffle(train_data)\n            batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n            losses = {}\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts,  # batch of texts\n                            annotations,  # batch of annotations\n                            drop=0.5,   # dropout - make it harder to memorise data\n                            losses=losses, \n                            )\n            print(\"Losses\", losses)\n    save_model(output_dir, nlp, 'st_ner')","6be595d4":"def run_train(n_iter=20):\n    \"\"\" Convenience so can comment out if not don't need to regenerat models. \"\"\"\n    for sentiment in ['positive', 'negative']:\n        model_path = get_model_out_path(sentiment)\n        train_data = get_training_data(sentiment, df_train)\n        train(train_data, model_path, n_iter=n_iter)","325727f6":"%%time\nrun_train(n_iter=5)","790134e0":"MODELS_BASE_PATH = 'models\/'\ndef predict_entities(text, model):\n    doc = model(text)\n    ent_array = []\n    for ent in doc.ents:\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        new_int = [start, end, ent.label_]\n        if new_int not in ent_array:\n            ent_array.append([start, end, ent.label_])\n    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n    return selected_text\n\ndef pred_set(df_set):\n    \"\"\" Run NER models on data. \"\"\"\n    df_pred = df_set.copy()\n    \n    selected_texts = []\n\n    print(\"Loading Models  from \", MODELS_BASE_PATH)\n    model_pos = spacy.load(MODELS_BASE_PATH + 'model_pos')\n    model_neg = spacy.load(MODELS_BASE_PATH + 'model_neg')\n\n    for index, row in df_pred.iterrows():\n        text = row.text\n        output_str = \"\"\n        if row.sentiment == 'neutral' or len(text.split()) <= 2:\n            selected_texts.append(text)\n        elif row.sentiment == 'positive':\n            selected_texts.append(predict_entities(text, model_pos))\n        else:\n            selected_texts.append(predict_entities(text, model_neg))\n\n    df_pred['predicted_text'] = selected_texts\n\n    return df_pred","88a9187a":"model_pos = spacy.load(MODELS_BASE_PATH + 'model_pos')","53249df6":"predict_entities(\"I love this model, it's great. I can't wait to lean more about training spacy models\", model_pos)","f99bedeb":"# Metric.\ndef jaccard(compare_strings): \n    str1, str2 = compare_strings\n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))","6dadd6e9":"# Predict on validation set - add to df.\ndf_pred = pred_set(df_train)","136eb7fd":"# Reminder that neutral are missing from this.\ndf_pred.sentiment.value_counts()","79681783":"# Calculate jaccard.\n# Do it here then move to above func - probably.\ndf_pred['jaccard'] = df_pred[['selected_text','predicted_text']].values.tolist()\ndf_pred['jaccard'] = df_pred.jaccard.apply(jaccard)","5ca7c59c":"# Not much difference in accuracy per sentiment type\nprint(df_pred.jaccard.mean())\nprint(df_pred[df_pred.sentiment=='positive'].jaccard.mean())\nprint(df_pred[df_pred.sentiment=='negative'].jaccard.mean())","65de3ee0":"display(df_pred[['text','selected_text', 'sentiment', 'predicted_text', 'jaccard']].sample(20))","5475fa89":"# Run NER on full test set.\nselected_texts = []\nMODELS_BASE_PATH = 'models\/'\n\nif MODELS_BASE_PATH is not None:\n    print(\"Loading Models  from \", MODELS_BASE_PATH)\n    model_pos = spacy.load(MODELS_BASE_PATH + 'model_pos')\n    model_neg = spacy.load(MODELS_BASE_PATH + 'model_neg')\n        \n    for index, row in df_test.iterrows():\n        text = row.text\n        output_str = \"\"\n        if row.sentiment == 'neutral' or len(text.split()) <= 2:\n            selected_texts.append(text)\n        elif row.sentiment == 'positive':\n            selected_texts.append(predict_entities(text, model_pos))\n        else:\n            selected_texts.append(predict_entities(text, model_neg))\n        \ndf_test['selected_text'] = selected_texts","063f8dcf":"print(len(df_test))\nprint(df_submission.describe())","3026728a":"df_submission.info()","2258e534":"df_submission = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/sample_submission.csv')\n\ndf_submission = df_test[['textID', 'selected_text']]\nprint(len(df_submission))\ndisplay(df_submission.head(10))","98fdb015":"os.chdir(\"\/kaggle\/working\/\")","98b3242e":"df_submission.to_csv(\"submission.csv\", index=False)","4e1ac143":"print(len(df_submission))\nprint(df_submission.describe())\nprint(df_submission.info())\ndf_submission.head(10)","e4c48b75":"df_submission","c0a68d55":"!ls","c5940bba":"# New EDA\n* Non-neutral sent where input and output are same lengths\n* Seem problematic.\n* Follow up on later","f34d6325":"## model train - helpers","9d28efdc":"# Notes\n* Pinched from [sentiment Extaction-Analysis,EDA and Model](https:\/\/www.kaggle.com\/dplutcho\/twitter-sentiment-extaction-analysis-eda-and-model\/edit)","ed50094c":"# Prep train set","98dd2851":"## Traning set testing.\n* need to use jackard as custom metric during trianing so can skip this","1a28bd3b":"# Prep","a84e82a6":"# Leftovers - Ignore this bit","114bfc9e":"# Start on the task","f688702e":"# Submission prep\n* You must have exact same number of rows as sample submission\n* Internet must be turned off.\n* After saving and running you will need to go to the output notebook and tell it which file to submit.","21803252":"## Build NER models","3f77d546":"# Prep validation set - DON'T DO THIS\n* DON'T DO THIS - Just rely on model trianing metric.\n* Extract 10% of pos and neg into df_valid and remove these from df_train.\n* \"A validation dataset is a sample of data held back from training your model that is used to give an estimate of model skill while tuning model\u2019s hyperparameters.\" - https:\/\/machinelearningmastery.com\/difference-test-validation-datasets\/","b87d72be":"## Testing","67e0b02d":"## Imports","5ff18734":"# One-off testing","2767ecea":"# Tweet sentiment extraction - SpaCy\n2020-10-24"}}