{"cell_type":{"56b3cf60":"code","1dc36d54":"code","9965876c":"code","caee5e17":"code","e7508e98":"code","c391970d":"code","59cba26d":"code","9f87ae3f":"code","c24e3ea8":"code","3b119c2a":"code","2f5aee4d":"code","ecc24db6":"code","fb3fa80a":"code","814a5f39":"code","c06616d9":"code","3437a0e4":"code","b29cab8e":"code","4fe4025c":"code","80c25fd6":"code","94e67aa5":"code","81dfb1b7":"code","196b97e1":"code","f344f3cf":"markdown","5ee287d1":"markdown","43a55f6c":"markdown","33866d0f":"markdown","7d0fd2df":"markdown","8c9dc9d4":"markdown","53f33bee":"markdown","91eaca74":"markdown","93d135a2":"markdown","3d21f2d9":"markdown","09152f96":"markdown","5c3e36e2":"markdown"},"source":{"56b3cf60":"import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.sparse import hstack\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport eli5","1dc36d54":"train = pd.read_csv('..\/input\/train.csv', index_col='id').fillna(' ')\nvalid = pd.read_csv('..\/input\/valid.csv', index_col='id').fillna(' ')\ntest = pd.read_csv('..\/input\/test.csv', index_col='id').fillna(' ')","9965876c":"train.head()","caee5e17":"train_val = pd.concat([train, valid])","e7508e98":"sns.countplot(train_val['label']);\nplt.title('Train+val: Target distribution');","c391970d":"plt.subplots(1, 2)\nplt.subplot(1, 2, 1)\ntrain_val['text'].apply(lambda x: len(x.split())).plot(kind='hist');\nplt.yscale('log');\nplt.title('Text length in words');\nplt.subplot(1, 2, 2)\ntrain_val['title'].apply(lambda x: len(x.split())).plot(kind='hist');\nplt.yscale('log');\nplt.title('Title length in words');","59cba26d":"plt.subplots(1, 2)\nplt.subplot(1, 2, 1)\ntest['text'].apply(lambda x: len(x.split())).plot(kind='hist');\nplt.yscale('log');\nplt.title('Text length in words');\nplt.subplot(1, 2, 2)\ntest['title'].apply(lambda x: len(x.split())).plot(kind='hist');\nplt.yscale('log');\nplt.title('Title length in words');","9f87ae3f":"from wordcloud import WordCloud, STOPWORDS\n\n# Thanks : https:\/\/www.kaggle.com\/aashita\/word-clouds-of-various-shapes ##\ndef plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), \n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color='black',\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=800, \n                    height=400,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \n    \nplot_wordcloud(train_val[\"title\"], title=\"Word Cloud of Titles\")","c24e3ea8":"title_transformer = TfidfVectorizer(stop_words='english', ngram_range=(1, 3), lowercase=True, max_features=50000)\ntext_transformer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), lowercase=True, max_features=150000)","3b119c2a":"%%time\nX_train_text = text_transformer.fit_transform(train_val['text'])\nX_test_text = text_transformer.transform(test['text'])","2f5aee4d":"%%time\nX_train_title = title_transformer.fit_transform(train_val['title'])\nX_test_title = title_transformer.transform(test['title'])","ecc24db6":"X_train = hstack([X_train_text, X_train_title])\nX_test = hstack([X_test_text, X_test_title])","fb3fa80a":"X_train.shape, X_test.shape","814a5f39":"logit = LogisticRegression(C=5e1, solver='lbfgs', multi_class='multinomial',\n                          random_state=17, n_jobs=4)","c06616d9":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)","3437a0e4":"%%time\ncv_results = cross_val_score(logit, X_train, train_val['label'], cv=skf, scoring='f1_micro')","b29cab8e":"cv_results, cv_results.mean()","4fe4025c":"%%time\nlogit.fit(X_train, train_val['label'])","80c25fd6":"eli5.show_weights(estimator=logit, \n                  feature_names= list(text_transformer.get_feature_names()) + \n                                 list(title_transformer.get_feature_names()),\n                 top=(50, 5))","94e67aa5":"test_preds = logit.predict(X_test)","81dfb1b7":"pd.DataFrame(test_preds, columns=['label']).head()","196b97e1":"pd.DataFrame(test_preds, columns=['label']).to_csv('logit_tf_idf_starter_submission.csv',\n                                                  index_label='id')","f344f3cf":"**Preparing submission.**","5ee287d1":"We can see that test titles are a bit shorter.","43a55f6c":"As for model, let's simply pick logistic regression.****","33866d0f":"**Cross-validation**","7d0fd2df":"**Trying to interpret model weights with ELI5 - look reasonable.**","8c9dc9d4":"As an entertainment, we can build a wordcloud for news titles. However, no useful insights from such a picture.","53f33bee":"We'll be validating with train + validation files.","91eaca74":"It's nice to see that cross-validation is more or less stable across folds. Let's train the model on train + val.","93d135a2":"After concatenation, we get 200k sparse features to represent news titles and texts.","3d21f2d9":"**What you can try next**\n\n - tune hyperparams, those of `TfIdfVectorizers` as well\n - add Word2Vec\/GloVE\/Fasttext embeddings, at least for titles\n - switch to ULMFiT and other heavy stuff\n ","09152f96":"We'll be using 2 Tf-Idf vectorizers - for titles and texts separetely.","5c3e36e2":"Copied from [this Kernel](https:\/\/www.kaggle.com\/kashnitsky\/eda-logit-tf-idf-starter).\n\nTf-Idf + Logistic regression is a very nice baseline for many tasks. Here we'll briefly explore a dataset with news classified as \"news\" (normal), \"clickbait\", and others. Then we'll build a simple baseline based on Tf-Idf representations of news titles and texts. Further we'll compare heavier approaches (like ULMFiT) with this baseline."}}