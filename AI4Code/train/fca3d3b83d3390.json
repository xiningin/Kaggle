{"cell_type":{"83fb63b7":"code","45911cb2":"code","b86472bc":"code","9f6340f9":"code","c25f70e0":"code","59c6fbb3":"code","0646cc3a":"code","ecf1b491":"code","a4a0013e":"code","3ced6c82":"code","1c50d088":"code","024931b7":"code","7581ca0d":"code","3aff16ea":"markdown"},"source":{"83fb63b7":"import torch\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader","45911cb2":"batch_size = 128\nmy_transforms = transforms.Compose(\n                [\n                    transforms.Resize(224),\n                    transforms.ToTensor()]\n)\n\ntrain_dataset = datasets.FashionMNIST(download=True,root=\"..\/data\", train=True, transform=my_transforms)\ntest_dataset = datasets.FashionMNIST(download=True, root=\"..\/data\", train=False, transform=my_transforms)\n\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)","b86472bc":"import os\nimport torchvision\n\n# Suppose you are trying to load pre-trained resnet model in directory- models\\resnet\n\nos.environ['TORCH_HOME'] = '..\/models' #setting the environment variable\n","9f6340f9":"vgg = torchvision.models.vgg16(pretrained=True) ","c25f70e0":"vgg.features[0] = nn.Conv2d(1,64,kernel_size=(3,3), stride=(1,1), padding=(1,1))\nvgg.classifier.out_features = 10","59c6fbb3":"for param in vgg.features.parameters():\n    param.requires_grad = False","0646cc3a":"def accuracy(y_hat,y):\n    return (y_hat.argmax(1)==y).sum()","ecf1b491":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","a4a0013e":"def full_accuracy(net, data_iter):\n    net.eval()\n#     device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'\n    net = net.to(device)\n    \n    total_acc = 0\n    total_num = 0\n    with torch.no_grad():\n        for X, y in data_iter:\n            X = X.to(device)\n            y = y.to(device)\n\n            y_hat = net(X)\n\n            total_acc += accuracy(y_hat, y)\n            total_num += y.numel()\n    \n    return total_acc\/total_num","3ced6c82":"def train_net(net):\n    \n    train_loss = []\n    train_acc = []\n    test_acc = []\n\n    net= net.to(device)\n    for epoch in range(num_epochs):\n\n        acc_value = 0\n        total_number = 0\n        total_loss= 0\n        for i, data in enumerate(train_dataloader):\n            inputs, labels = data\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            optimizer.zero_grad()\n\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n\n            total_loss += loss.item()\n            acc_value += accuracy(outputs, labels)\n            total_number += labels.numel()\n\n        with torch.no_grad():\n\n            print(f\"\\tEpoch {epoch} : Statistics: \")\n            print(f'\\tcurrent train loss : {total_loss} \/ {total_number} : {float(total_loss\/total_number)}')\n            print(f'\\tcurrent train acc : {acc_value}\/{total_number} : {float(acc_value\/total_number)}')\n            print(f'\\tcurrent test acc : {float(full_accuracy(net, test_dataloader))}')\n\n\n            train_loss.append(float(total_loss\/total_number))\n            test_acc.append(float(full_accuracy(net, test_dataloader)))\n            train_acc.append(float(acc_value\/total_number))\n    \n    return train_loss, test_acc, train_acc","1c50d088":"optimizer = torch.optim.SGD(vgg.parameters(), lr=0.001, momentum=0.9)\ncriterion = nn.CrossEntropyLoss()","024931b7":"num_epochs=6\ntrain_loss, test_acc, train_acc = train_net(vgg)","7581ca0d":"print(\"finished\")\n\nimport matplotlib.pyplot as plt\nnum_epochs = num_epochs\n# plt.plot(range(num_epochs), train_loss, label='train loss')\nplt.plot(range(num_epochs), train_acc, label = 'train acc')\nplt.plot(range(num_epochs), test_acc, label = 'test acc')\nplt.grid(True)\nplt.legend()\nplt.show()","3aff16ea":"### Exercises\n\n1. When printing out the dimensions of the layers we only saw 8 results rather than 11. Where\ndid the remaining 3 layer information go?\n\n* in maxpool\n\n2. Compared with AlexNet, VGG is much slower in terms of computation, and it also needs\nmore GPU memory. Analyze the reasons for this.\n\n* it has more conv layers\n\n3. Try changing the height and width of the images in Fashion-MNIST from 224 to 96. What\ninfluence does this have on the experiments?\n\n* it willrun faster\n\n4. Refer to Table 1 in the VGG paper (Simonyan & Zisserman, 2014) to construct other common\nmodels, such as VGG-16 or VGG-19.\n\n* it can be done but my GPU says hi"}}