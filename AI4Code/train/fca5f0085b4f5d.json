{"cell_type":{"181cc57c":"code","64fd3d8a":"code","4296f624":"code","951a8af9":"code","0f8a7f80":"code","90346727":"markdown","76fbca9a":"markdown"},"source":{"181cc57c":"import numpy as np\nimport os\nimport sys\nimport tensorflow as tf\nimport time\n\n# \u5bfc\u5165\u7528\u4e8e\u63d0\u4ea4\u9884\u6d4b\u7ed3\u679c\u7684\u5e93\nINPUT_DIR = '..\/input\/tensorflow-great-barrier-reef\/'\nsys.path.insert(0, INPUT_DIR)\nimport greatbarrierreef","64fd3d8a":"MODEL_DIR = '..\/input\/cots-detection-w-tensorflow-object-detection-api\/cots_efficientdet_d0'\nstart_time = time.time()\ntf.keras.backend.clear_session()\ndetect_fn_tf_odt = tf.saved_model.load(os.path.join(os.path.join(MODEL_DIR, 'output'), 'saved_model'))\nend_time = time.time()\nelapsed_time = end_time - start_time\nprint('Elapsed time: ' + str(elapsed_time) + 's')","4296f624":"def load_image_into_numpy_array(path):\n    \"\"\"Load an image from file into a numpy array.\n\n    Puts image into numpy array to feed into tensorflow graph.\n    Note that by convention we put it into a numpy array with shape\n    (height, width, channels), where channels=3 for RGB.\n\n    Args:\n    path: a file path (this can be local or on colossus)\n\n    Returns:\n    uint8 numpy array with shape (img_height, img_width, 3)\n    \"\"\"\n    img_data = tf.io.gfile.GFile(path, 'rb').read()\n    image = Image.open(io.BytesIO(img_data))\n    (im_width, im_height) = image.size\n    \n    return np.array(image.getdata()).reshape(\n      (im_height, im_width, 3)).astype(np.uint8)\n\ndef detect(image_np):\n    \"\"\"Detect COTS from a given numpy image.\"\"\"\n\n    input_tensor = np.expand_dims(image_np, 0)\n    start_time = time.time()\n    detections = detect_fn_tf_odt(input_tensor)\n    return detections","951a8af9":"env = greatbarrierreef.make_env()   #\u521d\u59cb\u5316\u73af\u5883\niter_test = env.iter_test()    #\u4f7f\u7528\u8fed\u4ee3\u5668\u904d\u5386\u6d4b\u8bd5\u96c6\u548c\u6837\u672c\u63d0\u4ea4","0f8a7f80":"DETECTION_THRESHOLD = 0.25\n\nsubmission_dict = {\n    'id': [],\n    'prediction_string': [],\n}\n\nfor (image_np, sample_prediction_df) in iter_test:\n    height, width, _ = image_np.shape\n    \n    #\u4f7f\u7528TensorFlow\u6a21\u578b\u8fd0\u884c\u5bf9\u8c61\u68c0\u6d4b\n    detections = detect(image_np)\n    \n    #\u89e3\u6790\u68c0\u6d4b\u7ed3\u679c\u5e76\u751f\u6210\u9884\u6d4b\u5b57\u7b26\u4e32\n    num_detections = detections['num_detections'][0].numpy().astype(np.int32)\n    predictions = []\n    for index in range(num_detections):\n        score = detections['detection_scores'][0][index].numpy()\n        if score < DETECTION_THRESHOLD:\n            continue\n\n        bbox = detections['detection_boxes'][0][index].numpy()\n        y_min = int(bbox[0] * height)\n        x_min = int(bbox[1] * width)\n        y_max = int(bbox[2] * height)\n        x_max = int(bbox[3] * width)\n        \n        bbox_width = x_max - x_min\n        bbox_height = y_max - y_min\n        \n        predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n    \n    # \u751f\u6210\u63d0\u4ea4\u6570\u636e\n    prediction_str = ' '.join(predictions)\n    sample_prediction_df['annotations'] = prediction_str\n    env.predict(sample_prediction_df)\n\n    print('Prediction:', prediction_str)","90346727":"\u8fd0\u884c\u63a8\u65ad\u5e76\u521b\u5efa\u63d0\u4ea4\u6570\u636e","76fbca9a":"\u5c06TensorFlow COTS\u68c0\u6d4b\u6a21\u578b\u52a0\u8f7d\u5230\u5185\u5b58\u4e2d\uff0c\u5e76\u5b9a\u4e49\u4e00\u4e9butil\u51fd\u6570\u6765\u8fd0\u884c\u63a8\u7406\u3002"}}