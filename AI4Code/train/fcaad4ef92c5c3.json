{"cell_type":{"988e3c3f":"code","76115273":"code","521c2caf":"code","8f2f5d17":"code","1533fb45":"code","e3a247d4":"code","2f3b611a":"code","62d218ce":"code","a1631e31":"code","3d457613":"code","f68cae45":"code","899dca98":"code","f24bf959":"code","31b2f64b":"code","30dd77ec":"code","d033541b":"code","fdc05ed9":"code","5d410786":"code","276b63ad":"code","fdfd293e":"code","29441a9a":"code","2b08f77e":"code","808221bf":"code","57e4e00a":"markdown","5034a61e":"markdown","a1260057":"markdown","e87e2499":"markdown","4d2aac25":"markdown","a4bf4280":"markdown","1bd5bc60":"markdown","2644830f":"markdown","03888ae8":"markdown","3e1d9cbe":"markdown","042f79a7":"markdown","a4135ec7":"markdown"},"source":{"988e3c3f":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\nsns.set_style(\"white\")\n\n\nplt.style.use(\"seaborn\")","76115273":"%%time\nTRAIN_PATH = \"..\/input\/riiid-test-answer-prediction\/train.csv\"\ntrain = pd.read_csv(TRAIN_PATH,low_memory=False, nrows=500000, \n                       dtype={'row_id': 'int64', 'timestamp': 'int64', 'user_id': 'int32', 'content_id': 'int16', 'content_type_id': 'int8',\n                              'task_container_id': 'int16', 'user_answer': 'int8', 'answered_correctly': 'int8', 'prior_question_elapsed_time': 'float32', \n                             'prior_question_had_explanation': 'boolean',\n                             })","521c2caf":"train = train.query('answered_correctly != -1').reset_index(drop=True) #Dropping null values","8f2f5d17":"print(f'Train Dataset Dimension: {train.shape}')","1533fb45":"train.info()","e3a247d4":"train.describe()","2f3b611a":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()\/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))","62d218ce":"%%time\nmissing_data(train)","a1631e31":"plt.figure(figsize=(15,6))\nsns.set_style(\"white\")\nsns.kdeplot(train.groupby(by='user_id').count()['row_id'], shade=True, gridsize=30,legend=False)\nplt.title(\"User_id distribution\", fontsize = 20)\nplt.xlabel('User_id counts', fontsize=12)\nplt.ylabel('Probability', fontsize=12);","3d457613":"fig, ax = plt.subplots(1,3,figsize = (19,7))\nsns.set_style(\"white\")\nsns.kdeplot(train[train['answered_correctly'] == 1].groupby(\"user_id\").count()['row_id'], shade=True, \n            gridsize=30,legend=True, ax = ax[0], label = \"Correct Answer\", color = 'g')\nplt.ylabel('Probability', fontsize=12);\nsns.kdeplot(train[train['answered_correctly'] == 0].groupby(\"user_id\").count()['row_id'], shade=True, \n            gridsize=30,legend=True,ax = ax[1], label = \"Wronng Answer\", color = 'r' )\nplt.ylabel('Probability', fontsize=12);\n# plt.show()\n\nsns.set_style(\"white\")\nsns.countplot(train[\"answered_correctly\"],palette='PRGn', ax = ax[2])\nplt.xlabel(\"Answered Correctly\")\nplt.ylabel(\"Counts\")\nplt.title(\"Target Counts\", fontsize = 15)\nplt.show()","f68cae45":"sns.set_style(\"white\")\nsns.kdeplot(train[\"prior_question_elapsed_time\"],shade=True, gridsize=30,legend=False)\nplt.title(\"prior_question_elapsed_time distribution\", fontsize = 20)\n# plt.xlabel('User_id counts', fontsize=12)\nplt.ylabel('Probability', fontsize=12);","899dca98":"sns.set_style(\"white\")\nsns.countplot(train[\"user_answer\"], palette=\"Set3\")\nplt.xlabel(\"User Answers\")\nplt.ylabel(\"Counts\")\nplt.title(\"User Answer Counts\", fontsize = 15)\nplt.show()","f24bf959":"sns.set_style(\"white\")\nsns.countplot(train[\"prior_question_had_explanation\"], palette=\"Set3\")\nplt.xlabel(\"User Answers\",fontsize=12)\nplt.ylabel(\"Counts\",fontsize=12)\nplt.title(\"User Answer Counts\", fontsize = 15)\nplt.show()","31b2f64b":"sns.countplot(train['answered_correctly'], hue=train['prior_question_had_explanation'],palette='PRGn')\nplt.xlabel(\"Answered Correctly\")\nplt.ylabel(\"Counts\")\nplt.xlabel('Answered_correctly', fontsize = 13)","30dd77ec":"sns.boxenplot(train[\"answered_correctly\"],train[\"prior_question_elapsed_time\"], palette='PRGn')\nplt.xlabel(\"Answered Correctly\",fontsize = 13)\nplt.xlabel('Answered_correctly', fontsize = 13)","d033541b":"sns.violinplot(train[\"user_answer\"],train[\"prior_question_elapsed_time\"],palette='PRGn')","fdc05ed9":"train[\"prior_question_had_explanation\"] = train[\"prior_question_had_explanation\"].map({False : 0,\n                                                                                       True: 1})","5d410786":"from xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import cross_validate,GridSearchCV, train_test_split","276b63ad":"X = train.drop(['answered_correctly', 'user_answer'], axis=1)\nY = train['answered_correctly']\n\ntrain_x, test_x, train_y, test_y = train_test_split(X,Y, test_size = 0.3,random_state = 42)","fdfd293e":"LGBM = LGBMClassifier( class_weight=\"balanced\", max_depth=-1,metric = 'auc',tree_learner = 'serial',\n                     min_data_in_leaf = 80,num_leaves = 50, learning_rate=0.0999,feature_fraction = 0.05,\n                     bagging_fraction = 0.4, n_estimators = 190)\nLGBM.fit(train_x.values,train_y.values)\npred_train = LGBM.predict_proba(train_x)[:,1]\nprint(\"Train ROC_AUC Score: \", roc_auc_score(train_y,pred_train))\npred_test = LGBM.predict_proba(test_x)[:,1]\nprint(\"Train ROC_AUC Score: \", roc_auc_score(test_y,pred_test))","29441a9a":"#Training lgbm on whole data\n\nLGBM = LGBMClassifier( class_weight=\"balanced\", max_depth=-1,metric = 'auc',tree_learner = 'serial',\n                     min_data_in_leaf = 80,num_leaves = 50, learning_rate=0.0999,feature_fraction = 0.05,\n                     bagging_fraction = 0.4, n_estimators = 190)\nLGBM.fit(X,Y)\npred_train = LGBM.predict_proba(X)[:,1]\nprint(\"Train ROC_AUC Score: \", roc_auc_score(Y,pred_train))","2b08f77e":"import riiideducation\nenv = riiideducation.make_env()\niter_test = env.iter_test()\n\n\nfor (test_df, sample_prediction_df) in iter_test:\n    y_preds = []\n    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].astype(float)\n    X_test = test_df.drop(['prior_group_answers_correct', 'prior_group_responses'], axis=1)\n\n#     for model in models:\n#         y_pred = LGBM.predict(X_test)\n#         y_preds.append(y_pred)\n\n#     y_preds = sum(y_preds) \/ len(y_preds)\n    test_df['answered_correctly'] = LGBM.predict(X_test)\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","808221bf":"XGB = XGBClassifier(max_depth = 5,n_estimators = 200)\nXGB.fit(train_x.values,train_y.values)\npred_train = XGB.predict_proba(train_x)[:,1]\nprint(\"Train ROC_AUC Score: \", roc_auc_score(train_y,pred_train))\npred_test = XGB.predict_proba(test_x)[:,1]\nprint(\"Train ROC_AUC Score: \", roc_auc_score(test_y,pred_test))","57e4e00a":"In this challenge, our objective is to create algorithms for \"Knowledge Tracing,\" the modeling of student knowledge over time (i.e) predict whether students are able to answer their next questions correctly.\n<hr>\nThis is a time-series code competition, you will receive test set data and make predictions with Kaggle's time-series API. Please be sure to review the Time-series API Details section closely. (Which is awesome!! :D)\n\nCheck -> https:\/\/www.kaggle.com\/sohier\/competition-api-detailed-introduction","5034a61e":"### Loading Data","a1260057":"# Updating...","e87e2499":"![image.png](attachment:image.png)","4d2aac25":"# Thanks for reading!!  Lot more to come :D","a4bf4280":"### Missing Data","1bd5bc60":"<h1><center><font size=\"6\">Riid! Basic Exploration<\/font><\/center><\/h1>\n\n<h2><center><font size=\"4\">Dataset used: Riid! Answer Correctness Prediction<\/font><\/center><\/h2>","2644830f":"# <a id='2'>Basic Information And Preprocessing<\/a>","03888ae8":"### Train contains:\n\n<b>row_id<\/b>: (int64) ID code for the row.\n\n<b>timestamp<\/b>: (int64) the time between this user interaction and the first event from that user.\n\n<b>user_id<\/b>: (int32) ID code for the user.\n\n<b>content_id<\/b>: (int16) ID code for the user interaction\n\n<b>content_type_id<\/b>: (int8) 0 if the event was a question being posed to the user, 1 if the event was the user watching a lecture.\n\n<b>task_container_id<\/b>: (int16) Id code for the batch of questions or lectures. For example, a user might see three questions in a row before seeing the explanations for any of them. Those three would all share a task_container_id. Monotonically increasing for each user.\n\n<b>user_answer<\/b>: (int8) the user's answer to the question, if any. Read -1 as null, for lectures.\n\n<b>answered_correctly<\/b>: (int8) if the user responded correctly. Read -1 as null, for lectures.\n\n<b>prior_question_elapsed_time<\/b>: (float32) How long it took a user to answer their previous question bundle, ignoring any lectures in between. The value is shared across a single question bundle, and is null for a user's first question bundle or lecture. Note that the time is the total time a user took to solve all the questions in the previous bundle.\n\n<b>prior_question_had_explanation<\/b>: (bool) Whether or not the user saw an explanation and the correct response(s) after answering the previous question bundle, ignoring any lectures in between. The value is shared across a single question bundle, and is null for a user's first question bundle or lecture. Typically the first several questions a user sees were part of an onboarding diagnostic test where they did not get any feedback.","3e1d9cbe":"# <a id='1'>Introduction<\/a>  ","042f79a7":"# <a id='3'>Benchmark Modeling<\/a>","a4135ec7":"For baseline let the LGBM\/XGBoost model can handle the missing values."}}