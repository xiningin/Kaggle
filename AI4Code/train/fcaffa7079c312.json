{"cell_type":{"6f15de4d":"code","3f310f40":"code","25d9d2bf":"code","68c93244":"code","d264dd4d":"code","4bbad908":"code","057786f3":"code","14bde3af":"code","df5e6673":"code","74d8477a":"code","28dcc349":"code","f6c65530":"code","fb4459bc":"code","b1d362be":"markdown","df24eba0":"markdown","916c1992":"markdown","9326c530":"markdown","11130a7e":"markdown","c0b7cf9f":"markdown"},"source":{"6f15de4d":"import os\nimport ast\nimport pandas as pd\nimport numpy as np\nimport wandb\nfrom PIL import Image","3f310f40":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wb_api\")\nwandb.login(key=secret_value_0)","25d9d2bf":"train_csv = pd.read_csv(\"..\/input\/tensorflow-great-barrier-reef\/train.csv\")\ntest_csv = pd.read_csv(\"..\/input\/tensorflow-great-barrier-reef\/test.csv\")\ntrain_csv.head(20)","68c93244":"run = wandb.init(project=\"visualization4\", name=\"coral-reef\")","d264dd4d":"# Checking the number of frames in each video\/video_id\ntrain_group = train_csv.groupby('video_id').count()['image_id']\ntrain_group","4bbad908":"data = []\nfor i in train_group.keys():\n    data.append([i, train_group[i]])\n    \ndata","057786f3":"table = wandb.Table(data=data, columns = [\"video_id\", \"No of Frames\"])\nwandb.log({\"my_bar_chart_id\" : wandb.plot.bar(table, \"video_id\",\n                               \"No of Frames\", title=\"Custom Bar Chart\")})","14bde3af":"# this is the order in which my classes will be displayed\ndisplay_ids = {\"coral\" : 1}\n# this is a revese map of the integer class id to the string class label\nclass_id_to_label = { int(v) : k for k, v in display_ids.items()}","df5e6673":"class_id_to_label","74d8477a":"def bounding_boxes(filename, v_boxes):\n    '''\n    inputs: \n        filename: path to input image\n        v_boxes: list of bounding boxes(dict) in format (x, y, width height)\n    outputs:\n        box_image: wandb image\n    '''\n    all_boxes = []\n    image = Image.open(filename)\n    for b_i, box in enumerate(v_boxes):\n        # get coordinates and labels\n        box_data = {\"position\" : {\n          \"minX\" : box['x'], # x1\n          \"maxX\" : box['x'] + box['width'], #x2\n          \"minY\" : box['y'], # y1\n          \"maxY\" : box['y'] + box['height']}, #y2\n          \"class_id\" : 1, #Defining the label as 1, and rest of the background is 0.\n          # optionally caption each box with its class and score\n          \"box_caption\" : \"%s\" % (\"coral\"),\n          \"domain\" : \"pixel\",\n          \"scores\" : { \"score\" : 1}}\n        all_boxes.append(box_data) #List of all boxes on a single image in a list\n\n    # log to wandb: raw image, predictions, and dictionary of class labels for each class id\n    box_image = wandb.Image(image, boxes = {\"gt\": {\"box_data\": all_boxes, \"class_labels\" : class_id_to_label}}, classes = [{\"id\": 0, \"name\": \"none\"}, {\"id\": 1, \"name\": \"coral\"}])\n    return box_image","28dcc349":"my_data = []\n#Path to base folder\nbase_folder_path = '..\/input\/tensorflow-great-barrier-reef\/train_images\/video_0'\nimage_list = sorted(os.listdir(base_folder_path))\n# Considering first 50 images for display\nfor i in range(50):\n    bounding_box_dict = train_csv.loc[i].annotations\n    bounding_box_d = ast.literal_eval(bounding_box_dict)\n    if len(bounding_box_d)>0:\n        if train_csv.loc[i].image_id.split('-')[-1]+'.jpg' in image_list:\n            image_name = train_csv.loc[i].image_id.split('-')[-1]+'.jpg'\n            sample_image_path = os.path.join(base_folder_path, image_name)\n            wandb_image = bounding_boxes(sample_image_path, bounding_box_d)\n            my_data.append([image_name, wandb_image])\n        \ncolumns= [\"image_no\", \"image\"]\ntest_table = wandb.Table(data=my_data, columns=columns)\nrun.log({\"coral_reef_boxes\": test_table})\nrun.finish()","f6c65530":"bounding_box_count = []\nfor row_index, row in train_csv.iterrows():\n    bounding_box_count.append(len(ast.literal_eval(row.annotations)))\n\nmin_boxes = min(bounding_box_count)\nmax_boxes = max(bounding_box_count)\naverage_boxes = np.mean(bounding_box_count)\n\n","fb4459bc":"print(\"The minimum number of boxes in any training frame is {}\".format(min_boxes))\nprint(\"The maximum number of boxes in any training frame is {}\".format(max_boxes))\nprint(\"The average number of boxes in any training frame is {}\".format(average_boxes))","b1d362be":"<h1> Bar graph to vizualize no of frames in each video","df24eba0":"<h1> Defining the image reading function","916c1992":"<h1> Initializing WandB","9326c530":"This is a very basic exercise on how to log images and see the bounding box using WandB.\nHow it simplifies a lot of stuff for us in vizualization.\n\nI followed the tutorial here:\nhttps:\/\/wandb.ai\/stacey\/yolo-drive\/reports\/Bounding-Boxes-for-Object-Detection--Vmlldzo4Nzg4MQ\n\nAlso find this(https:\/\/www.kaggle.com\/c\/tensorflow-great-barrier-reef\/discussion\/290062) amazing discussion thread by https:\/\/www.kaggle.com\/mpwolke to understand why this competition has a huge impact on environment.\n\n","11130a7e":"<h1>Basic Imports","c0b7cf9f":"<h1>Reading CSV files"}}