{"cell_type":{"f33cbeb0":"code","572aff3a":"code","fd3d1891":"code","e87fa5d7":"markdown"},"source":{"f33cbeb0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n\n%matplotlib inline\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n\nsns.set(style='white', context='notebook', palette='deep')","572aff3a":"from __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\n\nbatch_size = 128\nnum_classes = 10\nepochs = 50\n\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\n# the data, split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train \/= 255\nx_test \/= 255\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n\nmodel.save('digit_model.h5')","fd3d1891":"!tensorflowjs_converter --input_format keras \"digit_model.h5\" \".\/model\"","e87fa5d7":"# Recognize Handwritten Digits - A Simple Web App\n\n<img src=\"https:\/\/camo.githubusercontent.com\/a90291b885b67809d9d199c6298d24e70d73b579\/68747470733a2f2f6d65646961312e67697068792e636f6d2f6d656469612f55344d5564745442695876524b514f6741702f67697068792e676966\" \/>\n\nA simple web app that predicts numbers 0-9 using Deep Learning.\n- Visit: [Preview Web App](https:\/\/furkan-gulsen.github.io\/Recognize-Handwritten-Digits\/tfjs.html)\n- Github Repo: [Github Repo](https:\/\/github.com\/Furkan-Gulsen\/Recognize-Handwritten-Digits)\n\n\nI have been working on Deep Learning for 3-4 months. During this period, I realized that most of my work could not be used by anyone other than a developer. I made a small project called \"Digit Recognition Web App\" with the help of Flask using \"Digit Recognizer\", one of the most widely used datasets in the world. I made this project accessible to everyone by setting it as a web application on github\ud83e\udd17.\n\nIt is not possible for me to write Flask codes here. I will only write the codes for the part I trained in deep learning. You can visit my Github repo to access all codes \ud83d\udcaa"}}