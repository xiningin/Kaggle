{"cell_type":{"d8092173":"code","687e89c9":"code","af9f9a43":"code","53ec77ba":"code","07eb8fd8":"code","e21bb23d":"code","d9868ab0":"code","cb301706":"code","a596f7ec":"code","81304fa9":"code","8c846a3d":"markdown","50aec712":"markdown","9cdcd740":"markdown","256efcbb":"markdown"},"source":{"d8092173":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nvoy=pd.read_csv('\/kaggle\/input\/voynich\/voynich evatxt.csv',sep=';')","687e89c9":"voyeva=pd.read_csv('\/kaggle\/input\/voynich\/voyEVA.txt')\nvoyeva.columns=['txt']\nvoyeva\nesperanto=pd.read_csv('\/kaggle\/input\/voynich\/esperanto.csv')\n#herbal=pd.read_csv('\/kaggle\/input\/voynich\/herbal.txt',delimiter = \"\\t\")\n#herbal.columns=['txt']\n#voycur=pd.read_csv('\/kaggle\/input\/voynich\/voyCurr.txt',delimiter = \"\\t\")\n#voycur.columns=['txt']\n\nesperanto","af9f9a43":"# transform Currier file to EVA as good as possible\n#voycur['txt']=voycur['txt'].replace(['4','7','6','O','8','9','2','E','R','S','P','B','F','V','A','C','I','D','J','G','H','1','T','U','0','K','L','5','Q','W','X','Y'], ['q','j','g','o','d','y','s','l','r','h','t','p','k','f','a','c','i','n','m','il','iil','iiil','ir','iir','iiir','ij','iij','iiij','ctt','cpt','ckt','cpt'],regex=True)\n#voyeva['txt']=voyeva['txt'].replace(['co','cu','ca','ce','ci'],['KO','KU','KA'],regex=True)\n#['a\u03b1','b\u03d0','c\u03f2','t\u03b8','e\u03f5','k\u03ba','d\u03b4','t\u03c4','i\u03b9', 't\u03b8','t\u03b8r\u03c1','g\u03b3','t\u03b8','l\u03bb','o\u03bf' ,'r\u03c1','pp','z\u03b6','s\u03c2','p\u03c0','u\u03c5','n\u03bd' ,'x\u03c7','l\u03bb','\u03bcm']\n#['\u03b1','\u03d0','\u03f2','\u03b8','\u03f5','\u03ba','\u03b4','\u03c4','\u03b9', '\u03b8','\u03b8\u03c1','\u03b3','\u03b8','\u03bb','\u03bf' ,'\u03c1','p','\u03b6','\u03c2','\u03c0','\u03c5','\u03bd' ,'\u03c7','\u03bb','\u03bc']#\n\n#transformations to try to fit Voynich with esperanto\n#voyeva['txt']=voyeva['txt'].replace(['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r' ,'s','t' ,'u', 'v', 'x','y','z'],\n#                                    ['a','b','c','t','e','k','d','t','i', 't','tr','g','t','l','o' ,'r','p','z','s','p','u','n' ,'x','l','m'],regex=True)\n#voyeva['txt']=voyeva['txt'].replace(['k','p','t','f'],['N','PS','M','TS'],regex=True)\nvoyeva","53ec77ba":"from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n\ntfidf = TfidfVectorizer()\ntfidf.fit(  voyeva['txt'].fillna(''))\neva_words=tfidf.get_feature_names()\ntfidf.fit(  esperanto['name.1'].fillna('') )\n#tfidf.fit(  botany['txt'].fillna('') )\n#tfidf.fit(  voycur['txt'].fillna('') )\n\nnah_words=tfidf.get_feature_names()\nprint(len(eva_words),len(nah_words))","07eb8fd8":"wordsplit = TfidfVectorizer(ngram_range=(1,2),analyzer='char')\nwordmatrixv=pd.DataFrame(wordsplit.fit_transform([w[:2] for w in eva_words]).todense(),columns=wordsplit.get_feature_names(),index=eva_words)\n\n\nwordsplit2 = TfidfVectorizer(ngram_range=(1,2),analyzer='char')\nwordmatrixn=pd.DataFrame(wordsplit2.fit_transform([w[: 2]for w in nah_words]).todense(),columns=wordsplit2.get_feature_names(),index=nah_words)\n","e21bb23d":"wordmatrixv.sum().sort_values()","d9868ab0":"wordmatrixn.sum().sort_values()","cb301706":"matchtable=pd.DataFrame(wordmatrixv.sum().sort_values()).reset_index()[-30:]\nmatchtable.columns=['voynich','freq']\nmatchtable2=pd.DataFrame(wordmatrixn.sum().sort_values())[-30:]\nmatchtable['freq2']=matchtable2.index\nmatchtable['esperanto']=matchtable2.iloc[:,0].values*1\nmatchtable","a596f7ec":"wordmatrixv['voy']=1\nwordmatrixn['voy']=2\ntotaal=wordmatrixv.append(wordmatrixn)\ntotaal.fillna(0)","81304fa9":"def kluster(data,grbvar,nummercl,level):\n    '''nummercl < ncol'''\n\n\n    from sklearn.cluster import KMeans\n    from sklearn.metrics.pairwise import cosine_similarity\n    import matplotlib.pyplot as plt\n    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n    from sklearn.neighbors import KNeighborsClassifier\n    from sklearn.decomposition import PCA,TruncatedSVD,NMF,FastICA\n    from umap import UMAP  # knn lookalike of tSNE but faster, so scales up\n    from sklearn.manifold import TSNE,Isomap #limit number of records to 100000\n\n    clusters = [\n                PCA(n_components=2,random_state=0,whiten=True),\n                TruncatedSVD(n_components=2, n_iter=7, random_state=42),\n                FastICA(n_components=2,random_state=0),\n                Isomap(n_components=2,n_jobs=4),\n                NMF(n_components=2,random_state=0),\n                TSNE(n_components=2,random_state=0),\n                UMAP(n_neighbors=5,n_components=2, min_dist=0.3,metric='minkowski'),\n                ] \n    clunaam=['PCA','tSVD','FastI','Isom','NMF','tSNE','UMAP']\n    \n    grbdata=data.groupby(grbvar).mean()\n    simdata = cosine_similarity(grbdata.fillna(0))\n    if len(grbdata)<3:\n        simdata=data#.drop(grbvar,axis=1)\n        simdata=simdata.dot(simdata.T)\n        from sklearn import preprocessing\n        simdata = preprocessing.MinMaxScaler().fit_transform(simdata)\n\n    for cli in clusters:\n        print(cli)\n        clunm=clunaam[clusters.index(cli)] #find naam\n        if clunm=='NMF':\n            simdata=simdata-simdata.min()+1\n        svddata = cli.fit_transform(simdata)\n\n        km = KMeans(n_clusters=nummercl, random_state=0)\n        km.fit_transform(svddata)\n        cluster_labels = km.labels_\n        clulabel='Clu'+clunm+str(level)\n        cluster_labels = pd.DataFrame(cluster_labels, columns=[clulabel])\n\n        pd.DataFrame(svddata).plot.scatter(x=0,y=1,c=cluster_labels[clulabel].values,colormap='viridis')\n        print(clunm,cluster_labels.mean())\n        plt.show()\n\n        clusdata=pd.concat([pd.DataFrame(grbdata.reset_index()[grbvar]), cluster_labels], axis=1)\n        if len(grbdata)<3: \n            cluname='Clu'+clunm+str(level)\n            data[cluname]=cluster_labels.values\n        \n        else:\n            data=data.merge(clusdata,how='left',left_on=grbvar,right_on=grbvar)\n        print('Correlation\\n',data[[grbvar,clulabel]].corr())\n        cluname='Clu'+clunm+str(level)\n        print(data.groupby(cluname).count())                \n    return data\n#total2=kluster(encoding(total).fillna(0),['SexBin','Pclass','FareBin'],3,1)\ntotal=kluster(totaal[:15000].fillna(0),'voy',2,1)","8c846a3d":"# The eva superset alphabet\nthe oddity here is, you could think about a switch between t - h\n![](http:\/\/www.voynich.nu\/img\/extra\/eva01.gif)","50aec712":"# conclusion at first sight\n'\n\nthe 'a' is omnipresent in esperanto and lacks factor 3x in voynich\n\nthe e should be swapped with c, since they are written very lookalike,thats possible and makes those letters collide better\nthe h should be swapped with the r, here again this is an excellent improvement\n","9cdcd740":"![](https:\/\/www.omniglot.com\/images\/writing\/esperanto.gif)","256efcbb":"esperanto lack\n\nQ,W,X,Y\n"}}