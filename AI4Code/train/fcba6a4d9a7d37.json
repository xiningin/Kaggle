{"cell_type":{"3e6984f4":"code","65d0d192":"code","884b9bc0":"code","c3e7cad8":"code","c43e4e81":"code","63a62aa0":"code","ceab4368":"code","19ef81af":"code","846af85d":"code","d9afcc03":"code","e00052f9":"code","7a2783a9":"code","bbc958eb":"code","0c3206ca":"code","a47116dd":"code","c8d06c61":"code","e1a462d7":"code","28d24505":"code","2ddcccef":"code","73dc0c6a":"code","dba1e447":"code","1aef2d1a":"code","6cabe272":"code","1d7804cf":"code","a448ba5a":"markdown","091fdfaf":"markdown","7fa69308":"markdown","2702e93b":"markdown","94a80d8e":"markdown","f6b639dd":"markdown","2ee251f0":"markdown"},"source":{"3e6984f4":"import pandas as pd\nimport numpy as np\nimport os\n\nimport joblib\n\nfrom keras import utils\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, MaxPooling2D, Conv2D, LSTM, GRU, Bidirectional\nfrom keras import regularizers\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.wrappers.scikit_learn import KerasClassifier\nimport keras","65d0d192":"df = pd.read_csv('..\/input\/promoter-nonpromotor-dna-sequences\/NonPromoterSequence.txt', sep = '>', )\ndf.dropna(subset=['Unnamed: 0'], how='all', inplace=True)\ndf.reset_index(inplace = True)\ndf.drop(['EP 1 (+) mt:CoI_1; range -400 to -100.', 'index'], axis = 1, inplace=True) #data cleaning after error found\ndf.rename(columns={'Unnamed: 0': \"sequence\"}, inplace = True)\ndf['label'] = 0\ndisplay(df)\ndisplay(df.shape)","884b9bc0":"df2 = pd.read_csv('..\/input\/promoter-nonpromotor-dna-sequences\/PromoterSequence.txt', sep = '>', )\ndf2.dropna(subset=['Unnamed: 0'], how='all', inplace=True)\ndf2.reset_index(inplace = True)\ndf2.drop(['EP 1 (+) mt:CoI_1; range -100 to 200.', 'index'], axis = 1, inplace=True)\ndf2.rename(columns={'Unnamed: 0': \"sequence\"}, inplace = True)\ndf2['label'] = 1\n\ndisplay(df2)\ndisplay(df2.shape)","c3e7cad8":"df = pd.concat([df, df2], axis = 0 )\ndf.shape","c43e4e81":"for seq in df['sequence']:\n    if 'N' in seq:\n        display(df.loc[df['sequence'] == seq])","63a62aa0":"df.drop([1822], inplace = True)","ceab4368":"for seq in df['sequence']:\n    if 'N' in seq:\n        display(df.loc[df['sequence'] == seq])","19ef81af":"sequence = list(df.loc[:, 'sequence'])\nencoded_list = []","846af85d":"def encode_seq(s):\n    Encode = {'A':[1,0,0,0],'T':[0,1,0,0],'C':[0,0,1,0],'G':[0,0,0,1]}\n    return [Encode[x] for x in s]\n\nfor i in sequence:\n    x = encode_seq(i)\n    encoded_list.append(x)\n\nX = np.array(encoded_list)\nX.shape","d9afcc03":"y = df['label']\ny.shape","e00052f9":"X.shape","7a2783a9":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y)","bbc958eb":"y_train = utils.to_categorical(y_train)\ny_test = utils.to_categorical(y_test)","0c3206ca":"params = {\n    'first_node': [128, 64],\n    'second_node': [32, 64],\n    'alpha': [0.001, 0.01],\n    'first_filter': [9, 16, 32], \n    'dropout': [0.1, 0.2, 0.5]\n}\n#used for GridSearchCV","a47116dd":"gru_model = Sequential()\n\ngru_model.add(Conv1D(filters = 27, kernel_size = (4), activation = 'relu', input_shape = (301, 4)))\ngru_model.add(MaxPooling1D(pool_size= (3)))\ngru_model.add(Dropout(0.2))\n\ngru_model.add(Conv1D(filters = 14, kernel_size = (2), activation = 'relu', padding = 'same'))\n#cnn_model.add(MaxPooling1D(pool_size= (1)))\n#cnn_model.add(Dropout(0.2))\n\n\n\ngru_model.add(Bidirectional(GRU(128, activation = 'relu')))\ngru_model.add(Dropout(0.2))\ngru_model.add(Dense(128, activation = 'relu'))\ngru_model.add(Dense(64, activation = 'relu'))\ngru_model.add(Dense(64, activation = 'relu'))\ngru_model.add(Dense(16, activation = 'relu', kernel_regularizer = regularizers.l2(0.01)))\ngru_model.add(Dense(2, activation = 'sigmoid'))\n\ngru_model.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nearly_stop = keras.callbacks.EarlyStopping(monitor = 'val_accuracy', min_delta = 0.0005, patience=8, \n                                           restore_best_weights=True )\nhistory = gru_model.fit(X_train, y_train, batch_size = 128, validation_data=(X_test, y_test), \n                        epochs=115)","c8d06c61":"pred = gru_model.predict","e1a462d7":"df = pd.read_csv('..\/input\/testing\/test.csv', sep = '\\n', ) #loading full test set\ndf.head()","28d24505":"sequence = list(df.loc[:, 'Sequence'])\nencoded_list = []","2ddcccef":"def encode_seq(s):\n    Encode = {'A':[1,0,0,0],'T':[0,1,0,0],'C':[0,0,1,0],'G':[0,0,0,1]}\n    return [Encode[x] for x in s]\n\nfor i in sequence:\n    x = encode_seq(i)\n    encoded_list.append(x)\n\nX_test_test = np.array(encoded_list)\nX_test_test.shape","73dc0c6a":"preds = gru_model.predict_classes(X_test_test)","dba1e447":"preds","1aef2d1a":"len(preds)","6cabe272":"np.savetxt(\"test_predictions.csv\", preds, delimiter=\",\")","1d7804cf":"'''\ndef model_func(first_node, second_node, alpha, first_filter, dropout):\n\n    model = Sequential()\n    model.add(Conv2D(filters = first_filter,       \n                    kernel_size = (3,3),    \n                    activation = 'relu',    \n                  input_shape = (301, 4, 1)))\n    model.add(MaxPooling2D(pool_size= (2,2)))\n    model.add(Dropout(dropout))\n\n    model.add(Conv2D(filters = 15,  \n                     kernel_size = (2,2),\n                    activation = 'relu',\n                    padding = 'same'))\n    model.add(MaxPooling2D(pool_size= (1,1)))\n    model.add(Dropout(dropout))\n\n\n    model.add(Flatten())\n    model.add(Dense(first_node, activation = 'relu', kernel_regularizer = regularizers.l2(alpha)))\n    model.add(Dense(second_node, activation = 'relu'))\n    model.add(Dense(32, activation = 'relu'))\n    model.add(Dense(16, activation = 'relu'))\n    model.add(Dense(2, activation = 'sigmoid'))\n\n    model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n    \n    return model\n\n\nearly_stop = keras.callbacks.EarlyStopping(monitor = 'loss', min_delta = 0, patience=5, \n                                           restore_best_weights=True )\n\n\nnn = KerasClassifier(build_fn = model_func, batch_size = 512, epochs = 1)\n\ngs = GridSearchCV(nn, param_grid = params, cv = 2)\n\ngs.fit(X_train, y_train, callbacks = [early_stop])\n\ncnn_model_saved = cnn_model.save('CNN_best_model.h5')","a448ba5a":"X = X.reshape(X.shape[0],301, 4, 1)\nX.shape","091fdfaf":"# --------------------------------\ud83e\uddec DNA Classification Project \ud83e\uddec---------------------------------------","7fa69308":"## Step 3: Training and Testing Neural Networks\n\nNow that we have preprocessed the data and built our training and testing datasets, we can start to deploy different convultional neural network architectures. It's relatively easy to test multiple models using gridsearch; as a result, we will compare and contrast the perforance using GridSearchCV over many values.","2702e93b":"## Step 1: Importing the Dataset\n\nThe following code cells will import necessary libraries and import the dataset from the repository as a Pandas DataFrame","94a80d8e":"## About :\n### In this project, we will explore the world of bioinformatics by using through deep learning. A promoter is a short region of DNA (100\u20131,000 bp) where transcription of a gene by RNA polymerase begins. It is typically located directly upstream or at the 5\u2032 end of the transcription initiation site. DNA promoter has been proven to be the primary cause of many human diseases, especially diabetes, cancer, or Huntington's disease. Therefore, classifying promoters has become an interesting problem and it has attracted the attention of a lot of researchers in the bioinformatics field. We will try to classify this using Machine Learning and Neural Networks.\n\n\n#### It includes :\n<ul>\n    <li>Importing data from the repository<\/li>\n    <li>Converting text inputs to numerical data<\/li>\n    <li>Building and training classification algorithms<\/li>\n    <li>Comparing and contrasting classification algorithms<\/li>\n<\/ul>","f6b639dd":"## Step 2: Preprocessing the Dataset\n\nThe data is not in a usable form; as a result, we will need to process it before using it to train our algorithms.","2ee251f0":"## Initial Gridsearch on CNN model as backup.\n\nThe models is saved in this file. \n\n\nBest Parameters are\n - L2 alpha of 0.01, \n - Dropout of 0.02\n - First filter: 32\n - First node: 64\n - Second node: 64"}}