{"cell_type":{"c088a34e":"code","3abb8447":"code","093fad72":"code","5f205fa9":"code","05348219":"code","43b4eac1":"code","68760a29":"code","2c758d74":"code","bce4fb0a":"code","30bf5944":"code","5615c264":"code","2199b2ef":"code","4f40439f":"code","c7754672":"code","c32059e6":"code","3f4762df":"code","8ef6dd74":"code","89931da9":"markdown","2893800e":"markdown","9307c6fd":"markdown","769b0bd6":"markdown"},"source":{"c088a34e":"import numpy as np #\u532f\u5165numpy\u6a21\u7d44\uff0c\u7528\u65bc\u9663\u5217\u8a08\u7b97\nimport pandas as pd #\u532f\u5165pandas\u6a21\u7d44\uff0c\u6578\u64da\u5206\u6790\u6a21\u7d44\uff0c\u63d0\u4f9b\u4e09\u7a2e\u8cc7\u6599\u7d50\u69cb\u4f9b\u4f7f\u7528\uff1aSeries\u3001DataFrame\u3001Panel\nimport tensorflow as tf #\u7531Google\u958b\u767c\uff0c\u662f\u73fe\u4eca\u91cd\u8981\u7684\u6df1\u5ea6\u5b78\u7fd2\u6846\u67b6\u4e4b\u4e00\nimport tensorflow.keras.backend as K #keras\u5f8c\u7aef\u662ftensorflow\u548cTheano\uff0cKeras\u6a21\u584a\u80fd\u5920\u540c\u6642\u5728Theano\u548cTensorFlow\u5169\u500b\u6846\u67b6\u4e0a\u4f7f\u7528\nimport random #\u532f\u5165\u4e82\u6578\u6a21\u7d44\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau #\u8abf\u6574\u5b78\u7fd2\u7387\u7684\u51fd\u6578\nfrom sklearn.model_selection import KFold #KFold\u662f\u5e38\u898b\u7684\u4ea4\u53c9\u9a57\u8b49\u65b9\u6cd5\nimport os #\u532f\u5165os\u6a21\u7d44\uff0c\u8207\u4f5c\u696d\u7cfb\u7d71\u4e92\u52d5\u7684\u6a21\u7d44\nfor dirname, _, filenames in os.walk('\/kaggle\/input'): #\u628a\u8cc7\u6599\u593e\u8def\u5f91\u548c\u6a94\u540d\u4e32\u63a5\u8d77\u4f86\n    for filename in filenames:\n        print(os.path.join(dirname, filename)) ","3abb8447":"def seed_everything(seed=42): #\u8a2d\u7f6e\u96a8\u6a5f\u6578\u7a2e\u5b50\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed) \n    tf.random.set_seed(seed)\n    \nseed_everything(42)","093fad72":"#\u8b80\u53d6 CSV File\ntrain_features = pd.read_csv(\"\/kaggle\/input\/lish-moa\/train_features.csv\")\ntrain_targets = pd.read_csv(\"\/kaggle\/input\/lish-moa\/train_targets_scored.csv\")\ntest_features = pd.read_csv(\"\/kaggle\/input\/lish-moa\/test_features.csv\")\nsample_submission = pd.read_csv(\"\/kaggle\/input\/lish-moa\/sample_submission.csv\")","5f205fa9":"train_targets.head()","05348219":"sample_submission.head()","43b4eac1":"#\u8a13\u7df4\u96c6\u6a94\u6848\ntrain_features.head()\n#23814 rows \u00d7 876 columns","68760a29":"print(train_features.isnull().sum().any())#\u6aa2\u67e5\u8a13\u7df4\u96c6\u662f\u5426\u6709\u7a7a\u5b57\u4e32\nprint(train_features.info())#\u67e5\u770b\u8a13\u7df4\u96c6\u8cc7\u8a0a","2c758d74":"train_features.dtypes#\u67e5\u770b\u8a13\u7df4\u96c6\u8cc7\u6599\u578b\u614b","bce4fb0a":"train_features=pd.get_dummies(train_features,columns=['cp_type','cp_dose'])\ntest_features=pd.get_dummies(test_features,columns=['cp_type','cp_dose'])\n#pandas.get_dummies()\u9032\u884cOne hot encoding\uff0c\u6307\u5b9a\u8981\u8f49\u63db\u7684\u5217cp_type\u548ccp_dose\n\n#object-->uint8","30bf5944":"train_features.dtypes#\u67e5\u770b\u8a13\u7df4\u96c6\u8cc7\u6599\u578b\u614b","5615c264":"del train_features['sig_id']\ndel test_features['sig_id']\ndel train_targets['sig_id']\n#\u5c07\u8a13\u7df4\u6578\u64da\u96c6\u3001\u6e2c\u8a66\u6578\u64da\u96c6\u53ca\u76ee\u6a19\u7684sig_id\u522a\u9664","2199b2ef":"train_features\n#\u539f 876 columns + \u6a19\u7c64\u8b8a\u91cf 4 columns - 3 columns(sig_id\u3001cp_type\u3001cp_dose) = 877 columns\n#23814 rows \u00d7 877 columns","4f40439f":"def build_model():#\u5efa\u6a21\n  model = tf.keras.Sequential() #Sequential()\u7dda\u6027\u5806\u758a\u7684\u7db2\u8def(\u4e00\u5c64\u5c64\u9806\u5e8f\u57f7\u884c\u7684\u6a21\u578b)\n#\u4f7f\u7528.add()\u65b9\u6cd5\u5c07\u5404\u5c64\u65b0\u589e\u5230\u6a21\u578b\u4e2d\n  model.add(tf.keras.layers.Input(shape=(train_features.shape[1],))) #\u5b9a\u7fa9\u8f38\u5165\n  model.add(tf.keras.layers.BatchNormalization()) \n    #\u56e0training \u7684\u904e\u7a0b\u4e2d\uff0cNetwork \u7684\u53c3\u6578\u662f\u4e0d\u65b7\u5728\u8b8a\u5316\u7684\uff0c\u6240\u4ee5\u6bcf\u4e00\u500bHidden Layer \u7684 mean \u8ddf variance \u662f\u4e0d\u65b7\u5728\u8b8a\u5316\u7684\n    #\u6240\u4ee5\u6709\u4e86\u65b0\u6280\u8853\uff0c\u589e\u52a0\u795e\u7d93\u7db2\u7d61\u7684\u7a69\u5b9a\u6027>BatchNormalization \u6279\u91cf\u6b78\u4e00\u5316\n  model.add(tf.keras.layers.Dense(units=1024,activation='relu')) #\u5168\u9023\u63a5\u5c64(Fully-connected Layer) \n    #units:\u6b63\u6574\u6578\uff0c\u8f38\u51fa\u77e9\u9663\u7684\u7dad\u6578\u3002activation:\u6fc0\u6d3b\u51fd\u6578\u4f7f\u7528ReLU\u6fc0\u6d3b\u51fd\u6578\n  model.add(tf.keras.layers.BatchNormalization()) \n  model.add(tf.keras.layers.Dropout(0.5)) \n    #rate:\u57280\u548c1\u4e4b\u9593\u6d6e\u52d5\u3002\u9700\u8981\u4e1f\u68c4\u7684\u8f38\u5165\u6bd4\u4f8b(\u901a\u5e380.25-0.5)\u3002\u53ef\u907f\u514dOverfitting\n  model.add(tf.keras.layers.Dense(units=2048,activation='relu')) \n  model.add(tf.keras.layers.BatchNormalization()) \n  model.add(tf.keras.layers.Dropout(0.5)) \n  model.add(tf.keras.layers.Dense(206, activation=\"sigmoid\")) #\u8f38\u51fa\u5c64  \n#\u7de8\u8b6f\n  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"accuracy\",\"binary_crossentropy\"])\n    #\u9078\u64c7\u512a\u5316\u65b9\u6cd5(optimizer)\u3001\u640d\u5931\u51fd\u6578(loss)\u53ca\u6210\u6548\u8861\u91cf\u65b9\u5f0f(metrics)\n  return model","c7754672":"#zeros-->\u5168\u90e8\u70ba0\u7684\u77e9\u9663\npred = np.zeros((train_features.shape[0], 206)) #\u5efa\u7acb\u4e8c\u7dad\u9663\u5217 23814rows * 206columns(\u591a\u5206\u985e\u76ee\u6a19)\npe = np.zeros((test_features.shape[0], 206)) #\u5efa\u7acb\u4e8c\u7dad\u9663\u5217 3982rows * 206columns(\u591a\u5206\u985e\u76ee\u6a19)\ntrain_features = train_features.values\ntrain_targets = train_targets.values","c32059e6":"n_split = 5 #Kfold\u5206\u5272\u62105\u500b\u96c6\u5408 \nkfoldnumber= 0 \n\nfor train_index, validation_index in KFold(n_split).split(train_features):\n    kfoldnumber += 1 \n    print('Fold number: ',kfoldnumber) \n    #ReduceLROnPlateau-->\u7576\u8a55\u50f9\u6307\u6a19\uff08\u640d\u5931\uff0c\u6e96\u78ba\u6027\uff09\u505c\u6b62\u6539\u9032\u6642\uff0c\u8abf\u6574\u5b78\u7fd2\u7387\n    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4, mode='min')\n    #\u8aaa\u660e:\u76e3\u63a7val_loss\uff0c\u5728\u8a72\u6578\u503c\u7b49\u5f853\u6b21\uff0c\u82e5\u7121\u8f03\u597d\u8868\u73fe\u5247\u8abf\u964d\u5b78\u7fd2\u7387\uff0c\u4f46\u6700\u4f4e\u82e5\u70ba0.0001\uff0c\u5247\u4e0d\u5728\u8abf\u964d\u3002\n    net = build_model()\n    #fit\u51fd\u6578\u4ee5\u8a13\u7df4\u6a21\u578b(\u8f38\u5165\u6578\u64da,\u6a19\u7c64,...)\n        #batch_size=128 \u6bcf\u6279\u8cc7\u6599\u91cf\u7684\u5927\u5c0f\u8a2d\u70ba128\u6a23\u672c\n        #epoch=35 \u7528\u8a13\u7df4\u96c6\u4e2d\u7684\u5168\u90e8\u6a23\u672c\u8a13\u7df435\u6b21(\u9031\u671f)\n        #validation_data\uff1a\u5f62\u5f0f\u70ba\uff08X\uff0cy\uff09\u7684\u5217\u8868(tuple)\uff0c\u662f\u6307\u5b9a\u7684\u9a57\u8b49\u96c6\n    net.fit(train_features[train_index], train_targets[train_index], batch_size=128, epochs=35, \n            validation_data=(train_features[validation_index], train_targets[validation_index]), verbose=0, callbacks=[reduce_lr_loss])\n    #evaluate\u51fd\u6578\u6309batch\u8a08\u7b97\u5728\u67d0\u4e9b\u8f38\u5165\u6578\u64da\u4e0a\u6a21\u578b\u7684\u8aa4\u5dee\n    print(\"train\", net.evaluate(train_features[train_index], train_targets[train_index], verbose=0, batch_size=128))#\u8a13\u7df4\u6578\u64da\u8207\u8a13\u7df4\u6a19\u7c64\n    print(\"val\", net.evaluate(train_features[validation_index], train_targets[validation_index], verbose=0, batch_size=128))#\u9a57\u8b49\u6578\u64da\u8207\u9a57\u8b49\u6a19\u7c64\n    #predict\u51fd\u6578\u6309batch\u7372\u5f97\u8f38\u5165\u6578\u64da\u5c0d\u61c9\u7684\u8f38\u51fa\n    print(\"predict val...\")\n    pred[validation_index] = net.predict(train_features[validation_index], batch_size=128, verbose=0)\n    print(\"predict test...\")\n    pe += net.predict(test_features, batch_size=128, verbose=0) \/ n_split  ","3f4762df":"pe.shape\ncolumns = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')\ndel columns['sig_id']\nsub = pd.DataFrame(data=pe, columns=columns.columns)#\u8cc7\u6599\u8868\u683c\u5efa\u7acb","8ef6dd74":"sample = pd.read_csv('..\/input\/lish-moa\/sample_submission.csv')\nsub.insert(0, column = 'sig_id', value=sample['sig_id']) #\u589e\u52a0sig_id\u6b04\u4f4d\nsub.to_csv('submission.csv', index=False)","89931da9":"![NN.png](attachment:NN.png)","2893800e":"![Kfold.jpg](attachment:Kfold.jpg)","9307c6fd":"<img src=\"\">","769b0bd6":"\n**Neural Network \u8655\u7406\u6d41\u7a0b**\n1. \u5efa\u7acb\u6a21\u578b\uff1a\u5229\u7528Keras \u63d0\u4f9b\u7684\u5169\u7a2e\u6a21\u578bSequential Model\u8207Functional API\uff0c\u6211\u4f7f\u7528\u55ae\u8f38\u5165\u55ae\u8f38\u51fa\u7684Sequential Model\u3002\n1. \u78ba\u7acb\u76ee\u6a19\u53ca\u6c42\u89e3\u65b9\u6cd5\uff1a\u4f7f\u7528compile\u51fd\u6578\u5b9a\u7fa9\u512a\u5316\u51fd\u6578\u3001\u640d\u5931\u51fd\u6578\u53ca\u6210\u6548\u8861\u91cf\u6307\u6a19\u3002\n1. \u8a13\u7df4\u6a21\u578b\uff1a\u4f7f\u7528fit\u51fd\u6578\u8a13\u7df4\u6a21\u578b\u3002\n1. \u8a55\u4f30\u6a21\u578b\uff1a\u4f7f\u7528evaluate\u51fd\u6578\uff0c\u8a13\u7df4\u5f8c\u7684\u6a21\u578b\uff0c\u9700\u8981\u5c0d\u5176\u6027\u80fd\u9032\u884c\u8a55\u4f30\u3002\n1. \u9810\u6e2c\uff1a\u7528\u8a13\u7df4\u597d\u7684\u6a21\u578b\u5728\u65b0\u7684\u6578\u64da\u4e0a\u9032\u884c\u9810\u6e2c\uff0c\u4f7f\u7528predict\u51fd\u6578\u3002\n"}}