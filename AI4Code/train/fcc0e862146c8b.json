{"cell_type":{"062ac313":"code","a771a0c0":"code","e11a5463":"code","769bd9f1":"code","dec7253f":"code","8e12a7f9":"code","f50beaaf":"code","10193fff":"code","4d46ec99":"code","46376beb":"code","f01244f0":"code","62f4799f":"code","be428a6d":"code","19c7d4e5":"code","95d7be1c":"code","5563e30e":"code","036d2478":"code","b14f98c1":"code","f66a3223":"code","726bff1f":"code","bc9f2a0a":"markdown","4d9e6fe1":"markdown","5634da92":"markdown","289bd938":"markdown","f4c1e6de":"markdown","398b06e2":"markdown","2b0722d2":"markdown"},"source":{"062ac313":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, log_loss, roc_auc_score\nfrom warnings import filterwarnings\nfrom sklearn.metrics import roc_curve, auc\nfilterwarnings('ignore')\n\n\nimport os\nfor dirname, _, filenames in os.walk(\"\/kaggle\/input\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a771a0c0":"train = pd.read_csv(\"..\/input\/tabular-playground-series-oct-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-oct-2021\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/tabular-playground-series-oct-2021\/sample_submission.csv\")","e11a5463":"train.head()","769bd9f1":"train.info()","dec7253f":"train.describe()","8e12a7f9":"train.isnull().sum()","f50beaaf":"test.head()","10193fff":"test.isnull().sum()","4d46ec99":"# number_of_cols = [col for col in train.columns]\nnumber_of_cols = [col for col in test.columns]\ntrain[\"mean\"] = train[number_of_cols].mean(axis=1)\ntest[\"mean\"] = test[number_of_cols].mean(axis=1)\n\ntrain[\"std\"] = train[number_of_cols].std(axis=1)\ntest[\"std\"] = test[number_of_cols].std(axis=1)\n\ntrain[\"min\"] = train[number_of_cols].min(axis=1)\ntest[\"min\"] = test[number_of_cols].min(axis=1)\n\ntrain[\"max\"] = train[number_of_cols].max(axis=1)\ntest[\"max\"] = test[number_of_cols].max(axis=1)","46376beb":"def reduce_mem_usage(props):\n    start_mem_usg = props.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    for col in props.columns:\n        if props[col].dtype != object:  # Exclude strings\n            # make variables for Int, max and min\n            IsInt = False\n            mx = props[col].max()\n            mn = props[col].min()\n    \n            # test if column can be converted to an integer\n            asint = props[col].astype(np.int64)\n            result = (props[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True\n\n            \n            # Make Integer\/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        props[col] = props[col].astype(np.uint8)\n                    elif mx < 65535:\n                        props[col] = props[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        props[col] = props[col].astype(np.uint32)\n                    else:\n                        props[col] = props[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        props[col] = props[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        props[col] = props[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        props[col] = props[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        props[col] = props[col].astype(np.int64)    \n            \n            else:\n                props[col] = props[col].astype(np.float32)\n    \n    # Print final result\n    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = props.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage is: \",mem_usg,\" MB\")\n    print(\"This is \",100*mem_usg\/start_mem_usg,\"% of the initial size\")\n    return props","f01244f0":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","62f4799f":"train.head()","be428a6d":"bol_col_train = []\nfor i, col in enumerate(train.columns):\n    if train[col].dtypes == bool:\n        bol_col_train.append(i)","19c7d4e5":"bol_col_test = []\nfor i, col in enumerate(test.columns):\n    if test[col].dtypes == bool:\n        bol_col_test.append(i)","95d7be1c":"train.iloc[:,bol_col_train] = train.iloc[:,bol_col_train].astype(int)\ntest.iloc[:,bol_col_test] = test.iloc[:,bol_col_test].astype(int)","5563e30e":"train.head()","036d2478":"X = train.drop(columns=['id', 'target']).copy()\ny = train['target'].copy()\nX_test = test.copy()","b14f98c1":"params = {\n        'iterations': 15000, \n        'loss_function': 'Logloss', \n        'depth': 8, \n        'task_type' : 'GPU',\n        'use_best_model': True,\n        'eval_metric': 'AUC',\n        'early_stopping_rounds': 1000,\n        'learning_rate': 0.03,\n        'border_count': 32,\n        'l2_leaf_reg': 3,\n        \"verbose\": 1000\n    }","f66a3223":"kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\npreds = []\nscores = []\n\nfor fold, (idx_train, idx_valid) in enumerate(kf.split(X, y)):\n    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n    \n    model = CatBoostClassifier(**params)\n    \n    model.fit(X_train,y_train,\n              eval_set=[(X_valid,y_valid)],\n              early_stopping_rounds=100,\n              verbose=False)\n    \n    pred_valid = model.predict_proba(X_valid)[:,1]\n    fpr, tpr, _ = roc_curve(y_valid, pred_valid)\n    score = auc(fpr, tpr)\n    scores.append(score)\n    \n    print(f\"Fold: {fold + 1} Score: {score}\" \"\\n\")\n    print('||'*40, \"\\n\")\n    \n    test_preds = model.predict_proba(X_test)[:,1]\n    preds.append(test_preds)\n    \nprint(f\"Overall Validation Score: {np.mean(scores)}\")\n# kfold.split(train, train_targets)","726bff1f":"predictions = np.mean(np.column_stack(preds),axis=1)\n\nsubmission['target'] = predictions\nsubmission.to_csv('.\/catboost.csv', index=False)\nsubmission.head()","bc9f2a0a":"## EDA","4d9e6fe1":"***Our data is to large and take much time to load this is very helpful post, to deal with large size of data.***\nhttps:\/\/towardsdatascience.com\/how-to-work-with-million-row-datasets-like-a-pro-76fb5c381cdd","5634da92":"Choosing Boolian type columns in both train and test ","289bd938":"**find some usefull things, (mean, std, min, max) now, after unless feature will removed.**","f4c1e6de":"## Feature Engineering","398b06e2":"*Check-out the above function how its impect and assign returning dataframe into train and test*","2b0722d2":"### NOW CLICK UPVOTE BUTTON......Cheers"}}