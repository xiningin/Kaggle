{"cell_type":{"c318135c":"code","f4d4872d":"code","e8d049e8":"code","9683f944":"code","a157b716":"code","9a49a2f8":"code","2d51b219":"code","8793de77":"code","8ff42a7d":"code","390ef72c":"code","842fb47c":"code","41da0b00":"code","5cc40db1":"code","406b50c4":"code","d59cf0f7":"code","d7a0e916":"code","94dc62f3":"code","f8bfe305":"code","3e71c7fd":"code","9d29f8a9":"code","0e96c1df":"code","303519fe":"code","0abd3c2f":"code","969f13c6":"code","cdfca0c7":"code","ec5654a4":"code","4054141b":"code","602460b4":"code","c2247238":"code","5b8bc612":"code","0eca86d7":"code","fafeb773":"code","82b6f509":"code","220d82f7":"code","e8bcd211":"code","ec30444b":"code","fe137c86":"code","022684e2":"code","1135845f":"code","e6000e09":"code","2fb086f4":"code","707af7cc":"code","c3bb102e":"code","eacfde52":"code","3292183f":"code","306ba514":"code","9db95348":"code","56942cb5":"code","c1b4794c":"code","caea6df7":"code","bcfcb6e9":"code","d87f6c13":"code","76a7779a":"code","1ca9b729":"code","6d5b65be":"code","6b89e96d":"code","894a92cb":"code","758003eb":"code","73b8f109":"code","0e2d3776":"code","b2cb09e0":"code","15011e46":"code","5f7383fa":"code","d3a45df6":"code","f08c7ac0":"code","b78c607e":"code","f4758195":"code","0386ea6b":"code","3a7c33b6":"code","a628b406":"code","893626f0":"markdown","2b06ae3a":"markdown","590238fc":"markdown","d9b64bad":"markdown","dd394281":"markdown","6e49cc14":"markdown","e1a84151":"markdown","215bf563":"markdown","0adb8d10":"markdown","02d00531":"markdown","db4e35d1":"markdown","9b4470d8":"markdown","cca6af54":"markdown","724055e2":"markdown","e0e1dd08":"markdown","fd1c18f8":"markdown","50f63f42":"markdown","fd1371f6":"markdown","4a296e7a":"markdown","17cf9ada":"markdown","183cefaa":"markdown","0eef8270":"markdown","9ad3368b":"markdown","4c249dfd":"markdown","a979d8fd":"markdown","f7801baf":"markdown","8da4296a":"markdown","df6d675f":"markdown","78f13d35":"markdown","73262843":"markdown","43ad2d79":"markdown","4719eab6":"markdown","e57db449":"markdown","a71910d7":"markdown","24747ee4":"markdown"},"source":{"c318135c":"import warnings\nwarnings.filterwarnings('ignore')\n#\nfrom ipywidgets import interact\n#\nimport pandas as pd\npd.set_option('display.max_columns', None)\nimport numpy as np\nfrom scipy import stats\n#\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('seaborn-white');\nplt.rcParams['font.size'] = 14;\nplt.figure(figsize=(12,5));\npalette = sns.color_palette('Paired', 10);\n#\nfrom geopy.geocoders import Nominatim\nimport folium\nfrom folium.plugins import HeatMap\nimport calendar\n#\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.compose import make_column_selector\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.inspection import permutation_importance\nfrom sklearn import set_config; set_config(display='diagram')","f4d4872d":"data = pd.read_csv(\"\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv\")\ndata.head()","e8d049e8":"size_before = len(data)\ndata = data.drop_duplicates()\nsize_after = len(data)\nprint(str(size_before - size_after) + \" duplicates were removed.\")","9683f944":"100 * data.isnull().sum().sort_values(ascending=False)\/len(data)","a157b716":"data = data.drop([\"Sunshine\", \"Evaporation\", \"Cloud3pm\", \"Cloud9am\"], axis=1)\ndata.head()","9a49a2f8":"badly_named = {\"AliceSprings\":\"Alice Springs\",\n               \"BadgerysCreek\":\"Badgerys Creek\",\n               \"CoffsHarbour\": \"Coffs Harbour\",\n               \"GoldCoast\": \"Gold Coast\",\n               \"MelbourneAirport\": \"Melbourne Airport\",\n               \"MountGambier\": \"Mount Gambier\",\n               \"MountGinini\": \"Mount Ginini\",\n               \"NorahHead\": \"Norah Head\",\n               \"NorfolkIsland\": \"Norfolk Island\",\n               \"PearceRAAF\": \"Pearce RAAF\",\n               \"PerthAirport\": \"Perth Airport\",\n               \"SalmonGums\": \"Salmon Gums\",\n               \"SydneyAirport\": \"Sydney Airport\",\n               \"WaggaWagga\": \"Wagga Wagga\"}\ndata[\"Location\"] = data[\"Location\"].apply(lambda x: badly_named[x] if x in badly_named.keys() else x)","2d51b219":"geolocator = Nominatim(user_agent=\"null\")\n#\nlatitude = []\nlongitude = []\n#\nfor k in data[\"Location\"].unique():\n    search_ = k + \", Australia\"\n    location = geolocator.geocode(search_)\n    latitude.append(location.latitude)\n    longitude.append(location.longitude)\n#\nlatitude = dict(zip(data[\"Location\"].unique(), latitude))\nlongitude = dict(zip(data[\"Location\"].unique(), longitude))","8793de77":"data[\"longitude\"] = data[\"Location\"].map(longitude)\ndata[\"latitude\"] = data[\"Location\"].map(latitude)","8ff42a7d":"center_location = [-25.3455545, 131.036961]\nm = folium.Map(location=center_location, control_scale=True, zoom_start=4)#, tiles=\"Stamen terrain\")","390ef72c":"heatmap_data = data[['latitude', 'longitude', 'Rainfall']].groupby(['latitude', 'longitude']).sum().reset_index().values.tolist()\ngradient = {0.2: 'blue', 0.4: 'lime', 0.6: 'orange', 1: 'red'}\nHeatMap(data=heatmap_data, radius=15, gradient=gradient, max_zoom=1).add_to(m)\nm","842fb47c":"def barplot_rainTomorrow(df):\n    df.sort_values(by=\"Location\", inplace=True)\n    ax = sns.displot(data=df,x=\"Location\", hue=\"RainTomorrow\",multiple=\"stack\", aspect=2.2, height=7, legend=False);\n    plt.tick_params(axis='y', rotation=0, size=10, labelsize=18)\n    plt.xlabel(\"\", fontdict={\"fontsize\":25})\n    plt.ylabel(\"Days\", fontdict={\"fontsize\":25}, loc=\"bottom\")\n    plt.tick_params(axis='x', rotation=90, size=20, labelsize=20, top=False)\n    plt.tick_params(axis='y', right=False)\n    plt.legend([\"Yes\",\"No\"], title=\"Rain Tomorrow\", title_fontsize=20, fontsize=20, loc='right', bbox_to_anchor=(1.05, 1));\n    plt.title(\"Days of Rain Tomorrow per city \\n over the covered period\", fontsize=30);","41da0b00":"barplot_rainTomorrow(data)","5cc40db1":"data[\"Date\"] = pd.to_datetime(data[\"Date\"])\ndata[\"Month\"] = data[\"Date\"].apply(lambda x: x.month)","406b50c4":"@interact\ndef plot_climate(city=sorted(list(data.Location.unique()))):\n    #def plot_climate_script(data, city=city):\n    df = data.copy()\n    rainfall = df.groupby([\"Location\", \"Month\"])[[\"Rainfall\"]].mean()\n    max_temp = df.groupby([\"Location\", \"Month\"])[[\"MaxTemp\"]].mean()\n    max_tempMin = df.groupby([\"Location\", \"Month\"])[[\"MaxTemp\"]].min()\n    max_tempMax = df.groupby([\"Location\", \"Month\"])[[\"MaxTemp\"]].max()\n    min_temp = df.groupby([\"Location\", \"Month\"])[[\"MinTemp\"]].mean()\n    min_tempMin = df.groupby([\"Location\", \"Month\"])[[\"MinTemp\"]].min()\n    min_tempMax = df.groupby([\"Location\", \"Month\"])[[\"MinTemp\"]].max()\n    \n    fig, ax1 = plt.subplots(figsize=(13,7))\n    ax2 = ax1.twinx()\n    ax2.plot(max_temp.unstack()[\"MaxTemp\"].T[city], 'o-', color=\"red\", linewidth=3, markersize=12, label=\"Avg max temp\")\n    ax2.plot(max_tempMin.unstack()[\"MaxTemp\"].T[city], 'o-', color=\"orangered\", linewidth=1, markersize=5, alpha=0.3)\n    ax2.plot(max_tempMax.unstack()[\"MaxTemp\"].T[city], 'o-', color=\"orangered\", linewidth=1, markersize=5, alpha=0.3)\n    ax2.fill_between(np.arange(1, 13),\n                     max_tempMin.unstack()[\"MaxTemp\"].T[city],\n                     max_tempMax.unstack()[\"MaxTemp\"].T[city],\n                     color=\"orangered\",\n                     alpha=0.1,\n                     label=\"Max temp range\")\n    ax2.plot(min_temp.unstack()[\"MinTemp\"].T[city], 'o-', color=\"blue\", linewidth=3, markersize=12, label=\"Avg min temp\")\n    ax2.plot(min_tempMin.unstack()[\"MinTemp\"].T[city], 'o-', color=\"darkblue\", linewidth=1, markersize=5, alpha=0.3)\n    ax2.plot(min_tempMax.unstack()[\"MinTemp\"].T[city], 'o-', color=\"darkblue\", linewidth=1, markersize=5, alpha=0.3)\n    ax2.fill_between(np.arange(1, 13),\n                     min_tempMin.unstack()[\"MinTemp\"].T[city],\n                     min_tempMax.unstack()[\"MinTemp\"].T[city],\n                     color=\"darkblue\",\n                     alpha=0.1,\n                     label=\"Min temp range\")\n    ax2.tick_params(axis='y', size=5, labelsize=13)\n    ax2.set_ylabel('Temperature [\u00b0C]', fontsize=15, labelpad=15)\n    ax2.legend(title='', bbox_to_anchor=(1.05, 1), loc='upper left')\n    ax2.spines[\"top\"].set_visible(False)\n    ax2.spines[\"right\"].set_visible(False)\n    ax2.spines[\"left\"].set_visible(False)\n    \n    ax1.bar(x= np.arange(1, 13), height=rainfall.unstack()[\"Rainfall\"].T[city], label=\"Avg monthly rainfall\")\n    plt.xticks(list(rainfall.unstack()[\"Rainfall\"].columns),\n               list(pd.Series(rainfall.unstack()[\"Rainfall\"].columns).apply(lambda x: calendar.month_name[x])))\n    ax1.tick_params(axis='x', rotation=45, size=13, labelsize=13, top=False)\n    ax1.tick_params(axis='y', size=5, labelsize=13)\n    ax1.set_ylabel('Average monthly rainfall [mm]', fontsize=15, labelpad=15)\n    ax1.set_title(f\"{city}, South Australia\", pad=20, fontdict={\"fontsize\":30, \"color\":\"black\"})\n    ax1.spines[\"top\"].set_visible(False)\n    ax1.spines[\"right\"].set_visible(False)\n    ax1.spines[\"left\"].set_visible(False)\n    ax1.legend(title='', bbox_to_anchor=(1.05, 1.0), loc='lower left')\n    plt.tight_layout()","d59cf0f7":"data.head()","d7a0e916":"data = data.drop([\"Date\", \"longitude\", \"latitude\"], axis=1).reset_index(drop=True)","94dc62f3":"def clean_data(df):\n    df = df[(~df[\"RainTomorrow\"].isnull())]\n    df = df[(~df[\"RainToday\"].isnull())]\n    df[\"Month\"] = df[\"Month\"].apply(lambda x: calendar.month_name[x])\n    df[\"RainTomorrow\"] = df[\"RainTomorrow\"].apply(lambda x: 1 if x==\"Yes\" else 0)\n    df[\"RainToday\"] = df[\"RainToday\"].apply(lambda x: 1 if x==\"Yes\" else 0)\n    return df\n#\ndata = clean_data(data)","f8bfe305":"data[\"MinTemp\"].max()","3e71c7fd":"X_train = data.drop([\"RainTomorrow\"], axis=1).copy()\ny_train = data[\"RainTomorrow\"].copy()","9d29f8a9":"X_train.head()","0e96c1df":"pipe_numeric = Pipeline([\n    ('imputer', SimpleImputer(strategy = 'mean'))\n])\npipe_numeric","303519fe":"pipe_binary = Pipeline([\n    ('encoder', OneHotEncoder(sparse=False, drop='if_binary'))\n])\npipe_binary","0abd3c2f":"pipe_multiclass = Pipeline([\n    ('imputer', SimpleImputer(strategy = 'most_frequent')),\n    ('encoder', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n])\npipe_multiclass","969f13c6":"impute_and_encode = ColumnTransformer([\n    ('numeric', pipe_numeric, make_column_selector(dtype_include=\"float64\")),\n    ('binary', pipe_binary, make_column_selector(dtype_include=\"int64\")),\n    ('multiclass', pipe_multiclass, make_column_selector(dtype_include=\"object\"))])\nimpute_and_encode","cdfca0c7":"preprocessor = Pipeline([(\"preproc\", impute_and_encode), \n                         (\"scaler\", StandardScaler())])","ec5654a4":"preprocessor.fit(X_train)","4054141b":"def def_col_names(a, colnames):\n    col_names = []\n    for k in colnames:\n        col_names.append(a + \"_\" + str(k))\n    return col_names","602460b4":"output_pipe_columns = list(X_train[make_column_selector(dtype_include=\"float64\")].columns)\n#\noutput_pipe_columns += list(X_train[make_column_selector(dtype_include=\"int64\")].columns)\n#\nfor k in list(X_train[make_column_selector(dtype_include=\"object\")].columns):\n    output_pipe_columns += def_col_names(k, X_train[k].dropna().unique())","c2247238":"X_train_scaled = pd.DataFrame(preprocessor.fit_transform(X_train), columns=output_pipe_columns)\nX_train_scaled.head()","5b8bc612":"final_pipe = Pipeline([\n    (\"preprocessor\", preprocessor),\n    ('classifier', LogisticRegression(max_iter=10000))])\nfinal_pipe","0eca86d7":"cv_baseline_LR = cross_validate(final_pipe, X_train, y_train, scoring= \"recall\", cv=10)\nprint(\"Baseline recall score for LogisticRegression: \" + str(round(cv_baseline_LR[\"test_score\"].mean()*100, 2)) + \"%\")","fafeb773":"prediction_dataFrame = pd.DataFrame(y_train).copy()\nprediction_dataFrame['predictions'] = cross_val_predict(estimator=final_pipe,\n                                                        X=X_train,\n                                                        y=y_train,\n                                                        cv=10)","82b6f509":"prediction_dataFrame.columns = [\"y_true\", \"y_pred\"]\nprediction_dataFrame.head()","220d82f7":"fig = plt.figure(figsize=(18,6))\ngs = fig.add_gridspec(1,2)\nax1 = fig.add_subplot(gs[0, 0])\ndisp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(prediction_dataFrame[\"y_true\"], prediction_dataFrame[\"y_pred\"]))\ndisp.plot(cmap=\"Blues\", ax=ax1);\nax2 = fig.add_subplot(gs[0, 1])\nax2.spines['right'].set_visible(False)\nax2.spines['top'].set_visible(False)\nax2.spines['bottom'].set_visible(False)\nax2.spines['left'].set_visible(False)\nax2.set_xticklabels([])\nax2.set_yticklabels([])\n#\nax2.text(0.1, 0.6, 'Accuracy = '+ str(round(accuracy_score(prediction_dataFrame[\"y_true\"],\n                                                           prediction_dataFrame[\"y_pred\"])*100, 1)) + \"%\",\n         fontdict= {\"fontsize\":30});\n#\nax2.text(0.1, 0.4, 'Recall = '+ str(round(recall_score(prediction_dataFrame[\"y_true\"], \n                                                       prediction_dataFrame[\"y_pred\"])*100, 1)) + \"%\", \n         fontdict= {\"fontsize\":30});\n#\nax2.text(0.1, 0.2, 'Precision = '+ str(round(precision_score(prediction_dataFrame[\"y_true\"], \n                                                             prediction_dataFrame[\"y_pred\"])*100, 1)) + \"%\", \n         fontdict= {\"fontsize\":30});","e8bcd211":"X_train_scaled = pd.DataFrame(preprocessor.fit_transform(X_train), columns=output_pipe_columns)\nX_train_scaled.head()","ec30444b":"corr_df = X_train_scaled.corr().unstack().reset_index()\ncorr_df.columns = ['feature_1','feature_2', 'correlation']\ncorr_df.sort_values(by=\"correlation\",ascending=False, inplace=True)\ncorr_df = corr_df[corr_df['feature_1'] != corr_df['feature_2']]\ncorr_df = corr_df.reset_index(drop=True)\ncorr_df.head()","fe137c86":"high_correlation_coeff = corr_df[(corr_df[\"correlation\"]>0.9) | (corr_df[\"correlation\"]<-0.9)]\nhigh_correlation_coeff","022684e2":"X_train.drop([\"Temp3pm\"], axis=1, inplace=True)\nX_train.drop([\"Pressure3pm\"], axis=1, inplace=True)","1135845f":"grid_model = {'classifier': [RandomForestClassifier(), \n                             LogisticRegression(max_iter=10000), \n                             GradientBoostingClassifier(),\n                             DecisionTreeClassifier(),\n                             LinearSVC()],\n              \"preprocessor__scaler\": [StandardScaler(), RobustScaler(), MinMaxScaler()]\n             }\n\nsearch_model = GridSearchCV(final_pipe,\n                            grid_model,\n                            scoring=\"recall\",\n                            cv=5,\n                            n_jobs=-1,\n                            verbose=1)\nsearch_model.fit(X_train, y_train);","e6000e09":"search_model.best_params_","2fb086f4":"search_model.best_score_","707af7cc":"pred_best_model = pd.DataFrame(y_train).copy()\npred_best_model['predictions'] = cross_val_predict(estimator=search_model.best_estimator_,\n                                                   X=X_train,\n                                                   y=y_train,\n                                                   cv=5)\npred_best_model.columns = [\"y_true\", \"y_pred\"]","c3bb102e":"fig = plt.figure(figsize=(18,6))\ngs = fig.add_gridspec(1,2)\nax1 = fig.add_subplot(gs[0, 0])\ndisp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(pred_best_model[\"y_true\"], pred_best_model[\"y_pred\"]))\ndisp.plot(cmap=\"Blues\", ax=ax1);\nax2 = fig.add_subplot(gs[0, 1])\nax2.spines['right'].set_visible(False)\nax2.spines['top'].set_visible(False)\nax2.spines['bottom'].set_visible(False)\nax2.spines['left'].set_visible(False)\nax2.set_xticklabels([])\nax2.set_yticklabels([])\n#\nax2.text(0.1, 0.6, 'Accuracy = '+ str(round(accuracy_score(pred_best_model[\"y_true\"],\n                                                           pred_best_model[\"y_pred\"])*100, 1)) + \"%\",\n         fontdict= {\"fontsize\":30});\n#\nax2.text(0.1, 0.4, 'Recall = '+ str(round(recall_score(pred_best_model[\"y_true\"], \n                                                       pred_best_model[\"y_pred\"])*100, 1)) + \"%\", \n         fontdict= {\"fontsize\":30});\n#\nax2.text(0.1, 0.2, 'Precision = '+ str(round(precision_score(pred_best_model[\"y_true\"], \n                                                             pred_best_model[\"y_pred\"])*100, 1)) + \"%\", \n         fontdict= {\"fontsize\":30});","eacfde52":"grid_DTC = {'classifier': [DecisionTreeClassifier()],\n            'classifier__criterion': [\"gini\", \"entropy\"],\n            'classifier__splitter': [\"best\", \"random\"],\n            'classifier__max_depth': stats.randint(1, 300),\n            'classifier__min_samples_split': stats.randint(2, 30),\n            #'classifier__class_weight': [\"balanced\", \"none\"],\n            \"preprocessor__scaler\": [RobustScaler()]\n            }\n\nsearch_DTC = RandomizedSearchCV(final_pipe,\n                                grid_DTC,\n                                scoring=\"recall\",\n                                n_iter=20,\n                                cv=5,\n                                n_jobs=-1,\n                                verbose=True)\nsearch_DTC.fit(X_train, y_train);","3292183f":"search_DTC.best_params_","306ba514":"search_DTC.best_score_","9db95348":"pred_dtc_opt = pd.DataFrame(y_train).copy()\npred_dtc_opt['predictions'] = cross_val_predict(estimator=search_DTC.best_estimator_,\n                                                X=X_train,\n                                                y=y_train,\n                                                cv=5)\npred_dtc_opt.columns = [\"y_true\", \"y_pred\"]","56942cb5":"fig = plt.figure(figsize=(18,6))\ngs = fig.add_gridspec(1,2)\nax1 = fig.add_subplot(gs[0, 0])\ndisp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(pred_dtc_opt[\"y_true\"], pred_dtc_opt[\"y_pred\"]))\ndisp.plot(cmap=\"Blues\", ax=ax1);\nax2 = fig.add_subplot(gs[0, 1])\nax2.spines['right'].set_visible(False)\nax2.spines['top'].set_visible(False)\nax2.spines['bottom'].set_visible(False)\nax2.spines['left'].set_visible(False)\nax2.set_xticklabels([])\nax2.set_yticklabels([])\n#\nax2.text(0.1, 0.6, 'Accuracy = '+ str(round(accuracy_score(pred_dtc_opt[\"y_true\"],\n                                                           pred_dtc_opt[\"y_pred\"])*100, 1)) + \"%\",\n         fontdict= {\"fontsize\":30});\n#\nax2.text(0.1, 0.4, 'Recall = '+ str(round(recall_score(pred_dtc_opt[\"y_true\"], \n                                                       pred_dtc_opt[\"y_pred\"])*100, 1)) + \"%\", \n         fontdict= {\"fontsize\":30});\n#\nax2.text(0.1, 0.2, 'Precision = '+ str(round(precision_score(pred_dtc_opt[\"y_true\"], \n                                                             pred_dtc_opt[\"y_pred\"])*100, 1)) + \"%\", \n         fontdict= {\"fontsize\":30});","c1b4794c":"grid_DTC_opt = {'classifier': [DecisionTreeClassifier()],\n                'classifier__criterion': [\"gini\", \"entropy\"],\n                'classifier__splitter': [\"best\", \"random\"],\n                'classifier__max_depth': stats.randint(1, 300),\n                'classifier__min_samples_split': stats.randint(2, 30),\n                'classifier__class_weight': [\"balanced\"],\n                \"preprocessor__scaler\": [RobustScaler()]\n                }\n\nsearch_DTC_opt = RandomizedSearchCV(final_pipe,\n                                    grid_DTC_opt,\n                                    scoring=\"recall\",\n                                    n_iter=20,\n                                    cv=5,\n                                    n_jobs=-1,\n                                    verbose=True)\nsearch_DTC_opt.fit(X_train, y_train);","caea6df7":"search_DTC_opt.best_params_","bcfcb6e9":"search_DTC_opt.best_score_","d87f6c13":"pred_dtc_opt_balanced = pd.DataFrame(y_train).copy()\npred_dtc_opt_balanced['predictions'] = cross_val_predict(estimator=search_DTC_opt.best_estimator_,\n                                                         X=X_train,\n                                                         y=y_train,\n                                                         cv=5)\npred_dtc_opt_balanced.columns = [\"y_true\", \"y_pred\"]","76a7779a":"fig = plt.figure(figsize=(18,6))\ngs = fig.add_gridspec(1,2)\nax1 = fig.add_subplot(gs[0, 0])\ndisp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(pred_dtc_opt_balanced[\"y_true\"], pred_dtc_opt_balanced[\"y_pred\"]))\ndisp.plot(cmap=\"Blues\", ax=ax1);\nax2 = fig.add_subplot(gs[0, 1])\nax2.spines['right'].set_visible(False)\nax2.spines['top'].set_visible(False)\nax2.spines['bottom'].set_visible(False)\nax2.spines['left'].set_visible(False)\nax2.set_xticklabels([])\nax2.set_yticklabels([])\n#\nax2.text(0.1, 0.6, 'Accuracy = '+ str(round(accuracy_score(pred_dtc_opt_balanced[\"y_true\"],\n                                                           pred_dtc_opt_balanced[\"y_pred\"])*100, 1)) + \"%\",\n         fontdict= {\"fontsize\":30});\n#\nax2.text(0.1, 0.4, 'Recall = '+ str(round(recall_score(pred_dtc_opt_balanced[\"y_true\"], \n                                                       pred_dtc_opt_balanced[\"y_pred\"])*100, 1)) + \"%\", \n         fontdict= {\"fontsize\":30});\n#\nax2.text(0.1, 0.2, 'Precision = '+ str(round(precision_score(pred_dtc_opt_balanced[\"y_true\"], \n                                                             pred_dtc_opt_balanced[\"y_pred\"])*100, 1)) + \"%\", \n         fontdict= {\"fontsize\":30});","1ca9b729":"log_model = search_DTC_opt.best_estimator_.fit(X_train, y_train)","6d5b65be":"permutation_score = permutation_importance(log_model, X_train, y_train, n_repeats=50)","6b89e96d":"importance_df = pd.DataFrame(np.vstack((X_train.columns, permutation_score.importances_mean)).T)","894a92cb":"importance_df.columns=['feature','score decrease']","758003eb":"importance_df.sort_values(by=\"score decrease\", ascending = False)","73b8f109":"X_reduced = X_train[[\"Humidity3pm\", \"WindGustSpeed\", \"Location\", \"Pressure9am\", \"MinTemp\"]]","0e2d3776":"cv_reduced_DTC = cross_validate(search_DTC_opt.best_estimator_, X_reduced, y_train, scoring= \"recall\", cv=2)\nprint(\"Reduced recall score for RandomForestClassifier: \" + str(round(cv_reduced_DTC[\"test_score\"].mean()*100, 2)) + \"%\")","b2cb09e0":"pred_dtc_opt_reduced = pd.DataFrame(y_train).copy()\npred_dtc_opt_reduced['predictions'] = cross_val_predict(estimator=search_DTC_opt.best_estimator_,\n                                                        X=X_reduced,\n                                                        y=y_train,\n                                                        cv=5)\npred_dtc_opt_reduced.columns = [\"y_true\", \"y_pred\"]","15011e46":"fig = plt.figure(figsize=(18,6))\ngs = fig.add_gridspec(1,2)\nax1 = fig.add_subplot(gs[0, 0])\ndisp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(pred_dtc_opt_reduced[\"y_true\"], pred_dtc_opt_reduced[\"y_pred\"]))\ndisp.plot(cmap=\"Blues\", ax=ax1);\nax2 = fig.add_subplot(gs[0, 1])\nax2.spines['right'].set_visible(False)\nax2.spines['top'].set_visible(False)\nax2.spines['bottom'].set_visible(False)\nax2.spines['left'].set_visible(False)\nax2.set_xticklabels([])\nax2.set_yticklabels([])\n#\nax2.text(0.1, 0.6, 'Accuracy = '+ str(round(accuracy_score(pred_dtc_opt_reduced[\"y_true\"],\n                                                           pred_dtc_opt_reduced[\"y_pred\"])*100, 1)) + \"%\",\n         fontdict= {\"fontsize\":30});\n#\nax2.text(0.1, 0.4, 'Recall = '+ str(round(recall_score(pred_dtc_opt_reduced[\"y_true\"], \n                                                       pred_dtc_opt_reduced[\"y_pred\"])*100, 1)) + \"%\", \n         fontdict= {\"fontsize\":30});\n#\nax2.text(0.1, 0.2, 'Precision = '+ str(round(precision_score(pred_dtc_opt_reduced[\"y_true\"], \n                                                             pred_dtc_opt_reduced[\"y_pred\"])*100, 1)) + \"%\", \n         fontdict= {\"fontsize\":30});","5f7383fa":"X_train_resampled = preprocessor.fit_transform(X_train)\npd.DataFrame(X_train_resampled).head()","d3a45df6":"''' Imbalanced Classes'''\nimport imblearn\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline as imPipe","f08c7ac0":"# Sampling strategies\nover = SMOTE(sampling_strategy=0.4)\nunder = RandomUnderSampler(sampling_strategy=0.7)","b78c607e":"# Pipelining the two strategies\nsteps =  [('o', over), ('u', under)]\nsampling_pipe = imPipe(steps=steps)\n\n\n# Rebalance the dataset\nX_resampled, y_resampled = sampling_pipe.fit_resample(X_train_resampled, y_train)","f4758195":"# plotting\nwarnings.filterwarnings('ignore')\nfig, ax = plt.subplots(1, 2, figsize=(18,4))\n\n''' Before rebalancing classes'''\n\nsns.countplot(y_train, ax=ax[0], color='b')\nax[0].set_title('Y before balancing', fontsize=14)\n\n''' After rebalancing classes'''\n\nsns.countplot(y_resampled, ax=ax[1], color='b')\nax[1].set_title('Y after balancing', fontsize=14);","0386ea6b":"resampled_classifier = DecisionTreeClassifier(class_weight='balanced',\n                                              max_depth=19,\n                                              min_samples_split=7, \n                                              splitter='random', \n                                              criterion=\"gini\")","3a7c33b6":"cv_resampled = cross_validate(resampled_classifier, X_resampled, y_resampled, scoring= \"recall\", cv=10)\nprint(\"Resampled dataset recall score for DTC: \" + str(round(cv_resampled[\"test_score\"].mean()*100, 2)) + \"%\")","a628b406":"cv_resampled = cross_validate(LogisticRegression(class_weight=\"balanced\", max_iter=10000), X_resampled, y_resampled, scoring= \"recall\", cv=10)\nprint(\"Resampled dataset recall score for DTC: \" + str(round(cv_resampled[\"test_score\"].mean()*100, 2)) + \"%\")","893626f0":"## 7.3. Pipelines","2b06ae3a":"# 1. Imports","590238fc":"### 7.3.5. Preprocessor pipeline\n<div style=\"font-weight:700\">Let's define <span style=\"color:green; font-variant:small-caps\">StandardScaler()<\/span> as the default scaler<\/div>","d9b64bad":"<div style=\"font-weight:700\">Loosing a bit of accuracy but greatly increasing the recall score.<\/div>","dd394281":"<div style=\"display: block; height:200px; overflow:hidden;position: relative\">\n     <img src=\"https:\/\/imgur.com\/cSyszHt.jpg\" style=\"position: absolute;top: -250px;\">\n<\/div>","6e49cc14":"#### 7.5.2.2. Best parameters for the best baseline model: DecisionTreeClassifier()\n<div style=\"font-weight:700\">Now what are the best parameters for DecisionTreeClassifier():<\/div>","e1a84151":"#### 7.5.2.1. Baseline model\n<div style=\"font-weight:700\">What is the model providing the best recall score with its default parameters ?<\/div>","215bf563":"### 7.3.3. Pipeline for multiclass features\n<div style=\"font-weight:700\">Let's define <span style=\"color:green; font-variant:small-caps\">most frequent<\/span> as the default impute strategy<\/div>","0adb8d10":"<div style=\"font-weight:700\">We remove features which have a high correlation coefficient ( above 0.9 or below -0.9 )<\/div>","02d00531":"### 7.5.2. Randomized search cv for an optimized model\n<div style=\"font-weight:700\">We want to see if we can increase the recall score to capture more of the minority class, that is to say days with rain tomorrow<\/div>","db4e35d1":"<div>The goal is to train a model that could predict rain tomorrow in Australia, for this analysis a simple LogisticRegression model is used.<\/div>\n<br>\n<b>\n<ol >\n    <li>\n        <b>Imports<\/b>\n    <\/li>\n    <li>\n        <b>Loading dataset<\/b>\n    <\/li>\n    <li>\n        <b>Check duplicates<\/b>\n    <\/li>\n    <li>\n        <b>Check missing values<\/b>\n    <\/li>\n    <li>\n        <b>Coordinates<\/b>\n    <\/li>\n    <li>\n        <b>Explore data<\/b>\n    <\/li>\n    <li>\n        <b>Training<\/b>\n    <\/li>\n<\/ol>","9b4470d8":"### 7.3.4. Impute and encode pipeline combination","cca6af54":"### 7.4.1. Baseline accuracy score","724055e2":"# 5. Coordinates\n<br\/>\n<div style=\"font-weight:700\">To retrieve correct coordinates with Nominatim, we need cities name to be correctly written<\/div>","e0e1dd08":"# 7. Training","fd1c18f8":"# 4. Check missing values\n<div style=\"font-weight:700\">Dropping features that have too many missing values<\/div>","50f63f42":"<div style=\"font-weight:700\">Let's remove features with more than 30% missing values:<\/div>\n<br\/>\n<div style=\"font-weight:700\">> <span style=\"color:royalblue\">Sunshine<\/span>, <span style=\"color:royalblue\">Evaporation<\/span>, <span style=\"color:royalblue\">Cloud3pm<\/span>, <span style=\"color:royalblue\">Cloud9am<\/span><\/div>","fd1371f6":"# 6. Explore data","4a296e7a":"### 7.5.4. Undersampling Majority target class \/ Oversampling Minority target class","17cf9ada":"### 7.3.2. Pipeline for binary features","183cefaa":"### 7.3.1. Pipeline for numeric features\n<div style=\"font-weight:700\">Let's define <span style=\"color:green; font-variant:small-caps\">mean<\/span> as the default impute strategy<\/div>","0eef8270":"<div style=\"font-weight:700\">Overview of the preprocessor pipeline output:<\/div>","9ad3368b":"## 7.2. Model inputs","4c249dfd":"# 2. Loading dataset","a979d8fd":"## 7.1. Clean data\n<div style=\"font-weight:700\">Let's first remove features we had for exploration and that won't be usefull then<\/div> <ul><li><span style=\"color:royalblue\">latitude<\/span>, <span style=\"color:royalblue\">longitude<\/span>: because we have the feature <span style=\"color:royalblue\">Location<\/span><\/li><li><span style=\"color:royalblue\">Date<\/span>: because we have the feature <span style=\"color:royalblue\">Month<\/span><\/li><\/ul>","f7801baf":"<div style=\"font-weight:700\">The output columns will be in the order of appearance in the ColumnTranformer pipe:<\/div>","8da4296a":"<div style=\"font-weight:700\">Let's see what is happening if we use the class_weight = balanced parameter<\/div>","df6d675f":"## 7.5. Model optimisation","78f13d35":"### 7.4.2. Baseline confusion matrix","73262843":"### 7.3.6. Final pipeline\n<div style=\"font-weight:700\">Let's add a baseline model - <span style=\"color:green; font-variant:small-caps\">LogisticRegression()<\/span> - to the pipeline as the default model<\/div>","43ad2d79":"### 7.5.3. Model simplification\n<div style=\"font-weight:700\">We remove features with low prediction score from permutation importance<\/div>","4719eab6":"## 7.4. Baseline performance with a LogisticRegression classifier","e57db449":"# 3. Check duplicates","a71910d7":"### 7.5.1. Pearson Correlation\n<div style=\"font-weight:700\">Let's see which features are redundants<\/div>","24747ee4":"<div style=\"text-align:center; font-size: 30pt; font-weight:700\">Rain in Australia<\/div>"}}