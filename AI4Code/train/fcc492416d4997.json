{"cell_type":{"23a1153b":"code","939d6a69":"code","a4c922bb":"code","7dea46ff":"code","7b7ef541":"code","8b826ad2":"code","470c481c":"code","69dbd103":"code","101a2705":"code","74cf423a":"markdown","7cc41cf5":"markdown","6976ed33":"markdown","93d8039b":"markdown","c72a34e0":"markdown"},"source":{"23a1153b":"import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\n%matplotlib inline","939d6a69":"#change to input directory\n!ls","a4c922bb":"data = np.genfromtxt('perceptron_toydata.txt', delimiter='\\t')\nX, y = data[:, :2], data[:, 2]\ny = y.astype(np.int)","7dea46ff":"print('Class label counts:', np.bincount(y))\nprint('X.shape:', X.shape)\nprint('y.shape:', y.shape)\n\n# Shuffling & train\/test split\nshuffle_idx = np.arange(y.shape[0])\nshuffle_rng = np.random.RandomState(123)\nshuffle_rng.shuffle(shuffle_idx)\nX, y = X[shuffle_idx], y[shuffle_idx]\n\nX_train, X_test = X[shuffle_idx[:70]], X[shuffle_idx[70:]]\ny_train, y_test = y[shuffle_idx[:70]], y[shuffle_idx[70:]]\n\n# Normalize (mean zero, unit variance)\nmu, sigma = X_train.mean(axis=0), X_train.std(axis=0)\nX_train = (X_train - mu) \/ sigma\nX_test = (X_test - mu) \/ sigma\n","7b7ef541":"plt.scatter(X_train[y_train==0, 0], X_train[y_train==0, 1], label='class 0', marker='o')\nplt.scatter(X_train[y_train==1, 0], X_train[y_train==1, 1], label='class 1', marker='s')\nplt.xlabel('feature 1')\nplt.ylabel('feature 2')\nplt.legend()\nplt.show()","8b826ad2":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n\ndef custom_where(cond, x_1, x_2):\n    return (cond * x_1) + ((~(cond)) * x_2)\n\n\nclass Perceptron():\n    def __init__(self, num_features):\n        self.num_features = num_features\n        self.weights = torch.zeros(num_features, 1,dtype=torch.float32, device=device)\n        self.bias = torch.zeros(1, dtype=torch.float32, device=device)\n\n    def forward(self, x):\n        linear = torch.add(torch.mm(x, self.weights), self.bias)\n        predictions = custom_where(linear > 0., 1, 0).float()\n        return predictions\n        \n    def backward(self, x, y):  \n        predictions = self.forward(x)\n        errors = y - predictions\n        return errors\n        \n    def train(self, x, y, epochs):\n        for e in range(epochs):\n            \n            for i in range(y.size()[0]):\n                # use view because backward expects a matrix (i.e., 2D tensor)\n                errors = self.backward(x[i].view(1, self.num_features), y[i]).view(-1)\n                self.weights += (errors * x[i]).view(self.num_features, 1)\n                self.bias += errors\n                \n    def evaluate(self, x, y):\n        predictions = self.forward(x).view(-1)\n        accuracy = torch.sum(predictions == y).float() \/ y.size()[0]\n        return accuracy\n","470c481c":"ppn = Perceptron(num_features=2)\n\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32, device=device)\ny_train_tensor = torch.tensor(y_train, dtype=torch.float32, device=device)\n\nppn.train(X_train_tensor, y_train_tensor, epochs=5)\n\nprint('Model parameters:')\nprint('  Weights: %s' % ppn.weights)\nprint('  Bias: %s' % ppn.bias)","69dbd103":"X_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=device)\ny_test_tensor = torch.tensor(y_test, dtype=torch.float32, device=device)\n\ntest_acc = ppn.evaluate(X_test_tensor, y_test_tensor)\nprint('Test set accuracy: %.2f%%' % (test_acc*100))","101a2705":"w, b = ppn.weights, ppn.bias\n\nx_min = -2\ny_min = ( (-(w[0] * x_min) - b[0]) \n          \/ w[1] )\n\nx_max = 2\ny_max = ( (-(w[0] * x_max) - b[0]) \n          \/ w[1] )\n\n\nfig, ax = plt.subplots(1, 2, sharex=True, figsize=(7, 3))\n\nax[0].plot([x_min, x_max], [y_min, y_max])\nax[1].plot([x_min, x_max], [y_min, y_max])\n\nax[0].scatter(X_train[y_train==0, 0], X_train[y_train==0, 1], label='class 0', marker='o')\nax[0].scatter(X_train[y_train==1, 0], X_train[y_train==1, 1], label='class 1', marker='s')\n\nax[1].scatter(X_test[y_test==0, 0], X_test[y_test==0, 1], label='class 0', marker='o')\nax[1].scatter(X_test[y_test==1, 0], X_test[y_test==1, 1], label='class 1', marker='s')\n\nax[1].legend(loc='upper left')\nplt.show()","74cf423a":"### Perceptron","7cc41cf5":"### Evaluate","6976ed33":"### Toy Dataset\n#### We create two columns for features and 1 column for labels","93d8039b":"### Import","c72a34e0":"### Train"}}