{"cell_type":{"8105c32f":"code","b3a44d47":"code","741e273b":"code","61ffa44a":"code","fd799ec2":"code","734a457e":"code","7c61b515":"code","7dd58120":"code","b5adceb1":"code","7396ab4a":"code","9091765f":"code","5d28c83a":"code","1e6812bc":"code","2cbfad3a":"code","f6a13410":"code","e6e62c56":"code","1a28ad0a":"code","a4acd3cf":"code","3da6f440":"code","b9b39fd0":"code","53d9f7c2":"code","f739ad06":"code","ca74b8cf":"code","a332d918":"code","013535dd":"code","76a527b9":"code","32f59fa4":"code","c32095f4":"code","426d2798":"code","e000e5ff":"code","8611747f":"code","ea920605":"code","92ae1e70":"code","7d63e74d":"code","77fb13bf":"code","46624f36":"code","225caad4":"code","e3514279":"code","8f1182ba":"code","9ea80cea":"code","b6d8f830":"code","17e14163":"code","b3374246":"code","3b7be839":"code","a4d009a4":"code","ce3753fc":"code","be7c20e9":"code","6e8ce03c":"code","6db36edc":"code","7793d77a":"code","56d2e031":"code","003edda4":"code","813a8acc":"code","4f99385a":"code","2bc63cad":"code","bd307f64":"code","0c71571a":"code","ed08ffff":"code","daf823a3":"markdown","3b817fda":"markdown","a098d52e":"markdown","05366dfe":"markdown","5648f586":"markdown"},"source":{"8105c32f":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b3a44d47":"# Imports\n\nimport pandas as pd\npd.options.mode.chained_assignment = None \nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression,RidgeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, ExtraTreesClassifier, StackingClassifier","741e273b":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain.head()","61ffa44a":"train.shape, test.shape","fd799ec2":"Survived = train['Survived']\ntrain_idx = train.index\ntest_idx = test.index","734a457e":"# Concating train, test into single df for easy transformations\ndata = pd.concat([train.iloc[:,2:],test.iloc[:,1:]],axis=0, sort=False)","7c61b515":"data.describe()","7dd58120":"data.info()","b5adceb1":"sns.set_style(\"whitegrid\")\nplt.figure(figsize=(10,5))\nsns.heatmap(data.isna(), yticklabels=False, cmap=\"YlGnBu\")\nsns.set\nplt.show()","7396ab4a":"data.drop('Cabin', axis=1, inplace=True) # Since Cabin has lots of missing data we will drop it instead of imputing it","9091765f":"data[data.Embarked.isna()]","5d28c83a":"data[data['Pclass']==1]['Embarked'].value_counts()","1e6812bc":"data.Embarked.replace({np.nan,\"S\"}, inplace=True)","2cbfad3a":"sns.barplot(data=data,x=data.groupby('Sex')['Age'].agg(np.mean).index, y=data.groupby('Sex')['Age'].agg(np.mean).values)","f6a13410":"data.groupby('Sex')['Age'].agg(np.mean)","e6e62c56":"sns.barplot(data=data,x=data.groupby('Pclass')['Age'].agg(np.mean).index, y=data.groupby('Pclass')['Age'].agg(np.mean).values)","1a28ad0a":"data.groupby('Pclass')['Age'].agg(np.mean)","a4acd3cf":"# Using the Pclass for filling nan in Age column\n\ndef fn(pclass,age):\n    if np.isnan(age):\n        if pclass == 1 :\n            return 39.08\n        elif pclass == 2 :\n            return 29.49\n        else:\n            return 24.81\n    else:\n        return age\n\ndata[\"Age\"] = data[['Pclass',\"Age\"]].apply(lambda x: fn(x['Pclass'],x['Age']),axis=1)","3da6f440":"data[data.Fare.isna()]","b9b39fd0":"sns.histplot(data.Fare,bins=30)","53d9f7c2":"data.groupby('Pclass')['Fare'].agg(np.mean)","f739ad06":"data.Fare.fillna(13.30, inplace=True)","ca74b8cf":"#Creating subset only for EDA\n\ndata_exp = data.iloc[:891]\ndata_exp['Survived'] = train.Survived","a332d918":"category_names = ['Survived','Not Survived']\nsize = [data_exp['Survived'].value_counts()[1],data_exp['Survived'].value_counts()[0]]\n\n# Pie chart \nplt.figure(figsize=(5,5), dpi=100)\nplt.pie(size, labels=category_names, textprops={'fontsize':16}, startangle=90, autopct='%1.1f%%',\n        explode=[0,0.05])\nplt.show()","013535dd":"data_exp.groupby('Sex')['Survived'].value_counts()","76a527b9":"data_exp.groupby('Survived')['Embarked'].value_counts()","32f59fa4":"data_exp.groupby('Survived')['Fare'].agg(['mean','min','max'])","c32095f4":"fig,ax = plt.subplots(nrows=1,ncols=2,figsize=(20,5))\nsns.barplot(x=data_exp.SibSp.value_counts().index, y=data_exp.SibSp.value_counts(), ax=ax[0]) \nax[0].set_title('SibSp')\nsns.barplot(x=data_exp.Parch.value_counts().index, y=data_exp.Parch.value_counts(), ax=ax[1])\nax[1].set_title('Parch')\nplt.show()","426d2798":"data['Family'] = data['SibSp']+data['Parch']\n#data.drop(['SibSp','Parch'], axis=1, inplace=True)","e000e5ff":"data_exp.groupby('Ticket')['Survived'].value_counts()","8611747f":"encoder = LabelEncoder()\ndata['Ticket'] = encoder.fit_transform(data['Ticket'])","ea920605":"data.Age = data.Age.astype('int64')","92ae1e70":"data = pd.concat([data,pd.get_dummies(data['Sex'], drop_first=True)],axis=1)\ndata.drop('Sex', axis=1,inplace=True)","7d63e74d":"data = pd.concat([data,pd.get_dummies(data['Embarked'])],axis=1)\ndata.drop('Embarked', axis=1,inplace=True)","77fb13bf":"data['Pclass'] = data['Pclass'].astype('object') ","46624f36":"data = pd.concat([data,pd.get_dummies(data['Pclass'])],axis=1)\ndata.drop('Pclass', axis=1,inplace=True)","225caad4":"# Extracting only title for each person\ndata['Title'] = data.Name.apply(lambda x: x.split(\" \")[1])","e3514279":"def titles(title,male):\n    if title not in ['Mr.','Miss.','Mrs.','Master.','Rev.','Dr.']:\n        if male == 1:\n            return \"Mr.\"\n        else:\n            return \"Miss.\/Mrs.\"\n    else:\n        return title\n        \ndata['Title'] = data[['Title','male']].apply(lambda x : titles(x['Title'],x['male']),axis=1)","8f1182ba":"data.drop('Name', axis=1, inplace=True)","9ea80cea":"data = pd.concat([data,pd.get_dummies(data['Title'])],axis=1)\ndata.drop('Title', axis=1,inplace=True)","b6d8f830":"sns.histplot(data.Age)","17e14163":"scalar = MinMaxScaler()\ndata[['Age','Fare']] = scalar.fit_transform(data[['Age','Fare']])","b3374246":"data.head()","3b7be839":"train_set = data.iloc[:891,]\ntest_set = data.iloc[891:,]","a4d009a4":"train_set.shape, test_set.shape","ce3753fc":"model_result = pd.DataFrame(columns=['Model','Score','Parameters'])","be7c20e9":"cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)","6e8ce03c":"model = LogisticRegression()\n\nsolvers = ['newton-cg', 'lbfgs', 'liblinear']\npenalty = ['l1','l2','elasticnet']\nc_values = [14,15,16]\n\ngrid = dict(solver=solvers,penalty=penalty,C=c_values)\n\ngrid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\ngrid_result = grid_search.fit(train_set, Survived)\n\n\nmodel_result = model_result.append({'Model':'Logistic','Score':grid_result.best_score_, 'Parameters':grid_result.best_params_}, ignore_index=True)\nprint(\"Logistic Regression Best score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n\nlogistic_submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nlogistic_submission.Survived = grid_result.best_estimator_.predict(test_set)\nlogistic_submission.to_csv('logistic_submission.csv', index=False)","6db36edc":"model = RidgeClassifier()\n\nalpha = [1.13,1.15,1.18]\ngrid = dict(alpha=alpha)\n\ngrid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\ngrid_result = grid_search.fit(train_set, Survived)\n\n# summarize results\nmodel_result = model_result.append({'Model':'Ridge','Score':grid_result.best_score_, 'Parameters':grid_result.best_params_}, ignore_index=True)\nprint(\"Ridge Regression Best score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n\n\nRidge_submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nRidge_submission.Survived = grid_result.best_estimator_.predict(test_set)\nRidge_submission.to_csv('Ridge_submission.csv', index=False)","7793d77a":"model = KNeighborsClassifier()\n\nn_neighbors = range(15, 21)\nweights = ['uniform', 'distance']\nmetric = ['euclidean', 'manhattan', 'minkowski']\n\ngrid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n\ngrid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\ngrid_result = grid_search.fit(train_set, Survived)\n\nmodel_result = model_result.append({'Model':'KNeighbors','Score':grid_result.best_score_, 'Parameters':grid_result.best_params_}, ignore_index=True)\nprint(\"KNeighbors Regression Best score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n\n\nKNeighbors_submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nKNeighbors_submission.Survived = grid_result.best_estimator_.predict(test_set)\nKNeighbors_submission.to_csv('KNeighbors_submission.csv', index=False)","56d2e031":"model = RandomForestClassifier()\n\nn_estimators = [1000]\nmax_features = ['sqrt', 'log2']\n\ngrid = dict(n_estimators=n_estimators,max_features=max_features)\n\ngrid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\ngrid_result = grid_search.fit(train_set, Survived)\n\nmodel_result = model_result.append({'Model':'RandomForest','Score':grid_result.best_score_, 'Parameters':grid_result.best_params_}, ignore_index=True)\nprint(\"RandomForest Regression Best score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n\n\nRandomForest_submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nRandomForest_submission.Survived = grid_result.best_estimator_.predict(test_set)\nRandomForest_submission.to_csv('RandomForest_submission.csv', index=False)","003edda4":"model = BaggingClassifier()\n\nn_estimators = [1550,1750]\ngrid = dict(n_estimators=n_estimators)\n\ngrid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\ngrid_result = grid_search.fit(train_set, Survived)\n\nmodel_result = model_result.append({'Model':'BaggingClassifier','Score':grid_result.best_score_, 'Parameters':grid_result.best_params_}, ignore_index=True)\nprint(\"BaggingClassifier Regression Best score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n\n\nBaggingClassifier_submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nBaggingClassifier_submission.Survived = grid_result.best_estimator_.predict(test_set)\nBaggingClassifier_submission.to_csv('BaggingClassifier_submission.csv', index=False)","813a8acc":"plt.figure(figsize=(10,5))\ng = sns.barplot(x='Model', y='Score', data=model_result)\n\nfor index, row in model_result.iterrows():\n    g.text(row.name,row.Score, round(row.Score*100,2), color='black', ha=\"center\")\nplt.show()","4f99385a":"model_result","2bc63cad":"# define base learner models\nlevel0 = list()\nlevel0.append(('rd', RidgeClassifier(alpha= 1.18)))\nlevel0.append(('knn',KNeighborsClassifier(metric= 'manhattan', n_neighbors=15,weights='distance')))\nlevel0.append(('rf', RandomForestClassifier(max_features='log2', n_estimators= 1000)))\nlevel0.append(('bc', BaggingClassifier(n_estimators= 1750)))\nlevel0.append(('gb', GradientBoostingClassifier(learning_rate=0.01,max_depth=3, n_estimators=1000,subsample=0.7)))\n# define meta learner model\nlevel1 = LogisticRegression(C=14, penalty='l2',solver= 'liblinear')","bd307f64":"stacking_clf = StackingClassifier(estimators=level0, final_estimator=level1,n_jobs=-1)","0c71571a":"stacking_clf.fit(train_set,Survived)","ed08ffff":"Stacking_submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nStacking_submission.Survived = stacking_clf.predict(test_set)\nStacking_submission.to_csv('Stacking_submission.csv', index=False)","daf823a3":"#### Transforming data suitable for model fitting","3b817fda":"The notebook walks us through the workflow for using machine learning to create a best model that predicts which passengers survived the \nTitanic shipwreck.\n\nEnsemble method : **Stacking**\n\nBase Learners : \n* 1) RidgeClassifier\n* 2) KNeighborsClassifier\n* 3) RandomForestClassifier\n* 4) BaggingClassifier\n\nMeta Learner   : **Logistic Regression**","a098d52e":"#### Dealing with Missing values & EDA","05366dfe":"#### Model Fitting","5648f586":"#### Stacking Classifier"}}