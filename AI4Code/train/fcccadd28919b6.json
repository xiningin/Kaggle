{"cell_type":{"62f1d3f5":"code","da1021e9":"code","ed9d301e":"code","0692da32":"code","61177e0f":"code","cbb819ca":"code","721c5205":"code","7134af60":"code","c4cb4404":"code","f0c50d10":"code","0a587020":"code","bbb40deb":"code","0003ac64":"code","324245ee":"code","972021f8":"code","c22aa30c":"code","f55ed01a":"code","65610e12":"code","a311b4e5":"code","c93bc7e5":"code","9e4660ff":"code","2d39f21f":"code","8d4a21b5":"code","9a9000d0":"code","1d81069f":"code","d978eca5":"markdown","222d798f":"markdown","c09b19dc":"markdown","7bc7d517":"markdown","e25d4e5b":"markdown","3fc60bd8":"markdown","a3832c7e":"markdown","80d70dfe":"markdown","f9ace109":"markdown","6de3a808":"markdown","991c247d":"markdown","15c97c98":"markdown","f2929248":"markdown","61144628":"markdown"},"source":{"62f1d3f5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","da1021e9":"# importing Important Liberaries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport pandas_profiling as pp","ed9d301e":"# Loading data\ndf = pd.read_csv('\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndf","0692da32":"# getting shape of data\ndf.shape","61177e0f":"# Getting Data Types\ndf.info()","cbb819ca":"# Checking null values\ndf.isnull().sum()","721c5205":"# Statistical Analysis\ndf.describe().T","7134af60":"def hist_count(column, data):\n    if column in data:\n        f, axes = plt.subplots(1,1,figsize=(15,5))\n        sns.countplot(x=column, data=data)\n        plt.xticks(rotation = 90)\n        plt.suptitle(column, fontsize=20)\n        plt.show()\n    plt.show()","c4cb4404":"for column in df.columns:\n    hist_count(column,df)","f0c50d10":"#Pregnencies vs Outcome\nfig = px.histogram(df, x = df['Pregnancies'], color = 'Outcome')\nfig.show()\nfig2 = px.box(df, x = df['Pregnancies'], color = 'Outcome')\nfig2.show()","0a587020":"#Glucose vs Outcome\nfig = px.histogram(df, x = df['Glucose'], color = 'Outcome')\nfig.show()\nfig2 = px.box(df, x = df['Glucose'], color = 'Outcome')\nfig2.show()","bbb40deb":"#BloodPressure vs Outcome\nfig = px.histogram(df, x = df['BloodPressure'], color = 'Outcome')\nfig.show()\nfig2 = px.box(df, x = df['BloodPressure'], color = 'Outcome')\nfig2.show()","0003ac64":"#SkinThickness vs Outcome\nfig = px.histogram(df, x = df['SkinThickness'], color = 'Outcome')\nfig.show()\nfig2 = px.box(df, x = df['SkinThickness'], color = 'Outcome')\nfig2.show()","324245ee":"#Insulin vs Outcome\nfig = px.histogram(df, x = df['Insulin'], color = 'Outcome')\nfig.show()\nfig2 = px.box(df, x = df['Insulin'], color = 'Outcome')\nfig2.show()","972021f8":"#BMI vs Outcome\nfig = px.histogram(df, x = df['BMI'], color = 'Outcome')\nfig.show()\nfig2 = px.box(df, x = df['BMI'], color = 'Outcome')\nfig2.show()","c22aa30c":"# DiabetesPedigreeFunction andd Outcome\nfig = px.histogram(df, x = df['DiabetesPedigreeFunction'], color = 'Outcome')\nfig.show()\nfig2 = px.box(df, x = df['DiabetesPedigreeFunction'], color = 'Outcome')\nfig2.show()","f55ed01a":"# Age andd Outcome\nfig = px.histogram(df, x = df['Age'], color = 'Outcome')\nfig.show()\nfig2 = px.box(df, x = df['Age'], color = 'Outcome')\nfig2.show()","65610e12":"fig = px.line(df)\nfig.show()","a311b4e5":"#Correlation Matrix\nsns.heatmap(df.corr(), annot = True, cmap = 'magma_r');","c93bc7e5":"# pairploting\nsns.pairplot(df, hue=\"Outcome\", palette=\"viridis\");","9e4660ff":"profile = pp.ProfileReport(df, title = \"Pima Diabetes EDA\")\nprofile","2d39f21f":"#getting features \nfeatures = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI', 'DiabetesPedigreeFunction', 'Age']\nx = pd.get_dummies(df[features])\n\n# Getting Predicting Value\ny = df['Outcome']","8d4a21b5":"# Splitting Training and Testing data\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 1\/11, random_state = 242)","9a9000d0":"def Classification_models(x,y,xt,yt):\n    # Importing All LIberaries\n    from sklearn.metrics import accuracy_score\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n    from sklearn.naive_bayes import GaussianNB\n    from sklearn.tree import DecisionTreeClassifier\n    from sklearn.ensemble import RandomForestClassifier\n    from sklearn import svm\n    from sklearn.neighbors import KNeighborsClassifier\n\n    # Initializing models\n    logisreg = LogisticRegression()\n    lda = LinearDiscriminantAnalysis()\n    gnb = GaussianNB()\n    dtc = DecisionTreeClassifier()\n    rfc = RandomForestClassifier()\n    svmodel = svm.SVC()\n    knnmodel = KNeighborsClassifier()\n    \n    # Fitting Models\n    logisreg.fit(x,y)\n    lda.fit(x,y)\n    gnb.fit(x,y)\n    dtc.fit(x,y)\n    rfc.fit(x,y)\n    svmodel.fit(x,y)\n    knnmodel.fit(x,y)\n    \n    # Getting PRedicting Values\n    logi_pred = logisreg.predict(xt)\n    lda_pred = lda.predict(xt)\n    gnb_pred = gnb.predict(xt)\n    dtc_pred = dtc.predict(xt)\n    rfc_pred = rfc.predict(xt)\n    svm_pred = svmodel.predict(xt)\n    knn_pred = knnmodel.predict(xt)\n    \n    # Getting Accuracy Score\n    acc_logisreg = accuracy_score(yt, logi_pred)\n    acc_lda = accuracy_score(yt, lda_pred)\n    acc_ganb = accuracy_score(yt, gnb_pred)\n    acc_dtree = accuracy_score(yt, dtc_pred)\n    acc_rf = accuracy_score(yt, rfc_pred)\n    acc_svc = accuracy_score(yt, svm_pred)\n    acc_knn = accuracy_score(yt, knn_pred)\n    \n    # MOdel Selection\n    models = pd.DataFrame({\n    'Model': ['Logistic Regression','Linear Discriminant Analysis','Naive Bayes', 'Decision Tree', 'Random Forest', 'Support Vector Machines', \n              'K - Nearest Neighbors'],\n    'Score': [acc_logisreg, acc_lda, acc_ganb, acc_dtree, acc_rf, acc_svc, acc_knn]})\n\n    print(models.sort_values(by='Score', ascending=False))\n    sns.barplot(x = models['Score'], y = models['Model'], palette='viridis');","1d81069f":"Classification_models(x_train, y_train, x_test, y_test)","d978eca5":"# ***EDA and Data VIsualization***","222d798f":"***BMI and Outcome***","c09b19dc":"# Data Modeling","7bc7d517":"# ***Basic Classification Models***","e25d4e5b":"***Pandas Profiling***","3fc60bd8":"# Summary \n* **Linear Discriminent Analysis** has the Accuracy of exactly **90.00%**.\n* **Logistic Regression** was just behind it with the accuracy of **88.57%**","a3832c7e":"***SkinThickness and Outcome***","80d70dfe":"***Pregnencies And Outcome***","f9ace109":"***Blood Pressure And Outcome***","6de3a808":"***Age and Outcome***","991c247d":"***Insulin And Outcome***","15c97c98":"***Glucose and Outcome***","f2929248":"***Dont forgot to upvote and please give your feedback***","61144628":"***DiabetesPedigreeFunction and Outcome***"}}