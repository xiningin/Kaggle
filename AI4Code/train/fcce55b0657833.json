{"cell_type":{"fa86fd42":"code","d549186a":"code","5ad192af":"code","ec02cad4":"code","6690051e":"code","bb8925e0":"code","d827409d":"code","5fbafd43":"code","c4553327":"code","8709864c":"code","2ab65378":"markdown","ae5fbf60":"markdown","131569c9":"markdown","00de258e":"markdown","1a7cf007":"markdown","ed06a7fd":"markdown","6147dce6":"markdown","c7061526":"markdown","72abccc7":"markdown","34d59409":"markdown"},"source":{"fa86fd42":"import numpy as np\nimport pandas as pd\ntrain_data = pd.read_csv(\"\/kaggle\/input\/adult-pmr3508\/train_data.csv\", index_col=['Id'], na_values=\"?\")\ntrain_data.head()","d549186a":"train_analise = train_data.copy()\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain_analise['income'] = le.fit_transform(train_analise['income'])\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nvariavel_num = [\"age\", \"fnlwgt\", \"education.num\", \"capital.gain\", \"capital.loss\", \"hours.per.week\"]\nfor n in variavel_num:\n    sns.catplot(x=\"income\", y=n, kind=\"boxen\", data=train_analise)","5ad192af":"train_analise.describe()","ec02cad4":"variavel_cat = [\"workclass\", \"education\", \"marital.status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native.country\"]\nfor n in variavel_cat:\n    sns.catplot(y=n, x=\"income\", kind=\"bar\", data=train_analise)","6690051e":"train_data = train_data.drop(columns=['fnlwgt', 'native.country'])\nvar_classe = train_data.pop('income')","bb8925e0":"var_num = list(train_data.select_dtypes(include=[np.number]).columns.values)\nvar_num.remove('capital.gain')\nvar_num.remove('capital.loss')\n\nvar_esp = ['capital.gain', 'capital.loss']\n\nvar_cat = list(train_data.select_dtypes(exclude=[np.number]).columns.values)","d827409d":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import KNNImputer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\n\nnum_pipe = Pipeline(steps = [\n    ('imputer', KNNImputer(n_neighbors=15, weights=\"uniform\")),\n    ('scaler', StandardScaler())\n])\n\nesp_pipe = Pipeline(steps = [\n    ('imputer', KNNImputer(n_neighbors=15, weights=\"uniform\")),\n    ('scaler', RobustScaler())\n])\n\ncat_pipe = Pipeline(steps = [\n    ('imputer', SimpleImputer(strategy = 'most_frequent')),\n    ('onehot', OneHotEncoder(drop='if_binary'))\n])\n\npreprocessador = ColumnTransformer(transformers = [\n    ('num', num_pipe, var_num),\n    ('spr', esp_pipe, var_esp),\n    ('cat', cat_pipe, var_cat)\n])\n\ntrain_data = preprocessador.fit_transform(train_data)","5fbafd43":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nvizinhos = [10,15,20,25,30]\nmaior = 0\nparametro = 0\nfor k in vizinhos:\n    score = cross_val_score(KNeighborsClassifier(n_neighbors=k), train_data, var_classe, cv = 5, scoring=\"accuracy\").mean()\n    if score > maior:\n        maior = score\n        parametro =k\nprint(\"Melhor par\u00e2metro:\",parametro)\nprint(\"Maior pontua\u00e7\u00e3o:\",maior)\n        ","c4553327":"knn = KNeighborsClassifier(n_neighbors=20)\nknn.fit(train_data,var_classe)\n\ntest_data = pd.read_csv(\"\/kaggle\/input\/adult-pmr3508\/test_data.csv\", index_col=['Id'], na_values=\"?\")\nteste = test_data.drop(columns=['fnlwgt', 'native.country'])\nteste = preprocessador.transform(teste)\n\npredicao = knn.predict(teste)","8709864c":"submission = pd.DataFrame()\nsubmission[0] = test_data.index\nsubmission[1] = predicao\nsubmission.columns = ['Id','income']\nsubmission.to_csv('submission.csv',index = False)","2ab65378":"\u00c9 poss\u00edvel observar de primeira vista a presen\u00e7a de 13 vari\u00e1veis independentes e uma de classe, \"income\". A predi\u00e7\u00e3o ser\u00e1 sobre essa vari\u00e1vel de classe.\n\nPara preparar os dados para a implementa\u00e7\u00e3o do kNN de fato, antes \u00e9 necess\u00e1rio fazer uma an\u00e1lise um pouco mais detalhada de cada uma das vari\u00e1veis independentes, a fim de poder prepar\u00e1-las de maneira adequada.\n\nModificaremos agora, com o uso da biblioteca sklearn, os valores da vari\u00e1vel \"income\", que indica renda anual inferior ou superior a 50k, para simplesmente 0 ou 1, facilitando o processamento. Depois, ser\u00e3o montados gr\u00e1ficos comparando cada vari\u00e1vel num\u00e9rica com \"income\", buscando assim interpretar a rela\u00e7\u00e3o entre as duas.\n\nPara isso, faremos uma c\u00f3pia da nossa base de dados a fim de poder modific\u00e1-la para a visualiza\u00e7\u00e3o, e importaremos duas novas bibliotecas, *matplotlib* e *seaborn*.\n\n","ae5fbf60":"Enfim, faremos a prepara\u00e7\u00e3o dos dados restantes, subdividindo antes as vari\u00e1veis em num\u00e9ricas, categ\u00f3ricas e esparsas.","131569c9":"No geral, as vari\u00e1veis categ\u00f3ricas apresentam uma rela\u00e7\u00e3o clara com a renda anual. No entanto, a vari\u00e1vel \"native.country\", que indica a nacionalidade, apresenta um grande varia\u00e7\u00e3o. Isso ocorre principalmente pois a grande maioria dos indiv\u00edduos dos dados s\u00e3o estadunidenses e poucos s\u00e3o de outras nacionalidades. Isso \u00e9 percept\u00edvel comparando-se a varia\u00e7\u00e3o dos valores para o elemento \"United States\" com os outros. Como a amostra \u00e9 maior, a varia\u00e7\u00e3o diminui. Assim, essa vari\u00e1vel tamb\u00e9m ser\u00e1 descartada para a predi\u00e7\u00e3o.\n\nFeita essa an\u00e1lise, podemos remover as vari\u00e1veis consideradas irrelevantes e separar a vari\u00e1vel de classe do restante para preparar os dados em seguida.\n","00de258e":"Agora submetendo os resultados no Kaggle:","1a7cf007":"Pelo mesmo processo, visualizaremos agora as vari\u00e1veis categ\u00f3ricas:","ed06a7fd":"Para preparar os dados agora divididos, faremos pipelines para cada categoria, preenchendo dados faltantes e padronizando-as para serem interpretados corretamente depois. Para isso, ser\u00e1 utilizado o KNNImputer com 15 vizinhos para preencher os dados num\u00e9ricos faltantes e o SimpleImputer com a estrat\u00e9gia \"most_frequent\" para preencher os dados categ\u00f3ricos faltantes, e o StandardScaler para normalizar os dados num\u00e9ricos, RobustScaler para normalizar os dados esparsos, e o OneHotEnconder para transformar as vari\u00e1veis categ\u00f3ricas em bin\u00e1rias para a interpreta\u00e7\u00e3o.\n\nEm seguida, faremos um transformador com as pipelines, o ColumnTransformer, que as aplicar\u00e1 para as colunas adequadas do dataset.","6147dce6":"Feita a limpeza e prepara\u00e7\u00e3o dos dados, agora podemos aplicar o classificador kNN sobre os dados para realizar a predi\u00e7\u00e3o. Definiremos o melhor hiperpar\u00e2metro realizando testes com alguns valores de k entre 10 e 30 por meio da valida\u00e7\u00e3o cruzada e calculando a m\u00e9dia de acur\u00e1cia para cada caso.","c7061526":"**PMR3508 - Aprendizado de M\u00e1quina e Conhecimento de Padr\u00f5es**\n\nImplementando kNN no dataset Adult\n\nDaniel Pascotto Costa\n\nCome\u00e7aremos:\n\n* Importando as bibliotecas *numpy* e *pandas*\n* Importando os dados de treino, especificando a coluna \"Id\" como \u00edndice e os dados \"?\" comos faltantes\n* Realizando uma primeira verifica\u00e7\u00e3o visual dos dados\n","72abccc7":"O melhor par\u00e2metro encontrado foi 20, com uma pontua\u00e7\u00e3o de aproximadamente 0,87. Com isso, podemos agora criar nosso kNN com os dados de treino, preparar os dados de teste e por fim realizar a predi\u00e7\u00e3o com o dataset preparado.","34d59409":"Pela distribui\u00e7\u00e3o das vari\u00e1veis em cada gr\u00e1fico, j\u00e1 \u00e9 poss\u00edvel descartar a vari\u00e1vel \"fnlwgt\", visto que n\u00e3o h\u00e1 diferen\u00e7a aparente em sua distribui\u00e7\u00e3o para os casos que a renda \u00e9 maior ou menor que 50k.\n\nDe resto, \u00e9 poss\u00edvel perceber uma clara diferen\u00e7a de renda conforme se aumenta a idade da popula\u00e7\u00e3o observada, assim como um aumento com o n\u00edvel de educa\u00e7\u00e3o, com os ganhos e perdas de capital, e com a quantidade de horas de trabalho semanais. No entanto, as vari\u00e1veis \"capital.gain\" e \"capital.loss\" t\u00eam uma distribui\u00e7\u00e3o esparsa comparada com o restante.\n\nObservando as descri\u00e7\u00f5es gerais dos dados, isso fica mais evidente:\n"}}