{"cell_type":{"ee6bbe53":"code","831e843f":"code","8de54874":"code","c8d1e164":"code","8d47aeef":"code","a8f653b6":"code","84665656":"code","f0cad9f2":"code","f620280a":"code","5ebcaf6f":"code","b7de0b99":"code","48054460":"code","f561ab62":"code","49b51649":"code","0bd52811":"code","7ec7c33b":"code","044d7491":"code","c1e6e04c":"code","7a43d15d":"code","3dcc53a5":"code","ae03f0f6":"code","331bf2c5":"code","ce44979a":"code","0fc425a2":"code","69b4400e":"code","a8f8d30a":"code","2ff76e5b":"code","89cdc0c1":"code","6ed24d63":"code","351d9902":"code","3254d152":"code","b2baf9a3":"code","1a4db754":"code","1de83a8a":"code","36226d7b":"code","8b8e0ba7":"code","26606df7":"code","40649f7c":"code","d5548d21":"code","d852ebdb":"code","4b1271f0":"code","f249b848":"code","a28c6d62":"code","1bf67207":"code","dba90577":"code","23425ec3":"code","0cd3bd31":"code","403163d0":"code","3e7b0e36":"code","d6429323":"code","6c9db0db":"code","c5bed57d":"code","8e148a9f":"code","0dedfd3b":"code","724d12b9":"code","46529fca":"markdown","472ef5fd":"markdown","1cea1593":"markdown"},"source":{"ee6bbe53":"!pip install console_progressbar","831e843f":"# This preprocessing portion of the code is provided by foamliu on his github repo\n# https:\/\/github.com\/foamliu\/Car-Recognition\/blob\/master\/pre-process.py\n\nimport tarfile\nimport scipy.io\nimport numpy as np\nimport os\nimport cv2 as cv\nimport shutil\nimport random\nfrom console_progressbar import ProgressBar","8de54874":"def ensure_folder(folder):\n    if not os.path.exists(folder):\n        os.makedirs(folder)","c8d1e164":"def save_train_data(fnames, labels, bboxes):\n    src_folder ='..\/input\/stanford-cars-dataset\/cars_train\/cars_train\/'\n    num_samples = len(fnames)\n\n    train_split = 0.8\n    num_train = int(round(num_samples * train_split))\n    train_indexes = random.sample(range(num_samples), num_train)\n\n    pb = ProgressBar(total=100, prefix='Save train data', suffix='', decimals=3, length=50, fill='=')\n\n    for i in range(num_samples):\n        fname = fnames[i]\n        label = labels[i]\n        (x1, y1, x2, y2) = bboxes[i]\n\n        src_path = os.path.join(src_folder, fname)\n        src_image = cv.imread(src_path)\n        height, width = src_image.shape[:2]\n        # margins of 16 pixels\n        margin = 16\n        x1 = max(0, x1 - margin)\n        y1 = max(0, y1 - margin)\n        x2 = min(x2 + margin, width)\n        y2 = min(y2 + margin, height)\n        # print(\"{} -> {}\".format(fname, label))\n        pb.print_progress_bar((i + 1) * 100 \/ num_samples)\n\n        if i in train_indexes:\n            dst_folder = '\/kaggle\/working\/data\/train\/'\n        else:\n            dst_folder = '\/kaggle\/working\/data\/valid\/'\n\n        dst_path = os.path.join(dst_folder, label)\n        if not os.path.exists(dst_path):\n            os.makedirs(dst_path)\n        dst_path = os.path.join(dst_path, fname)\n\n        crop_image = src_image[y1:y2, x1:x2]\n        dst_img = cv.resize(src=crop_image, dsize=(img_height, img_width))\n        cv.imwrite(dst_path, dst_img)","8d47aeef":"def save_test_data(fnames, bboxes):\n    src_folder = '..\/input\/stanford-cars-dataset\/cars_test\/cars_test\/'\n    dst_folder = '\/kaggle\/working\/data\/test\/'\n    num_samples = len(fnames)\n\n    pb = ProgressBar(total=100, prefix='Save test data', suffix='', decimals=3, length=50, fill='=')\n\n    for i in range(num_samples):\n        fname = fnames[i]\n        (x1, y1, x2, y2) = bboxes[i]\n        src_path = os.path.join(src_folder, fname)\n        src_image = cv.imread(src_path)\n        height, width = src_image.shape[:2]\n        # margins of 16 pixels\n        margin = 16\n        x1 = max(0, x1 - margin)\n        y1 = max(0, y1 - margin)\n        x2 = min(x2 + margin, width)\n        y2 = min(y2 + margin, height)\n        # print(fname)\n        pb.print_progress_bar((i + 1) * 100 \/ num_samples)\n\n        dst_path = os.path.join(dst_folder, fname)\n        crop_image = src_image[y1:y2, x1:x2]\n        dst_img = cv.resize(src=crop_image, dsize=(img_height, img_width))\n        cv.imwrite(dst_path, dst_img)","a8f653b6":"def process_train_data():\n    print(\"Processing train data...\")\n    cars_annos = scipy.io.loadmat('..\/input\/cars-devkit\/cars_train_annos.mat')\n    annotations = cars_annos['annotations']\n    annotations = np.transpose(annotations)\n\n    fnames = []\n    class_ids = []\n    bboxes = []\n    labels = []\n\n    for annotation in annotations:\n        bbox_x1 = annotation[0][0][0][0]\n        bbox_y1 = annotation[0][1][0][0]\n        bbox_x2 = annotation[0][2][0][0]\n        bbox_y2 = annotation[0][3][0][0]\n        class_id = annotation[0][4][0][0]\n        labels.append('%04d' % (class_id,))\n        fname = annotation[0][5][0]\n        bboxes.append((bbox_x1, bbox_y1, bbox_x2, bbox_y2))\n        class_ids.append(class_id)\n        fnames.append(fname)\n\n    labels_count = np.unique(class_ids).shape[0]\n    print(np.unique(class_ids))\n    print('The number of different cars is %d' % labels_count)\n\n    save_train_data(fnames, labels, bboxes)","84665656":"def process_test_data():\n    print(\"Processing test data...\")\n    cars_annos = scipy.io.loadmat('..\/input\/cars-devkit\/cars_test_annos.mat')\n    annotations = cars_annos['annotations']\n    annotations = np.transpose(annotations)\n\n    fnames = []\n    bboxes = []\n\n    for annotation in annotations:\n        bbox_x1 = annotation[0][0][0][0]\n        bbox_y1 = annotation[0][1][0][0]\n        bbox_x2 = annotation[0][2][0][0]\n        bbox_y2 = annotation[0][3][0][0]\n        fname = annotation[0][4][0]\n        bboxes.append((bbox_x1, bbox_y1, bbox_x2, bbox_y2))\n        fnames.append(fname)\n\n    save_test_data(fnames, bboxes)","f0cad9f2":"img_width, img_height = 224, 224\n\ncars_meta = scipy.io.loadmat('..\/input\/cars-devkit\/cars_meta.mat')\nclass_names = cars_meta['class_names']  # shape=(1, 196)\nclass_names = np.transpose(class_names)\nprint('class_names.shape: ' + str(class_names.shape))\nprint('Sample class_name: [{}]'.format(class_names[8][0][0]))\n\nensure_folder('\/kaggle\/working\/data\/train')\nensure_folder('\/kaggle\/working\/data\/valid')\nensure_folder('\/kaggle\/working\/data\/test')\n\nprocess_train_data()\nprocess_test_data()","f620280a":"import torchvision\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate\nfrom fastai import *\nimport cv2 as cv\nimport numpy as np\nimport pandas as pd\nimport scipy.io as sio","5ebcaf6f":"tfms = get_transforms(do_flip=True, flip_vert=False, max_lighting=0.1, max_zoom=1.05,\n                      max_warp=0.,\n                      xtra_tfms=[rand_crop(), rand_zoom(1, 1.5),\n                                 symmetric_warp(magnitude=(-0.2, 0.2))])\n\ndata = ImageDataBunch.from_folder('data\/','train','valid',\n                                  ds_tfms=tfms\n                                  ,size=128,bs=64).normalize(imagenet_stats)","b7de0b99":"data.show_batch(rows=3, figsize=(12,9))","48054460":"# class names and number of classes\n# print(data.classes)\nlen(data.classes),data.c","f561ab62":"!pip install pretrainedmodels\nimport pretrainedmodels","49b51649":"from torch import nn\nimport torch.nn.functional as F\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1., gamma=2.):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, inputs, targets, **kwargs):\n        CE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n        pt = torch.exp(-CE_loss)\n        F_loss = self.alpha * ((1-pt)**self.gamma) * CE_loss\n        return F_loss.mean()","0bd52811":"def se_resnext50_32x4d(pretrained=False):\n    pretrained = 'imagenet' if pretrained else None\n    model = pretrainedmodels.se_resnext50_32x4d(pretrained=pretrained)\n    return nn.Sequential(*list(model.children()))","7ec7c33b":"learn = cnn_learner(data, se_resnext50_32x4d, pretrained=True, cut=-2,\n                    split_on=lambda m: (m[0][3], m[1]), \n                    metrics=[accuracy])\nlearn.loss_fn = FocalLoss()","044d7491":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","c1e6e04c":"learn.fit_one_cycle(32, max_lr=slice(2e-2), wd=1e-5)","7a43d15d":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","3dcc53a5":"learn.save('SE_ResNext50_1');\nlearn.unfreeze();\nlearn = learn.clip_grad();","ae03f0f6":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","331bf2c5":"learn.load('SE_ResNext50_1');\nlearn.unfreeze();\nlearn = learn.clip_grad();","ce44979a":"lr = [3e-3\/100, 3e-3\/20, 3e-3\/10]\nlearn.fit_one_cycle(36, lr, wd=1e-7)\n","0fc425a2":"learn.save('s2_SeResNext50_2');","69b4400e":"SZ = 224\ncutout_frac = 0.20\np_cutout = 0.75\ncutout_sz = round(SZ*cutout_frac)\ncutout_tfm = cutout(n_holes=(1,1), length=(cutout_sz, cutout_sz), p=p_cutout)\n\ntfms = get_transforms(do_flip=True, max_rotate=15, flip_vert=False, max_lighting=0.1,\n                      max_zoom=1.05, max_warp=0.,\n                      xtra_tfms=[rand_crop(), rand_zoom(1, 1.5),\n                                 symmetric_warp(magnitude=(-0.2, 0.2)), cutout_tfm])","a8f8d30a":"data = ImageDataBunch.from_folder('data\/','train','valid',\n                                  ds_tfms=tfms\n                                  ,size=224,bs=32).normalize(imagenet_stats)\n\nlearn.data = data\ndata.train_ds[0][0].shape","2ff76e5b":"learn.load('s2_SeResNext50_2');\nlearn.freeze();\nlearn = learn.clip_grad();","89cdc0c1":"learn.loss_func = FocalLoss()","6ed24d63":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","351d9902":"learn.fit_one_cycle(24, slice(3e-3), wd=5e-6)","3254d152":"learn.save('SeResNxt50_FL_3');\nlearn.load('SeResNxt50_FL_3');","b2baf9a3":"learn.unfreeze();\nlearn = learn.clip_grad();","1a4db754":"lr = [1e-3\/200, 1e-3\/20, 1e-3\/10]\nlearn.fit_one_cycle(32, lr)","1de83a8a":"learn.save('SeResNxt50_FL_4');\nlearn.load('SeResNxt50_FL_4');","36226d7b":"SZ = 299\ncutout_frac = 0.20\np_cutout = 0.75\ncutout_sz = round(SZ*cutout_frac)\ncutout_tfm = cutout(n_holes=(1,1), length=(cutout_sz, cutout_sz), p=p_cutout)","8b8e0ba7":"tfms = get_transforms(do_flip=True, max_rotate=15, flip_vert=False, max_lighting=0.1,\n                      max_zoom=1.05, max_warp=0.,\n                      xtra_tfms=[rand_crop(),\n                                 symmetric_warp(magnitude=(-0.2, 0.2)), cutout_tfm])","26606df7":"data = ImageDataBunch.from_folder('data\/','train','valid',\n                                  ds_tfms=tfms\n                                  ,size=SZ,bs=24).normalize(imagenet_stats)\n\nlearn.data = data","40649f7c":"learn.load('SeResNxt50_FL_4');\nlearn.freeze();\nlearn = learn.clip_grad();\nlearn.mixup();","d5548d21":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","d852ebdb":"learn.fit_one_cycle(32, slice(1e-2))","4b1271f0":"learn.save('SeResNext50_mixup_6');","f249b848":"learn.load('SeResNext50_mixup_6');","a28c6d62":"learn.unfreeze();\nlearn = learn.clip_grad();\n# learn.mixup();","1bf67207":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","dba90577":"lr = [2e-5, 2e-4, 2e-3]\nlearn.fit_one_cycle(64, lr)","23425ec3":"learn.export('\/kaggle\/working\/fastai_resnet.pkl');","0cd3bd31":"labels = sio.loadmat('..\/input\/cars-devkit\/cars_test_annos_withlabels.mat')","403163d0":"x = []\nfor i in range(8041):\n    x.append(np.transpose(np.array(labels['annotations']['fname']))[i][0][0])","3e7b0e36":"df=pd.DataFrame(data=np.transpose(np.array(labels['annotations']['class'],dtype=np.int)),\n                  index=x)\n\ndf.to_csv('\/kaggle\/working\/data\/test_labels.csv')","d6429323":"learn = load_learner('\/kaggle\/working\/','fastai_resnet.pkl', test= \n                     ImageList.from_csv('\/kaggle\/working\/data','test_labels.csv',folder='test'))\npreds,y = learn.TTA(ds_type=DatasetType.Test)","6c9db0db":"pd.DataFrame(preds.cpu().numpy()).to_csv('raw_test_preds.csv',index=False)","c5bed57d":"a=preds;a.shape\nb=np.array(labels['annotations']['class'],dtype=np.int)-1;b.shape \nb = torch.from_numpy(b)","8e148a9f":"acc=accuracy(a,b);acc","0dedfd3b":"labelled_preds = torch.argmax(preds,1).cpu().numpy()\nout = open('result.txt', 'a')\nfor val in labelled_preds:\n    out.write('{}\\n'.format(str(val+1)))\nout.close()","724d12b9":"!rm -rf data\/","46529fca":"# Predicting on the test set","472ef5fd":"# Size 299","1cea1593":"# Size 224"}}