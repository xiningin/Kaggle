{"cell_type":{"bb2f7db5":"code","391dbe3b":"code","59873be2":"code","4d81975b":"code","3087fce9":"code","ef7b5b35":"code","e588074f":"code","5db41a15":"code","fb900742":"code","fd965d8c":"code","20a352e0":"code","28f5dd07":"code","5e5cd930":"code","8b65c150":"code","8a034447":"code","4bf04d37":"code","7738ff3a":"code","92aee7cf":"code","ba0680fd":"code","0583ba81":"code","60105630":"code","042a1e18":"code","6b10ddfe":"code","7743b23d":"code","d45b48e4":"code","9acecf80":"code","efdc7adf":"code","70040db1":"code","ef9c766e":"code","dddd9d96":"code","23765615":"code","175e8484":"code","b563a0ea":"code","0e8d8e52":"code","074f22ff":"code","2f4a5382":"code","a2edab21":"code","263280c0":"code","ba5887ae":"code","354dfb78":"markdown","fd76f4a9":"markdown","299db668":"markdown","2fa3849e":"markdown","f007ca63":"markdown","a4dad089":"markdown","93c3b814":"markdown","a060b038":"markdown","a9e3b505":"markdown","3987a1f5":"markdown","d9f09ea1":"markdown","1859a1d9":"markdown","8f7cdfb1":"markdown"},"source":{"bb2f7db5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","391dbe3b":"folder = '..\/input\/'","59873be2":"train = pd.read_csv(folder+\"train.csv\")\ntest = pd.read_csv(folder+\"test.csv\")\ntest_labels = pd.read_csv(folder+\"test_labels.csv\")\nsubmission = pd.read_csv(folder+\"sample_submission.csv\")","4d81975b":"train.head(10)","3087fce9":"# Cantidad de observaciones\ntrain.shape","ef7b5b35":"# Defino y (Salida del modelo)\nlist_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values\nprint(y.shape)\nprint(y[:10])","e588074f":"# Dataset muy desbalanceado\ntoxic_ratio = (y.sum(axis = 1) > 0).sum()\/y.shape[0]\nprint('Porcentaje de comentarios toxicos:', toxic_ratio)","5db41a15":"# La mayor\u00eda son toxic\nprint(train[list_classes].sum())\nprint()\nprint(train[list_classes].sum()\/y.shape[0])","fb900742":"# Superposici\u00f3n entre las clases (Multilabel)\nfor cl in list_classes[1:]:\n    N = ((train['toxic'] == 0) & (train[cl] == 1)).sum()\n    print(f'Es {cl} pero no es toxic:', N)","fd965d8c":"# Baseline (Suponer que siempre elijo zeros (No toxico))\n1-(train[list_classes].sum().values\/len(train)).mean()","20a352e0":"((y == np.zeros_like(y)).sum(axis=0)\/len(y)).mean()","28f5dd07":"train[list_classes].sum().values\/len(train)","5e5cd930":"X_train, X_valid, Y_train, Y_valid = train_test_split(train['comment_text'], y, test_size = 0.1)\n\nprint(X_train.shape, X_valid.shape)\nprint(Y_train.shape, Y_valid.shape)","8b65c150":"X_train[:10]","8a034447":"raw_text_train = X_train.apply(str.lower)\nraw_text_valid = X_valid.apply(str.lower)\nraw_text_test = test[\"comment_text\"].apply(str.lower)","4bf04d37":"print(raw_text_train[:10]) # Recordar que train_test_split hace shuffle ","7738ff3a":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\nmax_features = 10000\n\ntfidf_vectorizer = TfidfVectorizer(max_df=0.11, min_df=1,\n                                   max_features=max_features,\n                                   stop_words='english')\n\n%time tfidf_matrix_train = tfidf_vectorizer.fit_transform(raw_text_train)","92aee7cf":"%time tfidf_matrix_valid = tfidf_vectorizer.transform(raw_text_valid)","ba0680fd":"count_vectorizer = CountVectorizer(max_df=0.11, min_df=1,\n                                   max_features=max_features,\n                                   stop_words='english')\n\n%time count_matrix_train = count_vectorizer.fit_transform(raw_text_train)","0583ba81":"tfidf_matrix_train.shape, count_matrix_train.shape","60105630":"sparsity = 1 - (tfidf_matrix_train>0).sum()\/(tfidf_matrix_train.shape[0]*tfidf_matrix_train.shape[1])\nprint(sparsity)","042a1e18":"top_10 = np.argsort(tfidf_matrix_train.sum(axis=0))[0,::-1][0,:10].tolist()[0]\nfeature_names = np.array(tfidf_vectorizer.get_feature_names())\nprint(feature_names[np.array(top_10)])","6b10ddfe":"top_10_count = np.argsort(count_matrix_train.sum(axis=0))[0,::-1][0,:10].tolist()[0]\nfeature_names_count = np.array(count_vectorizer.get_feature_names())\nprint(feature_names_count[np.array(top_10_count)])","7743b23d":"dense_matrix_train = tfidf_matrix_train.todense()\ndense_matrix_valid = tfidf_matrix_valid.todense()","d45b48e4":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import initializers","9acecf80":"input_features = dense_matrix_train.shape[1]\noutput_size = Y_train.shape[1]\n\nmodel_rl = Sequential()\nmodel_rl.add(Dense(output_size, input_dim=input_features, activation='sigmoid', \n                   kernel_initializer=initializers.normal(mean=0, stddev=0.001)))\nmodel_rl.summary()\nmodel_rl.compile('Adam', loss='binary_crossentropy', metrics=['accuracy'])","efdc7adf":"model_rl.evaluate(dense_matrix_valid, Y_valid)","70040db1":"batch_size = 128\nepochs = 20\nmodel_rl.fit(dense_matrix_train, \n          Y_train, \n          batch_size = batch_size,\n          epochs=epochs, \n          verbose=1, \n          validation_data=(dense_matrix_valid, Y_valid))","ef9c766e":"(model_rl.get_weights()[0]).shape","dddd9d96":"salida = 3\nsorted_indexes = np.argsort(model_rl.get_weights()[0][:,salida])[::-1]\nnp.array(tfidf_vectorizer.get_feature_names())[sorted_indexes][:20]","23765615":"from keras import regularizers\nfrom keras import initializers\nfrom keras.layers import Activation\nfrom keras import optimizers","175e8484":"default_initializer = initializers.normal(mean=0, stddev=0.01)\n","b563a0ea":"input_features = dense_matrix_train.shape[1]\noutput_size = Y_train.shape[1]\nhidden_units = 100\nlambd = 0 #0.001\nmodel_sig_nn = Sequential()\nmodel_sig_nn.add(Dense(200,\n                       input_dim=input_features, \n                       kernel_regularizer=regularizers.l2(lambd), \n                       kernel_initializer=default_initializer,\n                       name=\"Capa_Oculta_1\"))\nmodel_sig_nn.add(Activation('sigmoid'))\nmodel_sig_nn.add(Dense(200,\n                       input_dim=input_features, \n                       kernel_regularizer=regularizers.l2(lambd), \n                       kernel_initializer=default_initializer,\n                       name=\"Capa_Oculta_2\"))\nmodel_sig_nn.add(Activation('sigmoid'))\nmodel_sig_nn.add(Dense(output_size,\n                       kernel_regularizer=regularizers.l2(lambd), \n                       kernel_initializer=default_initializer,\n                       name=\"Capa_Salida\"))\nmodel_sig_nn.add(Activation('sigmoid', name=\"output\")) \nmodel_sig_nn.summary()\n\n\nlr = 0.001 \nbatch_size = 256\nepochs = 10\n\n#selectedOptimizer = optimizers.SGD(lr=lr)\nselectedOptimizer = optimizers.adam(lr=lr, decay=0.001)\n\nmodel_sig_nn.compile(loss = 'binary_crossentropy', optimizer=selectedOptimizer, \n                     metrics=['accuracy']) #auc","0e8d8e52":"model_sig_nn.evaluate(dense_matrix_valid, Y_valid)","074f22ff":"history = model_sig_nn.fit(dense_matrix_train, \n          Y_train, \n          batch_size = batch_size,\n          epochs=epochs, \n          verbose=1, \n          validation_data=(dense_matrix_valid, Y_valid), \n         )","2f4a5382":"pred_valid = model_sig_nn.predict(dense_matrix_valid, verbose = 1)\npred_train = model_sig_nn.predict(dense_matrix_train, verbose = 1)","a2edab21":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nfrom scipy import interp\nfrom itertools import cycle\n\nprint(roc_auc_score(Y_train, pred_train, average='macro'))\nprint(roc_auc_score(Y_valid, pred_valid, average='macro'))","263280c0":"fpr = dict()\ntpr = dict()\nroc_auc = dict()\nn_classes = Y_valid.shape[1]\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(Y_valid[:, i], pred_valid[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n    \nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_valid.ravel(), pred_valid.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])","ba5887ae":"from matplotlib import pyplot as plt\n# Compute macro-average ROC curve and ROC area\nlw = 2\n# First aggregate all false positive rates\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n# Then interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr \/= n_classes\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Some extension of Receiver operating characteristic to multi-class')\nplt.legend(loc=\"lower right\")\nplt.show()","354dfb78":"# Curva ROC","fd76f4a9":"# Resultados TFIDF","299db668":"# Armo TFIDF","2fa3849e":"- toxic\n- severe_toxic\n- obscene\n- threat\n- insult\n- identity_hate","f007ca63":"# An\u00e1lisis de un problema multilabel\n\nCompetencia original:\n\nhttps:\/\/www.kaggle.com\/c\/jigsaw-toxic-comment-classification-challenge","a4dad089":"# Divido entre train y valid","93c3b814":"# Sparsity","a060b038":"# EDA (Exploratory Data Analysis)","a9e3b505":"# Interpretaci\u00f3n","3987a1f5":"# Creaci\u00f3n del modelo","d9f09ea1":"# MLP","1859a1d9":"Se puede ver aca por ejemplo que si es severe_toxic es si o si toxic, pero que insulto puede no ser t\u00f3xico por ejemplo","8f7cdfb1":"## Defino salida del modelo $y$"}}