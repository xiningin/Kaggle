{"cell_type":{"90c9f18f":"code","2fe87f90":"code","cae195ad":"code","d7ed6dd9":"code","2d80a459":"code","9dca6b69":"code","58a61445":"markdown","f6f1c953":"markdown","daa0d9fe":"markdown","52c70c0a":"markdown","73e502a2":"markdown"},"source":{"90c9f18f":"# Input data files are available in the \"..\/input\/\" directory.\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/cord19-expertsystem-mesh\/cord19_expertsystem_mesh_060320'):\n    if 'json' in dirname:\n        print(f\"{'\/'.join(dirname.split('\/')[-2:])} has {len(filenames)} files\")\n        #uncomment to list all files under the input directory\n        #for filename in filenames:  \n            #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2fe87f90":"import logging\nimport json\nfrom pathlib import Path\nfrom pprint import pprint\n\nlogger = logging.getLogger(__name__)\n\nlogging.basicConfig(format=\"%(asctime)s %(levelname)s [PID: %(process)d - %(filename)s %(funcName)s] - %(message)s\",\n                    level=logging.INFO)\nlogger.info('start')","cae195ad":"# local functions\ndef load_taxonomies(dataset_root):\n    \"\"\"Given a path with the root directory, we navigate the path and read all the files having .json as extension.\n    Filename by filename, we build up a dictionary in the form {key : value, key1 : value1, ...} in which the key is the name of an entry in MeSH taxonomy, while the value is a set of paper ids for all the papers that contain that entry\"\"\"\n    tax_in_files = {}\n\n    for json_file in dataset_root.glob('**\/*'):\n        if json_file.is_dir():\n            continue\n        if not json_file.name.lower().endswith('.json'):\n            logger.warning(f'unused file {json_file.name}')\n            continue\n        json_data = json.load(json_file.open())\n        for tax_entry in json_data.get('MeSH_tax', []):\n            tax = tax_entry['tax']\n            tax_in_files[tax] = tax_in_files.get(tax, set())\n            tax_in_files[tax].add(json_data['paper_id'])\n    return tax_in_files\n\ndef filter_data(tax_in_files, taxonomy_entry):\n    \"\"\"Takes as input the dictionary built in load_taxonomies, tax_in_files, and a specific taxonomy entry.\n    Returns a new dictionary tax_in_files in which only the entries that have documents in common with the latest taxonomy entry are maintained. \n    In other words, the function can be called progressively on multiple taxonomies entries, so to filter the dictionary and have, in the end, only the sets of documents that share the entries all of interest.\"\"\"\n    if taxonomy_entry not in tax_in_files:\n        logger.error(f\"In the current set of entries there are no documents with tax = {taxonomy_entry}\")\n        return None\n    selected_set = tax_in_files[taxonomy_entry]\n    return {\n        taxonomy_entry: docs & selected_set\n        for taxonomy_entry, docs in tax_in_files.items()\n        if docs & selected_set\n    }\n\ndef dump_most_common_taxes(tax_in_files, rank=10):\n    \"\"\"Given the output of load_taxonomies(), the fuction returns the top entries (up to \"rank\") of the taxonomy, sorted decreasingly with respect to the number of documents they appear in.\"\"\"\n    tax_in_files_counter = [(taxonomy_entry, len(set_files))\n                            for taxonomy_entry, set_files in tax_in_files.items()]\n    return sorted(tax_in_files_counter, key=lambda x: x[1], reverse=True)[:rank]","d7ed6dd9":"%%time\n# Input data files are available in the \"..\/input\/\" directory.\n# Let's load the latest version of the data.\ndataset_root = Path('\/kaggle\/input\/cord19-expertsystem-mesh\/cord19_expertsystem_mesh_060320\/')\ntax_in_files = load_taxonomies(dataset_root)\n\n# for instance, let's filter documents by only selecting those that show the following selected_tax, about Vaccines\nselected_tax = '\/MeSH Taxonomy\/Chemicals and Drugs\/Complex Mixtures\/Biological Products\/Vaccines'\nselection_step = filter_data(tax_in_files, selected_tax)\npprint(dump_most_common_taxes(selection_step, 10))\nprint()\n","2d80a459":"%%time\n# Let's progressively select a subset of categories and find all the documents that contain all the following categories\n\nrequested_tax_entries = [\n    '\/MeSH Taxonomy\/Organisms\/Viruses\/RNA Viruses\/Nidovirales\/Coronaviridae\/Coronavirus',\n    '\/MeSH Taxonomy\/Phenomena and Processes\/Immune System Phenomena\/Immunity', \n    '\/MeSH Taxonomy\/Phenomena and Processes\/Microbiological Phenomena\/Virulence',\n    '\/MeSH Taxonomy\/Health Care\/Environment and Public Health\/Public Health\/Disease Outbreaks\/Epidemics\/Pandemics',\n    '\/MeSH Taxonomy\/Phenomena and Processes\/Physiological Phenomena\/Virus Shedding',\n    '\/MeSH Taxonomy\/Organisms\/Viruses\/DNA Viruses\/Herpesviridae\/Alphaherpesvirinae\/Simplexvirus'] \n\nfor selected_tax in requested_tax_entries:\n    selection_step = filter_data(selection_step, selected_tax)\n    pprint(dump_most_common_taxes(selection_step, 10))\n    print()","9dca6b69":"selected_docs = set()\nfor _, docs_with_tax in selection_step.items():\n    selected_docs |= docs_with_tax\n\npprint(selected_docs)","58a61445":"## Finding papers of interest through MeSH ids\n\nThe JSON files in this dataset present a high number of MeSH extractions. Each document is so identified, globally, by all the MeSH concepts that occur into it and are judged relevant. \n\nThis notebook shows how to navigate the dataset to easily find documents that contain certain entries of interest. ","f6f1c953":"## Get acquainted with the dataset\n\nYou can skip the next cell if you are familiar with the first notebook, [CORD-19_ExpertSystem_MeSH: how to](http:\/\/www.kaggle.com\/expsys\/cord-19-expertsystem-mesh-how-to).\n\nFirst things first: all the dataset files are in '\/kaggle\/input'. Here's a snippet in case you want to have a look at the contents of the subfolders:","daa0d9fe":"Let's first import the modules we are going to need and define the functions that will carry out the filtering.","52c70c0a":"Finally, let's print out the list of the documents matching the filter criteria.","73e502a2":"All done!"}}