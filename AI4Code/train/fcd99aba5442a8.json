{"cell_type":{"e2ed0117":"code","753e90be":"code","b12badec":"code","fc53c944":"code","4defd7fb":"code","3fc1a5ff":"code","b0938d22":"code","67e70057":"code","1b371a37":"code","d96edc47":"code","0ed41de6":"code","ae7aeb30":"code","23c12af3":"code","c6d622ce":"code","d0adfcd3":"code","68540b10":"code","91435f5f":"code","df211b76":"code","17cd1430":"code","88314689":"code","548102c9":"code","dca348e3":"code","21b028ab":"code","5fcd2bec":"code","8904d227":"code","18d8f647":"code","3f0d01b0":"code","86a9a15f":"code","fb8104d4":"code","0bc8ddbb":"code","2fb907f4":"code","608ad0e6":"code","28b26351":"code","c9b833b9":"code","92a9b7ea":"code","43c79a25":"code","2da98fb8":"code","09bff2b8":"code","af623106":"code","199136eb":"code","38ebc191":"code","9eeff9c3":"code","cde17851":"code","66f83208":"markdown","a454e739":"markdown","a3d7fdde":"markdown","cdda3e6b":"markdown","11338740":"markdown","0ae86772":"markdown","0973028b":"markdown","650da67b":"markdown","b2fe4fa7":"markdown","456aaedc":"markdown","b64bf003":"markdown","eee850b2":"markdown","a39fa817":"markdown","4656aa85":"markdown","cc43de19":"markdown"},"source":{"e2ed0117":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","753e90be":"!wget -O Data.npz https:\/\/zenodo.org\/record\/4269852\/files\/dermamnist.npz?download=1","b12badec":"data = np.load('Data.npz')\nprint(data.files)","fc53c944":"print(f'Train Set:      X:%s Y:%s' %(data['train_images'].shape, data['train_labels'].shape))\nprint(f'Validation Set: X:%s Y:%s' %(data['val_images'].shape, data['val_labels'].shape))\nprint(f'Test Set :      X:%s Y:%s' %(data['test_images'].shape, data['test_labels'].shape))","4defd7fb":"X_train = data['train_images']\nX_val = data['val_images']\nX_test = data['test_images']\nX = np.concatenate((X_train, X_val, X_test), axis=0)\n\ny_train = data['train_labels']\ny_val = data['val_labels']\ny_test = data['test_labels']\ny = np.concatenate((y_train, y_val, y_test), axis=0)","3fc1a5ff":"labels = ['akiec',\n          'bcc',\n          'bkl',\n          'df',\n          'nv',\n          'vasc',\n          'mel']","b0938d22":"lesion_type_dict = {\n    'akiec': 'Actinic keratoses',\n    'bcc': 'Basal cell carcinoma',\n    'bkl': 'Benign keratosis-like lesions ',\n    'df': 'Dermatofibroma',\n    'nv': 'Melanocytic nevi',\n    'vasc': 'Vascular lesions',\n    'mel': 'Melanoma'\n}","67e70057":"np.unique(y)","1b371a37":"num_classes = []\nfor i in range(len(labels)):\n  num_classes.append(len(np.where(y==i)[0]))\n\npd.DataFrame(num_classes,index=labels)","d96edc47":"fig, ax = plt.subplots(7, 5)\nfig.set_figheight(25)\nfig.set_figwidth(15)\nfor classes in range (7):\n  for i, inx in enumerate(np.where(y==classes)[0][:5]):\n    ax[classes,i].imshow(X[inx])\n    ax[classes,i].set_ylabel(labels[classes],fontsize = 20.0)\n    ax[classes,i].label_outer()","0ed41de6":"num_classes = []\nfor i in range(len(labels)):\n  num_classes.append(len(np.where(y_train==i)[0]))\n\npd.DataFrame(num_classes,index=labels)","ae7aeb30":"from imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\n\nos_dict = {0: num_classes[0]*7,\n           1: num_classes[1]*5,\n           2: 1500,\n           3: 2500,\n           4: 1500,\n           5: num_classes[5],\n           6: 1500}\noversample = RandomOverSampler(sampling_strategy=os_dict)\noversampled_X , oversampled_y = oversample.fit_resample(X_train.reshape(X_train.shape[0], -1), y_train)\nprint('OS_X:%s OS_y:%s' %(oversampled_X.shape, oversampled_y.shape))\n\nus_dict = {0: num_classes[0]*7,\n           1: num_classes[1]*5,\n           2: 1500,\n           3: 2500,\n           4: 1500,\n           5: 3000,\n           6: 1500}\n\nundersample = RandomUnderSampler(sampling_strategy=us_dict)\nundersampled_X , undersampled_y = undersample.fit_resample(oversampled_X, oversampled_y)\nprint('US_X:%s US_y:%s' %(undersampled_X.shape, undersampled_y.shape))","23c12af3":"undersampled_y.shape","c6d622ce":"undersampled_X = undersampled_X.reshape(-1,28,28,3)","d0adfcd3":"num_classes = []\nfor i in range(len(labels)):\n  num_classes.append(len(np.where(undersampled_y==i)[0]))\n\npd.DataFrame(num_classes,index=labels)","68540b10":"from tensorflow.keras.utils import to_categorical\nundersampled_y = to_categorical(undersampled_y)\ny_val = to_categorical(y_val)\ny_test = to_categorical(y_test)","91435f5f":"undersampled_y.shape","df211b76":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                  rotation_range = 10,\n                                  width_shift_range = 0.2,\n                                  height_shift_range = 0.2,\n                                  shear_range = 0.2,\n                                  horizontal_flip = True,\n                                  vertical_flip = True,\n                                  fill_mode = 'wrap')\n\nbatch_size=50\ntrain_data = train_datagen.flow(undersampled_X, undersampled_y, batch_size = batch_size, seed=1)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\nval_data = test_datagen.flow(X_val, y_val, batch_size=batch_size,seed=1)","17cd1430":"print(f'Train Set:      X:%s Y:%s' %(train_data.x.shape, train_data.y.shape))\nprint(f'Validation Set: X:%s Y:%s' %(val_data.x.shape, val_data.y.shape))\nprint(f'Test Set :      X:%s Y:%s' %(X_test.shape, y_test.shape))","88314689":"num_classes = []\nfor i in range(len(labels)):\n  num_classes.append(len(np.where(np.argmax(val_data.y, axis=1)==i)[0]))\n\npd.DataFrame(num_classes,index=labels)","548102c9":"from tensorflow import keras\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten","dca348e3":"input_layer = Input(shape=(28,28,3))\n\n# convolution block 1 \ncb11 = Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation=\"relu\")(input_layer)\ncb12 = Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation=\"relu\")(cb11)\nmaxpl1 = MaxPool2D((2,2))(cb12)\n\n#convolution block 2 \ncb21 = Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation=\"relu\")(maxpl1)\ncb22 = Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation=\"relu\")(cb21)\nmaxpl2 = MaxPool2D((2,2))(cb22)\n\n#convolution block 3\ncb31 = Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation=\"relu\")(maxpl2)\ncb32 = Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation=\"relu\")(cb31)\nmaxpl3 = MaxPool2D((2,2))(cb32)\n\n#convolution block 4\ncb41 = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation=\"relu\")(maxpl3)\ncb42 = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation=\"relu\")(cb41)\ncb43 = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation=\"relu\")(cb42)\nmaxpl4 = MaxPool2D((2,2))(cb43)\n\n# artificial neural network block\nflat   = Flatten()(maxpl4)\ndense1 = Dense(1024, activation=\"relu\")(flat)\ndense2 = Dense(1024, activation=\"relu\")(dense1)\ndense3 = Dense(1024, activation=\"relu\")(dense2)\noutput = Dense(7, activation=\"softmax\")(dense3)\nmodel = Model(inputs=input_layer, outputs=output)","21b028ab":"model.compile(optimizer= keras.optimizers.Adam(0.0001, decay=1e-5),\n              loss='categorical_crossentropy',\n              metrics=['acc'])#keras.metrics.Accuracy())","5fcd2bec":"batch_size = batch_size\nepochs = 30\nmodel_history = model.fit(train_data,\n                          steps_per_epoch= int(train_data.n\/batch_size),\n                          epochs=epochs,\n                          validation_data=val_data,\n                          validation_steps=int(val_data.n\/batch_size))","8904d227":"model_history.params","18d8f647":"model.summary()","3f0d01b0":"from tensorflow.keras.utils import plot_model\nplot_model(model)","86a9a15f":"model.evaluate(X_test\/255, y_test)","fb8104d4":"pd.DataFrame(model_history.history).plot(figsize=(8,5))\nplt.grid(True)\nplt.show()","0bc8ddbb":"y_proba = model.predict(X_test\/255)\ny_proba.round(2)","2fb907f4":"y_pred = np.argmax(y_proba, axis=-1)\ny_pred[:10]","608ad0e6":"y_pred_name = np.array(labels)[y_pred]\ny_pred_name[:10]","28b26351":"plt.figure(figsize=(20,10))\nfor i in range(5):\n    plt.subplot(1,5,i+1)\n    plt.imshow(X_test[i])\n    plt.title('True label: {}, Prediction: {}'.format(labels[y_test[i].argmax()], y_pred_name[i]))\nplt.tight_layout()   ","c9b833b9":"from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay","92a9b7ea":"y_test_numbers = np.array([y.argmax() for y in y_test])","43c79a25":"cm = confusion_matrix(y_test_numbers, y_pred)","2da98fb8":"cm_display = ConfusionMatrixDisplay(cm,display_labels=labels)\nfig, ax = plt.subplots(figsize=(10,10))\ncm_display.plot(ax=ax)","09bff2b8":"print(classification_report(y_test_numbers, y_pred, target_names = labels))","af623106":"model.layers","199136eb":"first_conv = model.layers[1]\nprint(first_conv)\nprint(first_conv.weights)","38ebc191":"print('Output Shape of the first Convolution layer: ',first_conv(X_test\/255).shape)\nprint('Number of Testset data:                      ',first_conv(X_test\/255).shape[0])\nprint('Number of first Convolution layer:           ',first_conv(X_test\/255).shape[3])","9eeff9c3":"n = 0\nplt.imshow(X_test[n])","cde17851":"#first layer output\ncurrent_layer_output = first_conv(X_test\/255)[n]\nprint(current_layer_output.shape)\nfig, ax = plt.subplots(3, 3)\nfor i in range(9):\n  ax[i\/\/3][i%3].imshow(current_layer_output[:,:,i])\n  ax[i\/\/3][i%3].axis('off')\nplt.tight_layout()","66f83208":"### Visualizing filters and output of the first layer of model ","a454e739":"## __Importing Dataset__ ","a3d7fdde":"### Making Labels Categorical","cdda3e6b":"## __Data Preprocessing and Augmentation__","11338740":"Obviously, we face an imbalanced dataset that has to be handled!","0ae86772":"## __Model Creation__","0973028b":"### Visualizing our data\n5 images of each 7 classes","650da67b":"### Image Data Generator","b2fe4fa7":"number of samples of each class in the whole dataset","456aaedc":"## __Importing Basic Library__","b64bf003":"### Labels","eee850b2":"#### ploting 9 first filter","a39fa817":"The data for this study was collected from MNIST HAM10000 Image dataset. This dataset contains 10,015 images of skin lesions that have been separated into seven categories:\n\nActinic keratoses and intraepithelial carcinoma \/ Bowen's disease (akiec), basal cell carcinoma (bcc), benign keratosis-like lesions (solar lentigines \/ seborrheic keratoses and lichen-planus like keratoses) (bkl), dermatofibroma (df), melanoma (mel), melanocytic nevi (nv) and vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage) (vasc) by histopathology, evaluation or expert consensus. \n\nThey were also assigned a label that is listed below:\n\n0 : akiec \n\n1 : bcc \n\n2 : bkl\n\n3 : df \n\n4 : nv \n\n5 : vasc \n\n6 : mel","4656aa85":"## __Model Evaluation__","cc43de19":"### Resampling"}}