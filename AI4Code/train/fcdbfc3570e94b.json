{"cell_type":{"3828eff4":"code","a9bc8e2a":"code","ec69e560":"code","5694c6fa":"code","7e16798d":"code","4db93552":"code","1a5a4225":"code","6355fc77":"code","2989615f":"code","34ff95f4":"code","cc88bf58":"code","da730af7":"code","6a62fce9":"code","f346f09a":"code","37ddbbb7":"code","28134e89":"code","65b4b6e8":"code","69e81b86":"code","94d5a029":"code","2b70993f":"code","52685456":"code","960569c8":"code","301988e3":"code","bbf3656f":"code","70e995cc":"code","878aadfa":"code","9cba7da8":"code","50b852a4":"code","af1681fd":"code","3225305a":"code","85150210":"code","3a94b36e":"code","ea5c70c9":"code","d108fb2d":"code","bf6fc823":"code","bdc339b7":"code","2ef87043":"code","d7a9b4ef":"code","40649df8":"code","2611cea2":"code","a1719f93":"code","7f092059":"code","12222076":"code","2a6291e8":"code","957777b4":"code","5a723f87":"code","1dec28c1":"code","64d78328":"code","65ee2df4":"code","5a8fc015":"code","ef6ca138":"code","2e1f4524":"code","cd7ab8e1":"code","a47b2623":"code","6809c799":"code","307dfb49":"code","2a7002b6":"code","19f4d303":"code","cae204d0":"code","979ab450":"code","06287fb0":"code","46e334a3":"code","2472cbe8":"code","d531113d":"markdown","a4349652":"markdown"},"source":{"3828eff4":"import pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nfrom tqdm import tqdm\nfrom itertools import product\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\n\nimport sys\nimport os\nimport gc\nfrom glob import glob\nimport pickle\nimport json\nimport subprocess\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold, train_test_split, RepeatedStratifiedKFold\n","a9bc8e2a":"# !pip install --no-index --find-links ..\/input\/pytorchset timm\n# !pip install --no-index --find-links ..\/input\/pytorchset pytorch-lightning","ec69e560":"# import torch\n# import torch.optim as optim\n# import torch.nn as nn\n# import torch.nn.functional as F\n\n# import torchvision.transforms as T\n# import timm\n# from sklearn.model_selection import StratifiedKFold\n# from torchvision.io import read_image\n# from torch.utils.data import DataLoader, Dataset\n\n# import pytorch_lightning as pl\n# from pytorch_lightning.utilities.seed import seed_everything\n# from pytorch_lightning import callbacks\n# from pytorch_lightning.callbacks.progress import ProgressBarBase\n# from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n# from pytorch_lightning.loggers import TensorBoardLogger\n# from pytorch_lightning import LightningDataModule, LightningModule\n\n# from sklearn.metrics import mean_squared_error\n# from scipy.optimize import minimize","5694c6fa":"# import tensorflow as tf\n# import tensorflow_addons as tfa\n# from tensorflow import keras\n# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","7e16798d":"# import lightgbm as lgb\n\n# import cupy as cp # linear algebra\n# import cudf as cd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# from cuml.svm import SVR\n# from cuml.decomposition import PCA\n\n# from cuml.metrics import accuracy_score","4db93552":"DF_CEILING_VALUE = 20000.0\nSHOP_CEILING_VALUE = 999999.9\nITEM_CEILING_VALUE = 999999.9\n\nTRANSITION_LENGTH = 18","1a5a4225":"for i in range(0, 33 - TRANSITION_LENGTH):\n    print(i)","6355fc77":"PATH = '..\/input\/competitive-data-science-predict-future-sales\/'\n\ndf = pd.read_csv(PATH + 'sales_train.csv')\ndf_test = pd.read_csv(PATH + 'test.csv')\nsample = pd.read_csv(PATH + 'sample_submission.csv')\nitems = pd.read_csv(PATH + 'items.csv')\nshops = pd.read_csv(PATH + 'shops.csv')\nitem_cats = pd.read_csv(PATH + 'item_categories.csv')","2989615f":"data_files_names = [\"df\",\"df_test\",\"sample\",\"items\",\"shops\",\"item_cats\"]\ndata_files = [df,df_test,sample,items,shops,item_cats]","34ff95f4":"df_test = df_test.drop('ID', axis=1)\ndf_test","cc88bf58":"print(len(df[(df['item_cnt_day']>0.0)&(df['item_cnt_day']<10.0)]))\nplt.hist(df[(df['item_cnt_day']>0.0)&(df['item_cnt_day']<10.0)]['item_cnt_day'],bins=20)","da730af7":"df.loc[df['item_cnt_day'] < -1.0, 'item_cnt_day'] = -1.0\nprint(len(df[df['item_cnt_day'] < -1.0]))\ndf[df['item_cnt_day'] < 0.0]","6a62fce9":"for i in range(3):\n    df.loc[df['item_cnt_day'] > 10.0, 'item_cnt_day'] = df[df['item_cnt_day'] > 10.0]['item_cnt_day'] \/ 10.0\n    df[df['item_cnt_day'] > 10.0]['item_cnt_day']\n# df.loc[df['item_cnt_day'] > 10.0, 'item_cnt_day'] = 1.0","f346f09a":"len(df[df['item_cnt_day']>10.0])","37ddbbb7":"print(len(df[(df['item_cnt_day']>0.0)&(df['item_cnt_day']<10.0)]))\nplt.hist(df[(df['item_cnt_day']>0.0)&(df['item_cnt_day']<10.0)]['item_cnt_day'],bins=20)","28134e89":"df","65b4b6e8":"df = df.groupby(['date_block_num', 'shop_id', 'item_id'], as_index=False\n        ).agg({'item_cnt_day':'sum'}\n        ).rename(columns={'item_cnt_day':'mon_shop_item_cnt'})","69e81b86":"df","94d5a029":"# Preprocessing transition\ndef prepro_transition(transition, ceiling_value):\n    p_transition = transition\n    \n    p_transition = p_transition.fillna(0)\n    # p_transition = p_transition.drop('ID', axis=1)\n    \n    # Outliers to 10.0\n#     p_transition[p_transition[0:34] > ceiling_value] = ceiling_value\n    p_transition[p_transition.iloc[:, 2:] > ceiling_value] = ceiling_value\n    \n    return p_transition","2b70993f":"# left 214200\ntransition = df_test\nfor i in range(34):\n    transition = pd.merge(transition, df[df['date_block_num']==i].drop('date_block_num', axis=1).rename(columns={'mon_shop_item_cnt': i }), how='left')\ntransition = prepro_transition(transition, DF_CEILING_VALUE)\ntransition","52685456":"# # Outer -> 526920\n# transition = df_test\n# for i in range(34):\n#     transition = pd.merge(transition, df[df['date_block_num']==i].drop('date_block_num', axis=1).rename(columns={'mon_shop_item_cnt': i}), how='outer')\n# transition = prepro_transition(transition, DF_CEILING_VALUE)\n# transition","960569c8":"transition.max()","301988e3":"# Shop\nshop_df = df.groupby(['date_block_num', 'shop_id'], as_index=False\n        ).agg({'mon_shop_item_cnt':'sum'}\n        )\nshop_df","bbf3656f":"# Shop\nshop_transition = shops\nfor i in range(34):\n    shop_transition = pd.merge(shop_transition, shop_df[shop_df['date_block_num']==i].drop('date_block_num', axis=1).rename(columns={'mon_shop_item_cnt': i}), on='shop_id', how='left')\nshop_transition = shop_transition.fillna(0)\nshop_transition","70e995cc":"shop_transition.mean()","878aadfa":"# Shop\nitem_df = df.groupby(['date_block_num', 'item_id'], as_index=False\n        ).agg({'mon_shop_item_cnt':'sum'}\n        )\nitem_df","9cba7da8":"# Shop\nitem_transition = items\nfor i in range(34):\n    item_transition = pd.merge(item_transition, item_df[item_df['date_block_num']==i].drop('date_block_num', axis=1).rename(columns={'mon_shop_item_cnt': i}), on='item_id', how='left')\nitem_transition = item_transition.fillna(0)\nitem_transition","50b852a4":"item_transition.mean()","af1681fd":"transition","3225305a":"transition.max()","85150210":"transition = transition.drop([33], axis=1)\nshop_transition = shop_transition.drop([33], axis=1)\nitem_transition = item_transition.drop([33], axis=1)","3a94b36e":"transition","ea5c70c9":"%%time\ntransition_array = transition.to_numpy().tolist()\nshop_transition_array = shop_transition.to_numpy().tolist()\nitem_transition_array = item_transition.to_numpy().tolist()","d108fb2d":"pd.DataFrame(columns = ['shop_id', 'item_id'] + [x for x in range(TRANSITION_LENGTH)])","bf6fc823":"%%time\nx_train = []\ny_train = []\n\nfor row in transition_array:\n    for i in range(0, 33 - TRANSITION_LENGTH):\n        if row[2+i+TRANSITION_LENGTH] < 20.0:\n            row_shop = shop_transition_array[int(row[0])][2+i : 2+i+TRANSITION_LENGTH] if shop_transition_array[int(row[0])] else [0.0]*(TRANSITION_LENGTH)\n            row_item = item_transition_array[int(row[1])][2+i : 2+i+TRANSITION_LENGTH] if item_transition_array[int(row[1])] else [0.0]*(TRANSITION_LENGTH)\n            x_train.append(row[0:2] + row[2+i : 2+i+TRANSITION_LENGTH] + row_shop + row_item )\n            y_train.append(row[2+i+TRANSITION_LENGTH] if row[2+i+TRANSITION_LENGTH] < DF_CEILING_VALUE else DF_CEILING_VALUE)\n        \n            \n    ","bdc339b7":"x_train[0]","2ef87043":"y_train[0]","d7a9b4ef":"len(x_train[0])","40649df8":"len(x_train)","2611cea2":"len(y_train)","a1719f93":"# # Set Callbacks\n# def model_checkpoint(kind, fold):\n#     return ModelCheckpoint(f'{kind}{fold:03}.h5',\n#               verbose = 1, \n#               monitor = 'val_loss', \n#               mode = 'min', \n#               save_weights_only=True,\n#               save_best_only = True)\n# def early_stopping():\n#     return EarlyStopping(\n#         monitor='val_loss',\n#         min_delta=0.0,\n#         patience=EARRY_STOP,\n#     )\n\n# def create_model():\n#     # Create Model\n#     # base_model = SwinTransformer('swin_base_384', include_top=False, pretrained=True, use_tpu=True)\n    \n#     x_input = tf.keras.layers.Input(shape=(35,))\n\n# #     x = tf.keras.layers.Dropout(0.1)(x)\n#     x = tf.keras.layers.Dense(256, activation=tf.nn.relu)(x_input)\n#     x = tf.keras.layers.Dense(256, activation=tf.nn.relu)(x)\n#     x = tf.keras.layers.Dense(64, activation=tf.nn.relu)(x)\n#     x = tf.keras.layers.Dense(64, activation=tf.nn.relu)(x)\n#     x = tf.keras.layers.Dense(1, activation=tf.nn.relu)(x)\n\n#     model = keras.Model(inputs = x_input, outputs = x)\n\n#     model.compile(\n#         optimizer = tfa.optimizers.AdamW(\n#             learning_rate=LR, weight_decay=WD\n#         ),\n#         loss = tf.keras.losses.MeanAbsoluteError(),\n# #         metrics=[tf.keras.metrics.RootMeanSquaredError()],\n#     )\n\n#     return model\n# model = create_model()","7f092059":"%%time\nval_transition = df_test\nrow_i = 0\n# plus 1 to get val_y\ni = 0\nfor i in range(TRANSITION_LENGTH + 1):\n    # subtraction from colum as y\n    row_i = 34 - 1 - TRANSITION_LENGTH + i\n    val_transition = pd.merge(val_transition, df[df['date_block_num']==row_i].drop('date_block_num', axis=1).rename(columns={'mon_shop_item_cnt': i }), how='left')\n\ny_val = val_transition[i].fillna(0)\nval_transition = val_transition.drop([i], axis=1)\n\nfor i in range(TRANSITION_LENGTH):\n    row_i = 34 - 1 - TRANSITION_LENGTH + i\n    val_transition = pd.merge(val_transition, shop_df[shop_df['date_block_num']==row_i].drop(['date_block_num'], axis=1).rename(columns={'mon_shop_item_cnt': TRANSITION_LENGTH + i }), how='left')\nfor i in range(TRANSITION_LENGTH):\n    row_i = 34 - 1 - TRANSITION_LENGTH + i\n    val_transition = pd.merge(val_transition, item_df[item_df['date_block_num']==row_i].drop(['date_block_num'], axis=1).rename(columns={'mon_shop_item_cnt': TRANSITION_LENGTH * 2 + i }), how='left')\n\n\nval_transition = val_transition.fillna(0)\n\nval_transition","12222076":"val_transition = val_transition[y_val < 20.0]\ny_val = y_val[y_val < 20.0]","2a6291e8":"print(len(val_transition), len(y_val))","957777b4":"y_val","5a723f87":"y_val.mean()","1dec28c1":"y_val.max()","64d78328":"lgb_train = lgb.Dataset(x_train, y_train, free_raw_data=False)\nlgb_val = lgb.Dataset(val_transition, y_val, reference=lgb_train, free_raw_data=False)\n\n\nlgbm_params = {\n    'objective': 'mse',\n    'metric': 'rmse',\n    \"num_leaves\": 500,\n    'is_unbalance':True,\n    'boosting':'gbdt',\n    \"learning_rate\": 0.01,\n    'num_boost_round': 100000,\n    'early_stopping_rounds':200\n}\n\n\n\n\n# # optimized by oputuna\n# lgbm_params = {\n#     'objective': 'mse',\n#     'metric' : 'rmse',\n#     \"num_leaves\": 966,\n#     \"cat_smooth\": 45.01680827234465,\n#     \"min_child_samples\": 27,\n#     \"min_child_weight\": 0.021144950289224463,\n#     \"max_bin\": 214,\n#     \"learning_rate\": 0.01,\n#     \"subsample_for_bin\": 300000,\n#     \"min_data_in_bin\": 7,\n#     \"colsample_bytree\": 0.8,\n#     \"subsample\": 0.6,\n#     \"subsample_freq\": 5,\n#     \"n_estimators\": 3000,\n# }\n","65ee2df4":"model = lgb.train(lgbm_params,\n                  lgb_train,\n                  valid_names=['train', 'valid'],\n                  valid_sets=[lgb_train, lgb_val],\n                  early_stopping_rounds=20,\n                  verbose_eval=100)","5a8fc015":"TRANSITION_LENGTH","ef6ca138":"shop_df","2e1f4524":"submit_transition = df_test\nfor i in range(TRANSITION_LENGTH):\n    row_i = 34 - TRANSITION_LENGTH + i\n    submit_transition = pd.merge(submit_transition, df[df['date_block_num']==row_i].drop('date_block_num', axis=1).rename(columns={'mon_shop_item_cnt': i }), how='left')\nfor i in range(TRANSITION_LENGTH):\n    row_i = 34 - TRANSITION_LENGTH + i\n    submit_transition = pd.merge(submit_transition, shop_df[shop_df['date_block_num']==row_i].drop(['date_block_num'], axis=1).rename(columns={'mon_shop_item_cnt': TRANSITION_LENGTH + i }), how='left')\nfor i in range(TRANSITION_LENGTH):\n    row_i = 34 - TRANSITION_LENGTH + i\n    submit_transition = pd.merge(submit_transition, item_df[item_df['date_block_num']==row_i].drop(['date_block_num'], axis=1).rename(columns={'mon_shop_item_cnt': TRANSITION_LENGTH * 2 + i }), how='left')\n\nsubmit_transition = submit_transition.fillna(0)\n# p_transition = p_transition.drop('ID', axis=1)\n\nstart_column = 2\nsubmit_transition[submit_transition.iloc[:, start_column:start_column + TRANSITION_LENGTH] > DF_CEILING_VALUE] = DF_CEILING_VALUE\n\nstart_column += TRANSITION_LENGTH\nsubmit_transition[submit_transition.iloc[:, start_column:start_column + TRANSITION_LENGTH] > SHOP_CEILING_VALUE] = SHOP_CEILING_VALUE\n\nstart_column += TRANSITION_LENGTH\nsubmit_transition[submit_transition.iloc[:, start_column:start_column + TRANSITION_LENGTH] > ITEM_CEILING_VALUE] = ITEM_CEILING_VALUE\n\n\nsubmit_transition","cd7ab8e1":"submit_transition.loc[0:10, 25:35]","a47b2623":"\n# for row in transition_array:\n#     for i in range(0, 34 - TRANSITION_LENGTH):\n#         row_shop = shop_transition_array[int(row[0])][2+i : 2+i+TRANSITION_LENGTH] if shop_transition_array[int(row[0])] else [0.0]*(TRANSITION_LENGTH+1)\n#         row_item = item_transition_array[int(row[1])][2+i : 2+i+TRANSITION_LENGTH] if item_transition_array[int(row[1])] else [0.0]*(TRANSITION_LENGTH+1)\n#         x_train.append(row[0:2] + row[2+i : 2+i+TRANSITION_LENGTH] + row_shop + row_item )\n#         y_train.append(row[2+i+TRANSITION_LENGTH] if row[2+i+TRANSITION_LENGTH] < DF_CEILING_VALUE else DF_CEILING_VALUE)","6809c799":"preds = model.predict(submit_transition)","307dfb49":"sample['item_cnt_month'] = preds\nsample.to_csv('submission.csv', index=False)","2a7002b6":"sample.head(50)","19f4d303":"sample['item_cnt_month'].mean()","cae204d0":"sample['item_cnt_month'].std()","979ab450":"sample['item_cnt_month'].max()","06287fb0":"plt.hist(sample['item_cnt_month'],bins=50)","46e334a3":"plt.hist(sample[(sample['item_cnt_month']>0.0)&(sample['item_cnt_month']<10.0)]['item_cnt_month'],bins=50)","2472cbe8":"plt.hist(sample[(sample['item_cnt_month']>10.0)]['item_cnt_month'],bins=50)","d531113d":"I focus to transition of cnt month sales.\n\nI divided transition of cnt month sales datast to each train data, and use LightGBM to predict future sales.","a4349652":"Preprocessing each data"}}