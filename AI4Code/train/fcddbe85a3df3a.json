{"cell_type":{"fdac601d":"code","98b40cff":"code","35df357c":"code","cf5fb024":"code","7adbbba4":"code","90722bf3":"code","b4cfc9e1":"code","14956b4f":"code","76efc832":"code","405673fd":"code","5e06229f":"code","4d772e05":"code","4d41f07b":"code","5e17ec86":"code","ce42c800":"code","1500e3a2":"code","36a5ed99":"code","16a0def3":"code","f1493915":"code","dfde3f73":"markdown","ac5ef823":"markdown","1d43877a":"markdown","e0a0662e":"markdown","373a2afd":"markdown","c144c8bd":"markdown","607fd790":"markdown","f7ee5ab7":"markdown","24b88a6b":"markdown","b2f1bb39":"markdown"},"source":{"fdac601d":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pytesseract","98b40cff":"def order_points(pts):\n    # initialzie a list of coordinates that will be ordered\n    # such that the first entry in the list is the top-left,\n    # the second entry is the top-right, the third is the\n    # bottom-right, and the fourth is the bottom-left\n    rect = np.zeros((4, 2), dtype=\"float32\")\n\n    # the top-left point will have the smallest sum, whereas\n    # the bottom-right point will have the largest sum\n    s = pts.sum(axis=1)\n    rect[0] = pts[np.argmin(s)]\n    rect[2] = pts[np.argmax(s)]\n\n    # now, compute the difference between the points, the\n    # top-right point will have the smallest difference,\n    # whereas the bottom-left will have the largest difference\n    diff = np.diff(pts, axis=1)\n    rect[1] = pts[np.argmin(diff)]\n    rect[3] = pts[np.argmax(diff)]\n\n    # return the ordered coordinates\n    return rect","35df357c":"def four_point_transform(image, pts):\n    # obtain a consistent order of the points and unpack them\n    # individually\n    rect = order_points(pts)\n    (tl, tr, br, bl) = rect\n\n    # compute the width of the new image, which will be the\n    # maximum distance between bottom-right and bottom-left\n    # x-coordiates or the top-right and top-left x-coordinates\n    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n    maxWidth = max(int(widthA), int(widthB))\n\n    # compute the height of the new image, which will be the\n    # maximum distance between the top-right and bottom-right\n    # y-coordinates or the top-left and bottom-left y-coordinates\n    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n    maxHeight = max(int(heightA), int(heightB))\n\n    # now that we have the dimensions of the new image, construct\n    # the set of destination points to obtain a \"birds eye view\",\n    # (i.e. top-down view) of the image, again specifying points\n    # in the top-left, top-right, bottom-right, and bottom-left\n    # order\n    dst = np.array([\n        [0, 0],\n        [maxWidth - 1, 0],\n        [maxWidth - 1, maxHeight - 1],\n        [0, maxHeight - 1]], dtype=\"float32\")\n\n    # compute the perspective transform matrix and then apply it\n    M = cv2.getPerspectiveTransform(rect, dst)\n    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n\n    # return the warped image\n    return warped","cf5fb024":"def automatic_brightness_and_contrast(image, clip_hist_percent=10):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # Calculate grayscale histogram\n    hist = cv2.calcHist([gray],[0],None,[256],[0,256])\n    hist_size = len(hist)\n\n    # Calculate cumulative distribution from the histogram\n    accumulator = []\n    accumulator.append(float(hist[0]))\n    for index in range(1, hist_size):\n        accumulator.append(accumulator[index -1] + float(hist[index]))\n\n    # Locate points to clip\n    maximum = accumulator[-1]\n    clip_hist_percent *= (maximum\/100.0)\n    clip_hist_percent \/= 2.0\n\n    # Locate left cut\n    minimum_gray = 0\n    while accumulator[minimum_gray] < clip_hist_percent:\n        minimum_gray += 1\n\n    # Locate right cut\n    maximum_gray = hist_size -1\n    while accumulator[maximum_gray] >= (maximum - clip_hist_percent):\n        maximum_gray -= 1\n\n    # Calculate alpha and beta values\n    alpha = 255 \/ (maximum_gray - minimum_gray)\n    beta = -minimum_gray * alpha\n\n    auto_result = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n    return auto_result, alpha, beta","7adbbba4":"def detect(img_rgb):\n\n    img = img_rgb.copy()\n    input_height = img_rgb.shape[0]\n    input_width = img_rgb.shape[1]\n    hsv_frame = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2HSV)\n\n    # yellow color\n    low_yellow = np.array([20, 100, 100])\n    high_yellow = np.array([30, 255, 255])\n    yellow_mask = cv2.inRange(hsv_frame, low_yellow, high_yellow)\n    yellow = cv2.bitwise_and(yellow_mask, yellow_mask, mask=yellow_mask)\n\n    cv2.imwrite(\"temp\/1_yellow_color_detection.png\", yellow)\n    # Close morph\n    k = np.ones((5, 5), np.uint8)\n    closing = cv2.morphologyEx(yellow, cv2.MORPH_CLOSE, k)\n\n    cv2.imwrite(\"temp\/2_closing_morphology.png\", closing)\n    # Detect yellow area\n    contours, hierarchy = cv2.findContours(closing, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n    # List of final crops\n    crops = []\n\n    # Loop over contours and find license plates\n    for cnt in contours:\n        x, y, w, h = cv2.boundingRect(cnt)\n\n        # Conditions on crops dimensions and area\n        if h*6 > w > 2 * h and h > 0.1 * w and w * h > input_height * input_width * 0.0001:\n\n            # Make a crop from the RGB image, the crop is slided a bit at left to detect bleu area\n            crop_img = img_rgb[y:y + h, x-round(w\/10):x]\n            crop_img = crop_img.astype('uint8')\n\n            # Compute bleu color density at the left of the crop\n            # Bleu color condition\n            try:\n                hsv_frame = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)\n                low_bleu = np.array([100,150,0])\n                high_bleu = np.array([140,255,255])\n                bleu_mask = cv2.inRange(hsv_frame, low_bleu, high_bleu)\n                bleu_summation = bleu_mask.sum()\n\n            except:\n                bleu_summation = 0\n\n            # Condition on bleu color density at the left of the crop\n            if bleu_summation > 550:\n\n                # Compute yellow color density in the crop\n                # Make a crop from the RGB image\n                imgray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n                crop_img_yellow = img_rgb[y:y + h, x:x+w]\n                crop_img_yellow = crop_img_yellow.astype('uint8')\n\n                # Detect yellow color\n                hsv_frame = cv2.cvtColor(crop_img_yellow, cv2.COLOR_BGR2HSV)\n                low_yellow = np.array([20, 100, 100])\n                high_yellow = np.array([30, 255, 255])\n                yellow_mask = cv2.inRange(hsv_frame, low_yellow, high_yellow)\n\n                # Compute yellow density\n                yellow_summation = yellow_mask.sum()\n\n                # Condition on yellow color density in the crop\n                if yellow_summation > 255*crop_img.shape[0]*crop_img.shape[0]*0.4:\n\n                    # Make a crop from the gray image\n                    crop_gray = imgray[y:y + h, x:x + w]\n                    crop_gray = crop_gray.astype('uint8')\n\n                    # Detect chars inside yellow crop with specefic dimension and area\n                    th = cv2.adaptiveThreshold(crop_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n                    contours2, hierarchy = cv2.findContours(th, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n                    # Init number of chars\n                    chars = 0\n                    for c in contours2:\n                        area2 = cv2.contourArea(c)\n                        x2, y2, w2, h2 = cv2.boundingRect(c)\n                        if w2 * h2 > h * w * 0.01 and h2 > w2 and area2 < h * w * 0.9:\n                            chars += 1\n\n                    # Condition on the number of chars\n                    if 20 > chars > 4:\n                        rect = cv2.minAreaRect(cnt)\n                        box = cv2.boxPoints(rect)\n                        box = np.int0(box)\n                        pts = np.array(box)\n                        warped = four_point_transform(img, pts)\n                        crops.append(warped)\n\n                        # Using cv2.putText() method\n                        img_rgb = cv2.putText(img_rgb, 'LP', (x, y), cv2.FONT_HERSHEY_SIMPLEX,1, (0, 0, 255), 2, cv2.LINE_AA)\n\n                        cv2.drawContours(img_rgb, [box], 0, (0, 0, 255), 2)\n\n    return img_rgb, crops","90722bf3":"def process(src):\n\n    # Brigthness and contrast adjustment\n    cv2.imwrite(\"temp\/3_detected_plate.png\", src)\n    adjusted, a, b = automatic_brightness_and_contrast(src)\n    cv2.imwrite(\"temp\/4_Brigthness_contrast_adjustment.png\", adjusted)\n    # BGR to gray\n    gray = cv2.cvtColor(adjusted, cv2.COLOR_BGR2GRAY)\n    cv2.imwrite(\"temp\/5_gray.png\", gray)\n    # Binary thresh\n    #ret, th = cv2.threshold(gray, 140, 255, cv2.THRESH_BINARY)\n    ret, th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    cv2.imwrite(\"temp\/6_threshold.png\", th)\n    return th","b4cfc9e1":"def post_process(text):\n    \n    puncts = [',', '.', '\"', ':', ')', '(', '!', '?', '|', ';', \"'\", '$', '&', '\/', '[', ']', '>', '%', '=',\n              '#', '*', '+', '\\\\', '\u2022', '~', '@', '\u00a3',\n              '\u00b7', '_', '{', '}', '\u00a9', '^', '\u00ae', '`', '<', '\u2192', '\u00b0', '\u20ac', '\u2122', '\u203a', '\u2665', '\u2190', '\u00d7', '\u00a7', '\u2033', '\u2032',\n              '\u00c2', '\u2588', '\u00bd', '\u2026',\n              '\u201c', '\u2605', '\u201d', '\u25cf', '\u25ba', '\u00a2', '\u00b2', '\u00ac', '\u2591', '\u00b6', '\u2191', '\u00b1', '\u00bf', '\u25be', '\u2550', '\u00a6', '\u2551',\n              '\u00a5', '\u2593', '\u2039',\n              '\u2592', '\uff1a', '\u00bc', '\u2295', '\u25bc', '\u25aa', '\u2020', '\u25a0', '\u2019', '\u2580', '\u00a8', '\u2584', '\u266b', '\u2606', '\u2666', '\u00a4', '\u25b2', '\u00b8', '\u00be',\n              '\u00c3', '\u22c5', '\u2018', '\u221e',\n              '\u2219', '\uff09', '\u2193', '\u3001', '\u2502', '\uff08', '\u00bb', '\uff0c', '\u266a', '\u2569', '\u255a', '\u00b3', '\u30fb', '\u2566', '\u2563', '\u2554', '\u2557', '\u25ac', '\u2764', '\u00d8',\n              '\u00b9', '\u2264', '\u2021', '\u221a', '\u00ab', ' ']\n\n    for punct in puncts:\n        if punct in text:\n            text = text.replace(punct, '')\n\n    return text","14956b4f":"\ndef recognise(src_path):\n    \n    custom_config = r'-l eng --psm 6 --dpi 300 --oem 1'\n    text = pytesseract.image_to_string(src_path, config=custom_config)\n\n    return text\n","76efc832":"# Load image\nimg = cv2.imread('..\/input\/dutch-plates\/3.jpg')\nplt.axis(\"off\")\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nplt.show()","405673fd":"# Make the detection\ndetection, crops = detect(img)\n\ni = 1\nfor crop in crops:\n    crop = process(crop)\n    cv2.imwrite('temp\/crop' + str(i) + '.png', crop)\n    i += 1\n    \ncv2.imwrite('temp\/detection.png', detection)\ndetection = cv2.imread('temp\/detection.png')\nplt.axis(\"on\")\nplt.imshow(cv2.cvtColor(detection, cv2.COLOR_BGR2RGB))","5e06229f":"# Processed license plate crop\ncrop = cv2.imread('temp\/crop1.png')\nplt.axis(\"off\")\nplt.imshow(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\nplt.show()","4d772e05":"# License plate recognition\ntxt = recognise(crop)\nprint(txt)","4d41f07b":"cleaned_text = post_process(txt)\nprint(cleaned_text)","5e17ec86":"# Full steps\n\nstep1 = cv2.imread('temp\/1_yellow_color_detection.png')\nplt.axis(\"off\")\nplt.imshow(cv2.cvtColor(step1, cv2.COLOR_BGR2RGB))\nplt.show()","ce42c800":"step2 = cv2.imread('.\/temp\/2_closing_morphology.png')\nplt.axis(\"off\")\nplt.imshow(cv2.cvtColor(step2, cv2.COLOR_BGR2RGB))\nplt.show()","1500e3a2":"step3 = cv2.imread('.\/temp\/3_detected_plate.png')\nplt.axis(\"off\")\nplt.imshow(cv2.cvtColor(step3, cv2.COLOR_BGR2RGB))\nplt.show()","36a5ed99":"step4 = cv2.imread('.\/temp\/4_Brigthness_contrast_adjustment.png')\nplt.axis(\"off\")\nplt.imshow(cv2.cvtColor(step4, cv2.COLOR_BGR2RGB))\nplt.show()","16a0def3":"step5 = cv2.imread('.\/temp\/5_gray.png')\nplt.axis(\"off\")\nplt.imshow(cv2.cvtColor(step5, cv2.COLOR_BGR2RGB))\nplt.show()","f1493915":"step5 = cv2.imread('.\/temp\/6_threshold.png')\nplt.axis(\"off\")\nplt.imshow(cv2.cvtColor(step5, cv2.COLOR_BGR2RGB))\nplt.show()","dfde3f73":"**Tesseract for OCR process**","ac5ef823":"**\"automatic_brightness_and_contrast\" is responsible for automatic brightness and contrast adjustment before passing the image to the detection function.**","1d43877a":"License plate detection is based on this pipeline :\n![pipe.png](attachment:pipe.png)","e0a0662e":"The function that is responsible of detecting license plate.","373a2afd":"# Some images for steps explanation","c144c8bd":"# **License plate detection using color segmentation and recognition using Google Ocr engine Tesseract**\n\nIn this work we present Dutch license plate detection based on color segmentation. We will use python with the two libraries Opencv and Numpy.\nGithub project link : https:\/\/github.com\/GuiltyNeuron\/ANPR","607fd790":"**These two functions \"four_point_transform\" and \"order_points\" are used to crop the license plate after the detection.**","f7ee5ab7":"We use this function to clean text after recognising the license plate.","24b88a6b":"# **Let's apply our function to detect and recognise Dutch license plates**","b2f1bb39":"**This function is reponsible for precesssing the detected crop (license plate crop).**"}}