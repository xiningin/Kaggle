{"cell_type":{"87123a05":"code","ab13866c":"code","66a81a2e":"code","07c19d25":"code","f3595396":"code","f88bd71d":"code","7badd7cb":"code","8ec21c41":"code","506daec6":"code","868d41e3":"code","0e627144":"code","358d7923":"code","5c64828c":"code","e3532bd0":"code","88bb75d9":"code","e0746909":"code","27685b4e":"code","cab12e79":"code","3090763b":"code","a7e0bb2d":"code","8a1fb550":"code","f343d58e":"code","99a15ab3":"code","1f4e7c05":"code","6207ded9":"code","7777e802":"code","7455bb8a":"code","db4ae5ae":"code","e5269ed0":"code","bb627814":"code","211081c0":"code","1bb67afc":"code","e44b8c5e":"code","26b0beef":"code","439cd456":"code","103c0a6e":"code","5749b959":"markdown","12d91b38":"markdown","0e277d57":"markdown","9b7900fe":"markdown","f7aa8549":"markdown","d3a291ca":"markdown","6f150efb":"markdown","b4fcc86e":"markdown","c702cd17":"markdown","bbf33a92":"markdown","f8ad6a8f":"markdown","c36d1aa1":"markdown","a253c5aa":"markdown","1aacd855":"markdown","acdffbad":"markdown","edffb905":"markdown","3ce57800":"markdown","b9c402d8":"markdown","5118c177":"markdown","e2498b91":"markdown","1cff9022":"markdown","a344803b":"markdown","d9a95b69":"markdown","0d1cbad9":"markdown","3984d442":"markdown","99d767cd":"markdown","e67b4d81":"markdown","e147bda5":"markdown","e07f387f":"markdown","e2cb053e":"markdown"},"source":{"87123a05":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import LocalOutlierFactor #cok degiskenli aykiri deger yakalama yontemi\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\nfrom sklearn.ensemble import RandomForestClassifier\n\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\npd.set_option('display.width', 500)\n\ndf = pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")\n\ndf.head()\ndf.shape\ndf.info()\n","ab13866c":"df.Pregnancies.dtypes","66a81a2e":"def grab_col_names(dataframe, cat_th=10, car_th=20):\n    \"\"\"\n     It gives the names of categorical, numerical and categorical but cardinal variables in the data set.\n     Note: Categorical variables with numerical appearance are also included in categorical variables.\n     parameters\n     -------\n         dataframe: dataframe\n             The dataframe from which variable names are to be retrieved\n         cat_th: int optional\n             class threshold for numeric but categorical variables\n         car_th: int, optional\n             class threshold for categorical but cardinal variables\n     Returns\n     -------\n         cat_cols: list\n             Categorical variable list\n         num_cols: list\n             Numeric variable list\n    \"\"\"\n\n# There are 3 concepts here: 1.Categorical variable: Gender, 2.Numerical Variable,\n# 3. Categorical Variable with Numeric View\n\n# Categorical Variables with Numeric View\n# Variables that look categorical but carry no information. Variables with high cardinality.\n# There are variables that normally appear to be categorical but not categorical.\n\n\n     # cat_cols, cat_but_car\n     # here first categorical variables are selected.\n     # then numeric but categorical ones are selected.\n\n     # If the number of classes of a numeric variable in a variable is less than 10, this variable is categorical with a numeric appearance.\n     # To catch this, look at the number of variables in the relevant variable, if it is less than the threshold (cat_th) I specified and the type of the variable is not object,\n     # ie catch variables that are stored numeric but categorical.\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    # I set car_th for categorical but cardinal variables.\n    # A categorical variable is not measurable if the number of unique classes is greater than 20. If there are as many classes as the observation class\n    cat_but_car = [col for col in dataframe.columns if dataframe [col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    # cat_cols listemizi ba\u015ftan olu\u015fturduk. Bir cat_cols listem vard\u0131 ama bir de numerik g\u00f6r\u00fcn\u00fcml\u00fc kategorikler vard\u0131.\n    cat_cols = cat_cols + num_but_cat\n    # There were variables with high cardinality in cat_cols, I'm doing them here as well.\n    # When I say select categorical but not cardinal, cat_cols is now clean.\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # HERE NOW: There are categorical ones, there are categorical ones that look numerical, and there are categorical but cardinal ones.\n\n    # num_cols\n    # here we bring those whose type is different from object. inf and floats will come.\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n\n    # There were categorical ones that looked like #numerical but we remove them from here.\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    # THUS I HAVE: I have True Numerics, True Categoricals, and Cardinals.\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, num_cols, cat_but_car\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)\n","07c19d25":"def check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False","f3595396":"def outlier_thresholds(dataframe, col_name, q1=0.05, q3=0.95):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit","f88bd71d":"for col in num_cols:\n    print(col, check_outlier(df, col))","7badd7cb":"df.shape","8ec21c41":"for col in df.columns:\n    print(col, check_outlier(df, col))","506daec6":"low, up = outlier_thresholds(df, \"Insulin\")\ndf[((df[\"Insulin\"] < low) | (df[\"Insulin\"] > up))].shape","868d41e3":"clf = LocalOutlierFactor(n_neighbors=20)\nclf.fit_predict(df)","0e627144":"df_scores = clf.negative_outlier_factor_","358d7923":"df_scores[0:5]","5c64828c":"scores = pd.DataFrame(np.sort(df_scores))\nscores.plot(stacked=True, xlim=[0, 20], style='.-')\nplt.show()","e3532bd0":"th = np.sort(df_scores)[3]","88bb75d9":"df[df_scores < th]\ndf[df_scores < th].shape","e0746909":"df.describe([0.01, 0.05, 0.75, 0.90, 0.99]).T\ndf[df_scores < th].index","27685b4e":"cat_cols, num_cols, cat_but_car = grab_col_names(df)\n\ndef target_summary_with_cat(dataframe, target, categorical_col):\n    print(pd.DataFrame({\"TARGET_MEAN\": dataframe.groupby(categorical_col)[target].mean()}), end=\"\\n\\n\\n\")\n\n\ntarget_summary_with_cat(df, \"Insulin\", \"Age\")\n\nfor col in cat_cols:\n    target_summary_with_cat(df, \"Insulin\", col)\n\ndef target_summary_with_num(dataframe, target, numerical_col):\n    print(dataframe.groupby(target).agg({numerical_col: \"mean\"}), end=\"\\n\\n\\n\")\n\n\ntarget_summary_with_num(df, \"Insulin\", \"Age\")\n\nfor col in num_cols:\n    target_summary_with_num(df, \"Insulin\", col)","cab12e79":"num_cols","3090763b":"for col in num_cols:\n    print(col, check_outlier(df, col))","a7e0bb2d":"sns.boxplot(x=df[\"Age\"])\nplt.show()","8a1fb550":"def outlier_thresholds(dataframe, col_name, q1=0.05, q3=0.95):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit","f343d58e":"def replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\nfor i in df.columns:\n low, up = outlier_thresholds(df, i)\n if ((df[i] < low) | (df[i] > up)).any():\n      print(f\"\\nIndices: {df[(df[i] < low) | (df[i] > up)].index}\\n\")\n      print(df[(df[i] < low) | (df[i] > up)].head())\n      replace_with_thresholds(df,i)\n\noutlier_thresholds(df, \"Age\")","99a15ab3":"low, up = outlier_thresholds(df, \"Age\")\n\ndf[(df[\"Age\"] < low) | (df[\"Age\"] > up)].head()","1f4e7c05":"def check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False\n\ncheck_outlier(df, \"Age\")","6207ded9":"df.isnull().values.any()","7777e802":"num_cols = [col for col in df.columns if df[col].dtype in [int, float]]\n\ncorr = df[num_cols].corr()\ndf.corr()","7455bb8a":"df.shape\ndf.head()\n\nplt.figure(figsize=(10,10))\nsns.heatmap(df.corr(),annot=True)","db4ae5ae":"def missing_values_table(dataframe, na_name=False):\n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n    ratio = (dataframe[na_columns].isnull().sum() \/ dataframe.shape[0] * 100).sort_values(ascending=False)\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n    print(missing_df, end=\"\\n\")\n    if na_name:\n        return na_columns","e5269ed0":"df.head()\n\ncols = [\"Pregnancies\",\"Glucose\",\"Insulin\"]\nfor i in cols:\n    df[i] = df[i].replace({'0': np.nan, 0: np.nan})","bb627814":"df[cols].head()\n\ndf = df.apply(lambda x: x.fillna(x.median()) if x.dtype != \"O\" else x, axis=0)\ndf.info()\ndf.head()","211081c0":"df.columns = [col.upper() for col in df.columns]","1bb67afc":"df[\"NEW_PREGNANCIES_BOOL\"] = df[\"PREGNANCIES\"].notnull().astype('int')\n\n\ndf.groupby(\"NEW_PREGNANCIES_BOOL\").agg({\"AGE\": \"mean\"})\n\ndf.loc[((df['GLUCOSE'] + df['INSULIN']) > 0), \"DIET\"] = 1\ndf.loc[((df['GLUCOSE'] + df['INSULIN']) <= 0), \"DIET\"] = 0\n\ndf.groupby(\"DIET\").agg({\"AGE\":\"mean\"})\n\n\ndf[\"NEW_AGE_INSULIN\"] = df[\"AGE\"] * df[\"INSULIN\"]\n\ndf[\"INSULIN_OUTCOME\"] = df[\"INSULIN\"] * df[\"OUTCOME\"]\n\ndf.head()\n\ndf[\"INSULIN_OUTCOME\"] = df[\"INSULIN\"].notnull().astype('int')\n\n\ndf.groupby(\"INSULIN_OUTCOME\").agg({\"OUTCOME\": \"mean\"})\n\ndf[\"INSULIN_PREGNANCIES\"] = df[\"INSULIN\"].notnull().astype('int')\n\ndf.groupby(\"INSULIN_PREGNANCIES\").agg({\"PREGNANCIES\": \"mean\"})","e44b8c5e":"df.DIET.value_counts()","26b0beef":"df.head()\ndf[\"DIET\"].head()\nle = LabelEncoder()\nle.fit_transform(df[\"DIET\"])[0:5]\n\ndef label_encoder(dataframe, binary_col):\n    labelencoder = LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe\n\nbinary_cols = [col for col in df.columns if df[col].dtype not in [int, float]\n               and df[col].nunique() == 2]\n\nfor col in binary_cols:\n    label_encoder(df, col)","439cd456":"scaler = StandardScaler()\nscaled = scaler.fit_transform(df)\ndf.head()","103c0a6e":"y = df[\"OUTCOME\"]\nX = df.drop([\"OUTCOME\"], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=17)\n\nrf_model = RandomForestClassifier(random_state=46).fit(X_train, y_train)\ny_pred = rf_model.predict(X_test)\n\naccuracy_score(y_pred, y_test)","5749b959":"It's an outlier in the insulin variable and we'll see how many outliers there are","12d91b38":"**Multivariate Outlier Analysis: Local Outlier Factor**","0e277d57":"# 6. Perform a missing observation analysis.","9b7900fe":"# Step 3. Perform the encoding operations.\nLet's label encode the OUTCOME values.","f7aa8549":"# **DIABETES DATASET**","d3a291ca":"# 3. Analyze numerical and categorical variables\n- Who are the categorical variables to the diabetes dataset here? Who are the numerical values? we asked the question of non-functional variables.\n- Now we will ask this dataframe for check_outliers.","6f150efb":"Let's observe 5 LocalOutlierFactor scores","b4fcc86e":"I can use this way when I don't want to observe them with negative values.\ndf_scores = -df_scores","c702cd17":"- Is there an outlier or not? It is necessary to generalize this to adapt it to a different variable each time.\n- I called outlier_thresholds and entered the necessary parameters.\n- If; If we want to format the other arguments of the outlier_thresholds function from the check_outlier function, so I have to enter Q1 and Q3 as arguments here.","bbf33a92":"If the number of classes of a numeric variable in a variable is less than 10, this variable is a categorical variable with a numerical appearance.\n- Who are the numerical variables? Who are the categorical variables?\n- Who are the seemingly categorical but not categorical (cardinals)?\n- Who are the categorical ones that look like numbers?","f8ad6a8f":"# **About the Dataset**\n\nThe diabetes data containing information about PIMA Indian females, near Phoenix, Arizona has been under continuous study since 1965 due to the high incidence rate of Diabetes in PIMA females. The dataset was originally published by the National Institute of Diabetes and Digestive and Kidney Diseases, consisting of diagnostic measurements pertaining to females of age greater than 20. It contains information of 768 females, of which 268 females were diagnosed with Diabetes. Information available includes 8 variables, such as, Age, Number of Pregnancies, Glucose, Insulin, etc. More detailed description about the variables is listed in the table below. The response variable in the dataset is a binary classifier, Outcome, that indicates if the person was diagnosed with Diabetes or not.\n","c36d1aa1":"# 7. Perform correlation analysis.","a253c5aa":"# Step 2. Create new variables.","1aacd855":"# 1. Examine the content of the dataset.\n\nRequired Libraries and Settings\n","acdffbad":"Query whether there is a missing value in the entire dataset","edffb905":"# Step 1. Take necessary actions for missing and outlier values. \nThere are no missing observations in the data set, but Glucose, Insulin etc. Observation units containing 0 in the variables may represent the missing value. E.g; a person's glucose or insulin value will not be 0. Considering this situation, you can assign the zero values to the relevant values as NaN and then apply the operations to the missing values.","3ce57800":"The higher, the more normal. Inliers tend to have a LOF score close to 1","b9c402d8":"How many observations are in this dataset?","5118c177":"# Step 5. Build a model.","e2498b91":"**Outliers**","1cff9022":"- The main goal is to model whether humans will survive or not, on this dataset.\n- Let's bring all the names of the variables into one format and enlarge them all.\n- Navigate through the df columns, enlarge any name you catch.","a344803b":"# 4. Perform target variable analysis. \n(The mean of the target variable according to the categorical variables, the mean of the numeric variables according to the target variable)","d9a95b69":"- boxplot returns the distribution information of a numeric variable.\n\n1. I set a threshold value.\n2. I have reached outliers.\n3. Are there any outliers or not?","0d1cbad9":"# Step 4. Standardize for numeric variables.","3984d442":"Some structures that are not significant on their own, when evaluated together, create a multivariate outlier.","99d767cd":"There seem to be 2 outliers.\nOutlier threshold was 25 to 75.\nWe know that we can use it as 5 to 95. If we approached the subject with a single variable and deleted or filled in 0 to 95, there would have been a serious loss of data.\nIf we are using tree methods, we should prefer not to to","e67b4d81":"# 2. Find numeric and categorical variables.","e147bda5":"- Catch outliers.\n- Check for outliers.","e07f387f":"I want the NaN variables in the insulin variable to link to Age and create a new variable.\nI asked if the PREGNANCIES values here are full or empty and I converted them to 1 - 0.","e2cb053e":"# 5. Perform outlier observation analysis."}}