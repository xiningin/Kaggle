{"cell_type":{"3f617ab3":"code","c0c5c413":"code","fdb1c929":"code","b26cabe6":"code","43ceebdf":"code","7ee9c40a":"code","3407e4eb":"code","b168cf8c":"code","c7e34285":"code","9d1d86fb":"code","0fb6f217":"code","714d1900":"code","c03a56b9":"code","d7f50e32":"code","61e59816":"code","02ebabe6":"code","fbc38ecf":"code","e016d2c3":"code","944e5806":"code","71129371":"code","face0f35":"code","9f034e79":"code","e5b3f770":"code","941821c3":"code","5390e550":"code","b872c29f":"code","8e38f2f0":"code","29dce574":"code","dbdc8e13":"code","754b6a4b":"code","d4019071":"code","97aaca3e":"code","f1223b1e":"code","ce343010":"code","ac31dcff":"code","e5bd2c77":"code","145ac5e5":"code","94c236ed":"code","dac87e87":"code","a5cae405":"code","8e24db0d":"code","0f7771b0":"code","15ba2279":"code","24f5cfa8":"code","db1eff90":"code","9202b5dc":"code","8d0ddbdc":"code","6aad1b0b":"markdown","4b81f692":"markdown","1e6b9fe4":"markdown","3bac7a80":"markdown","46375011":"markdown","a2700a73":"markdown"},"source":{"3f617ab3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c0c5c413":"import matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns #for heatmap and barplot","fdb1c929":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","b26cabe6":"train = train.set_index(\"PassengerId\")\ntest = test.set_index(\"PassengerId\")\n#tempTrain = train.copy()\n#tempTrain['train_test'] = 'TRAIN'\ntrain['train_test'] = 1\ntest['train_test'] = 0\ntest['Survived'] = np.NaN\nallData = pd.concat([train, test], axis=0, sort=False)\n#allData = pd.concat([tempTrain, tempVal, test])","43ceebdf":"df_num = train[['Age','SibSp','Parch','Fare']]\ndf_cat = train[['Survived','Pclass','Sex','Ticket','Cabin','Embarked']]","7ee9c40a":"f,ax=plt.subplots()\nsns.violinplot(data=train[['SibSp','Parch']])\nsns.despine(offset=10,trim=True)\n#sns.swarmplot(data=train[['SibSp','Parch']],color=\"white\")","3407e4eb":"sns.relplot(x=\"Pclass\",y=\"Age\",hue=\"Survived\",data=train);","b168cf8c":"def bar_chart(column):\n    survived=train[train[\"Survived\"]==1][column].value_counts()\n    dead=train[train[\"Survived\"]==0][column].value_counts()\n    df1=pd.DataFrame([survived,dead])\n    df1.index=[\"Survived\",\"Dead\"]\n    df1.plot(kind=\"bar\",figsize=(10,5))","c7e34285":"bar_chart(\"Pclass\")","9d1d86fb":"for i in df_num.columns:\n    plt.hist(df_num[i])\n    plt.title(i)\n    plt.show()","0fb6f217":"#print(df_num.corr())\n#sns.heatmap(df_num.corr())","714d1900":"plt.figure(figsize=(10, 6))\nsns.heatmap(train.corr(), annot=True, linewidths=0.05, fmt= '.2f',cmap=\"magma\")\nplt.show()","c03a56b9":"pd.pivot_table(train, index = 'Survived', values = ['Age','SibSp','Parch','Fare'])","d7f50e32":"print(pd.pivot_table(train, index = 'Survived', columns = 'Pclass', values = 'Ticket' ,aggfunc ='count'))\nprint()\nprint(pd.pivot_table(train, index = 'Survived', columns = 'Sex', values = 'Ticket' ,aggfunc ='count'))\nprint()\nprint(pd.pivot_table(train, index = 'Survived', columns = 'Embarked', values = 'Ticket' ,aggfunc ='count'))","61e59816":"columns = ['Pclass', 'Sex','Embarked','SibSp', 'Parch','Survived']\n\nplt.figure(figsize=(16, 14))\nsns.set(font_scale= 1.2)\nsns.set_style('ticks')\n\nfor i, feature in enumerate(columns):\n    plt.subplot(3, 3, i+1)\n    sns.countplot(data=train, x=feature, hue='Survived', palette='Paired')\n    \nsns.despine()","02ebabe6":"train.groupby(['Pclass','Sex','Survived'])['Age'].median()","fbc38ecf":"train.isna().sum()\/len(train)","e016d2c3":"#Filling the missing values with mean of Pclass and Sex.\nallData[\"Age\"].fillna(allData.groupby(['Pclass','Sex'])['Age'].transform(\"mean\"), inplace=True)","944e5806":"allData[\"Fare\"].fillna(allData.groupby(['Pclass', 'Sex'])['Fare'].transform(\"median\"), inplace=True)","71129371":"train['Title'] = train.Name.str.extract('([A-Za-z]+)\\.', expand = False)","face0f35":"train.Title.value_counts()","9f034e79":"least_occuring = ['Rev','Dr','Major', 'Col', 'Capt','Jonkheer','Countess']\n\ntrain.Title = train.Title.replace(['Ms', 'Mlle','Mme','Lady'], 'Miss')\ntrain.Title = train.Title.replace(['Countess','Dona'], 'Mrs')\ntrain.Title = train.Title.replace(['Don','Sir'], 'Mr')\n\ntrain.Title = train.Title.replace(least_occuring,'Rare')\n\ntrain.Title.unique()","e5b3f770":"pd.crosstab(train['Title'], train['Survived'])\n#faixas_etarias = df['Age'].apply(calc_faixa_etaria)\n#df.loc[:,'Faixa Etaria'] = faixas_etarias","941821c3":"#faixas_fare = df['Fare'].apply(calc_faixa_fare)\n#df.loc[:,'Faixa Fare'] = faixas_fare","5390e550":"#df.loc[:,'Tem Cabine'] = df['Cabin'].isna()  < 1","b872c29f":"idade_media = int(df['Age'].mean())\ndf.loc[:,'Age'] = df.loc[:,'Age'].fillna(idade_media)","8e38f2f0":"df.dropna(axis=1,thresh=600,inplace=True)\ndf.dropna(axis=0,subset=['Embarked'],inplace=True)","29dce574":"#df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Faixa Fare', 'Tem Cabine'],inplace=True)\n#df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Faixa etaria'],inplace=True)\ndf.drop(columns=['PassengerId', 'Name', 'Ticket'],inplace=True)","dbdc8e13":"df = pd.get_dummies(df)","754b6a4b":"target = 'Survived'\nfeatures = list(df.columns)\nfeatures.remove(target)","d4019071":"X_train, X_val, y_train, y_val = train_test_split(df[features], df[target], test_size=0.2, random_state=17)","97aaca3e":"scaler = MinMaxScaler()\nscaler.fit(X_train)\nX_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\nX_val = pd.DataFrame(scaler.transform(X_val), columns=X_train.columns)","f1223b1e":"clf = KNeighborsClassifier(n_neighbors=3)\nclf.fit(X_train, y_train)","ce343010":"y_pred = clf.predict(X_val)","ac31dcff":"acc = accuracy_score(y_val, y_pred)\nprint('Acuracia =', acc)","e5bd2c77":"n_vizinhos = np.arange(1,11)\nresultados = []\nfor k in n_vizinhos:\n  clf = KNeighborsClassifier(n_neighbors=k)\n  clf.fit(X_train, y_train)\n  y_pred = clf.predict(X_val)\n  acc = accuracy_score(y_val,y_pred)\n  resultados.append(acc)","145ac5e5":"plt.plot(n_vizinhos, resultados, '-o')\nplt.xticks(n_vizinhos);","94c236ed":"#df.loc[:,features] = pd.DataFrame(scaler.transform(df.loc[:,features]), columns=X_train.columns)","dac87e87":"#clf = KNeighborsClassifier(n_neighbors=9)\n#clf.fit(df[features], df[target])","a5cae405":"test.loc[:,'Age'] = test.loc[:,'Age'].fillna(idade_media)\ntest.loc[:,'Fare'] = test.loc[:,'Fare'].fillna(50)","8e24db0d":"aplica = test.drop(columns=['PassengerId','Name', 'Ticket', 'Cabin'])","0f7771b0":"aplica = pd.get_dummies(aplica)","15ba2279":"aplica = pd.DataFrame(scaler.transform(aplica), columns=X_train.columns)","24f5cfa8":"X_test = aplica[features]","db1eff90":"y_test = clf.predict(X_test)","9202b5dc":"subm = pd.DataFrame(y_test, columns=['Survived'])\nbase = pd.DataFrame(test['PassengerId'])","8d0ddbdc":"#base.to_csv('base.csv', index=False)\nsubm.to_csv('subm.csv', index=False)","6aad1b0b":"## Feature Engineering","4b81f692":"The most corr: Fare with Pclass (**-0.55** ->neg) and Parch with SibSP (**0.41** ->pos)","1e6b9fe4":"O melhor modelo de KNN foi obtido com n = 9 (acc > 80%). Agora vou refazer o modelo juntando a base de validacao e a de treino (Nao poderei mais medir a acuracia)","3bac7a80":"# Improvements in this release:\n* More detailed EDA\n* Add EDA on the test base\n* Code simplification\n* Improve the KNN model\n* Modelling with decision_tree \n* Incorporate Ken Jee studies (https:\/\/www.youtube.com\/watch?v=I3FBJdiExcg)\n* Incorporate [Vipin Kumar](https:\/\/www.kaggle.com\/vipin20\/titanic-prediction-eda-hyperparameter-top-10) studies \n* Incorporate [Javier Vallejos](https:\/\/www.kaggle.com\/javiervallejos\/titanic-top-3) studies ","46375011":"## Missing Values\n\nThere are three approaches with missing values: remove some observations; fill with mean, median, or mode; excluding some features.\nIn our case, we are applying these three approaches: there are just 2 obs without 'Embarked' info - so we'll remove them; less than 20% of the age is missing - so we'll fill them; more than 77% Cabin is missing - so we'll drop these feature. ","a2700a73":"# EDA\n    \n    By watching the movie, we saw that women, children, and riches had more chance to survive the accident. Now it's time to check if it was true.\n    We need to do a Exploratory Data Analysis to understand the problem and for checking if our model makes sense. In allData we have 3 bases (train,val, and test). I ckecked the 3 bases and compared them and I didn't notice any difference among all the bases. Therefore, the model can be trained on the train base, validate on the val base and applied on the test base.\n    \n## Train\/Val Base\n    \n    The Validation base corresponds a 20% of the train base (it was sorted randomly). \n    "}}