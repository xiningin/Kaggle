{"cell_type":{"1b432cfc":"code","5c20de73":"code","56f210ad":"code","58da9a2a":"code","6cffb12d":"code","9f94f5a9":"code","c39c5b49":"code","736b0beb":"code","bfcab023":"code","02d6cd38":"code","fcfc84f9":"code","eaa7c571":"code","cfac3112":"code","bcb45771":"code","71afea25":"code","e8e6c380":"code","7421778b":"code","7d224eb5":"code","17294cd5":"code","3ae277e8":"code","9943e05f":"code","d4a77a05":"code","cc6d7aa3":"code","32352739":"code","1b271db8":"code","c41c051e":"code","f7a5aa0b":"code","72ffec79":"code","61e8b35d":"code","d9737a00":"code","91245bbd":"code","66f218b4":"code","cff13e1a":"code","2178cfbb":"code","aa9c99b6":"code","bb429406":"code","2bb179eb":"code","cf7d9e68":"code","ac17eea5":"code","87d339b4":"code","0d9750c3":"code","2ebca050":"code","386a6eae":"code","132b62f3":"code","7c8a1003":"code","41760ec7":"code","bb3cd202":"code","f406e23b":"code","5249b0e6":"code","490a1e4c":"code","c941f48f":"code","79453d6c":"code","063aa8e3":"code","31928776":"code","ad42a096":"code","4de118db":"code","98a1fa28":"code","113ba827":"code","01450033":"code","85333151":"code","aabec239":"code","3ed863e2":"code","d4605d69":"markdown","1fe319c3":"markdown","2e729719":"markdown","7ea9f5d3":"markdown","ca21fff0":"markdown","20d51caa":"markdown"},"source":{"1b432cfc":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5c20de73":"train = pd.read_csv('\/kaggle\/input\/avhranalytics\/train_jqd04QH.csv')\ntest = pd.read_csv('\/kaggle\/input\/avhranalytics\/test_KaymcHn.csv')","56f210ad":"train.head()","58da9a2a":"train.dtypes","6cffb12d":"train.shape, test.shape","9f94f5a9":"combine = train.append(test)\ncombine.shape","c39c5b49":"combine.isnull().sum()","736b0beb":"combine['company_size'].value_counts()","bfcab023":"combine['company_size'].fillna(\"Unknown\", inplace=True)\ncombine['company_size'] = combine['company_size'].replace('50-99','CS_Tier3')\ncombine['company_size'] = combine['company_size'].replace('100-500','CS_Tier4')\ncombine['company_size'] = combine['company_size'].replace('10\/49','CS_Tier2')\ncombine['company_size'] = combine['company_size'].replace('10000+','CS_Tier8')\ncombine['company_size'] = combine['company_size'].replace('1000-4999','CS_Tier6')\ncombine['company_size'] = combine['company_size'].replace('<10','CS_Tier1')\ncombine['company_size'] = combine['company_size'].replace('500-999','CS_Tier5')\ncombine['company_size'] = combine['company_size'].replace('5000-9999','CS_Tier7')\ncombine['company_size'].value_counts()","02d6cd38":"combine['gender'].value_counts()","fcfc84f9":"combine['gender'].fillna(\"Unknown\", inplace=True)\ncombine['gender'].value_counts()","eaa7c571":"combine['relevent_experience'].value_counts()","cfac3112":"combine['relevent_experience'].fillna(\"Unknown\", inplace=True)\ncombine['relevent_experience'] = combine['relevent_experience'].replace('Has relevent experience','RE_Yes')\ncombine['relevent_experience'] = combine['relevent_experience'].replace('No relevent experience','RE_No')\ncombine['relevent_experience'].value_counts()","bcb45771":"combine['enrolled_university'].value_counts()","71afea25":"combine['enrolled_university'].fillna(\"Unknown\", inplace=True)\ncombine['enrolled_university'] = combine['enrolled_university'].replace('no_enrollment','No')\ncombine['enrolled_university'] = combine['enrolled_university'].replace('Full time course','Full_Time')\ncombine['enrolled_university'] = combine['enrolled_university'].replace('Part time course','Part_Time')\ncombine['enrolled_university'].value_counts()","e8e6c380":"combine['education_level'].value_counts()","7421778b":"combine['education_level'].fillna(\"0\", inplace=True)\ncombine['education_level'] = combine['education_level'].replace('Graduate','3')\ncombine['education_level'] = combine['education_level'].replace('Masters','4')\ncombine['education_level'] = combine['education_level'].replace('High School','2')\ncombine['education_level'] = combine['education_level'].replace('Phd','5')\ncombine['education_level'] = combine['education_level'].replace('Primary School','1')\ncombine['education_level'] = combine['education_level'].astype('int')\ncombine['education_level'].value_counts()","7d224eb5":"combine['major_discipline'].value_counts()","17294cd5":"combine['major_discipline'].fillna(\"Unknown\", inplace=True)\ncombine['major_discipline'] = combine['major_discipline'].replace('Business Degree','Business_Degree')\ncombine['major_discipline'] = combine['major_discipline'].replace('No Major','No_Major')\ncombine['major_discipline'].value_counts()","3ae277e8":"combine['experience'].value_counts()","9943e05f":"combine['experience'].fillna(\"-1\", inplace=True)\ncombine['experience'] = combine['experience'].replace('>20','21')\ncombine['experience'] = combine['experience'].replace('<1','0')\ncombine['experience'] = combine['experience'].astype('int')\ncombine['experience'].value_counts()","d4a77a05":"bins= [-1,0,3,6,9,12,15,18,21]\nlabels = ['Unknown','Exp_Tier1','Exp_Tier2','Exp_Tier3','Exp_Tier4','Exp_Tier5','Exp_Tier6','Exp_Tier7']\ncombine['experience'] = pd.cut(combine['experience'], bins=bins, labels=labels, right=False)\ncombine['experience'].value_counts()","cc6d7aa3":"combine['company_type'].value_counts()","32352739":"combine['company_type'].fillna(\"Unknown\", inplace=True)\ncombine['company_type'] = combine['company_type'].replace('Pvt Ltd','Pvt_Ltd')\ncombine['company_type'] = combine['company_type'].replace('Funded Startup','Funded_Startup')\ncombine['company_type'] = combine['company_type'].replace('Public Sector','Public_Sector')\ncombine['company_type'] = combine['company_type'].replace('Early Stage Startup','Early_Stage_Startup')\ncombine['company_type'].value_counts()","1b271db8":"combine['last_new_job'].value_counts()","c41c051e":"combine['last_new_job'].fillna(\"-1\", inplace=True)\ncombine['last_new_job'] = combine['last_new_job'].replace('>4','5')\ncombine['last_new_job'] = combine['last_new_job'].replace('never','0')\ncombine['last_new_job'] = combine['last_new_job'].astype('int')\ncombine['last_new_job'].value_counts()","f7a5aa0b":"combine['training_hours'].describe()","72ffec79":"combine['training_hours'] = np.log(combine['training_hours'])\ncombine['training_hours'].describe()","61e8b35d":"combine['city_development_index'].describe()","d9737a00":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ncombine['city'] = encoder.fit_transform(combine['city'])","91245bbd":"combine.dtypes","66f218b4":"train_cleaned = combine[combine['target'].isnull()!=True].drop(['enrollee_id'], axis=1)","cff13e1a":"combine = pd.get_dummies(combine)\ncombine.shape","2178cfbb":"X = combine[combine['target'].isnull()!=True].drop(['enrollee_id','target'], axis=1)\ny = combine[combine['target'].isnull()!=True]['target']\n\nX_test = combine[combine['target'].isnull()==True].drop(['enrollee_id','target'], axis=1)\n\nX.shape, y.shape, X_test.shape","aa9c99b6":"train_cleaned.head()","bb429406":"import seaborn as sns\nimport plotly.io as pio\nimport plotly.graph_objects as go\nimport plotly.express as px","2bb179eb":"fig = px.parallel_categories(train_cleaned[['education_level','enrolled_university','major_discipline','target']], \n                             color=\"target\", \n                             color_continuous_scale=px.colors.sequential.Inferno)\nfig.show()","cf7d9e68":"fig = px.parallel_categories(train_cleaned[['gender', 'target']], \n                             color=\"target\", \n                             color_continuous_scale=px.colors.sequential.Inferno)\nfig.show()","ac17eea5":"train_cleaned.columns","87d339b4":"CompanyType = pd.crosstab(train_cleaned['company_type'],train_cleaned['target']).reset_index().melt(id_vars='company_type')\nfig = px.bar(CompanyType, x=\"company_type\", y=\"value\", color='target', barmode='group',\n             height=400, width=900)\nfig.show()","0d9750c3":"Gender = pd.crosstab(train_cleaned['gender'],train_cleaned['target']).reset_index().melt(id_vars='gender')\nfig = px.bar(Gender, x=\"gender\", y=\"value\", color='target', barmode='group',\n             height=400, width=900)\nfig.show()","2ebca050":"MajorDiscipline = pd.crosstab(train_cleaned['major_discipline'],\n                              train_cleaned['target']).reset_index().melt(id_vars='major_discipline')\nfig = px.bar(MajorDiscipline, x=\"major_discipline\", y=\"value\", color='target', barmode='group',\n             height=400, width=900)\nfig.show()","386a6eae":"EducationLevel = pd.crosstab(train_cleaned['education_level'],\n                              train_cleaned['target']).reset_index().melt(id_vars='education_level')\nfig = px.bar(EducationLevel, x=\"education_level\", y=\"value\", color='target', barmode='group',\n             height=400, width=900)\nfig.show()","132b62f3":"CompanySize = pd.crosstab(train_cleaned['company_size'],\n                          train_cleaned['target']).reset_index().melt(id_vars='company_size')\nfig = px.bar(CompanySize, x=\"company_size\", y=\"value\", color='target', barmode='group',\n             height=400, width=900)\nfig.show()","7c8a1003":"Experience = pd.crosstab(train_cleaned['experience'],\n                          train_cleaned['target']).reset_index().melt(id_vars='experience')\nfig = px.bar(Experience, x=\"experience\", y=\"value\", color='target', barmode='group',\n             height=400, width=900)\nfig.show()","41760ec7":"from sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2)","bb3cd202":"from lightgbm import LGBMClassifier\nmodel = LGBMClassifier(max_depth=5,\n                       learning_rate=0.4, \n                       n_estimators=100)\n\nmodel.fit(x_train,y_train,\n          eval_set=[(x_train,y_train),(x_val, y_val.values)],\n          eval_metric='auc',\n          early_stopping_rounds=100,\n          verbose=200)\n\npred_y = model.predict_proba(x_val)[:,1]","f406e23b":"from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\nprint(roc_auc_score(y_val, pred_y))\nconfusion_matrix(y_val, pred_y>0.5)","5249b0e6":"fpr, tpr, thresholds = roc_curve(y_val, pred_y)\nfig = px.line(x=fpr, y=tpr, width=400, height=400,\n              labels={'x':'False Positive Rates','y':'True Positive Rates'})\nfig.show()","490a1e4c":"import lightgbm\nlightgbm.plot_importance(model)","c941f48f":"err = []\ny_pred_tot_lgm = []\n\nfrom sklearn.model_selection import StratifiedKFold\n\nfold = StratifiedKFold(n_splits=15)\ni = 1\nfor train_index, test_index in fold.split(X, y):\n    x_train, x_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y[train_index], y[test_index]\n    m = LGBMClassifier(boosting_type='gbdt',\n                       max_depth=5,\n                       learning_rate=0.05,\n                       n_estimators=5000,\n                       min_child_weight=0.01,\n                       colsample_bytree=0.5,\n                       random_state=1994)\n    m.fit(x_train, y_train,\n          eval_set=[(x_train,y_train),(x_val, y_val)],\n          early_stopping_rounds=200,\n          eval_metric='auc',\n          verbose=200)\n    pred_y = m.predict_proba(x_val)[:,1]\n    print(\"err_lgm: \",roc_auc_score(y_val,pred_y))\n    err.append(roc_auc_score(y_val, pred_y))\n    pred_test = m.predict_proba(X_test)[:,1]\n    i = i + 1\n    y_pred_tot_lgm.append(pred_test)","79453d6c":"np.mean(err,0)","063aa8e3":"from xgboost import XGBClassifier\n\nerrxgb = []\ny_pred_tot_xgb = []\n\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nfold = StratifiedKFold(n_splits=15)\ni = 1\nfor train_index, test_index in fold.split(X,y):\n    x_train, x_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y[train_index], y[test_index]\n    m = XGBClassifier(boosting_type='gbdt',\n                      max_depth=5,\n                      learning_rate=0.07,\n                      n_estimators=5000,\n                      random_state=1994)\n    m.fit(x_train, y_train,\n          eval_set=[(x_train,y_train),(x_val, y_val)],\n          early_stopping_rounds=200,\n          eval_metric='auc',\n          verbose=200)\n    pred_y = m.predict_proba(x_val)[:,-1]\n    print(\"err_xgb: \",roc_auc_score(y_val,pred_y))\n    errxgb.append(roc_auc_score(y_val, pred_y))\n    pred_test = m.predict_proba(X_test)[:,-1]\n    i = i + 1\n    y_pred_tot_xgb.append(pred_test)","31928776":"np.mean(errxgb,0)","ad42a096":"from catboost import CatBoostClassifier,Pool, cv\nerrCB = []\ny_pred_tot_cb = []\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nfold = StratifiedKFold(n_splits=15)\ni = 1\nfor train_index, test_index in fold.split(X,y):\n    x_train, x_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y[train_index], y[test_index]\n    m = CatBoostClassifier(n_estimators=5000,\n                           random_state=1994,\n                           eval_metric='AUC',\n                           learning_rate=0.03, max_depth=5)\n    m.fit(x_train, y_train,\n          eval_set=[(x_train,y_train),(x_val, y_val)],\n          early_stopping_rounds=200,\n          verbose=200)\n    pred_y = m.predict_proba(x_val)[:,-1]\n    print(\"err_cb: \",roc_auc_score(y_val,pred_y))\n    errCB.append(roc_auc_score(y_val,pred_y))\n    pred_test = m.predict_proba(X_test)[:,-1]\n    i = i + 1\n    y_pred_tot_cb.append(pred_test)","4de118db":"np.mean(errCB, 0)","98a1fa28":"(np.mean(errxgb, 0) + np.mean(err, 0) + np.mean(errCB, 0))\/3","113ba827":"# Stacking the predictions\nsubmission = pd.DataFrame()\nsubmission['enrollee_id'] = combine[combine['target'].isnull()==True]['enrollee_id']\nsubmission['target'] = (np.mean(y_pred_tot_lgm, 0) + np.mean(y_pred_tot_cb, 0) + np.mean(y_pred_tot_xgb, 0))\/3\nsubmission.to_csv('Stacking.csv', index=False, header=True)\nsubmission.shape","01450033":"import tensorflow as tf\nprint(tf.__version__)","85333151":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epochs, logs={}):\n        if(logs.get('val_AUC') > 0.620):\n            self.model.stop_training = True\n            \ncallbacks = myCallback()\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Input(shape=(X.shape[1],)),\n    tf.keras.layers.Dense(100, activation='relu'),\n    tf.keras.layers.Dense(10, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.summary()\n\nfrom tensorflow.keras.optimizers import RMSprop, SGD, Adamax, Adagrad\n\nmodel.compile(optimizer = \"adam\", \n              loss = 'binary_crossentropy', \n              metrics = ['AUC'])\n\nhistory = model.fit(\n    x_train, \n    y_train, \n    epochs = 30, \n    validation_data = (x_val, y_val),\n    callbacks = [callbacks]\n)\n\nscore = model.evaluate(x_val, y_val, verbose=1)\n\nprint(\"Test Score:\", score[0])\nprint(\"Test AUC:\", score[1])","aabec239":"auc = history.history['AUC']\nval_auc = history.history['val_AUC']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(auc))\n\nplt.plot(epochs, auc, label=\"Training\")\nplt.plot(epochs, val_auc, label=\"Validation\")\nplt.legend()\nplt.title('Training and validation accuracy')\nplt.show()\n\nplt.plot(epochs, loss, label=\"Training\")\nplt.plot(epochs, val_loss, label=\"Validation\")\nplt.legend()\nplt.title('Training and validation loss')\nplt.show()","3ed863e2":"pred_test = model.predict(X_test)\nsubmission = pd.DataFrame()\nsubmission['enrollee_id'] = combine[combine['target'].isnull()==True]['enrollee_id']\nsubmission['target'] = pred_test\nsubmission.to_csv('NN.csv', index=False, header=True)\nsubmission.shape","d4605d69":"# HR Analytics Challenge","1fe319c3":"# Neural Networks with 2 Layers","2e729719":" Github Link: https:\/\/github.com\/bilalProgTech\/online-data-science-ml-challenges\/tree\/master\/AV-Janata-Hack-HR-Analytics","7ea9f5d3":"A training institute which conducts training for analytics\/ data science wants to expand their business to manpower recruitment (data science only) as well. \n \nCompany gets large number of signups for their trainings. Now, company wants to connect these enrollees with their clients who are looking to hire employees working in the same domain. Before that, it is important to know which of these candidates are really looking for a new employment. They have student information related to demographics, education, experience and features related to training as well.\n \nTo understand the factors that lead a person to look for a job change, the agency wants you to design a model that uses the current credentials\/demographics\/experience to predict the probability of an enrollee to look for a new job.","ca21fff0":"# EDA","20d51caa":"# Boosting Algorithms"}}