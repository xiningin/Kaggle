{"cell_type":{"ea61fcd7":"code","13047a53":"code","8f8e7aa4":"code","41ff8eb1":"code","1777c69f":"code","4dff3870":"code","debda70f":"code","db0467f6":"code","4d4a7204":"code","49270863":"markdown","4e0dde67":"markdown","a42e4d5d":"markdown","472a9bd5":"markdown","020c8f70":"markdown"},"source":{"ea61fcd7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","13047a53":"DATASET = \"\/kaggle\/input\/ucf-cc-50-with-people-density-map\/ucfcrowdcountingdataset_cvpr13_with_people_density_map\/UCF_CC_50\/\"\nprint(os.listdir(DATASET))","8f8e7aa4":"#","41ff8eb1":"import os\nimport glob\nfrom sklearn.model_selection import train_test_split\nimport json\nimport random\nimport os\nfrom PIL import Image, ImageFilter, ImageDraw\nimport numpy as np\nimport h5py\nfrom PIL import ImageStat\nimport cv2\nimport os\nimport random\nimport torch\nimport numpy as np\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport torchvision.transforms.functional as F\nfrom torchvision import datasets, transforms\n\n\"\"\"\ncreate a list of file (full directory)\n\"\"\"\n\ndef create_training_image_list(data_path):\n    \"\"\"\n    create a list of absolutely path of jpg file\n    :param data_path: must contain subfolder \"images\" with *.jpg  (example ShanghaiTech\/part_A\/train_data\/)\n    :return:\n    \"\"\"\n    DATA_PATH = data_path\n    image_path_list = glob.glob(os.path.join(DATA_PATH, \"images\", \"*.jpg\"))\n    return image_path_list\n\n\ndef get_train_val_list(data_path, test_size=0.1):\n    DATA_PATH = data_path\n    image_path_list = glob.glob(os.path.join(DATA_PATH, \"images\", \"*.jpg\"))\n    if len(image_path_list) is 0:\n        image_path_list = glob.glob(os.path.join(DATA_PATH, \"*.jpg\"))\n    train, val = train_test_split(image_path_list, test_size=test_size)\n\n    print(\"train size \", len(train))\n    print(\"val size \", len(val))\n    return train, val\n\n\ndef load_data(img_path, train=True):\n    gt_path = img_path.replace('.jpg', '.h5').replace('images', 'ground-truth-h5')\n    img = Image.open(img_path).convert('RGB')\n    gt_file = h5py.File(gt_path, 'r')\n    target = np.asarray(gt_file['density'])\n\n    target = cv2.resize(target, (int(target.shape[1] \/ 8), int(target.shape[0] \/ 8)),\n                        interpolation=cv2.INTER_CUBIC) * 64\n\n    return img, target\n\n\ndef load_data_ucf_cc50(img_path, train=True):\n    gt_path = img_path.replace('.jpg', '.h5')\n    img = Image.open(img_path).convert('RGB')\n    gt_file = h5py.File(gt_path, 'r')\n    target = np.asarray(gt_file['density'])\n\n    target = cv2.resize(target, (int(target.shape[1] \/ 8), int(target.shape[0] \/ 8)),\n                        interpolation=cv2.INTER_CUBIC) * 64\n\n    return img, target\n\nclass ListDataset(Dataset):\n    def __init__(self, root, shape=None, shuffle=True, transform=None, train=False, seen=0, batch_size=1,\n                 num_workers=4, dataset_name=\"shanghaitech\"):\n        \"\"\"\n        if you have different image size, then batch_size must be 1\n        :param root:\n        :param shape:\n        :param shuffle:\n        :param transform:\n        :param train:\n        :param seen:\n        :param batch_size:\n        :param num_workers:\n        \"\"\"\n        if train:\n            root = root * 4\n        if shuffle:\n            random.shuffle(root)\n\n        self.nSamples = len(root)\n        self.lines = root\n        self.transform = transform\n        self.train = train\n        self.shape = shape\n        self.seen = seen\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        self.dataset_name = dataset_name\n        # load data fn\n        if dataset_name is \"shanghaitech\":\n            self.load_data_fn = load_data\n        elif dataset_name is \"ucf_cc_50\":\n            self.load_data_fn = load_data_ucf_cc50\n\n    def __len__(self):\n        return self.nSamples\n\n    def __getitem__(self, index):\n        assert index <= len(self), 'index range error'\n        img_path = self.lines[index]\n        img, target = self.load_data_fn(img_path, self.train)\n        if self.transform is not None:\n            img = self.transform(img)\n        return img, target\n\n\ndef get_dataloader(train_list, val_list, test_list, dataset_name=\"shanghaitech\"):\n    train_loader = torch.utils.data.DataLoader(\n        ListDataset(train_list,\n                            shuffle=True,\n                            transform=transforms.Compose([\n                                transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                                            std=[0.229, 0.224, 0.225]),\n                            ]),\n                            train=True,\n                            batch_size=1,\n                            num_workers=4, dataset_name=dataset_name),\n        batch_size=1, num_workers=4)\n\n    val_loader = torch.utils.data.DataLoader(\n        ListDataset(val_list,\n                            shuffle=False,\n                            transform=transforms.Compose([\n                                transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                                            std=[0.229, 0.224, 0.225]),\n                            ]), train=False, dataset_name=dataset_name),\n        batch_size=1)\n    if test_list is not None:\n        test_loader = torch.utils.data.DataLoader(\n            ListDataset(test_list,\n                        shuffle=False,\n                        transform=transforms.Compose([\n                            transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                                        std=[0.229, 0.224, 0.225]),\n                        ]), train=False, dataset_name=dataset_name),\n            batch_size=1)\n    else:\n        test_loader = None\n\n    return train_loader, val_loader, test_loader","1777c69f":"\"\"\"\ncontain dummy args with config\nhelpfull for copy paste Kaggle\n\"\"\"\nimport argparse\n\n\ndef make_args(gpu=\"0\", task=\"task_one_\"):\n    \"\"\"\n    these arg does not have any required commandline arg (all with default value)\n    :param train_json:\n    :param test_json:\n    :param pre:\n    :param gpu:\n    :param task:\n    :return:\n    \"\"\"\n    parser = argparse.ArgumentParser(description='PyTorch CSRNet')\n\n    args = parser.parse_args()\n    args.gpu = gpu\n    args.task = task\n    args.pre = None\n    return args\n\nclass Meow():\n    def __init__(self):\n        pass\n\n\ndef make_meow_args(gpu=\"0\", task=\"task_one_\"):\n    args = Meow()\n    args.gpu = gpu\n    args.task = task\n    args.pre = None\n    return args\n\n\ndef like_real_args_parse(data_input):\n    args = Meow()\n    args.input = data_input\n    args.original_lr = 1e-7\n    args.lr = 1e-7\n    args.batch_size = 1\n    args.momentum = 0.95\n    args.decay = 5 * 1e-4\n    args.start_epoch = 0\n    args.epochs = 120\n    args.steps = [-1, 1, 100, 150]\n    args.scales = [1, 1, 1, 1]\n    args.workers = 4\n    args.print_freq = 30\n    return args\n\n\ndef real_args_parse():\n    \"\"\"\n    this is not dummy\n    if you are going to make all-in-one notebook, ignore this\n    :return:\n    \"\"\"\n    parser = argparse.ArgumentParser(description='CrowdCounting')\n    parser.add_argument(\"--task_id\", action=\"store\", default=\"dev\")\n    parser.add_argument('-a', action=\"store_true\", default=False)\n\n    parser.add_argument('--input', action=\"store\",  type=str)\n    parser.add_argument('--output', action=\"store\", type=str)\n    parser.add_argument('--model', action=\"store\", default=\"csrnet\")\n\n    # args with default value\n    parser.add_argument('--lr', action=\"store\", default=1e-7, type=float)\n    parser.add_argument('--momentum', action=\"store\", default=0.95, type=float)\n    parser.add_argument('--decay', action=\"store\", default=5*1e-4, type=float)\n    parser.add_argument('--epochs', action=\"store\", default=1, type=int)\n\n    # args.original_lr = 1e-7\n    # args.lr = 1e-7\n    # args.batch_size = 1\n    # args.momentum = 0.95\n    # args.decay = 5 * 1e-4\n    # args.start_epoch = 0\n    # args.epochs = 120\n    # args.steps = [-1, 1, 100, 150]\n    # args.scales = [1, 1, 1, 1]\n    # args.workers = 4\n    # args.seed = time.time()\n    # args.print_freq = 30\n\n    arg = parser.parse_args()\n    return arg","4dff3870":"from __future__ import division\n\nimport torch\nimport math\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics.metric import Metric\n\nclass CrowdCountingMeanAbsoluteError(Metric):\n    \"\"\"\n    Calculates the mean absolute error.\n\n    - `update` must receive output of the form `(y_pred, y)`.\n    \"\"\"\n    def reset(self):\n        self._sum_of_absolute_errors = 0.0\n        self._num_examples = 0\n\n    def update(self, output):\n        y_pred, y = output\n        pred_count = torch.sum(y_pred)\n        true_count = torch.sum(y)\n        absolute_errors = torch.abs(pred_count - true_count)\n        self._sum_of_absolute_errors += torch.sum(absolute_errors).item()\n        self._num_examples += y.shape[0]\n\n    def compute(self):\n        if self._num_examples == 0:\n            raise NotComputableError('MeanAbsoluteError must have at least one example before it can be computed.')\n        return self._sum_of_absolute_errors \/ self._num_examples\n\n\nclass CrowdCountingMeanSquaredError(Metric):\n    \"\"\"\n    Calculates the mean squared error.\n\n    - `update` must receive output of the form `(y_pred, y)`.\n    \"\"\"\n    def reset(self):\n        self._sum_of_squared_errors = 0.0\n        self._num_examples = 0\n\n    def update(self, output):\n        y_pred, y = output\n        pred_count = torch.sum(y_pred)\n        true_count = torch.sum(y)\n        squared_errors = torch.pow(pred_count - true_count, 2)\n        self._sum_of_squared_errors += torch.sum(squared_errors).item()\n        self._num_examples += y.shape[0]\n\n    def compute(self):\n        if self._num_examples == 0:\n            raise NotComputableError('MeanSquaredError must have at least one example before it can be computed.')\n        return math.sqrt(self._sum_of_squared_errors \/ self._num_examples)\n\n\n","debda70f":"import torch.nn as nn\nimport torch\nfrom torchvision import models\n\n\nclass CSRNet(nn.Module):\n    def __init__(self, load_weights=False):\n        super(CSRNet, self).__init__()\n        self.seen = 0\n        self.frontend_feat = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512]\n        self.backend_feat = [512, 512, 512, 256, 128, 64]\n        self.frontend = make_layers(self.frontend_feat)\n        self.backend = make_layers(self.backend_feat, in_channels=512, dilation=True)\n        self.output_layer = nn.Conv2d(64, 1, kernel_size=1)\n        if not load_weights:\n            mod = models.vgg16(pretrained=True)\n            self._initialize_weights()\n            for i in range(len(list(self.frontend.state_dict().items()))):\n                list(self.frontend.state_dict().items())[i][1].data[:] = list(mod.state_dict().items())[i][1].data[:]\n\n    def forward(self, x):\n        x = self.frontend(x)\n        x = self.backend(x)\n        x = self.output_layer(x)\n\n        # remove channel dimension\n        # (N, C_{out}, H_{out}, W_{out}) => (N, H_{out}, W_{out})\n        x = torch.squeeze(x, dim=1)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.normal_(m.weight, std=0.01)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n\ndef make_layers(cfg, in_channels=3, batch_norm=False, dilation=False):\n    if dilation:\n        d_rate = 2\n    else:\n        d_rate = 1\n    layers = []\n    for v in cfg:\n        if v == 'M':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=d_rate, dilation=d_rate)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = v\n    return nn.Sequential(*layers)","db0467f6":"\n\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.metrics import Loss, MeanAbsoluteError, MeanSquaredError\n\nimport torch\nfrom torch import nn\n\nimport os\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nargs = like_real_args_parse(DATASET)\nprint(args)\nDATA_PATH = args.input\n\n\n# create list\ntrain_list, val_list = get_train_val_list(DATA_PATH, test_size=0.2)\ntest_list = None\n\n# create data loader\ntrain_loader, val_loader, test_loader = get_dataloader(train_list, val_list, test_list, dataset_name=\"ucf_cc_50\")\n\n\n# model\nmodel = CSRNet()\nmodel = model.to(device)\n\n# loss function\nloss_fn = nn.MSELoss(size_average=False).cuda()\n\noptimizer = torch.optim.SGD(model.parameters(), args.lr,\n                            momentum=args.momentum,\n                            weight_decay=args.decay)\n\ntrainer = create_supervised_trainer(model, optimizer, loss_fn, device=device)\nevaluator = create_supervised_evaluator(model,\n                                        metrics={\n                                            'mae': CrowdCountingMeanAbsoluteError(),\n                                            'mse': CrowdCountingMeanSquaredError(),\n                                            'nll': Loss(loss_fn)\n                                        }, device=device)\nprint(model)\n\n\n@trainer.on(Events.ITERATION_COMPLETED)\ndef log_training_loss(trainer):\n    print(\"Epoch[{}] Interation [{}] Loss: {:.2f}\".format(trainer.state.epoch, trainer.state.iteration, trainer.state.output))\n\n\n@trainer.on(Events.EPOCH_COMPLETED)\ndef log_training_results(trainer):\n    evaluator.run(train_loader)\n    metrics = evaluator.state.metrics\n    print(\"Validation Results - Epoch: {}  Avg mae: {:.2f} Avg mse: {:.2f} Avg loss: {:.2f}\"\n          .format(trainer.state.epoch, metrics['mae'], metrics['mse'], metrics['nll']))\n\n\n@trainer.on(Events.EPOCH_COMPLETED)\ndef log_validation_results(trainer):\n    evaluator.run(val_loader)\n    metrics = evaluator.state.metrics\n    print(\"Validation Results - Epoch: {}  Avg mae: {:.2f} Avg mse: {:.2f} Avg loss: {:.2f}\"\n          .format(trainer.state.epoch, metrics['mae'], metrics['mse'], metrics['nll']))\n\n\ntrainer.run(train_loader, max_epochs=150)","4d4a7204":"evaluator.run(val_loader)\nmetrics = evaluator.state.metrics\nprint(\"Validation Results - Epoch: {}  Avg mae: {:.2f} Avg mse: {:.2f} Avg loss: {:.2f}\"\n      .format(trainer.state.epoch, metrics['mae'], metrics['mse'], metrics['nll']))","49270863":"# csrnet.py","4e0dde67":"# crowd_counting_error_metrics.py","a42e4d5d":"# main","472a9bd5":"# args_util.py","020c8f70":"# data_flow.py"}}