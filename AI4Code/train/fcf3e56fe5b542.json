{"cell_type":{"bf72cd1f":"code","33b9ed16":"code","616d64ed":"code","c9bd6d14":"code","dd79a552":"code","ff3aa6fb":"code","7dc1725d":"code","86a1da57":"code","818e3c91":"code","7e85cb78":"code","a2d98ab1":"code","eb1a758b":"code","b57cca28":"code","1ebe82f6":"code","eba55d7d":"code","8b814177":"code","559610b6":"code","740ea3d5":"code","951c50b1":"code","c038c6b0":"code","e09b16c1":"code","b9c813d0":"code","9e8b8857":"markdown"},"source":{"bf72cd1f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","33b9ed16":"# \ud544\uc694\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac import\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom math import sin, cos, sqrt, atan2, radians\nimport math\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom IPython.display import HTML\nimport base64\n\n# \ub178\ud2b8\ubd81 \uc548\uc5d0 \uadf8\ub798\ud504\ub97c \uadf8\ub9ac\uae30 \uc704\ud574\n%matplotlib inline\n\n# \uadf8\ub798\ud504\uc5d0\uc11c \uaca9\uc790\ub85c \uc22b\uc790 \ubc94\uc704\uac00 \ub208\uc5d0 \uc798 \ub744\ub3c4\ub85d ggplot \uc2a4\ud0c0\uc77c\uc744 \uc0ac\uc6a9\nplt.style.use('ggplot')\n\n# \uadf8\ub798\ud504\uc5d0\uc11c \ub9c8\uc774\ub108\uc2a4 \ud3f0\ud2b8 \uae68\uc9c0\ub294 \ubb38\uc81c\uc5d0 \ub300\ud55c \ub300\ucc98\nmpl.rcParams['axes.unicode_minus'] = False","616d64ed":"from subprocess import check_output\n\nnp.set_printoptions(threshold=np.nan)\npd.set_option('display.max_columns', None)\n\nbaseDir=\"..\/input\"\nprint(check_output([\"ls\", baseDir]).decode(\"utf8\")) #check the files available in the directory","c9bd6d14":"train = pd.read_csv(baseDir+\"\/train_with_school_and_subway.csv\")\ntest = pd.read_csv(baseDir+\"\/test_with_school_and_subway.csv\")\n\ntrain.shape\ntrain.info()\n\n#train_apart = pd.read_csv(baseDir+\"\/train.csv\")\n#test_apart = pd.read_csv(baseDir+\"\/test.csv\")\n\n#train_apart.info()","dd79a552":"'''\ncorrMatt = train[[\"transaction_year_month\", \"year_of_completion\", \"exclusive_use_area\", \"floor\",  \"total_parking_capacity_in_site\",\n                 \"total_household_count_in_sites\", \"apartment_building_count_in_sites\", \"tallest_building_in_sites\" ,\"lowest_building_in_sites\" ,\"supply_area\", \"room_id\", \n                  \"total_household_count_of_area_type\", \"room_count\", \"bathroom_count\" ,\"nearest_subway_distance\",\n                 \"nearest_school_distance\",\"address_by_law_x\",\"city\",\"heat_type\",\"heat_fuel\",\"front_door_structure\",\"nearest_subway_index\",\"nearest_school_code\",\n                  \"operation_type\",\"foundation_date\",\"subway_line_count\",\"transaction_real_price\"]]\ncorrMatt = corrMatt.corr()\n#print(corrMatt)\n\nmask = np.array(corrMatt)\nmask[np.tril_indices_from(mask)] = False\n\nfig, ax = plt.subplots()\nfig.set_size_inches(20,20)\nsns.heatmap(corrMatt, mask=mask,vmax=.8, square=True,annot=True)\n'''","ff3aa6fb":"from sklearn.metrics import make_scorer\nfrom sklearn.model_selection import train_test_split # import 'train_test_split'\nfrom sklearn.ensemble import RandomForestRegressor # import RandomForestRegressor\nfrom sklearn.metrics import r2_score, make_scorer, mean_squared_error # import metrics from sklearn\nfrom time import time\n\ndef rmsle(predicted_values, actual_values, convertExp=True):\n\n    if convertExp:\n        predicted_values = np.exp(predicted_values),\n        actual_values = np.exp(actual_values)\n\n    # \ub118\ud30c\uc774\ub85c \ubc30\uc5f4 \ud615\ud0dc\ub85c \ubc14\uafd4\uc900\ub2e4.\n    predicted_values = np.array(predicted_values)\n    actual_values = np.array(actual_values)\n    \n    # \uc608\uce21\uac12\uacfc \uc2e4\uc81c \uac12\uc5d0 1\uc744 \ub354\ud558\uace0 \ub85c\uadf8\ub97c \uc50c\uc6cc\uc900\ub2e4.\n    # \uac12\uc774 0\uc77c \uc218\ub3c4 \uc788\uc5b4\uc11c \ub85c\uadf8\ub97c \ucde8\ud588\uc744 \ub54c \ub9c8\uc774\ub108\uc2a4 \ubb34\ud55c\ub300\uac00 \ub420 \uc218\ub3c4 \uc788\uae30 \ub54c\ubb38\uc5d0 1\uc744 \ub354\ud574 \uc90c\n    # \ub85c\uadf8\ub97c \uc50c\uc6cc\uc8fc\ub294 \uac83\uc740 \uc815\uaddc\ubd84\ud3ec\ub85c \ub9cc\ub4e4\uc5b4\uc8fc\uae30 \uc704\ud574\n    log_predict = np.log(predicted_values + 1)\n    log_actual = np.log(actual_values + 1)\n    \n    # \uc704\uc5d0\uc11c \uacc4\uc0b0\ud55c \uc608\uce21\uac12\uc5d0\uc11c \uc2e4\uc81c\uac12\uc744 \ube7c\uc8fc\uace0 \uc81c\uacf1\uc744 \ud574\uc900\ub2e4.\n    difference = log_predict - log_actual\n    difference = np.square(difference)\n    \n    # \ud3c9\uade0\uc744 \ub0b8\ub2e4.\n    mean_difference = difference.mean()\n    \n    # \ub2e4\uc2dc \ub8e8\ud2b8\ub97c \uc50c\uc6b4\ub2e4.\n    score = np.sqrt(mean_difference)\n    \n    return score\n\ndef output_submission(test_key, prediction, id_column, prediction_column):\n    df = pd.DataFrame(prediction, columns=[prediction_column])\n    df[\"key\"] = test_key\n    print('Output complete')\n    return df[[id_column, prediction_column]]\n    \n    \ndef output_submission2(train_key, prediction, train_org_price, prediction_column):\n    df = pd.DataFrame(prediction, columns=[prediction_column])\n    df[\"key\"] = train_key\n    df['org_real'] = train_org_price\n    \n    return df[[id_column, prediction_column,'org_real']]\n\ndef my_score(y_train, y_result):\n    score = sqrt(mean_squared_error(y_train, y_result))\n    return score\n\n\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)","7dc1725d":"label_name = \"transaction_real_price\"\n\ny_train = train[label_name].copy()","86a1da57":"train.drop(label_name,axis=1, inplace=True)\ntest.drop(label_name,axis=1, inplace=True)","818e3c91":"train_id = train['key'].copy()\ntest_id = test['key'].copy()\n\ntrain.drop(\"key\",axis=1, inplace=True)\ntest.drop(\"key\",axis=1, inplace=True)\n\n#train.drop(\"nearest_school_code\",axis=1, inplace=True)\n#test.drop(\"nearest_school_code\",axis=1, inplace=True)\n\nprint(train_id.shape)\nprint(test_id.shape)","7e85cb78":"print(train.shape)\nprint(test.shape)\n#drop_features = [\"room_count\",\"subway_line_count\",\"foundation_date\",\"operation_type\",\"front_door_structure\",\"heat_fuel\",\"heat_type\",\"nearest_school_code\",\"\"]\ndrop_features = [\"front_door_structure\",\"heat_fuel\",\"heat_type\"]\n\n#for var in drop_features:\ntrain.drop(drop_features, axis=1, inplace=True)\ntest.drop(drop_features, axis=1, inplace=True)\n\nprint(train.shape)\nprint(test.shape)","a2d98ab1":"train.info()","eb1a758b":"feature_names = [\"transaction_year_month\", \"exclusive_use_area\", \"floor\",  \"total_parking_capacity_in_site\",\n                 \"total_household_count_in_sites\", \"apartment_building_count_in_sites\", \"tallest_building_in_sites\" ,\"lowest_building_in_sites\" ,\"supply_area\",\n                  \"room_count\", \"bathroom_count\",\"nearest_subway_distance\", \"nearest_school_distance\"]\n\nfeature_names\n\nX_train = train[feature_names]\nprint(X_train.shape)\nX_train.head()\n\nX_test = test[feature_names]\nprint(X_test.shape)\nX_test.head()","b57cca28":"X_train = X_train.fillna(X_train.mean())\nX_test = X_test.fillna(X_test.mean())","1ebe82f6":"categorical_feature_names = [\"address_by_law\", \"nearest_school_index\", \"city\",\"apartment_id\",\"room_id\",\"year_of_completion\"]\n#nearest_subway_index drop\nfor var in categorical_feature_names:\n    X_train[var] = train[var].astype(\"category\")\n    X_test[var] = test[var].astype(\"category\")","eba55d7d":"#categorical_feature_names= [\"address_by_law\", \"nearest_school_index\", \"city\",\"apartment_id\"]\n# label encoder\nfrom sklearn.preprocessing import LabelEncoder\n\ncols = categorical_feature_names\n# process columns, apply LabelEncoder to categorical features\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(X_train[c].values)) \n    X_train[c] = lbl.transform(list(X_train[c].values))\n\n# shape        \nprint('Shape train: {}'.format(X_train.shape))\n\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(X_test[c].values)) \n    X_test[c] = lbl.transform(list(X_test[c].values))\n\n# shape        \nprint('Shape test: {}'.format(X_test.shape))","8b814177":"# temp for var in drop_features:\n#drop_features = [\"nearest_subway_index\"]\n#X_train.drop(drop_features, axis=1, inplace=True)\n#X_test.drop(drop_features, axis=1, inplace=True)\n\n#X_train['room_count'].replace(0, 1,inplace=True)\n#X_test['room_count'].replace(0, 1,inplace=True)\n\n\n\nprint(X_test.isnull().sum())\nX_test.info()","559610b6":"#model train\n\nrfModel = RandomForestRegressor(n_estimators=100,verbose=1,n_jobs=-1,warm_start=True)\ny_train_log = np.log1p(y_train)\n#rfModel.fit(X_train, y_train_log)","740ea3d5":"#case step 1 graph\n\nestimators = np.arange(10, 101, 10)\nscores = []\nfor n in estimators:\n    rfModel.set_params(n_estimators=n)\n    rfModel.fit(X_train, y_train_log)\n    scores.append(rfModel.score(X_train, y_train_log))\nplt.title(\"Effect of n_estimators\")\nplt.xlabel(\"n_estimator\")\nplt.ylabel(\"score\")\nplt.plot(estimators, scores)\n","951c50b1":"#case step 2 train only\n#rfModel.fit(X_train, y_train_log)","c038c6b0":"# \ud53c\uccd0 \uc2a4\ucf54\uc5b4 \ud655\uc778 \ud558\uae30.\nfeature_importances = pd.DataFrame(rfModel.feature_importances_,\n                                   index = X_train.columns,\n                                    columns=['importance']).sort_values('importance',ascending=False)\nfeature_importances.head(50)","e09b16c1":"# train \uc2a4\ucf54\uc5b4 \ud655\uc778 \ud558\uae30.\npreds = rfModel.predict(X_train)\npreds2 = np.exp(preds)\n\nscore = my_score(y_train,preds2)\nprint(\"score : {}\".format(score))","b9c813d0":"prediction = rfModel.predict(X_test)\n\nprediction = np.exp(prediction)\ndf = output_submission(test_id, prediction, 'key', 'transaction_real_price')\ncreate_download_link(df)\n#df.to_csv('mycsvfile.csv',index=False)","9e8b8857":"1.  score : 12551552.800465401 ---> Score is '99698652.456740'.\n1. score : 12552595.855800638 ---> Score is '101559494.741470'.\n"}}