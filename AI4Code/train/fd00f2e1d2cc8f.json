{"cell_type":{"cec3eb04":"code","58e158a2":"code","8ae8c3e5":"code","c1cb44dd":"code","6ca149a1":"code","d8f868a8":"code","76168f55":"code","f64e9a17":"code","33c0de51":"code","78c1380f":"code","bdae96e9":"code","6c7986e6":"code","171d8175":"code","5e0e7b26":"code","eef0015a":"code","2f8945f5":"code","581e70a1":"code","30cf249c":"code","dcbaf1bb":"code","5a194fde":"code","9db5f2b9":"code","e284c456":"code","ed207e8c":"code","2728ff02":"code","601a865b":"code","445c1036":"code","28189d6d":"markdown"},"source":{"cec3eb04":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.impute import KNNImputer, SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_selection import SelectKBest, f_regression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import RandomizedSearchCV\nimport missingno as msno","58e158a2":"train = pd.read_csv('\/kaggle\/input\/onlinedatasciencechallenge\/train.csv')\ntest  = pd.read_csv('\/kaggle\/input\/onlinedatasciencechallenge\/test_input.csv')","8ae8c3e5":"train_columns = train.columns.values\ntest_columns  = test.columns.values\nnp.setdiff1d(train_columns, test_columns)","c1cb44dd":"train.drop(columns='CONTPAIDAMNT07', inplace=True)","6ca149a1":"train_columns = train.columns.values\nnp.setdiff1d(train_columns, test_columns)","d8f868a8":"((train.isna().sum()\/train.shape[0])*100)","76168f55":"def mis_visual(df):\n    msno.bar(df)\n    msno.matrix(df)\n    msno.heatmap(df)\n    msno.dendrogram(df)\n\nmissing_cols = []\nfor col in train_columns:\n    num_na = train[col].isna().sum()\n    if num_na>0:\n        missing_cols.append(col)\n\nmis_visual(train[missing_cols])","f64e9a17":"train.drop(columns=['BLNAMNT03','TIMEDEPAVG12','TRAN_DATE'],inplace=True)\ntest.drop(columns =['BLNAMNT03','TIMEDEPAVG12','TRAN_DATE'],inplace=True)","33c0de51":"train_columns = train.columns.values\ntest_columns  = test.columns.values\nnp.setdiff1d(train_columns, test_columns)","78c1380f":"train['DEBTAVG00'].fillna(0, inplace=True)\ntrain['CARDDINSUM12'].fillna(0, inplace=True)\ntrain['EFTAMNTSUM12'].fillna(0, inplace=True)\ntrain['LASTAUTOPAYTIME'].fillna(0, inplace=True)\nautopayment = []\nfor i in range(len(train['LASTAUTOPAYTIME'])):\n    if (train['LASTAUTOPAYTIME'][i] == 0):\n        autopayment.append(0)\n    else:\n        autopayment.append(1)\n\ntrain = train.assign(AUTOPAYMENT = pd.Series(autopayment).values)","bdae96e9":"test['DEBTAVG00'].fillna(0, inplace=True)\ntest['CARDDINSUM12'].fillna(0, inplace=True)\ntest['EFTAMNTSUM12'].fillna(0, inplace=True)\ntest['LASTAUTOPAYTIME'].fillna(0, inplace=True)\nautopayment = []\nfor i in range(len(test['LASTAUTOPAYTIME'])):\n    if (test['LASTAUTOPAYTIME'][i] == 0):\n        autopayment.append(0)\n    else:\n        autopayment.append(1)\n\ntest = test.assign(AUTOPAYMENT = pd.Series(autopayment).values)","6c7986e6":"train['CUSTNBR']      = train['CUSTNBR'].astype('object')\ntrain['DEMINFO1']     = train['DEMINFO1'].astype('object')\ntrain['DEMINFO2']     = train['DEMINFO2'].astype('object')\ntrain['CONTDEBTNUM']  = train['CONTDEBTNUM'].astype('object')\ntrain['MAXTIMECONTR'] = train['MAXTIMECONTR'].astype('object')\ntrain['AUTOPAYMENT']  = train['AUTOPAYMENT'].astype('object')\ntrain['ACCACVNUM12']  = train['ACCACVNUM12'].astype('float')","171d8175":"test['CUSTNBR']      = test['CUSTNBR'].astype('object')\ntest['DEMINFO1']     = test['DEMINFO1'].astype('object')\ntest['DEMINFO2']     = test['DEMINFO2'].astype('object')\ntest['CONTDEBTNUM']  = test['CONTDEBTNUM'].astype('object')\ntest['MAXTIMECONTR'] = test['MAXTIMECONTR'].astype('object')\ntest['AUTOPAYMENT']  = test['AUTOPAYMENT'].astype('object')\ntest['ACCACVNUM12']  = test['ACCACVNUM12'].astype('float')","5e0e7b26":"y_train = train['ADDCONTAMNT']\nX_train = train.drop(columns='ADDCONTAMNT')\n\nX_test = test","eef0015a":"col_names = X_train.columns\ntypes = X_train.dtypes.to_dict()\nimp = SimpleImputer()\nX_train_imputed = pd.DataFrame(imp.fit_transform(X_train))\nX_train_imputed.columns = col_names\nX_train_imputed = X_train_imputed.astype(types)","2f8945f5":"col_names = X_test.columns\ntypes = X_test.dtypes.to_dict()\nX_test_imputed = pd.DataFrame(imp.transform(X_test))\nX_test_imputed.columns = col_names\nX_test_imputed = X_test_imputed.astype(types)","581e70a1":"X_train, X_test = X_train_imputed, X_test_imputed","30cf249c":"col_names = X_test.columns\ntypes = X_test.dtypes.to_dict()\nX_test_imputed = pd.DataFrame(imp.transform(X_test))\nX_test_imputed.columns = col_names\nX_test_imputed = X_test_imputed.astype(types)","dcbaf1bb":"col_names = X_train.columns\na = X_train.columns[range(0,len(X_train.columns))]\nb = ['x' + str(i) for i in np.arange(1,len(a)+1)]\nd = dict(zip(a, b))\nX_train = X_train.rename(columns=d)\nX_test = X_test.rename(columns=d)\ns = (X_train.dtypes == 'object')\ncat_cols = list(s[s].index)\nn = (X_train.dtypes != 'object')\nnum_cols = list(n[n].index)","5a194fde":"scaler = RobustScaler() \nscaled_num_cols = pd.DataFrame(scaler.fit_transform(X_train[num_cols]))\nscaled_num_cols.columns = num_cols","9db5f2b9":"test_scaled_num = pd.DataFrame(scaler.transform(X_test[num_cols]))\ntest_scaled_num.columns = num_cols","e284c456":"le = LabelEncoder()\nX_train.x10 = (le.fit_transform(X_train.x10))\nX_test.x10 = (le.transform(X_test.x10))\nX_train.x11 = (le.fit_transform(X_train.x11))\nX_test.x11 = (le.transform(X_test.x11))\nX_train.x30 = (le.fit_transform(X_train.x30))\nX_test.x30 = (le.transform(X_test.x30))\nX_train.x33 = (le.fit_transform(X_train.x33))\nX_test.x33 = (le.transform(X_test.x33))\nX_train.x36 = (le.fit_transform(X_train.x36))\nX_test.x36 = (le.transform(X_test.x36))","ed207e8c":"X_train = pd.concat([scaled_num_cols, X_train[cat_cols]], axis=1)\nX_test = pd.concat([test_scaled_num, X_test[cat_cols]], axis=1)","2728ff02":"print(X_train.shape, X_test.shape)","601a865b":"selector = SelectKBest(f_regression, k=30)\nselector.fit(X_train,y_train)\nX_train_selected = selector.transform(X_train)\nX_test_selected  = selector.transform(X_test)","445c1036":"#(train_updated['ACCMVMTAVG'] == 0).sum()\n#(train_updated['ACCAMNTAVG03'] == 0).sum()\n#(train_updated['CARDDINSUM12'] == 0).sum()\n#(train['EFTAMNTSUM12'] == 0).sum()\n#(train['DEBTAVG00'] == 0).sum()\n# 0 yok DON'T DROP\n################################################\n#train['TIMEDEPAVG12'].head(30)\n# 0 yok, \u00f6deyenler de\u011fil. DROP\n#(train['CONTPAIDAMNT01'] == 0).sum()\n# 0 datada var demek ki na'ler \u00f6demeyenler de\u011fil. Listwise silinebilir.","28189d6d":"Bir ka\u00e7 notebook'ta \u00e7al\u0131\u015fman\u0131n sonucunda bir kar\u0131\u015f\u0131kl\u0131k ya\u015fam\u0131\u015f\u0131m \u015fuan fark ettim, asl\u0131nda CONTPAIDAMNT00...CONTPAIDAMNT11'e kadar olan t\u00fcm column'larda ayn\u0131 missingness pattern'\u0131 var o y\u00fczden listwise silmek gerekliydi fakat ald\u0131\u011f\u0131m notu unutup onu yapmadan imputation uygulam\u0131\u015f\u0131m."}}