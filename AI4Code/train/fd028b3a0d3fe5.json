{"cell_type":{"fd332e7b":"code","786a360d":"code","3e626358":"code","9af4e542":"code","75a24ea0":"code","4f7948da":"code","e9bc5d90":"code","afed96c1":"code","e7482161":"code","97150f40":"code","81fed329":"code","9f9abe9a":"code","cc2e0617":"code","7a7ce76e":"code","97b30eca":"code","8bf59c03":"code","7e5767f1":"code","e1781b5c":"code","204e9717":"code","49dd9bf2":"code","1b21d971":"code","a64ac580":"code","911a54c5":"code","62700d8e":"code","390bce12":"code","d9a4b53e":"code","2813df1f":"code","226cb008":"code","88595536":"code","2515ecb1":"code","1051dbad":"code","818a5943":"code","db9a10b0":"code","6ea2f9aa":"code","fa8b3d16":"code","20716319":"code","ea64cc2a":"code","e52aaa8d":"code","71abbb5f":"code","66537cb7":"code","2d7e3c2b":"code","228d7181":"markdown","3c81e21a":"markdown","089c7061":"markdown","bb48f503":"markdown","796c845c":"markdown","900381a2":"markdown","81b55b97":"markdown","7dfc84a3":"markdown","efa7756e":"markdown","2bc707f2":"markdown"},"source":{"fd332e7b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","786a360d":"\n!git clone https:\/\/github.com\/fizyr\/keras-retinanet.git","3e626358":"!pip install --upgrade keras","9af4e542":"%cd keras-retinanet\/\n\n!pip install .","75a24ea0":"!python setup.py build_ext --inplace\n","4f7948da":"import os\nimport tensorflow as tf\nimport cv2\nimport tempfile\nimport numpy as np \nimport pandas as pd\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nfrom matplotlib.patches import Rectangle\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n","e9bc5d90":"\nfrom tensorflow import keras\nimport seaborn as sns\nfrom pylab import rcParams\nfrom matplotlib import rc\nfrom pandas.plotting import register_matplotlib_converters\nimport csv\nimport cv2\nimport time\nfrom sklearn.model_selection import train_test_split\n#RETINANET LIBRARIES\nfrom keras_retinanet import models\nfrom keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\nfrom keras_retinanet.utils.visualization import draw_box, draw_caption\nfrom keras_retinanet.utils.colors import label_color\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nregister_matplotlib_converters()\nsns.set(style='whitegrid', palette='muted', font_scale=1.5)\n\nrcParams['figure.figsize'] = 22, 10\n","afed96c1":"##############################################################################################################################\n#CREATING DATAFRAME FOR DATA PRE PROCESSING AND CREATING DICTIONARY{DICT1} FOR LABELS\n##############################################################################################################################\n\n%cd ..\ncsv_pth = '..\/input\/face-mask-detection-dataset\/train.csv'\n\ndf = pd.read_csv(csv_pth,header=None)\ndf = df.iloc[1:]\ndf[0] = '..\/input\/face-mask-detection-dataset\/Medical mask\/Medical mask\/Medical Mask\/images\/' + df[0].astype(str)\n\nprint(df.head())\n\n\nprint(\"==============================================================================\")\n\nndf = pd.read_csv(csv_pth,index_col='name')\n\ndict1={}\ncategories=set(ndf['classname'])\nfor j,i in enumerate(categories):\n    dict1[i] = j+1\nprint(dict1)\n\n\n","e7482161":"##############################################################################################################################\n#CREATING ndf DATAFRAME JUST FOR CHECKING AND ANALYSING THE DATA AND CORDINATES LIST FOR DRAWING THE BOUNDING BOX\n##############################################################################################################################\n\ncordinates=list(ndf.iloc[:,0:4].values)\n\nndf['cordinates'] = cordinates\nndf=ndf.drop(['x1', 'x2','y1','y2'], axis = 1) \nprint(ndf)","97150f40":"##############################################################################################################################\n#CREATING DIR JUST FOR ANALYSING THE DATA_SET\n##############################################################################################################################\nsrc_dir = r'..\/input\/face-mask-detection-dataset\/Medical mask\/Medical mask\/Medical Mask\/images\/'\nsrc_img=os.listdir(src_dir)\ntest_src=src_img[:1698]\ntrain_src=src_img[1698:]\n\nprint(len(train_src))\nprint(len(test_src))\n\ntrain_img=train_src\ntrain_img_path=[os.path.join(src_dir, fname) for fname in train_img]\n\ntest_img=test_src\ntest_img_path=[os.path.join(src_dir, fname) for fname in test_img]\n\nprint(train_img_path)\nprint(\"==============================================================================\")\nprint(test_img_path)","81fed329":"##############################################################################################################################\n# CREATING FUNCTION TO CREATING BOUNDING BOX AND GIVING TAGS FOR ANALYSED IMAGES\n##############################################################################################################################\n\nimport matplotlib.patches as patches\n\ndef bounds_and_taggs(img):\n    coords=[];classes=[]\n    ndf1=(ndf.loc[[img]].values)\n    #print(ndf1)\n    for i in ndf1:\n        classes.append(i[0])\n        coords.append(i[1])\n    classes= list(set(classes))\n    return coords,classes","9f9abe9a":"##############################################################################################################################\n#TESTING THE bounds_and_taggs FUNCTION AND ANALYSING THE DATA\n##############################################################################################################################\ncoords,classes=bounds_and_taggs(train_img[355])\n\nplt.imshow(Image.open(train_img_path[355]))\nfor i in coords:\n    plt.gca().add_patch(Rectangle((i[0],i[1]),i[2]-i[0],i[3]-i[1],linewidth=1.5,edgecolor='g',facecolor='none'))\nprint(\"related tags: ->\",classes)\nplt.show()","cc2e0617":"##############################################################################################################################\n#SPLITTING THE DATA IN TRAINING AND TESTING USING SCIKITLEARN. RATIO IS 85:15 TRAIN AND TESTING RESPECTIVELY.\n##############################################################################################################################\n\ntrain_df, test_df = train_test_split(\n  df, \n  test_size=0.15, \n  shuffle=False\n)","7a7ce76e":"##############################################################################################################################\n#HANDLING THE VALUE_ERROR I WAS FACING AT 8132 IN DATAFRAME SO I DROPPED THE ROW.\n##############################################################################################################################\n\ntrain_df.iloc[8131:8132,:]\ntrain_df=train_df.drop([8132], axis=0)","97b30eca":"##############################################################################################################################\n#CHECKING THE LENGTH OF BOTH THE DATASET.\n##############################################################################################################################\n\nprint(\"trining set len ->\",len(train_df))\nprint(\"testing set len ->\",len(test_df))","8bf59c03":"##############################################################################################################################\n#CREATING ESSENTIAL CSV AS RETINANET REQUIRES TWO CSV FILE AS ARGUMENT, ANNOTATION FILE AND CLASSES FILE.\n##############################################################################################################################\n\ntrain_annots_file = 'train_annots.csv'\ntest_annots_file = 'test_annots.csv'\nclasses_file='classes.csv'","7e5767f1":"##############################################################################################################################\n#CONVERTING THE DATAFRAME INTO CSV FILES USING PANDAS, AND...\n#WE DONT WANNA INCLUDE HEADER AND INDEX AS RETINANET WONT TAKE CARE OF THAT.\n##############################################################################################################################\n\ntrain_df.to_csv(train_annots_file, index=False, header=None)\ntest_df.to_csv(test_annots_file, index=False, header=None)","e1781b5c":"##############################################################################################################################\n#CHECKING IF THE CONVERSION TO CSV WENT WELL\n##############################################################################################################################\n\n!head train_annots.csv\n#!head test_annots.csv","204e9717":"##############################################################################################################################\n#SWAPPING THE VALUES OF key and value pair IN DICT1 AND CONVERTING IT INTO LABELS FOR TRAINING\n##############################################################################################################################\n\nlabels = dict([(value, key) for key, value in dict1.items()])\nlabels\n\n","49dd9bf2":"##############################################################################################################################\n#WRITING THE LABELS FILE INTO CSV FOR PASSING IT INTO TRAING AS A ARGUMENT.\n##############################################################################################################################\n\nwith open(classes_file, 'w') as f:\n  for i,j in labels.items():\n    f.write('{},{}\\n'.format(j,i))","1b21d971":"##############################################################################################################################\n#CHECKING IF THE CONVERSION TO CSV WENT WELL.\n##############################################################################################################################\n\n!head classes.csv\n!tail classes.csv","a64ac580":"##############################################################################################################################\n#IMPORTING THE TRAINING MODEL FROM THE GIVEN LINK AND WE WILL USE THIS PRETAINED MODEL FOR CUSTOM TRAINING OF OUR DATSET.\n##############################################################################################################################\n\nimport urllib\n\nPRETRAINED_MODEL = 'pretrained_model.h5'\n\nURL_MODEL = 'https:\/\/github.com\/fizyr\/keras-retinanet\/releases\/download\/0.5.1\/resnet50_coco_best_v2.1.0.h5'\nurllib.request.urlretrieve(URL_MODEL, PRETRAINED_MODEL)\n\nprint('Downloaded pretrained model to ' + PRETRAINED_MODEL)","911a54c5":"##############################################################################################################################\n#INSTALLING TENSORFLOW-GPU\n##############################################################################################################################\n\n!pip install tensorflow-gpu","62700d8e":"##############################################################################################################################\n#FILES NEEDED FOR TRAINING.\n##############################################################################################################################\n\nANNOTATIONS_FILE = 'train_annots.csv'\nCLASSES_FILE = 'classes.csv'","390bce12":"##############################################################################################################################\n#FINALLY TRAIING .. USING BATCHSIZE= 8 ;  STEPS= 500 ; EPOCHS= 10 ;\n##############################################################################################################################\n\n\n!keras-retinanet\/keras_retinanet\/bin\/train.py \\\n--freeze-backbone \\\n--random-transform \\\n--weights {PRETRAINED_MODEL} \\\n--batch-size 8 \\\n--steps 500 \\\n--epochs 10 \\\ncsv train_annots.csv classes.csv\n","d9a4b53e":"##############################################################################################################################\n#CHEKING THE \n##############################################################################################################################\n\n!ls snapshots","2813df1f":"##############################################################################################################################\n#GIVING MODEL, A PATH\n##############################################################################################################################\n\nmodel_path = os.path.join('snapshots', sorted(os.listdir('snapshots'), reverse=True)[0])\n\nprint(model_path)\n\nmodel = models.load_model(model_path, backbone_name='resnet50')\nmodel = models.convert_model(model)","226cb008":"##############################################################################################################################\n#SAVING THE TRAINED MODEL USING PICKLE LIBRARY\n##############################################################################################################################\n\n# import pickle\n# filename = 'cutom_model.sav'\n# pickle.dump(model, open(filename, 'wb'))","88595536":"##############################################################################################################################\n#LOADING THE MODEL \n##############################################################################################################################\n# import pickle\n# Pkl_Filename = r'custom_model.sav'\n# with open(Pkl_Filename, 'rb') as file:  \n#     Pickled_Model = pickle.load(file)","2515ecb1":"##############################################################################################################################\n#CONVERTING THE CLASSES(LABELS CSV FILE) INTO DICTIONARY AGAIN.ALSO TAKING TRANSPOSE.\n##############################################################################################################################\n\nlabels_to_names = pd.read_csv(classes_file, header=None).T.loc[0].to_dict()\nlabels_to_names","1051dbad":"##############################################################################################################################\n#USING IMAGE PRE_PROCESSING PROVIDED BY RETINANET AND PREDICTING USING THE TRAINED MODEL.\n##############################################################################################################################\n\ndef predict(image):\n  image = preprocess_image(image.copy())\n  image, scale = resize_image(image)\n\n  boxes, scores, labels = model.predict_on_batch(\n    np.expand_dims(image, axis=0)\n  )\n\n  boxes \/= scale\n\n  return boxes, scores, labels","818a5943":"##############################################################################################################################\n#DRAWING BOX ACROSS THE DETECTED OBJECTS \n##############################################################################################################################\n\nTHRES_SCORE = 0.55\n\ndef draw_detections(image, boxes, scores, labels):\n    \n    coordinates=[];category=[];\n\n    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n\n        if score < THRES_SCORE:\n            break\n\n        color = label_color(label)\n        #print(label)\n\n        b = box.astype(int)\n        draw_box(image, b, color=color)\n\n        caption = \"{} {:.3f}\".format(labels_to_names[label-1], score)\n        draw_caption(image, b, caption)\n        category.append(labels_to_names[label-1])\n        coordinates.append(box)\n\n    return coordinates,category\n    ","db9a10b0":"##############################################################################################################################\n#LABELLING OR TAGIING AND ALSO CREATING BOUNDING BOX AROUNG THE DETECTED OBJECT\n##############################################################################################################################\n\ndef show_detected_objects(image_row):\n    img_path = image_row[\"name\"]\n#     img_dir='..\/input\/face-mask-detection-dataset\/Medical mask\/Medical mask\/Medical Mask\/images'\n#     img_path=os.path.join(img_dir, img_path)\n\n    image = read_image_bgr(img_path)\n\n    boxes, scores, labels = predict(image)\n\n    draw = image.copy()\n    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n\n    true_box = [\n      image_row[\"x1\"], image_row[\"x2\"], image_row[\"y1\"], image_row[\"y2\"]\n    ]\n    #draw_box(draw, true_box, color=(255, 255, 0))\n    #####################################################################\n    #the below code is just for creating submission csv \n    #####################################################################\n    coordinates,category=draw_detections(draw, boxes, scores, labels)\n#     final_df=pd.DataFrame(coordinates,columns=['x1' , 'x2', 'y1', 'y2'])\n#     final_df['label']=category\n#     final_df['name']=image_row['name']\n#     final_df=final_df[['name','x1' , 'x2', 'y1', 'y2','label']]\n#     return final_df\n\n\n\n    plt.axis('off')\n    plt.imshow(draw)\n    plt.show()","6ea2f9aa":"##############################################################################################################################\n#CHANGING DATAFRAME NAMES IN CONVENIENCE TO PASSING ARGUMENTS ACROSS THE FUNCTION.\n##############################################################################################################################\n\ntest_df.columns = ['name', 'x1', 'x2', 'y1','y2','classname']\ntest_df","fa8b3d16":"##############################################################################################################################\n#TESTING ANY RANDOM IMAGES\n##############################################################################################################################\nshow_detected_objects(test_df.iloc[558])","20716319":"##############################################################################################################################\n#GENERATING SUBMISSION CSV\n##############################################################################################################################\nsubmission=pd.read_csv(\"..\/input\/face-mask-detection-dataset\/submission.csv\")\nsubmission = submission.drop_duplicates()\nsubmission.head()","ea64cc2a":"##############################################################################################################################\n#CREATING DATAFRAME SKELETON FOR THE SUBMISSION\n##############################################################################################################################\nsubmission_df=pd.DataFrame(columns=['name','x1' , 'x2', 'y1', 'y2','label'])","e52aaa8d":"##############################################################################################################################\n#IMPORTING VALUE INTO SUBMISSION DATAFRAME\n##############################################################################################################################\nfor i in range(0,len(submission)):\n    b=show_detected_objects(submission.iloc[i])\n    submission_df=submission_df.append(b,ignore_index = True)\nsubmission_df.head()","71abbb5f":"submission_df","66537cb7":"complete=submission_df.to_csv(r'submission_csv.csv')","2d7e3c2b":"#################################################################################################################################################################################","228d7181":"# This Model is trained using Retinanet\n\nREFERENCE_LINK = https:\/\/github.com\/fizyr\/keras-retinanet\n\nAbout retinanet :Keras implementation of RetinaNet object detection as described in Focal Loss for Dense Object Detection by Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He and Piotr Doll\u00e1r.","3c81e21a":">  # IMPORTING AND INSTALLING PRE-REQUISITE FOR RETINANET","089c7061":"# TRAINING......................\/\/\/\/ FINALLYYYY....","bb48f503":"> # PRE_TRAINING PROCESS","796c845c":"> # GENERATING SUBMISSION CSV","900381a2":"> #  PREDICTING,TAGGING & DRAWING FUNCTIONS.","81b55b97":"# PREDICTIONS.........\/-\\-\/-\\-\/-\\-\/-\\-\/","7dfc84a3":"> # ITS DONE AND DUSTED.....................\/","efa7756e":"> # DATA PRE_PROCESSING & ANALYZING.......\\\\\\\\\\","2bc707f2":"#  Importing Data"}}