{"cell_type":{"f49d0f7d":"code","0dbb6fac":"code","8afc7ab8":"code","d95ed3bb":"code","d5eda3c8":"code","8539ee7e":"code","f71b86a2":"code","4d0c3436":"code","76edd4c4":"code","330adba5":"code","ebdbe018":"code","8e45e403":"code","4e28b164":"code","66b10889":"code","f275178c":"code","385436f0":"code","461ca692":"code","147d4839":"code","37b50b2a":"code","be52a5c3":"code","d3fb09fb":"code","e11b6188":"code","3213e08c":"code","55ed0cf9":"code","f16c66dd":"markdown","78439855":"markdown","f3265176":"markdown","cbd2f1f0":"markdown","8fbc194e":"markdown","eba154de":"markdown","ad058fb3":"markdown","760d851d":"markdown","e5a0de83":"markdown","4c0bdeb9":"markdown","65c91a92":"markdown","e199fa05":"markdown","a7783399":"markdown","ea991545":"markdown","fd2a2da3":"markdown"},"source":{"f49d0f7d":"!pip install pycaret","0dbb6fac":"import pandas as pd \nimport numpy as np\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom sklearn.metrics import r2_score\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom joblib import dump, load\n\n%matplotlib inline\nsns.set(color_codes=True)\npal = sns.color_palette(\"viridis\", 10)\nsns.set_palette(pal)","8afc7ab8":"data = pd.read_csv('..\/input\/dl-course-data\/concrete.csv')","d95ed3bb":"data.isnull().sum()","d5eda3c8":"!pip install dataprep","8539ee7e":"from dataprep.eda import plot, create_report","f71b86a2":"plot(data)","4d0c3436":"create_report(data)","76edd4c4":"#log1p is log(1+x), did this to handle log(0) case\n\ndata['BlastFurnaceSlag'] = np.log1p(data['BlastFurnaceSlag'])\ndata['FlyAsh'] = np.log1p(data['FlyAsh'])\ndata['Water'] = np.log1p(data['Water'])\ndata['Superplasticizer'] = np.log1p(data['Superplasticizer'])\ndata['Age'] = np.log1p(data['Age'])","330adba5":"from pycaret.regression import *\nreg = setup(data = data , target = 'CompressiveStrength', numeric_features= list(data.drop(['CompressiveStrength'],axis=1).columns),remove_outliers=True,   silent=True, train_size = 0.7)","ebdbe018":"compare_models()","8e45e403":"cb = create_model('catboost')","4e28b164":"plot_model(cb)","66b10889":"plot_model(cb, plot = 'feature')","f275178c":"interpret_model(cb)","385436f0":"X = data.iloc[:,:-1].values\ny = data.iloc[:,-1].values\nX_train, X_dev, y_train, y_dev = train_test_split(X,y,random_state=13, train_size = 0.7)","461ca692":"from catboost import CatBoostRegressor, Pool\ntrain_pool = Pool(data=X_train, label=y_train)\ntest_pool = Pool(data = X_dev, label = y_dev)\n\ndef r2_check(lr):\n    cb_2 = CatBoostRegressor(eval_metric='R2',random_state=13, learning_rate=lr*0.001).fit(train_pool, eval_set = test_pool,  verbose=False)\n    pred = cb_2.predict(X_dev)\n    return r2_score(y_dev,pred)\n\ndef get_best_lr(r2):\n    m=0\n    best_lr=0\n    for i in range(len(r2)):\n        if r2[i]>m:\n            m=r2[i]\n            best_lr = 0.001*(i+51)\n    return best_lr","147d4839":"lr = [i for i in range(51,100)]\nr2 = []\nfor i in lr:\n    r2.append(r2_check(i))\nprint(max(r2), get_best_lr(r2))\ncb_2 = CatBoostRegressor(eval_metric='R2',random_state=13, learning_rate=get_best_lr(r2)).fit(train_pool, eval_set = test_pool,  verbose=False)\npred = cb_2.predict(X_dev)\n","37b50b2a":"df = pd.DataFrame({'True Compressive Stength (MPA)': y_dev , 'Predicted Compressive Strength(MPA)': pred}).head(40)\ndf","be52a5c3":"X = data.drop(['CompressiveStrength'],axis=1)\ny = data['CompressiveStrength']\nX_train, X_dev, y_train, y_dev = train_test_split(X,y,random_state=13, train_size = 0.75)\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nX_train = ss.fit_transform(X_train)\nX_dev = ss.transform(X_dev)","d3fb09fb":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\nmodel = keras.Sequential([\n    layers.Dense(512, activation='relu', input_shape=[8]),\n    layers.Dropout(0.2),\n    layers.BatchNormalization(),\n    layers.Dense(512, activation='relu'),\n    layers.Dropout(0.2),\n    layers.BatchNormalization(),\n    layers.Dense(512, activation='relu'),\n    layers.Dropout(0.2),\n    layers.BatchNormalization(),\n    layers.Dense(1),\n])","e11b6188":"\nmodel.compile(\n    optimizer='adam',\n    loss='mae', \n)\n\nhistory = model.fit(\n    X_train, y_train, \n    validation_data=(X_dev, y_dev),\n    batch_size=32,\n    epochs=100,\n    verbose=0\n)\n\n\n# Show the learning curves\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot();\nprint((\"Minimum Validation Loss: {:0.4f}\").format(history_df['val_loss'].min()))","3213e08c":"pred = model.predict(X_dev)\nr2_score(y_dev,pred)","55ed0cf9":"dump(cb_2, 'model.joblib')","f16c66dd":"## 2. Data Prepration","78439855":"> #### Catboost giving best score","f3265176":"> ## No improvement to Catboost Score","cbd2f1f0":"## Kindly Upvote the notebook if you found it informative, Thanks!! ","8fbc194e":"## 3. Model Selection with Pycaret\n### Its an auto ML library, we will take its help to find the best model to fit our data, It saves time and code !!","eba154de":"## Handling Skewness\n\n### As shown in the report variables that are skewed are\n1. BlastfurnaceSlag\n2. Flyash\n3. Water\n4. Superplasticiser\n5. Age\n\n### To handle Skewness there are many methods, we will use Log transformation","ad058fb3":"### Checking Predictions","760d851d":">#### Log transformation decreased the Mean Absolute error by > 0.1 and increased the r2 score from 0.92 to 0.933 on best model","e5a0de83":"------- End of the Notebook ---------- ","4c0bdeb9":"> ### No null value","65c91a92":"# Predicting Conrete Compressive Strength\n\n## This is an starter notebook for the regression task of Concrete Compressive Strength, this notebook follows these steps :-\n\n##### 1. EDA and Visualisation (using auto EDA library Dataprep)\n##### 2. Data Prepration (Handling Skewed Data and data preprocessing)\n##### 3. Model Selection (using Pycaret AutoML)\n##### 4. Visualising Model and Predictions\n##### 5. Building and Comparing Neural Network Model\n##### 6. Finalising the best Model\n\n## This notebook can be used as guide to any Regression task.","e199fa05":"## 4. Visualising Model and Predictions","a7783399":"## 1. EDA and detailed report with Dataprep","ea991545":"## 5. Let's Compare Catboost with Neural Network","fd2a2da3":"## 6. Finalising and Saving best Model"}}