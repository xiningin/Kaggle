{"cell_type":{"612fbd4a":"code","dd75e4e9":"code","ef6acde1":"code","9454c6a4":"code","f6ddb6cf":"code","4cc9697f":"code","0e1e403f":"code","063d92f4":"code","45d2018a":"code","e31f7f27":"code","9d92c9f1":"code","4c06cca3":"code","b0591fae":"code","4e9ea066":"code","ea6c2b79":"code","aa97e8f7":"code","0698869e":"code","7264f47d":"code","8f7a7a9f":"code","fd47e9d0":"code","6a24f0bc":"code","d56b3746":"code","91996a1f":"code","3723582b":"code","2bca37d0":"code","b2f2b4e5":"markdown","b9916489":"markdown","73e787ea":"markdown","7b46eacc":"markdown","2ededb2e":"markdown","188f2fe2":"markdown","60c5b2c1":"markdown","58f1666b":"markdown","d4f98389":"markdown","bed9f2ba":"markdown","6c88da71":"markdown","f4221bfe":"markdown","6d567ccd":"markdown","2a663489":"markdown","0d776f9d":"markdown","9f85e16d":"markdown","39d06eea":"markdown","933d216a":"markdown","74dc5c05":"markdown","4884c8a1":"markdown","651fa9d9":"markdown","9bd9e015":"markdown","62e9affc":"markdown","74c2f0e1":"markdown"},"source":{"612fbd4a":"import warnings\nwarnings.filterwarnings('ignore')","dd75e4e9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport json\nfrom pandas.io.json import json_normalize\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ef6acde1":"import datetime\n\nimport IPython\nimport IPython.display\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom sklearn.ensemble import RandomForestRegressor\n\nmpl.rcParams['figure.figsize'] = (8, 6)\nmpl.rcParams['axes.grid'] = False","9454c6a4":"token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}","f6ddb6cf":"train_full = pd.read_json('..\/input\/stanford-covid-vaccine\/train.json', lines=True)\ntrain_full.shape","4cc9697f":"train_full.head().T","0e1e403f":"train_json = [json.loads(line) for line in open('..\/input\/stanford-covid-vaccine\/train.json', 'r')]","063d92f4":"def preprocess_json(input_json):\n    \n    for index,json_ in enumerate(input_json):\n        length = json_['seq_scored']\n        json_['step'] = list(range(length))\n            \n        json_['sequence'] = pd.Series([json_['sequence']]).map(lambda seq: [token2int[x] for x in seq]).values.tolist()[0][:length]\n        json_['structure'] = pd.Series([json_['structure']]).map(lambda seq: [token2int[x] for x in seq]).values.tolist()[0][:length]\n        json_['predicted_loop_type'] = pd.Series([json_['predicted_loop_type']]).map(lambda seq: [token2int[x] for x in seq]).values.tolist()[0][:length]\n        if os.path.exists('..\/input\/stanford-covid-vaccine\/bpps\/'+json_['id']+'.npy'):\n            json_['unpaired_probability'] = list(1-sum(np.load('..\/input\/stanford-covid-vaccine\/bpps\/'+json_['id']+'.npy')))[:length]\n        else:\n            print('bpps not found')\n\npreprocess_json(train_json)","45d2018a":"def process_json(input_json):\n    train = pd.json_normalize(data = input_json, \n                                record_path ='step',  \n                                meta =['id','seq_length','seq_scored']) \n    train.rename(columns={0:'step'}, inplace=True)\n    train['unpaired_probability'] = pd.json_normalize(data = input_json, \n                                record_path ='unpaired_probability'\n                                            )\n    train['sequence'] = pd.json_normalize(data = input_json, \n                                record_path ='sequence'\n                                            )\n    train['structure'] = pd.json_normalize(data = input_json, \n                                record_path ='structure'\n                                            )\n    train['predicted_loop_type'] = pd.json_normalize(data = input_json, \n                                record_path ='predicted_loop_type'\n                                            )\n    train['reactivity'] = pd.json_normalize(data = input_json, \n                                    record_path ='reactivity'\n                                                )\n    train['reactivity_error'] = pd.json_normalize(data = input_json, \n                                    record_path ='reactivity_error'\n                                                )\n    train['deg_Mg_pH10'] = pd.json_normalize(data = input_json, \n                                    record_path ='deg_Mg_pH10'\n                                                )\n    train['deg_error_Mg_pH10'] = pd.json_normalize(data = input_json, \n                                    record_path ='deg_error_Mg_pH10'\n                                                )\n    train['deg_pH10'] = pd.json_normalize(data = input_json, \n                                    record_path ='deg_pH10',\n                                                )\n    train['deg_error_pH10'] = pd.json_normalize(data = input_json, \n                                    record_path ='deg_error_pH10',\n                                                )\n    train['deg_Mg_50C'] = pd.json_normalize(data = input_json, \n                                    record_path ='deg_Mg_50C',\n                                                )\n    train['deg_error_Mg_50C'] = pd.json_normalize(data = input_json, \n                                    record_path ='deg_error_Mg_50C',\n                                                )\n    train['deg_50C'] = pd.json_normalize(data = input_json, \n                                    record_path ='deg_50C',\n                                                )\n    train['deg_error_50C'] = pd.json_normalize(data = input_json, \n                                    record_path ='deg_error_50C',\n                                                )\n        \n    train.set_index(['id','step'], inplace=True)\n    return train\n\nX_train = process_json(train_json)","e31f7f27":"def post_process_json(input_df):\n    input_df = pd.concat([input_df.drop('sequence', axis=1), pd.get_dummies(input_df['sequence'], prefix='Base')], axis=1)\n    input_df = pd.concat([input_df.drop('structure', axis=1), pd.get_dummies(input_df['structure'], prefix='Structure')], axis=1)\n    input_df = pd.concat([input_df.drop('predicted_loop_type', axis=1), pd.get_dummies(input_df['predicted_loop_type'], prefix='Loop')], axis=1)\n    return input_df\n\nX_train_full = post_process_json(X_train)","9d92c9f1":"label_cols = ['reactivity','deg_Mg_pH10','deg_pH10','deg_Mg_50C','deg_50C']\ny_train = X_train_full[label_cols]","4c06cca3":"input_cols = ['Base_3','Base_4','Base_5','Base_6','Structure_0','Structure_1','Structure_2','Loop_7','Loop_8','Loop_9','Loop_10','Loop_11','Loop_12','Loop_13']\nX_train = X_train_full[input_cols]","b0591fae":"corr_matrix = X_train.corr()\n\nmask = np.zeros_like(corr_matrix, dtype=np.bool)\nmask[np.triu_indices_from(mask)]= True\n\nf, ax = plt.subplots(figsize=(20, 20)) \nheatmap = sns.heatmap(corr_matrix, \n                      mask = mask,\n                      square = True,\n                      linewidths = .5,\n                      cmap = 'coolwarm',\n                      cbar_kws = {'shrink': .4, \n                                'ticks' : [-1, -.5, 0, 0.5, 1]},\n                      vmin = -1, \n                      vmax = 1,\n                      annot = True,\n                      annot_kws = {'size': 12})#add the column names as labels\nax.set_yticklabels(corr_matrix.columns, rotation = 0)\nax.set_xticklabels(corr_matrix.columns)\nsns.set_style({'xtick.bottom': True}, {'ytick.left': True})","4e9ea066":"print(token2int)","ea6c2b79":"model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\nmodel.fit(X_train, y_train)\nimportances = pd.DataFrame({'feature':input_cols,'importance':np.round(model.feature_importances_,3)})\n\nplt.figure(figsize=(10, 5))\nsns.barplot(x=importances['importance'], y=importances['feature'])\nplt.title('Feaure Importance')\nplt.tight_layout()\nimportances = importances.sort_values('importance',ascending=False).set_index('feature')\nimportances","aa97e8f7":"input_cols = ['unpaired_probability','Base_3','Base_4','Base_5','Base_6','Structure_0','Structure_1','Structure_2','Loop_7','Loop_8','Loop_9','Loop_10','Loop_11','Loop_12','Loop_13']\nX_train = X_train_full[input_cols]","0698869e":"corr_matrix = X_train.corr()\n\nmask = np.zeros_like(corr_matrix, dtype=np.bool)\nmask[np.triu_indices_from(mask)]= True\n\nf, ax = plt.subplots(figsize=(20, 20)) \nheatmap = sns.heatmap(corr_matrix, \n                      mask = mask,\n                      square = True,\n                      linewidths = .5,\n                      cmap = 'coolwarm',\n                      cbar_kws = {'shrink': .4, \n                                'ticks' : [-1, -.5, 0, 0.5, 1]},\n                      vmin = -1, \n                      vmax = 1,\n                      annot = True,\n                      annot_kws = {'size': 12})#add the column names as labels\nax.set_yticklabels(corr_matrix.columns, rotation = 0)\nax.set_xticklabels(corr_matrix.columns)\nsns.set_style({'xtick.bottom': True}, {'ytick.left': True})","7264f47d":"model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\nmodel.fit(X_train, y_train)\nimportances = pd.DataFrame({'feature':input_cols,'importance':np.round(model.feature_importances_,3)})\n\nplt.figure(figsize=(10, 5))\nsns.barplot(x=importances['importance'], y=importances['feature'])\nplt.title('Feaure Importance')\nplt.tight_layout()\nimportances = importances.sort_values('importance',ascending=False).set_index('feature')\nimportances","8f7a7a9f":"submission = pd.read_csv('..\/input\/stanford-covid-vaccine\/sample_submission.csv', index_col= 0)\nsubmission.to_csv('submission.csv')\nsubmission.T","fd47e9d0":"# Dummy","6a24f0bc":"# Dummy","d56b3746":"# Dummy","91996a1f":"y_train.describe()","3723582b":"n = submission.shape[0]\nreactivity_bar = 0.374922; reactivity_sd = 0.725652\ndeg_Mg_pH10_bar = 0.446303; deg_Mg_pH10_sd = 0.704172\ndeg_pH10_bar = 0.446911; deg_pH10_sd = 1.285747\ndeg_Mg_50C_bar = 0.407030; deg_Mg_50C_sd = 0.868013\ndeg_50C_bar = 0.425889; deg_50C_sd = 1.122356\nsubmission['reactivity']=np.random.normal(reactivity_bar, reactivity_sd, size=n)\nsubmission['deg_Mg_pH10']=np.random.normal(deg_Mg_pH10_bar, deg_Mg_pH10_sd, size=n)\nsubmission['deg_pH10']=np.random.normal(deg_pH10_bar, deg_pH10_sd, size=n)\nsubmission['deg_Mg_50C']=np.random.normal(deg_Mg_50C_bar, deg_Mg_50C_sd, size=n)\nsubmission['deg_50C']=np.random.normal(deg_50C_bar, deg_50C_sd, size=n)\nsubmission","2bca37d0":"submission.to_csv('submission.csv')","b2f2b4e5":"## Train your model","b9916489":"It can be seen that unpaired probability, base type and loop 8 ('E') have major contribution to output. And as hypothesised, the contributions of structure and loop 12 have gone down which is a good indication. It can be also noted that unpaired probability contributes about 85% of all the information,","73e787ea":"Seems you will need something like an LSTM that works on sequence data.","7b46eacc":"This will be overwritten if everything works fine.","2ededb2e":"It can be seen that loop 12 ('S' type - paired stem) has good correlation with Structure.  Especially Structure 2, i.e. unpaired bases has a -1 correlation, which means they are negatively correlated. This is correct since an unpaired base cannot form a paired stem. And structure 0 and structure 1 has correlation 0.58 each, which is also intuitive as they are the paired bases forming the paired stem. Hence it can be hypothesised that the structure fields do not add any new information over the loop 12 filed and can be removed.","188f2fe2":"It can be noted that there is high negative correlation between unpaired probability and loop 12, structure information. This is also intuitive as paired bases will have near to zero unpaired probability and unpaired bases will have near to one unpaired probability. So it seems that this single feature can encode the information in these 4 fields. Lets check it out.","60c5b2c1":"Lets use values mean and std from train data as a dummy submission","58f1666b":"### Make dummy submission File","d4f98389":"## Develop Your model","bed9f2ba":"## Filling dummy values","6c88da71":"A starter notebook for those planning to build your submission from scratch. Will update with EDA as and when time permits.","f4221bfe":"This notebook presents how to find correlation between features and grade features by importance for training.","6d567ccd":"Not so intuitive, right. Lets see if we can flatten it.","2a663489":"## Submit","0d776f9d":"## Perform your prediction","9f85e16d":"# OpenVaccine: COVID-19 mRNA Vaccine Degradation Prediction Getting Started Notebook","39d06eea":"## Feature Importance","933d216a":"# EOF","74dc5c05":"Lets check these assumptions with a feature importance metric derived from Random Forest","4884c8a1":"## Find the correlation between Features and Display on a heatmap","651fa9d9":"## Read train and test json","9bd9e015":"You have to make 107 \/ 130 predictions per input for the 5 parameters (only 3 of these are used for scoring).","62e9affc":"## Feature:Unpaired Probability\n\nLets repeat the above analysis with unpaired probability.","74c2f0e1":"It can be seen that first four features amount to almost 90% of information. Base unpaired information (structure 2), loop 8(E), loop 12(S), loop 9(H), loop 10(I) and bases can provide almost the full information. Structure 0 and structure 1 contribution is less because this information is there in loop12. But eventhough structure 2 and loop 12 have a -1 correlation, that is not depicted here. This is here the forest is unable to decode this link, Lets probe further to see if we can use that information as well."}}