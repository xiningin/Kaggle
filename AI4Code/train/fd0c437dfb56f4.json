{"cell_type":{"d2f99db9":"code","b525a586":"code","a399f22c":"code","6bd02727":"code","0108e18d":"code","2d024a72":"code","81491c3e":"code","53510bac":"code","f316f4a8":"code","ff97ba29":"code","a6ec7330":"code","2ccfdbeb":"code","12d46db9":"code","44de0692":"code","57d6007d":"code","6e1f7375":"code","b7fcda01":"code","398f9939":"code","96a08e5c":"code","fb581c1e":"code","9186d50b":"code","ebccd1c7":"code","e96d9453":"code","14f757fd":"code","882e2275":"code","eccb5ac7":"code","d24400d2":"code","80c7617f":"code","998a134d":"code","0d210269":"code","64c1d718":"code","56774600":"code","f19633ad":"code","854efcc2":"code","9ddeb7f2":"code","5fa73ff9":"code","a85a09b1":"code","0423489d":"code","f1c82835":"code","0d9eec82":"code","8bcdab4a":"code","4ab3440f":"code","329e688d":"code","2eac0872":"code","57732129":"code","46b096f3":"code","3910c3e7":"code","8e67f0ca":"code","706a217c":"code","ddb04a86":"code","9eed6a0f":"code","48406ffd":"markdown","b37d733e":"markdown","1cfdd5db":"markdown","3864b9ed":"markdown","80a0d73f":"markdown","237e19ec":"markdown","a1ff7bf9":"markdown","9a46f6cf":"markdown","61fd083a":"markdown","28e08276":"markdown","b2eb6bda":"markdown","4905eb1f":"markdown"},"source":{"d2f99db9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b525a586":"# Import Python Packages\n# PyTesseract and Tika-Python for OCR\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport shutil\nimport PIL\nimport os\nfrom os import walk\nfrom shutil import copytree, ignore_patterns\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\nfrom PIL import Image\nfrom wand.image import Image as Img\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', 500)\n#mueller_report = pd.read_csv('..\/input\/data-science-cheat-sheets\/Interview Questions\/AI Questions.pdf') # one row per line","a399f22c":"# Define helper function for plotting word clouds\ndef wordCloudFunction(df,column,numWords):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    word_string=str(popular_words_nonstop)\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white',\n                          max_words=numWords,\n                          width=1000,height=1000,\n                         ).generate(word_string)\n    plt.clf()\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()","6bd02727":"# Define helper function for plotting word bar graphs\ndef wordBarGraphFunction(df,column,title):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    plt.barh(range(50), [word_count_dict[w] for w in reversed(popular_words_nonstop[0:50])])\n    plt.yticks([x + 0.5 for x in range(50)], reversed(popular_words_nonstop[0:50]))\n    plt.title(title)\n    plt.show()","0108e18d":"# Preview the data folder\ninputFolder = '..\/input\/'\nfor root, directories, filenames in os.walk(inputFolder):\n    for filename in filenames: \n        print(os.path.join(root,filename))\n        \n# Move data to folder with read\/write access\noutputFolder = '\/kaggle\/working\/pdfs\/'\nshutil.copytree(inputFolder,outputFolder,ignore=ignore_patterns('*.db'))\nfor root, directories, filenames in os.walk(outputFolder, topdown=False):\n    for file in filenames:\n        try:\n            shutil.move(os.path.join(root, file), outputFolder)\n        except OSError:\n            pass\nprint(os.listdir(outputFolder))","2d024a72":"# Look at page 3\npdf = os.path.join(outputFolder,'immunity.pdf[3]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/immunity.jpg') # intro page to preview later","81491c3e":"# Parse a PDF file and convert it to CSV using PyTesseract\nimport pytesseract\npdfimage = Image.open('\/kaggle\/working\/immunity.jpg')\ntext = pytesseract.image_to_string(pdfimage)  \ndf = pd.DataFrame([text.split('\\n')])","53510bac":"# Plot WordCloud of page 3\nplt.figure(figsize=(10,10))\nwordCloudFunction(df.T,0,10000000)\nplt.figure(figsize=(10,10))\nwordBarGraphFunction(df.T,0,\"Most Common Words on Page  of BCG\/CFP Immunity\")","f316f4a8":"import matplotlib.pyplot as plt \nimport seaborn as sns\n%matplotlib inline\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as py\nimport plotly.express as px\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom graphviz import Source","ff97ba29":"from colorama import Fore, Style\n\nnRowsRead = 1000 # specify 'None' if want to read whole file\n# ham_lyrics.csv has 3634 rows in reality, but we are only loading\/previewing the first 1000 rows\ndf = pd.read_csv('..\/input\/hackathon\/task_2-owid-covid-data-22_September_2020.csv', delimiter=',', nrows = nRowsRead)\ndf.dataframeName = 'task_2-owid-covid-data-22_September_2020.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\nprint(Fore.CYAN + 'Data shape: ',Style.RESET_ALL,df.shape)\ndf.head()","a6ec7330":"#Code by Md Redwan Karim Sony https:\/\/www.kaggle.com\/redwankarimsony\/space-missions-data-eda-temporal-analysis\n\n# Calculating\npercent_missing = df.isnull().sum() * 100 \/ len(df)\nmissing_value_df = pd.DataFrame({'column': df.columns,\n                                 'percent': percent_missing})\nmissing_value_df.sort_values('percent', inplace=True)\nmissing_value_df.reset_index(drop=True, inplace=True)\nmissing_value_df = missing_value_df[missing_value_df['percent']>0]\n\n# Plotting\nfig = px.bar(\n    missing_value_df, \n    x='percent', \n    y=\"column\", \n    orientation='h', \n    title='Columns with Missing Values', \n    height=200, \n    width=600\n)\nfig.show()","2ccfdbeb":"# categorical features with missing values\ncategorical_nan = [feature for feature in df.columns if df[feature].isna().sum()>0 and df[feature].dtypes=='O']\nprint(categorical_nan)","12d46db9":"# Lets handle numerical features with nan value\nnumerical_nan = [feature for feature in df.columns if df[feature].isna().sum()>1 and df[feature].dtypes!='O']\nnumerical_nan","44de0692":"df[numerical_nan].isna().sum()","57d6007d":"## Replacing the numerical Missing Values\n\nfor feature in numerical_nan:\n    ## We will replace by using median since there are outliers\n    median_value=df[feature].median()\n    \n    df[feature].fillna(median_value,inplace=True)\n    \ndf[numerical_nan].isnull().sum()","6e1f7375":"cols_to_drop=['new_tests','total_tests', 'total_tests_per_thousand', 'new_tests_per_thousand', 'new_tests_smoothed', 'new_tests_smoothed_per_thousand', 'tests_per_case', 'positive_rate', 'tests_units']\ndf=df.drop(cols_to_drop,axis=1)\ndf.columns","b7fcda01":"from sklearn.preprocessing import LabelEncoder\n\n#fill in mean for floats\nfor c in df.columns:\n    if df[c].dtype=='float16' or  df[c].dtype=='float32' or  df[c].dtype=='float64':\n        df[c].fillna(df[c].mean())\n\n#fill in -999 for categoricals\ndf = df.fillna(-999)\n# Label Encoding\nfor f in df.columns:\n    if df[f].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(df[f].values))\n        df[f] = lbl.transform(list(df[f].values))\n        \nprint('Labelling done.')","398f9939":"df = pd.get_dummies(df)","96a08e5c":"import seaborn as sbn\n\ncorrelation=df.corr()\nplt.figure(figsize=(15,15))\nsbn.heatmap(correlation,annot=True,cmap=plt.cm.Greens)","fb581c1e":"import shap\nimport lightgbm as lgb\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nimport random","9186d50b":"SEED = 99\nrandom.seed(SEED)\nnp.random.seed(SEED)","ebccd1c7":"dfmodel = df.copy()\n\n# read the \"object\" columns and use labelEncoder to transform to numeric\nfor col in dfmodel.columns[dfmodel.dtypes == 'object']:\n    le = LabelEncoder()\n    dfmodel[col] = dfmodel[col].astype(str)\n    le.fit(dfmodel[col])\n    dfmodel[col] = le.transform(dfmodel[col])","e96d9453":"#change columns names to alphanumeric\ndfmodel.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in dfmodel.columns]","14f757fd":"X = dfmodel.drop(['stringency_index','population_density'], axis = 1)\ny = dfmodel['stringency_index']","882e2275":"lgb_params = {\n                    'objective':'binary',\n                    'metric':'auc',\n                    'n_jobs':-1,\n                    'learning_rate':0.005,\n                    'num_leaves': 20,\n                    'max_depth':-1,\n                    'subsample':0.9,\n                    'n_estimators':2500,\n                    'seed': SEED,\n                    'early_stopping_rounds':100, \n                }","eccb5ac7":"# choose the number of folds, and create a variable to store the auc values and the iteration values.\nK = 5\nfolds = KFold(K, shuffle = True, random_state = SEED)\nbest_scorecv= 0\nbest_iteration=0\n\n# Separate data in folds, create train and validation dataframes, train the model and cauculate the mean AUC.\nfor fold , (train_index,test_index) in enumerate(folds.split(X, y)):\n    print('Fold:',fold+1)\n          \n    X_traincv, X_testcv = X.iloc[train_index], X.iloc[test_index]\n    y_traincv, y_testcv = y.iloc[train_index], y.iloc[test_index]\n    \n    train_data = lgb.Dataset(X_traincv, y_traincv)\n    val_data   = lgb.Dataset(X_testcv, y_testcv)\n    \n    LGBM = lgb.train(lgb_params, train_data, valid_sets=[train_data,val_data], verbose_eval=250)\n    best_scorecv += LGBM.best_score['valid_1']['auc']\n    best_iteration += LGBM.best_iteration\n\nbest_scorecv \/= K\nbest_iteration \/= K\nprint('\\n Mean AUC score:', best_scorecv)\nprint('\\n Mean best iteration:', best_iteration)","d24400d2":"lgb_params = {\n                    'objective':'binary',\n                    'metric':'auc',\n                    'n_jobs':-1,\n                    'learning_rate':0.05,\n                    'num_leaves': 20,\n                    'max_depth':-1,\n                    'subsample':0.9,\n                    'n_estimators':round(best_iteration),\n                    'seed': SEED,\n                    'early_stopping_rounds':None, \n                }\n\ntrain_data_final = lgb.Dataset(X, y)\nLGBM = lgb.train(lgb_params, train_data)","80c7617f":"print(LGBM)","998a134d":"# telling wich model to use\nexplainer = shap.TreeExplainer(LGBM)\n# Calculating the Shap values of X features\nshap_values = explainer.shap_values(X)","0d210269":"shap.summary_plot(shap_values[1], X, plot_type=\"bar\")","64c1d718":"shap.summary_plot(shap_values[1], X)","56774600":"#Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\ncolor = plt.cm.RdBu(np.linspace(0,1,20))\ndf[\"stringency_index\"].value_counts().sort_values(ascending=False).head(20).plot.pie(y=\"population_density\",colors=color,autopct=\"%0.1f%%\")\nplt.title(\"View of the Pandemic by Stringency Index\")\nplt.axis(\"off\")\nplt.show()","f19633ad":"#Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\ncolor = plt.cm.flag(np.linspace(0,1,20))\ndf[\"aged_65_older\"].value_counts().sort_values(ascending=False).head(10).plot.pie(y=\"total_cases\",colors=color,autopct=\"%0.1f%%\")\nplt.title(\"View of the Pandemic by Age 65 older\")\nplt.axis(\"off\")\nplt.show()","854efcc2":"#Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\ncolor = plt.cm.ocean(np.linspace(0,1,20))\ndf[\"female_smokers\"].value_counts().sort_values(ascending=False).head(10).plot.pie(y=\"new_cases_smoothed\",colors=color,autopct=\"%0.1f%%\")\nplt.title(\"View of the Pandemic by Female Smokers\")\nplt.axis(\"off\")\nplt.show()","9ddeb7f2":"#Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\ncolor = plt.cm.Oranges(np.linspace(0,1,20))\ndf[\"diabetes_prevalence\"].value_counts().sort_values(ascending=False).head(20).plot.pie(y=\"new_cases_per_million\",colors=color,autopct=\"%0.1f%%\")\nplt.title(\"View of the Pandemic by Diabetes Prevalence\")\nplt.axis(\"off\")\nplt.show()","5fa73ff9":"#Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\ncolor = plt.cm.Blues(np.linspace(0,1,20))\ndf[\"extreme_poverty\"].value_counts().sort_values(ascending=False).head(20).plot.pie(y=\"new_deaths_per_milion\",colors=color,autopct=\"%0.1f%%\")\nplt.title(\"View of the Pandemic by Extreme Poverty\")\nplt.axis(\"off\")\nplt.show()","a85a09b1":"import plotly.offline as pyo\nimport plotly.graph_objs as go\nlowerdf = df.groupby('cardiovasc_death_rate').size()\/df['total_deaths_per_million'].count()*100\nlabels = lowerdf.index\nvalues = lowerdf.values\n\n# Use `hole` to create a donut-like pie chart\nfig = go.Figure(data=[go.Pie(labels=labels, values=values,marker_colors = px.colors.sequential.Darkmint, hole=.6)])\nfig.show()","0423489d":"fig = px.pie(df,\n             values=\"stringency_index\",\n             names=\"population_density\",\n             template=\"seaborn\")\nfig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\nfig.show()","f1c82835":"fig = px.pie(df,\n             values=\"aged_65_older\",\n             names=\"continent\",\n             template=\"seaborn\")\nfig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\nfig.show()","0d9eec82":"px.bar(df, x = 'stringency_index', y = 'population_density', color = 'continent',orientation='h' , title='Covid-19 Stringency Index vs Population Density',  height = 500 )","8bcdab4a":"px.bar(df, x = 'total_deaths', y = 'aged_65_older', color = 'continent',orientation='h' , title='Covid-19 Deaths by Age',  height = 500 )","4ab3440f":"px.histogram(df, x='total_deaths', range_x=[-5, 50], color='continent')","329e688d":"fig = px.bar(df, x= \"continent\", y= \"total_deaths\", color_discrete_sequence=['crimson'], title=\"Total Covid-19 Deaths by Continent\")\nfig.show()","2eac0872":"# Count Plot\nplt.style.use(\"classic\")\nplt.figure(figsize=(8, 6))\nsns.countplot(df['continent'], palette='RdBu', **{'hatch':'\/','linewidth':3})\nplt.xlabel(\"Continents\")\nplt.ylabel(\"Count\")\nplt.title(\"View of the Pandemic by Continents\")\nplt.xticks(rotation=45, fontsize=8)\nplt.show()","57732129":"#Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\ncolor = plt.cm.rainbow(np.linspace(0,1,20))\ndf[\"continent\"].value_counts().sort_values(ascending=False).head(10).plot.pie(y=\"total_deaths\",colors=color,autopct=\"%0.1f%%\")\nplt.title(\"View of the Pandemic by Continents\")\nplt.axis(\"off\")\nplt.show()","46b096f3":"fig = px.bar(df, x= \"stringency_index\", y= \"population_density\", color_discrete_sequence=['#2B3A67'], title=\"Stringency Index vs. Population density\")\nfig.show()","3910c3e7":"ls ..\/input\/hackathon\/task_1-google_search_txt_files_v2\/PM\/","8e67f0ca":" SaintPierreMiquelon= '..\/input\/hackathon\/task_1-google_search_txt_files_v2\/PM\/Saint Pierre and Miquelon-en-result-108-original.txt'","706a217c":"text = open(SaintPierreMiquelon, 'r',encoding='utf-8',\n                 errors='ignore').read()","ddb04a86":"print(text[:2500])","9eed6a0f":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Thanks for your patience \u2013 please keep coming back to see my improvements, @mpwolke Was Here.' )","48406ffd":"#There are still many missing values.","b37d733e":"#Mycobacterium tuberculosis Culture Filtrate Proteins plus CpG Oligodeoxynucleotides Confer Protection to Mycobacterium bovis\n#BCG-Primed Mice by Inhibiting Interleukin-4 Secretion.\n\nAuthors: Denise Morais da Fonseca, Celio Lopes Silva, Pryscilla Fanini Wowk, Marina Oliveira e Paula,\nSimone Gusm\u00e3o Ramos, Cynthia Horn, Gilles Marchal, and V\u00e2nia Luiza Deperon Bonato.\n\n\nCulture filtrate proteins (CFP) are potential targets for tuberculosis vaccine development. The Authors previously showed that despite the high level of gamma interferon (IFN-) production elicited by homologous immunization with CFP plus CpG oligodeoxynucleotides (CFP\/CpG). \n\nThey did not observe protection when these mice were challenged with Mycobacterium tuberculosis. In order to use the IFN-inducing ability of CFP antigens,in this study they evaluated a prime-boost heterologous immunization based on CFP\/CpG to boost Mycobacterium bovis BCG vaccination in order to find an immunization schedule that could induce protection. Heterologous BCG-CFP\/CpG immunization provided significant protection against experimental tuberculosis, and this protection was sustained during the late phase of infection and was even better than that conferred by a single BCG immunization. \n\nThe protection was associated with high levels of antigen-specific IFN- and interleukin-17 (IL-17) and low IL-4 production. The deleterious role of IL-4 was confirmed when IL-4 knockout mice vaccinated with CFP\/CpG showed consistent protection similar to that elicited by BCG-CFP\/CpG heterologous immunization.\n\nThese findings show that a single dose of CFP\/CpG can represent a new strategy to boost the protection conferred by BCG vaccination. Moreover, different immunological parameters, such as IFN- and IL-17 and tightly regulated IL-4 secretion, seem to contribute to the efficacy of this tuberculosis vaccine.https:\/\/www.arca.fiocruz.br\/bitstream\/icict\/39057\/2\/ve_Fonseca_Denise_etal_INI_2009.pdf\nhttps:\/\/www.arca.fiocruz.br\/handle\/icict\/39057","1cfdd5db":"#Codes from Paul Mooney https:\/\/www.kaggle.com\/paultimothymooney\/what-is-inside-of-the-mueller-report\/notebook","3864b9ed":"#Handling Missing Values","80a0d73f":"#I have no clue why only Three continents. Have you?","237e19ec":"#I had already made `total_deaths` and `aged_65_older`, therefore I tried to see how stringency_index works with `population_density`","a1ff7bf9":"#Final Model Modify the hyperparameters to use the best iteration value and train the final model","9a46f6cf":"#\"Bacille Calmette-Gu\u00e9rin (BCG) remains the only effective vaccine against disseminated TB, but its inability to confer complete #protection against pulmonary TB in adolescents and adults calls for an urgent need to develop new and better vaccines. There is #also a need to identify markers of disease protection and develop novel drugs.\" \n\nWords from the text printed above (nanosymposium at the Institute of Infectious Disease and Molecular Medicine at the University of Cape Town).","61fd083a":"#PDF to CSV\n\nConvert Page 3 of PDF to CSV (Method 1 of 2: PyTesseract)","28e08276":"![](https:\/\/iai.asm.org\/content\/iai\/77\/12\/5311\/F1.medium.gif)\n#Protection against experimental TB conferred by the different vaccination schedules.\n\nBALB\/c mice (n = 8 to 10) were immunized subcutaneously with a single dose of BCG (BCG group), three doses of CFP\/CpG (CFP\/CpG group) at 7-day intervals, one dose of BCG followed by one dose of CFP\/CpG after 15 days (BCG-CFP\/CpG group), or one dose of CFP\/CpG followed by one dose of BCG after 15 days (CFP\/CpG-BCG group). Sixty days after vaccination, mice were challenged with a virulent strain of M. tuberculosis. At 30 (A) or 70 (B) days after infection, the lungs were processed for the CFU assay and histopathological analysis. Bacterial load is expressed as log10 CFU\/g of lung from the means \u00b1 standard deviations of serial dilutions individually counted for each group. Results are from experiments repeated twice. #, P < 0.05 versus other groups; *, P < 0.05 versus nonimmunized, infected mice (MTB group); &, P < 0.05 versus the BCG-vaccinated group. For histological representation of the lungs from infected mice, sections (5 \u03bcm) of 30-day or 70-day infected lungs were stained with hematoxylin and eosin. Magnification, \u00d750.https:\/\/iai.asm.org\/content\/77\/12\/5311","b2eb6bda":"#Shap Codes by rossinEndrew https:\/\/www.kaggle.com\/endrewrossin\/fast-initial-lightgbm-model-to-detect-exam-result\/comments","4905eb1f":"#Only three Continents? It's a Pandemic, there should be more continents."}}