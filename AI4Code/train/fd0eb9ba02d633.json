{"cell_type":{"403dc82f":"code","b5e3407f":"code","31f169a1":"code","cda740c0":"code","587a90c3":"code","67608295":"code","f2b3d28f":"code","551fd3ac":"code","6f3aa876":"code","c2c280e9":"code","ef51ee4e":"code","85a59e5e":"code","e4bf863f":"code","a61662f5":"code","de04e6ea":"code","2b680f0b":"code","c665772e":"code","acf969d4":"markdown","adc204d6":"markdown","8cb73e5b":"markdown","aad149a4":"markdown","0445e1c7":"markdown","6dc73f28":"markdown","f8002b58":"markdown","8121b8d8":"markdown","0ae742da":"markdown"},"source":{"403dc82f":"import pandas as pd\nimport spacy\nfrom spacy.lang.en import English\nfrom spacy.lang.en.stop_words import STOP_WORDS","b5e3407f":"#Read the data set\ndf= pd.read_csv('..\/input\/amazon-alexa\/amazon_alexa.tsv', sep='\\t')","31f169a1":"#First five observations\ndf.head()","cda740c0":"#Shape of the dataset\ndf.shape","587a90c3":"#Count of output feature\ndf['feedback'].value_counts()","67608295":"#Create list of punctuation marks\nimport string\npunctuations=string.punctuation\n\n#Create list of stopwords\nnlp=spacy.load('en')\nstop_words= spacy.lang.en.stop_words.STOP_WORDS\n\n#Load English tokenizer, tagger, parser, NER and word vectors\nparser=English()\n\n#Create tokenizer function\ndef spacy_tokenizer(sentence):\n  #Creating our token object, which is used to create documents with linguistic annotations.\n  mytokens=parser(sentence)\n  #Lemmatizing each token and converting each token into lowercase\n  mytokens=[word.lemma_.lower().strip() if word.lemma_!='-PRON-' else word.lower_ for word in mytokens]\n  #Removing stopwords\n  mytokens= [word for word in mytokens if word not in stop_words and word not in punctuations]\n  #Return preprocessed list of tokens\n  return mytokens","f2b3d28f":"#To further clean our text data, we\u2019ll also want to create a custom transformer for removing initial and end spaces and converting text into lower case.\nfrom sklearn.base import TransformerMixin\nclass predictors(TransformerMixin):\n  def transform(self,X, **transform_params):\n    return [clean_text(text) for text in X]\n  \n  def fit(self,X,y=None, **fit_params):\n    return self\n  \n  def get_params(self, deep=True):\n    return {}\n#Basic function to clean the text\ndef clean_text(text):\n  #Removing spaces and converting text into lowercase\n  return text.strip().lower()","551fd3ac":"#We need to perform feature vectorization in order to transform word tokens into numbers. We can do it using tf-idf ,Bag of Words.\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\nbow_vector= CountVectorizer(tokenizer=spacy_tokenizer, ngram_range=(1,3))\ntfidf_vector= TfidfVectorizer(tokenizer=spacy_tokenizer)","6f3aa876":"#Spliting data into train and test\nfrom sklearn.model_selection import train_test_split\nX= df['verified_reviews']\ny=df['feedback']\nX_train, X_test,y_train,y_test= train_test_split(X,y,test_size=0.25)","c2c280e9":"#We will use pipeline to integrate the entire modeling technique.\n#Pipeline 1\n#Decision Tree with GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nclassifier= DecisionTreeClassifier(class_weight='balanced')\nparameters={'min_samples_split': range(10,500,20),'max_depth': range(1,20,2)}\nclf=GridSearchCV(classifier,parameters)","ef51ee4e":"#Pipeline using tfidf\npipe1= Pipeline([('cleaner', predictors()),\n                 ('vectorizer',tfidf_vector),\n                 ('classifier', classifier)])\npipe1.fit(X_train,y_train)","85a59e5e":"#Evaluation of GridSearchCV Decision Tree model\nfrom sklearn import metrics\npredicted= pipe1.predict(X_test)\nprint('Accuracy:',metrics.accuracy_score(predicted,y_test))\nprint('Precision:',metrics.precision_score(predicted,y_test))\nprint('Recall:',metrics.recall_score(predicted,y_test))\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ncfm=metrics.confusion_matrix(y_test,predicted)\nlbl1=['Predicted Negetive', 'Predicted Positive']\nlbl2=['Actual Negetive', 'Actual Positive']\nsns.heatmap(cfm, annot=True, cmap='Blues',fmt='d',xticklabels=lbl1,yticklabels=lbl2)\nplt.show()","e4bf863f":"#Pipeline 2\n#Decision Tree without GridSearchCV\npipe2= Pipeline([('cleaner',predictors()),\n                 ('vectorizer',bow_vector),\n                 ('classifier',clf)])\npipe2.fit(X_train,y_train)","a61662f5":"##Evaluation of simple Decision Tree model\npredicted2= pipe2.predict(X_test)\nprint('Accuracy:',metrics.accuracy_score(predicted2,y_test))\nprint('Precision:',metrics.precision_score(predicted2,y_test))\nprint('Recall:',metrics.recall_score(predicted2,y_test))\n\ncfm=metrics.confusion_matrix(y_test,predicted2)\nlbl1=['Predicted Negetive', 'Predicted Positive']\nlbl2=['Actual Negetive', 'Actual Positive']\nsns.heatmap(cfm, annot=True, cmap='Blues',fmt='d',xticklabels=lbl1,yticklabels=lbl2)\nplt.show()","de04e6ea":"#Pipeline 3\n#SVM with GridSearchCV\nfrom sklearn.svm import SVC\nsvc=SVC(class_weight='balanced')\nparams1={'kernel':['linear','rbf','poly','sigmoid'],'C':[0.01,0.1,1,10],'gamma':[0.01,0.1,1,10]}\ngs_svc=GridSearchCV(svc,params1)","2b680f0b":"#Pipeline using tfidf\npipe3= Pipeline([('cleaner', predictors()),\n                 ('vectorizer',tfidf_vector),\n                 ('classifier', gs_svc)])\npipe3.fit(X_train,y_train)","c665772e":"#Evaluation of GridSearchCV SVM\npredicted3= pipe3.predict(X_test)\nprint('Accuracy:',metrics.accuracy_score(predicted3,y_test))\nprint('Precision:',metrics.precision_score(predicted3,y_test))\nprint('Recall:',metrics.recall_score(predicted3,y_test))\n\ncfm=metrics.confusion_matrix(y_test,predicted3)\nlbl1=['Predicted Negetive', 'Predicted Positive']\nlbl2=['Actual Negetive', 'Actual Positive']\nsns.heatmap(cfm, annot=True, cmap='Blues',fmt='d',xticklabels=lbl1,yticklabels=lbl2)\nplt.show()","acf969d4":"Problem:\nThe data set consists of records of customers review regarding Amazon's Alexa. Each customer's review has been categorized into Postive and Negatve based on the reviews given.\n\nObjective:\nThe objective of this analysis is to build a predictive classification model on text data highly processed by scpCy and predict future instances.","adc204d6":"##Pipeline","8cb73e5b":"##Import Data","aad149a4":"##Tokenization","0445e1c7":"##Custom Transformer using spaCy","6dc73f28":"##Vectorization","f8002b58":"##Import Packages","8121b8d8":"##Evaluation","0ae742da":"##Train Test Split"}}