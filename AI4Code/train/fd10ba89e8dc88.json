{"cell_type":{"460a305d":"code","b39c0cd8":"code","736db3a1":"code","dd0ac0c3":"code","ffc3a859":"code","dc4bf92b":"code","89c4c2af":"code","d4d0eeb1":"code","78bc6ccc":"code","0cf0f429":"code","a475addd":"code","e323b060":"markdown"},"source":{"460a305d":"from matplotlib import pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\nimport random \nimport os\nimport cv2\nimport gc\nfrom tqdm.auto import tqdm\n\n\nimport numpy as np\nimport keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.models import clone_model\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import plot_model\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport datetime as dt\n\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b39c0cd8":"def resize(df, size=64, need_progress_bar=True):\n    resized = {}\n    for i in range(df.shape[0]):\n        image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size))\n        resized[df.index[i]] = image.reshape(-1)\n    resized = pd.DataFrame(resized).T\n    return resized","736db3a1":"train_data = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/train.csv')\n\ntrain_data =  pd.merge(pd.read_parquet(f'\/kaggle\/input\/bengaliai-cv19\/train_image_data_0.parquet'), train_data, on='image_id').drop(['image_id'], axis=1)\n\ntrain_labels = train_data[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic','grapheme']]\n\ntrain_data = train_data.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic','grapheme'], axis=1)\n\ntrain_data = resize(train_data)\/255\n\ntrain_data = train_data.values.reshape(-1, 64, 64, 1)","dd0ac0c3":"model_dict = {\n    'grapheme_root': Sequential(),\n    'vowel_diacritic': Sequential(),\n    'consonant_diacritic': Sequential()\n}\n\nfor model_type, model in model_dict.items():\n    model.add(Conv2D(32, 5, activation=\"relu\", padding=\"same\", input_shape=[64, 64, 1]))\n    model.add(layers.BatchNormalization(momentum=0.15))\n    model.add(MaxPooling2D(2))\n    model.add(Conv2D(64, 3, activation=\"relu\", padding=\"same\"))\n    model.add(Conv2D(64, 3, activation=\"relu\", padding=\"same\"))\n    model.add(MaxPooling2D(2))\n    model.add(Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n    model.add(Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n    model.add(MaxPooling2D(2))\n    model.add(Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n    model.add(Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n    model.add(MaxPooling2D(2))\n    model.add(Flatten())\n    model.add(Dense(1024, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(512, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    if model_type == 'grapheme_root':\n        model.add(layers.Dense(168, activation='softmax', name='root_out'))\n    elif model_type == 'vowel_diacritic':\n        model.add(layers.Dense(11, activation='softmax', name='vowel_out'))\n    elif model_type == 'consonant_diacritic':\n        model.add(layers.Dense(7, activation='softmax', name='consonant_out'))\n\n    model.compile(optimizer=\"adam\", loss=['categorical_crossentropy'], metrics=['accuracy'])","ffc3a859":"batch_size = 32\nepochs = 10\nhistory_list = []","dc4bf92b":"# del Y_train\n# del x_train\n# del x_test\n# del y_train\n# del y_test\n# gc.collect()","89c4c2af":"plot_model(model_dict['grapheme_root'])","d4d0eeb1":"keras.backend.clear_session()\nnp.random.seed(42)\ntf.random.set_seed(42)\nmodel_types = ['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']\nfor target in model_types:\n    Y_train = train_labels[target]\n    Y_train = pd.get_dummies(Y_train).values\n    x_train, x_test, y_train, y_test = train_test_split(train_data, Y_train, test_size=0.1, random_state=123)\n    y_train = tf.cast(y_train, tf.int32)\n    y_test = tf.cast(y_test, tf.int32)\n#     datagen = ImageDataGenerator(rotation_range=5)\n    datagen = ImageDataGenerator()\n    checkpoint_cb = ModelCheckpoint(\"{}.h5\".format(target), save_best_only=True)\n    early_stopping_cb = EarlyStopping(patience=3, restore_best_weights=True)\n    history = model_dict[target].fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size), \n                                               epochs = epochs, validation_data = (x_test, y_test), callbacks=[checkpoint_cb, early_stopping_cb])\n    history_list.append(history)\n    model_dict[target] = keras.models.load_model(\"{}.h5\".format(target))\n    \n    del Y_train\n    del x_train\n    del x_test\n    del y_train\n    del y_test\n    gc.collect()","78bc6ccc":"plt.figure()\nfor i in range(3):\n    plt.plot(np.arange(0, len(history_list[i].history['accuracy'])), history_list[i].history['accuracy'], label='train_accuracy')\n    plt.plot(np.arange(0, len(history_list[i].history['accuracy'])), history_list[i].history['val_accuracy'], label='val_accuracy')\n    plt.title(model_types[i])\n    plt.xlabel('Epoch #')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.show()","0cf0f429":"preds_dict = {\n    'grapheme_root': [],\n    'vowel_diacritic': [],\n    'consonant_diacritic': []\n}","a475addd":"target=[] # model predictions placeholder\nrow_id=[] # row_id place holder\nfor i in range(4):\n    print(\"Parquet: {}\".format(i))\n    df_test_img = pd.read_parquet('\/kaggle\/input\/bengaliai-cv19\/test_image_data_{}.parquet'.format(i)) \n    df_test_img.set_index('image_id', inplace=True)\n\n    X_test = resize(df_test_img, need_progress_bar=False)\/255\n    X_test = X_test.values.reshape(-1, 64, 64, 1)\n\n    for i, p in preds_dict.items():\n        model = keras.models.load_model(\"{}.h5\".format(i))\n        preds = model.predict(X_test)\n        preds_dict[i] = np.argmax(preds, axis=1)\n\n    for k,id in enumerate(df_test_img.index.values):  \n        for i,comp in enumerate(model_types):\n            id_sample=id+'_'+comp\n            row_id.append(id_sample)\n            target.append(preds_dict[comp][k])\n            \n    del df_test_img\n    del X_test\n    gc.collect()\n\ndf_sample = pd.DataFrame(\n    {\n        'row_id': row_id,\n        'target':target\n    },\n    columns = ['row_id','target'] \n)\ndf_sample.to_csv('submission.csv',index=False)\ndf_sample.head()","e323b060":"Work conducted by: Jason Katz, David Kebudi, Naina Wodon, and Michael Harder"}}