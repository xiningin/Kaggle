{"cell_type":{"310fd6c7":"code","3bb24ad8":"code","9b23dab3":"code","3311fa05":"code","35a159fe":"code","58a3ceef":"code","d710815b":"code","897aedbb":"code","34d56c6c":"code","48347c3a":"code","55465559":"code","3a153c17":"code","f3a1ce1f":"code","42aac792":"code","74ee8578":"code","b9a03a79":"code","3abdd1b5":"code","35672fcb":"code","7c4ba489":"code","b995d4c2":"code","1521c846":"code","9fe63eb0":"code","8eff4722":"code","692ae4f9":"code","59f9f823":"code","d71c59fc":"code","be784ee3":"code","78cdee9f":"code","d0ac2e78":"code","f0176972":"markdown","ec7ce2a4":"markdown","0c413f9d":"markdown","f09ca06b":"markdown","791c84fb":"markdown","8502dd77":"markdown","cc0c5a3d":"markdown","b9fe8f79":"markdown","e602a9db":"markdown","6672f71a":"markdown","e881cbde":"markdown","08d0a414":"markdown","2c05a8ac":"markdown","0bdcc3c4":"markdown","f21d48de":"markdown","a2b73543":"markdown","aa441ea0":"markdown","e59bfdca":"markdown","6ccca2f7":"markdown","ab8a67a0":"markdown","29d80d70":"markdown","ac703c13":"markdown","f7356ffd":"markdown","20d37908":"markdown","db8914ca":"markdown","cb523fb9":"markdown"},"source":{"310fd6c7":"# packages to use\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#from sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nfrom statistics import mode\n\n\n#Reading the data sets\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\n","3bb24ad8":"#head of fist 5 rows\ndf_train.head()","9b23dab3":"#to  get the size of the file\ndf_train.shape\n#all column names\ndf_train.columns\n#list of variables with its statistics\ndf_train.describe().transpose()","3311fa05":"#list of variables with missing values\ndf_train.columns[df_train.isnull().any()]\n#data set only missing variable values\ndf_train_missing=df_train[df_train.columns[df_train.isnull().any()]]\n\n#Create a new function for missing values:\ndef num_missing(x):\n    return sum(x.isnull())\n#Applying per row:\n#df_train['nmissing']=df_train_missing.apply(num_missing, axis=1) #axis=1 defines that function is to be applied on each row\n#Applying per column:\ndf_train_missing.apply(num_missing, axis=0) #axis=0 defines that function is to be applied on each column\ndf_train_missing_table=round(df_train_missing.apply(num_missing, axis=0)\/1460,4)*100 #axis=0 defines that function is to be applied on each column\ndf_train_missing_table =pd.DataFrame({'MissingPercentage':df_train_missing_table})\ndf_train_missing_table","35a159fe":"#None inputation\nvar1=['Alley','MasVnrType','MasVnrArea','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','FireplaceQu','GarageType','GarageYrBlt','GarageFinish','GarageQual','GarageCond','PoolQC','Fence','MiscFeature']\ndf_train[var1]=df_train[var1].fillna('NA')\n\n#Mean inputation\ndf_train['LotFrontage']=df_train['LotFrontage'].fillna(df_train['LotFrontage'].mean())\n\n#Mode inputation\ndf_train['Electrical']=df_train['Electrical'].fillna(mode(df_train['Electrical']))","58a3ceef":"#list of variables with missing values\ndf_test.columns[df_test.isnull().any()]\n#data set only missing variable values\ndf_test_missing=df_test[df_test.columns[df_test.isnull().any()]]\n\n#Applying per column:\ndf_test_missing.apply(num_missing, axis=0) #axis=0 defines that function is to be applied on each column\n\n#None inputation\nvar1=['BsmtQual','Alley','Utilities','Exterior1st','Exterior2nd','MasVnrType','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','FireplaceQu','GarageType','GarageYrBlt','GarageFinish','GarageQual','GarageCond','PoolQC','Fence','MiscFeature']\ndf_test[var1]=df_test[var1].fillna('NA')\n\n#Mean inputation\ndf_test['LotFrontage']=df_test['LotFrontage'].fillna(df_test['LotFrontage'].mean())\ndf_test['MasVnrArea']=df_test['MasVnrArea'].fillna(df_test['MasVnrArea'].mean())\ndf_test['BsmtFinSF1']=df_test['BsmtFinSF1'].fillna(df_test['BsmtFinSF1'].mean())\ndf_test['BsmtFinSF2']=df_test['BsmtFinSF2'].fillna(df_test['BsmtFinSF2'].mean())\ndf_test['BsmtUnfSF']=df_test['BsmtUnfSF'].fillna(df_test['BsmtUnfSF'].mean())\ndf_test['TotalBsmtSF']=df_test['TotalBsmtSF'].fillna(df_test['TotalBsmtSF'].mean())\ndf_test['GarageCars']=df_test['GarageCars'].fillna(df_test['GarageCars'].mean())\ndf_test['GarageArea']=df_test['GarageArea'].fillna(df_test['GarageArea'].mean())\ndf_test['GarageArea']=df_test['GarageArea'].fillna(df_test['GarageArea'].mean())\n\n#Mode inputation\ndf_test['MSZoning']=df_test['MSZoning'].fillna(mode('MSZoning'))\ndf_test['BsmtHalfBath']=df_test['BsmtHalfBath'].fillna(0)\ndf_test['KitchenQual']=df_test['KitchenQual'].fillna('TA')\ndf_test['Functional']=df_test['Functional'].fillna(mode('Functional'))\ndf_test['BsmtFullBath']=df_test['BsmtFullBath'].fillna(0)\ndf_test['SaleType']=df_test['SaleType'].fillna(mode('SaleType'))\n","d710815b":"#check outlier\nsns.boxplot(x=df_train['SalePrice']);","897aedbb":"#Remove Outlier\ndf_train=df_train[np.abs(df_train.SalePrice-df_train.SalePrice.mean()) <= (6*df_train.SalePrice.std())]","34d56c6c":"df_test['TT_SF']=df_test['1stFlrSF']+df_test['2ndFlrSF']+df_test['TotalBsmtSF']+df_test['GarageArea']+df_test['GrLivArea']\ndf_test['TT_bathrooms']=df_test['FullBath']+df_test['HalfBath']+df_test['BsmtFullBath']+df_test['HalfBath']\ndf_test['TT_rooms']=df_test['TotRmsAbvGrd']+df_test['BsmtFullBath']+df_test['BsmtHalfBath']\n\ndf_train['TT_SF']=df_train['1stFlrSF']+df_train['2ndFlrSF']+df_train['TotalBsmtSF']+df_train['GarageArea']+df_train['GrLivArea']\ndf_train['TT_bathrooms']=df_train['FullBath']+df_train['HalfBath']+df_train['BsmtFullBath']+df_train['HalfBath']\ndf_train['TT_rooms']=df_train['TotRmsAbvGrd']+df_train['BsmtFullBath']+df_train['BsmtHalfBath']\n","48347c3a":"#delete the ID variable in train data\n#del df_train['Id']","55465559":"#histogram\nsns.distplot(df_train['SalePrice']);","3a153c17":"#skewness and kurtosis\nprint(\"Skewness: %f\" % df_train['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % df_train['SalePrice'].kurt())","f3a1ce1f":"#applying log transformation\ndf_train['SalePrice'] = np.log(df_train['SalePrice'])","42aac792":"#histogram\nsns.distplot(df_train['SalePrice']);","74ee8578":"#skewness and kurtosis\nprint(\"Skewness: %f\" % df_train['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % df_train['SalePrice'].kurt())","b9a03a79":"#List of numeric variables\nnumeric_vars = df_train.dtypes[df_train.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_vars = df_train[numeric_vars].skew().sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew':skewed_vars})\n\n#keeping only the one with high skewness\nskewness = skewness[abs(skewness['Skew']) > 0.7]\nskewness\n\n#Transformation \nskewed_vars = skewness.index\ndf_train[skewed_vars] = np.log(df_train[skewed_vars]+0.001)\ndf_test[skewed_vars] = np.log(df_test[skewed_vars]+0.001)","3abdd1b5":"#convert categorical variable into dummy\ndf_train=pd.get_dummies(df_train)\ndf_test=pd.get_dummies(df_test)\n\n#Sort column to get the same order \nfinal_train, final_test = df_train.align(df_test,join='inner',axis=1)\n","35672fcb":"#correlation\ncorr_df=df_train.corr()\n\n#list of variables with high correaltion with Sale price\nhigh_corr_df=corr_df[corr_df['SalePrice']>0.5]\nhigh_corr_df=high_corr_df[list(corr_df[corr_df['SalePrice']>0.5].index)]\n\n#graph\nheatmap_df=high_corr_df\nplt.subplots(figsize=(10,8))\nsns.heatmap(heatmap_df,annot=True);","7c4ba489":"#Distibution and correation graph of the variables with highest correaltion\nsns.pairplot(df_train[['SalePrice','OverallQual','GarageCars','GrLivArea', 'GarageArea']]);","b995d4c2":"from sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_val_score\n\n# GradientBoostingRegressor:\n# define pipeline\nGBR_model = make_pipeline(GradientBoostingRegressor())\n# cross validation score\nscore = cross_val_score(GBR_model,final_train, df_train.SalePrice, scoring= 'neg_mean_absolute_error')\nprint('Mean Absolute Error %2f' %(-1 * score.mean()))","1521c846":"# fit and make predictions\nGBR_model.fit(final_train,df_train.SalePrice)\npredictions= GBR_model.predict(final_test)","9fe63eb0":"# Import libaries for  models\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import LinearRegression\nfrom mlxtend.regressor import StackingRegressor\nfrom sklearn.linear_model import Lasso\n\n# Metrics for root mean squared error\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt","8eff4722":"# Initialize models\nlr = LinearRegression()\nrd = Ridge()\nrf = RandomForestRegressor(\n    n_estimators = 12,\n    max_depth = 3,\n    n_jobs = -1)\ngb = GradientBoostingRegressor()\nlasso=Lasso(alpha =0.0005, random_state=1)\n\n#nn = MLPRegressor(\n#    hidden_layer_sizes = (90, 90),\n#    alpha = 2.75)","692ae4f9":"# Initialize Ensemble\nmodel = StackingRegressor(\n    regressors=[rf, gb, rd, lasso],\n    meta_regressor=lr)\n\n# Fit the model on our data\nmodel.fit(final_train, df_train.SalePrice);","59f9f823":"# Predict training data\ny_pred = model.predict(final_train)\nprint(sqrt(mean_squared_error(df_train.SalePrice, y_pred)))","d71c59fc":"# Predict test data\ny_pred = model.predict(final_test)","be784ee3":"# Fit the model on our data\nlasso.fit(final_train, df_train.SalePrice)\n\nscore = cross_val_score(lasso,final_train, df_train.SalePrice, scoring= 'neg_mean_absolute_error')\nprint('Mean Absolute Error %2f' %(-1 * score.mean()))","78cdee9f":"submission = pd.DataFrame({'Id': df_test.Id, 'SalePrice': np.exp(predictions)})\nsubmission.to_csv('submissionGB.csv', index=False)\nsubmission.head()","d0ac2e78":"# Create empty submission dataframe\nsubmission = pd.DataFrame({'Id': df_test.Id, 'SalePrice': np.exp(y_pred)})\n\n# Output submission file\nsubmission.to_csv('submissionEM.csv',index=False)\nsubmission.head()","f0176972":"### 1.2 variables in the file\nThe file has in total 1460 row and 81 variables.","ec7ce2a4":"### 2.3 Creating New variables ","0c413f9d":"## 5-File to summit Ensemble models","f09ca06b":"### 2.1 Missing values check and inputation\n\nThe missing values on the  following variables could mean they don't have that attribute so we will input \"none\"\n* PoolQC: This one has a high percentage of missings (99.5%). We will keep it as If this is missing, it means the house doesn't have a pool. \n* MiscFeature: Miscellaneous feature not covered in other categories. Missing values probably mean that there are no special features.\n* Alley: Type of alley access. Probably no alley access if missing\n* Fence: Fence quality. Probably no fence if missing. \n* FireplaceQu: Fireplace quality. Probably no fireplace if missing.\n* Garage variables: If missing houses do not have a garage.\n* Basement variables:  If missing houses do not Basement.\n* MasVnrType\/MasVnrArea:  If missing houses do not have Masonry veneer.\n\nAdditional imputation\n* LotFrontage: Linear feet of street connected to the property. is a numeric variable so we will input the mean.\n* Electrical: low missing (7%) and the should have an Electrical system so will input the due to the mode since is categorical.","791c84fb":"# House Prices Prediction\n[Andreina Torres ](https:\/\/www.linkedin.com\/in\/andreina-torres-25341565\/)\n\n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------","8502dd77":"The SalePrice variable does not follow a normal distribution.","cc0c5a3d":"The goal of this project predicts the sales price (SalePrice variable) in a data set of houses base on a set of characteristics that describe the house. This model could bel be useful to assign prices and future estimation of new houses. The real state agencies and anyone looking  to buy a new house can have an idea.\n\nTo aim this goal we will be implementing a Gradient Boosting model, over a file that includes 80,000 different houses.","b9fe8f79":"Creating the Dummy variables to use in the model of categorical data.","e602a9db":"Applying log transformation to get a normalized variable.","6672f71a":"The list of the Packages to used and reading the data process.","e881cbde":"### 2.1 Checking and removing outliers\nThere are some outliers in the file so,  we keep only the ones that are within +6 to -6 standard deviations in the column 'Data'.","08d0a414":"## 3- Exploratory data Analysis\n\nThe highest correlation of the SalePrice of the houses with are with the following variables:\n\n* OverallQual: Rates the overall material and finish of the house (0 to 10).\n* Years built:  Original construction date.\n* Years remoadd: Remodel date (same as construction date if no remodeling or additions).\n* TotalBsmtSF\t: Total square feet of basement area.\n* 1stFlrSF: First Floor square feet.\n* GrLivArea:\t Above grade (ground) living area square feet\n* FullBath: Full bathrooms above grade.\n* TotRmsAbvGrd:\tTotal rooms above grade (does not include bathrooms).\n* GarageCars: Size of garage in car capacity.\n* GarageArea:\tSize of garage in square feet.","2c05a8ac":"Creating the same process for Missing values check and inputation in the test file.","0bdcc3c4":"These are the set of models that will be use to create the Ensemble model, in the Prosess were compared, checked and removed each of them and others. \n\n* LinearRegression\n* Ridge\n* RandomForestRegressor\n* GradientBoostingRegressor\n* Lasso","f21d48de":"Same process for other continuous variables.","a2b73543":"Final data for summition, since gradient boosting returns a higher error in the crossvalidation.","aa441ea0":"## 1- Data Base\nThe goal is first understand the data structured to evaluate possible variable transformations, and required data cleaning.\nMost of the variables a categorical and the variable to predict is a continuous variable.\n\n### 1.1 Data  Structure","e59bfdca":"--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------","6ccca2f7":" ## 5- Fit Ensemble models","ab8a67a0":"## 6-File to Summit gradientBoosting","29d80d70":"New variables base on  other variables:\n* TT_SF: Total SF of the house.\n* TT_bathrooms: Total number of bathrooms.\n* TT_rooms: Total number of rooms","ac703c13":"### 2.4 Checking lineal model assumsions","f7356ffd":"The prediction using the ensemble model.","20d37908":"--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n###  Lasso model checking\nThe following step is how check some in Mean Absolute Error  in one of the models.","db8914ca":"## 2-Data cleaning","cb523fb9":"## 4- Fit a GradientBoostingRegressor"}}