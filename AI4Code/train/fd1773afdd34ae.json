{"cell_type":{"8fbf8626":"code","3d553fd1":"code","94a9c493":"code","77c8a798":"code","d44ec8de":"code","13bd85e4":"code","2de7c53f":"code","3091eefe":"code","3d24bab2":"code","52eae8a1":"code","f3a9f400":"code","55470b5d":"code","afcd772e":"code","4c85afed":"code","e685ec7d":"code","c54b3aea":"code","d625128b":"code","fe1e9f47":"code","fcdb33ca":"code","85665d95":"code","addebd3d":"code","6c2484a0":"code","89642379":"code","cda3a151":"code","88824e0f":"code","09504887":"code","f2b45a02":"code","6e42d971":"code","36778b0c":"code","e3a2a052":"code","69851a77":"code","dfd7b0e3":"code","4bdc632c":"code","c2e6a36d":"code","7eadb6cf":"code","7841cbfd":"code","5c088f9b":"code","b25bc7c0":"code","76955ae4":"code","0bc33421":"code","5f6ed925":"code","d0185e4f":"code","df3c1c12":"code","642f1f11":"code","5350e363":"code","e3172299":"code","18020bbd":"code","fb1b5406":"code","6515b3de":"code","9502cc25":"code","758ad759":"code","e505ac83":"code","b16d6695":"code","a241b5a3":"code","ec9c4794":"code","ffd77e07":"code","43e5f5b9":"code","7648e27a":"code","b9a01ca8":"code","0d8c4f6e":"code","b66cce9c":"code","cc661432":"code","a0e209fe":"code","c2b2e55d":"code","87efdc50":"code","b8d1a316":"code","43f76a6d":"code","ec4b2b9b":"code","c0a0f416":"code","b0f48236":"code","05952693":"code","2e119a52":"code","ba0e8ff2":"code","fc875a73":"code","5d481b03":"code","3df9164e":"code","21af56b4":"code","aa14f342":"code","0c9f0942":"code","d20d7da2":"code","cb069cd3":"code","4d2dd484":"code","9603d166":"code","5572b3c5":"code","822809ab":"code","aa3f4590":"code","ebb8807a":"code","bc9415db":"code","2fe9b071":"code","8bf0a485":"code","f71b5c08":"code","987cb867":"code","fac4c14e":"code","836fca1d":"code","5d25ad3a":"code","2954aff5":"code","b2654d15":"code","e7d9d9ac":"markdown","f26e15f3":"markdown","491bea94":"markdown","57379baf":"markdown","e96acdf7":"markdown","682fedf0":"markdown","a5927cec":"markdown","e1acd2cd":"markdown","76977353":"markdown","8f0f8d9c":"markdown","678f152a":"markdown","07ad847d":"markdown","eb6328bf":"markdown","1b5fb627":"markdown","e69c9798":"markdown","41f153f8":"markdown","5e3eba4e":"markdown","9f5d4a4b":"markdown","19b13974":"markdown","ac8baaac":"markdown","1ab5840f":"markdown","80e2015d":"markdown","d199ea42":"markdown","9becbd12":"markdown","4301e7dc":"markdown","00aee096":"markdown","21d12b80":"markdown","e7b7dfca":"markdown","b616bdcc":"markdown","e387a866":"markdown","3d240677":"markdown","10a70b78":"markdown","46ad3f9f":"markdown","e5c5970e":"markdown","48ff3c17":"markdown","cae67b50":"markdown","7d944496":"markdown","21e8399b":"markdown","ce12202a":"markdown","34d51607":"markdown","1209472f":"markdown","fe55a674":"markdown","a87475a7":"markdown","4000756b":"markdown","fd4b2a57":"markdown","f3cbde1b":"markdown","4681515e":"markdown","a6e87f2f":"markdown","a622d3c4":"markdown","213ce678":"markdown","6efe88c0":"markdown","c4979926":"markdown","ffd01b05":"markdown","5b6cd703":"markdown","b41b4512":"markdown","287121c0":"markdown","7f8d914d":"markdown","c111b2e4":"markdown","16828754":"markdown","ce3c7097":"markdown","b7408a5b":"markdown","9cfc2e87":"markdown","e6166fa0":"markdown","a39cabf5":"markdown","8bd8b439":"markdown","4b61ed85":"markdown","af2a6b3e":"markdown","f2bb0f72":"markdown","733fcc4f":"markdown","9c9165d0":"markdown","978f1226":"markdown","8c6dedb4":"markdown","d7483412":"markdown","f37fde61":"markdown","57a3d095":"markdown","afaad324":"markdown","270c1e47":"markdown","806a8100":"markdown","05ab1a9f":"markdown","b096f43f":"markdown","f6fa360e":"markdown","44be5e6f":"markdown","eb543825":"markdown","a106f424":"markdown","7c70388f":"markdown","bfda66bc":"markdown","f1d48bf5":"markdown","89f62d85":"markdown","021248b8":"markdown","7eed6d22":"markdown","1359aff6":"markdown","130826f8":"markdown"},"source":{"8fbf8626":"from IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:80% !important; }<\/style>\"))","3d553fd1":"import warnings\nwarnings.filterwarnings('ignore')","94a9c493":"# numpy & pandas\nimport numpy as np\nimport pandas as pd\nfrom math import sqrt\n\n#visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n#Machine learning Libraries\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import RFE\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error","77c8a798":"\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","d44ec8de":"bike = pd.read_csv(\"\/kaggle\/input\/boombikes\/day.csv\", parse_dates=['dteday'])","13bd85e4":"# Checking the top 5 rows of the dataframe\nbike.head()","2de7c53f":"# Checking the last 5 rows of the dataframe\nbike.tail()","3091eefe":"#Checking the shape of the dataframe \nbike.shape","3d24bab2":"# Checking the size of the dataframe\nbike.size","52eae8a1":"# How many types of each data type column exists and total memory usage\nbike.info()","f3a9f400":"#Checking the numerical columns data distribution statistics\nbike.describe()","55470b5d":"# To check if there are any missing values in the dataset\n\nimport missingno as mn\nmn.matrix(bike)","afcd772e":"# Creating a copy of original dataframe for duplicate check\nbike_dup = bike\n\n# Checking for duplicates and dropping the entire duplicate row if any\nbike_dup.drop_duplicates(subset=None, inplace=True)\nbike_dup.shape","4c85afed":"# Checking the relationship between casual, registered and cnt column\nbike_cnt = bike[['casual','registered','cnt']]\n# Creating a column whch will show the value of casual + registered\nbike_cnt['total'] = bike_cnt['casual'] + bike_cnt ['registered']\nsns.pairplot(bike_cnt)\nplt.show","e685ec7d":"# also checking the correlation of the variables \nplt.figure(figsize = (6,6))\nax= sns.heatmap(bike_cnt.corr(), annot = True, cmap=\"RdYlGn\",linewidth =1)\nplt.show()","c54b3aea":"#dropping the unwanted columns\nbike.drop(['instant','dteday','casual','registered'],axis=1,inplace=True)\nbike.shape","d625128b":"#Converting season\nbike.season.replace((1,2,3,4), ('W1_Spring','W2_Summer','W3_Fall','W4_Winter'), inplace=True)\nbike.season.value_counts(normalize=True)","fe1e9f47":"#Converting mnth\nbike.mnth.replace((1,2,3,4,5,6,7,8,9,10,11,12),('Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'), inplace=True)\nbike.mnth.value_counts(normalize=True)","fcdb33ca":"#Converting weathersit\nbike.weathersit.replace((1,2,3,4), ('Clear','Misty','Light_rainsnow','Heavy_rainsnow'), inplace=True)\nbike.weathersit.value_counts(normalize=True)","85665d95":"#Converting weathersit\nbike.weekday.replace((0,1,2,3,4,5,6), ('Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday'), inplace=True)\nbike.weekday.value_counts(normalize=True)","addebd3d":"# Build boxplot of all categorical variables (before creating dummies) againt the target variable 'cnt' \n# to see how each of the predictor variable stackup against the target variable.\n\nplt.figure(figsize=(25, 10))\nplt.subplot(2,3,1)\nsns.boxplot(x = 'season', y = 'cnt', data = bike)\nplt.subplot(2,3,2)\nsns.boxplot(x = 'mnth', y = 'cnt', data = bike)\nplt.subplot(2,3,3)\nsns.boxplot(x = 'weathersit', y = 'cnt', data = bike)\nplt.subplot(2,3,4)\nsns.boxplot(x = 'weekday', y = 'cnt', data = bike)\nplt.subplot(2,3,5)\nsns.boxplot(x = 'holiday', y = 'cnt', data = bike)\nplt.subplot(2,3,6)\nsns.boxplot(x = 'workingday', y = 'cnt', data = bike)\nplt.show()","6c2484a0":"# function to generate statistics related to Categorical Variables\ndef categorical_stats(col):\n    cat_df = bike.groupby(col)['cnt'].agg(['sum', 'mean','count']).sort_values('sum',ascending = False)\n    cat_df['sum_perc']=cat_df['sum']\/bike.cnt.sum()*100\n    cat_df['count_perc']=cat_df['count']\/bike.cnt.count()*100\n    return round(cat_df,2)","89642379":"# function to generate plots related to Categorical Variables\ndef categorical_plot(col,x,y):\n    plt.figure(figsize = (x,y))\n    plt.subplot(1,2,1)\n    sns.barplot(col,'cnt',data=bike)\n    plt.subplot(1,2,2)\n    sns.barplot(col,'cnt',data=bike, hue='yr',palette='Paired')\n    plt.legend(labels=['2018', '2019'])\n    return","cda3a151":"categorical_stats('season')","88824e0f":"categorical_plot('season',12,6)","09504887":"categorical_stats('mnth')","f2b45a02":"categorical_plot('mnth',12,6)","6e42d971":"categorical_stats('weathersit')","36778b0c":"categorical_plot('weathersit',18,6)","e3a2a052":"categorical_stats('weekday')","69851a77":"categorical_plot('weekday',18,6)","dfd7b0e3":"categorical_stats('holiday')","4bdc632c":"categorical_plot('holiday',12,6)","c2e6a36d":"categorical_stats('workingday')","7eadb6cf":"categorical_plot('workingday',12,6)","7841cbfd":"categorical_stats('yr')","5c088f9b":"sns.barplot('yr','cnt',data=bike)\nplt.show()","b25bc7c0":"#Generating pairplot to check the relationships between numeric variables variables\nbike_num = bike[['temp','atemp','hum','windspeed','cnt']]\nsns.pairplot(bike_num)\nplt.show()","76955ae4":"# Checking correlation of the parameters by mapping a correlation heatmap\n\nplt.figure(figsize = (6,6))\nax= sns.heatmap(bike_num.corr(), annot = True, cmap=\"RdYlGn\",linewidth =1)","0bc33421":"# Checking the impact of year against the numerical variable : \nax = sns.pairplot(x_vars=['temp', 'atemp', 'hum', 'windspeed'], y_vars=['cnt'] , data=bike, hue='yr', palette='Set2')\nax._legend.remove()\nplt.legend(labels=['2018', '2019'])\nplt.show()","5f6ed925":"season = pd.get_dummies(bike['season'], drop_first = True)\nseason.head(3)","d0185e4f":"weather = pd.get_dummies(bike['weathersit'], drop_first = True)\nweather.head(3)","df3c1c12":"month = pd.get_dummies(bike['mnth'], drop_first = True)\nmonth.head(3)","642f1f11":"weekday = pd.get_dummies(bike['weekday'], drop_first = True)\nweekday.head(3)","5350e363":"# Creating a new dataframe called bike_new where season, month, weather and weekday dataframe is being added\nbike_new = pd.concat([bike,season,month,weather,weekday], axis = 1)\nbike_new.head(3)","e3172299":"bike_new.shape","18020bbd":"bike_new.info()","fb1b5406":"#deleting the unnecessry column season, mnth, weathersit and weekday as the respective values are already populated as binary columns data\nbike_new.drop(['season','mnth','weathersit','weekday'],axis=1,inplace=True)\nbike_new.shape","6515b3de":"bike_new.info()","9502cc25":"# We specify this so that the train and test data set always have the same rows, respectively\nnp.random.seed(0)\nbike_train, bike_test = train_test_split(bike_new, train_size = 0.7, random_state = 333)","758ad759":"bike_train.shape","e505ac83":"bike_train.describe()","b16d6695":"bike_test.shape","a241b5a3":"bike_test.describe()","ec9c4794":"# Rescaling using MinMaxCcaler\nscaler = MinMaxScaler()","ffd77e07":"#Dataframe before scaling \nbike_train.head(3)","43e5f5b9":"# Apply scaler() to all the columns except the 'yes-no' and 'dummy' variables\nnum_vars = ['temp','atemp','hum','windspeed','cnt']\nbike_train[num_vars] = scaler.fit_transform(bike_train[num_vars])","7648e27a":"#Checking after rescalling\nbike_train.head(3)","b9a01ca8":"plt.figure(figsize = (25,20))\nax= sns.heatmap(bike_train.corr(), annot = True, cmap=\"RdYlGn\",linewidth =1)\nplt.show()","0d8c4f6e":"y_train = bike_train.pop('cnt')\nX_train = bike_train","b66cce9c":"# Running RFE with the output number of the variable equal to 15\nlm = LinearRegression()\nlm.fit(X_train, y_train)\n\nrfe = RFE(lm, 15)             # running RFE\nrfe = rfe.fit(X_train, y_train)","cc661432":"# Checking which parameters have been selected in that list of 15\nlist(zip(X_train.columns,rfe.support_,rfe.ranking_))","a0e209fe":"# storing the selected 15 variables in col list\ncol = X_train.columns[rfe.support_]\ncol","c2b2e55d":"# checking which columns have been eleminated \nX_train.columns[~rfe.support_]","87efdc50":"# Creating X_train dataframe with RFE selected variables\nX_train_rfe = X_train[col]","b8d1a316":"# Function for VIF Calculation\n\ndef calculateVIF(df):\n    vif = pd.DataFrame()\n    vif['Features'] = df.columns\n    vif['VIF'] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    return vif ","43f76a6d":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\ncalculateVIF(X_train_rfe)","ec4b2b9b":"# Add a constant\nX_train_lm1 = sm.add_constant(X_train_rfe)\n\n# Create a first fitted model\nlr1 = sm.OLS(y_train, X_train_lm1).fit()\n\n# Print a summary of the linear regression model obtained\nprint(lr1.summary())","c0a0f416":"X_train_new = X_train_rfe.drop(['atemp'], axis = 1)\n# Run the function to calculate VIF for the new model\ncalculateVIF(X_train_new)","b0f48236":"# Add a constant\nX_train_lm1 = sm.add_constant(X_train_rfe)\n\n# Create a first fitted model\nlr1 = sm.OLS(y_train, X_train_lm1).fit()\n\n# Print a summary of the linear regression model obtained\nprint(lr1.summary())","05952693":"X_train_new = X_train_new.drop(['hum'], axis = 1)\n# Run the function to calculate VIF for the new model\ncalculateVIF(X_train_new)","2e119a52":"# Add a constant\nX_train_lm3 = sm.add_constant(X_train_new)\n\n# Create a first fitted model\nlr3 = sm.OLS(y_train, X_train_lm3).fit()\n\n# Print a summary of the linear regression model obtained\nprint(lr3.summary())","ba0e8ff2":"X_train_new = X_train_new.drop(['W3_Fall'], axis = 1)\n# Run the function to calculate VIF for the new model\ncalculateVIF(X_train_new)","fc875a73":"# Add a constant\nX_train_lm4 = sm.add_constant(X_train_new)\n\n# Create a first fitted model\nlr4 = sm.OLS(y_train, X_train_lm4).fit()\n\n# Print a summary of the linear regression model obtained\nprint(lr4.summary())","5d481b03":"X_train_new = X_train_new.drop(['Nov'], axis = 1)\n# Run the function to calculate VIF for the new model\ncalculateVIF(X_train_new)","3df9164e":"# Add a constant\nX_train_lm5 = sm.add_constant(X_train_new)\n\n# Create a first fitted model\nlr5 = sm.OLS(y_train, X_train_lm5).fit()\n\n# Print a summary of the linear regression model obtained\nprint(lr5.summary())","21af56b4":"X_train_new = X_train_new.drop(['Mar'], axis = 1)\n# Run the function to calculate VIF for the new model\ncalculateVIF(X_train_new)\n","aa14f342":"# Add a constant\nX_train_lm6 = sm.add_constant(X_train_new)\n\n# Create a first fitted model\nlr6 = sm.OLS(y_train, X_train_lm6).fit()\n\n# Print a summary of the linear regression model obtained\nprint(lr6.summary())","0c9f0942":"# Checking the parameters obtained\nlr6.params","d20d7da2":"sm.graphics.plot_ccpr(lr6, 'temp')\nplt.show()","cb069cd3":"sm.graphics.plot_ccpr(lr6, 'windspeed')\nplt.show()","4d2dd484":"y_train_pred = lr6.predict(X_train_lm6)\nresidual = y_train - y_train_pred\nsns.scatterplot(y_train,residual)\nplt.plot(y_train,(y_train - y_train), '-r')\nplt.xlabel('Count')\nplt.ylabel('Residual')\nplt.show()","9603d166":"# Validating Multi Colinearity\nplt.figure(figsize=(15,8))\nsns.heatmap(X_train_new.corr(),annot = True, cmap=\"RdYlGn\",linewidth =1)\nplt.show()","5572b3c5":"# Run the function to calculate VIF for the final model\ncalculateVIF(X_train_new)","822809ab":"print('The Durbin-Watson value for Final Model lr 6 is',round(sm.stats.stattools.durbin_watson((y_train - y_train_pred)),4))","aa3f4590":"res = y_train-y_train_pred\n\n# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((res), bins = 20)\nfig.suptitle('Error Terms')                  \nplt.xlabel('Errors')                         \nplt.show()","ebb8807a":"sm.qqplot((y_train - y_train_pred), fit=True, line='45')\nplt.show()","bc9415db":"\nnum_vars = ['temp', 'atemp', 'hum', 'windspeed','cnt']\nbike_test[num_vars] = scaler.transform(bike_test[num_vars])\nbike_test.head()","2fe9b071":"bike_test.describe()","8bf0a485":"y_test = bike_test.pop('cnt')\nX_test = bike_test","f71b5c08":"#Selecting the variables that were part of final model.\ncol1=X_train_new.columns\n\nX_test=X_test[col1]\n\n# Adding constant variable to test dataframe\nX_test_lm6 = sm.add_constant(X_test)\n\nX_test_lm6.info()","987cb867":"# Making predictions using the final model (lr6)\n\ny_pred = lr6.predict(X_test_lm6)","fac4c14e":"# plotting y_test and y_pred to understand the spread\nfig = plt.figure()\nplt.scatter(y_test, y_pred,alpha = 0.5)\nfig.suptitle('y_test vs y_pred')             \nplt.xlabel('y_test')                          \nplt.ylabel('y_pred') ","836fca1d":"r2 = round(r2_score(y_test, y_pred),4)\nr2","5d25ad3a":"# n is number of rows in test dataset\nn = X_test.shape[0]\n\n# Number of features (predictors, p) is the shape along axis 1\np = X_test.shape[1]\n\n# We find the Adjusted R-squared using the formula\nadjusted_r2 = round(1-(1-r2)*(n-1)\/(n-p-1),4)\nadjusted_r2","2954aff5":"RMSE = round(sqrt(mean_squared_error(y_test, y_pred)),4)\nRMSE","b2654d15":"MAE = round(mean_absolute_error(y_test, y_pred),4)\nMAE","e7d9d9ac":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            2.1 Encoding Categorical columns\n            <\/span>   \n        <\/font>    \n<\/h3>\n<span style='font-family:Georgia'>\n    <p>Converting season, mnth,weathersit and weekday to categorical columns<\/p>\n    <ul>\n        <li><b>season<\/b>: converting season values as per criteria - 1:Spring, 2:Summer, 3:Fall, 4:Winter <\/li>\n        <li><b>mnth<\/b>: converting mnth values as 1:Jan, 2:Feb, 3:Mar, 4:Apr, 5:May, 6:Jun, 7:Jul, 8:Aug, 9:Sep, 10:Oct, 11:Nov, 12:Dec <\/li>\n        <li><b>weathersit<\/b>: converting weathersit values as 1:Clear, 2:Misty, 3:Light_RainSnow 4:Heavy_RainSnow<\/li>\n        <li><b>weekday<\/b>: converting weekday values as 0:Sun, 1:Mon, 2:Tue, 3:Wed, 4:Thu, 5:Fri, 6:Sat <\/li>\n    <\/ul>    \n<\/span>","f26e15f3":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            5.1 Dividing into X_train and y_train\n            <\/span>   \n        <\/font>    \n<\/h3>","491bea94":"<h4>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n             2.2.5 Holiday :\n            <\/span>   \n        <\/font>    \n<\/h4>","57379baf":"<h2>\n    <font color = green>\n        <span style='font-family:Georgia'>\n        Step 1: Reading & Understanding the data\n        <\/span>    \n    <\/font>\n<\/h2>","e96acdf7":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> All the parameters have increased values in 2019 compared to 2019. Thus, year may become a key paratemeter in the model  \n    <\/span>    \n<\/div>","682fedf0":"<h2>\n    <font color = green>\n        <span style='font-family:Georgia'>\n        Step 6: Final Model Interpretation\n        <\/span>    \n    <\/font>\n<\/h2>","a5927cec":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> There are no missing values in any of the columns and rows.   \n    <\/span>    \n<\/div>","e1acd2cd":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            5.3.4 Model 4\n            <\/span>   \n        <\/font>    \n<\/h3>\n<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> Next we will remove W3_Fall as it has high VIF\n    <\/span>    \n<\/div>","76977353":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            7.3 Absence of Multicolinearity\n            <\/span>   \n        <\/font>    \n<\/h3>","8f0f8d9c":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            5.3.3 Model 3\n            <\/span>   \n        <\/font>    \n<\/h3>","678f152a":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            1.1 Importing the Data\n            <\/span>   \n        <\/font>    \n<\/h3>","07ad847d":"<span style='font-family:Georgia'>\n<h4>   \n      <font color = green >\n          Adjusted R<sup>2<\/sup> Value Calculation for bike_test dataframe           \n        <\/font>    \n<\/h4>\n<\/span>\n<span style=\"font-size:18\" >\n    <span style ='font-family:Georgia'>\n        <font color = blue > \n      <math> R<sup>2<\/sup><sub>adj<\/sub>=1\u2212<\/math>\n        <span style=\"display: inline-block;vertical-align: middle;\">\n    <div style=\"text-align: center;border-bottom: 1px solid black;\">(1-R<sup>2<\/sup>) x (n-1)<\/div>\n     <div style=\"text-align: center;\">(n-p-1)<\/div> \n        <\/span>\n        <\/font>\n<\/span>\n<\/span>","eb6328bf":"<span style='font-family:Georgia'>\n    <p> Season <\/p>\n<\/span>","1b5fb627":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            7.2 Homoscedasticity\n            <\/span>   \n        <\/font>    \n<\/h3>","e69c9798":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            7.1 Linear Relationship\n            <\/span>   \n        <\/font>    \n<\/h3>","41f153f8":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> Based on the histogram, we can conclude that error terms are following a normal distribution\n    <\/span>    \n<\/div>","5e3eba4e":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            2.3 Numerical Variable Analysis\n            <\/span>   \n        <\/font>    \n<\/h3>","9f5d4a4b":"<h2>\n    <font color = green>\n        <span style='font-family:Georgia'>\n        Step 7: Model Validation\n        <\/span>    \n    <\/font>\n<\/h2>\n<span style='font-family:Georgia'>\n    <p> Validating the assumption of Linear Regression Model : <\/p>\n        <ul>\n            <li> Linear Relationship <\/li>\n            <li> Homoscedasticity <\/li>\n            <li> Absence of Multicollinearity <\/li>\n            <li> Independence of residuals <\/li>\n            <li> Normality of Errors<\/li>\n        <\/ul>\n    \n<\/span>","19b13974":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            4.3 Checking Correlation Coefficient\n            <\/span>   \n        <\/font>    \n<\/h3>","ac8baaac":"<h2>\n    <font color = green>\n        <span style='font-family:Georgia'>\n        Step 8: Making Predictions using final model\n        <\/span>    \n    <\/font>\n<\/h2>\n<span style='font-family:Georgia'>\n<h3>   \n      <font color = green >\n            8.1 Scaling bike_test dataframe             \n        <\/font>    \n<\/h3>\n<p>Apply scaler() to all numeric variables in test dataset. Note: we will only use scaler.transform, as we want to use the metrics that the model learned from the training data to be applied on the test data.In other words, we want to prevent the information leak from train to test dataset.\n<\/p>\n<\/span>  ","1ab5840f":"<span style='font-family:Georgia'>\n    <p> Verifying the train - test split and new dataframe details <\/p>\n<\/span>","80e2015d":"<h4>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            2.2.2 Month :\n            <\/span>   \n        <\/font>    \n<\/h4>","d199ea42":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> There is no visible pattern in residual values, thus homoscedacity is well preserved\n    <\/span>    \n<\/div>","9becbd12":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> The above plots represents the relationship between the model and the predictor variables. As we can see, linearity is well preserved\n    <\/span>    \n<\/div>","4301e7dc":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            3.1 Dummy Variable Creation\n            <\/span>   \n        <\/font>    \n<\/h3>\n","00aee096":"<h2>\n    <font color = green>\n        <span style='font-family:Georgia'>\n        Step 3: Data Preparation\n        <\/span>    \n    <\/font>\n<\/h2>","21d12b80":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> Based on the 70% - 30% split between train and test dataset we have 510 rows in train dataset and 220 in test dataset\n    <\/span>    \n<\/div>","e7b7dfca":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <p>\n            <b>Insight:<\/b> <br>\n            Bike rental demand has gone up from 2018 to 2019\n        <\/p>\n    <\/span>    \n<\/div>","b616bdcc":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            5.3.5 Model 5\n            <\/span>   \n        <\/font>    \n<\/h3>\n<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> Next we will remove Nov due to high p-value\n    <\/span>    \n<\/div>","e387a866":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <p>\n            <b>Insight:<\/b> <br>\n            Almost 32% of the bike booking were happening in Fall with a median of over 5000 bookings (for two years). It is followed by Summer & Winter with 27% & 25% of total booking. It indicates that the season can be a good predictor of the dependent variable.\n        <\/p>\n    <\/span>    \n<\/div>","3d240677":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> The Root Mean Squared Error value for the test dataset based on final model is 0.093 and Mean Absolute Error is 0.0714, which indicates that the model is really good.\n    <\/span>    \n<\/div>","10a70b78":"<h2>\n    <font color = green>\n        <span style='font-family:Georgia'>\n        Step 5: Building the Linear Model\n        <\/span>    \n    <\/font>\n<\/h2>","46ad3f9f":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <p>\n            <b>Insight:<\/b> <br>\n            Almost 69% of the bike booking were happening in 'workingday' with a median of close to 5000 bookings (for two years). It indicates that the workingday can be a good predictor of the dependent variable\n        <\/p>\n    <\/span>    \n<\/div>","e5c5970e":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <p>\n            <b>Insight:<\/b> <br>\n            Almost 97% of bike rentals are happening during non-holiday time.\n        <\/p>\n    <\/span>    \n<\/div>","48ff3c17":"<span style='font-family:Georgia'>\n<h3>   \n      <font color = green >\n            8.2 Dividing X_test and y_test            \n        <\/font>    \n<\/h3>\n<\/span> ","cae67b50":"<h4>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            2.2.4 Weekday :\n            <\/span>   \n        <\/font>    \n<\/h4>","7d944496":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            5.3.6 Model 6\n            <\/span>   \n        <\/font>    \n<\/h3>\n<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> Next we will remove Mar due to high p-value\n    <\/span>    \n<\/div>","21e8399b":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            1.4 Duplicate Checking\n            <\/span>   \n        <\/font>    \n<\/h3>","ce12202a":"<h2>\n    <font color = green>\n        <span style='font-family:Georgia'>\n        Step 4: Splitting the data into Train & Test Dataset\n        <\/span>    \n    <\/font>\n<\/h2>","34d51607":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> All the 30 columns are now as numeric value. The dataframe is ready now for splitting into Train & Test dataframes\n    <\/span>    \n<\/div>","1209472f":"<h4>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            4.1. Train & Test Split\n            <\/span>   \n        <\/font>    \n<\/h4>","fe55a674":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            4.2 Rescalling bike_train dataframe\n            <\/span>   \n        <\/font>    \n<\/h3>","a87475a7":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            1.2 Inspecting the Dataframe\n            <\/span>   \n        <\/font>    \n<\/h3>","4000756b":"<span style='font-family:Georgia'>\n<h4>   \n      <font color = green >\n          Calculating Mean Absolute Error for the selected Model          \n        <\/font>    \n<\/h4>\n<\/span>","fd4b2a57":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n<b>Insight:<\/b> \n        <ul>\n            <li>Except one column which is date type, all other are either float or integer type.<\/li>\n            <li>There are some fields that are categorical in nature, but are in integer\/float type. Example : <b> season, mnth, weathersit <\/b> etc. <\/li>\n        <\/ul>\n        <p>\n            We will have to analyze and decide whether to convert them to categorical or treat as integer. From Readme.txt file more information of these categorical columns can be inferred. \n        <\/p>    \n    <\/span>    \n<\/div>","f3cbde1b":"<span style='font-family:Georgia'>\n<h4>   \n      <font color = green >\n            Model Train & Test R2 Statsitics Comparison           \n        <\/font>    \n<\/h4>\n<table>\n    <thead>\n    <tr><th>Measurement<\/th><th>Train Dataset<\/th><th>Test Dataset<\/th><\/tr>\n    <\/thead>\n    <tbody>\n        <tr><td>R2 Value<\/td><td>82.4%<\/td><td>82%<\/td><\/tr>\n        <tr><td>Adjusted R2 Value<\/td><td>82.1%<\/td><td>81.2%<\/td><\/tr>\n    <\/tbody>\n<\/table>\n    <p> It seems to be really a good model that can generalize various datasets. <\/p>\n<\/span>","4681515e":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Note:<\/b> The dataframe has 730 rows and 16 columns\n    <\/span>    \n<\/div>","a6e87f2f":"<span style='font-family:Georgia'>\n<h4>   \n      <font color = green >\n          R<sup>2<\/sup> Value Calculation for bike_test dataframe           \n        <\/font>    \n<\/h4>\n<\/span>","a622d3c4":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> This model looks good, as there seems to be VERY LOW Multicollinearity between the predictors and the p-values for all the predictors seems to be significant. For now, we will consider this as our final model (unless the Test data metrics are not significantly close to this number)\n    <\/span>    \n<\/div>","213ce678":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> There is linear relationship between temp and atemp. Both of the parameters cannot be used in the model due to multicolinearity. We will decide which parameters to keep based on VIF and p-value w.r.t other variables  \n    <\/span>    \n<\/div>","6efe88c0":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            2.2 Categorical Variable Analysis\n            <\/span>   \n        <\/font>    \n<\/h3>","c4979926":"<span style='font-family:Georgia'>\n    <p> Month <\/p>\n<\/span>","ffd01b05":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            5.3 Manual Model Development using statsmodel\n            <\/span>   \n        <\/font>    \n<\/h3>","5b6cd703":"<h2>\n    <font color = green>\n        <span style='font-family:Georgia'>\n        Step 2: Encoding & Visualizing the data\n        <\/span>    \n    <\/font>\n<\/h2>","b41b4512":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            5.2 RFE\n            <\/span>   \n        <\/font>    \n<\/h3>\n<span style='font-family:Georgia'>\n    <p> Recursive feature elimination: We will be using the LinearRegression function from SciKit Learn for its compatibility with RFE <\/p>\n<\/span>   ","287121c0":"<h2>   \n      <font color = blue >\n            <span style='font-family:Georgia'>\n            Background:\n            <\/span>   \n        <\/font>    \n<\/h2>\n<p>\n    <span style='font-family:Georgia'>\n    A bike-sharing system is a service in which bikes are made available for shared use to individuals on a short term basis for a price or free. Many bike share systems allow people to borrow a bike from a \"dock\" which is usually computer-controlled wherein the user enters the payment information, and the system unlocks it. This bike can then be returned to another dock belonging to the same system.\n    <\/span>\n<\/p>   \n<hr>\n<h2>\n     <font color = blue >\n            <span style='font-family:Georgia'>\n            Problem Statement:\n            <\/span>   \n        <\/font>    \n<\/h2>\n<p>\n   <span style='font-family:Georgia'>\n    A US bike-sharing provider BoomBikes has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state.<br>\n<br>     \nIn such an attempt, BoomBikes aspires to understand the demand for shared bikes among the people after this ongoing quarantine situation ends across the nation due to Covid-19. They have planned this to prepare themselves to cater to the people's needs once the situation gets better all around and stand out from other service providers and make huge profits.<br>\n <br>      \nThey have contracted a consulting company to understand the factors on which the demand for these shared bikes depends. Specifically, they want to understand the factors affecting the demand for these shared bikes in the American market. The company wants to know:<br>\n    <\/span>\n<\/p>\n<ol>\n    <span style='font-family:Georgia'> \n        <li> Which variables are significant in predicting the demand for shared bikes. <\/li>\n        <li>How well those variables describe the bike demand<\/li>\n    <\/span>\n<\/ol>\n\n<p>\n    <span style='font-family:Georgia'> \nBased on various meteorological surveys and people's styles, the service provider firm has gathered a large dataset on daily bike demands across the American market based on some factors.        \n    <\/span> \n<\/p>   \n<hr>\n<h2>\n     <font color = blue >\n            <span style='font-family:Georgia'>\n            Business Goal:\n            <\/span>   \n        <\/font>    \n<\/h2>\n<p>\n    <span style='font-family:Georgia'>\nWe are required to model the demand for shared bikes with the available independent variables. It will be used by the management to understand how exactly the demands vary with different features. They can accordingly manipulate the business strategy to meet the demand levels and meet the customer's expectations. Further, the model will be a good way for management to understand the demand dynamics of a new market. \n    <\/span>\n<\/p> \n","7f8d914d":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            1.3 Data quality check\n            <\/span>   \n        <\/font>    \n<\/h3>","c111b2e4":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            3.2 Merging the Dataframes\n            <\/span>   \n        <\/font>    \n<\/h3>","16828754":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> Both temp and atemp has high VIF but atemp has high p-value additionally. We will go ahead with dropping atemp from the equation\n    <\/span>    \n<\/div>","ce3c7097":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> As hum has the highest VIF value, we will remove the variable next\n    <\/span>    \n<\/div>","b7408a5b":"<span style='font-family:Georgia'>\n    <p> Weekday <\/p>\n<\/span>","9cfc2e87":"<span style='font-family:Georgia'>\n    <h4> The equation of best fitted surface based on model lr6: <\/h4>\n<\/span> \n\n<div class=\"alert alert-block alert-success\">\n    <span style='font-family:Times New Roman'>\n        <p style=\"font-size:20px\">\n        cnt=0.082768 + (0.230252 x yr) + (0.043963 x workingday) + (0.564438 x temp) \u2212 (0.154241 x windspeed) + (0.082300 x W2_Summer) + (0.129186 x W4_Winter) + (0.094832 x Sep) + (0.057838 x Saturday) \u2212 (0.074921 x Misty) \u2212 (0.307082 x Light_rainsnow) \n        <\/p>\n    <\/span>\n<\/div>","e6166fa0":"<span style='font-family:Georgia'>\n    <font color = green>\n        <h3> Interpretation of coefficients : <\/h3>\n    <\/font>\n    <ul>\n        <li><b>const<\/b> : The Constant value of \u20180.082768\u2019 indicated that, in the absence of all other predictor variables (i.e. when x1,x2...xn =0), The bike rental can still increase by 0.084143 units <\/li><hr>\n         <li><b>yr<\/b> : A coefficient value of \u20180.230252\u2019 indicated that a unit increase in yr variable, increases the bike hire numbers by 0.230252 units <\/li><hr> \n         <li><b>workingday<\/b> : A coefficient value of \u20180.043963\u2019 indicated that, a unit increase in workingday variable increases the bike hire numbers by 0.043963 units <\/li><hr> \n         <li><b>temp<\/b> : A coefficient value of \u20180.564438\u2019 indicated that a unit increase in temp variable, increases the bike hire numbers by 0.564438 units <\/li><hr> \n         <li><b>windspeed<\/b> : A coefficient value of \u2018-0.154241\u2019 indicated that, a unit increase in windspeed variable decreases the bike hire numbers by 0.154241 units <\/li><hr> \n         <li><b>W2_Summer<\/b> : A coefficient value of \u20180.082300\u2019 indicated that a unit increase in W2_Summer variable decreases the bike hire numbers by 0.082300 units <\/li><hr> \n         <li><b>W4_Winter<\/b> : A coefficient value of \u20180.129186\u2019 indicated that a unit increase in W4_Winter variable increases the bike hire numbers by 0.129186 units<\/li><hr> \n         <li><b>Sep<\/b> : A coefficient value of \u20180.094832\u2019 indicated that a unit increase in Sep variable increases the bike hire numbers by 0.094832 units <\/li><hr> \n         <li><b>Light_rainsnow<\/b> : A coefficient value of \u2018-0.307082\u2019 indicated that, a unit increase in Weathersit3 variable, decreases the bike hire numbers by -0.307082 units <\/li><hr> \n         <li><b>Misty<\/b> : A coefficient value of \u2018-0.074921\u2019 indicated that a unit increase in Misty weather variable, decreases the bike hire numbers by 0.074921 units <\/li><hr> \n         <li><b>Saturday<\/b> : A coefficient value of \u20180.057838\u2019 indicated that a unit increase in Saturday variable increases the bike hire numbers by 0.057838 units <\/li><hr> \n    <\/ul>\n<\/span>","a39cabf5":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> The shape after running the drop duplicate command is same as the original dataframe. Hence we can conclude that there were not any duplicate values in the dataset.  \n    <\/span>    \n<\/div>","8bd8b439":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Note: <\/b> \n        <p>From the Readme.txt file, it was understood that the field 'dteday' is a date.Thus,parsing it as a date type while importing the bike data<\/p>\n    <\/span>    \n<\/div>","4b61ed85":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            0.1 Adjusting Screen Width\n            <\/span>   \n        <\/font>    \n<\/h3>","af2a6b3e":"<h4>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n             2.2.7 Year :\n            <\/span>   \n        <\/font>    \n<\/h4>","f2bb0f72":"<h2>\n    <font color = green>\n        <span style='font-family:Georgia'>\n        Step 9: Model Evaluation\n        <\/span>    \n    <\/font>\n<\/h2>","733fcc4f":"<span style='font-family:Georgia'>\n<h3>   \n      <font color = green >\n            7.4 Independence of residuals  \n       <\/font>    \n<\/h3>\n<p>Autocorrelation refers to the fact that observations\u2019 errors are correlated. To verify that the observations are not auto-correlated, we can use the Durbin-Watson test. The test will output values between 0 and 4. The closer it is to 2, the less auto-correlation there is between the various variables.<\/p>\n    <blockquote>\n        0 \u2013 2: positive auto-correlation<br>\n        2 \u2013 4: negative auto-correlation)\n    <\/blockquote>\n<\/span>     ","9c9165d0":"<span style='font-family:Georgia'>\n    <font color = green>\n        <h3> F-Staitsics : <\/h3>\n    <\/font>\n    <p> F-Statistics is used for testing the overall significance of the Model. The higher the F-Statistics, the more significant the Model is.<\/p>\n    <blockquote>\n        F-Statistics :       233.6 <br>\n        Prob (F-statistic):  4.48e-181\n    <\/blockquote>   \n<\/span>\n<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> The F-Statistics value of 233 (which is greater than 1) and the p-value of '~0.0000' states that the overall model is significant\n    <\/span>    \n<\/div>","978f1226":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            0.3 Import Necessary Python Libraries\n            <\/span>   \n      <\/font>    \n<\/h3>","8c6dedb4":"<span style='font-family:Georgia'>\n<h2>   \n      <font color = green >\n            Model Outcome Summary        \n        <\/font>    \n<\/h2>\n<\/span>\n<div class=\"alert alert-block alert-success\">\n    <span style='font-family:Georgia'>\n        <p><b>As per the final model, the top 5 predictor variables that influences bike booking are: <\/b><\/p><hr>\n        <ol>\n            <li><b>Temperature (Temp)<\/b><br> A coefficient value of \u20180.564438\u2019 indicated that a temperature has significant impact on bike rentals <\/li>\n            <li><b>Light Rain & Snow (weathersit =3)<\/b><br>A coefficient value of \u2018-0.307082\u2019 indicated that the light snow and rain deters people from renting out bikes<\/li>\n            <li><b> Year (yr) <\/b><br>A coefficient value of \u20180.230252\u2019 indicated that a year wise the rental numbers are increasing<\/li>\n        <\/ol>\n<hr>\n<p>It is recommended to give utmost importance to these three variables while planning to achieve maximum bike rental booking.<br>\n    As high temperature and good weather positively impacts bike rentals, it is recommended that bike availability and promotions to be increased during summer months to further increase bike rentals. \n        <\/p>\n     <\/span> \n<\/div>   ","d7483412":"<span style='font-family:Georgia'>\n    <font color = green>\n        <h3> Hypothesis Testing : <\/h3>\n    <\/font>\n    <p> Hypothesis Testing States that<br>\n        <blockquote>\n            H0:B1=B2=...=Bn=0 <br>\n            H1: at least one  Bi!=0\n        <\/blockquote><br>\n    <b> lr6 model coefficient values<\/b>\n    <\/p>\n    <table>\n    <thead>\n    <tr><th>Parameter<\/th><th>Coefficient<\/th><\/tr>\n    <\/thead>\n    <tbody>\n        <tr><td>const<\/td><td>0.084143<\/td><\/tr>\n        <tr><td>yr<\/td><td>0.230846<\/td><\/tr>\n        <tr><td>workingday<\/td><td>0.043203<\/td><\/tr>\n        <tr><td>temp<\/td><td>0.563615<\/td><\/tr>\n        <tr><td>windspeed<\/td><td>-0.155191<\/td><\/tr>\n        <tr><td>W2_Summer<\/td><td>0.082706<\/td><\/tr>\n        <tr><td>W4_Winter<\/td><td>0.128744<\/td><\/tr>\n        <tr><td>Sep<\/td><td>0.094743<\/td><\/tr>\n        <tr><td>Might_rainsnow<\/td><td>-0.306992<\/td><\/tr>\n        <tr><td>Misty<\/td><td>-0.074807<\/td><\/tr>\n        <tr><td>Saturday<\/td><td>0.056909<\/td><\/tr>\n    <\/tbody>\n<\/table>\n<\/span>\n<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> From the lr6 model summary, it is evident that all our coefficients are not equal to zero, which means we <b>REJECT the NULL HYPOTHESIS<\/b> \n    <\/span>    \n<\/div>","f37fde61":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <p>\n            <b>Insight:<\/b> <br>\n            Almost 10% of the bike booking was happening in the months' May to Sep with a median of over 4000 bookings per month. It indicates that the mnth has some trend for bookings and can be a good predictor for the dependent variable. \n        <\/p>\n    <\/span>    \n<\/div>","57a3d095":"<h4>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            2.2.1 Season :\n            <\/span>   \n        <\/font>    \n<\/h4>","afaad324":"<h4>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            2.2.3 Weather:\n            <\/span>   \n        <\/font>    \n<\/h4>","270c1e47":"<h4>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n             2.2.6 Working Day :\n            <\/span>   \n        <\/font>    \n<\/h4>","806a8100":"<span style='font-family:Georgia'>\n    <p> Weather <\/p>\n<\/span>","05ab1a9f":"<span style='font-family:Georgia'>\n<h3>   \n      <font color = green >\n            7.5 Normality of error \n       <\/font>    \n<\/h3>\n<\/span>\n","b096f43f":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> All the predictor variables have VIF value less than 5. So we can consider that there is insignificant multicolinearity among the predictor variables.\n    <\/span>    \n<\/div>","f6fa360e":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Note:<\/b> \n            <p>\n            Based on the high level analysis of the data and the data dictionary, the following variables can be removed from further analysis -\n            <\/p>\n        <ul>\n            <li><b>instant<\/b>: It is only an index value <\/li>\n            <li><b>dteday<\/b>: This has the date, Since we already have separate columns for 'year' & 'month' we could live without this column<\/li>\n            <li><b>casual<\/b> & <b>registered<\/b>: Both these columns contains the count of bike booked by different categories of customers. From the pairplot as well as the correlation heatmap, we can concur that total bike rental value 'cnt = 'casual' + 'registered'. Since our objective is to find the total count of bikes and not by specific category, we will ignore these two columns.<\/li>\n        <\/ul>    \n    <\/span>    \n<\/div>","44be5e6f":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <p>\n            <b>Insight:<\/b> <br>\n            weekday variable shows the very close trend (between 13.5%-14.8% of total booking on all days of the week) having their independent medians between 4000 to 5000 bookings. This variable can have some or no influence on the predictor. Further analysis would be needed to determine whether this attribute needs to be included in the model parameter selection \n        <\/p>\n    <\/span>    \n<\/div>","eb543825":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <p>\n            <b>Insight:<\/b> <br>\n            Almost 68.6% of the bike booking was happening during Clear weather with a median of close to 5000 bookings (for two years). This was followed by Misty with 30% of the total booking. It indicates that the weathersit does show some trend towards the bike bookings, and it can be a good predictor for the dependent variable. The current data frame does not have any data where the weather is Heavy_RainSnow\n        <\/p>\n    <\/span>    \n<\/div>","a106f424":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> \n        <p>There is multi-colinearity between the variables. We need to consider the factors when developing the model. <\/p>\n        <ul>\n            <li> temp and atemp has very high correlation value of 0.99. This suggest, we can use only one of these two variables<\/li>\n            <li> workingday variable has high negative correlation with Sat & Sun (where workingday =0) <\/li>\n            <li> Spring is negatively correlated with cnt <\/li>\n            <li> emp, atemp and yr has strong correlation with cnt <\/li>\n            <li> misty weather and humidity has correlation<\/li>\n            <li> various months and corresponding weather has correlation<\/li>            \n        <\/ul>    \n    <\/span>    \n<\/div>","7c70388f":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            5.3.2 Model 2\n            <\/span>   \n        <\/font>    \n<\/h3>","bfda66bc":"<h2>\n    <font color = green>\n        <span style='font-family:Georgia'>\n        0. Import necessary libraries\n        <\/span>    \n    <\/font>\n<\/h2> ","f1d48bf5":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            5.3.1 Model 1\n            <\/span>   \n        <\/font>    \n<\/h3>","89f62d85":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            0.2 Supressing Warnings\n            <\/span>   \n      <\/font>    \n<\/h3>","021248b8":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            1.5 Removing Redundant columns\n            <\/span>   \n        <\/font>    \n<\/h3>","7eed6d22":"<div class=\"alert alert-block alert-info\">\n    <span style='font-family:Georgia'>\n        <b>Insight:<\/b> There is almost no autocorrelation.\n    <\/span>    \n<\/div>","1359aff6":"<span style='font-family:Georgia'>\n<h4>   \n      <font color = green >\n          Calculating RMSE for the selected Model          \n        <\/font>    \n<\/h4>\n<\/span>","130826f8":"<h3>   \n      <font color = green >\n            <span style='font-family:Georgia'>\n            3.3 Removing unnecessary columns\n            <\/span>   \n        <\/font>    \n<\/h3>"}}