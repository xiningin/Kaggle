{"cell_type":{"d7e5d44b":"code","b97ddc27":"code","5b636f1b":"code","63dcbe60":"code","cf51366e":"code","33fa6572":"code","52f756f5":"code","7c4bfa94":"code","f63dfa83":"code","04163767":"code","84d18205":"code","772b4087":"code","8555b00e":"code","5a4a742a":"code","01d6cd38":"code","f27f3b85":"code","3edbb3d5":"code","10fe80dd":"code","efae137e":"code","907d4427":"code","9da99911":"code","bfe63505":"code","9ff1de51":"code","cf2c7d42":"code","55a1a49b":"code","35aaa367":"code","8f32cfef":"code","cca19a20":"markdown","ba46c48e":"markdown","398eb277":"markdown"},"source":{"d7e5d44b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b97ddc27":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score\n","5b636f1b":"data = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')","63dcbe60":"# Start exploring the dataset\nprint(data.columns)","cf51366e":"data.head()","33fa6572":"data.tail()","52f756f5":"# distribution of Amount\namount = [data['Amount'].values]\nsns.distplot(amount)","7c4bfa94":"# distribution of Time\ntime = data['Time'].values\nsns.distplot(time)\n","f63dfa83":"# Correlation matrix\ncorrmat = data.corr()\nfig = plt.figure(figsize = (12, 9))\n\nsns.heatmap(corrmat, vmax = .8, square = True)\nplt.show()","04163767":"# dataset informations\ndata.info()","84d18205":"# checking the number of missing values in each column\ndata.isnull().sum()","772b4087":"data['Class'].value_counts()","8555b00e":"# separating the data for analysis\nl = data[data.Class == 0]\nf = data[data.Class == 1]","5a4a742a":"print(l.shape)\nprint(f.shape)","01d6cd38":"l_sample = l.sample(n=492)","f27f3b85":"new_dataset = pd.concat([l_sample, f], axis=0)","3edbb3d5":"new_dataset.head()","10fe80dd":"new_dataset['Class'].value_counts()","efae137e":"X = new_dataset.drop(columns='Class', axis=1)\nY = new_dataset['Class']","907d4427":"print(X)","9da99911":"print(Y)","bfe63505":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)","9ff1de51":"print(X.shape, X_train.shape, X_test.shape)","cf2c7d42":"\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nrfc.fit(X_train,Y_train)\ny_pred = rfc.predict(X_test)\nacc= accuracy_score(Y_test,y_pred)\n","55a1a49b":"model = LogisticRegression()\nmodel.fit(X_train, Y_train)\nX_train_prediction = model.predict(X_train)\ntraining_data_accuracy = accuracy_score(X_train_prediction, Y_train)\nX_test_prediction = model.predict(X_test)\naccuracy = accuracy_score(X_test_prediction, Y_test)\n","35aaa367":"acc1=f1_score(Y_test,y_pred)\naccuracy1 = f1_score(Y_test,y_pred)","8f32cfef":"\nprint(\"The accuracy of Logistic Regression  is  {}\".format(accuracy))\nprint(\"The accuracy of Random Forest Classifier  is  {}\".format(acc))\nprint(\"The accuracy of Logistic Regression  is  {}\".format(accuracy1))\nprint(\"The accuracy of Random Forest Classifier  is  {}\".format(acc1))","cca19a20":"=> ***unblanced dataset***","ba46c48e":"***loading the dataset to a Pandas DataFrame***\n","398eb277":"****Importing All Necessary API****"}}