{"cell_type":{"9187a1e3":"code","a808cee2":"code","3ebea809":"code","d749b855":"code","1a83ab2b":"code","d238e838":"code","8948f784":"code","32741849":"code","3bf3ba52":"code","eeae0f57":"code","cff3cca1":"code","7839e2da":"code","96a0a902":"code","73f82499":"code","e8821d10":"code","b4418f45":"code","c805896b":"code","21d27192":"code","3f40cb4d":"code","33df4038":"code","6779ab76":"code","1e5a36a7":"code","146bf9ce":"code","afca6377":"code","b7cbe000":"markdown","e2ab8cf5":"markdown","ddbfd3f7":"markdown","7017a9a4":"markdown","0752385b":"markdown","dd356678":"markdown","64fc8def":"markdown","66ed2e60":"markdown","7587a756":"markdown","ea4ecd06":"markdown","edc94588":"markdown","dacd7f62":"markdown","a881417d":"markdown","7cc5e5e6":"markdown"},"source":{"9187a1e3":"# importing some basic libraries|\nimport pandas as pd\nimport numpy as np\nimport os\nimport math","a808cee2":"## load train and test data\ntrain_data= pd.read_csv('..\/input\/30-days-of-ml\/train.csv')\ntest_data=pd.read_csv('..\/input\/30-days-of-ml\/test.csv')","3ebea809":"train_data.describe()","d749b855":"train_data.info()","1a83ab2b":"train_data.isnull().sum()","d238e838":"test_data.isnull().sum()","8948f784":"pd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","32741849":"figure, axis = plt.subplots(5, 3)\nfigure.set_figheight(25)\nfigure.set_figwidth(20)\n\naxis[0, 0].scatter(x=train_data['cont0'],y=train_data['target'],s=.5)\naxis[1, 0].scatter(x=train_data['cont1'],y=train_data['target'],s=.5)\naxis[2, 0].scatter(x=train_data['cont2'],y=train_data['target'],s=.5)\naxis[0, 2].scatter(x=train_data['cont3'],y=train_data['target'],s=.5)\naxis[0, 1].scatter(x=train_data['cont4'],y=train_data['target'],s=.5)\naxis[1, 1].scatter(x=train_data['cont5'],y=train_data['target'],s=.5)\naxis[2, 1].scatter(x=train_data['cont6'],y=train_data['target'],s=.5)\naxis[1, 2].scatter(x=train_data['cont7'],y=train_data['target'],s=.5)\naxis[2, 2].scatter(x=train_data['cont8'],y=train_data['target'],s=.5)\naxis[3, 0].scatter(x=train_data['cont9'],y=train_data['target'],s=.5)\naxis[3, 1].scatter(x=train_data['cont10'],y=train_data['target'],s=.5)\naxis[3, 2].scatter(x=train_data['cont11'],y=train_data['target'],s=.5)\naxis[4, 0].scatter(x=train_data['cont12'],y=train_data['target'],s=.5)\naxis[4, 1].scatter(x=train_data['cont13'],y=train_data['target'],s=.5)\n","3bf3ba52":"sns.histplot(data=train_data,x='target')","eeae0f57":"figure, axis = plt.subplots(3, 4)\nfigure.set_figheight(9)\nfigure.set_figwidth(12)\naxis[0, 0].scatter(x=train_data['cat0'],y=train_data['target'],s=5)\naxis[0, 1].scatter(x=train_data['cat1'],y=train_data['target'],s=5)\naxis[0, 2].scatter(x=train_data['cat2'],y=train_data['target'],s=5)\naxis[0, 3].scatter(x=train_data['cat3'],y=train_data['target'],s=5)\naxis[1, 0].scatter(x=train_data['cat4'],y=train_data['target'],s=5)\naxis[1, 1].scatter(x=train_data['cat5'],y=train_data['target'],s=5)\naxis[1, 2].scatter(x=train_data['cat6'],y=train_data['target'],s=5)\naxis[1, 3].scatter(x=train_data['cat7'],y=train_data['target'],s=5)\naxis[2, 0].scatter(x=train_data['cat8'],y=train_data['target'],s=5)\naxis[2, 1].scatter(x=train_data['cat9'],y=train_data['target'],s=5)\n","cff3cca1":"traindf=train_data.copy()\ntestdf=test_data.copy()\n\nfor i in range(10):\n    map_=list(train_data['cat'+str(i)].unique())\n    map_.sort()\n    traindf['cat'+str(i)]=traindf['cat'+str(i)].apply(lambda x : map_.index(x))\n    testdf['cat'+str(i)]=testdf['cat'+str(i)].apply(lambda x : map_.index(x))","7839e2da":"# Lets plot the correlation heatmap\nsns.heatmap(traindf.corr(),annot=True,cmap='magma',linewidths=0.2,annot_kws={'size':5})\nfig=plt.gcf()\nfig.set_size_inches(14,10)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.show()","96a0a902":"# importing automl and converting pandas df to h2o df\nimport h2o\nfrom h2o.automl import H2OAutoML\nh2o.init()\nhf = h2o.H2OFrame(traindf.drop(columns=['id']))\ny_col = \"target\"\nx_col =[ col for col in hf.columns if col!=\"target\" ]","73f82499":"# Starting the search for best model \n# We run the search for max 30 min, and limit search space to 50 models and we want to sort the models by rmse\n\n# aml = H2OAutoML(seed=1,sort_metric='rmse')\n# aml.train(x=x_col, y=y_col, training_frame=hf)","e8821d10":"# aml.leaderboard","b4418f45":"# leaderboard=aml.leaderboard.as_data_frame(use_pandas=True)\n# leaderboard.to_csv('h2o_leaderboard.csv')","c805896b":"leaderboard=pd.read_csv('..\/input\/aml-leaderboard\/h2o_leaderboard (3).csv')\nleaderboard\n# model_list=leaderboard['model_id'].values\n# blend=traindf.copy()\n# blend_test=testdf.copy()\n# thf = h2o.H2OFrame(testdf.drop(columns=['id']))\n# for i in range(10):\n#     model=h2o.get_model(model_list[i])\n#     preds=model.predict(hf)\n#     preds=preds.as_data_frame(use_pandas=True)\n#     preds_test=model.predict(thf)\n#     preds_test=preds_test.as_data_frame(use_pandas=True)\n#     blend[\"pred\"+str(i)]=preds['predict']\n#     blend_test[\"pred\"+str(i)]=preds_test['predict']","21d27192":"# blend.to_csv('blend.csv')\n# blend_test.to_csv('blend_test.csv')","3f40cb4d":"blend=pd.read_csv('..\/input\/30-days-of-ml-blend\/blend.csv')\nblend_test=pd.read_csv('..\/input\/30-days-of-ml-blend\/blend_test.csv')","33df4038":"pred_cols=[col for col in blend.columns if(\"pred\" in col or col=='target')]","6779ab76":"# from sklearn.linear_model import LinearRegression\n# from xgboost import XGBRegressor\n# lr=XGBRegressor()\n\n# lr.fit(blend[pred_cols],blend['target'])\n# preds=lr.predict(blend_test[pred_cols])\n# submission = pd.DataFrame({'id':blend_test['id'],'target':preds})\n# submission.to_csv('submission_auto.csv',index = False)","1e5a36a7":"# hf = h2o.H2OFrame(blend[pred_cols])\n# y_col = \"target\"\n# x_col =[ col for col in hf.columns if col!=\"target\" ]","146bf9ce":"# aml = H2OAutoML(seed=1,sort_metric='rmse')\n# aml.train(x=x_col, y=y_col, training_frame=hf)","afca6377":"# preds=aml.leader.predict(h2o.H2OFrame(blend_test[x_col]))\n# preds=preds.as_data_frame(use_pandas=True)\n# submission = pd.DataFrame({'id':blend_test['id'],'target':preds['predict']})\n# submission.to_csv('submission_auto.csv',index = False)","b7cbe000":"### We could use Linear Regression,Xgboost or some other regressor. But just for fun I again used the H2O AutoML to find best model !","e2ab8cf5":"### Lets see how target is distributed","ddbfd3f7":"# Model Training \n\n### Alright, lets get into AutoML","7017a9a4":"### Commenting out this part as it takes a while to run","0752385b":"# Conclusion\n\n### Aim of this notebook to expose newbies like me to AutoML. I got better score by using tuned XGBoost, LGBM models. Comment down if you guys have any doubt or question!! \n### I Hope you guys had fun reading this one !","dd356678":"# Hey Everyone !\n### In this notebook we'll learn about AutoML using H2O.ai\n### We'll start with basic EDA and visualization, followed by Feature Engineering and finally model building !!\n\n\n## Lets get started !!","64fc8def":"### For this problem we don't have much to explore, but lets see what we dealing with","66ed2e60":"### Plotting categorical features","7587a756":"### Reading the saved blend data","ea4ecd06":"# Feature Engineering\n\n### Because we don't have labels for the columns, we cant really do much other than shoot in the dark. We can create new features by combining the available featues, but right now, lets just convert categorical variables to numerical and move forward ! ","edc94588":"# EDA","dacd7f62":"### It's nice that we don't need to deal with null values !","a881417d":"## What is AutoML ? \n## AutoML helps solving the tedious manual task of exploring different models for our train data.\n## AutoML can search over a huge model space to find the model that best fits our task","7cc5e5e6":"### Plotting continuous features"}}