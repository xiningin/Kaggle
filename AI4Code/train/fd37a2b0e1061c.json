{"cell_type":{"27b6ea7f":"code","da8c730c":"code","bb27448b":"code","36513f7d":"code","74dd8eb5":"code","82b88074":"code","625ec595":"code","3ef45ebd":"code","73721765":"code","b7115b9b":"code","1c97a4e4":"code","5d04ca98":"code","0513bf4a":"code","4a9dfaa9":"code","f4c2128f":"code","28e3374e":"code","5fce0fc6":"code","5023cde5":"code","a9dd04fe":"code","35a8c7ae":"code","e7dbbc62":"code","6fc20aed":"code","a4e53c98":"code","13f5810a":"code","df108175":"code","d5682395":"code","bdc863e8":"code","156a6912":"code","bd73764f":"code","627fbd0c":"code","1b4ca44f":"code","4524238a":"code","959fd584":"markdown"},"source":{"27b6ea7f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","da8c730c":"from sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly.express as px\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport cufflinks as cf\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\nfrom wordcloud import WordCloud,STOPWORDS\nimport matplotlib.pyplot as plt\n\nimport warnings            \nwarnings.filterwarnings(\"ignore\") ","bb27448b":"covid_data = pd.read_csv('\/kaggle\/input\/covid19-tweets\/covid19_tweets.csv')\ncovid_data.head()","36513f7d":"print('Total tweets in this data: {}'.format(covid_data.shape[0]))\nprint('Total Unique Users in this data: {}'.format(covid_data['user_name'].nunique()))","74dd8eb5":"# info of the data\n\ncovid_data.info()","82b88074":"covid_data['country_name'] = covid_data['user_location'].str.split(',').str[-1]\ncovid_data['only_date'] = pd.to_datetime(covid_data['date']).dt.date","625ec595":"# let's see top 15 users by no. of tweets\n\nuser_analysis = pd.DataFrame(covid_data['user_name'].value_counts().sort_values(ascending=False))\nuser_analysis = user_analysis.rename(columns={'user_name':'count'})\n\ntrace = go.Bar(x = user_analysis.index[:15],\n              y = user_analysis['count'][:15],\n              marker = dict(color='rgba(255,155,128,0.5)',\n              line = dict(color='rgb(0,0,0)', width=1.5)))\n\nlayout = go.Layout(title=\"Top 15 user by no. of tweets\",\n                  xaxis=dict(title='User Name',zeroline= False,\n                         gridcolor='rgb(183,183,183)',showline=True),\n                  yaxis=dict(title='Frequency of tweets',zeroline= False,\n                            gridcolor='rgb(183,183,183)',showline=True),\n                  font=dict(family='Courier New, monospace', size=12, color='rgb(0,0,0)')\n)\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","3ef45ebd":"# let's see top 15 users by no. of tweets\n\nlocation_analysis = pd.DataFrame(covid_data['user_location'].value_counts().sort_values(ascending=False))\nlocation_analysis = location_analysis.rename(columns={'user_location':'count'})\n\ntrace = go.Bar(x = location_analysis.index[:15],\n              y = location_analysis['count'][:15],\n              marker = dict(color='rgba(125, 215, 180, 0.5)',\n              line = dict(color='rgb(0,0,0)', width=1.5)))\n\nlayout = go.Layout(title=\"Top 15 Location by no. of tweets\",\n                  xaxis=dict(title='Location Name',zeroline= False,\n                         gridcolor='rgb(183,183,183)',showline=True),\n                  yaxis=dict(title='Frequency of tweets',zeroline= False,\n                            gridcolor='rgb(183,183,183)',showline=True),\n                  font=dict(family='Courier New, monospace', size=12, color='rgb(0,0,0)')\n)\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","73721765":"data = {\n   \"values\": location_analysis['count'][:15],\n   \"labels\": location_analysis.index[:15],\n   \"domain\": {\"column\": 0},\n   \"name\": \"Location Name\",\n   \"hoverinfo\":\"label+percent+name\",\n   \"hole\": .4,\n   \"type\": \"pie\"\n}\nlayout = go.Layout(\n   {\n      \"title\":\"Location Ratio\",\n}\n)\n\ndata = [data]\nfig = go.Figure(data = data, layout = layout)\niplot(fig)\n","b7115b9b":"tweet_analysis = pd.DataFrame(covid_data['only_date'].value_counts())\ntweet_analysis = tweet_analysis.rename(columns={'only_date':'count'})\n\ntrace = go.Bar(x = tweet_analysis.index,\n              y = tweet_analysis['count'],\n              marker = dict(color='rgba(150, 200, 100, 0.5)',\n              line = dict(color='rgb(0,0,0)', width=1.5)))\n\nlayout = go.Layout(barmode='group',\n                  title=\"Date wise no. of tweets\",\n                  xaxis=dict(title='Date',zeroline= False,\n                         gridcolor='rgb(183,183,183)',showline=True),\n                  yaxis=dict(title='Frequency of tweets',zeroline= False,\n                            gridcolor='rgb(183,183,183)',showline=True),\n                  font=dict(family='Courier New, monospace', size=12, color='rgb(0,0,0)')\n)\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","1c97a4e4":"# top source \nsource_analysis = pd.DataFrame(covid_data['source'].value_counts().sort_values(ascending=False))\nsource_analysis = source_analysis.rename(columns={'source':'count'})\n\ntrace = go.Bar(x = source_analysis.index[:10],\n              y = source_analysis['count'][:10],\n              marker = dict(color='rgba(150, 125, 180, 0.5)',\n              line = dict(color='rgb(0,0,0)', width=1.5)))\n\nlayout = go.Layout(title=\"Top 10 Sources by no. of tweets\",\n                  xaxis=dict(title='Source Name',zeroline= False,\n                         gridcolor='rgb(183,183,183)',showline=True),\n                  yaxis=dict(title='Frequency of tweets',zeroline= False,\n                            gridcolor='rgb(183,183,183)',showline=True),\n                  font=dict(family='Courier New, monospace', size=12, color='rgb(0,0,0)')\n)\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","5d04ca98":"data = {\n   \"values\": source_analysis['count'][:15],\n   \"labels\": source_analysis.index[:15],\n   \"domain\": {\"column\": 0},\n   \"name\": \"Source Name\",\n   \"hoverinfo\":\"label+percent+name\",\n   \"hole\": .4,\n   \"type\": \"pie\"\n}\nlayout = go.Layout(\n   {\n      \"title\":\"Source Ratio of Top 15 sources\",\n}\n)\ndata = [data]\nfig = go.Figure(data = data, layout = layout)\nfig.update_layout(\n    autosize=False,\n    width=1200,\n    height=700,)\niplot(fig)","0513bf4a":"def wordcloud(string):\n    wc = WordCloud(width=800,height=500,mask=None,random_state=21, max_font_size=110,stopwords=stop_words).generate(string)\n    fig=plt.figure(figsize=(16,8))\n    plt.axis('off')\n    plt.imshow(wc)","4a9dfaa9":"stop_words=set(STOPWORDS)\ncountry_string = \" \".join(covid_data['country_name'].astype('str'))\nsource_string = \" \".join(covid_data['source'].astype('str'))\ntext_string = \" \".join(covid_data['text'])\ndescription_string = \" \".join(covid_data['user_description'].astype('str'))\nhastage_string = \" \".join(covid_data['hashtags'].astype('str'))\nlocation_string = \" \".join(covid_data['user_location'].astype('str'))","f4c2128f":"wordcloud(country_string)","28e3374e":"wordcloud(source_string)","5fce0fc6":"wordcloud(text_string)","5023cde5":"wordcloud(description_string)","a9dd04fe":"wordcloud(hastage_string)","35a8c7ae":"wordcloud(location_string)","e7dbbc62":"sentiment_data = pd.read_csv('\/kaggle\/input\/twitterdata\/finalSentimentdata2.csv')","6fc20aed":"sentiment_data.head()","a4e53c98":"sentiment_data = sentiment_data.drop(columns=['Unnamed: 0'])","13f5810a":"sentiment_data['sentiment'].unique()","df108175":"import re\nimport string\ndef remove_punc(text):\n    # Dealing with Punctuation\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\nsentiment_data['text'] = sentiment_data['text'].apply(remove_punc)","d5682395":"from nltk import stem\nfrom nltk.corpus import stopwords\nstemmer = stem.SnowballStemmer('english')\nstopwords = set(stopwords.words('english'))\n\ndef alternative_review_messages(msg):\n    # converting messages to lowercase\n    msg = msg.lower()\n    # removing stopwords\n    msg = [word for word in msg.split() if word not in stopwords]\n    # using a stemmer\n    msg = \" \".join([stemmer.stem(word) for word in msg])\n    return msg\n\nsentiment_data['text'] = sentiment_data['text'].apply(alternative_review_messages)","bdc863e8":"SEED = 2000\nx_train, x_validation, y_train, y_validation = train_test_split(sentiment_data['text'], sentiment_data['sentiment'], \n                                                                test_size=.2, random_state=SEED)","156a6912":"from time import time\ndef prediction(pipeline, x_train, y_train,testtext):\n    t0 = time()\n    sentiment_fit = pipeline.fit(x_train, y_train)\n    y_pred = sentiment_fit.predict(testtext)\n    return y_pred","bd73764f":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import RidgeClassifier\n\nvectorizer=TfidfVectorizer()\nchecker_pipeline = Pipeline([\n            ('vectorizer', vectorizer),\n            ('classifier', RidgeClassifier())\n        ])\nvectorizer.set_params(stop_words=None, max_features=10000, ngram_range=(1,4))\nprediction=prediction(checker_pipeline,x_train, y_train,x_validation)","627fbd0c":"from sklearn.metrics import accuracy_score\ndef acc_summary(pipeline, x_train, y_train, x_test, y_test):\n    t0 = time()\n    sentiment_fit = pipeline.fit(x_train, y_train)\n    y_pred = sentiment_fit.predict(x_test)\n    train_test_time = time() - t0\n    accuracy = accuracy_score(y_test, y_pred)\n    print(\"accuracy score: {0:.2f}%\".format(accuracy*100))\n    print(\"train and test time: {0:.2f}s\".format(train_test_time))\n    print(\"-\"*80)\n    return accuracy, train_test_time\nclf_acc = acc_summary(checker_pipeline, x_train, y_train, x_validation, y_validation)","1b4ca44f":"from sklearn.svm import SVC\ndef prediction2(pipeline, x_train, y_train,testtext):\n    t0 = time()\n    sentiment_fit = pipeline.fit(x_train, y_train)\n    y_pred = sentiment_fit.predict(testtext)\n    return y_pred\nchecker_pipeline2 = Pipeline([\n            ('vectorizer', vectorizer),\n            ('classifier', SVC(C=1000))\n        ])\nvectorizer.set_params(stop_words=None, max_features=10000, ngram_range=(1,4))\nprediction=prediction2(checker_pipeline2,x_train, y_train,x_validation)","4524238a":"clf_acc = acc_summary(checker_pipeline2, x_train, y_train, x_validation, y_validation)","959fd584":"If you found this kernel helpful, please upvote it"}}