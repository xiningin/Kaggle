{"cell_type":{"4125378f":"code","fdb63bf5":"code","846f1890":"code","8e84b7e3":"code","caee92b7":"code","47c38b76":"code","f19c760b":"code","8e5145bc":"code","026b49e1":"code","1b9f4d58":"code","1a67dbb8":"code","d2be00a0":"code","de3c7477":"code","17190158":"code","7d6835b6":"markdown","deb3c883":"markdown"},"source":{"4125378f":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport glob\nimport pickle\nimport random\nimport os\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Dense","fdb63bf5":"# options\n\nN_SPLITS = 10\n\nSEED = 2021\n\nNUM_FEATS = 20 # number of features that we use. there are 100 feats but we don't need to use all of them\n\nbase_path = '\/kaggle'","846f1890":"feature_dir = f\"{base_path}\/input\/indoorunifiedwifids\"\ntrain_files = sorted(glob.glob(os.path.join(feature_dir, '*_train.csv')))\ntest_files = sorted(glob.glob(os.path.join(feature_dir, '*_test.csv')))\nsubm = pd.read_csv(f'{base_path}\/input\/indoor-location-navigation\/sample_submission.csv', index_col=0)","8e84b7e3":"with open(f'{feature_dir}\/train_all.pkl', 'rb') as f:\n  data = pickle.load( f)\n\nwith open(f'{feature_dir}\/test_all.pkl', 'rb') as f:\n  test_data = pickle.load(f)","caee92b7":"# get numbers of bssids to embed them in a layer\n\nwifi_bssids = []\nfor i in range(100):\n    wifi_bssids.extend(data.iloc[:,i].values.tolist())\nwifi_bssids = list(set(wifi_bssids))\n\nwifi_bssids_size = len(wifi_bssids)\nprint(f'BSSID TYPES: {wifi_bssids_size}')\n\nwifi_bssids_test = []\nfor i in range(100):\n    wifi_bssids_test.extend(test_data.iloc[:,i].values.tolist())\nwifi_bssids_test = list(set(wifi_bssids_test))\n\nwifi_bssids_size = len(wifi_bssids_test)\nprint(f'BSSID TYPES: {wifi_bssids_size}')\n\nwifi_bssids.extend(wifi_bssids_test)\nwifi_bssids_size = len(wifi_bssids)","47c38b76":"# preprocess\n\nle = LabelEncoder()\nle.fit(wifi_bssids)\nle_site = LabelEncoder()\nle_site.fit(data['site_id'])\n\nss = StandardScaler()\nss.fit(data.loc[:,RSSI_FEATS])","f19c760b":"data.loc[:,RSSI_FEATS] = ss.transform(data.loc[:,RSSI_FEATS])\nfor i in BSSID_FEATS:\n    data.loc[:,i] = le.transform(data.loc[:,i])\n    data.loc[:,i] = data.loc[:,i] + 1\n    \ndata.loc[:, 'site_id'] = le_site.transform(data.loc[:, 'site_id'])\n\ndata.loc[:,RSSI_FEATS] = ss.transform(data.loc[:,RSSI_FEATS])","8e5145bc":"test_data.loc[:,RSSI_FEATS] = ss.transform(test_data.loc[:,RSSI_FEATS])\nfor i in BSSID_FEATS:\n    test_data.loc[:,i] = le.transform(test_data.loc[:,i])\n    test_data.loc[:,i] = test_data.loc[:,i] + 1\n    \ntest_data.loc[:, 'site_id'] = le_site.transform(test_data.loc[:, 'site_id'])\n\ntest_data.loc[:,RSSI_FEATS] = ss.transform(test_data.loc[:,RSSI_FEATS])","026b49e1":"from sklearn import preprocessing\nnp.random.seed(10)\ndataset = data.values\nnp.random.shuffle(dataset)\nX= dataset[:, 0:20]\nY = dataset[:,200:203]\n#x_rssi=dataset[:, 100:120]\nX_site=dataset[:,204:205]\n#X = preprocessing.scale(X)\nX=np.hstack((X,X_site))\n#X -= X.mean(axis=0)\n#X \/= X.std(axis=0)\n#X = preprocessing.scale(X)\nprint(X)\nprint(Y)\n","1b9f4d58":"X_train, Y_train = X[:200000], Y[:200000]     \nX_test, Y_test = X[200000:], Y[200000:] ","1a67dbb8":"#fail  tranversion \nimport numpy as np\nimport pandas as pd\nimport keras\nimport keras.backend as kb\nimport tensorflow as tf\n\nmodel = keras.Sequential([\n    keras.layers.Dense(32, activation=tf.nn.relu, input_shape=(X.shape[-1],)),\n    keras.layers.Dense(32, activation=tf.nn.relu),\n    keras.layers.Dense(32, activation=tf.nn.relu),\n    keras.layers.Dense(2)\n  ])\n\noptimizer = tf.keras.optimizers.RMSprop(0.0099)\n#optimizer = tf.keras.optimizers.RMSprop(0.9)\nmodel.compile(loss='mean_squared_error',optimizer=optimizer)\n#model.summary()\nX_train= np.asarray(X_train).astype('float32')\nY_train= np.asarray(Y_train).astype('float32')\nmodel.fit(X_train,Y_train,epochs=100)\n#model.evaluate(X_test, Y_test, verbose=20)","d2be00a0":"X_train= np.asarray(X_train).astype('float32')\nY_train= np.asarray(Y_train).astype('float32')\nmodel = Sequential()\nmodel.add(Dense(32, input_shape=(X_train.shape[1],), activation=\"relu\"))\nmodel.add(Dense(32, activation=\"relu\"))\nmodel.add(Dense(3))\nmodel.compile(loss=\"mse\", optimizer=\"adam\",\nmetrics=[\"mae\"])\nmodel.fit(X_train, Y_train, epochs=80, batch_size=16, verbose=0)","de3c7477":"X_test= np.asarray(X_test).astype('float32')\nY_test= np.asarray(Y_test).astype('float32')\naccuracy =model.evaluate(X_test, X_test, verbose=2)","17190158":"X_test= np.asarray(X_test).astype('float32')\nY_test= np.asarray(Y_test).astype('float32')\nY_pred = model.predict(X_test, batch_size=10, verbose=0)\nprint(Y_pred) \n","7d6835b6":"### options\nWe can change the way it learns with these options. <br>\nEspecialy **NUM_FEATS** is one of the most important options. <br>\nIt determines how many features are used in the training. <br>\nWe have 100 Wi-Fi features in the dataset, but 100th Wi-Fi signal sounds not important, right? <br>\nSo we can use top Wi-Fi signals if we think we need to. ","deb3c883":"## Overview\n\nIt demonstrats how to utilize [the unified Wi-Fi dataset](https:\/\/www.kaggle.com\/kokitanisaka\/indoorunifiedwifids).<br>\nThe Neural Net model is not optimized, there's much space to improve the score. \n\nIn this notebook, I refer these two excellent notebooks.\n* [wifi features with lightgbm\/KFold](https:\/\/www.kaggle.com\/hiro5299834\/wifi-features-with-lightgbm-kfold) by [@hiro5299834](https:\/\/www.kaggle.com\/hiro5299834\/)<br>\n I took some code fragments from his notebook.\n* [Simple \ud83d\udc4c 99% Accurate Floor Model \ud83d\udcaf](https:\/\/www.kaggle.com\/nigelhenry\/simple-99-accurate-floor-model) by [@nigelhenry](https:\/\/www.kaggle.com\/nigelhenry\/)<br>\n I use his excellent work, the \"floor\" prediction.\n\nIt takes much much time to finish learning. <br>\nAnd even though I enable the GPU, it doesn't help. <br>\nIf anybody knows how to make it better, can you please make a comment? <br>\n\nThank you!"}}