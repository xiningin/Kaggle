{"cell_type":{"2d8c6523":"code","ddec06cd":"code","d8fa12a0":"code","6e472a5f":"code","ab0a51f5":"code","ffba7b71":"code","4a3bf732":"code","41bf8d13":"code","28c2bcbc":"code","aed023bb":"code","7fbc57c5":"code","95b0b44d":"code","5779e686":"code","8bc5020b":"code","48e33f65":"code","38b2aec3":"code","3bab8e1a":"code","ad1e13a2":"code","f70010e1":"code","7a1a7d31":"markdown","06e8deff":"markdown","22856769":"markdown","730f487e":"markdown"},"source":{"2d8c6523":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ddec06cd":"train_df = pd.read_csv('\/kaggle\/input\/random-linear-regression\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/random-linear-regression\/test.csv')","d8fa12a0":"train_df.head(10)","6e472a5f":"print(f'There dataset has {train_df.shape[0]} rows and {train_df.shape[1]} columns')","ab0a51f5":"train_df.describe()","ffba7b71":"train_df.corr().round(3)","4a3bf732":"sns.lmplot(x= 'x', y= 'y', data= train_df)","41bf8d13":"ax = sns.boxplot(data= train_df, orient= 'h')\nax.figure.set_size_inches(20, 6)\n# variant item found","28c2bcbc":"train_df[train_df['x']>3500]","aed023bb":"train_df.dropna(inplace = True)\n\n\ntrain_df.shape[0]\n## The variant is an outline and it is increasing the value of some calculations. That\u00b4s why needs to the dropped","7fbc57c5":"ax = sns.distplot(train_df['x'])\nax.figure.set_size_inches(20, 6)","95b0b44d":"X_train = train_df[['x']]\nX_test = test_df[['x']]\ny_train = train_df[['y']]\ny_test = test_df[['y']]","5779e686":"model = LinearRegression()","8bc5020b":"model.fit(X_train, y_train)","48e33f65":"print('R\u00b2 = {}'.format(model.score(X_train, y_train).round(3)))\n# The coefficient of determination has an accepitable value","38b2aec3":"y_prediction = model.predict(X_test)","3bab8e1a":"print('R\u00b2 = %s' % metrics.r2_score(y_test, y_prediction).round(3))","ad1e13a2":"plt.scatter(X_train, y_train)\nplt.plot(X_train, model.predict(X_train), c='purple')\nplt.title(\"Training set\")","f70010e1":"plt.scatter(X_test, y_test)\nplt.plot(X_test, model.predict(X_test), c='green')\nplt.title(\"Testing set\")\n","7a1a7d31":"# Creating Training Environment","06e8deff":"# Analyzing the degree of efficiency to the model","22856769":"# Preliminery Analysis","730f487e":"# Frequent Distribution"}}