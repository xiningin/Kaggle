{"cell_type":{"0f58b967":"code","2a8830d7":"code","7be2921e":"code","2d213406":"code","b54f65d7":"code","ef637706":"code","1c7b4e1b":"code","7393439e":"code","0d6b2b3c":"code","ef1d70bf":"code","bc6aa57f":"code","8fe95b75":"code","49283191":"code","5192530b":"code","c648248f":"code","eda6dad8":"code","91c4de8e":"code","f9f373fb":"code","627ab324":"code","d900228f":"code","d943a42d":"code","f0351a47":"code","ff2fe4c6":"code","fd5bb5c8":"code","259ae7d0":"code","0ebb2154":"markdown","d7846099":"markdown","0b56b3a6":"markdown","cfdc85e7":"markdown","bd5f5e85":"markdown","197360ae":"markdown","26f2558b":"markdown"},"source":{"0f58b967":"#Importing necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport scipy\nimport sklearn\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nimport seaborn as sns","2a8830d7":"#Loading in the data\ndf = pd.read_csv(\"..\/input\/Iris.csv\")","7be2921e":"df.shape","2d213406":"df.info()","b54f65d7":"df.Species.unique()","ef637706":"df.isnull().sum()","1c7b4e1b":"df.groupby('Species').count()","7393439e":"df.where(df['Species']==\"Iris-setosa\").head()","0d6b2b3c":"df[df['SepalLengthCm']>7]","ef1d70bf":"#Relationships btwn two quantitative variables\nsns.FacetGrid(df, hue=\"Species\", size=7) \\\n.map(plt.scatter, \"SepalLengthCm\", \"PetalLengthCm\") \\\n.add_legend()\nplt.show()","bc6aa57f":"sns.FacetGrid(df, hue=\"Species\", size=7) \\\n.map(plt.scatter, \"SepalLengthCm\", \"SepalWidthCm\") \\\n.add_legend()\nplt.show()","8fe95b75":"df.plot(kind='box',subplots='True',layout=(2,3),figsize=(7,7))","49283191":"sns.boxplot(x='Species',y='PetalLengthCm',data=df)\nplt.show()","5192530b":"#Insert jitter=True so that the data points remain scattered and not piled into a verticle line.\n#Assign ax to each axis, so that each plot is ontop of the previous axis. \nax = sns.boxplot(x='Species',y='PetalLengthCm',data=df)\nax = sns.stripplot(x='Species',y='PetalLengthCm',data = df, jitter=True)\nplt.show()","c648248f":"#Make the scatter points more visible\nax = sns.boxplot(x='Species',y='PetalLengthCm',data=df)\nax = sns.stripplot(x='Species',y='PetalLengthCm',data = df, jitter=True)\nboxtwo = ax.artists[2]\nboxtwo.set_facecolor('pink')\nboxthree = ax.artists[1]\nboxthree.set_facecolor('red')\nax.artists[0].set_facecolor('green')\nplt.show()","eda6dad8":"df.hist(figsize=(20,20))","91c4de8e":"#Multivariate Plot\npd.plotting.scatter_matrix(df,figsize=(10,10))\nplt.figure()","f9f373fb":"sns.violinplot(data=df,x=\"Species\",y=\"PetalLengthCm\")\n","627ab324":"#Using seaborn's pairplot to look at bivariate relations between each pair of variables\nsns.pairplot(data=df, hue=\"Species\")","d900228f":"#Correlation Heatmap\nplt.figure(figsize=(10,10))\nsns.heatmap(df.corr(),annot=True)\n","d943a42d":"#Multivariate data visualization using RadViz from pandas\n#Based on a spring tension minimization algorithm \nfrom pandas.plotting import radviz\nplt.figure(figsize=(7,7))\nradviz(df.drop(\"Id\",axis=1),\"Species\")\n","f0351a47":"# Seperating the data into dependent and independent variables\nX = df.iloc[:, :-1].values # All rows and all columns except the last ## Feature variables\ny = df.iloc[:, -1].values # Only the last column ## Target variable\n# Splitting the data into training and test data\nfrom sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)","ff2fe4c6":"from sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier(n_neighbors=8)\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))\nprint(\"accuracy is\",accuracy_score(y_test,y_pred))","fd5bb5c8":"from sklearn.neighbors import RadiusNeighborsClassifier\nmodel = RadiusNeighborsClassifier(radius=8)\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\nprint(classification_report(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))\nprint(\"accuracy is\",accuracy_score(y_test,y_pred))","259ae7d0":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint('accuracy is',accuracy_score(y_pred,y_test))","0ebb2154":"**Visualisations**","d7846099":" **Data Preprocessing**\n","0b56b3a6":"**Exploring the data**","cfdc85e7":"**Logistic regression**\n\nMost appropriate when outcome is binary.\n","bd5f5e85":"**Radius Neighbors Classifier**","197360ae":"**Violin Plots**\n![violin-plot-01.png](attachment:violin-plot-01.png)","26f2558b":" Precision - True Positive results\/All positive results\n\nRecall - True Positive results\/ All correct positive results\n \n F1 score = 2*((precision*recall)\/(precision+recall)) \n** 0<F1 score <1**\n\n**K - Nearest Neighbours**\n"}}