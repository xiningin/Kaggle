{"cell_type":{"116a3c3a":"code","15f516b4":"code","01ebea3d":"code","917af62a":"code","09e1ea7b":"code","12450d1e":"code","96707cf6":"code","58373a58":"code","67a39823":"code","de09c8b4":"code","e589d3ec":"code","cb98de3a":"code","21f967cc":"code","a4529291":"code","bdd1de90":"code","f96f1e2d":"code","f688e406":"code","ee3ce488":"code","7e3ad68d":"code","cc8b7a38":"code","a6623aa9":"code","1522c13c":"code","e9821618":"markdown","8fd28e46":"markdown"},"source":{"116a3c3a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pathlib\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport os\nimport PIL\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n         (os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","15f516b4":"path_to_train = pathlib.Path(\"..\/input\/dogs-cats-images\/dataset\/training_set\")\n","01ebea3d":"image_count_train = len(list(path_to_train.glob('*\/*.jpg')))\nprint(image_count_train)","917af62a":"batch_size = 32\nimg_height = 180\nimg_width = 180\nimage_size = (180, 180)","09e1ea7b":"def ds_gen(image_size, batch_size , type_ds):\n    return tf.keras.preprocessing.image_dataset_from_directory(\n    path_to_train,\n    labels='inferred',\n    color_mode='rgb',\n   \n    validation_split=0.2,\n    subset= type_ds,\n    seed=123,\n    interpolation='bilinear',\n    image_size=image_size,\n    batch_size=batch_size,\n)\n    ","12450d1e":"\ntrain_ds = ds_gen(image_size ,batch_size , \"training\")","96707cf6":"val_ds =  ds_gen(image_size ,batch_size , \"validation\")","58373a58":"class_names = train_ds.class_names\nprint(class_names)","67a39823":"import matplotlib.pyplot as plt\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[int(labels[i])])\n        plt.axis(\"off\")","de09c8b4":"AUTOTUNE = tf.data.experimental.AUTOTUNE\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","e589d3ec":"data_augmentation = keras.Sequential(\n  [\n    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n                                                 input_shape=(img_height, \n                                                              img_width,\n                                                              3)),\n    layers.experimental.preprocessing.RandomRotation(0.1),\n    layers.experimental.preprocessing.RandomZoom(0.1),\n  ]\n)","cb98de3a":"plt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n  for i in range(9):\n    augmented_images = data_augmentation(images)\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n    plt.axis(\"off\")","21f967cc":"def model_gen(num_classes,dense,drop):\n    return  Sequential([\n  data_augmentation,\n  layers.experimental.preprocessing.Rescaling(1.\/255),\n  layers.Conv2D(8, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n\n\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n \n  # layers.Dropout(0.2),\n  layers.Conv2D(256, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(drop),\n  layers.Flatten(),\n  layers.Dense(dense, activation='relu'),\n  layers.Dense(num_classes)\n])","a4529291":"model = model_gen(2 , 512 , 0.2 )","bdd1de90":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(\n    from_logits=True, reduction=\"auto\", name=\"sparse_categorical_crossentropy\"),\n              metrics=['accuracy'])","f96f1e2d":"model.summary()","f688e406":"history = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=25\n)","ee3ce488":"def predicting(image_val):\n      img = keras.preprocessing.image.load_img(\n          image_val, target_size=(180, 180)\n      )\n      img_array = keras.preprocessing.image.img_to_array(img)\n      img_array = tf.expand_dims(img_array, 0) # Create a batch\n\n      predictions = model.predict(img_array)\n      score = tf.nn.softmax(predictions[0])\n\n      return(\n          \" :  {}  {:.2f} % confidence.\"\n          .format(class_names[np.argmax(score)], 100 * np.max(score))\n      )","7e3ad68d":"from glob import glob\ndogs = pathlib.Path(\"..\/input\/dogs-cats-images\/dataset\/test_set\/dogs\")\ntest_path = pathlib.Path(\"..\/input\/dogs-cats-images\/dataset\/test_set\/\")\npath_list = [x for x in glob(os.path.join(test_path, '*','', '*.jpg'))]\n","cc8b7a38":"count = 0\nfor  p in path_list:\n  count= count +1\n  predictions= predicting(p);\n  p=p.replace(str(dogs) +\"\/\", \"\");\n  p=p.split(\"\/\")[0];\n \n  print(p + predictions);\n  if count ==10:\n    break","a6623aa9":"cats = pathlib.Path(\"..\/input\/dogs-cats-images\/dataset\/test_set\/\")","1522c13c":"count = 0\nfor  p in path_list:\n  predictions= predicting(p);\n  \n  \n  p=p.replace(str(cats) +\"\/\", \"\");\n  p = p.split(\"\/\")[0];\n  if (p==\"cats\"):\n   count = count+1;\n   print(p + predictions )\n   if(count == 20):\n    break\n  ","e9821618":"## Making Prediction on the Test data (top 10 values)","8fd28e46":"### Predicting top 20 cat results "}}