{"cell_type":{"42ec23f5":"code","3bba79cf":"code","67515664":"code","3ee1fe6a":"code","fe40264d":"code","408c9184":"code","80080bf0":"code","e0c96a2c":"code","6f32bf7b":"code","9dc7fcc3":"code","1f3e4c8a":"code","c309508d":"code","7893dee9":"code","36095f86":"code","66be849f":"code","7f3021d3":"code","02d8e71d":"code","44bae4c4":"code","4b6d5dae":"code","f43eb193":"code","19bcb584":"code","456a8e7b":"markdown","02598e88":"markdown","2d269204":"markdown","d8a0bcd2":"markdown","97615f45":"markdown","be76b15c":"markdown","a34cc3b8":"markdown","951a2941":"markdown","ea6d346e":"markdown","a0aab99b":"markdown","07058a6e":"markdown","4918532e":"markdown"},"source":{"42ec23f5":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec \nimport seaborn as sns\nfrom PIL import ImageDraw\nfrom matplotlib import animation, rc\nrc('animation', html='jshtml')\n\nimport ast","3bba79cf":"train = pd.read_csv('..\/input\/tensorflow-great-barrier-reef\/train.csv')\ntest = pd.read_csv('..\/input\/tensorflow-great-barrier-reef\/test.csv')\nsample = pd.read_csv('..\/input\/tensorflow-great-barrier-reef\/example_sample_submission.csv')","67515664":"train.head()","3ee1fe6a":"train.tail()","fe40264d":"train.info()","408c9184":"train.duplicated().sum()","80080bf0":"train['video_id'].nunique()","e0c96a2c":"sns.set_theme(style=\"whitegrid\")\nax = sns.countplot(x='video_id', data=train)","6f32bf7b":"for i in range(3):\n    print(\"Video \" + str(i))\n    print(\"Frames with Annotations : \" + str((train[train['video_id'] != i]['annotations'] != '[]').sum()) )\n    print(\"Frames without Annotations : \" + str((train[train['video_id'] == i]['annotations'] != '[]').sum()) )\n    print(\"---------\")","9dc7fcc3":"train.iloc[16].annotations\n# Note the below result is string. We need to convert it to list","1f3e4c8a":"# Convert String to List Type\ntrain['annotations'] = train['annotations'].apply(ast.literal_eval)","c309508d":"train['num_bboxes'] = train['annotations'].apply(lambda x: len(x))","7893dee9":"print('Total rows without annotations : {}'.format(train[train['num_bboxes'] == 0]['num_bboxes'].count()))","36095f86":"plt.figure(figsize = (15,8))\nsns.countplot(x=train[train['num_bboxes'] > 0].num_bboxes,data=train)","66be849f":"train[train['annotations'].str.len() > 2]","7f3021d3":"from os import listdir\nfrom PIL import Image\n\ndef validate_images(video_id):\n    path = '\/kaggle\/input\/tensorflow-great-barrier-reef\/train_images\/video_{}\/'.format(video_id)\n    \n    print(\"Verifying that video {} frames are valid...\".format(video_id))\n    for filename in listdir(path):\n        if filename.endswith('.jpg'):\n            try:\n                img = Image.open(path+filename)\n                img.verify() # Verify it is in fact an image\n            except (IOError, SyntaxError) as e:\n                print('Bad file:', filename) # Print out the names of corrupt files\n    print(\"Verified! Video {} has all valid images\".format(video_id))\n\nfor video_id in range(3):\n    validate_images(video_id)","02d8e71d":"def fetch_image(df, video_id, frame_id):\n    # get frame\n    frame = df[(df['video_id'] == video_id) & (df['video_frame'] == frame_id)].iloc[0]\n    # get bounding_boxes\n    bounding_boxes = frame['annotations']\n    # open image\n    img = Image.open('\/kaggle\/input\/tensorflow-great-barrier-reef\/' + f'train_images\/video_{video_id}\/{frame_id}.jpg')\n\n    for box in bounding_boxes:\n        x0, y0, x1, y1 = (box['x'], box['y'], box['x']+box['width'], box['y']+box['height'])\n        draw = ImageDraw.Draw(img)\n        draw.rectangle( (x0, y0, x1, y1), outline=180, width=5)\n    return img\n\ndef fetch_image_list(df, video_id, num_images, start_frame_idx):\n    image_list = [np.array(fetch_image(df, video_id, start_frame_idx + index)) for index in range(num_images)]\n\n    return image_list","44bae4c4":"images = fetch_image_list(train, video_id=0, num_images=80, start_frame_idx=25)\n\nprint(f'Number of images: {len(images)}')","4b6d5dae":"grid = gridspec.GridSpec(4, 2) \nplt.figure(figsize=(18, 20))\n\nidx_list = [0, 5, 10, 15, 20, 25, 30, 35] \n\nfor i, idx in enumerate(idx_list): \n    ax = plt.subplot(grid[i])\n    plt.imshow(images[idx], interpolation='nearest')\n    ax.set_title(f'frame index {idx}')\n    plt.axis('off')","f43eb193":"def create_animation(imgs, frame_interval=130):\n    fig = plt.figure(figsize=(7, 4))\n    plt.axis('off')\n    img = plt.imshow(imgs[0])\n\n    def animate(i):\n        img.set_array(imgs[i])\n        return [img]\n\n    return animation.FuncAnimation(fig, animate, frames=len(imgs), interval=frame_interval)","19bcb584":"frame_interval = 130 # set smaller number if you want to play fast, otherwise set bigger\n\ncreate_animation(images, frame_interval=frame_interval)","456a8e7b":"# Visualize COTS Annimation","02598e88":"# Feature Engineering","2d269204":"# Validate Images","d8a0bcd2":"# References\n* Thanks to DIEGO GOMEZ & BAEK KYUN SHIN\n* https:\/\/www.kaggle.com\/diegoalejogm\/great-barrier-reefs-eda-with-animations\n* https:\/\/www.kaggle.com\/werooring\/basic-eda-starter-for-everyone","97615f45":"### Checking Duplicates","be76b15c":"# Imports","a34cc3b8":"# Load data","951a2941":"### Lets see the distribution of number of COTS per image","ea6d346e":"### Lets create a feature which have info about number of annotations per image","a0aab99b":"### As you can see, we have totally 3 videos in the training dataset. Now lets see row count for each videos","07058a6e":"### Not all the images have Crown-Of-Thorns Starfish (COTS) for which we have annotations as []","4918532e":"# Analyze"}}