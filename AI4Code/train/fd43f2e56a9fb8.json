{"cell_type":{"0e1686ad":"code","f32d115f":"code","75a69c89":"code","5a09ed9c":"code","319871b8":"code","4dafcb88":"code","9770af51":"code","9c49c933":"code","29b537ae":"code","ad53edd8":"code","93b0f177":"code","0e2df75d":"code","729fcaaf":"code","020b51d3":"code","e78ab87c":"code","509f3d4e":"code","c60fbdec":"code","42f9a075":"code","8ca4e2be":"code","4c6652fd":"code","aa2bf9b1":"code","d07b6ec0":"code","3a9f28b2":"code","5af9ac36":"code","c10b2e77":"code","6a428472":"code","03206610":"code","20bd369d":"code","99f63f12":"code","6bab64bd":"code","33cad72d":"code","e234f69d":"code","dc8c8620":"code","d6571bee":"code","625bdac8":"code","da2a5e05":"code","f4e89a8e":"code","4a97639c":"code","840db577":"code","16da3755":"code","78c262ea":"code","04046097":"code","480cb46d":"code","c44f9ff3":"markdown","1661f7eb":"markdown","2a4b8310":"markdown","55e5b74f":"markdown","b6a0e46c":"markdown","1e82ee1c":"markdown","75534485":"markdown","bc838394":"markdown","53d782d7":"markdown","7adb636f":"markdown","4c4cf9e0":"markdown","53260924":"markdown","94fae02b":"markdown","219766ff":"markdown","cd56af54":"markdown","f0ea0084":"markdown","e865199f":"markdown","8eb65fdc":"markdown","a6703233":"markdown","f991bcc0":"markdown","c6176194":"markdown","f487437a":"markdown","aff73d71":"markdown","315d92b3":"markdown","ea66c13d":"markdown","92c9a454":"markdown","85c72db8":"markdown","7ecd7578":"markdown","34f889d4":"markdown","e0dd8ad8":"markdown","af2b8313":"markdown","c8ef18a1":"markdown","fa64f345":"markdown","bedc2f69":"markdown","4cc007f0":"markdown"},"source":{"0e1686ad":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport sklearn\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nmpl.rcParams['figure.figsize']=(20,5)\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nnineties = pd.DataFrame(pd.read_csv('..\/input\/the-spotify-hit-predictor-dataset\/dataset-of-90s.csv')) #Spotify dataset of all songs from the nineties\naughts = pd.DataFrame(pd.read_csv('..\/input\/the-spotify-hit-predictor-dataset\/dataset-of-00s.csv'))  #Spotify dataset of all songs from the 2000's\ntens = pd.DataFrame(pd.read_csv('..\/input\/the-spotify-hit-predictor-dataset\/dataset-of-10s.csv'))  #Spotify dataset of all songs from the 2010's","f32d115f":"nineties['decade'] = 1990\naughts['decade'] = 2000\ntens['decade'] = 2010","75a69c89":"all_dfs = [nineties, aughts, tens]\nall_songs = pd.concat(all_dfs) #combines all the decade dataframes\nprint(all_songs['decade'].unique()) #check that the new dataframe has all the decades","5a09ed9c":"all_songs.to_csv('all_songs.csv', index = False) #create a CSV file of the new dataframe\nall_songs.head(3)","319871b8":"pd.isnull(all_songs).sum()","4dafcb88":"all_songs.columns","9770af51":"#create two var lists, one with Spotify's features (spfeatures_var_list) and one with the song traits (song_traits_var_list)\nspfeatures_var_list = ['danceability', 'energy', 'key', 'loudness','mode', 'speechiness', 'acousticness', \n                       'instrumentalness', 'liveness','valence']\nsong_traits_var_list = ['key', 'loudness','tempo', 'time_signature', 'chorus_hit','sections'] \n#duration_ms has been removed since it has such larger numbers than the other variables","9c49c933":"all_songs.describe() #show the descriptive statistics of the variables of all the songs in all decades","29b537ae":"#going to focus on the spotify features when comparing the hits and flops\nall_songs_hits = all_songs[spfeatures_var_list].loc[all_songs['target'] == 1]\nall_songs_flops = all_songs[spfeatures_var_list].loc[all_songs['target'] == 0]","ad53edd8":"#create a dataframe that includes the means for hits and flops\nhits_means = pd.DataFrame(all_songs_hits.describe().loc['mean'])\nflops_means = pd.DataFrame(all_songs_flops.describe().loc['mean'])\nmeans_joined = pd.concat([hits_means,flops_means], axis = 1)\nmeans_joined.columns = ['hit_mean', 'flop_mean']\n\nmeans_joined","93b0f177":"#going to scale the dataframe to make the graph more readable\nfrom sklearn.preprocessing import StandardScaler\n\nss = StandardScaler()\nmeans_joined_scaled = pd.DataFrame(ss.fit_transform(means_joined),index= means_joined.index, columns = means_joined.columns)\nmeans_joined_scaled\n\n\nmeans_joined_scaled.plot(kind = 'bar', figsize=(10, 5), color = ('purple', 'grey'), title = 'Means of Hit Songs and Flop Songs for Song Features')\nplt.legend(labels=['Hits', 'Flops'], loc='upper right')\nplt.show()\nplt.show()","0e2df75d":"#create histograpms of all the variables to see distributions\nfig, ax = plt.subplots(5,3, figsize=(20,20))\n\ndef hist_plot(row, column, variable, binsnum, color):\n    ax[row, column].hist(all_songs[variable], bins = binsnum, color = color)\n    ax[row, column].set_title(variable + ' histogram')\n    \nhist_plot(0, 0, 'danceability', 10, 'purple')\nhist_plot(0, 1, 'energy', 10, 'orchid')\nhist_plot(0, 2, 'key', 10, 'plum')\nhist_plot(1,0, 'loudness', 10, 'purple')\nhist_plot(1,1, 'mode', 10, 'orchid')\nhist_plot(1,2, 'speechiness', 10, 'plum')\nhist_plot(2,0, 'acousticness', 10, 'purple')\nhist_plot(2,1, 'instrumentalness', 10, 'orchid')\nhist_plot(2,2, 'liveness', 10, 'plum')\nhist_plot(3,0, 'valence', 10, 'purple')\nhist_plot(3,1, 'tempo', 10, 'orchid')\nhist_plot(3,2, 'duration_ms', 50, 'plum')\nhist_plot(4,0, 'time_signature', 10, 'purple')\nhist_plot(4,1, 'chorus_hit', 10, 'orchid')\nhist_plot(4,2, 'sections', 50, 'plum')\n\nplt.show()","729fcaaf":"#to create more readable graphs, I created two boxplots, one with the first 10 song features\nmpl.rcParams['figure.figsize']=(20,5)\nall_songs[all_songs['target']==1].iloc[:, 0:13].plot(kind='box', title = 'Hits')\nplt.show()\nall_songs[all_songs['target']==0].iloc[:, 0:13].plot(kind='box', title = 'Flops')\nplt.show()","020b51d3":"#...and one with the last 5 song features\nall_songs[all_songs['target']==1].iloc[:, 13:18].plot(kind='box', title = 'Hits')\nplt.show()\nall_songs[all_songs['target']==0].iloc[:, 13:18].plot(kind='box', title = 'Flops')\nplt.show()","e78ab87c":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import scale\n\nindep_columns = ['danceability', 'energy', 'key', 'loudness',\n       'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n       'valence', 'tempo', 'duration_ms', 'time_signature', 'chorus_hit',\n       'sections']\n\nX = all_songs[indep_columns]\ny = all_songs['target']\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0) #use 75% of the data for training the model and 25% of the model for testing\nRF = RandomForestClassifier()\nRF.fit(X_train, y_train)\ny_pred = RF.predict(X_test)","509f3d4e":"#create a confusion matrix to see the efficacy of the model\nfrom sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\ncnf_matrix","c60fbdec":"#create a figure\/heatmap of the confusion matrix for a better visual\nmpl.rcParams['figure.figsize']=(10,5)\nclass_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"RdPu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","42f9a075":"#create a dataframe of the feature importances to determine which variables are the most important in determining a hit\nall_songs_feat = RF.feature_importances_\ndf_indep_columns = pd.DataFrame(indep_columns)\ndf_all_songs_feat = pd.DataFrame(all_songs_feat)\nall_songs_feat_vars = pd.concat([df_indep_columns, df_all_songs_feat], axis = 1)\nall_songs_feat_vars.columns = ['Variable', 'Feature importance all decades']\nall_songs_feat_vars = all_songs_feat_vars.set_index('Variable')\nall_songs_feat_vars = all_songs_feat_vars.sort_values(by=['Feature importance all decades'], ascending = False)\nall_songs_feat_vars\nall_songs_feat_vars.to_csv('all_songs_feat.csv', index = False) #create a CSV file of the new dataframe","8ca4e2be":"all_songs_feat_vars","4c6652fd":"all_songs_feat_vars.plot(kind='bar', color = \"purple\", title = \"Most important features for predicting hit and flop songs for all decades\", legend = None)\nplt.ylabel('Feature importance')\nplt.show()","aa2bf9b1":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","d07b6ec0":"X = nineties[indep_columns]\ny = nineties['target']\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\nRF = RandomForestClassifier()\nRF.fit(X_train, y_train)\ny_pred = RF.predict(X_test)\n\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\ncnf_matrix","3a9f28b2":"class_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"RdPu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","5af9ac36":"nineties_feat = RF.feature_importances_\ndf_indep_columns = pd.DataFrame(indep_columns)\ndf_nineties_feat = pd.DataFrame(nineties_feat)\nnineties_feat_vars = pd.concat([df_indep_columns, df_nineties_feat], axis = 1)\nnineties_feat_vars.columns = ['Variable', 'Feature importance 1990s']\nnineties_feat_vars = nineties_feat_vars.set_index('Variable')\nnineties_feat_vars = nineties_feat_vars.sort_values(by=['Feature importance 1990s'], ascending = False)\nnineties_feat_vars\nnineties_feat_vars.to_csv('nineties_feat_vars.csv', index = False) #create a CSV file of the new dataframe","c10b2e77":"nineties_feat_vars","6a428472":"nineties_feat_vars.plot(kind='bar', color = \"purple\", title = \"Most important features for predicting hit and flop songs for the nineties\", legend = None)\nplt.ylabel('Feature importance')\nplt.show()","03206610":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","20bd369d":"X = aughts[indep_columns]\ny = aughts['target']\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\nRF = RandomForestClassifier()\nRF.fit(X_train, y_train)\ny_pred = RF.predict(X_test)\n\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\ncnf_matrix","99f63f12":"class_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"RdPu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","6bab64bd":"aughts_feat = RF.feature_importances_\ndf_indep_columns = pd.DataFrame(indep_columns)\ndf_aughts_feat = pd.DataFrame(aughts_feat)\naughts_feat_vars = pd.concat([df_indep_columns, df_aughts_feat], axis = 1)\naughts_feat_vars.columns = ['Variable', 'Feature importance 2000s']\naughts_feat_vars = aughts_feat_vars.set_index('Variable')\naughts_feat_vars = aughts_feat_vars.sort_values(by=['Feature importance 2000s'], ascending = False)\naughts_feat_vars\naughts_feat_vars.to_csv('aughts_feat_vars.csv', index = False) #create a CSV file of the new dataframe","33cad72d":"aughts_feat_vars","e234f69d":"aughts_feat_vars.plot(kind='bar', color = \"purple\", title = \"Most important features for predicting hit and flop songs for the 2000's\", legend = None)\nplt.savefig('aughts_feature_importance_bar.jpg')\nplt.ylabel('Feature importance')\nplt.show()","dc8c8620":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","d6571bee":"X = tens[indep_columns]\ny = tens['target']\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\nRF = RandomForestClassifier()\nRF.fit(X_train, y_train)\ny_pred = RF.predict(X_test)\n\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\ncnf_matrix","625bdac8":"RF.feature_importances_ #corresponds to the order of the variables","da2a5e05":"class_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"RdPu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","f4e89a8e":"tens_feat = RF.feature_importances_\ndf_indep_columns = pd.DataFrame(indep_columns)\ndf_tens_feat = pd.DataFrame(tens_feat)\ntens_feat_vars = pd.concat([df_indep_columns, df_tens_feat], axis = 1)\ntens_feat_vars.columns = ['Variable', 'Feature importance 2010s']\ntens_feat_vars = tens_feat_vars.set_index('Variable')\ntens_feat_vars = tens_feat_vars.sort_values(by=['Feature importance 2010s'], ascending = False)\ntens_feat_vars\ntens_feat_vars.to_csv('tens_feat_vars.csv', index = False) #create a CSV file of the new dataframe","4a97639c":"tens_feat_vars","840db577":"tens_feat_vars.plot(kind='bar', color = \"purple\", title = \"Most important features for predicting hit and flop songs for the 2010's\", legend = None)\nplt.ylabel('Feature importance')\nplt.show()\n","16da3755":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","78c262ea":"compare_feats = all_songs_feat_vars + nineties_feat_vars + aughts_feat_vars + tens_feat_vars\ncompare_feats_df = pd.concat([all_songs_feat_vars, nineties_feat_vars, aughts_feat_vars, tens_feat_vars], axis = 1)\ncompare_feats_df\ncompare_feats_df.to_csv('compare_feats_df.csv') #create a CSV file of the new dataframe","04046097":"compare_feats_df","480cb46d":"compare_feats_df.plot(kind='bar', color = ('purple','orchid','plum','thistle' ), figsize = (20,8))\nplt.ylabel(\"Feature importance\")\nplt.show()","c44f9ff3":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\n    Create a combined CSV file of the past three decades.\n<\/p> ","1661f7eb":"<p style=\"font-family: Georgia, serif; font-size:15pt; font-style: bold\">    \n   Inferential Statistics\n<\/p>","2a4b8310":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\n    The model is highly accurate, precise, and has good recall.\n<\/p>","55e5b74f":"<p style=\"font-family: Georgia, serif; font-size:11pt\">    \nSince I didn't scale the dataset, it is a bit hard to see the boxplots of some of the song features. Overall, however, there does appear to be a difference between hit and flop songs. This leads me to the next part of the analysis.   \n<\/p>","b6a0e46c":"<p style=\"font-family: Georgia, serif; font-size:12pt\">    \n   Boxplots\n<\/p>\n<p style=\"font-family: Georgia, serif; font-size:11pt\">    \n   Let's create some boxplots to see the spread of the song features and any differences between hits and flops.\n<\/p>\n","1e82ee1c":"<p style=\"font-family: Georgia, serif; font-size: 15pt; font-style = bold\">\nHas feature importance changed through time?\n<\/p>\n<p style=\"font-family: Georgia, serif; font-size:11pt\">\nFrom our previous models, it's apparent that feature importance has changed through time. Let's graph the results to show that visually.\n<\/p>","75534485":"<p style=\"font-family: Georgia, serif; font-size:20pt; font-style: bold\">\n    What features make a hit song?\n<\/p>\n<p style=\"font-family: Georgia, serif; font-size:15pt\">\n    An analysis of three decades of music using data from Spotify\n<\/p>","bc838394":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\nOnce again, the confusion matrix demonstrates that the model is very good at predicting hits and flops. \n<\/p>","53d782d7":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\nThe confusion matrix demonstrates that the model correctly identified hits and flops most of the time. \n<\/p>","7adb636f":"<p style=\"font-family: Georgia, serif; font-size:12pt; font-style = bold\">\nDecade: The 2010's\n<\/p>\n<p style=\"font-family: Georgia, serif; font-size:11pt\">\nRepeat the model for songs from the 2010's.\n<\/p>","4c4cf9e0":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\nIn the 2000's hit and flop songs were mostly predicted by instrumentalness, danceability, loudness, duration, and acousticness.\n<\/p>","53260924":"<p style=\"font-family: Georgia, serif; font-size:12pt\">\nSpotify\u2019s web API can be used to create a dataset of songs and their features, including the songs popularity.\nUsing data analytics and a dataset from Kaggle, I determined which song features can be used to predict \u201chits\u201d.\nSongs were analyzed from three decades: 1990\u2019s, 2000\u2019s, and 2010\u2019s, to determine which song features create hits and whether these features change over time.\nFor more information about what Spotify's song features are go to this website: https:\/\/developer.spotify.com\/documentation\/web-api\/reference\/#endpoint-get-several-tracks.\n<\/p>","94fae02b":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\n    No nulls, so data looks good.\n<\/p>    \n<p style=\"font-family: Georgia, serif; font-size:11pt\">    \n    Check the columns of the dataframe to determine the names of the variables to be analyzed and create a list of variables.\n<\/p>","219766ff":"<p style=\"font-family: Georgia, serif; font-size:15pt; font-style = bold\">    \nRandom Forest Classifier  \n<\/p>\n<p style=\"font-family: Georgia, serif; font-size:11pt\">    \nCreate model to determine if hit songs can be determined for all three decades combined using a Random Forest Classifier.  \n<\/p>","cd56af54":"<p style=\"font-family: Georgia, serif; font-size:15pt; font-style = bold\">\n   Data Organizing and Cleaning\n<\/p>","f0ea0084":"<p style=\"font-family: Georgia, serif; font-size:11pt\">    \n    Compare the means for Spotify's song features for hit songs and flop songs.\n<\/p>","e865199f":"<p style=\"font-family: Georgia, serif; font-size:15pt; font-style: bold\">    \n    Descriptive Statistics\n<\/p>","8eb65fdc":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\nFor all decades, instrumentalness, danceability, acousticness, duration_ms, and loudness were the greatest predictors of if a song was a hit.\n<\/p>","a6703233":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\nOnce again, the confusion matrix demonstrates that the model is very good at predicting hits and flops. \n<\/p>","f991bcc0":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\nOverall the most important predictors of hit and flop songs are their instrumentalness, danceability, acousticness, duration, energy and loudness. However, there has been some fluctuation of these through the decades with some song features being more important in particular decades.  \n<\/p>","c6176194":"<p style=\"font-family: Georgia, serif; font-size:12pt; font-style = bold\">\nDecade: The 2000's\n<\/p>\n<p style=\"font-family: Georgia, serif; font-size:11pt\">\nRepeat the model for songs from the 2000's.\n<\/p>","f487437a":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\nThe model has high accuracy, precision and recall, indicating it is good at classifying hit and flop songs.\n<\/p>","aff73d71":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\nOnce again, the confusion matrix demonstrates that the model is very good at predicting hits and flops. \n<\/p>","315d92b3":"<p style=\"font-family: Georgia, serif; font-size:11pt\">    \nJudging by the differences in the means between hits and flops, there does appear to be a difference between the two types of songs. This means we could possibly create a model to predict hits and flops based on song features.   \n<\/p>","ea66c13d":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\nHit and flop songs in the 90's were predicted mostly by instrumentalness, duration, danceability, acousticness and energy.\n<\/p>","92c9a454":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\n    Start by importing libraries and CSV files.\n<\/p>","85c72db8":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\nThe model also had high accuracy, precision, and recall for the 90's.\n<\/p>","7ecd7578":"<p style=\"font-family: Georgia, serif; font-size:11pt\">    \nSome interesting patterns here - songs tend to be more danceable than less danceable, songs tend to have more energy than less energy, the key of C is the most popular key, songs tend to be under 10 decibels, most songs are in major scales, most songs contain more music than speech, most songs are not live, most songs are not acoustic, most songs contain music, there's a good mix of happy and sad songs, most songs are about 80-90 beats per minute, and most songs are in 4\/4 time.\n<\/p>","34f889d4":"<p style=\"font-family: Georgia, serif; font-size:12pt\">    \nHistograms\n<\/p>","e0dd8ad8":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\n    Add a column for year into all dfs before combining all the CSV files.\n<\/p>","af2b8313":"<p style=\"font-family: Georgia, serif; font-size:15pt; font-style: bold\">    \nExploratory Data Analysis\n<\/p>\n<p style=\"font-family: Georgia, serif; font-size:11pt\">    \nMore information could be gleaned from histograms and boxplots than just means.\n<\/p>","c8ef18a1":"<p style=\"font-family: Georgia, serif; font-size:12pt; font-style = bold\">\n    Decade: 1990's\n<\/p>\n<p style=\"font-family: Georgia, serif; font-size:11pt\">\n    Let's repeat the model but specifically for songs in the 1990's.\n<\/p>","fa64f345":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\nHit and flop songs of the 2010's were most influenced by instrumentalness, loudness, acousticness, danceability and energy.\n<\/p>","bedc2f69":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\nThe model has high accuracy, precision and recall, indicating it is good at classifying hit and flop songs.\n<\/p>","4cc007f0":"<p style=\"font-family: Georgia, serif; font-size:11pt\">\n    Check for nulls to determine if you need to clean the data.\n<\/p> "}}