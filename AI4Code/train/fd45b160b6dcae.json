{"cell_type":{"bf405693":"code","f294b77d":"code","ddac8cbc":"code","0dcb12e2":"code","5c9e63e4":"code","14f38c3b":"code","a89c4f49":"code","6e818d5b":"code","1b8fc9bc":"code","05e7c6f8":"code","717db376":"code","73e4ef14":"code","df5e6a49":"code","83d56597":"code","096608eb":"markdown","318ce05b":"markdown"},"source":{"bf405693":"import numpy as np #array di python\nimport pandas as pd #data manipulation and analysis di python\nimport numpy.matlib #matrix library\nimport matplotlib.pyplot as plt  #untuk plotting data\nimport seaborn as sns #data visualization untuk matplotlib\n\n# generate random values for cluster initialization\nimport random\nfrom datetime import datetime\n\n\ncompanies_data = pd.read_csv('..\/input\/crunchbasedata\/companies.csv', encoding = 'unicode_escape')\ninvesments_data = pd.read_csv('..\/input\/crunchbasedata\/investments.csv', encoding = 'unicode_escape')","f294b77d":"#fix typo columns name\ncompanies_data.rename(columns = {' funding_total_usd ': 'funding_total_usd'}, inplace = True)\n#copy particular columns into new array\ndata_DF = companies_data[['name','funding_total_usd', 'funding_rounds','first_funding_at']].copy(deep=True)\n\n#drop row with unavailable funding total value\ndata_DF.drop(data_DF[data_DF['funding_total_usd'] == '-'].index,inplace=True)\n#drop row with NaN funding total value\ndata_DF.dropna(axis=0,subset=['funding_total_usd'], inplace=True)\n#remove digit separator in funding total value\ndata_DF['funding_total_usd'] = data_DF['funding_total_usd'].str.replace(\",\",\"\")\n#cast funding total str to int type\ndata_DF['funding_total_usd'] = data_DF['funding_total_usd'].astype('float')\n#sort data by funding total decendingly\ndata_DF.sort_values(by=['funding_total_usd'], ascending=False, inplace=True)\n\ndata_DF.reset_index(drop=True, inplace=True)","ddac8cbc":"def zscore(data):\n    return (data-data.mean())\/data.std()","0dcb12e2":"a = pd.to_datetime(data_DF['first_funding_at'], errors='coerce')\nb = pd.to_datetime(data_DF['first_funding_at'], format='%Y%m%d', errors='coerce')\nc = b.combine_first(a)\n\ndel a,b\n\nfunding_years = 2015 - c.dt.year +1\n\ndel c\n\nraised_per_year = data_DF['funding_total_usd'] \/ funding_years\nrounds_per_year = data_DF['funding_rounds'] \/ funding_years\n\nraised_per_year_Z = zscore(raised_per_year)\n\nrounds_per_year_Z = zscore(rounds_per_year)\n\ncluster_data = pd.concat([raised_per_year_Z, rounds_per_year_Z], axis=1).to_numpy()\n\nstartup_unicorns = [\"Uber\",\"Amazon\",\"Google\",\"Dropbox\",\"Facebook\",\"Alibaba\",\n                     \"Stripe\",\"Airbnb\",\"Robinhood\",\"DigitalOcean\",\"Coursera\"]\n\nunicorn_status = data_DF['name'].isin(startup_unicorns)\n\ncluster_data_DF = pd.concat([data_DF['name'],raised_per_year.rename('raised_per_year'), rounds_per_year.rename('rounds_per_year')\n                             , unicorn_status.rename('unicorn')], axis=1)\n\ndel funding_years, raised_per_year, rounds_per_year\n\n\nprint(cluster_data)","5c9e63e4":"def calc_distance(x1, x2):\n    return (sum((x1 - x2)**2))**0.5","14f38c3b":"def init_cluster(k, cluster_array):\n\n    random.seed(datetime.now())\n    rand_point = random.sample(range(cluster_data.shape[0]), k)\n    \n    init_centr = cluster_array[rand_point]\n    \n    print(\"initial centroid:\", rand_point)\n    \n    init_clusters = assign_clusters(init_centr, cluster_array)\n    return init_clusters","a89c4f49":"def assign_clusters(centroids, cluster_array): \n    #array untuk simpan hasil assign cluster yang baru, yang nantinya jadi output fungsi\n    clusters = []\n    \n    #nested loop untuk ngehitung jarak dari setiap point(loop luar) dengan setiap setiap centroid(loop dalam) \n    for i in range(cluster_array.shape[0]):\n        #array untuk simpan nilai jarak suatu point terhadap setiap centroid\n        distances = []\n        for centroid in centroids:\n            \n            #panggil function untuk menghitung jarak, simpan jarak ke dalam array\n            distances.append(calc_distance(centroid, cluster_array[i]))\n            \n        cluster = np.argmin(distances, axis=0)\n        clusters.append(cluster)\n    \n    return clusters","6e818d5b":"def calc_centroids(clusters, cluster_array):\n    new_centroids = []\n    cluster_df = pd.concat([pd.DataFrame(cluster_array),pd.DataFrame(clusters, columns=['cluster'])],axis=1)\n    for c in set(cluster_df['cluster']):\n        current_cluster = cluster_df[cluster_df['cluster']\\\n                                     ==c][cluster_df.columns[:-1]]\n        cluster_mean = current_cluster.mean(axis=0)\n        new_centroids.append(cluster_mean)\n    return new_centroids","1b8fc9bc":"def calc_centroid_variance(clusters, cluster_array):\n    sum_squares = []\n    cluster_df = pd.concat([pd.DataFrame(cluster_array),\n                            pd.DataFrame(clusters, \n                                         columns=['cluster'])], \n                           axis=1)\n    for c in set(cluster_df['cluster']):\n        current_cluster = cluster_df[cluster_df['cluster']\\\n                                     ==c][cluster_df.columns[:-1]]\n        cluster_mean = current_cluster.mean(axis=0)\n        mean_repmat = np.matlib.repmat(cluster_mean, \n                                       current_cluster.shape[0],1)\n        sum_squares.append(np.sum(np.sum((current_cluster - mean_repmat)**2)))\n    return sum_squares","05e7c6f8":"def classify(centroids, testing_data):\n\n    #array untuk simpan nilai jarak suatu point terhadap setiap centroid\n    distances = []\n    for centroid in centroids:\n        #panggil function untuk menghitung jarak, simpan jarak ke dalam array\n        distances.append(calc_distance(centroid, testing_data))\n        \n    print('distances: ', distances)\n    closest_centr = np.argmin(distances, axis=0)\n    \n    return closest_centr","717db376":"#k = number of cluster(s)\nk = 6\ncluster_vars = []\n\nrandom.seed(datetime.now())\nvalue = random.sample(range(cluster_data.shape[0]), k)\n\ninitial_clusters = init_cluster(k, cluster_data)\nclusters = initial_clusters\n\ncluster_data_DF['cluster_label'] = clusters\n\ncluster_vars.append(np.mean(calc_centroid_variance(clusters, cluster_data)))\nprint(0, cluster_vars[0])\n","73e4ef14":"for i in range(20):\n    centroids = calc_centroids(clusters, cluster_data)\n    clusters = assign_clusters(centroids, cluster_data)\n    cluster_var = np.mean(calc_centroid_variance(clusters, \n                                                 cluster_data))\n    cluster_vars.append(cluster_var)\n    print(i+1, cluster_var)","df5e6a49":"sns.set_style(\"whitegrid\")\n\n\nLABEL_COLOR_MAP = {0 : 'r',\n                   1 : 'g',\n                   2 : 'b',\n                   3 : 'y',\n                   4 : 'm',\n                   5 : 'c',\n                   6 : 'k'\n                   }\n\n\ninit_label_color = [LABEL_COLOR_MAP[l] for l in initial_clusters]\n\nplt.figure(figsize=(20, 10))\nplt.scatter(cluster_data_DF['raised_per_year'], cluster_data_DF['rounds_per_year'], c=init_label_color)\nplt.title('Scatter plot initial cluster')\nplt.xlabel('Amount of money raised per year')\nplt.ylabel('Number of rounds per year')\nplt.show()\n\nlabel_color = [LABEL_COLOR_MAP[l] for l in clusters]\n\nplt.figure(figsize=(20, 10))\nplt.scatter(cluster_data_DF['raised_per_year'], cluster_data_DF['rounds_per_year'], c=label_color)\nplt.title('Scatter plot converged cluster')\nplt.xlabel('Amount of money raised per year')\nplt.ylabel('Number of rounds per year')\nplt.show()","83d56597":"#Testing data\nfirst_funding_year= 2010\ntotal_funding=10000000\nfunding_rounds=3\n\nfunding_years = 2015 - first_funding_year +1\nfunding_per_year = total_funding \/ funding_years\nrounds_per_year = funding_rounds \/ funding_years\n\ntesting_data = np.array([funding_per_year, rounds_per_year])\n\nprint(\"years of funding: \", funding_years)\nprint(\"testing data: \", testing_data)\n\nprint('\\n')\n\ntesting_data_label = classify(centroids, testing_data)\nprint(\"testing data cluster: \", testing_data_label)\n\nprint('\\n')\n\ncluster_unicorn = cluster_data_DF[(cluster_data_DF['cluster_label'] == testing_data_label) & (cluster_data_DF['unicorn'] == True)]\nprint('unicorn in cluster', testing_data_label, ':')\nprint(cluster_unicorn)","096608eb":"**Import Package and Datasets**","318ce05b":"**Pre-processing**"}}