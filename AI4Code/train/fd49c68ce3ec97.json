{"cell_type":{"3cc04b61":"code","26eefb8a":"code","81efc226":"code","6e615f0c":"code","ab394c59":"code","f559c7b4":"code","48086377":"code","95aa505c":"code","039c7b32":"code","e68d82f5":"code","e2f3d0fb":"code","36928248":"code","58b06315":"code","fa019c0a":"code","5d899d88":"code","ff6fa5aa":"code","90d6b9b5":"markdown","9eb495f2":"markdown","05d67a67":"markdown","6dfdce50":"markdown","685e5a61":"markdown","f5d8c9a3":"markdown","e6692077":"markdown","57219d86":"markdown","81f14776":"markdown","0b801bcb":"markdown"},"source":{"3cc04b61":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","26eefb8a":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import Input,Model\nfrom tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint","81efc226":"train_datagen=ImageDataGenerator(rescale=1.\/255,\n                                shear_range=0.2,\n                                zoom_range=0.2,\n                                width_shift_range=0.2,\n                                height_shift_range=0.2,\n                                fill_mode='nearest')\n\nvalid_gen=ImageDataGenerator(rescale=1.\/255)\n\nbatch_size=32\nbase_dir=\"..\/input\/new-plant-diseases-dataset\/new plant diseases dataset(augmented)\/New Plant Diseases Dataset(Augmented)\"\n\ntraining_set=train_datagen.flow_from_directory(base_dir+'\/train',\n                                              target_size=(224,224),\n                                              batch_size=batch_size,\n                                              class_mode='categorical')\n\nvalid_set=valid_gen.flow_from_directory(base_dir+'\/valid',\n                                       target_size=(224,224),\n                                       batch_size=batch_size,\n                                       class_mode='categorical')","6e615f0c":"train_num=training_set.samples\nvalid_num=valid_set.samples","ab394c59":"base_model=tf.keras.applications.VGG16(include_top=False,\n                                      weights='imagenet',\n                                      input_shape=(224,224,3))\nbase_model.summary()","f559c7b4":"base_model.trainable=False","48086377":"base_model.summary()","95aa505c":"inputs=Input(shape=(224,224,3))\nx=base_model(inputs,training=False)\nx=GlobalAveragePooling2D()(x)\nx=Dense(512,activation='relu')(x)\nx=Dropout(0.2)(x)\nx=Dense(512,activation='relu')(x)\nx=Dropout(0.2)(x)\noutputs=Dense(38,activation='softmax')(x)\n\n\nvgg_model=Model(inputs,outputs)\n\nvgg_model.summary()","039c7b32":"\nvgg_model.compile(optimizer=tf.keras.optimizers.Adam(),\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])","e68d82f5":"len(vgg_model.trainable_variables)","e2f3d0fb":"vgg_model.evaluate(valid_set)","36928248":"weightpath='best_weights_9.hdf5'\ncheckpoint = ModelCheckpoint(weightpath, monitor='val_acc', verbose=1, \n                             save_best_only=True, save_weights_only=True, mode='max')\n\nhistory=vgg_model.fit_generator(training_set,\n                        steps_per_epoch=150,\n                        epochs=15,\n                        validation_data=valid_set,\n                        validation_steps=100,\n                        callbacks=[checkpoint])","58b06315":"history=vgg_model.fit_generator(training_set,\n                        steps_per_epoch=150,\n                        epochs=15,\n                        validation_data=valid_set,\n                        validation_steps=100,\n                        callbacks=[checkpoint])","fa019c0a":"history=vgg_model.fit_generator(training_set,\n                        steps_per_epoch=150,\n                        epochs=15,\n                        validation_data=valid_set,\n                        validation_steps=100,\n                        callbacks=[checkpoint])","5d899d88":"base_model.trainable=True #Un-Freezing the base model\nvgg_model.summary()","ff6fa5aa":"vgg_model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n                 loss='categorical_crossentropy',\n                 metrics=['accuracy'])\n\nfine_tune_history=vgg_model.fit_generator(training_set,\n                                        steps_per_epoch=150,\n                                        validation_data=valid_set,\n                                        epochs=10,\n                                        validation_steps=100)","90d6b9b5":"# Transfer Learning with VGG","9eb495f2":"Download VGG-16 model without Dense layers","05d67a67":"# Train the model","6dfdce50":"Import required modules","685e5a61":"Freeze the convolutional base created and use its as a feature extractor (by base_model.trainable=False) prevent the weights in a given layer from being updated during training","f5d8c9a3":"In the feature extraction experiment, you were only training a few layers on top of an VGG-16 base model. The weights of the pre-trained network were not updated during training.\n\nOne way to increase performance even further is to train (or \"fine-tune\") the weights of the top layers of the pre-trained model alongside the training of the classifier you added. The training process will force the weights to be tuned from generic feature maps to features associated specifically with the dataset.\n\n The goal of fine-tuning is to adapt these specialized features to work with the new dataset, rather than overwrite the generic learning.","e6692077":"Compile the model before training it. Since there are two classes, use a categorical cross-entropy loss & Adam optimizer","57219d86":"# Input Data and Data Argumentation ","81f14776":"# Fine Tuning","0b801bcb":"Build a model by channing the base_model layer and Dense layers"}}