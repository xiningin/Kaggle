{"cell_type":{"92fced73":"code","65dff5cb":"code","94daabae":"code","94160af0":"code","099582ca":"code","72d7785f":"code","1efd2db3":"code","4f1b8d4b":"code","1a1c95de":"code","818eb403":"code","7f296621":"code","1f0f9af8":"code","524a36a9":"code","daad3fcc":"code","88bf6085":"code","ada8c6fa":"markdown","dcd5f8b8":"markdown","a57270da":"markdown","52465c13":"markdown","c1e55071":"markdown","125809f3":"markdown"},"source":{"92fced73":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","65dff5cb":"# DATASET PATHS:\n## {O:'NORMAL', 1:'PNEUMONIA'} Mapping used in naming variable\n\nBASE_PATH = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/'\n\nTRAIN_PATH = BASE_PATH + 'train\/'\nTEST_PATH  = BASE_PATH + 'test\/'\nVAL_PATH   = BASE_PATH + 'val\/'\n\nTRAIN_0 = TRAIN_PATH + 'NORMAL\/'\nTRAIN_1 = TRAIN_PATH + 'PNEUMONIA\/'\n\nTEST_0 = TEST_PATH + 'NORMAL\/'\nTEST_1 = TEST_PATH + 'PNEUMONIA\/'\n\nVAL_0 = VAL_PATH + 'NORMAL\/'\nVAL_1 = VAL_PATH + 'PNEUMONIA\/'","94daabae":"print('The number of training images belonging to class 0: ', len(os.listdir(TRAIN_0)))\nprint('The number of training images belonging to class 1: ', len(os.listdir(TRAIN_1)))\n\nprint('The number of validation images belonging to class 0: ', len(os.listdir(VAL_0)))\nprint('The number of validation images belonging to class 1: ', len(os.listdir(VAL_1)))\n\nprint('The number of test images belonging to class 0: ', len(os.listdir(TEST_0)))\nprint('The number of test images belonging to class 1: ', len(os.listdir(TEST_1)))","94160af0":"from keras.preprocessing import image","099582ca":"filenames = os.listdir(TRAIN_0)\nindex = np.random.randint(0, len(filenames))\nIMAGE_PATH = TRAIN_0 + filenames[index]\n\nimg = image.load_img(IMAGE_PATH)\nimg = image.img_to_array(img)\/255.\n\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n\nplt.imshow(img)\nplt.axis('off')\nplt.title('Normal')\nplt.show()","72d7785f":"img.shape","1efd2db3":"def toDataframe(D_0, D_1):\n    filenames_0 = np.array(os.listdir(D_0))\n    y_0 = np.full(len(filenames_0), 'normal')\n\n    filenames_1 = np.array(os.listdir(D_1))\n    y_1 = np.full(len(filenames_1), 'pneumonia')\n\n    filenames = np.append(filenames_0, filenames_1)\n    y = np.append(y_0, y_1)\n\n    df = pd.DataFrame({'Filenames':filenames, 'Classes':y})\n    \n    # Shuffling the data:\n    df = df.sample(frac=1).reset_index(drop=True)\n    \n    return df","4f1b8d4b":"df_train = toDataframe(TRAIN_0, TRAIN_1)\ndf_val   = toDataframe(VAL_0, VAL_1)\ndf_test  = toDataframe(TEST_0, TEST_1)\ndisplay(df_train, df_val, df_test)","1a1c95de":"from keras.applications import Xception","818eb403":"# As of now, I have kept the input shape as (150, 150, 3)\nmodel_base = Xception(weights='imagenet', include_top=False, input_shape=(150, 150, 3))","7f296621":"from keras.models import Sequential\nfrom keras.layers import Flatten, Dense, Dropout, BatchNormalization\n\n#model_base.trainable = False\n\nmodel = Sequential()\nmodel.add(model_base) # Adding the base as a layer\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.summary()","1f0f9af8":"from keras.preprocessing.image import ImageDataGenerator as IDG\n\ntrain_datagen = IDG(\n    rescale=1.\/255,\n    rotation_range=5,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    #shear_range=0.2, #extra\n    #zoom_range=0.2, #extra\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\ntest_datagen = IDG(rescale=1.\/255) # Don't augment these images\n\ntrain_gen = train_datagen.flow_from_directory(\n    TRAIN_PATH,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary'\n)\n\nvalidation_gen = test_datagen.flow_from_directory(\n    VAL_PATH,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary'\n)\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer='adam',\n    metrics=['acc']\n)\n\nm = len(df_train)\nhistory = model.fit_generator(\n    train_gen,\n    steps_per_epoch=m\/32.,\n    epochs=10,\n    validation_data=validation_gen,\n    validation_steps=1\n)","524a36a9":"test_gen = test_datagen.flow_from_directory(\n    TEST_PATH,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary'\n)\n\nm_test = len(df_test)\ntest_loss, test_acc = model.evaluate_generator(test_gen, steps=m_test\/32)","daad3fcc":"model.save('xception_1.h5')","88bf6085":"print('Test accuracy: ' ,test_acc)","ada8c6fa":"## Converting the dataset into a dataframe:","dcd5f8b8":"## Visualizing the data:","a57270da":"Each image is a high quality image.","52465c13":"## Defining dataset paths:","c1e55071":"## Using Data Augmentation:","125809f3":"## The Xception Model"}}