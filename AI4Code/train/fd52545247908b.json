{"cell_type":{"151fd3a7":"code","038319db":"code","393340ac":"code","38326e08":"code","3cb31226":"code","50b24acf":"markdown","d2ade632":"markdown","c651f88e":"markdown","e2c8b884":"markdown","6817be28":"markdown"},"source":{"151fd3a7":"!pip install witwidget\n!jupyter nbextension install --py --symlink --sys-prefix witwidget\n!jupyter nbextension enable --py --sys-prefix witwidget","038319db":"import pandas as pd\ncsv_columns = [\n  \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Marital-Status\",\n  \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital-Gain\", \"Capital-Loss\",\n  \"Hours-per-week\", \"Country\", \"Over-50K\"]\ndf = pd.read_csv(\"..\/input\/adult-training.csv\", names=csv_columns, skipinitialspace=True)\ndf","393340ac":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport functools\n\n# Creates a tf feature spec from the dataframe and columns specified.\ndef create_feature_spec(df, columns=None):\n    feature_spec = {}\n    if columns == None:\n        columns = df.columns.values.tolist()\n    for f in columns:\n        if df[f].dtype is np.dtype(np.int64):\n            feature_spec[f] = tf.FixedLenFeature(shape=(), dtype=tf.int64)\n        elif df[f].dtype is np.dtype(np.float64):\n            feature_spec[f] = tf.FixedLenFeature(shape=(), dtype=tf.float32)\n        else:\n            feature_spec[f] = tf.FixedLenFeature(shape=(), dtype=tf.string)\n    return feature_spec\n\n# Creates simple numeric and categorical feature columns from a feature spec and a\n# list of columns from that spec to use.\n#\n# NOTE: Models might perform better with some feature engineering such as bucketed\n# numeric columns and hash-bucket\/embedding columns for categorical features.\ndef create_feature_columns(columns, feature_spec):\n    ret = []\n    for col in columns:\n        if feature_spec[col].dtype is tf.int64 or feature_spec[col].dtype is tf.float32:\n            ret.append(tf.feature_column.numeric_column(col))\n        else:\n            ret.append(tf.feature_column.indicator_column(\n                tf.feature_column.categorical_column_with_vocabulary_list(col, list(df[col].unique()))))\n    return ret\n\n# An input function for providing input to a model from tf.Examples\ndef tfexamples_input_fn(examples, feature_spec, label, mode=tf.estimator.ModeKeys.EVAL,\n                       num_epochs=None, \n                       batch_size=64):\n    def ex_generator():\n        for i in range(len(examples)):\n            yield examples[i].SerializeToString()\n    dataset = tf.data.Dataset.from_generator(\n      ex_generator, tf.dtypes.string, tf.TensorShape([]))\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        dataset = dataset.shuffle(buffer_size=2 * batch_size + 1)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.map(lambda tf_example: parse_tf_example(tf_example, label, feature_spec))\n    dataset = dataset.repeat(num_epochs)\n    return dataset\n\n# Parses Tf.Example protos into features for the input function.\ndef parse_tf_example(example_proto, label, feature_spec):\n    parsed_features = tf.parse_example(serialized=example_proto, features=feature_spec)\n    target = parsed_features.pop(label)\n    return parsed_features, target\n\n# Converts a dataframe into a list of tf.Example protos.\ndef df_to_examples(df, columns=None):\n    examples = []\n    if columns == None:\n        columns = df.columns.values.tolist()\n    for index, row in df.iterrows():\n        example = tf.train.Example()\n        for col in columns:\n            if df[col].dtype is np.dtype(np.int64):\n                example.features.feature[col].int64_list.value.append(int(row[col]))\n            elif df[col].dtype is np.dtype(np.float64):\n                example.features.feature[col].float_list.value.append(row[col])\n            elif row[col] == row[col]:\n                example.features.feature[col].bytes_list.value.append(row[col].encode('utf-8'))\n        examples.append(example)\n    return examples\n\n# Converts a dataframe column into a column of 0's and 1's based on the provided test.\n# Used to force label columns to be numeric for binary classification using a TF estimator.\ndef make_label_column_numeric(df, label_column, test):\n  df[label_column] = np.where(test(df[label_column]), 1, 0)","38326e08":"import numpy as np\n\n# Set the column in the dataset you wish for the model to predict\nlabel_column = 'Over-50K'\n\n# Make the label column numeric (0 and 1), for use in our model.\n# In this case, examples with a target value of '>50K' are considered to be in\n# the '1' (positive) class and all other examples are considered to be in the\n# '0' (negative) class.\nmake_label_column_numeric(df, label_column, lambda val: val == '>50K')\n\n# Set list of all columns from the dataset we will use for model input.\ninput_features = [\n  'Age', 'Workclass', 'Education', 'Marital-Status', 'Occupation',\n  'Relationship', 'Race', 'Sex', 'Capital-Gain', 'Capital-Loss',\n  'Hours-per-week', 'Country']\n\n# Create a list containing all input features and the label column\nfeatures_and_labels = input_features + [label_column]\n\n# Convert data to example format\nexamples = df_to_examples(df)\n\n# Create a feature spec for the classifier\nfeature_spec = create_feature_spec(df, features_and_labels)\n\n# Define and train the classifier\nnum_steps = 5000\ntrain_inpf = functools.partial(tfexamples_input_fn, examples, feature_spec, label_column)\nclassifier = tf.estimator.LinearClassifier(\n    feature_columns=create_feature_columns(input_features, feature_spec))\nclassifier.train(train_inpf, steps=num_steps)","3cb31226":"from witwidget.notebook.visualization import WitConfigBuilder\nfrom witwidget.notebook.visualization import WitWidget\n\n# Setup the tool with some examples and the trained classifier\nconfig_builder = WitConfigBuilder(examples[0:2000]).set_estimator_and_feature_spec(\n    classifier, feature_spec)\nWitWidget(config_builder, height=800)","50b24acf":"We then load up the census data.","d2ade632":"The [What-If Tool](https:\/\/pair-code.github.io\/what-if-tool) is an interactive visual tool for exploring trained models and their behavior on input data. Check out the [website](https:\/\/pair-code.github.io\/what-if-tool) for more information including documentation, demos, example colab notebooks, and a walkthrough of the features.\n\nIn this kernel, we train a [TensorFlow Estimator](https:\/\/www.tensorflow.org\/guide\/estimators) simple linear classifier model for income prediction (to answer if someone's income is >=$50k) using the [UCI census dataset](https:\/\/www.kaggle.com\/johnolafenwa\/us-census-data). The What-If Tool works with non-TensorFlow models as well, and example notebooks showing that can be found on the tool's website.\n\nTo use the tool inside a Kaggle Kernel, we need to install the What-If Tool jupyter extension through pip and enable it through the jupyter nbextension install and enable commands.","c651f88e":"Below we define some helper functions used during training of our model.","e2c8b884":"Now we get our data into the format necessary for training (convert the training data DataFrame into a list of tf.Example protos), define the model and train it. This cell will take a few minutes to complete.","6817be28":"Now that we have trained a model, we invoke the What-If Tool by providing it with some examples to use and the model to use. See this [walkthrough](https:\/\/pair-code.github.io\/what-if-tool\/walkthrough.html) for an introduction to the features of the tool.\n\nNote that the What-If Tool won't appear in the persisted version of the kernel.  You need to run this kernel to see and use the tool.\n\nIf the tool doesn't appear upon running the below cell, you may need to refresh the browser page and re-run the cell as due to jupyter extension intricacies, the widget installation might not be complete until this page reloads."}}