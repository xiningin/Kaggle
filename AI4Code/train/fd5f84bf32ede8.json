{"cell_type":{"3279a21f":"code","07f268fe":"code","c6dd5709":"code","ac1f6065":"code","f714a7c0":"code","a3edde82":"code","a25ea0cc":"code","49de36ef":"code","6c7f0aa4":"code","46a93727":"code","0b4f6995":"code","59e25e2e":"code","8ff2f849":"code","a0e43deb":"code","aebcf165":"code","7e830026":"code","c2349011":"markdown","5c010e81":"markdown","fe578409":"markdown","60d28ba4":"markdown","2d55e08c":"markdown","ac3c2f7e":"markdown","632bf031":"markdown","6969404e":"markdown","c6e2c42f":"markdown","d7be2974":"markdown","ff644f5c":"markdown","9c69fcac":"markdown","c2c84e57":"markdown","b5894609":"markdown","bd38e536":"markdown","d420c836":"markdown","906e2830":"markdown","754ce8e3":"markdown","8aba62f4":"markdown","e22e618d":"markdown","ea55f97b":"markdown"},"source":{"3279a21f":"import numpy as np\nimport pandas as pd\n#import os\nfrom matplotlib import pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport seaborn as sns\nsns.set(style='white')\nsns.set(style='whitegrid', color_codes=True)","07f268fe":"df = pd.read_csv(\"..\/input\/Admission_Predict.csv\")\ndf.head()","c6dd5709":"df.describe()","ac1f6065":"df.rename(columns = {'Chance of Admit ':'Chance of Admit', 'LOR ':'LOR'}, inplace=True)\ndf.drop(labels='Serial No.', axis=1, inplace=True)","f714a7c0":"fig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(df.corr(), annot=True, cmap='Blues')","a3edde82":"plt.figure(figsize=(20,6))\nplt.subplot(1,2,1)\nsns.distplot(df['CGPA'])\nplt.title('CGPA Distribution of Applicants')\n\nplt.subplot(1,2,2)\nsns.regplot(df['CGPA'], df['Chance of Admit'])\nplt.title('CGPA vs Chance of Admit')","a25ea0cc":"plt.figure(figsize=(20,6))\nplt.subplot(1,2,1)\nsns.distplot(df['GRE Score'])\nplt.title('Distributed GRE Scores of Applicants')\n\nplt.subplot(1,2,2)\nsns.regplot(df['GRE Score'], df['Chance of Admit'])\nplt.title('GRE Scores vs Chance of Admit')","49de36ef":"plt.figure(figsize=(20,6))\nplt.subplot(1,2,1)\nsns.distplot(df['TOEFL Score'])\nplt.title('Distributed TOEFL Scores of Applicants')\n\nplt.subplot(1,2,2)\nsns.regplot(df['TOEFL Score'], df['Chance of Admit'])\nplt.title('TOEFL Scores vs Chance of Admit')","6c7f0aa4":"fig, ax = plt.subplots(figsize=(8,6))\nsns.countplot(df['Research'])\nplt.title('Research Experience')\nplt.ylabel('Number of Applicants')\nax.set_xticklabels(['No Research Experience', 'Has Research Experience'])","46a93727":"fig, ax = plt.subplots(figsize=(8,6))\nsns.countplot(df['University Rating'])\nplt.title('University Rating')\nplt.ylabel('Number of Applicants')","0b4f6995":"targets = df['Chance of Admit']\nfeatures = df.drop(columns = {'Chance of Admit'})\n\nX_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42)","59e25e2e":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)","8ff2f849":"linreg = LinearRegression()\nlinreg.fit(X_train, y_train)\ny_predict = linreg.predict(X_test)\nlinreg_score = (linreg.score(X_test, y_test))*100\nlinreg_score","a0e43deb":"dec_tree = DecisionTreeRegressor(random_state=0, max_depth=6)\ndec_tree.fit(X_train, y_train)\ny_predict = dec_tree.predict(X_test)\ndec_tree_score = (dec_tree.score(X_test, y_test))*100\ndec_tree_score","aebcf165":"forest = RandomForestRegressor(n_estimators=110,max_depth=6,random_state=0)\nforest.fit(X_train, y_train)\ny_predict = forest.predict(X_test)\nforest_score = (forest.score(X_test, y_test))*100\nforest_score","7e830026":"Methods = ['Linear Regression', 'Decision Trees', 'Random Forests']\nScores = np.array([linreg_score, dec_tree_score, forest_score])\n\nfig, ax = plt.subplots(figsize=(8,6))\nsns.barplot(Methods, Scores)\nplt.title('Algorithm Prediction Accuracies')\nplt.ylabel('Accuracy')","c2349011":"## **Machine Learning **\n\nNow we'll implement machine learning algorithms to predict the chance of admission. We'll use multiple techniques and eventually select the method with the best score. The methods used will be:\n\n1. Linear Regression\n2. Decision Trees\n3. Random Forests","5c010e81":"### **GRE Score**\n\nThe Graduate Record Examination is a standarized exam, often required for admission to graduate and MBA programs globally. It's made up of three components:\n1. Analytical Writing (Scored on a 0-6 scale in half-point increments)\n2. Verbal Reasoning (Scored on a 130-170 scale)\n3. Quantitative Reasoning (Scored on a 130-170 scale)\n\nIn this dataset, the GRE Score is based on a maximum of 340 points. The mean is 317 with a standard deviation of 11.5.\n\n### **GRE Score vs Chance of Admit**\n\nGRE scores have a strong correlation with the chance of admission however not as strong as one's CGPA.\n","fe578409":"### **Random Forests**","60d28ba4":"## **Introduction**\n\n### **Objective**\n400 applicants have been surveyed as potential students for UCLA. The university weighs certain aspects of a student's education to determine their acceptance.\n\nThe objective is to explore what kind of data is provided, determine the most important factors that contribute to a student's chance of admission, and select the most accurate model to predict the probability of admission.\n\n### **Data Description**\nThe dataset contains information about a student's:\n* GRE Score\n* TOEFL Score\n* University Ratings\n* Statement of Purpose Score\n* Letter of Recomendation Score\n* CGPA\n* Whether the Student Has Done Any Research\n* Chance of Admission (What We're Trying to Predict)","2d55e08c":"For my curiosity, I want to explore the data a little bit further regarding research and university rankings. Even though they hold a lower importance in the chance of admission, it would be nice to understand their characteristics in the dataset.","ac3c2f7e":"Next, let's import our dataset and see what we're working with.","632bf031":"### **Decision Trees**","6969404e":"## **Importing Libraries and Data**\nImporting libraries and setting the default style in Seaborn.","c6e2c42f":"## **Exploratory Analysis**\n\nFrom these charts it looks like we have no missing values! \n\nIt seems as though Serial No. is just an index for students, which we can take out. \n\nTwo columns also have an added space in the label which we'll take out\n\nWe are also removing the blank sapces.","d7be2974":"## **Conclusion**\n\nThis was a great way to get started on Kaggle and for my first project outside of coursework. It gave me some practice some exploratory analysis and simple machine learning techniques. \n\nIt's great to see what specific variables contribute to the chance of admission and how they are weighted against eachother.","ff644f5c":"The top three features that affect the Chance to Admit are:\n1. CGPA\n2. GRE Score\n3. TOEFL Score\n\nLet's explore these three features to get a better understanding.","9c69fcac":"### **Linear Regression**","c2c84e57":"### **Comparing Scores**\n\nLet's put all the scores in a table and display their scores side-by-side.","b5894609":"# **Graduate Admission Analysis for UCLA**","bd38e536":"## **Preparing Data for Machine Learning**\n\nNow that we understand our dataset, it's time to implement machine learning methods to predict future applicant's chances of admission.\n\nFirst we have to prepare our data, by splitting it into training and testing data. We'll also scale our data, from 0 to 1, to receive more accurate predictions.","d420c836":"### **CGPA**\n\nThe Cumulative Grade Point Average is a 10 point grading system.\n\nFrom the data shown below, it appears the submissions are normally distributed. With a mean of 8.6 and standard deviation of 0.6.\n\n### **CGPA vs Chance of Admit**\n\nIt appears as applicant's CGPA has a strong correlation with their chance of admission.","906e2830":"### **University Rating**\n\nLet's see the distribution of applicants coming from each kind of university.\n\nMost applicants come from a tier 3 and tier 2 university.","754ce8e3":"### **Selecting the Best Algorithm**\n\n1. Linear Regression - 81.74%\n2. Random Forests - 81.35%\n3. Decision Trees - 73.99%\n\nIt seems that Linear Regression is the most accurate of the 3 methods and will be used to predict the future applicant's chances of admission.\n\n","8aba62f4":"Let's plot a heatmap to see the correlation of all the features compared to Chance to Admit:","e22e618d":"### **Research**\n\nLet's explore how many applicants have research experience.\n\nIt seems the majority of applicants have research experience. However, this is the least important feature, so it doesn't matter all too much if an applicant has the experience or not.","ea55f97b":"### **TOEFL Score**\n\nThe Test of English as a Foreign Language is a standarized test for non-native English speakers that are choosing to enroll in English-speaking universities.\n\nThe test is split up into 4 sections:\n1. Reading\n2. Listening\n3. Speaking\n4. Writing\n\nAll sections are scored out of 30, giving the exam a total score of 120 marks. In this dataset, the TOEFL scores have a mean of 107 and a standard deviation of 6.\n\n### **TOEFL Score vs Chance of Admit**\n\nLike GRE scores, the scores received for the TOEFL strongly correlate to an applicants chance of admission."}}