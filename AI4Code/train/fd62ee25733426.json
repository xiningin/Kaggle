{"cell_type":{"cd8f6fab":"code","d56d90d7":"code","8273f384":"code","4e07ac7a":"code","71915b9a":"code","bc5eeff2":"code","966733b7":"code","f7a9c8d4":"code","c27d8081":"code","73ef443a":"code","b44b99fd":"code","5c35e2bd":"code","915b2ca3":"code","779f1bc6":"code","f9c36ee9":"code","852488a7":"code","91a01ac2":"code","14c1690e":"code","1d72029d":"code","ffc96486":"code","be7d2977":"code","845a5346":"code","f0e62735":"code","5e4e6549":"code","1d145b52":"code","ff7a8259":"code","2b8f6810":"code","d23e9dc2":"code","22c488cd":"code","ab943268":"code","d02b71e9":"code","f233fa39":"code","49f616a5":"markdown","a1db19bd":"markdown","91f11404":"markdown","c9755d69":"markdown","6453fd3c":"markdown","18b3ce98":"markdown","e0c616bb":"markdown","4cc1e56a":"markdown","37a8e661":"markdown","9b696ddd":"markdown","95e70681":"markdown","d17d163a":"markdown","ca07ba34":"markdown","2da0341e":"markdown","6f9e4c9a":"markdown","234af71d":"markdown","9b9b7a63":"markdown","56c86a42":"markdown","939c824b":"markdown","c154d4db":"markdown"},"source":{"cd8f6fab":"! pip install turicreate\nimport turicreate","d56d90d7":"# Reading the data and creating an SFrame of the data\nproducts = turicreate.SFrame.read_csv('..\/input\/reviews-of-amazon-baby-products\/amazon_baby.csv')\nproducts","8273f384":"products","4e07ac7a":"products.groupby('name',operations={'count':turicreate.aggregate.COUNT()}).sort('count',ascending=False)","71915b9a":"\nselected_words = ['awesome', 'great', 'fantastic', 'amazing', 'love', 'horrible', 'bad', 'terrible', 'awful', 'wow', 'hate']\n","bc5eeff2":"products['word_count'] = turicreate.text_analytics.count_words(products['review'] )","966733b7":"# Loop through word counts to create a classifier for only a few words \n# Created an individual column for each item \nfor word in selected_words:\n    products[word] = products['word_count'].apply(lambda counts: counts.get(word, 0))\n\nproducts","f7a9c8d4":"for word in selected_words:\n    print(\"\\nThe number of times {} appears: {}\".format(word, products[word].sum()))","c27d8081":"train_data,test_data = products.random_split(.8, seed=0)","73ef443a":"# Features to be trained on \nfeatures = selected_words","b44b99fd":"products['rating'].show()","5c35e2bd":"#ignore all 3*  reviews\nproducts = products[products['rating']!= 3]","915b2ca3":"#positive sentiment = 4-star or 5-star reviews\nproducts['sentiment'] = products['rating'] >= 4","779f1bc6":"products","f9c36ee9":"products['sentiment'].show()","852488a7":"train_data,test_data = products.random_split(.8,seed=0)","91a01ac2":"# Original Analysis Model \nsentiment_model = turicreate.logistic_classifier.create(train_data,target='sentiment', \n                                                        features=['word_count'], \n                                                        validation_set=test_data)","14c1690e":"# Creating the model with selected words \nselected_words_model = turicreate.logistic_classifier.create(train_data,target='sentiment', \n                                                        features=features, \n                                                        validation_set=test_data)","1d72029d":"# Calling and descreibing our coefficients and weights allotted to each word\nselected_words_model.coefficients.sort(key_column_names='value', ascending=True)","ffc96486":"# Evaluate the orginal analysis model first \nsentiment_model.evaluate(test_data)","be7d2977":"# Evaluate the limited words model \nselected_words_model.evaluate(test_data)","845a5346":"# Extract only the relevant data\ndiaper_champ_reviews = products[products['name']== 'Baby Trend Diaper Champ']\ndiaper_champ_reviews","f0e62735":"selected_words_model.predict(diaper_champ_reviews[0:1], output_type='probability')","5e4e6549":"diaper_champ_reviews['predicted_sentiment'] = selected_words_model.predict(diaper_champ_reviews, output_type = 'probability')","1d145b52":"products","ff7a8259":"diaper_champ_reviews = diaper_champ_reviews.sort('predicted_sentiment', ascending=False)","2b8f6810":"diaper_champ_reviews","d23e9dc2":"diaper_champ_reviews.tail()","22c488cd":"diaper_champ_reviews[0]['review']","ab943268":"diaper_champ_reviews[1]['review']","d02b71e9":"diaper_champ_reviews[-1]['review']","f233fa39":"diaper_champ_reviews[-2]['review']","49f616a5":"# Most negative reivews","a1db19bd":"## Show the most positive reviews","91f11404":"# Apply the sentiment classifier to better understand the Baby Trend Diaper Champ reviews\n\n**Interpreting the difference in performance between the models:** To understand why the model with all word counts performs better than the one with only the selected_words, we will now examine the reviews for a particular product.\n\n* We will investigate a product named \u2018Baby Trend Diaper Champ\u2019. (This is a trash can for soiled baby diapers, which keeps the smell contained.)\n\n* Just like we did for the reviews for the giraffe toy in the Jupyter Notebook in the lecture video, before we start our analysis you should select all reviews where the product name is \u2018Baby Trend Diaper Champ\u2019. Let\u2019s call this table diaper_champ_reviews.\n\n* Again, just as in the video, use the sentiment_model to predict the sentiment of each review in diaper_champ_reviews and sort the results according to their \u2018predicted_sentiment\u2019.","c9755d69":"Now, I am creating a subset of words to create a classifier. Often, ML practitioners will throw out words they consider \u201cunimportant\u201d before training their model. This procedure can often be helpful in terms of accuracy. Here, we are going to throw out all words except for the very few above. Using so few words in our model will hurt our accuracy, but help us interpret what our classifier is doing. ","6453fd3c":"## Evaluation of our models","18b3ce98":"## Train and Test Split","e0c616bb":"Our first goal is to create a column products[\u2018awesome\u2019] where each row contains the number of times the word \u2018awesome\u2019 showed up in the review for the corresponding product, and 0 if the review didn\u2019t show up. One way to do this is to look at the each row \u2018word_count\u2019 column and follow this logic: ","4cc1e56a":"Out of the 11 words in selected_words, which one got the most positive weight? Which one got the most negative weight? \nMost Positive: love \nMost Negative: horrible\n\nMakes total sense because love is a great word and horrible is a bad descriptor. ","37a8e661":"# Sort the Diaper Champ reviews according to predicted sentiment","9b696ddd":"# Explore data","95e70681":"## Analysing our model and weights ","d17d163a":"## Build word count vectors","ca07ba34":"# Analyze Product Sentiment","2da0341e":"# Read product review data","6f9e4c9a":"As we can see above, the highest count is of the word `great`\nand the lowest count is of the word `wow`","234af71d":"Accuracy increases multifold! ","9b9b7a63":"# Train our sentiment classifier","56c86a42":"# Building a sentiment classifier","939c824b":"Using the .sum() method on each of the new columns you created, answer the following questions: Out of the selected_words, which one is most used in the dataset? Which one is least used?","c154d4db":"# Define what is positive and negative sentiment"}}