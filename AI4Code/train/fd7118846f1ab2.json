{"cell_type":{"ba4e11f6":"code","66ceae57":"code","4ac4b5c8":"code","e339e899":"code","3ec5f29d":"code","b0eb2199":"code","9cd7cf47":"code","42de19f0":"code","ad6b189c":"code","53524d40":"code","4f8f97e3":"code","449a44be":"code","16c7af6f":"code","a9519f60":"code","d32647c5":"code","4209f107":"code","10223bd6":"code","84904387":"code","c9de2db2":"code","ffd5f475":"code","c1c5f4f6":"code","0cf26299":"code","75b00cc7":"code","c0fc7f60":"code","6b7fa2fa":"code","8e8df93e":"code","020a6ac6":"code","053b955d":"code","b22c0d99":"code","b0ccd0d4":"code","44fbc884":"code","6e32e4de":"code","f044ffee":"code","9c5799b7":"code","9353fefc":"code","b63ed44d":"code","6db3ff7e":"code","2d022b77":"code","ba5c375b":"code","68864a1f":"code","60a52042":"code","d07b1d30":"code","3a16a95e":"code","b1248ff8":"code","05e10a17":"code","3e36f507":"code","400961b6":"code","88d8092f":"code","81245cf2":"code","82e0a2aa":"code","6b72e84b":"code","612d0a4b":"code","48a50388":"code","c252f3c7":"code","83c60442":"code","1558c20b":"code","c85f44f2":"code","87425467":"code","3db3bcf9":"code","c33468d0":"code","29024183":"code","a8954e1c":"code","1055c657":"code","6ac54204":"code","2a7e1d82":"markdown","05d7cbdd":"markdown","a2bf80d3":"markdown","8c34708d":"markdown"},"source":{"ba4e11f6":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM\nfrom keras.layers import CuDNNLSTM\nimport pandas as pd\nimport numpy as np\nimport gc \nimport seaborn as sns\nimport sklearn\nimport sklearn.utils\nimport warnings \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import *\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import *\n\n%matplotlib inline\nwarnings.filterwarnings('ignore')","66ceae57":"test_data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")","4ac4b5c8":"train_data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","e339e899":"train_data.head()","3ec5f29d":"train_data.info()","b0eb2199":"train_data.describe()","9cd7cf47":"sns.histplot(train_data,x=\"LotFrontage\")","42de19f0":"#keep this running_1 \nNull_Col = pd.DataFrame(train_data.isnull().sum().sort_values(ascending=False) , columns = [\"Num_Count\"])","ad6b189c":"#keep this running_1 \nNull_Col_2 = pd.DataFrame(test_data.isnull().sum().sort_values(ascending=False) , columns = [\"Num_Count\"])","53524d40":"#keep this running_2 \nNull_Col[ Null_Col.Num_Count > 0 ][[\"Num_Count\"]]","4f8f97e3":"#keep this running_2 \nNull_Col_2[ Null_Col_2.Num_Count > 0 ][[\"Num_Count\"]]","449a44be":"train_data[[\"PoolQC\",\"MiscFeature\",\"Alley\",\"Fence\"]] = train_data[[\"PoolQC\",\"MiscFeature\",\"Alley\",\"Fence\"]].fillna(\"None\")","16c7af6f":"test_data[[\"PoolQC\",\"MiscFeature\",\"Alley\",\"Fence\"]] = test_data[[\"PoolQC\",\"MiscFeature\",\"Alley\",\"Fence\"]].fillna(\"None\")","a9519f60":"train_data.FireplaceQu.value_counts(normalize=True)*100","d32647c5":"test_data.FireplaceQu.value_counts(normalize=True)*100","4209f107":"train_data[\"FireplaceQu\"] = train_data[\"FireplaceQu\"].fillna(\"None\")\ntest_data[\"FireplaceQu\"] = test_data[\"FireplaceQu\"].fillna(\"None\")","10223bd6":"train_data[\"LotFrontage\"] = train_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\ntest_data[\"LotFrontage\"] = test_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))","84904387":"#as the Data Description says the Null values for Garage are all because of not having garage\n#Since they are Categorical_values so we fill them with \"NONE\"\ntrain_data[['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']] = train_data[['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']].fillna('None')\ntest_data[['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']] = test_data[['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']].fillna('None')","c9de2db2":"#Since they are Numerical_values so we fill them with 0\ntrain_data[['GarageYrBlt', 'GarageArea', 'GarageCars']] = train_data[['GarageYrBlt', 'GarageArea', 'GarageCars']].fillna(0)\ntest_data[['GarageYrBlt', 'GarageArea', 'GarageCars']] = test_data[['GarageYrBlt', 'GarageArea', 'GarageCars']].fillna(0)","ffd5f475":"#Same as garage related columns , Basement related columns had taken NULL values because of not having basement\ntrain_data[['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']] = train_data[['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']].fillna(\"None\")\ntrain_data[['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']] = train_data[['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']].fillna(0)","c1c5f4f6":"test_data[['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']] = test_data[['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']].fillna(\"None\")\ntest_data[['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']] = test_data[['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']].fillna(0)","0cf26299":"# Null Value in this columns most likely means no masonry veneer for these houses\ntrain_data[\"MasVnrType\"] = train_data[\"MasVnrType\"].fillna(\"None\")\ntrain_data[\"MasVnrArea\"] = train_data[\"MasVnrArea\"].fillna(0)","75b00cc7":"test_data[\"MasVnrType\"] = test_data[\"MasVnrType\"].fillna(\"None\")\ntest_data[\"MasVnrArea\"] = test_data[\"MasVnrArea\"].fillna(0)","c0fc7f60":"train_data.Electrical.value_counts(normalize=True)*100","6b7fa2fa":"train_data[\"Electrical\"]=train_data[\"Electrical\"].fillna(\"SBrkr\")","8e8df93e":"# train_data = train_data.drop([\"Id\"],axis=1)\ntrain_data.head()","020a6ac6":"# test_data = test_data.drop([\"Id\"],axis=1)\ntest_data.head()","053b955d":"train_data.isnull().sum().sort_values(ascending=False)","b22c0d99":"test_data['MSZoning'].value_counts(normalize=True)*100","b0ccd0d4":"test_data[\"MSZoning\"]=test_data[\"MSZoning\"].fillna(\"Rl\")","44fbc884":"test_data['Utilities'].value_counts(normalize=True)*100","6e32e4de":"test_data[\"Utilities\"]=test_data[\"Utilities\"].fillna(\"AllPub\")","f044ffee":"test_data[\"Functional\"].value_counts(normalize=True)*100","9c5799b7":"test_data[\"Functional\"] = test_data[\"Functional\"].fillna(\"Typ\")","9353fefc":"test_data[\"KitchenQual\"].value_counts(normalize=True)*100","b63ed44d":"test_data[\"KitchenQual\"] = test_data[\"KitchenQual\"].fillna(\"TA\")","6db3ff7e":"test_data[\"Exterior2nd\"].value_counts(normalize=True)*100","2d022b77":"test_data[\"Exterior2nd\"] = test_data[\"Exterior2nd\"].fillna(\"VinylSd\")","ba5c375b":"test_data[\"Exterior1st\"].value_counts(normalize=True)*100","68864a1f":"test_data[\"Exterior1st\"] = test_data[\"Exterior1st\"].fillna(\"VinylSd\")","60a52042":"test_data[\"SaleType\"].value_counts(normalize=True)*100","d07b1d30":"test_data[\"SaleType\"] = test_data[\"SaleType\"].fillna(\"WD\")","3a16a95e":"test_data.isnull().sum().sort_values(ascending=False)","b1248ff8":"# At the First glance ive tried to Encode The some of the categorical features but \n# as i progressed through the competition ive learned many new things and decided to change my method\n# ---------------------------------------------------------------------------------------------------\n# cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n#         'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n#         'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n#         'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n#         'YrSold', 'MoSold')","05e10a17":"# #Label Encoding some categorical variables that may \n# # contain information in their ordering set\n\n# for col in cols :    \n#     lbl = LabelEncoder() \n#     lbl.fit(list(train_data[col].values)) \n#     train_data[col] = lbl.transform(list(train_data[col].values))\n    ","3e36f507":"# for col in cols :    \n#     lbl = LabelEncoder() \n#     lbl.fit(list(test_data[col].values)) \n#     test_data[col] = lbl.transform(list(test_data[col].values))","400961b6":"# #MSSubClass=The building class\n# train_data['MSSubClass'] = train_data['MSSubClass'].apply(str)\n# test_data['MSSubClass'] = test_data['MSSubClass'].apply(str)\n\n\n# #Changing OverallCond into a categorical variable\n# train_data['OverallCond'] = train_data['OverallCond'].astype(str)\n# test_data['OverallCond'] = test_data['OverallCond'].astype(str)\n\n\n\n# #Year and month sold are transformed into categorical features.\n# train_data['YrSold'] = train_data['YrSold'].astype(str)\n# train_data['MoSold'] = train_data['MoSold'].astype(str)\n# test_data['YrSold'] = test_data['YrSold'].astype(str)\n# test_data['MoSold'] = test_data['MoSold'].astype(str)","88d8092f":"# # We could have used Box Cox here to to handle skewness but as this is a simple excercise i decided not to use it here ...\n# train_data.head()","81245cf2":"#train_target = pd.DataFrame(train_data[\"SalePrice\"], columns=[\"SalePrice\"])","82e0a2aa":"#train_data = train_data.drop([\"SalePrice\"],axis=1)","6b72e84b":"# Memmory management\nnon_cat_features = []\n#cat_features = []\ncolumns = train_data.columns\nfor col in columns:\n    if train_data.values.dtype == \"float64\":\n        non_cat_features.append(col)\n    elif train_data.values.dtype == \"int64\":\n        non_cat_features.append(col)\n\n        \ntrain_data[non_cat_features] = train_data[non_cat_features].astype('float32')\n#train_data[cat_features] = train_data[cat_features].astype('str')","612d0a4b":"test_data.info()","48a50388":"train_data.info()","c252f3c7":"# Memmory management\nnon_cat_features_1 = []\n#cat_features_1 = []\ncolumns_1 = test_data.columns\nfor col in columns_1:\n    if test_data.values.dtype == \"float64\":\n        non_cat_features_1.append(col)\n    elif train_data.values.dtype == \"int64\":\n        non_cat_features_1.append(col)\n\ntest_data[non_cat_features_1] = test_data[non_cat_features_1].astype('float32')\n# test_data[cat_features_1] = test_data[cat_features_1].astype('str')","83c60442":"features = [\n        'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n       'MoSold', 'YrSold', 'Neighborhood', 'SalePrice'\n]\n\ntrain_data = train_data.loc[:, features]\ntrain_data_price = train_data['SalePrice']\ntrain_data = train_data.loc[:, features[:len(features)-1]]\n\ntest_data_id = test_data['Id']\ntest_data = test_data.loc[:, features[:len(features)-1]]","1558c20b":"train_data = pd.get_dummies(train_data)\ntest_data = pd.get_dummies(test_data)","c85f44f2":"MX = MinMaxScaler()\ntrain_data_scaled = MX.fit_transform(train_data.values)\ntrain_data = pd.DataFrame(train_data_scaled, columns=train_data.columns)\n\n\ntest_data_scaled = MX.transform(test_data.values)\ntest_data = pd.DataFrame(test_data_scaled, columns=test_data.columns)","87425467":"train_labels = train_data_price\n\ntrain_data, validation_data, train_labels, validation_labels = train_test_split(train_data, train_labels, test_size = 0.15, random_state=2)","3db3bcf9":"print(train_data.shape)\nprint(train_labels.shape)\nprint(validation_data.shape)\nprint(validation_labels.shape)","c33468d0":"model = tf.keras.Sequential([\n    tf.keras.layers.Dense(64, kernel_initializer='lecun_normal', activation='selu', input_shape=(train_data.shape[1], )),\n    tf.keras.layers.Dense(64, kernel_initializer='lecun_normal', activation='selu'),\n    tf.keras.layers.Dense(64, kernel_initializer='lecun_normal', activation='selu'),\n    tf.keras.layers.Dense(64, kernel_initializer='lecun_normal', activation='selu'),\n    tf.keras.layers.Dense(64, kernel_initializer='lecun_normal', activation='selu'),\n    tf.keras.layers.Dense(64, kernel_initializer='lecun_normal', activation='selu'),\n    tf.keras.layers.Dense(1, kernel_initializer='normal', activation='linear')\n ])\n    \nmodel.summary()","29024183":"initial_learning_rate = 0.001\n\nlr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=10)\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=100, restore_best_weights=True)\n\nmodel.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate=initial_learning_rate), loss=tf.keras.losses.Huber())\n\nepochs = 1000\nhistory = model.fit(x=train_data, y=train_labels, \n                    batch_size=16,\n                    validation_data=(validation_data, validation_labels),\n                    epochs=epochs,\n                    callbacks=[\n                        early_stop,\n                        lr_scheduler\n                    ])","a8954e1c":"loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(loss) + 1)\n\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\n\nplt.show()","1055c657":"predictions = model.predict(test_data)","6ac54204":"sub_data = pd.DataFrame(predictions, columns=['SalePrice'])\nsub_data.insert(0, 'Id', test_data_id)\n\nsub_data.to_csv('\/kaggle\/working\/submission.csv', index=False)","2a7e1d82":"# EDA","05d7cbdd":"# Model Training","a2bf80d3":"# Data Prep","8c34708d":"<div><h4> Now that Null-Values been taken care off \n    <\/h4>\n    <h5>now let's get to the next step <\/h5>\n    <\/div>"}}