{"cell_type":{"3f6d3250":"code","71b1af47":"code","f6eb2d28":"code","0690dfe6":"code","45584575":"code","9869198e":"code","d1b51960":"code","4fc7effe":"markdown","5670e954":"markdown","8c08b77c":"markdown","e3fc9d78":"markdown","4c545232":"markdown","e1c201fb":"markdown"},"source":{"3f6d3250":"import numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import RepeatedKFold","71b1af47":"df = pd.read_csv(\"..\/input\/real-or-fake-fake-jobposting-prediction\/fake_job_postings.csv\")\ndf.head()","f6eb2d28":"cols = [\"title\", \"company_profile\", \"description\", \"requirements\", \"benefits\"]\nfor c in cols:\n    df[c] = df[c].fillna(\"\")\n\ndef extract_features(df):    \n    for c in cols:\n        df[c+\"_len\"] = df[c].apply(lambda x : len(str(x)))\n        df[c+\"_wc\"] = df[c].apply(lambda x : len(str(x.split())))\n\n    \nextract_features(df)","0690dfe6":"df['combined_text'] = df['company_profile'] + \" \" + df['description'] + \" \" + df['requirements'] + \" \" + df['benefits']\n\nn_features = {\n    \"title\" : 100,\n    \"combined_text\" : 500\n}\n\nfor c, n in n_features.items():\n    tfidf = TfidfVectorizer(max_features=n, norm='l2', stop_words = 'english')\n    tfidf.fit(df[c])\n    tfidf_train = np.array(tfidf.transform(df[c]).toarray(), dtype=np.float16)\n\n    for i in range(n_features[c]):\n        df[c + '_tfidf_' + str(i)] = tfidf_train[:, i]","45584575":"cat_cols = [\"employment_type\", \"required_experience\", \"required_education\", \"industry\", \"function\"]\nfor c in cat_cols:\n    encoded = pd.get_dummies(df[c])\n    df = pd.concat([df, encoded], axis=1)","9869198e":"drop_cols = ['title', 'location', 'department', 'salary_range', 'company_profile', 'description', 'requirements', 'benefits', 'combined_text']\ndrop_cols += cat_cols\ndf = df.drop(drop_cols, axis = 1)\ndf.head()","d1b51960":"df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df.columns]\nidd, target = \"job_id\", \"fraudulent\"\nfeatures = [f for f in df.columns if f not in [idd, target]]\n\nX = df[features]\ny = df[target]\n\nkf = RepeatedKFold(n_splits=3, n_repeats=1, random_state=0)\nauc_buf = []   \ncnt = 0\nfor train_index, valid_index in kf.split(X):\n    print('Fold {}'.format(cnt + 1))\n\n    train_x,train_y = X.loc[train_index], y.loc[train_index]\n    test_x, test_y = X.loc[valid_index], y.loc[valid_index]\n    \n    clf = LogisticRegression(max_iter = 5000).fit(train_x, train_y)\n    preds = clf.predict(test_x)\n    \n    auc = roc_auc_score(test_y, preds)\n    print('{} AUC: {}'.format(cnt, auc))\n    auc_buf.append(auc)\n\n    cnt += 1\n\nauc_mean = np.mean(auc_buf)\nauc_std = np.std(auc_buf)\nprint('AUC = {:.6f} +\/- {:.6f}'.format(auc_mean, auc_std))","4fc7effe":"1. Feature Engineering\n\nCreate features from text columns : length of text and TFIDF","5670e954":"Build a Simple Logistic Model","8c08b77c":"## Predict if the Job Descriptions are Real or Fraud \n\nLet's quickly create a baseline model in this kernel","e3fc9d78":"One Hot Encoding for Categorical Columns","4c545232":"Create TF IDF Features","e1c201fb":"Prepare Dataset : Drop unnecessary columns"}}