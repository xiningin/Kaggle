{"cell_type":{"e3beed70":"code","0bc6d6e9":"code","b2bf3697":"code","4e5aab4b":"code","ae2c94d8":"code","9402d9d4":"code","a57cd549":"code","b4223b29":"code","75fc627c":"code","18462032":"code","019c39dd":"code","7f1ecbc0":"code","ac0d59e1":"code","2f84b052":"code","6e2a5da9":"code","676a9a58":"code","fc75ce8a":"code","e60ee55f":"code","88b048bf":"code","2e2a3095":"code","d8442b0c":"code","cb7d366e":"code","4adfc228":"code","34a5d5ee":"code","121768e2":"code","75f47a94":"code","69bdd3aa":"code","c3a4f438":"code","de1d2286":"code","4cdf28fc":"code","f5363c3a":"code","cf42b789":"code","58357192":"code","73ade3ba":"code","5b24346c":"code","1672a5ec":"code","9cbf078c":"code","99674208":"code","7d3a6f5f":"code","aa0296d1":"code","17737681":"code","b17ba81d":"code","914e17a1":"code","0844de2d":"code","71f7d83a":"code","72a4515f":"code","05d47c36":"code","8e854e17":"code","57fda230":"code","f409102b":"code","56dcda1d":"code","a5848ee5":"code","3dc2e37f":"code","7a5e6dc8":"code","c7a40a46":"code","c36bf009":"code","bb714812":"code","6ab913d9":"code","4764aded":"code","9be3247d":"code","a7560b04":"code","5f241f84":"code","6da9a6e6":"code","66539f5d":"code","6aba7c4f":"code","394379c2":"code","cd22ad3e":"markdown","1feeb485":"markdown","c52ed330":"markdown","ae930e00":"markdown","060beebb":"markdown","2d602392":"markdown","43077f76":"markdown","6add29ec":"markdown","27260481":"markdown","cb98788f":"markdown"},"source":{"e3beed70":"import os\nimport zipfile\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom shutil import copyfile\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV","0bc6d6e9":"csv_file='..\/input\/breast-cancer-prediction-dataset\/Breast_cancer_data.csv'\ndf=pd.read_csv(csv_file)\ndf","b2bf3697":"df.dtypes","4e5aab4b":"df_corr=df.corr()","ae2c94d8":"sns.heatmap(df_corr,annot=True,cmap='coolwarm')","9402d9d4":"# Dropping overlapped features\ndf.drop(['mean_radius','mean_area'],axis=1,inplace=True)","a57cd549":"df_2_corr=df.corr()","b4223b29":"sns.heatmap(df_2_corr,annot=True,cmap='coolwarm')","75fc627c":"df.diagnosis.value_counts()\/len(df)","18462032":"sns.countplot(y=df.diagnosis)","019c39dd":"df['target'] = df['diagnosis'].map({0:'B',1:'M'})\nsns.pairplot(df.drop('diagnosis', axis = 1), hue='target',palette='prism');","7f1ecbc0":"X = df.drop(['diagnosis','target'],axis=1)\nY = df['diagnosis']","ac0d59e1":"x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)","2f84b052":"x_train","6e2a5da9":"from sklearn.preprocessing import MinMaxScaler\n\nsc = MinMaxScaler()\nX_train = sc.fit_transform(x_train)\ny_train=np.array(y_train)\nX_test = sc.fit_transform(x_test)\ny_test=np.array(y_test)","676a9a58":"from sklearn.linear_model import LogisticRegression\n\nlog_clf=LogisticRegression()","fc75ce8a":"log_clf.fit(X_train,y_train)","e60ee55f":"y_pred=log_clf.predict(X_test)","88b048bf":"log_clf.score(X_test,y_test)","2e2a3095":"log_clf.score(X_train,y_train)","d8442b0c":"from sklearn.svm import SVC\n\nparam_grid = {'C': [0.1, 1, 10, 100, 1000], \n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n              'kernel': ['rbf']} \ngrid=GridSearchCV(SVC(),param_grid)","cb7d366e":"grid.fit(X_train,y_train)","4adfc228":"grid.best_params_","34a5d5ee":"svc=SVC(**grid.best_params_)","121768e2":"svc.fit(X_train,y_train)","75f47a94":"svc.score(X_train,y_train)","69bdd3aa":"svc.score(X_test,y_test)","c3a4f438":"from sklearn.metrics import confusion_matrix, plot_confusion_matrix\ny_pred=svc.predict(X_test)\ncm_svc = confusion_matrix(y_test, y_pred)\ncm_svc","de1d2286":"plot_confusion_matrix(svc,X_test,y_test)","4cdf28fc":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","f5363c3a":"from mpl_toolkits.mplot3d import Axes3D\nfig = plt.figure()\nfig.set_size_inches(9, 9)\ntmp = np.linspace(-5,5,30)\nx,y = np.meshgrid(tmp,tmp)\nax = fig.add_subplot(111, projection='3d')\nax.scatter(X_train[:,0][y_train==0], X_train[:,1][y_train==0],X_train[:,2][y_train==0],'ob')\nax.scatter(X_train[:,0][y_train==1], X_train[:,1][y_train==1],X_train[:,2][y_train==1],'sr')\nax.set_xlabel(f\"{x_train.columns[0]}\")\nax.set_ylabel(f\"{x_train.columns[1]}\")\nax.set_zlabel(f\"{x_train.columns[2]}\")\nax.view_init(30, 60)\nplt.show()","cf42b789":"from sklearn.ensemble import RandomForestClassifier\nrf= RandomForestClassifier()","58357192":"param_grid = { \n    'n_estimators': [50,100,200,500],\n    'max_features': ['auto', 'sqrt', 'log2'],\n    'max_depth' : [2,3,4,5,6,7,8],\n    'criterion' :['gini', 'entropy']\n}","73ade3ba":"grid_rf=GridSearchCV(rf,param_grid)","5b24346c":"grid_rf.fit(X_train,y_train)","1672a5ec":"grid_rf.best_params_","9cbf078c":"rf=RandomForestClassifier(**grid_rf.best_params_)","99674208":"rf.fit(X_train,y_train)","7d3a6f5f":"rf.score(X_train,y_train)","aa0296d1":"rf.score(X_test,y_test)","17737681":"y_pred=rf.predict(X_test)\ncm_rf = confusion_matrix(y_test, y_pred)\ncm_rf","b17ba81d":"plot_confusion_matrix(rf,X_test,y_test)","914e17a1":"print(classification_report(y_test, y_pred))","0844de2d":"from sklearn.ensemble import GradientBoostingClassifier\n\nGBC=GradientBoostingClassifier()","71f7d83a":"GBC.fit(X_train,y_train)","72a4515f":"GBC.score(X_train,y_train)","05d47c36":"GBC.score(X_test,y_test)","8e854e17":"from sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nHGBC=HistGradientBoostingClassifier()","57fda230":"HGBC.fit(X_train,y_train)","f409102b":"HGBC.score(X_train,y_train)","56dcda1d":"HGBC.score(X_test,y_test)","a5848ee5":"from sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import cross_val_score\n\neclf = VotingClassifier(\n    estimators=[('svc', svc), ('rf', rf), ('GBC', GBC),('HGBC',HGBC)],\n    voting='hard')\n\nfor clf_num, label in zip([svc, rf, GBC , HGBC], ['Support Vector Machine', 'Random Forest', 'GBC', 'HGBC']):\n    scores = cross_val_score(clf_num, X_train, y_train, scoring='accuracy', cv=5)\n    print(\"Accuracy: %0.2f (+\/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))","3dc2e37f":"eclf.fit(X_train, y_train)","7a5e6dc8":"eclf.score(X_train,y_train)","c7a40a46":"eclf.score(X_test,y_test)","c36bf009":"y_pred=eclf.predict(X_test)\ncm_rf = confusion_matrix(y_test, y_pred)\ncm_rf","bb714812":"plot_confusion_matrix(eclf,X_test,y_test)","6ab913d9":"print(classification_report(y_test, y_pred))","4764aded":"model=tf.keras.Sequential([\n    tf.keras.layers.Dense(10,activation='relu'),\n    tf.keras.layers.Dense(20,activation='relu'),\n    tf.keras.layers.Dense(1,activation='sigmoid')\n])","9be3247d":"model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","a7560b04":"history=model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=300)","5f241f84":"# PLOT LOSS AND ACCURACY\n%matplotlib inline\n\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\n\nacc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(epochs, loss, 'r', \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n\n\nplt.title('Training and validation loss')","6da9a6e6":"y_prediction=model.predict(X_test)\ncutoff=0.5\ny_pred=np.where(y_prediction>cutoff,1,0)","66539f5d":"cm_deep = confusion_matrix(y_test, y_pred)\ncm_deep","6aba7c4f":"cm_matrix = pd.DataFrame(data=cm_deep, columns=['Actual Positive:1', 'Actual Negative:0'], \n                                 index=['Predict Positive:1', 'Predict Negative:0'])\n\nsns.heatmap(cm_matrix, annot=True)","394379c2":"print(classification_report(y_test, y_pred))","cd22ad3e":"## Conclusion: I have tried 7 different models to train (linear, svc, random forest, gradientboosting, histgradientboosting, voting with 3 tree based & svc and deep learning), and voting method and deep learning have the best score. However, while voting model has more false negative, deep learning has more false positive and since false negative could bring more critical issues in breast cancer classification, deep learning algorithm shows the best result.","1feeb485":"## GradientBoostingClassifier","c52ed330":"##  Import related libraries","ae930e00":"## Random Forest","060beebb":"## Voting","2d602392":"## HistGradientBoostingClassifier","43077f76":"## SVC","6add29ec":"## Logistic Regression","27260481":"## Data preprocessing","cb98788f":"## Deep learning"}}