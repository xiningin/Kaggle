{"cell_type":{"1031dc62":"code","7ceab64c":"code","9d23bcac":"code","3011615c":"code","bc62f62c":"code","24ec924d":"code","f48e6fcd":"code","f82c7d73":"code","12d1a490":"code","faeb09db":"code","dec1a0f2":"code","16f98177":"code","0c33e4df":"code","95605cd0":"code","edd11cc0":"code","eaf7e1cc":"code","02eed33b":"code","04e23bc7":"code","aee7c4b0":"code","8eb84a5a":"code","ba63657a":"code","21badb24":"code","4d0902f4":"code","e1b60b15":"code","a618d257":"code","e60745b5":"code","5fb1b217":"code","bb37fcff":"code","bad45e4d":"code","f9675124":"code","bfd1b6a4":"code","9a9d7a87":"code","450f3869":"code","72075d23":"code","8c68e253":"code","e8bd0320":"code","61667ee1":"code","169a84df":"code","78585218":"code","96286444":"code","69e0a1ac":"code","e32b0130":"code","8ef86642":"code","ddf8c268":"code","2501c489":"code","d1584e57":"code","47495a7a":"code","8534041b":"code","8238123b":"code","d822b7ed":"code","6ae3d4be":"markdown","87ff6c19":"markdown","03e48a40":"markdown","3228048b":"markdown","d709425b":"markdown","b40c33f0":"markdown"},"source":{"1031dc62":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        \n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7ceab64c":"!pip install catboost","9d23bcac":"df_train=pd.read_csv(os.path.join(dirname,'train.csv'))\n\n","3011615c":"df_train","bc62f62c":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn import preprocessing\nfrom sklearn import datasets\nfrom sklearn import metrics\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.feature_selection import f_regression\nfrom matplotlib import pyplot\nimport tensorflow\ntensorflow.random.set_seed(1)\nfrom tensorflow.python.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.python.keras.models import Sequential\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nimport xgboost as xg \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import mean_squared_error as MSE \nfrom catboost import CatBoostRegressor\n","24ec924d":"df_train=pd.concat([df_train,pd.get_dummies(df_train.cat0,prefix='cat0')],axis=1)\ndf_train=df_train.drop(['cat0','cat0_B'],axis=1)\ndf_train=pd.concat([df_train,pd.get_dummies(df_train.cat1,prefix='cat1')],axis=1)\ndf_train=df_train.drop(['cat1','cat1_B'],axis=1)\ndf_train=pd.concat([df_train,pd.get_dummies(df_train.cat2,prefix='cat2')],axis=1)\ndf_train=df_train.drop(['cat2','cat2_B'],axis=1)\ndf_train=pd.concat([df_train,pd.get_dummies(df_train.cat3,prefix='cat3')],axis=1)\ndf_train=df_train.drop(['cat3','cat3_D'],axis=1)\ndf_train=pd.concat([df_train,pd.get_dummies(df_train.cat4,prefix='cat4')],axis=1)\ndf_train=df_train.drop(['cat4','cat4_D'],axis=1)\ndf_train=pd.concat([df_train,pd.get_dummies(df_train.cat5,prefix='cat5')],axis=1)\ndf_train=df_train.drop(['cat5','cat5_D'],axis=1)\n#df_train=pd.concat([df_train,pd.get_dummies(df_train.cat6,prefix='cat6')],axis=1)\ndf_train=df_train.drop(['cat6'],axis=1)\n#df_train=df_train.drop(['cat6','cat6_I'],axis=1)\ndf_train=pd.concat([df_train,pd.get_dummies(df_train.cat7,prefix='cat7')],axis=1)\ndf_train=df_train.drop(['cat7','cat7_I'],axis=1)\ndf_train=pd.concat([df_train,pd.get_dummies(df_train.cat8,prefix='cat8')],axis=1)\ndf_train=df_train.drop(['cat8','cat8_G'],axis=1)\ndf_train=pd.concat([df_train,pd.get_dummies(df_train.cat9,prefix='cat9')],axis=1)\ndf_train=df_train.drop(['cat9','cat9_O'],axis=1)","f48e6fcd":"df_train","f82c7d73":"y=df_train['target'].values\ndf_train=df_train.drop(['target'],axis=1)","12d1a490":"df_train","faeb09db":"X=df_train.iloc[:,1:].values","dec1a0f2":"df_train","16f98177":"negative_columns=np.any(X,axis=0)\nprint(negative_columns,negative_columns.shape)","0c33e4df":"names = df_train.iloc[:,1:].columns\nscaler = preprocessing.MinMaxScaler((0,1))\nscaled_df = scaler.fit_transform(df_train.iloc[:,1:])\nscaled_df = pd.DataFrame(scaled_df, columns=names)","95605cd0":"X=scaled_df.values","edd11cc0":"X.shape","eaf7e1cc":"X.shape","02eed33b":"'''from sklearn.decomposition import PCA \n   \npca = PCA(n_components = 20) \npca.fit(X) \nx_pca = pca.transform(X) \n  \nx_pca.shape '''","04e23bc7":"df_test=pd.read_csv(os.path.join(dirname,'test.csv'))","aee7c4b0":"df_test=pd.concat([df_test,pd.get_dummies(df_test.cat0,prefix='cat0')],axis=1)\ndf_test=df_test.drop(['cat0','cat0_B'],axis=1)\ndf_test=pd.concat([df_test,pd.get_dummies(df_test.cat1,prefix='cat1')],axis=1)\ndf_test=df_test.drop(['cat1','cat1_B'],axis=1)\ndf_test=pd.concat([df_test,pd.get_dummies(df_test.cat2,prefix='cat2')],axis=1)\ndf_test=df_test.drop(['cat2','cat2_B'],axis=1)\ndf_test=pd.concat([df_test,pd.get_dummies(df_test.cat3,prefix='cat3')],axis=1)\ndf_test=df_test.drop(['cat3','cat3_D'],axis=1)\ndf_test=pd.concat([df_test,pd.get_dummies(df_test.cat4,prefix='cat4')],axis=1)\ndf_test=df_test.drop(['cat4','cat4_D'],axis=1)\ndf_test=pd.concat([df_test,pd.get_dummies(df_test.cat5,prefix='cat5')],axis=1)\ndf_test=df_test.drop(['cat5','cat5_D'],axis=1)\n#df_test=pd.concat([df_test,pd.get_dummies(df_test.cat6,prefix='cat6')],axis=1)\ndf_test=df_test.drop(['cat6'],axis=1)\n#df_test=df_test.drop(['cat6','cat6_I'],axis=1)\ndf_test=pd.concat([df_test,pd.get_dummies(df_test.cat7,prefix='cat7')],axis=1)\ndf_test=df_test.drop(['cat7','cat7_I'],axis=1)\ndf_test=pd.concat([df_test,pd.get_dummies(df_test.cat8,prefix='cat8')],axis=1)\ndf_test=df_test.drop(['cat8','cat8_G'],axis=1)\ndf_test=pd.concat([df_test,pd.get_dummies(df_test.cat9,prefix='cat9')],axis=1)\ndf_test=df_test.drop(['cat9','cat9_O'],axis=1)","8eb84a5a":"df_test","ba63657a":"X_test=df_test.iloc[:,1:].values","21badb24":"X_test.shape","4d0902f4":"#x_test_pca = pca.transform(X_test) ","e1b60b15":"id_=df_test.iloc[:,0].values","a618d257":"names_test= df_test.iloc[:,1:].columns\nscaled_df_test = scaler.transform(df_test.iloc[:,1:])\nscaled_df_test = pd.DataFrame(scaled_df_test, columns=names_test)\nX_test=scaled_df_test.values","e60745b5":"X_test.shape","5fb1b217":"\ndef select_features(X_train, y_train, X_test):\n    # configure to select all features\n    fs = SelectKBest(score_func=f_regression, k='all')\n    # learn relationship from training data\n    fs.fit(X_train, y_train)\n    # transform train input data\n    X_train_fs = fs.transform(X_train)\n    # transform test input data\n    X_test_fs = fs.transform(X_test)\n    return X_train_fs, X_test_fs, fs\n\n","bb37fcff":"X.shape,X_test.shape","bad45e4d":"X_train_fs, X_test_fs, fs = select_features(X, y, X_test)\n\nfor i in range(len(fs.scores_)):\n    print('Feature %d: %f' % (i, fs.scores_[i]))\n\npyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\npyplot.show()","f9675124":"X_train_fs.shape","bfd1b6a4":"xgb = xg.XGBRegressor(objective ='reg:linear', \n                  n_estimators = 53, seed = 123) \n  \nxgb.fit(X_train_fs, y) \n  \npred = xgb.predict(X_test_fs) \n  \n","9a9d7a87":"pred.shape","450f3869":"csvlist=[]\nfor i in range(pred.shape[0]):\n    csvlist.append([id_[i],pred[i]])","72075d23":"Output=pd.DataFrame(csvlist,columns=['id','target'])\nOutput.to_csv('output_XGB.csv',index=False)\n","8c68e253":"model=CatBoostRegressor(iterations=100, depth=10, learning_rate=0.01, loss_function='RMSE')","e8bd0320":"model.fit(X_train_fs,y ,plot=True)","61667ee1":"pred=model.predict(X_test_fs)\n","169a84df":"csvlist=[]\nfor i in range(pred.shape[0]):\n    csvlist.append([id_[i],pred[i]])","78585218":"Output=pd.DataFrame(csvlist,columns=['id','target'])\nOutput.to_csv('output_CATBOOST.csv',index=False)\n","96286444":"model = Sequential()\nmodel.add(Dense(53, input_dim=20, kernel_initializer='normal', activation='relu'))\nmodel.add(Dense(2670, activation='relu'))\nmodel.add(Dense(1345, activation='relu'))\nmodel.add(Dense(1, activation='linear'))\nmodel.summary()","69e0a1ac":"model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\nearlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\nmcp_save = ModelCheckpoint('model_pca_MLP.h5', save_best_only=True, monitor='val_loss', mode='min')\nreduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=5, verbose=1, epsilon=1e-4, mode='min')\nhistory_pl = model.fit(X_train_fs,y, batch_size=128, epochs=30, verbose=1, \n                       callbacks=[earlyStopping, mcp_save,reduce_lr_loss], validation_split=0.25 )\n","e32b0130":"model = Sequential()\nmodel.add(Dense(53, input_dim=20, kernel_initializer='normal', activation='relu'))\nmodel.add(Dense(2670, activation='relu'))\nmodel.add(Dense(1345, activation='relu'))\nmodel.add(Dense(1, activation='linear'))\nmodel.summary()\nmodel.load_weights('model_pca_MLP.h5')","8ef86642":"X_train_fs.shape,X_test_fs.shape","ddf8c268":"predictions = model.predict(X_test_fs)","2501c489":"predictions.shape,id_.shape\n","d1584e57":"list(predictions[:,0]),list(id_)","47495a7a":"predictions[0][0]","8534041b":"predictions.shape,id_.shape","8238123b":"csvlist=[]\nfor i in range(predictions.shape[0]):\n    csvlist.append([id_[i],predictions[i][0]])","d822b7ed":"Output=pd.DataFrame(csvlist,columns=['id','target'])\nOutput.to_csv('output.csv',index=False)\n","6ae3d4be":"Normalizing Input features","87ff6c19":"PCA","03e48a40":"MLP","3228048b":"Feature Selection ( MUTUAL INFORMATION)","d709425b":"CATBOOST","b40c33f0":"XGBOOST"}}