{"cell_type":{"039d5988":"code","adebb0e1":"code","59e800d8":"code","820caee9":"code","fd48c299":"code","d621cb7c":"code","7edd08d9":"code","35b1f817":"code","6f5d9f34":"code","e0b8031d":"code","62cc877c":"code","c2eb81be":"code","61aaffde":"code","27af0e10":"code","f9355249":"code","f00deaf8":"code","a884b154":"code","2dc57e6d":"code","0ff9b501":"code","a5068780":"markdown","a9c22add":"markdown"},"source":{"039d5988":"import os\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold\nimport itertools\nimport xgboost as xgb\nimport time\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import *","adebb0e1":"X_train = pd.read_csv(\"..\/input\/X_train.csv\")\nX_test = pd.read_csv(\"..\/input\/X_test.csv\")\ny_train = pd.read_csv(\"..\/input\/y_train.csv\")\nsub = pd.read_csv(\"..\/input\/sample_submission.csv\")","59e800d8":"X_train.head()","820caee9":"plt.figure(figsize=(15, 5))\nsns.countplot(y_train['surface'])\nplt.title('Target distribution', size=15)\nplt.show()","fd48c299":"# https:\/\/www.kaggle.com\/jesucristo\/1-smart-robots-complete-notebook-0-73\/notebook\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(X_train.iloc[:,3:].corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","d621cb7c":"#https:\/\/www.kaggle.com\/prashantkikani\/help-humanity-by-helping-robots\n\ndef fe(data):\n    \n    df = pd.DataFrame()\n    data['totl_anglr_vel'] = (data['angular_velocity_X']**2 + data['angular_velocity_Y']**2 +\n                             data['angular_velocity_Z']**2)** 0.5\n    data['totl_linr_acc'] = (data['linear_acceleration_X']**2 + data['linear_acceleration_Y']**2 +\n                             data['linear_acceleration_Z'])**0.5\n    data['totl_xyz'] = (data['orientation_X']**2 + data['orientation_Y']**2 +\n                             data['orientation_Z'])**0.5\n   \n    data['acc_vs_vel'] = data['totl_linr_acc'] \/ data['totl_anglr_vel']\n    \n    for col in data.columns:\n        if col in ['row_id','series_id','measurement_number']:\n            continue\n        df[col + '_mean'] = data.groupby(['series_id'])[col].mean()\n        df[col + '_median'] = data.groupby(['series_id'])[col].median()\n        df[col + '_max'] = data.groupby(['series_id'])[col].max()\n        df[col + '_min'] = data.groupby(['series_id'])[col].min()\n        df[col + '_std'] = data.groupby(['series_id'])[col].std()\n        df[col + '_range'] = df[col + '_max'] - df[col + '_min']\n        df[col + '_maxtoMin'] = df[col + '_max'] \/ df[col + '_min']\n        df[col + '_mean_abs_chg'] = data.groupby(['series_id'])[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        df[col + '_abs_max'] = data.groupby(['series_id'])[col].apply(lambda x: np.max(np.abs(x)))\n        df[col + '_abs_min'] = data.groupby(['series_id'])[col].apply(lambda x: np.min(np.abs(x)))\n        df[col + '_abs_avg'] = (df[col + '_abs_min'] + df[col + '_abs_max'])\/2\n    return df\n","7edd08d9":"%%time\nX_train = fe(X_train)\nX_test = fe(X_test)\nprint(X_train.shape)","35b1f817":"le = LabelEncoder()\ny_train['surface'] = le.fit_transform(y_train['surface'])\n","6f5d9f34":"X_train.fillna(0, inplace = True)\nX_test.fillna(0, inplace = True)\nX_train.replace(-np.inf, 0, inplace = True)\nX_train.replace(np.inf, 0, inplace = True)\nX_test.replace(-np.inf, 0, inplace = True)\nX_test.replace(np.inf, 0, inplace = True)","e0b8031d":"#X_train.drop('row_index', axis=1)\n#X_test.drop(['row_index'], axis=1)\ndata = X_train\ntarget = y_train[\"surface\"]\nprint(X_train.shape)\nprint(X_test.shape)\n","62cc877c":"from sklearn.model_selection import GridSearchCV,StratifiedKFold, train_test_split\nkfold = StratifiedKFold(n_splits=5)\nfrom sklearn.metrics import roc_auc_score,roc_curve,auc\ntrain_x,val_x,train_y,val_y = train_test_split(data, target, test_size = 0.10, random_state=14)\ntrain_x.shape,val_x.shape,train_y.shape,val_y.shape","c2eb81be":"import lightgbm\ntrain_data = lightgbm.Dataset(train_x, label=train_y)\ntest_data = lightgbm.Dataset(val_x, label=val_y)","61aaffde":"#used tuned parameters after applying gridsearch\npara={'boosting_type': 'gbdt',\n 'colsample_bytree': 0.85,\n 'learning_rate': 0.1,\n 'max_bin': 512,\n 'max_depth': -1,\n 'metric': 'multi_error',\n 'min_child_samples': 8,\n 'min_child_weight': 1,\n 'min_split_gain': 0.5,\n 'nthread': 3,\n 'num_class': 9,\n 'num_leaves': 31,\n 'objective': 'multiclass',\n 'reg_alpha': 0.8,\n 'reg_lambda': 1.2,\n 'scale_pos_weight': 1,\n 'subsample': 0.7,\n 'subsample_for_bin': 200,\n 'subsample_freq': 1}\n\nmodel = lightgbm.train(para,\n                       train_data,\n                       valid_sets=test_data,\n                       num_boost_round=5000,\n                       early_stopping_rounds=50,\n                      )","27af0e10":"y_pred = model.predict(X_test)","f9355249":"class_prediction=pd.DataFrame(y_pred).idxmax(axis=1) ","f00deaf8":"submission1 = pd.DataFrame({\n        \"series_id\": X_test.index,\n        \"surface\": class_prediction,\n        \n    })\nsubmission1.surface.value_counts()","a884b154":"submission1.surface=le.inverse_transform(submission1.surface)","2dc57e6d":"submission1.head()","0ff9b501":"submission1.to_csv('submissionlgb.csv', index=False)","a5068780":"### Feature Engineer","a9c22add":"Here we can discover strong correlation between angular_velocity_Z and angular_velocity_Y.\n"}}