{"cell_type":{"b5b68da0":"code","76e11afa":"code","0bd659a1":"code","1d84c007":"code","02d24158":"code","cced8a25":"code","12954bc0":"code","16b7571b":"code","fec34a57":"markdown","7993f1c0":"markdown","03256a9f":"markdown","9b89144a":"markdown","95d939d3":"markdown","b2aaaba4":"markdown"},"source":{"b5b68da0":"import cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","76e11afa":"train_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')","0bd659a1":"image_id = (train_df['id_code'])[1]\npath = f\"..\/input\/train_images\/{image_id}.png\"\nimg = cv2.imread(path)\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) ## note that cv.imread() gives BGR array, so need convert it to RGB array","1d84c007":"img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nplt.gray()\nplt.imshow(img)","02d24158":"tol = 5\nmask = img > tol\n\nnz_rows = mask.any(1)  ## filter rows where all values are less than tol out\nnz_cols = mask.any(0)  ## filter cols where all values are less than tol out\n\nimg = img[np.ix_(nz_rows, nz_cols)]\nplt.imshow(img)","cced8a25":"img = cv2.resize(img, (224, 224))\nplt.imshow(img)","12954bc0":"kernel_size = (0, 0)\nsigma_XY = 224\/10\nimg2 = cv2.GaussianBlur(img, kernel_size, sigma_XY)\nplt.imshow(img2)","16b7571b":"img = cv2.addWeighted(img, 4, img2, -4, 128)  ## img = 4 * img - 4 * img2 + 128\nplt.imshow(img)  ## sharpened image","fec34a57":"## Import packages","7993f1c0":"### Sharpen image\nSharpen the image by subtracting blured image, and add mean level.\n\nIn fact, I don't understand how magic numbers (used for cv2.GaussianBlur() and cv2.addWeighted()) are determined.\nAnyway, you can find the basic concept of this process (i.e., using Gaussian Blur as low-pass filter) in various articles (the URL below, for example).\n\nhttps:\/\/stackoverflow.com\/questions\/4993082\/how-to-sharpen-an-image-in-opencv","03256a9f":"## Convert image into gray-scale\n\nConvert a BGR image into a gray-scale image by cv2.cvtColor().\nBecause better performances are achieved with more information in general, I have no confidence that I should always discard information of colors. However, at least there are several reasons which justify to discard them:\n\n1. As mentioned by the organizer, the images were taken with various kinds of cameras, so color information could work as noise. (\"The images were gathered from multiple clinics using a variety of cameras over an extended period of time, which will introduce further variation.\")\n\n2. Images in this dataset are not so colorful, and it's likely that imformation of colors are not so extensively useful for this competitions. (Though I have no perfect confidence about it, because I'm not a doctor!)\n\n3. Discard colors can reduce data size and could save computing time.","9b89144a":"\n## Purpose of this kernel\n\nHi, I've been interested in image processing world for a long time, and finally joined APTOS competition.\n\nSame as other novice competitors, I begun to read discussions and kernels witten by other competitors, and I especially enjoyed Michael Kazachok's nice kernel (https:\/\/www.kaggle.com\/miklgr500\/auto-encoder), which demonstrate auto encoder technique and apply PCA on image data, because his kernel gave me great insight about how dataset are distributed.\n\n\nIn adittion, I learned elementary techniques to preprocess image data from Kazachok's kernel, so write this kernel which introduce how to read and preprocess images for newcomers like me.\n\nAny comments for clarification and correction are welcome.","95d939d3":"## Read image\n\nUse cv2(OpenCV) package's imread() to read images.","b2aaaba4":"## Clip and resize\n\nCut off outside of retina image, and resize it into handy size."}}