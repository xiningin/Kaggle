{"cell_type":{"45d8b413":"code","4adf3123":"code","4e91c8b1":"code","76cd0fc0":"code","b0537f18":"code","abd8e810":"code","1bf384b6":"code","badfcf75":"code","40e455ee":"code","6c116991":"code","a0641e46":"code","41c482f2":"code","ac4a1eb1":"code","ec4820d1":"code","c0f8f665":"code","d6b2d422":"code","ea162311":"code","3f724afc":"code","7893be3e":"code","cbda996f":"markdown","45aeea36":"markdown","a9eb3e89":"markdown","3019da5b":"markdown","af7094f2":"markdown","9b4466d0":"markdown","9a7e30ea":"markdown","6b1e71de":"markdown","312a4a8e":"markdown","6f41ce6d":"markdown","e582cb3f":"markdown","865c36e8":"markdown","10ac763c":"markdown","fe8dc462":"markdown"},"source":{"45d8b413":"import shap\nimport numpy  as np\nimport pandas as pd\nimport plotly.express as px\nimport matplotlib.pyplot as plt\n\nfrom sklearn.impute   import SimpleImputer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics  import accuracy_score, auc, roc_curve, precision_recall_curve, roc_auc_score, precision_score, recall_score, average_precision_score\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost  import XGBClassifier\n\nplt.style.use('ggplot')","4adf3123":"def evaluate(model, testing_set_x, testing_set_y):\n    predictions = model.predict_proba(testing_set_x)\n    \n    accuracy  = accuracy_score(testing_set_y, predictions[:,1] >= 0.5)\n    roc_auc   = roc_auc_score(testing_set_y, predictions[:,1])\n    precision = precision_score(testing_set_y, predictions[:,1] >= 0.5)\n    recall    = recall_score(testing_set_y, predictions[:,1] >= 0.5)\n    pr_auc    = average_precision_score(testing_set_y, predictions[:,1])\n    \n    result = pd.DataFrame([[accuracy, precision, recall, roc_auc, pr_auc]], columns=['Accuracy', 'Precision', 'Recall', 'ROC_auc','PR_auc'])\n    return(result)","4e91c8b1":"def run_experiment(df, model_class, n = 100, **kwargs):\n    results = pd.DataFrame(columns=['Accuracy', 'Precision', 'Recall', 'ROC_auc','PR_auc'])\n    for i in range(n):\n        # Compose dataset\n        train_x, test_x = train_test_split(df.drop('PATIENT_VISIT_IDENTIFIER', axis=1),\n                               test_size = 0.3,\n                               stratify  = df['ICU'],\n                               random_state = i\n                                )\n        \n        train_y = train_x.pop('ICU')\n        test_y  = test_x.pop('ICU')\n        \n        # Train Model\n        model = model_class(**kwargs)\n        model.fit(train_x, train_y)\n         \n        # Evaluate results\n        current_result = evaluate(model, test_x, test_y)\n        results = results.append(current_result)\n        \n    return(results.reset_index(drop=True))","76cd0fc0":"def print_results(df, plot = True, extras = False, color='dodgerblue'):\n    print('|||||||||||||||||||||||||||||||||||||||||||||||||||||||')\n    print('[ Experiment Results ]')\n    print('Accuracy:   {}'.format(df.Accuracy.mean()))\n    print('Precision:  {}'.format(df.Precision.mean()))\n    print('Recall:     {}'.format(df.Recall.mean()))\n    print('ROC Auc:    {}'.format(df.ROC_auc.mean()))\n    print('PR Auc:     {}'.format(df.PR_auc.mean()))\n    print('|||||||||||||||||||||||||||||||||||||||||||||||||||||||')\n    \n    if plot:\n        fig = px.box(df.melt(var_name='metric'),\n                       y = 'metric',\n                       x = 'value',\n                       title = 'Distribution of Metric Values Across 100 Runs',\n                       color_discrete_sequence=[color]\n                      )\n\n        fig.update_xaxes(title='Metric')\n        fig.update_yaxes(title='Value')\n\n        fig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 00)',\n                           'paper_bgcolor': 'rgba(240, 240, 240, 100)'})\n        fig.show()\n        \n        \n    if extras:\n        print('Also, the maximum results were:')\n        print('    Accuracy:   {}'.format(df.Accuracy.max()))\n        print('    Precision:  {}'.format(df.Precision.max()))\n        print('    Recall:     {}'.format(df.Recall.max()))\n        print('    ROC Auc:    {}'.format(df.ROC_auc.max()))\n        print('    PR Auc:     {}'.format(df.PR_auc.max()))","b0537f18":"# Read data\nraw_data = pd.read_excel('..\/input\/covid19\/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx')\nraw_data.sample(5)\n\n# Data Preparation\nraw_data['AGE_PERCENTIL'] = raw_data['AGE_PERCENTIL'].str.replace('Above ','').str.extract(r'(.+?)th')\nraw_data['WINDOW'] = raw_data['WINDOW'].str.replace('ABOVE_12','12-more').str.extract(r'(.+?)-')\n\n# Missingness as features\nraw_data['row_missingness'] = raw_data.isnull().sum(axis=1)\n\n# Mean imputation\nmean_impute  = SimpleImputer(strategy='mean')\nimputed_data = mean_impute.fit_transform(raw_data)\nimputed_data = pd.DataFrame(imputed_data, columns = raw_data.columns)","abd8e810":"# Check imbalance\nraw_data['ICU'].value_counts()","1bf384b6":"rf_optimal = {\n              'n_estimators':2100,\n              'max_depth':27,\n              'max_features':0.15,\n              'max_samples':0.5363991145732665,\n              'min_samples_split':2,\n              'min_samples_leaf':4,\n              'n_jobs':-1,\n              'random_state':451,\n            }","badfcf75":"rf_experiment = run_experiment(imputed_data, model_class = RandomForestClassifier, **rf_optimal)\nprint_results(rf_experiment, color = '#3F3F3F')","40e455ee":"optimal_1 = {'learning_rate': 0.02956340635276464,\n 'n_estimators': 3831,\n 'num_leaves': 101,\n 'max_depth': 28,\n 'max_bin': 211,\n 'bagging_freq': 9,\n 'bagging_fraction': 0.9292245982209768,\n 'feature_fraction': 0.95,\n 'lambda_l1': 2.50667180728151,\n 'lambda_l2': 4.010110517090694,\n 'drop_rate': 0.5917712341785191,\n 'min_child_samples': 15,\n 'min_child_weight': 3,\n 'min_split_gain': 0.0,\n 'scale_pos_weight': 0.283126887443018,\n 'boosting_type': 'gbdt',\n 'bagging_seed': 42,\n 'metric': 'auc',\n 'verbosity': -1,\n 'random_state': 451,\n 'max_drop': 50}","6c116991":"optimal_2 = {'learning_rate': 0.05744913989406643,\n 'n_estimators': 2067,\n 'num_leaves': 8,\n 'max_depth': 27,\n 'max_bin': 384,\n 'bagging_freq': 5,\n 'bagging_fraction': 0.7038650070406707,\n 'feature_fraction': 0.4806588217742334,\n 'lambda_l1': 2.841137907985995,\n 'lambda_l2': 5.983397074528167,\n 'drop_rate': 0.490746746058113,\n 'min_child_samples': 3,\n 'min_child_weight': 0,\n 'min_split_gain': 0.0,\n 'scale_pos_weight': 9.91024410907254,\n 'boosting_type': 'gbdt',\n 'bagging_seed': 42,\n 'metric': 'auc',\n 'verbosity': -1,\n 'random_state': 451,\n 'max_drop': 50}","a0641e46":"optimal_3 = {'learning_rate': 0.05744913989406643,\n 'n_estimators': 2067,\n 'num_leaves': 8,\n 'max_depth': 27,\n 'max_bin': 384,\n 'bagging_freq': 5,\n 'bagging_fraction': 0.7038650070406707,\n 'feature_fraction': 0.4806588217742334,\n 'lambda_l1': 2.841137907985995,\n 'lambda_l2': 5.983397074528167,\n 'drop_rate': 0.490746746058113,\n 'min_child_samples': 3,\n 'min_child_weight': 0,\n 'min_split_gain': 0.0,\n 'scale_pos_weight': 0.91024410907254,\n 'boosting_type': 'gbdt',\n 'bagging_seed': 42,\n 'metric': 'auc',\n 'verbosity': -1,\n 'random_state': 451,\n 'max_drop': 50}","41c482f2":"# Model #1\nlgbm_experiment_1 = run_experiment(imputed_data, model_class = LGBMClassifier, **optimal_1)\nprint_results(lgbm_experiment_1, color = '#8400E8')","ac4a1eb1":"# Model #2\nlgbm_experiment_2 = run_experiment(imputed_data, model_class = LGBMClassifier, **optimal_2)\nprint_results(lgbm_experiment_2, color = '#00E800')","ec4820d1":"# Model #3\nlgbm_experiment_3 = run_experiment(imputed_data, model_class = LGBMClassifier, **optimal_3)\nprint_results(lgbm_experiment_3, extras=True, color = '#00A4E8')","c0f8f665":"# Lets train a single model first\ntrain_x, test_x = train_test_split(imputed_data.drop('PATIENT_VISIT_IDENTIFIER', axis=1),\n                                   test_size = 0.3,\n                                   stratify  = imputed_data['ICU'],\n                                   random_state = 451\n                                  )\n        \ntrain_y = train_x.pop('ICU')\ntest_y  = test_x.pop('ICU')\n\n\nmodel = LGBMClassifier(**optimal_3)\nmodel.fit(train_x, train_y)","d6b2d422":"# Extract shap values\nexplainer   = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(train_x)","ea162311":"# Average feature contribution\nplt.title('Average Feature Contribution for each Class')\nshap.summary_plot(shap_values, train_x, plot_type=\"bar\")","3f724afc":"# Granular feature contribution plot\nplt.title('Feature Contribution According to Value')\nshap.summary_plot(shap_values[1], train_x, plot_size = (15,10))","7893be3e":"shap.initjs()\nshap.force_plot(explainer.expected_value[1], shap_values[1][0:50], train_x[0:50])","cbda996f":"> From this plot we can see the most important features as per their SHAP values, and the top 20 features show a rather balanced pattern in contribution for each class.\n\n> The importance of `AGE_PERCENTIL` is somewhat unexpected. While the age may relate to many phenomena it is hardly ever powerful in predicting anything specific. A feature so broad having such impact could be indactive of selection bias within the dataset.\n\n> It is just a suspicion, but we have to factor the average patient profile of this hospital, as well as the possibility that media broadcasting certain age groups as risk groups could cause them to change their behaviour during that time, and such temporal shift of behaviour could affect the dataset.","45aeea36":"## Abstract\n\n\n\n### **Methods**\n> - **Data preparation**: Mean imputation, really minor feature engineering.\n\n> - **Data split**: Stratified 70\/30 split.\n\n> - **Models**: 3x LightGBM (major), Randomforest (baseline).\n\n> - **Evaluation**: Results were extracted as the mean of 100 executions, all varying the dataset splits while preserving stratification.\n\n> - **Metrics**: Precision-recall auc and ROC auc as primary metrics, precision, recall and accuracy as secondary.\n\n> - **Hyperparameter tunning**: Nevergrad, gaussian mixture, lagrangian relaxation and manual inputs.\n    \n\n### **Results**\n> - Accuracy:   0.8796885813148784\n- Precision:  0.8321628618100186\n- Recall:     0.6916774193548385\n- ROC Auc:    0.9268143064134833\n- PR Auc:     0.8611576142950069\n\n### **Conclusion**\n\n> The model is only as relevant as it the way it is integrated into practice. To that extent there are models with higher precision or higher recall with the same tier of overall performance, which could allow for different benefits, such as optimized resource allocation and screening aid respectively, though the present models are far more consistent in precision than recall.\n\n> The variable composition makes these models very acessible which could have an enormous impact in the lens of public health and 150 million people that rely on SUS for their healthcare needs.\nFor as much as machine learning may drive progress in the fight against the pandemic, its implementation is just as challenging.\n\n\n\nMinor disclaimer: Still a work in progress... I'll work on interpretability and some pathways to implementation in the future.","a9eb3e89":"## Data Preparation\n\nNothing fancy, basicaly turned the 'categorical' variables into numerics.\n\n#### Missingness Imputation\nThere is considerable missingness in the dataset, which is to be expected as not every patient made the same set of exams.\nWith that said, I tested mean, median and raw imputation (-2 for every np.nan), and mean imputation came out on top.\n\n\n#### Missingness as a feature\n\n> \"Our bugs are just additional features\" - Dark Souls franchise ([reference](https:\/\/www.youtube.com\/watch?v=hWbZZslsKqc&t=196))\n\nThe very missingness in the data sheds lights on how many procedures our patient went through.\nThis could be indicative of complications, or at the very least indicate that the values were imputed rather than measured, so we'll make a feature out of missingness within each row.","3019da5b":"> This plot has a gigantic wealth of knowledge.\n\n> From the first two features, we can see that respiratory rate is key, and the mean is possibly being blinded by extremes when measuring, causing max to be more assertive.\n\n> The `OTHER` feature carries some relevant signal and it is therefore recommended to unpack whatever is inside that feature.\n\n> There is more to extract from this plot, and this is still only the top 20 features of the 230.","af7094f2":"### Closing Remarks\n\nSo there we have it, our best Lightgbm achieves Precision-Recall Auc of **0.86** and ROC Auc of **0.92**.\nAlso, the models present different patterns of average precision and recall, which allows for flexibility depending on the task in which the model will be deployed to help.\n\nOne such example would be to use the recall model as a screening aid and the precision model for resource allocation (staff, exams, etc).\nIt is also worth noting that the we should not exclude the possibility of a selection bias in the dataset composition, as specific hospitals may catter to specific patients as well.\n\nIf there's any question just let me know, Cheers :)","9b4466d0":"### Model Interpretation\n\nLet's make use of [SHAP](https:\/\/www.nature.com\/articles\/s42256-019-0138-9.epdf?shared_access_token=RCYPTVkiECUmc0CccSMgXtRgN0jAjWel9jnR3ZoTv0O81kV8DqPb2VXSseRmof0Pl8YSOZy4FHz5vMc3xsxcX6uT10EzEoWo7B-nZQAHJJvBYhQJTT1LnJmpsa48nlgUWrMkThFrEIvZstjQ7Xdc5g%3D%3D) as a way to leverage understanding from our model.","9a7e30ea":"## Auxiliar Functions","6b1e71de":"#### Data Split\nFor splitting data under class imbalance as we have here, I made sure to stratify by the labels in order to ensure consistent results at the end.\nThe `ICU` label has an imbalance in the realms of 30\/70, where a **baseline accuracy is set at 73.25%**.","312a4a8e":"> Here we have a sample of 50 rows and by using the cursor we can have a rough idea of why a particular region was classified in such way. The default settings \"sample order by similarity\" groups similar rows.\n\n> While there is no definite range where the model always outputs a class, every region associated with positive COVID-19 diagnosis has respiratory variables driving such decision. The fact that the model has no definitive regions is a good sign, as the variables are not specific and other diseases could cause similar values.","6f41ce6d":"### Hyperparameter Tunning\n\nAll parameters were obtained by a mix of optimization and manual input.\nI used facebook's nevergrad library and a few others in order to create distinct, yet performatic models.","e582cb3f":"![](https:\/\/i.redd.it\/8xj5uz79yon41.jpg)\n\"*We are waves on the same ocean, leafs from the same tree, flowers from the same garden.*\" - Chinese doctors upon disembarking on Italy","865c36e8":"### Future Updates\n\n- Add more models;\n- Add feature engineering.","10ac763c":"### Random Forest Baseline\n\nAs part of a methodological choice, I chose to create a random forest as a baseline for the next models.\nRather than blindly going for the usual suspects (Catboost, Lightgbm, DNNs).\n\nThe not greedy pattern of bagging makes the results very consistent with little effort.\nAs far as my opinion is concerned, Random forests are great baselines, but hardly ever the best final models - yet the goal here is to have a strong foundation of what improving the score will look like.\n\n","fe8dc462":"#### Model Evaluation\nAs the data presented is not particularly large, and the imbalanced exarcebates this issue, I'll use multiple runs of the same experiment in order to increase the trustworthyness of the results.\nFurthermore, I'll also make sure that every set of data is stratified, as to increase the consistency of training and evaluation.\n\nThis is very much recommeded, both by small size, but also due to the stakes of our model: **human lives**."}}