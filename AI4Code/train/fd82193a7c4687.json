{"cell_type":{"6ca85b2f":"code","a0580de4":"code","54170965":"code","d098028b":"code","600cd518":"code","231849fa":"code","a478b8da":"code","059f1032":"code","cfdbb0a0":"code","ba391316":"code","5e0602ab":"code","8be1617e":"code","65785492":"code","29c57fbe":"code","5b069b27":"code","1d61d7eb":"code","c62e776b":"code","168e7a01":"code","4a7d087b":"code","2580342f":"code","499055bc":"code","96cd6606":"code","cd4ea47d":"markdown","991b8932":"markdown","0fe5c074":"markdown","fe1067ad":"markdown","880b1da5":"markdown"},"source":{"6ca85b2f":"import sys\nimport os\nimport gc\nimport random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb\nimport optuna\nimport warnings\nwarnings.simplefilter('ignore')\n\nSEED=2021\ndef seed_all(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\nseed_all(SEED)","a0580de4":"anime = pd.read_csv('..\/input\/anime-recommendation-database-2020\/anime.csv')\nrating = pd.read_csv('..\/input\/anime-recommendation-database-2020\/rating_complete.csv')","54170965":"print(f\"\"\"\nanime: shape:{anime.shape}\nanime_num: {len(anime.MAL_ID.unique())}\n\"\"\"\n)\nanime.head()","d098028b":"print(f\"\"\"\nrating: shape:{rating.shape}\nuser_num: {len(rating.user_id.unique())}\nanime_num: {len(rating.anime_id.unique())}\n\"\"\")\nrating.head()","600cd518":"# rating dataset is large so sample some records.\nrating = rating.sample(frac=0.1)\nprint(f\"\"\"\nsampled rating\nshape:{rating.shape}\nuser_num: {len(rating.user_id.unique())}\nanime_num: {len(rating.anime_id.unique())}\n\"\"\")","231849fa":"# use anime features\nanime_features = ['MAL_ID','English name','Japanese name','Score','Genres','Popularity','Members',\n            'Favorites','Watching','Completed','On-Hold','Dropped',\n            'Score-1','Score-2','Score-3','Score-4','Score-5',\n            'Score-6','Score-7','Score-8','Score-9','Score-10',\n           ]\nanime = anime[anime_features]","a478b8da":"# merge anime and rating\nmerged_df = anime.merge(rating, left_on='MAL_ID', right_on='anime_id', how='inner')\nprint(merged_df.shape)\nmerged_df.head()","059f1032":"del anime\ndel rating\ngc.collect()","cfdbb0a0":"# use genres\ngenre_names = [\n    'Action', 'Adventure','Comedy',\n    'Slice of Life','Drama','Sci-Fi',\n    'Game','Harem','Military','Space','Music', 'Mecha',\n     'Historical', 'Mystery', 'School', 'Hentai', 'Fantasy', 'Horror',\n     'Kids', 'Sports', 'Magic', 'Romance', \n]\n\n\ndef genre_to_category(df):\n    '''Add genre cagegory column\n    '''\n    d = {name :[] for name in genre_names}\n    \n    def f(row):\n        genres = row.Genres.split(',')\n        for genre in genre_names:\n            if genre in genres:\n                d[genre].append(1)\n            else:\n                d[genre].append(0)\n\n    # create genre category dict\n    df.apply(f, axis=1)\n    \n    # add genre category\n    genre_df = pd.DataFrame(d, columns=genre_names)\n    df = pd.concat([df, genre_df], axis=1)\n    return df\n\ndef make_anime_feature(df):\n    # convert object to a numeric type, replacing Unknown with nan.\n    df['Score'] = df['Score'].apply(lambda x: np.nan if x=='Unknown' else float(x)) \n    for i in range(1, 11):\n        df[f'Score-{i}'] = df[f'Score-{i}'].apply(lambda x: np.nan if x=='Unknown' else float(x))\n    \n    # add genre ctegory columns\n    df = genre_to_category(df)\n    \n    return df\n\ndef make_user_feature(df):\n    # add user feature\n    df['rating_count'] = df.groupby('user_id')['anime_id'].transform('count')\n    df['rating_mean'] = df.groupby('user_id')['rating'].transform('mean')\n    return df\n\ndef preprocess(merged_df):\n    merged_df = make_anime_feature(merged_df)\n    merged_df = make_user_feature(merged_df)\n    return merged_df","ba391316":"merged_df = preprocess(merged_df)\nmerged_df.head()","5e0602ab":"# random split\ntrain, test = train_test_split(merged_df, test_size=0.2, random_state=SEED)\ndel merged_df\ngc.collect()","8be1617e":"print('train shape: ',train.shape)\nprint('test shape: ',test.shape)","65785492":"features = ['Score', 'Popularity','Members',\n            'Favorites','Watching','Completed','On-Hold','Dropped',\n            'Score-1','Score-2','Score-3','Score-4','Score-5',\n            'Score-6','Score-7','Score-8','Score-9','Score-10',\n            'rating_count','rating_mean'\n           ]\nfeatures += genre_names\nuser_col = 'user_id'\nitem_col = 'anime_id'\ntarget_col = 'rating'","29c57fbe":"train = train.sort_values('user_id').reset_index(drop=True)\ntest = test.sort_values('user_id').reset_index(drop=True)","5b069b27":"# model query data\ntrain_query = train[user_col].value_counts().sort_index()\ntest_query = test[user_col].value_counts().sort_index()","1d61d7eb":"# try parameter tuning\ndef objective(trial):\n    # search param\n    param = {\n        'reg_alpha': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n        'reg_lambda': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n        'max_depth': trial.suggest_int('max_depth', 3, 8),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.1, 1), \n        #'subsample': trial.suggest_uniform('subsample', 1e-8, 1), \n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100), \n    }\n     \n    #train model\n    model = lgb.LGBMRanker(n_estimators=1000, **param, random_state=SEED,)\n    model.fit(\n        train[features],\n        train[target_col],\n        group=train_query,\n        eval_set=[(test[features], test[target_col])],\n        eval_group=[list(test_query)],\n        eval_at=[1, 3, 5, 10, 20], # calc validation ndcg@1,3,5,10,20\n        early_stopping_rounds=50,\n        verbose=10\n    )\n    \n    # maximize mean ndcg\n    scores = []\n    for name, score in model.best_score_['valid_0'].items():\n        scores.append(score)\n    return np.mean(scores)\n \nstudy = optuna.create_study(direction='maximize',\n                            sampler=optuna.samplers.TPESampler(seed=SEED) #fix random seed\n                           )\nstudy.optimize(objective, n_trials=10)","c62e776b":"print('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","168e7a01":"# train with best params\nbest_params = study.best_trial.params\nmodel = lgb.LGBMRanker(n_estimators=1000, **best_params, random_state=SEED,)\nmodel.fit(\n    train[features],\n    train[target_col],\n    group=train_query,\n    eval_set=[(test[features], test[target_col])],\n    eval_group=[list(test_query)],\n    eval_at=[1, 3, 5, 10, 20],\n    early_stopping_rounds=50,\n    verbose=10\n)","4a7d087b":"#\u3000check output\u3000value\nmodel.predict(test.iloc[:10][features])","2580342f":"# feature imporance\nplt.figure(figsize=(10, 7))\ndf_plt = pd.DataFrame({'feature_name': features, 'feature_importance': model.feature_importances_})\ndf_plt.sort_values('feature_importance', ascending=False, inplace=True)\nsns.barplot(x=\"feature_importance\", y=\"feature_name\", data=df_plt)\nplt.title('feature importance')","499055bc":"def recommend_for_user(user, model, k, sample_anime_num):\n    anime = pd.read_csv('..\/input\/anime-recommendation-database-2020\/anime.csv')\n    pred_df = anime.sample(sample_anime_num).reset_index(drop=True) # sample recommend candidates\n    rating = pd.read_csv('..\/input\/anime-recommendation-database-2020\/rating_complete.csv')\n\n    # preprocess for model prediction\n    user_df = rating.query('user_id==@user')\n    user_df = make_user_feature(user_df)\n    for col in user_df.columns:\n        if col in features:\n            pred_df[col] = user_df[col].values[0]\n    pred_df = make_anime_feature(pred_df)\n\n    # recommend\n    preds = model.predict(pred_df[features])    \n    topk_idx = np.argsort(preds)[::-1][:k]\n    recommend_df = pred_df.loc[topk_idx].reset_index(drop=True)\n\n    # check recommend\n    print('---------- Recommend ----------')\n    for i, row in recommend_df.iterrows():\n        print(f'{i+1}: {row[\"Japanese name\"]}:{row[\"English name\"]}')\n\n    print('---------- Actual ----------')\n    user_df = user_df.merge(anime, left_on='anime_id', right_on='MAL_ID', how='inner')\n    for i, row in user_df.sort_values('rating',ascending=False).iterrows():\n        print(f'rating:{row[\"rating\"]}: {row[\"Japanese name\"]}:{row[\"English name\"]}')    \n\n    return recommend_df","96cd6606":"user = 20 # user_id\nk = 10 # num of recommend items\nsample_anime_num=1000 # num of recommend candidates \nrecommend_df = recommend_for_user(user, model, k, sample_anime_num)","cd4ea47d":"# Training","991b8932":"# Preprocess","0fe5c074":"# Load Data","fe1067ad":"# Recommend for user","880b1da5":"# Split data"}}