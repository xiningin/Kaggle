{"cell_type":{"5a3c6aae":"code","be3b1894":"code","e616f19e":"code","5ae27bbf":"code","667ef951":"code","f72c36d2":"code","efbc1f7a":"code","ac6a3972":"code","afe83e70":"code","ce000f5a":"code","c2a9cce3":"code","94e217f5":"code","a441c3c7":"code","217650f5":"code","4f32c88f":"code","9a16ff60":"code","22b905a2":"code","ebf34e3b":"code","66ee3ec3":"code","ebb1b406":"code","89da984f":"code","6c8216df":"code","c8d8c8df":"code","60b10546":"code","403e2a48":"code","b9be5033":"code","85221687":"code","8131d5a1":"code","6ad376f6":"markdown","a30003ae":"markdown","1f021302":"markdown","66b17964":"markdown","c11e9b5c":"markdown","bb3773dd":"markdown","a9dc4625":"markdown"},"source":{"5a3c6aae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport cv2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n!pip install imutils\nimport os\nimport keras.backend as K\nimport imutils\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","be3b1894":"import glob\nno_files=[]\nyes_files=[]\nfor file in glob.glob(\"\/kaggle\/input\/brain-mri-images-for-brain-tumor-detection\/no\/*.jpg\"):\n    no_files.append(file)\nfor file in glob.glob(\"\/kaggle\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/*.jpg\"):\n    yes_files.append(file)\n        ","e616f19e":"def crop_brain_contour(image, plot=False):\n    \n    # Convert the image to grayscale, and blur it slightly\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n    \n    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n    thresh = cv2.erode(thresh, None, iterations=2)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n    # Find contours in thresholded image, then grab the largest one\n    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    cnts = imutils.grab_contours(cnts)\n    c = max(cnts, key=cv2.contourArea)\n    # extreme points\n    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n    extRight = tuple(c[c[:, :, 0].argmax()][0])\n    extTop = tuple(c[c[:, :, 1].argmin()][0])\n    extBot = tuple(c[c[:, :, 1].argmax()][0])\n    \n    # crop new image out of the original image using the four extreme points (left, right, top, bottom)\n    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]            \n\n    if plot:\n        plt.figure()\n        plt.subplot(1, 2, 1)\n        plt.imshow(image)\n        plt.tick_params(axis='both', which='both', top=False, bottom=False, left=False, right=False,labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n        plt.title('Original Image')\n        plt.subplot(1, 2, 2)\n        plt.imshow(new_image)\n        plt.tick_params(axis='both', which='both',top=False, bottom=False, left=False, right=False,labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n        plt.title('Cropped Image')\n        plt.show()\n    \n    return new_image","5ae27bbf":"import os\ntry:\n    os.rmdir('..\/output\/kaggle\/working\/crop\/yes')\nexcept:\n    pass\ntry:\n    os.rmdir('..\/output\/kaggle\/working\/crop\/no')\nexcept:\n    pass\ntry:\n    os.makedirs('..\/output\/kaggle\/working\/crop\/yes')\nexcept:\n    pass\ntry:\n    os.makedirs('..\/output\/kaggle\/working\/crop\/no')\nexcept:\n    pass","667ef951":"\n\nex_img = cv2.imread('\/kaggle\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/Y107.jpg')\nex_crop_img = crop_brain_contour(ex_img, True)\n\n\n\nfor file in no_files:\n    \n    ex_img = cv2.imread(file)\n    ex_crop_img = crop_brain_contour(ex_img, False)\n    filename='..\/output\/kaggle\/working\/crop\/no\/'+os.path.basename(file)\n    \n    cv2.imwrite(filename,ex_crop_img)\n    \nfor file in yes_files:\n    ex_img = cv2.imread(file)\n    ex_crop_img = crop_brain_contour(ex_img, False)\n    cv2.imwrite('..\/output\/kaggle\/working\/crop\/yes\/'+os.path.basename(file),ex_crop_img)\n    ","f72c36d2":"import glob\nno_files_crop=[]\nyes_files_crop=[]\nfor file in glob.glob(\"..\/output\/kaggle\/working\/crop\/no\/*.jpg\"):\n    no_files_crop.append(file)\nfor file in glob.glob(\"..\/output\/kaggle\/working\/crop\/yes\/*.jpg\"):\n    yes_files_crop.append(file)\n        ","efbc1f7a":"df=pd.DataFrame(columns=['filename','class'])\nfor file in no_files_crop:\n    df=df.append({'filename':file,'class':'no'},ignore_index=True)\n\nfor file in yes_files_crop:\n    df=df.append({'filename':file,'class':'yes'},ignore_index=True)","ac6a3972":"from sklearn.utils import shuffle\ndf_shuffle=shuffle(df)","afe83e70":"df_shuffle.groupby(['class']).count().hist()","ce000f5a":"from sklearn.model_selection import train_test_split\n\nX_train,X_=train_test_split(df_shuffle,test_size=0.2,random_state=0)\n\nX_test,X_val=train_test_split(X_,test_size=0.2,random_state=0)\n\n\n","c2a9cce3":"X_train.groupby(['class']).count()","94e217f5":"X_val.groupby(['class']).count()","a441c3c7":"X_train","217650f5":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\n\n\n\nimg_generator=ImageDataGenerator(rescale=1\/255)\n\ntrain_it = img_generator.flow_from_dataframe(X_train, class_mode='binary',\n                                             featurewise_std_normalization=True,\n                                             batch_size=136,\n                                             image_size=(256, 256))\ntest_it = img_generator.flow_from_dataframe(X_test, class_mode='binary',image_size=(256, 256),featurewise_std_normalization=True,batch_size=28)\nval_it = img_generator.flow_from_dataframe(X_val, class_mode='binary',image_size=(256, 256),featurewise_std_normalization=True)","4f32c88f":"import matplotlib.pyplot as plt\n\nfig,ax=plt.subplots(2,2,figsize=(6,6))\n\nimages,labels = train_it.next()\nx=0\ny=0\nfor i in range(0,16):\n    image = images[i]\n    if y<2 and x<2:\n        ax[y][x].imshow(image)\n    if x>2:\n        y=y+1\n        x=0\n    x=x+1\nplt.show()","9a16ff60":"!pip install git+https:\/\/github.com\/keras-team\/keras-tuner.git@1.0.2rc0\n!pip install autokeras==1.0.3","22b905a2":"# example of tending the vgg16 model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dropout\n\n# load model without classifier layers\nvgg = VGG16(include_top=False, input_shape=(256, 256, 3))\n# add new classifier layers\nflat1 = Flatten()(vgg.output)\ndropout = Dropout(0.5)(flat1)\ndense1 = Dense(1024, activation='relu')(flat1)\nbatch =  BatchNormalization()(dense1)\ndense2 = Dense(1024, activation='relu')(batch)\ndropout = Dropout(0.5)(dense2)\noutput = Dense(1, activation='sigmoid')(dropout)\n# define new model\nmodel = Model(inputs=vgg.inputs, outputs=output)\n# summarize\nmodel.summary()\n\n#for layer in vgg.layers:\n#    layer.trainable=False\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","ebf34e3b":"import tensorflow as tf\n\nimport autokeras as ak\n\nimages,labels = train_it.next()\n\n\n#train_set = tf.data.Dataset.from_tensor_slices(((x_train,), (x_test,)))\n# Initialize the image classifier.\nclf = ak.ImageClassifier(\n    overwrite=True,\n    max_trials=2)\n\n# Feed the image classifier with training data.\nclf.fit(images,labels , epochs=10)","66ee3ec3":"X_test,y_test = test_it.next()\n\naccuracy=clf.evaluate(X_test, y_test)\n","ebb1b406":"accuracy[1]","89da984f":"df_shuffle","6c8216df":"df_yes=df_shuffle[df_shuffle['class']=='yes']\nname=list(df_yes.iloc[1:2,:]['filename'])[0]\nprint(name)\nex_img = cv2.imread(name)\nex_img = cv2.resize(ex_img,(256,256))\nplt.imshow(ex_img)\n\nfrom tensorflow.keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\n\nx_reshape = ex_img.reshape((1, ex_img.shape[0],ex_img.shape[1], ex_img.shape[2]))\n\nimage = preprocess_input(x_reshape)\n\nclf.predict(image)","c8d8c8df":"df_no=df_shuffle[df_shuffle['class']=='no']\nname=list(df_no.iloc[1:2,:]['filename'])[0]\nprint(name)\nex_img = cv2.imread(name)\nex_img = cv2.resize(ex_img,(256,256))\nplt.imshow(ex_img)\n\nfrom tensorflow.keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\n\nx_reshape = ex_img.reshape((1, ex_img.shape[0],ex_img.shape[1], ex_img.shape[2]))\n\nimage = preprocess_input(x_reshape)\n\nclf.predict(image)","60b10546":"y_pred=[]\ny_true=[]\n\n\nfor i,r in df_shuffle.iterrows():\n    ex_img = cv2.imread(r['filename'])\n    ex_img = cv2.resize(ex_img,(256,256))\n    plt.imshow(ex_img)\n\n    from tensorflow.keras.preprocessing import image\n    from keras.applications.vgg16 import preprocess_input\n\n    x_reshape = ex_img.reshape((1, ex_img.shape[0],ex_img.shape[1], ex_img.shape[2]))\n\n    image = preprocess_input(x_reshape)\n    \n    pred=clf.predict(image)\n    \n    y_true.append(r['class'])\n    \n\n    \n \n    y_pred.extend(pred[0])\n   ","403e2a48":"y_pred_=[int(y>0.5) for y in y_pred]","b9be5033":"y_test=[1 if x=='yes' else 0 for x in y_true]","85221687":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred_))","8131d5a1":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test,y_pred_)","6ad376f6":"### Reading Files","a30003ae":"## Class Balance","1f021302":"## Test Accuracy","66b17964":"## Train model","c11e9b5c":"## Crop Image","bb3773dd":"## Test Predictions","a9dc4625":"## Show images"}}