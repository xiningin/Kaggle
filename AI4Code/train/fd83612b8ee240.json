{"cell_type":{"78160a06":"code","a80e1a41":"code","f97252db":"code","fce5405c":"code","3b116577":"code","b128c297":"code","9b59be4d":"code","59ee4dba":"code","507f7f8e":"code","08a3a5ff":"code","df7727ad":"code","8be7df82":"code","93526dcd":"markdown","a7b0eb10":"markdown","e3950a17":"markdown","7fc7d254":"markdown","5b7bd15c":"markdown","66062262":"markdown","46cbbbc9":"markdown","f6db0101":"markdown","753ea7ac":"markdown","0c2831fc":"markdown","ba48aeff":"markdown","a052569c":"markdown","e68044ab":"markdown"},"source":{"78160a06":"from keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Dense\nfrom keras import backend as K\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import classification_report\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.optimizers import SGD\nfrom keras.datasets import cifar10\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n%matplotlib inline","a80e1a41":"def MiniVGGNet(width, height, depth, classes):\n    model = Sequential()\n    inputShape = (height, width, depth)\n    chanDim = -1\n\n    if K.image_data_format()==\"channels_first\":\n        inputShape = (depth, height, width)\n        chanDim = 1\n\n    model.add(Conv2D(32, (3,3), padding = \"same\", input_shape = inputShape))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=chanDim))\n    model.add(Conv2D(32, (3,3), padding = \"same\"))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=chanDim))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(64, (3,3), padding = \"same\"))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=chanDim))\n    model.add(Conv2D(64, (3,3), padding = \"same\"))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=chanDim))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(512))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(classes))\n    model.add(Activation(\"softmax\"))\n    return model","f97252db":"def step_decay(epoch):\n    initAlpha = 0.01\n    factor = 0.25\n    dropEvery = 5\n    \n    alpha = initAlpha *(factor **np.floor((1 + epoch)\/dropEvery))\n    \n    return float(alpha)","fce5405c":"print(\"Loading CIFAR-10 data . . . \")\n((trainX, trainY), (testX, testY)) = cifar10.load_data()\n\ntrainX = trainX.astype(\"float\") \/ 255.0\ntestX = testX.astype(\"float\") \/ 255.0","3b116577":"lb = LabelBinarizer()\ntrainY = lb.fit_transform(trainY)\ntestY = lb.transform(testY)","b128c297":"labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]","9b59be4d":"print(\"Compiling Model . . .\")\ncallbacks = [LearningRateScheduler(step_decay)]\nopt = SGD(lr=0.01, decay=0.01 \/ 40, momentum=0.9, nesterov=True)\nmodel = MiniVGGNet(width=32, height=32, depth=3, classes=10)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])","59ee4dba":"print(\"Training Neural Network . . .\")\nH = model.fit(trainX, trainY, validation_data=(testX, testY),\nbatch_size=64, epochs=40, verbose=1)","507f7f8e":"print(\"Evaluating Neural network...\")\npredictions = model.predict(testX, batch_size=64)\nprint(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=labelNames))","08a3a5ff":"acc = H.history['accuracy']\nval_acc = H.history['val_accuracy']\nloss = H.history['loss']\nval_loss = H.history['val_loss']\n\nepochs = range(1, len(acc) + 1)","df7727ad":"plt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and Validation accuracy')\nplt.legend()\nplt.figure()","8be7df82":"plt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.figure()","93526dcd":"### Plot of Training Loss Vs Validation Loss","a7b0eb10":"> ## Step Decay Function","e3950a17":"### Importing required libraries","7fc7d254":"### Train the network","5b7bd15c":"### Initialize the label names for the CIFAR-10 dataset","66062262":"### Loading CIFAR-10 Dataset","46cbbbc9":"### A function MiniVGGNet() which takes input of (width, height, depth and number of classes) and model is defined. ","f6db0101":"### Convert the labels from integers to vectors","753ea7ac":"### Compile the model with loss, optimizer and metric","0c2831fc":"### Evaluate the network","ba48aeff":"### Plot of Training Accuracy Vs Validation Accuracy","a052569c":"### End of Notebook, if you like it then upvote it. ","e68044ab":"# Custom Learning Rate Scheduler in Keras"}}