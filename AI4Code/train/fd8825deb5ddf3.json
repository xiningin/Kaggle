{"cell_type":{"e2d0d4f9":"code","a818f691":"code","34596a66":"code","85b3e9ab":"code","0b72b2a1":"code","a7a58b18":"code","ec7e2ece":"code","1b5240e3":"code","2be807f7":"code","fe7af044":"code","03a6c676":"code","759fd39e":"code","bcf89cad":"code","3bb138b0":"code","4ab83ed7":"code","67c8f85d":"code","eecf6ee4":"code","d367e8ba":"code","1cf816fb":"code","72a88a7b":"code","9ece7f0f":"code","99962ec2":"code","6e093819":"code","24a84974":"code","25ca2408":"code","d345d0d9":"code","89b7d802":"code","fbbe9ee5":"code","e924f5de":"code","ef05d87d":"code","8113b488":"code","5b686232":"code","4e6aebd9":"code","4b4a5add":"code","9b69c170":"code","31f9f988":"code","b070f44e":"code","52fe24c0":"code","87501744":"code","5b4042f8":"code","cad46a1f":"code","3b2a65d6":"code","bcecaeaf":"code","c6cf39fb":"code","8dc7bd38":"code","ef0069bb":"code","89dc841c":"code","9df660ee":"code","7572c8f1":"code","01327bb9":"code","79bab707":"code","51639197":"code","4be589fc":"code","ea3886a0":"code","0e2d98e8":"code","400cf2be":"code","2862b9d2":"code","3164848e":"code","b358fd40":"code","c1d7cdc2":"code","743e4703":"code","b43a541b":"markdown","de2f36ec":"markdown","3d5d058f":"markdown","a9c62dcc":"markdown","5f066c5b":"markdown","dc64c84e":"markdown","6a6a70cd":"markdown","9b3afc92":"markdown","ad1342b7":"markdown","62d31a19":"markdown","9c85af4c":"markdown","93a0d6de":"markdown","2496c875":"markdown","ce26cabc":"markdown","a88dd2f6":"markdown","784c1a29":"markdown","d067b712":"markdown","b8227f13":"markdown"},"source":{"e2d0d4f9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a818f691":"# libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.datasets import CIFAR10\nfrom torchvision.transforms import ToTensor\nfrom torchvision.utils import make_grid\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data import random_split\n%matplotlib inline\n\nfrom pathlib import Path\nimport os\nimport cv2\nimport glob\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport torchvision.transforms as transforms\nimport torch\nimport torchvision.transforms.functional as F\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom tqdm.notebook import tqdm","34596a66":"!pip install albumentations > \/dev\/null 2>&1","85b3e9ab":"!pip install pretrainedmodels > \/dev\/null 2>&1","0b72b2a1":"import albumentations\nimport pretrainedmodels","a7a58b18":"## read the csv data files\ntrain_df = pd.read_csv('..\/input\/janatahack-av-computervision\/train_SOaYf6m\/train.csv')\ntest_df = pd.read_csv('..\/input\/janatahack-av-computervision\/test_vc2kHdQ.csv')\nsubmit = pd.read_csv('..\/input\/janatahack-av-computervision\/sample_submission_yxjOnvz.csv')","ec7e2ece":"train_df.shape, test_df.shape","1b5240e3":"train_df.groupby('emergency_or_not').count()","2be807f7":"sns.countplot(x='emergency_or_not' , data=train_df)","fe7af044":"## set the data folder\ndata_folder = Path(\"..\/input\/janatahack-av-computervision\")\ndata_path = \"..\/input\/janatahack-av-computervision\/train_SOaYf6m\/images\/\"\n\npath = os.path.join(data_path , \"*jpg\")","03a6c676":"data_path","759fd39e":"files = glob.glob(path)\ndata=[]\nfor file in files:\n    image = cv2.imread(file)\n    data.append(image)","bcf89cad":"train_images = data[:1646]\ntest_images= data[1646:]","3bb138b0":"#Look at the shape of the image\nprint(train_images[0].shape), print(train_images[100].shape)","4ab83ed7":"def get_images_class(cat):\n    list_of_images = []\n    fetch = train_df.loc[train_df['emergency_or_not']== cat][:3].reset_index()\n    for i in range(0,len(fetch['image_names'])):\n        list_of_images.append(fetch['image_names'][i])\n    return list_of_images ","67c8f85d":"get_images_class(0)","eecf6ee4":"get_images_class(1)","d367e8ba":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfig = plt.figure(figsize=(20,15))\nfor i, image_name in enumerate(get_images_class(0)):\n    plt.subplot(1,3 ,i+1)\n    img=mpimg.imread('..\/input\/janatahack-av-computervision\/train_SOaYf6m\/images\/'+image_name)\n    imgplot = plt.imshow(img)\n    plt.xlabel(str(\"Non-Emergency Vehicle\") + \" (Index:\" +str(i+1)+\")\" )\nplt.show()","1cf816fb":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfig = plt.figure(figsize=(20,15))\nfor i, image_name in enumerate(get_images_class(1)):\n    plt.subplot(1,3 ,i+1)\n    img=mpimg.imread('..\/input\/janatahack-av-computervision\/train_SOaYf6m\/images\/'+image_name)\n    imgplot = plt.imshow(img)\n    plt.xlabel(str(\"Emergency Vehicle\") + \" (Index:\" +str(i)+\")\" )\nplt.show()","72a88a7b":"class EmergencyDataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None):\n        self.df = pd.read_csv(csv_file)\n        self.transform = transform\n        self.root_dir = root_dir\n        \n    def __len__(self):\n        return len(self.df)    \n    \n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        img_id, img_label = row['image_names'], row['emergency_or_not']\n        img_fname = self.root_dir + str(img_id)\n#         + \".jpg\"\n        img = Image.open(img_fname)\n        if self.transform:\n            img = self.transform(img)\n        return img, img_label","9ece7f0f":"TRAIN_CSV = '..\/input\/janatahack-av-computervision\/train_SOaYf6m\/train.csv'\ntransform = transforms.Compose([transforms.ToTensor()])\ndataset = EmergencyDataset(TRAIN_CSV, data_path, transform=transform)","99962ec2":"torch.manual_seed(10)\n\nval_pct = 0.2\nval_size = int(val_pct * len(dataset))\ntrain_size = len(dataset) - val_size","6e093819":"train_ds, val_ds = random_split(dataset, [train_size, val_size])\nlen(train_ds), len(val_ds)","24a84974":"batch_size = 32","25ca2408":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])","d345d0d9":"dataset = EmergencyDataset(TRAIN_CSV, data_path, transform=transform)","89b7d802":"train_loader  = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\nvalidation_loader = DataLoader(val_ds, batch_size*2, num_workers=2, pin_memory=True)","fbbe9ee5":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        # 3 input image channel, 16 output channels, 3x3 square convolution kernel\n        self.conv1 = nn.Conv2d(3,16,kernel_size=3,stride=2,padding=1)\n        self.conv2 = nn.Conv2d(16, 32,kernel_size=3,stride=2, padding=1)\n        self.conv3 = nn.Conv2d(32, 64,kernel_size=3,stride=2, padding=1)\n        self.conv4 = nn.Conv2d(64, 64,kernel_size=3,stride=2, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.dropout = nn.Dropout2d(0.4)\n        self.batchnorm1 = nn.BatchNorm2d(16)\n        self.batchnorm2 = nn.BatchNorm2d(32)\n        self.batchnorm3 = nn.BatchNorm2d(64)\n        self.fc1 = nn.Linear(64*4*4,512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 2)\n        self.sig = nn.Sigmoid()\n        \n        \n    def forward(self, x):\n\n        x = self.batchnorm1(F.relu(self.conv1(x)))\n        x = self.batchnorm2(F.relu(self.conv2(x)))\n        x = self.dropout(self.batchnorm2(self.pool(x)))\n        x = self.batchnorm3(self.pool(F.relu(self.conv3(x))))\n        x = self.dropout(self.conv4(x))\n\n        x = x.view(x.size(0), -1)\n\n\n        x = self.dropout(self.fc1(x))\n        x = self.dropout(self.fc2(x))\n        x = self.sig(self.fc3(x))\n        return x","e924f5de":"model = Net() # On CPU\n#model = Net().to(device)  # On GPU\nprint(model)","ef05d87d":"criterion = nn.CrossEntropyLoss()\n# criterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)","8113b488":"def accuracy(out, labels):\n    _,pred = torch.max(out, dim=1)\n    return torch.sum(pred==labels).item()","5b686232":"n_epochs = 20\nprint_every = 10\nvalid_loss_min = np.Inf\nval_loss = []\nval_acc = []\ntrain_loss = []\ntrain_acc = []\ntotal_step = len(train_loader)\nfor epoch in range(1, n_epochs+1):\n    running_loss = 0.0\n    # scheduler.step(epoch)\n    correct = 0\n    total=0\n    print(f'Epoch {epoch}\\n')\n    for batch_idx, (data_, target_) in enumerate(train_loader):\n        #data_, target_ = data_.to(device), target_.to(device)# on GPU\n        # zero the parameter gradients\n        optimizer.zero_grad()\n        # forward + backward + optimize\n        outputs = model(data_)\n        loss = criterion(outputs, target_)\n        loss.backward()\n        optimizer.step()\n        # print statistics\n        running_loss += loss.item()\n        _,pred = torch.max(outputs, dim=1)\n        correct += torch.sum(pred==target_).item()\n        total += target_.size(0)\n        if (batch_idx) % 20 == 0:\n            print ('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}' \n                   .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n    train_acc.append(100 * correct \/ total)\n    train_loss.append(running_loss\/total_step)\n    print(f'\\ntrain loss: {np.mean(train_loss):.4f}, train acc: {(100 * correct \/ total):.4f}')\n    batch_loss = 0\n    total_t=0\n    correct_t=0\n    with torch.no_grad():\n        model.eval()\n        for data_t, target_t in (validation_loader):\n            #data_t, target_t = data_t.to(device), target_t.to(device)# on GPU\n            outputs_t = model(data_t)\n            loss_t = criterion(outputs_t, target_t)\n            batch_loss += loss_t.item()\n            _,pred_t = torch.max(outputs_t, dim=1)\n            correct_t += torch.sum(pred_t==target_t).item()\n            total_t += target_t.size(0)\n        val_acc.append(100 * correct_t \/ total_t)\n        val_loss.append(batch_loss\/len(validation_loader))\n        network_learned = batch_loss < valid_loss_min\n        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t \/ total_t):.4f}\\n')\n        # Saving the best weight \n        if network_learned:\n            valid_loss_min = batch_loss\n            torch.save(model.state_dict(), 'model_classification.pt')\n            print('Detected network improvement, saving current model')\n    model.train()","4e6aebd9":"fig = plt.figure(figsize=(20,10))\nplt.title(\"Train - Validation Loss\")\nplt.plot( train_loss, label='train')\nplt.plot( val_loss, label='validation')\nplt.xlabel('num_epochs', fontsize=12)\nplt.ylabel('loss', fontsize=12)\nplt.legend(loc='best')","4b4a5add":"fig = plt.figure(figsize=(20,10))\nplt.title(\"Train - Validation Accuracy\")\nplt.plot(train_acc, label='train')\nplt.plot(val_acc, label='validation')\nplt.xlabel('num_epochs', fontsize=12)\nplt.ylabel('accuracy', fontsize=12)\nplt.legend(loc='best')","9b69c170":"# Importing trained Network with better loss of validation\nmodel.load_state_dict(torch.load('model_classification.pt'))","31f9f988":"def img_display(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    npimg = np.transpose(npimg, (1, 2, 0))\n    return npimg","b070f44e":"dataiter = iter(validation_loader)\nimages, labels = dataiter.next()\nvehicle_types = {0: 'Non-Emergency-Vehicle', 1: 'Emergency-Vehicle'}\n# Viewing data examples used for training\nfig, axis = plt.subplots(3, 5, figsize=(20, 15))\nwith torch.no_grad():\n    model.eval()\n    for ax, image, label in zip(axis.flat,images, labels):\n        ax.imshow(img_display(image)) # add image\n        image_tensor = image.unsqueeze_(0)\n        output_ = model(image_tensor)\n        output_ = output_.argmax()\n        k = output_.item()==label.item()\n        ax.set_title(str(vehicle_types[label.item()])+\":\" +str(k)) # add label\n","52fe24c0":"TEST_CSV = '..\/input\/janatahack-av-computervision\/sample_submission_yxjOnvz.csv'\ntest_dataset = EmergencyDataset(TEST_CSV, data_path, transform=transform)","87501744":"len(test_dataset)","5b4042f8":"test_dl = DataLoader(test_dataset, batch_size, num_workers=2, pin_memory=True)","cad46a1f":"test_dl","3b2a65d6":"@torch.no_grad()\ndef predict_dl(dl, model):    \n    torch.cuda.empty_cache()\n    batch_probs = []\n    for xb, _ in tqdm(dl):\n        probs = model(xb)        \n        batch_probs.append(probs.cpu().detach())\n    batch_probs = torch.cat(batch_probs)\n\n    return [x.numpy() for x in batch_probs]\n ","bcecaeaf":"submission_df = pd.read_csv(TEST_CSV)\ntest_preds = predict_dl(test_dl, model)\nsubmission_df.emergency_or_not = np.argmax(test_preds, axis = 1)\nsubmission_df.head()","c6cf39fb":"submission_df.tail()","8dc7bd38":"submission_df['emergency_or_not'].value_counts()","ef0069bb":"submission_df.to_csv('submission.csv', index=False)","89dc841c":"model.eval()\n\npreds = []\nfor batch_i, (data, target) in enumerate(test_dl):\n#     data, target = data.cuda(), target.cuda()\n    output = model(data)\n\n    pr = output[:,1].detach().cpu().numpy()\n    for i in pr:\n        preds.append(i)\nsubmission_df['emergency_or_not'] = submission_df['emergency_or_not'].apply(lambda x: 1 if x >= 0.5 else 0)\nsubmission_df.to_csv('submission_output.csv', index=False)","9df660ee":"submission_df.head()","7572c8f1":"submission_df['emergency_or_not'].value_counts()","01327bb9":"print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t \/ total_t):.4f}\\n')\n        # Saving the best weight ","79bab707":"## function to create download link\nfrom IPython.display import HTML\ndef create_download_link(title = \"Download CSV file\", filename = \"submission_output.csv\"):  \n    html = '<a href={filename}>{title}<\/a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)","51639197":"create_download_link(filename = 'submission_output.csv')","4be589fc":"arch = (512,256,2)","ea3886a0":"lrs = [0.0001]","0e2d98e8":"epochs = [20]","400cf2be":"validation_loss =  np.mean(val_loss)\nvalidation_acc =  (100 * correct_t \/ total_t)\nprint(validation_loss, validation_acc)","2862b9d2":"# # Project name used for jovian.commit\n# project_name = '01-Emergency_Vehicle_Detection'","3164848e":"# !pip install jovian --upgrade --quiet","b358fd40":"# import jovian","c1d7cdc2":"# # Clear previously recorded hyperparams & metrics\n# jovian.reset()\n# jovian.log_hyperparams(arch=arch, \n#                        lrs=lrs, \n#                        epochs=epochs)\n# jovian.log_metrics(test_loss=validation_loss, test_acc=validation_acc)","743e4703":"# torch.save(model.state_dict(), '01-emergency-vehicle-detector.pth')\n# jovian.commit(project=project_name, environment=None, outputs=['01-emergency-vehicle-detector.pth'])","b43a541b":"Q: What were the final test accuracy & test loss?","de2f36ec":"**Data Description**\n* train.zip: contains 2 csvs and 1 folder containing image data\n* train.csv \u2013 [\u2018image_names\u2019, \u2018emergency_or_not\u2019] contains the image name and correct class for 1646 (70%) train images\n* images \u2013 contains 2352 images for both train and test sets\n* test.csv: [\u2018image_names\u2019] contains just the image names for the 706 (30%) test images\n* sample_submission.csv: [\u2018image_names\u2019,\u2019emergency_or_not\u00ad\u2019] contains the exact format for a valid * submission (1 - For Emergency Vehicle, 0 - For Non Emergency Vehicle)","3d5d058f":"#### Recoding your results\nAs your perform multiple experiments, it's important to record the results in a systematic fashion, so that you can review them later and identify the best approaches that you might want to reproduce or build upon later.\n\nQ: Describe the model's architecture with a short summary.\n\nE.g. \"3 layers (16,32,10)\" (16, 32 and 10 represent output sizes of each layer)","a9c62dcc":"Fatalities due to traffic delays of emergency vehicles such as ambulance & fire brigade is a huge problem. In daily life, we often see that emergency vehicles face difficulty in passing through traffic. So differentiating a vehicle into an emergency and non emergency category can be an important component in traffic monitoring as well as self drive car systems as reaching on time to their destination is critical for these services.\n\nIn this problem, you will be working on classifying vehicle images as either belonging to the emergency vehicle or non-emergency vehicle category. For the same, you are provided with the train and the test dataset. Emergency vehicles usually includes police cars, ambulance and fire brigades.","5f066c5b":"![image.png](attachment:image.png)","dc64c84e":"evaluating the model performance through visualization","6a6a70cd":"### Accuracy and loss Curve","9b3afc92":"### Submission on Test Set","ad1342b7":"### References","62d31a19":"Q: Provide the list of learning rates used while training.","9c85af4c":"### Emergency vs Non-Emergency Vehicle Classification","93a0d6de":"### Evaluation","2496c875":"### Preparing data","ce26cabc":"# Assignment 5 - Course Project","a88dd2f6":"### Save and upload","784c1a29":"1. https:\/\/www.kaggle.com\/basu369victor\/pytorch-tutorial-the-classification","d067b712":"****Evaluation Metric****\n\nThe evaluation metric for this competition is Accuracy.\n\nThe link to the above datasets and problem statement are:\n\nhttps:\/\/datahack.analyticsvidhya.com\/contest\/janatahack-computer-vision-hackathon\/#ProblemStatement","b8227f13":"Q: Provide the list of no. of epochs used while training."}}