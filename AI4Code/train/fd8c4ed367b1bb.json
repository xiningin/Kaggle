{"cell_type":{"c769caed":"code","e9fa9fe8":"code","e6be0885":"code","bc671689":"code","c1cb46a2":"code","9bc5b077":"code","44d2b0ff":"code","bdf625ef":"code","1cf80781":"code","946442ea":"code","8808f64a":"code","55769905":"code","6c446b43":"markdown","0bb4a3e9":"markdown","9d184691":"markdown","e1c354b4":"markdown","e8ca6cb7":"markdown","46212050":"markdown","09c4cce4":"markdown","cc584748":"markdown","97faefee":"markdown","48207d9c":"markdown","5318e9d4":"markdown","264f8279":"markdown","5f4d6eb5":"markdown","f92ca48c":"markdown","90c508d9":"markdown","bca88cbc":"markdown","836ccdf1":"markdown","12749647":"markdown","f77047a2":"markdown","9822b2cf":"markdown"},"source":{"c769caed":"# As imagens do Dataset \"RxTorax\" que cont\u00e9m 350 imagens normais e 350 de derrame j\u00e1 est\u00e3o vinculadas a este \"Notebook\"\n# Para editar o dataset vinculado a este kernel v\u00e1 em \"Add Data\" no menu \u00e0 direita. \n# Agora que ja temos o dataset pronto, vamos criar uma lista dos arquivos utilizando o glob, que l\u00ea e lista os arquivos que existem dentro de uma pasta\n\nfrom glob import glob\n\nderrame_dir = '..\/input\/effusion\/*\/*.png' #Define o caminho das pastas que cont\u00e9m as imagens\nnormal_dir = '..\/input\/normal\/*\/*.png'\n\nderrame_lista = glob(derrame_dir) #Lista os arquvos dentro de cada uma das pastas, usando o glob()\nnormal_lista = glob(normal_dir)\n\nprint('N\u00famero de casos com derrame: ', len(derrame_lista)) #Visualiza o tamanho da lista\nprint('N\u00famero de casos normais: ', len(normal_lista))\nprint ('\\nEtapa Conclu\u00edda. Vamos para a pr\u00f3xima!')\n\n#Execute com SHIFT + ENTER\n\n#O resultado esperado \u00e9:\n#N\u00famero de casos com derrame:  350\n#N\u00famero de casos normais:  350","e9fa9fe8":"import cv2 #Para abrir o arquivo de imagem, utilizaremos o openCV, uma biblioteca aberta de vis\u00e3o computacional\nfrom matplotlib import pyplot as plt #Biblioteca de plotagem de gr\u00e1ficos chamada a matplotlib\n\n#Em 'Classe' digite 'N' para imagens da classe 'Normal', \n#ou substitua-o por 'D' para imagens com derrame\nClasse = 'D'\n\n#Escolha uma imagem entre 0 e 349:\nID_arquivo = 102\n\nif Classe == 'N':\n    classe = 'Normal'\n    classe_lista = normal_lista\nelif Classe == 'D':\n    classe = 'Derrame'\n    classe_lista = derrame_lista\n    \nimagem = cv2.imread(classe_lista[ID_arquivo])\nplt.imshow(imagem)\nplt.show()\n    \nprint('Classe: ',classe)\nprint ('\\nEtapa Conclu\u00edda. Vamos para a pr\u00f3xima!')\n\n#Execute com SHIFT + ENTER\n#Pode modificar o ID_arquivo ou a Classe para vizualizar outras imagens. Pode repetir quantas vezes quiser","e6be0885":"import numpy as np #biblioteca NumPy para trabalharmos com matrizes\n# Por que usamos matrizes? A entrada de informa\u00e7\u00f5es nas redes neurais se d\u00e1 nesse formato,\n# o computador enxerga as imagens dessa forma e permite processamento computacional paralelo e maior velocidade de processamento.\n\ndataset = [] # cria uma lista vazia para incluir as imagens do dataset\nlabels = [] # cria uma lista vazia para incluir a categoria a qual cada imagem pertence (0 ou 1)\n\nfor arquivo in derrame_lista: # para cada arquivo de imagem na lista derrame:\n    img = cv2.imread(arquivo, cv2.IMREAD_GRAYSCALE) #abre o arquivo em escala de cinzas\n    img = cv2.resize(img, (256,256)) #redimensiona a imagem para 256 x 256\n    dataset.append(img) #adiciona essa imagem na lista do dataset que criamos acima\n    labels.append(1) #informa que ela \u00e9 um caso de derrrame (1)\n\n#Agora faremos o mesmo para as imagens sem derrame\nfor arquivo in normal_lista:\n    img = cv2.imread(arquivo, cv2.IMREAD_GRAYSCALE) \n    img = cv2.resize(img, (256,256)) \n    dataset.append(img)\n    labels.append(0) #mas agora informaremos que ela \u00e9 um caso normal (0)\n    \ndataset = np.asarray(dataset, dtype=np.float32) #transforma a lista de vari\u00e1veis numa matriz\nlabels = np.asarray(labels)\n\nfor i in range(len(dataset)):\n  dataset[i] = (dataset[i] - np.average(dataset[i], axis= (0, 1))) \/ np.std(dataset[i], axis= (0, 1)) #faremos a normaliza\u00e7\u00e3o, dividindo a m\u00e9dia pelo desvio padr\u00e3o\n  # normaliza\u00e7\u00e3o diminui a variabilizada do dataset, deixando os valores mais pr\u00f3ximos um do outro\n  \nprint('Dimens\u00f5es da Matriz: ',dataset.shape)\nprint ('\\nEtapa Conclu\u00edda. Vamos para a pr\u00f3xima!')\n\n#Vamos ver qual o tamanho dessa matriz 'dataset'\n#Esperamos que a primeira dimens\u00e3o dela seja de 700 (350 casos de derrame e 350 normais)\n#A segunda e a terceira dimens\u00f5es devem ser 256.\n\n# a sa\u00edda esperada \u00e9 (700, 256, 256)","bc671689":"#Vamos separar nosso dataset em grupos de treinamento, valida\u00e7\u00e3o e teste. Para isso, usaremos a biblioteca sklearn.\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n\n#Vamos dividir o grupo de treino, valida\u00e7\u00e3o e teste na propor\u00e7\u00e3o de cerca de 70%\/15%\/15%, \n#com valores aproximados para ficarmos com n\u00fameros redondos de 500\/100\/100\n\ndataset_train, dataset_test, labels_train, labels_test = train_test_split(dataset[:,...,np.newaxis], labels[:,...,np.newaxis], test_size=0.142, random_state=80)\ndataset_train, dataset_val, labels_train, labels_val = train_test_split(dataset_train, labels_train, test_size=0.1651, random_state=80)\n\nprint('(N\u00famero de imagens, Imagem_X, Imagem_Y, canais de cor) (N\u00famero de labels, 1)')\nprint(dataset_train.shape, labels_train.shape)\nprint(dataset_val.shape, labels_val.shape)\nprint(dataset_test.shape, labels_test.shape)\n\n#Voc\u00ea deve ver a seguinte sa\u00edda:\n#(500, 256, 256, 1) (500,1)\n#(100, 256, 256, 1) (100,1)\n#(100, 256, 256, 1) (100,1)\n\nprint ('\\nEtapa Conclu\u00edda. Vamos para a pr\u00f3xima!')","c1cb46a2":"#Vamos importar as fun\u00e7\u00e3o do Keras que faz data augmentation:\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\n#Aqui podemos definir diferentes vari\u00e1veis que v\u00e3o definir como as imagens  \n#v\u00e3o mudar em rota\u00e7\u00e3o, \"corte\" ou zoom.\n\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\nprint ('\\nEtapa Conclu\u00edda. Vamos para a pr\u00f3xima!')","9bc5b077":"#Nesta etapa vamos criar a arquitetura da nossa rede neural convolucional, \n#Utilizaremos a biblioteca Keras, pr\u00f3pria para Deep Learning em Python\n#Inicialmente vamos importar as fun\u00e7\u00f5es do Keras que iremos utilizar:\n\nfrom keras.models import Sequential\nfrom keras import optimizers\nfrom keras.layers.core import Dense, Dropout\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPool2D, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.layers import Input, Concatenate, add\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.layers import Activation, Dense, LeakyReLU\nfrom keras.utils.np_utils import to_categorical\nimport keras\n\n#Agora criaremos a estrutura da rede neural convolucional\n\n#A primeira camada define o tamanho da camada de entrada da rede\nimgs = Input(shape=(256,256,1))\n\n#Lembre que a nossa matriz com todas as 556 imagens de cada categoria tem o formato (556, 256, 256)\n#Nesse caso a entrada (input) da rede \u00e9 cada imagem individualmente\n#Ou seja, uma imagem de tamanho 256 x 256 pixels e 1 canal de cor (escala de cinzas) (256, 256, 1)\n\n#Agora vamos adicionar a primeira camada convolucional\nx = Conv2D(8, 3, padding='same', activation='relu')(imgs)\n\n#Em seguida, adicionamos uma camada MaxPool, que ir\u00e1 reduzir em 75% o tamanho da sa\u00edda da camada convolucional.\n#Fazemos isso para evitar que o n\u00famero de par\u00e2metros da rede aumente demais.\nx = MaxPool2D()(x)\n\n#Adicionaremos mais camadas convolucionais, seguidas de MaxPool\nx = Conv2D(8, 3, padding='same', activation='relu')(x)\nx = MaxPool2D()(x)\nx = Conv2D(12, 3, padding='same', activation='relu')(x)\nx = MaxPool2D()(x)\nx = Conv2D(12, 3, padding='same', activation='relu')(x)\nx = MaxPool2D()(x)\nx = Conv2D(20, 5, padding='same', activation='relu')(x)\nx = MaxPool2D()(x)\nx = Conv2D(20, 5, padding='same', activation='relu')(x)\nx = MaxPool2D()(x)\nx = Conv2D(50, 5, padding='same', activation='relu')(x)\nx = GlobalAveragePooling2D()(x)\n\n#Finalmente adicionaremos duas camadas densas, chamadas de 'Fully Connected Layers'.\n#Essas camadas s\u00e3o redes neurais n\u00e3o convolucionais.\n#Estas camadas recebem os par\u00e2metros das primeiras e ajudam a realizar a classifica\u00e7\u00e3o dos resultados\nx = Dense(128, activation='relu')(x)\n\n#Dropout \u00e9 uma t\u00e9cnica para reduzir overfitting onde exclu\u00edmos parte dos neur\u00f4nios de uma camada.\nx = Dropout(0.6)(x)\n\nx = Dense(32, activation='relu')(x)\n\n#Nossa camada de \"output\" tem o argumento \"1\" pois a sa\u00edda da rede \u00e9 a classifica\u00e7\u00e3o derrame x n\u00e3o-derrame\n#Ou seja, a sa\u00edda da rede \u00e9 apenas um n\u00famero (0 ou 1)\noutputs = Dense(1, activation='sigmoid')(x)\n\ninputs = imgs\n\n#Por fim, definiremos nossa rede com a entrada e a sa\u00edda da rede\nRadEinstein_CNN = Model(inputs=inputs, outputs=outputs)\n\n#Agora, definiremos o m\u00e9todo de otimiza\u00e7\u00e3o da rede: ADAM, com a taxa de aprendizado e de decaimento\n#Cada um desses par\u00e2metros \u00e9 ajust\u00e1vel.\ncustom_adam = optimizers.Adam(lr=0.0005, decay=0.0002)\n\n#Compila o modelo definindo o tipo de fun\u00e7\u00e3o 'loss', otimiza\u00e7\u00e3o e a m\u00e9trica.\nRadEinstein_CNN.compile(loss='binary_crossentropy', optimizer=custom_adam, metrics=['acc'])\n\nprint('Veja abaixo as camadas da sua rede neural' )\nprint('Note que cada camada cont\u00e9m uma quantidade diferente de par\u00e2metros a serem treinados')\nprint('No final da lista, note que nossa rede cont\u00e9m um total de 54.627 par\u00e2metros trein\u00e1veis')\nprint ('\\nRadEinstein_CNN Sumary')\nRadEinstein_CNN.summary()\nprint ('\\nEtapa Conclu\u00edda. V\u00e1 para a pr\u00f3xima!')","44d2b0ff":"import time #Fun\u00e7\u00e3o time para medirmos o tempo de treinamento\n\ncheckpointer = ModelCheckpoint(filepath='Melhor_modelo.hdf5', monitor='val_loss',\n                               verbose=1, save_best_only=True) #Salvar o melhor modelo que for encontrado durante o treino\n\nprint('Treinando a Rede RadEinstein_CNN:')\n\nValida = (dataset_val, labels_val)\n\n# Finalmente vamos treinar a nossa rede\n# Se quiser treinar sua rede um pouco mais, altere o n\u00famero de epochs, \n# e vamos ver os diferentes resultados.\n\nstart_time = time.time()\nhist = RadEinstein_CNN.fit_generator(datagen.flow(dataset_train, labels_train, batch_size=16), \n                                     steps_per_epoch=len(dataset_train), \n                                     epochs=10, \n                                     validation_data= (dataset_val, labels_val), \n                                     callbacks=[checkpointer])\n\n#Definimos o treinamento com o dataset de treino, realizando valida\u00e7\u00e3o no dataset de valida\u00e7\u00e3o.\n#O treinamento n\u00e3o usa o dataset de teste, ficar\u00e1 guardado para avaliarmos nossa rede depois.\n\ntempo = str(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time)))\nprint('')\nprint('Treino finalizado em %s' % tempo)\n\n#Por fim, plotamos os resultados de evolu\u00e7\u00e3o da medida de erro (loss) e acur\u00e1cia ao longo dos epochs\nplt.plot(hist.history['loss'], 'b-', label='train loss')\nplt.plot(hist.history['val_loss'], 'r-', label='val loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.show()\n\nplt.plot(hist.history['acc'], 'b-', label='train accuracy')\nplt.plot(hist.history['val_acc'], 'r-', label='val accuracy')\nplt.ylabel('acc')\nplt.xlabel('epoch')\nplt.show()\n\nprint ('\\nAgora vamos avaliar o modelo no dataset de teste. Vamos para a pr\u00f3ximo comando.')\n\n#Execute esse c\u00f3digo com SHIFT + ENTER","bdf625ef":"from keras.models import load_model #Vamos importar a fun\u00e7\u00e3o do keras que abre modelos salvos previamente\n\nmelhor_modelo = load_model('Melhor_modelo.hdf5') #Abrimos o melhor modelo que salvamos no treinamento\n\nprint ('\\nPesos da rede neural atualizados para os da melhor \u00e9poca.')\nprint ('\\nEtapa Conclu\u00edda. Vamos para a pr\u00f3xima!')\n#Execute esse c\u00f3digo com SHIFT + ENTER","1cf80781":"#Usamos a fun\u00e7\u00e3o evaluate para avaliar a acur\u00e1cia do nosso modelo no grupo de teste\nprint('Acur\u00e1cia no grupo de teste: ', melhor_modelo.evaluate(dataset_test, labels_test, verbose=0)[1])\n\nprint ('\\033[1m' + 'Etapa Conclu\u00edda. Vamos para a pr\u00f3xima!')\n#Execute esse c\u00f3digo com SHIFT + ENTER","946442ea":"# Instale a biblioteca Keras-vis para visualizarmos como a rede neural enxerga a imagem.\n# Se tiver problemas com a instala\u00e7\u00e3o ative o campo \"internet\" na barra lateral de configura\u00e7\u00f5es -->\n!pip install -q keras-vis\nprint ('\\033[1m' + 'Instala\u00e7\u00e3o conclu\u00edda. Vamos para a pr\u00f3xima etapa!')\n","8808f64a":"# Agora vamos visualizar as predi\u00e7\u00f5es para algumas imagens\n# e visualizar o mapa de ativa\u00e7\u00e3o no nosso dataset de teste.\n\n# Fonte: https:\/\/fairyonice.github.io\/Grad-CAM-with-keras-vis.html\n\nfrom vis.visualization import visualize_cam\nimport matplotlib.cm as cm\nimport random \n\ndef plot_map(grads, classe, predicao):\n    fig, axes = plt.subplots(1,2,figsize=(14,5))\n    axes[0].imshow(np.squeeze(img), cmap='gray')\n    axes[1].imshow(np.squeeze(img), cmap='gray')\n    i = axes[1].imshow(grads,cmap=\"jet\",alpha=0.5)\n    fig.colorbar(i)\n    plt.suptitle(\"Classe: {}. Pred = {}\".format(classe, predicao))\n    \nfor n in range(10):\n    i = random.randrange(0,100)\n    ID_imagem = i\n    \n    img = dataset_test[ID_imagem]\n    layer_idx = 18\n    penultimate_layer_idx = 13\n    class_idx  = 0\n    seed_input = img\n    grad_top1  = visualize_cam(melhor_modelo, layer_idx, class_idx, seed_input, \n                               penultimate_layer_idx = penultimate_layer_idx,#None,\n                               backprop_modifier     = None,\n                               grad_modifier         = None)\n    \n    #Vamos mostrar a qual classe ela pertence\n    _classe = 'normal' if labels_test[ID_imagem]==0 else 'derrame'\n\n    _predicao = melhor_modelo.predict(dataset_test[ID_imagem][np.newaxis,:,...], verbose=0)\n\n    plot_map(grad_top1, _classe, _predicao[0][0])","55769905":"from IPython.display import HTML, display\nprint ('\\n' + '\\033[1m' + '\u00d3timo trabalho! Parab\u00e9ns, voc\u00ea treinou sua primeira rede neural!\\n')\ndisplay(HTML('<img src=\"https:\/\/media0.giphy.com\/media\/S6TEoUBJuGfQCoGl8l\/giphy.gif?cid=ecf05e47oxgcxjd98g6ghdaalezi4jhrkxmig00jf8vhg2np&rid=giphy.gif\">'))\n","6c446b43":"# Antes de come\u00e7ar, vamos entender brevemente o que \u00e9 uma Rede Neural Convolucional (CNN)\n\nAs CNNs s\u00e3o modelos inspirados na biologia do c\u00f3rtex visual dos mam\u00edferos. D. H. Hubel e T. N. Wiesel  propuseram uma explica\u00e7\u00e3o para a maneira como os mam\u00edferos percebem visualmente o mundo ao seu redor usando uma arquitetura em camadas de neur\u00f4nios no c\u00e9rebro, e isso, por sua vez, inspirou os engenheiros a tentar desenvolver mecanismos semelhantes de reconhecimento de padr\u00f5es na vis\u00e3o computacional.\n\n![alt text](https:\/\/github.com\/EPreis\/handsonfigs\/blob\/master\/visualcortex2.jpg?raw=true)\nhttp:\/\/blog.arimaresearch.com\/convolutional-neural-network-cnn\/\n\n\nNa hip\u00f3tese deles, dentro do c\u00f3rtex visual, respostas funcionais complexas geradas por c\u00e9lulas mais \"profundas\" s\u00e3o constru\u00eddas a partir de respostas mais simples de \"c\u00e9lulas iniciais\".\n\nPor exemplo, c\u00e9lulas simples responderiam a linhas especificamente orientadas e bordas, enquanto c\u00e9lulas mais profundas tamb\u00e9m responder\u00e3o a certas orienta\u00e7\u00f5es, mas com um grau progressivo de complexidade.\n\nBasicamente uma c\u00e9lula mais profunda responde a uma soma de entradas de outras c\u00e9lulas mais iniciais.\n\nA arquitetura das redes neurais convolucionais foi inspirada nestas id\u00e9ias.\n\n\n\n","0bb4a3e9":"# **Como o computador enxerga uma imagem?**\n\nConsidere cada imagem como uma matriz em que o valor de cada pixel corresponde a um \nn\u00famero que determina o tom de cinza da imagem.\n\n![alt text](https:\/\/github.com\/EPreis\/handsonfigs\/blob\/master\/8_digits.gif?raw=true)\n\n\nPortanto, para enxergar os contornos de uma imagem nosso algoritmo vai tentar criar filtros que representem estes contornos em n\u00fameros, como no exemplo abaixo.\n\n![alt text](https:\/\/github.com\/EPreis\/handsonfigs\/blob\/master\/contornos.png?raw=true)\n\n\n","9d184691":"O que estamos fazendo agora \u00e9 basicamente tentando achar a menor diferen\u00e7a entre o que o algoritmo prediz e a resposta correta, esta diferen\u00e7a \u00e9 chamada de perda (loss), quanto menor a perda (loss), mais o seu algoritmo esta acertando, consequentemente maior \u00e9 a acur\u00e1cia (acc).\n\n![alt text](https:\/\/i1.wp.com\/francescolelli.info\/wp-content\/uploads\/2019\/05\/NeuralNetworks-input-layer-hidden-layer-output-layer.png?resize=448%2C293&ssl=1)\nFonte: https:\/\/francescolelli.info\/tutorial\/neural-networks-a-collection-of-youtube-videos-for-learning-the-basics\/\n\n\nVeja no gr\u00e1fico abaixo que a rede neural est\u00e1 buscando o ponto de menor perda (loss) (azul mais escuro), mas para chegar l\u00e1 ela pode tenta fazer v\u00e1rios caminhos diferentes de forma aleat\u00f3ria, por isso precisamos repetir o processo v\u00e1rias vezes, at\u00e9 ela achar o melhor caminho e chegar no ponto mais baixo (global minima).\n\n![alt text](https:\/\/regenerativetoday.com\/wp-content\/uploads\/2019\/06\/GradientDescentWithMutlipleLocalMinimum.jpg)\nFonte: https:\/\/regenerativetoday.com\/machine-learning-gradient-descent-concept\/\n\n","e1c354b4":"# Passo 6: Avaliando o seu algoritmo no dataset de Teste","e8ca6cb7":"# Visualizando seus dados\n\nPodemos tamb\u00e9m ver cada uma das imagens do nosso dataset. \n\nVamos visualizar uma imagem com derrame\n\nNa linha \"ID_arquivo\" escolha um numero entre 0 e 349 e rode a c\u00e9lula, pode repetir quantas vezes quiser.","46212050":"Neste passo, iremos apresentar todo o dataset de teste para o modelo que criamos, de forma a calcular a acur\u00e1cia da nossa rede neural num grupo de imagens que o modelo nunca viu antes.","09c4cce4":"** O que \u00e9 uma convolu\u00e7\u00e3o **\n\nUma convolu\u00e7\u00e3o \u00e9 uma opera\u00e7\u00e3o matem\u00e1tca que consiste em multiplicar uma matriz (a nossa imagem) por um filtro (matrix de pesos)\n\n\n\n---\n\n\n\n\nLemba-se de como o computador enxerga um contorno?\nAtrav\u00e9s de uma matriz de n\u00fameros estrat\u00e9gicamente orientados:\n\n\n![alt text](https:\/\/github.com\/EPreis\/handsonfigs\/blob\/master\/Screen-Shot-2017-07-26-at-6.13.41-PM.png?raw=true)\n\n---\n\n\n\nVamos utilizar esses filtros n\u00fam\u00e9ricos para enxergar os contornos ao longo de toda a imagem.\n\n![alt text](https:\/\/media3.giphy.com\/media\/i4NjAwytgIRDW\/giphy.gif?cid=ecf05e47xxytwe09f1mjua95h5exicu1gouki8wgenmql6sy&rid=giphy.gif)\n\n\n\nE repetiremos essa opera\u00e7\u00e3o v\u00e1rias vezes para nossa rede enxergar caracter\u00edsticas cada vez mais complexas, gerando filtros decontornos assim como j\u00e1 mostrado acima na famosa imagem da Lena:\n\n![alt text](https:\/\/github.com\/EPreis\/handsonfigs\/blob\/master\/contornos.png?raw=true)","cc584748":"# Passo 3: Dividindo o dataset nos grupos Treinamento\/Valida\u00e7\u00e3o\/Teste\n\n![alt text](https:\/\/github.com\/edureisMD\/handsonfigs\/blob\/master\/Captura.png?raw=true)","97faefee":"## Vamos ver a predi\u00e7\u00e3o caso a caso","48207d9c":"Durante o treinamento da rede, os pesos das sinapses de todas as camadas s\u00e3o atualizados.\n\nAp\u00f3s a conclus\u00e3o do treinamento, cada filtro representar\u00e1 uma caracter\u00edstica de imagem a ser procurada nas imagens do nosso dataset.\n\nProcure na linha \"hist\" que definimos alguns hyperparameters, como por exemplo o n\u00famero de epochs para 60, que significa por quantas repeti\u00e7\u00f5es (\u00e9pocas) faremos o treinamento. Se quiser treinar um pouco mais a sua rede, altere o n\u00famero para at\u00e9 100 epochs, e vamos ver os diferentes resultados.\n\nCom estes par\u00e2metros, dever\u00e1 levar entre 5 e 10 minutos para treinar seu modelo.","5318e9d4":"# Hands-on - Deep Learning para Reconhecimento de Padr\u00f5es em Imagem\n### Detec\u00e7\u00e3o de Derame Pleural em Rx de T\u00f3rax\n\nEduardo Pontes Reis, Felipe Nascimento","264f8279":"# Passo 5: criando a estrutura da rede neural convolucional","5f4d6eb5":"**OBJETIVO:**\n\nDemonstrar os passos b\u00e1sicos do treinamento de uma rede neural convolucional para detectar derrame pleural.\n","f92ca48c":"# Passo 5: Treinando a sua rede neural","90c508d9":"# Passo 2 - Criando os Lables e transformando nossas imagens em matrizes (n\u00fameros)\n\nPrecisamos informar explicitamente a qual das categorias as imagens pertecem em uma lista chamada labels (derrame = 1, normal = 0)\n\nFaremos isso ao mesmo tempo que salvaremos as imagens numa matriz, pois como as redes neurais tem entrada de tamanho fixo, precisaremos redimensionar todas as imagens para um tamanho \u00fanico que deve ser exatamente o mesmo da primeira camada da nossa rede neural convolucional (Input Layer), imagine que cada pixel ser\u00e1 transformado em um n\u00famero que vai entrar em cada neuronio da primeira camada, no nosso caso utilizaremos um tamanho de 256 x 256 pixels.","bca88cbc":"## Rode a \u00faltima c\u00e9lula para concluir o treinamento:","836ccdf1":"# Passo 4: Data Augmentation\n\nN\u00f3s temos um dataset pequeno, o que eleva a chance de overfiting do nosso modelo, ou seja, nosso modelo fica muito especializado apenes Rx de t\u00f3rax que apresentamos, n\u00e3o conseguindo generalizar para os mais variados Rx de t\u00f3rax do mundo real, com posi\u00e7\u00f5es diferentes, etc...\n\nPara tentar aumentar artificialmente o n\u00famero de exemplos, vamos utilizar uma t\u00e9cnica chamada Data Augmentation, que levemente roda e muda a posi\u00e7\u00e3o da imagem aleat\u00f3riamente antes de apresentar para a rede neural. \n\n![alt text](https:\/\/github.com\/EPreis\/handsonfigs\/blob\/master\/aug.002.jpeg?raw=true)","12749647":"# Vamos come\u00e7ar\n# Passo 1: Criando o dataset\n\n**Dataset:**\n\n    O NIH ChestXray14 cont\u00e9m cerca de 110.000 raio x de t\u00f3rax anotados em 14 diferentes categorias\n\nO conjunto de dados que vamos uttilizar consiste de 350 imagens de Rx de t\u00f3rax normais e 350 Rx com derrame, retiradas e selecionadas do dataset p\u00fablico NIH ChestXray14.\n\n\n** Siga as instru\u00e7\u00f5es em texto e em azul dentro das c\u00e9lulas. **\n#### Para executar cada c\u00e9lula, pressione SHIFT + ENTER","f77047a2":"**REFER\u00caNCIAS:**\n\nUtilizaremos imagens selecionadas do dataset p\u00fablico NIH ChestXray14.\n\nParte do material did\u00e1tico foi baseado no tutorial \n[https:\/\/github.com\/llSourcell\/Convolutional_neural_network](https:\/\/github.com\/llSourcell\/Convolutional_neural_network)\ne parte do c\u00f3digo no workshop realizado na JPR2018 e outros c\u00f3digos open source\n\n","9822b2cf":"**RECURSOS:**\n\nO notebook do Kaggle \u00e9 um computador em nuvem rodando um ambiente python j\u00e1 com todas as configura\u00e7\u00f5es necess\u00e1rias para machine learning instaladas.\n\nTodo o processo ser\u00e1 realizado com a linguagem Python, e bibliotecas como Keras\/Tensorflow, Numpy, openCV, SKlearn, etc...\n\nVoc\u00ea ver\u00e1 que importaremos as bibliotecas espec\u00edficas para cada tarefa ao longo do processo."}}