{"cell_type":{"ceaaa40e":"code","ceb8a2b8":"code","1ebd6f6b":"code","814b0990":"code","7f31f313":"code","384c990a":"code","8e9d7f2c":"code","d270238a":"code","a52649a3":"code","2da94752":"code","b101ab01":"code","f9c046fa":"code","f237c6a5":"code","744373a3":"markdown","8abea5ea":"markdown","5967eed9":"markdown","738e2dd1":"markdown","8a47ce1b":"markdown","ecc35327":"markdown","87e9a30d":"markdown","1dd00bb6":"markdown"},"source":{"ceaaa40e":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.callbacks import Callback\n\nfrom sklearn.metrics import f1_score, make_scorer\n\nimport numpy as np\nimport pandas as pd\n\nimport os","ceb8a2b8":"batch_size = 16\nNAMA_PRAKTIKUM = \"if4074-praktikum-1-cnn\"\nIMG_BASE_DIR = f'..\/input\/{NAMA_PRAKTIKUM}'\nIMG_TRAIN_DIR = f\"{IMG_BASE_DIR}\/P1_dataset\/train\"\nIMG_TEST_DIR = f\"{IMG_BASE_DIR}\/P1_dataset\/\"\n\nIMG_WIDTH = 256\nIMG_HEIGHT = 256\n\nCLASS_MODE = \"categorical\"\n\n# this is the augmentation configuration we will use for training\n# initial load, no preprocessing\ntrain_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        validation_split=0.15\n)\n\n# this is the augmentation configuration we will use for testing:\n# only rescaling\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# this is a generator that will read pictures found in\n# subfolers of 'data\/train', and indefinitely generate\n# batches of augmented image data\ntrain_generator = train_datagen.flow_from_directory(\n        IMG_TRAIN_DIR,  # this is the target directory\n        target_size=(IMG_WIDTH, IMG_HEIGHT),  # all images will be resized to 150x150\n        batch_size=batch_size,\n        subset=\"training\",\n        class_mode=CLASS_MODE  \n) \n\n# this is a similar generator, for validation data\nvalidation_generator = train_datagen.flow_from_directory(\n        IMG_TRAIN_DIR,\n        target_size=(IMG_WIDTH, IMG_HEIGHT), \n        batch_size=batch_size,\n        subset=\"validation\",\n        class_mode=CLASS_MODE\n)\n\n# this is a similar generator, for test data\ntest_generator = test_datagen.flow_from_directory(\n        IMG_TEST_DIR,\n        target_size=(IMG_WIDTH, IMG_HEIGHT), \n        # only read images from `test` directory\n        classes=['test'],\n        # don't generate labels\n        class_mode=None,\n        # don't shuffle\n        shuffle=False,\n)","1ebd6f6b":"if K.image_data_format() == 'channels_first':\n    input_shape = (3, IMG_WIDTH, IMG_HEIGHT)\nelse:\n    input_shape = (IMG_WIDTH, IMG_HEIGHT, 3)","814b0990":"N_CLASS=4\n    \n# CONVOLUTIONAL LAYER\n## CONV 1\nmodel = Sequential()\nmodel.add(Conv2D(64, (3, 3), input_shape=input_shape))\nmodel.add(Activation('relu'))\n\n## CONV 2\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n\n# DENSE LAYER\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\n\n# OUTPUT LAYER\nmodel.add(Dense(N_CLASS))\nmodel.add(Activation('softmax'))","7f31f313":"model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=[\n                  'accuracy',\n                  tf.keras.metrics.Precision(),\n                  tf.keras.metrics.Recall()\n              ],)\n\nmodel.summary()","384c990a":"N_CLASS=4\n    \n# CONVOLUTIONAL LAYER\n## CONV 1\nmodel_1 = Sequential()\nmodel_1.add(Conv2D(32, (3, 3), input_shape=input_shape))\nmodel_1.add(Activation('relu'))\nmodel_1.add(MaxPooling2D(pool_size=(2, 2))) # added\n\n## CONV 2\nmodel_1.add(Conv2D(64, (3, 3)))\nmodel_1.add(Activation('relu'))\nmodel_1.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2))) \n\n## CONV 3\nmodel_1.add(Conv2D(128, (3, 3))) # added\nmodel_1.add(Activation('relu')) # added\nmodel_1.add(MaxPooling2D(pool_size=(2, 2))) # added\n\n## CONV 3\nmodel_1.add(Conv2D(255, (3, 3))) # added\nmodel_1.add(Activation('relu')) # added\nmodel_1.add(MaxPooling2D(pool_size=(2, 2))) # added\n\n# DENSE LAYER\nmodel_1.add(Flatten())\nmodel_1.add(Dense(256))\nmodel_1.add(Activation('relu'))\nmodel_1.add(Dropout(0.5)) # added\nmodel_1.add(Dense(256))\nmodel_1.add(Activation('relu'))\n\n# OUTPUT LAYER\nmodel_1.add(Dropout(0.5)) # added\nmodel_1.add(Dense(N_CLASS))\nmodel_1.add(Activation('softmax'))","8e9d7f2c":"model_1.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=[\n                  'accuracy',\n                  tf.keras.metrics.Precision(),\n                  tf.keras.metrics.Recall()\n              ],)\n\nmodel_1.summary()","d270238a":"CHOSEN_MODEL = \"ripVGG-modified\"\n\nif CHOSEN_MODEL == \"ripVGG-modified\":    \n    model = model_1\nif CHOSEN_MODEL != \"ripVGG-modified\" and CHOSEN_MODEL != \"ripVGG\":\n    raise Exception(\"CHOSEN_MODEL must be either ripVGG or ripVGG-modified\")","a52649a3":"epochs=80\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples \/\/ batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples \/\/ batch_size,\n    )","2da94752":"import matplotlib.pyplot as plt\n\npd.Series(history.history['val_accuracy']).plot()\nplt.title(f\"Validation Accuracy over {epochs} epochs\")","b101ab01":"pd.Series(history.history['val_loss']).plot()\nplt.title(f\"Validation Loss over {epochs} epochs\")","f9c046fa":"preds = model.predict_classes(\n    test_generator)\n\ndef truncate_filename(x):\n    return x.replace(\"test\/\", \"\")\n\nsubmission = pd.DataFrame()\nsubmission['id'] = pd.Series(test_generator.filenames).apply(truncate_filename)\nsubmission['label'] = preds # np.argmax(preds, axis=1)\nsubmission","f237c6a5":"try:\n    SUB_NUM += 1\nexcept:\n    SUB_NUM = 0\n    \nsubmission.to_csv(f\"submission{SUB_NUM}.csv\", index=False)","744373a3":"### Define Model","8abea5ea":"### Predict","5967eed9":"## Image Loader","738e2dd1":"### Model Base: RipVGG","8a47ce1b":"### Pembagian Tugas\n\n\n| NIM      | NAMA                     | Pembagian Tugas |\n|----------|--------------------------|-----------------|\n| 13517042 | Muhamad Nobel Fauzan     | Implementasikan neural network dengan arsitektur ripVGG, Modifikasikan arsitektur ripVGG |\n| 13517062 | Ardysatrio Fakhri Haroen | Muat data latih serta data uji, Implementasikan neural network dengan arsitektur ripVGG, Modifikasikan arsitektur ripVGG |\n| 13517066 | Willy Santoso            | Implementasikan neural network dengan arsitektur ripVGG, Modifikasikan arsitektur ripVGG |\n\nCatatan: Pengerjaan dilakukan dengan pair programming menggunakan Google Meet, sehingga setiap anggota mengerjakan semua bagian","ecc35327":"### Train Model","87e9a30d":"### Model Modifikasi 1\n\nKami melakukan beberapa modifikasi terhadap ripVGG untuk meningkatkan performa\n\n#### 1. Add Dropout 0.5 di 2 Layer terakhir untuk reduce overfitting <br>\n        \nDropout merupakan metode dimana beberapa node di suatu dense layer diabaikan dalam fase training. Hal ini berguna untuk mengurangi overfitting karena penambahan dropout memasukkan suatu unsur \"acak\" ke dalam fase pelatihan model, sehingga model tidak menyesuaikan inputnya hanya dengan variansi data yang ada. Berhubung ripVGG menggunakan 2 layer dense, kami menambahkan dropout ke masing-masing layer dense tersebut untuk mencegah overfitting di keduanya. \n    \nKami juga menerapkan strategi dropout yang cukup agresif (0.5), yakni 50% dari node yang ada di suatu dense layer secara random tidak diikutkan pada proses training\n\n#### 2. Add 2 Convolutional Layer untuk meningkatkan performa feature extraction <br>\n\nKami melihat beberapa referensi, diantaranya:\n1. https:\/\/blog.keras.io\/building-powerful-image-classification-models-using-very-little-data.html\n2. https:\/\/www.geeksforgeeks.org\/vgg-16-cnn-model\/\n    \nDan kami berpikir bahwa jumlah convolutional layer yang ada di RipVGG masih sangat sedikit, dan kami pikir hal tersebut berpengaruh buruk terhadap kemampuan model untuk mengekstraksi fitur. Oleh karena itu kami menambahkan 2 convolutional layers untuk meningkatkan kemampuan model mengekstraksi fitur.\n    \nSelain itu, kami juga memodifikasi jumlah filter agar merupakan kelipatan 32, karena dari sumber yang kami baca, pada training menggunakan GPU, proses filter-nya menggunakan  block-block yang kelipatan 32 thread. \n    \nKami hanya menambahkan 2 layer agar tidak terlalu banyak filter yang diproses di akhir convolutional layers.\n#### 3. Jumlah feature map di setiap Convolutional Layers dibuat meningkat seiring mendekati output layer, mengikuti pola pada VGG-16 <br> \n\nKami melihat pola arsitektur VGG-16 dan melihat bahwa semakin mendekati output layer, maka semakin banyak pula feature map yang ada. \n\n#### 4. Add Pooling di setiap Convolutional Layer untuk reduce overfitting <br>\n\nKami menambahkan pooling di setiap akhir convolutional layer untuk mengurangi overfitting. Pola yang sama juga kami lihat ada pada VGG-16 dimana setiap akhir convolutional layer terdapat pooling.\n\n#### 5. Kurangi Nodes di Dense layer menjadi 256 untuk reduce overfitting <br>\n\nBanyaknya node di Dense layer akan memengaruhi performa model dan terjadinya overfitting. Jika node terlalu banyak, maka model akan belajar terlalu menyesuaikan variansi dari data yang ada dan sulit untuk menggeneralisasi. Oleh karena itu, kami kurangi node nya menjadi 1\/2 dari awal untuk mengurangi overfitting.\n    \nSelain itu, pengurangan node ini akan menghemat resource waktu dan memori untuk training\n\n#### 6. Mengurangi Batch Size\n\nKami mengurangi batch size dari 32 menjadi 16 agar perubahan weight lebih banyak terjadi dalam satu epoch, dan harapannya jumlah epoch yang dibutuhkan model untuk mencapai performa optimal dapat berkurang. Hal ini diharapkan dapat mengurangi training time.","1dd00bb6":"## Modelling"}}