{"cell_type":{"2abfa7db":"code","083bfbc0":"code","77f154d0":"code","b74f7c5b":"code","fbe538ce":"code","c233581a":"code","d13614e5":"code","d3d45d28":"code","016f7c3c":"code","f1bc243a":"code","1a63e00a":"code","09882dd1":"code","bb9a08da":"code","e0182370":"code","ca0411e6":"code","333813c0":"code","3d4d097b":"markdown","e49acab9":"markdown","b3d3fa19":"markdown","747ba0ec":"markdown","69cd34f9":"markdown","e76c8e76":"markdown","f6cad6b5":"markdown","82be989f":"markdown","a230e435":"markdown","7dca2772":"markdown","f2db5efb":"markdown","75c719e5":"markdown","746e02f9":"markdown","6c5294b5":"markdown","432a8d4f":"markdown","6b30897b":"markdown","e7fbebcd":"markdown","14ae81f2":"markdown","9d41b854":"markdown"},"source":{"2abfa7db":"from pandas import read_csv\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import scatter_matrix\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nimport numpy as np","083bfbc0":"df = pd.read_csv('..\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv')\ndf.head()","77f154d0":"# indexing on Serial No.\ndf.set_index('Serial No.', inplace = True)","b74f7c5b":"df.head()","fbe538ce":"# luckily we're only dealing with numbers and clean up of NaN values\/invalid values is unecessary\ndf.info()","c233581a":"df.hist(bins = 50, figsize = (20, 15))\nplt.show()","d13614e5":"scatter_matrix(df)\nplt.show()","d3d45d28":"corr_matrix = df.corr()\ncorr_matrix[\"Chance of Admit \"].sort_values(ascending = False)","016f7c3c":"corr_matrix","f1bc243a":"train_set, test_set = train_test_split(df, test_size = 0.25, random_state = 42)\n# training set\nX_train = train_set.values[:,0:7]\ny_train = train_set.values[:,7]\n\n# test set\nX_test = test_set.values[:,0:7]\ny_test = test_set.values[:,7]","1a63e00a":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\nminmax_scaler = MinMaxScaler(feature_range = (0, 1)).fit(X_train)\nstandard_scaler = StandardScaler().fit(X_train)\n\n# Min-Max \nX_train_MM = minmax_scaler.transform(X_train)\nX_test_MM = minmax_scaler.transform(X_test)\n\n# Standard Scaler\nX_train_ST = standard_scaler.transform(X_train)\nX_test_ST = standard_scaler.transform(X_test)","09882dd1":"from sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.svm import LinearSVR\nfrom sklearn.tree import DecisionTreeRegressor \n\nmodels = []\nmodels += [['Ridge', Ridge(alpha = 0.9, solver = \"cholesky\")]]\nmodels += [['Lasso', Lasso(alpha = 1)]]\nmodels += [['Elastic Net', ElasticNet(alpha = 0.1, l1_ratio = 0.25)]]\nmodels += [['SVM', LinearSVR()]]\nmodels += [['Tree', DecisionTreeRegressor()]]","bb9a08da":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\n\nkfold = KFold(n_splits = 5, random_state = 42)\nresult_MM =[]\nnames = []\n\nfor name, model in models:\n    cv_score = -1 * cross_val_score(model, X_train_MM, y_train, cv = kfold, scoring = 'neg_root_mean_squared_error')\n    result_MM +=[cv_score]\n    names += [name]\n    print('%s: %f (%f)' % (name,cv_score.mean(), cv_score.std()))","e0182370":"result_ST =[]\nfor name, model in models:\n    cv_score = -1 * cross_val_score(model, X_train_ST, y_train, cv = kfold, scoring = 'neg_root_mean_squared_error')\n    result_MM +=[cv_score]\n    print('%s: %f (%f)' % (name,cv_score.mean(), cv_score.std()))","ca0411e6":"# training the models\nRidge_model_MM = Ridge(alpha = 0.9, solver = \"cholesky\").fit(X_train_MM, y_train)\nRidge_model_ST = Ridge(alpha = 0.9, solver = \"cholesky\").fit(X_train_ST, y_train)\n\n# getting predictions\npredictions_MM = Ridge_model_MM.predict(X_test_MM)\npredictions_ST = Ridge_model_ST.predict(X_test_ST)","333813c0":"from sklearn.metrics import mean_squared_error\nprint(\"Ridge, Min Max: \" + str(np.sqrt(mean_squared_error(y_test, predictions_MM))))\nprint(\"Ridge, Standard Scaler: \" + str(np.sqrt(mean_squared_error(y_test, predictions_ST))))","3d4d097b":"Now evaluating our models","e49acab9":"Using Standard Scaler results in a lower RMSE score, so our final model to choose to predict university admission is Ridge Regression model <br>\n\nP.S. This is my first ever Kaggle submission, please give me comments\/advice\/areas to improve on!","b3d3fa19":"<h4> Min Max\n    ","747ba0ec":"The data has 7 total attributes:\n1. GRE Score (340 max)\n2. TOEFL Score (120 max)\n3. University Rating (5 max)\n4. Statement of Purpose (5 max)\n5. Letter of Reccomendation (5 max)\n6. Undergraduate GPA (10 max)\n7. Research Experience (1 max)","69cd34f9":"It seems like the TOEFL score, GRE score and CGPA have the highest correlation with university admittance. However, let's look at how all attributes relate to each other","e76c8e76":"<h4> Standard Scaler","f6cad6b5":"<h2> Evaluation","82be989f":"From first glance it seems that the chance of admission has a strong correlation with:\n1. CGPA\n2. LOR\n3. SOP\n4. TOEFL score\n5. GRE score \n\nand a weak correlation with:\n1. University rating \n2. Research\n\nLet's check the correlation coefficient between the different attributes:","a230e435":"<h2> Model Creation","7dca2772":"Task at hand is to predict the likelihood of admission","f2db5efb":"<h2> Get the Data","75c719e5":"<h2> Preparing Data","746e02f9":"<h2> Explore Data","6c5294b5":"Several models will be compared:\n1. Ridge Regression\n2. Lasso Regression\n3. Elastic Net\n4. SVM\n5. Decision Tree","432a8d4f":"both min-max and StandardScaler will be used and compared. Note that both scalers are fit on the training data set and then applied to the test set as well. ","6b30897b":"We are dealing with labelled data that is continuous so our model will be a supervised regression model","e7fbebcd":"Once again, Ridge and SVM are the top two models with respective RMSE scores of 0.060759 and 0.061416. Using both Min Max and StandardScaler, Ridge Regression seems to have the least amount of error in both cases so let us continue with this model","14ae81f2":"From a quick glance, it appears that all attributes are related, either strongly or weakly, to other attributes. Fortunately, this should not affect the predictive power of our machine learning model. \n\nNow creating the training and testing set. Because of our extremely small dataset sample (500 entries total), we will split on the training and testing set on a 3:1 ratio to prevent overfitting of our model.","9d41b854":"From this, it seems like Ridge linear regression is the best choice (RMSE = 0.061186) with SVM in close second place (RMSE = 0.061156). Note that the constant -1 was multiplied to the cross_val_score simply to make the RMSE positive"}}