{"cell_type":{"4bae4e59":"code","6b8d3fc3":"code","c836ae05":"code","075c8766":"code","7013b08a":"code","4490e8e6":"code","1e4284f4":"code","f341a035":"code","3973f6af":"code","7b88bc0e":"code","518e96df":"code","2467b4da":"code","8cb3e85e":"code","96802648":"code","5771a3d5":"code","545470cf":"code","2865cb61":"code","68fa10ad":"markdown","11a98b00":"markdown","1594dc5d":"markdown","61f5f63b":"markdown","b109be1c":"markdown","5b06ea56":"markdown","6375f9fb":"markdown","e3b5f928":"markdown","b8b77904":"markdown"},"source":{"4bae4e59":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\nprint(os.listdir(\"..\/input\"))\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as transforms\nfrom PIL import Image\n\nfrom tqdm import tqdm_notebook as tnote\ntorch.manual_seed(42)","6b8d3fc3":"from zipfile import ZipFile\nwith ZipFile('..\/input\/images.zip', 'r') as zipObj: # Unzipping images\n   # Extract all the contents of zip file in current directory\n   zipObj.extractall()","c836ae05":"print(os.listdir(\"..\/input\"))","075c8766":"train_path = \"..\/input\/train.csv.zip\"\ndata = pd.read_csv(train_path)\ndata.head()","7013b08a":"data.loc[:,['id','species']].head()","4490e8e6":"class LeafLoader(Dataset):\n    \"\"\"Loads the Leaf Classification dataset.\"\"\"\n\n    def __init__(self, csv_file, transform=None):\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n\n        # First 2 columns contains the id for the image and the class of the image\n        self.dict = self.data.iloc[:,:2].to_dict()\n        # When we index we want to get the id\n        self.ids = self.dict[\"id\"]\n        \n\n        self.classes = self.data[\"species\"].unique() # List of unique class names\n        self.class_to_idx = {j: i for i, j in enumerate(self.classes)} \n        # Assigns number to every class in the order which it appears in the data\n        self.species = self.dict[\"species\"]\n        # Use this go back to class name from index of the class name\n        self.path_leaf = \"images\" # Where the images are stored\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n\n        if torch.is_tensor(idx):\n            idx = idx.item()\n            assert isinstance(idx, int)\n\n        num = self.ids[idx] # Id of the indexed item\n        loc = f\"\/{num}.jpg\"\n        label = self.dict[\"species\"][idx] # Find the label\/class of the image at given index\n        label = self.class_to_idx[label] # Convert it to int\n        image = Image.open(self.path_leaf + loc)\n        if self.transform:\n            image = self.transform(image)\n\n        return (image, label)","1e4284f4":"image_size = (28,28)\nnormalize = ((0.5), (0.5))\n\ntransform = transforms.Compose([transforms.Resize(image_size),transforms.ToTensor(), transforms.Normalize(*normalize)])\ndataset = LeafLoader(train_path,transform)\n\ntrain_size = int(0.8 * len(dataset)) # 80% of the data to be used for training\ntest_size = len(dataset) - train_size # The remainder for testing\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n# Function above takes dataset, and lengths of train,test as input that's what we a supplying here\n\nbatch_size = 16\ntrainloader_dataset = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntestloader_dataset = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)","f341a035":"def subplot_random():\n    im, lab = next(iter(trainloader))\n    fig=plt.figure(figsize=(15, 15))\n\n    for idx,(i,j) in enumerate(zip(im,lab)):\n        idx +=1\n        ax = fig.add_subplot(4,4,idx)\n        ax.imshow(i.squeeze().numpy())\n        ax.set_title(dataset.idx_to_class[j.item()])\n    plt.show()\n\nsubplot_random() # We plot a batch using this helper function","3973f6af":"import shutil # To copy files from one directory to another","7b88bc0e":"# Create a list of species to iterate on\nlabels = data.species.values.tolist() # Labels are the species of the leafs\ndef make_folders(verbose=False):\n    folder_count = 0\n    root = 'Data\/'\n    print('Total labels = ',len(set(labels)))\n    for i in set(labels):\n        os.makedirs(f'{root}{i}') # Make directories similar to Data\/class_name\n        folder_count += 1\n    print(\"Total folders = \", folder_count )\n    print(f\"Root is {root}\")\nmake_folders()","518e96df":"# Since we know that we have 10 images for each class we can define a function that splits  \n# the list once it reaches a length of 10\ndef create_chunks(list_name, n):\n    for i in range(0, len(list_name), n):\n        yield list_name[i:i + n]","2467b4da":"species_list = data.sort_values('species').species.unique().tolist() # Unique species\nid_list = list(create_chunks(data.sort_values('species').id.values.tolist(),10)) # list of lists with sublist length of 10\ndict_train = dict(zip(species_list,id_list))","8cb3e85e":"# Checks if the data is correct\nfor key,val in dict_train.items():\n    assert sorted(data[data.species == key].id.tolist()) == sorted(val)","96802648":"for item,key in dict_train.items():\n    for i in range(10):\n        path1 = f'images\/{str(dict_train.get(item)[i])}.jpg'\n        path2 = f'Data\/{item}'\n        shutil.copyfile(path1,path2+'\/'+str(dict_train.get(item)[i])+'.jpg')","5771a3d5":"root = 'Data\/'\ntransform = transforms.Compose([transforms.Resize(image_size),\n                               transforms.Grayscale(num_output_channels=1),\n                               transforms.ToTensor(),\n                               transforms.Normalize(*normalize)\n                               ])\ndataset_fold = ImageFolder(root, transform= transform)\ntrain,valid = random_split(dataset,[train_size,test_size])\n\n# To load our data in batches\ntrain_loader_folder = DataLoader(train, batch_size=16, shuffle=True)\nvalid_loader_folder = DataLoader(valid, batch_size=16, shuffle=False)\n","545470cf":"assert len(trainloader_dataset) == len(train_loader_folder)\nassert len(testloader_dataset) == len(valid_loader_folder)","2865cb61":"shutil.rmtree(\"Data\")\nshutil.rmtree(\"images\")","68fa10ad":"We can then apply our standard transformations and load data into `DataLoader`","11a98b00":"1. To load data into Pytorch we are going to define a class which inherits from the `data.Dataset` class.\n2. By creating this class we will be able to use the `DataLoader` which simplifies the training\/validatation process. \n3. But first we need to implement `__len__` and `__getitem__` methods for the `LeafLoader` object","1594dc5d":"# References:\n`create_chunks(list_name, n):` from [DataCamp](https:\/\/www.datacamp.com\/community\/tutorials\/lists-n-sized-chunks)\n","61f5f63b":"# Image Folder Method","b109be1c":"The only two columns we are interested are id and species columns.","5b06ea56":"# Dataset Method","6375f9fb":"Now we can plot a batch of images to check if it's working properly","e3b5f928":"Image Folder Method is expecially useful when your data is structed in the following way.\n- root\/Acer_Capillipes\/1196.jpg\n- root\/Acer_Capillipes\/227.jpg\n- root\/Acer_Capillipes\/990.jpg\n- .\n- .\n- .\n- root\/Zelkova_Serrata\/1410.jpg\n- root\/Zelkova_Serrata\/718.jpg\n- root\/Zelkova_Serrata\/1136.jpg\n\n\nHowever, in this example the data is not structured in that way so we will get it in that form.","b8b77904":"Lets take a quick look at how the data is structured."}}