{"cell_type":{"c4f8e5ee":"code","38fe8b5c":"code","5100f08b":"code","78255c9f":"code","11a2139b":"code","9ca6b2a6":"code","883ee723":"code","c2983fc0":"code","42e34682":"code","442c400f":"code","a7d76970":"code","775c157e":"code","ce9da631":"code","e2fe2a2e":"code","a13b5729":"code","f9be545c":"code","f41c3b46":"code","dab58f4b":"code","b3f2c5fb":"code","59ac99b1":"code","229f7a08":"code","589a2829":"code","c042d25c":"code","8c37fdb5":"code","7d123d25":"code","8403bd8a":"code","6a529840":"code","d41c7726":"code","0412c88f":"code","1c42d64f":"code","ccf5094e":"code","1117f53a":"code","e293601e":"code","555a50fe":"code","b15f4d7d":"code","6e8e92a4":"code","cd3c9aa5":"code","e3b39517":"code","5e8683cc":"code","07cf1f8b":"code","ee7ed7a9":"markdown","cc1d7634":"markdown","4c42278a":"markdown","0e6ab33b":"markdown","fc36f92d":"markdown","3e0ce804":"markdown","21412466":"markdown","dfc2b2ff":"markdown","e6fb8795":"markdown","99549464":"markdown","64bc3b92":"markdown","c9b9e21f":"markdown","66b62dfd":"markdown"},"source":{"c4f8e5ee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","38fe8b5c":"df_train_sales = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv\", parse_dates=['date'])\ndf_item_cat = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv\")\ndf_items = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/items.csv\")\ndf_shops = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/shops.csv\")\ndf_test = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/test.csv\")\n\ndf_submission = pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv\")","5100f08b":"df_train_sales.info()","78255c9f":"df_train_sales.head()","11a2139b":"# Creating extra features based on date\ndf_train_sales['year'] = df_train_sales['date'].dt.year\ndf_train_sales['month'] = df_train_sales['date'].dt.month","9ca6b2a6":"df_train_sales_temp = pd.merge(df_train_sales, df_items, on='item_id', how='left')\ndf_train_sales_temp2 = pd.merge(df_train_sales_temp, df_item_cat, on='item_category_id', how='left')\ndf_train_sales_temp3 = pd.merge(df_train_sales_temp2, df_shops, on='shop_id', how='left')\n\ndf_train_sales_temp3.head()","883ee723":"df_train_sales_eda = df_train_sales_temp3.loc[(df_train_sales_temp3['shop_id'].isin(df_test['shop_id'])) &\n                                              (df_train_sales_temp3['item_id'].isin(df_test['item_id']))].copy()\n\ndel df_train_sales_temp, df_train_sales_temp2, df_train_sales_temp3","c2983fc0":"df_train_sales_eda.describe().T","42e34682":"print(\"No. of unique items sold:\", df_train_sales_eda['item_name'].nunique())\n\nx = df_train_sales_eda['item_name'].value_counts()\nnp.log10(x).hist(bins=25)\nplt.xlabel('count of unique item name');\n\nprint(f\"Item name that repeats more than 5 times: {100*x[x>10].shape[0]\/x.shape[0]:1.0f}%\")","442c400f":"only_use_item_names = x[x>10].index","a7d76970":"# Most sold item\nx.nlargest(15)","775c157e":"print(\"No. of unique item category:\", df_train_sales_eda['item_category_name'].nunique())\n\ndf_train_sales_eda['item_category_name'] = df_train_sales_eda['item_category_name'].str.split().str[0]\nx = df_train_sales_eda['item_category_name'].value_counts()\nnp.log10(x).hist(bins=25)\nplt.xlabel('count of unique item name');\n\nprint(f\"Item name that repeats more than 500 times: {100*x[x>5].shape[0]\/x.shape[0]:1.0f}%\")","ce9da631":"only_use_item_cat_name = x[x>5].index","e2fe2a2e":"print(\"No. of unique shop names:\", df_train_sales_eda['shop_name'].nunique())\nx = df_train_sales_eda['shop_name'].value_counts()\nx.hist(bins=25)\nplt.xlabel('count of unique shop name');\n\nprint(f\"Shop name that repeats more than 300 time: {100*x[x>500].shape[0]\/x.shape[0]:1.0f}%\")","a13b5729":"only_use_shop_names = x[x>300].index","f9be545c":"# Most item selling shop\nx.nlargest(5)","f41c3b46":"fig, ax = plt.subplots(figsize=(5,4))\nsns.violinplot(x = df_train_sales_eda[\"year\"]\n               , y = np.log10(df_train_sales_eda['item_price']+0.1)\n               , showfliers=False)","dab58f4b":"# Purchase trend by year\nfig, ax = plt.subplots(figsize=(5,4))\nsns.boxplot(x = df_train_sales_eda[\"year\"]\n               , y = df_train_sales_eda['item_price']\n               , showfliers=False)","b3f2c5fb":"for year in [2013, 2014, 2015]:\n    x = df_train_sales_eda.loc[df_train_sales_eda['year']==year, 'item_name'].value_counts().nlargest(5)\n    print(f\"Year: {year}\\n\", x, '\\n')","59ac99b1":"for year in [2013, 2014, 2015]:\n    x = df_train_sales_eda.loc[df_train_sales_eda['year']==year, 'shop_name'].value_counts().nlargest(5)\n    print(f\"Year: {year}\\n\", x, '\\n')","229f7a08":"fig, ax = plt.subplots(figsize=(15,5))\nsns.countplot(x='shop_name', hue='year'\n              ,data = df_train_sales_eda, ax=ax)\nplt.xticks(rotation=90);","589a2829":"# Top 25 popular shop, by years.\n\nfig, ax = plt.subplots(figsize=(15,5))\nsns.countplot(x='shop_name', hue='year'\n              ,data = df_train_sales_eda.loc[df_train_sales_eda['shop_name'].\\\n                                             isin(df_train_sales_eda['shop_name'].\\\n                                                  value_counts().nlargest(25).index)], ax=ax)\nplt.xticks(rotation=90);","c042d25c":"# Top 25 popular item, by years.\n\nfig, ax = plt.subplots(figsize=(18,5))\nsns.countplot(x='item_name', hue='year'\n              ,data = df_train_sales_eda.loc[df_train_sales_eda['item_name'].\\\n                                             isin(df_train_sales_eda['item_name'].\\\n                                                  value_counts().nlargest(50).index)], ax=ax)\nplt.xticks(rotation=90);","8c37fdb5":"df_train_sales_eda.\\\n    groupby(['shop_name', 'item_name']).\\\n    agg({'item_cnt_day': 'sum'}).\\\n    sort_values('item_cnt_day', ascending=False)","7d123d25":"# Remove -ve or extremely high sales\nnp.log10(df_train_sales_eda['item_price']).hist(bins=25)","8403bd8a":"# Removing outliers in item_price [10, 10000]\ndf_train_sales_eda = df_train_sales_eda.loc[(df_train_sales_eda['item_price'] > 10) & (df_train_sales_eda['item_price'] < 1e4)].copy()","6a529840":"# Remove non +ve item counts\ndf_train_sales_eda = df_train_sales_eda.loc[(df_train_sales_eda['item_cnt_day']>=1) & (df_train_sales_eda['item_cnt_day']<=10)].copy()\n\nnp.log10(df_train_sales_eda['item_cnt_day']).hist(bins=25)","d41c7726":"# Shop name\ndf_train_sales_eda['shop_name'].unique()","0412c88f":"df_train_sales_eda.loc[~df_train_sales_eda['shop_name'].isin(only_use_shop_names), 'shop_name'] = 'Unknown'\ndf_train_sales_eda.loc[~df_train_sales_eda['item_name'].isin(only_use_item_names), 'item_name'] = 'Unknown'\ndf_train_sales_eda.loc[~df_train_sales_eda['item_category_name'].isin(only_use_item_cat_name), 'item_category_name'] = 'Unknown'","1c42d64f":"from sklearn.preprocessing import LabelEncoder\nimport lightgbm as lgb","ccf5094e":"# Label encoding\nlabel_encoder = LabelEncoder()\ndf_train_sales_eda['shop_name'] = label_encoder.fit_transform(df_train_sales_eda['shop_name'])\n\nlabel_encoder = LabelEncoder()\ndf_train_sales_eda['item_category_name'] = label_encoder.fit_transform(df_train_sales_eda['item_category_name'])","1117f53a":"# Create tuple of shop id and item id per date_block_num\n\nmeta_features = ['date_block_num', 'shop_id', 'item_id']\n\ntrain_agg_set = df_train_sales_eda.groupby(meta_features, as_index=False).size()\n\ntrain_agg_set = train_agg_set[meta_features].copy()\n\ntrain_agg_set","e293601e":"df_train_sales_eda.columns","555a50fe":"group1 = df_train_sales_eda.groupby(meta_features, as_index=False).agg({'item_price': 'mean'\n                                                                       ,'item_cnt_day': 'sum'})\n\ntrain_agg_set = pd.merge(train_agg_set, group1, on=meta_features, how='left')\n\ntrain_agg_set = train_agg_set.rename(columns={'item_cnt_day': 'item_cnt_month', 'item_price': 'item_price_mean'})","b15f4d7d":"train_agg_set.describe()","6e8e92a4":"train_agg_set","cd3c9aa5":"# From here heavily influenced by https:\/\/www.kaggle.com\/werooring\/top-3-5-lightgbm-with-feature-engineering\n# Merging train\/test into one\n\ndf_test['date_block_num'] = 34\n\ndf_combo = pd.concat([train_agg_set, df_test.drop('ID', axis=1)], ignore_index=True, keys=meta_features)\ndf_combo = df_combo.fillna(0)","e3b39517":"# Train data (Features)\nX_train = df_combo[df_combo['date_block_num'] < 33]\nX_train = X_train.drop(['item_cnt_month'], axis=1)\n\n# Valid data (Features)\nX_valid = df_combo[df_combo['date_block_num'] == 33]\nX_valid = X_valid.drop(['item_cnt_month'], axis=1)\n\n# Test data (Features)\nX_test = df_combo[df_combo['date_block_num'] == 34]\nX_test = X_test.drop(['item_cnt_month'], axis=1)\n\n# Train data (Target values)\ny_train = df_combo[df_combo['date_block_num'] < 33]['item_cnt_month']\n# Valid data (Target values)\ny_valid = df_combo[df_combo['date_block_num'] == 33]['item_cnt_month']","5e8683cc":"\n# lgb hyper-parameters\nparams = {'metric': 'rmse',\n          'num_leaves': 200,\n          'learning_rate': 0.003, 'feature_fraction': 0.75,\n          'bagging_fraction': 0.75,\n          'bagging_freq': 5, 'force_col_wise' : True,\n          'random_state': 42}\n\n#cat_features = ['shop_id', 'city', 'item_category_id', 'category', 'month']\n\n# lgb train and valid dataset\ndtrain = lgb.Dataset(X_train, y_train)\ndvalid = lgb.Dataset(X_valid, y_valid)\n \n# Train LightGBM model\nlgb_model = lgb.train(params=params,\n                      train_set=dtrain,\n                      num_boost_round=2500,\n                      valid_sets=(dtrain, dvalid),\n                      early_stopping_rounds=250,\n                      #categorical_feature=cat_features,\n                      verbose_eval=250)      ","07cf1f8b":"preds = lgb_model.predict(X_test).clip(0,20)\n\ndf_submission['item_cnt_month'] = preds\ndf_submission.to_csv('submission.csv', index=False)","ee7ed7a9":"### Purchase trend by year","cc1d7634":"### Data cleaning","4c42278a":"### Item count","0e6ab33b":"### Read data","fc36f92d":"### Overall stats","3e0ce804":" No need to train model for shop and items missing in test data?","21412466":"## Preparation for model fitting","dfc2b2ff":"##### Checking diversity of categorical feature item_name and shop_name","e6fb8795":"### Merging tables to form a complete dataset","99549464":"#### Train\/Test","64bc3b92":"### What is most selling item\/shop by year ? ","c9b9e21f":"#### Generating group features","66b62dfd":"All shop seems to have increasing sales trend with increasing years."}}