{"cell_type":{"42ebb30b":"code","ff1aa2c9":"code","babf7f6a":"code","ed62d66e":"code","17a9ee00":"code","38aa22b6":"code","34a9c77e":"code","ace8577d":"code","7060ad4b":"markdown","480a118a":"markdown","a4bb8cf1":"markdown","1920ac15":"markdown"},"source":{"42ebb30b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ff1aa2c9":"# Import training data - review shape and columns\nimport pandas as pd\ntrain = pd.read_csv('\/kaggle\/input\/learn-together\/train.csv', index_col='Id')\nprint(train.info())","babf7f6a":"# Reverse the one hot encoding for Wilderness Area and Soil Type to create one column each for Wilderness Areas and Soil Types which contain all all possible category values\ntrain_1 = train.copy()\ntrain_1['Wild_Area'] = train_1.iloc[:,10:14].idxmax(axis=1)\ntrain_1['Soil_Type'] = train_1.iloc[:,14:54].idxmax(axis=1)\ntrain_1.head()\n# Drop the one hot encoded columns to a get a data frame only with numeric and the categorical columns\ncol_to_drop = np.arange(10,54)\ncol_to_drop\ntrain_1.drop(train_1.columns[col_to_drop], axis = 1, inplace = True)\ntrain_1.dtypes","ed62d66e":"# list of non zero soil types available in training data\navail_soil = train_1.Soil_Type.value_counts().index\nprint(avail_soil)\n\n# Get all possible Soil Types available as features in the original training data as columns\nall_soil = train.columns[14:54]\nprint(all_soil)\n# Check the missing soil types from training data by comparing all_soil and avail_soil\nmiss_soil = np.setdiff1d(all_soil,avail_soil)\nprint(miss_soil)","17a9ee00":"# Make a copy of train df for ML experiments\ntrain_2 = train.copy()\ntrain_2.drop(['Soil_Type7','Soil_Type15', 'Soil_Type8','Soil_Type25'], axis = 1, inplace=True)\ntrain_2.columns\n\n# Separate feature and target arrays as X and y\nX = train_2.drop('Cover_Type', axis = 1)\ny=train_2.Cover_Type\nprint(X.columns)\ny[:5]\n\n# Split X and y into Train and Validation sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X,y,test_size = 0.2, stratify = y, random_state = 99)\nprint(X_train.shape)\nprint(y_train.shape)","38aa22b6":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\n\n# Function to execute random forest\ndef rf_grid(X_train,y_train, param_grid, cv=5):\n    rf = RandomForestClassifier(random_state=99)\n    rf_grid = GridSearchCV(rf,param_grid, cv=5)\n    rf_grid.fit(X_train,y_train)\n    y_pred = rf_grid.predict(X_val)\n    print(pd.DataFrame(rf_grid.cv_results_)[['params','mean_test_score']])\n    print('Random Forest Best Parameters: ',rf_grid.best_params_)\n    print('Random Forest Best Training Score: ',rf_grid.best_score_)\n    print('Random Forest Validation Accuracy is: ', accuracy_score(y_val,y_pred))\n\nparam_grid_rf = {'n_estimators': [700,800,1000,1200]}\n\n# Execute Random Forest\nrf_grid(X_train,y_train,param_grid_rf)\n","34a9c77e":"from sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\n\n# Function to execute Extremely Randomized Trees\ndef extra_trees_grid(X_train,y_train, param_grid, cv=5):\n    extra_trees = ExtraTreesClassifier(random_state=99)\n    extra_trees_grid = GridSearchCV(extra_trees,param_grid, cv=5)\n    extra_trees_grid.fit(X_train,y_train)\n    y_pred = extra_trees_grid.predict(X_val)\n    print(pd.DataFrame(extra_trees_grid.cv_results_)[['params','mean_test_score']])\n    print('Extra Trees Best Parameters: ',extra_trees_grid.best_params_)\n    print('Extra Trees Best Training Score: ',extra_trees_grid.best_score_)\n    print('Extra Trees Validation Accuracy is: ', accuracy_score(y_val,y_pred))\n    \nparam_grid_extra = {'n_estimators': [700,1000,1400,1700,2000]}\n\n# Execute Extremely Randomized Trees\nextra_trees_grid(X_train,y_train,param_grid_extra)\n\n","ace8577d":"from lightgbm import LGBMClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\n\n# Function to execute lightGBM classifier\ndef lgbm_grid(X_train,y_train, param_grid, cv=5):\n    lgbm = LGBMClassifier(random_state=99)\n    lgbm_grid = GridSearchCV(lgbm,param_grid, cv=5)\n    lgbm_grid.fit(X_train,y_train)\n    y_pred = lgbm_grid.predict(X_val)\n    print(pd.DataFrame(lgbm_grid.cv_results_)[['params','mean_test_score']])\n    print('LightGBM Best Parameters: ',lgbm_grid.best_params_)\n    print('LightGBM Best Training Score: ',lgbm_grid.best_score_)\n    print('LightGBM Validation Accuracy is: ', accuracy_score(y_val,y_pred))\n\nparam_grid_lgbm = {'n_estimators': [1000,1200,1400,1600,1800]}\n\n# Execute LightGBM classifier\nlgbm_grid(X_train,y_train,param_grid_lgbm)","7060ad4b":"## Prepare data for ML Experiments","480a118a":"### Execute LightBGM Baseline with GridSearch - Tune only number of trees","a4bb8cf1":"### Execute Random Forest Baseline with GridSearch - Tune only number of trees","1920ac15":"### Execute Extremely Randomized Trees Baseline with GridSearch - Tune only number of trees"}}