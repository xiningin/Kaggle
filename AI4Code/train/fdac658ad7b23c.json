{"cell_type":{"ca3c3b81":"code","6b33f98f":"code","6e7a5b3e":"code","a8a72fe3":"code","758f0482":"code","e1de2b7c":"code","0ac3096a":"code","a760dcb1":"code","11cc35b8":"code","75b72014":"code","774e5c18":"code","312a57dd":"code","92992ab8":"code","839feac9":"code","261a793a":"code","b34ed496":"code","bf2341dc":"code","f8f0472d":"code","47681326":"code","19858c6b":"code","434dc438":"code","42666917":"code","582d6433":"code","94dc0408":"code","f38f8bdb":"code","8a6fbfee":"code","78e8ca79":"code","fea10fbd":"code","80c71a7d":"code","a38eadd4":"code","1b5032d3":"code","ea9a2588":"code","7c7c60e4":"code","e8801375":"code","55294a67":"code","885f2aab":"code","8941b1e6":"code","1baffb95":"code","35976dfc":"code","8a5380ca":"code","f33af9db":"code","ba668c56":"code","c034172b":"code","0430ea92":"code","75dad0b9":"code","f5a521ee":"code","4299cab9":"code","87d5c322":"code","e7cba068":"code","2624842e":"code","ec8df2c2":"code","7f5c1597":"code","7af33c92":"code","9959aedc":"code","24741ddf":"code","9d6cb398":"code","236dc38b":"markdown","53fa933f":"markdown","a32a5ce7":"markdown","b4923cae":"markdown","eccc2c4d":"markdown","d2d1a6d7":"markdown","99125c76":"markdown"},"source":{"ca3c3b81":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6b33f98f":"os.chdir(\"..\/input\")\nos.listdir()","6e7a5b3e":"import pandas as pd\nimport numpy as np\n\ndf=pd.read_csv(\"..\/input\/laptop-price\/laptop_price.csv\",encoding='latin-1')","a8a72fe3":"df.info()","758f0482":"df.isnull().sum()","e1de2b7c":"df.head(10)","0ac3096a":"df[\"Ram\"] = df[\"Ram\"].str.replace('GB', '') ## remove 'GB'","a760dcb1":"df[\"Weight\"] = df[\"Weight\"].str.replace('kg', '') ## remove 'kg'","11cc35b8":"df['Memory'] = df['Memory'].astype(str).replace('\\.0', '', regex=True) ## '.0' part remove ex; '1.0'---> '1' ","75b72014":"df[\"Memory\"] = df[\"Memory\"].str.replace('GB', '') ## remove 'GB'","774e5c18":"df[\"Memory\"] = df[\"Memory\"].str.replace('TB', '000') # convert to TB to GB values ex; 1TB=1000GB","312a57dd":"new2 = df[\"Memory\"].str.split(\"+\", n = 1, expand = True) # seperate according to '+'","92992ab8":"# making separate first name column from new data frame \ndf[\"first\"]= new2[0]\ndf[\"first\"]=df[\"first\"].str.strip() # First part of Memory","839feac9":"# making separate last name column from new data frame \ndf[\"second\"]= new2[1] # Second part of Memory","261a793a":"### Categorization of first part and second part of Memory\n# Categorization of first part of Memory\n\ndf[\"Layer1HDD\"] = df[\"first\"].apply(lambda x: 1 if \"HDD\" in x else 0)\ndf[\"Layer1SSD\"] = df[\"first\"].apply(lambda x: 1 if \"SSD\" in x else 0)\ndf[\"Layer1Hybrid\"] = df[\"first\"].apply(lambda x: 1 if \"Hybrid\" in x else 0)\ndf[\"Layer1Flash_Storage\"] = df[\"first\"].apply(lambda x: 1 if \"Flash Storage\" in x else 0)","b34ed496":"# Data Cleaning for first part unwanted charecters \ndf['first'] = df['first'].str.replace(r'\\D', '')","bf2341dc":"# For Consisting of one part Memory fill the Na values with 0\ndf[\"second\"].fillna(\"0\", inplace = True)","f8f0472d":"# Categorization of second part of Memory\ndf[\"Layer2HDD\"] = df[\"second\"].apply(lambda x: 1 if \"HDD\" in x else 0)\ndf[\"Layer2SSD\"] = df[\"second\"].apply(lambda x: 1 if \"SSD\" in x else 0)\ndf[\"Layer2Hybrid\"] = df[\"second\"].apply(lambda x: 1 if \"Hybrid\" in x else 0)\ndf[\"Layer2Flash_Storage\"] = df[\"second\"].apply(lambda x: 1 if \"Flash Storage\" in x else 0)","47681326":"## Data Cleaning for second part unwanted charecters \ndf['second'] = df['second'].str.replace(r'\\D', '')","19858c6b":"df.info()","434dc438":"# Convert to integer first and second parts \ndf[\"first\"] = df[\"first\"].astype(int)\ndf[\"second\"] = df[\"second\"].astype(int)","42666917":"df.info()","582d6433":"# Calculation of Total Memory\ndf[\"Total_Memory\"]=(df[\"first\"]*(df[\"Layer1HDD\"]+df[\"Layer1SSD\"]+df[\"Layer1Hybrid\"]+df[\"Layer1Flash_Storage\"])+df[\"second\"]*(df[\"Layer2HDD\"]+df[\"Layer2SSD\"]+df[\"Layer2Hybrid\"]+df[\"Layer2Flash_Storage\"]))\ndf[\"Memory\"]=df[\"Total_Memory\"]","94dc0408":"# Calculation of Category HDD,SSD,Hybrid,Flash Storage\ndf[\"HDD\"]=(df[\"first\"]*df[\"Layer1HDD\"]+df[\"second\"]*df[\"Layer2HDD\"])\ndf[\"SSD\"]=(df[\"first\"]*df[\"Layer1SSD\"]+df[\"second\"]*df[\"Layer2SSD\"])\ndf[\"Hybrid\"]=(df[\"first\"]*df[\"Layer1Hybrid\"]+df[\"second\"]*df[\"Layer2Hybrid\"])\ndf[\"Flash_Storage\"]=(df[\"first\"]*df[\"Layer1Flash_Storage\"]+df[\"second\"]*df[\"Layer2Flash_Storage\"])","f38f8bdb":"# Seperate Screen Resolution Part according to 'x' character\n# new data frame with split value columns \nnew = df[\"ScreenResolution\"].str.split(\"x\", n = 1, expand = True) ","8a6fbfee":"# X resolution \n# making separate first name column from new data frame \ndf[\"X_res\"]= new[0] ","78e8ca79":"# Y resolution \n# making separate last name column from new data frame \ndf[\"Y_res\"]= new[1] ","fea10fbd":"df[\"Y_res\"]=pd.to_numeric(df[\"Y_res\"])","80c71a7d":"df[\"Y_res\"] = df[\"Y_res\"].astype(float)","a38eadd4":"# Data Cleaning for X_res part unwanted charecters \ndf[\"X_res\"]=(df['X_res'].str.replace(',','').str.findall(r'(\\d+\\.?\\d+)').apply(lambda x: pd.Series(x).astype(int)).mean(1))\ndf[\"X_res\"]=pd.to_numeric(df[\"X_res\"])","1b5032d3":"df.info()","ea9a2588":"# Calculation of PPI from X_res,Y_res,Inches\ndf[\"PPI\"]=(((df[\"X_res\"]**2+df[\"Y_res\"]**2)**(1\/2))\/df[\"Inches\"]).astype(float)","7c7c60e4":"# Update the ScreenResolution now this coloumn is numeric value\ndf[\"ScreenResolution\"]=(df[\"X_res\"]*df[\"Y_res\"]).astype(float)","e8801375":"# Object value convert to numeric values\ndf[\"Ram\"] = df[\"Ram\"].astype(int)\ndf[\"Weight\"] = df[\"Weight\"].astype(float)","55294a67":"# Drop unused columns from the Dataframe \ndf=df.drop(['laptop_ID','first','second','Layer1HDD','Layer1SSD','Layer1Hybrid','Layer1Flash_Storage','Layer2HDD','Layer2SSD','Layer2Hybrid','Layer2Flash_Storage','Total_Memory'],axis=1)\n","885f2aab":"df.info()","8941b1e6":"df.head(10)","1baffb95":"X=df.drop(['Price_euros'],axis=1)","35976dfc":"# Log transform of y values\ny=np.log(df['Price_euros'].values)","8a5380ca":"X=pd.concat([X,pd.get_dummies(X)],axis=1)\nprint(X.info())","f33af9db":"X_=X.select_dtypes(exclude=['object'])","ba668c56":"# Cleaning duplicate columns ..\nX_ = X_.loc[:,~X_.columns.duplicated()]","c034172b":"# Normalization of Features\nX=(X_-np.min(X_))\/(np.max(X_)-np.min(X_))","0430ea92":"print(X.info())","75dad0b9":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n","f5a521ee":"from sklearn.metrics import mean_squared_error\n# Let's see what is the prediction error of our model.\n\n\ny_pred_lr = lin_reg.predict(X)\nlin_mse = mean_squared_error(y, y_pred_lr)\nlin_rmse = np.sqrt(lin_mse)\nprint(\"Linear Regression MSE: \",lin_mse)\nprint(\"Linear Regression RMSE: \",lin_rmse)\n","4299cab9":"# Let's see how accurate is our model.\nfrom sklearn import metrics\naccuracy_lin = metrics.r2_score(y, y_pred_lr)\nprint(\"Linear Regression r2: \",accuracy_lin)\n","87d5c322":"from sklearn.metrics import mean_absolute_error\n\nlin_mae = mean_absolute_error(y, y_pred_lr)\nprint(\"Linear Regression MAE: \",lin_mae)","e7cba068":"from sklearn.tree import DecisionTreeRegressor\n\ntree_reg=DecisionTreeRegressor()\ntree_reg.fit(X,y)\n","2624842e":"# Let's see what is the prediction error of our model.\n\ny_pred_dt=tree_reg.predict(X)\n\ndt_mse = mean_squared_error(y, y_pred_dt)\ndt_rmse = np.sqrt(dt_mse)\nprint(\"Decision Tree Regression MSE: \",dt_mse)\nprint(\"Decision Tree Regression RMSE: \",dt_rmse)\n\n","ec8df2c2":"# Let's see how accurate is our model.\n\naccuracy_dt = metrics.r2_score(y, y_pred_dt)\nprint(\"Decision Tree Regression r2: \",accuracy_dt)","7f5c1597":"dt_mae = mean_absolute_error(y, y_pred_dt)\nprint(\"Decision Tree Regression MAE: \",dt_mae)","7af33c92":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\n\nx_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.4,random_state=42)\n\nrf=RandomForestRegressor(n_estimators=100,random_state=42)\n\nrf.fit(x_train,y_train)","9959aedc":"# Let's see what is the prediction error of our model.\n\ny_pred_rf=rf.predict(x_test)\n\nrf_mse = mean_squared_error(y_test, y_pred_rf)\nrf_rmse = np.sqrt(rf_mse)\n\nprint(\"Random Forest Regression MSE: \",rf_mse)\nprint(\"Random Forest Regression RMSE: \",rf_rmse)","24741ddf":"# Let's see how accurate is our model.\n\naccuracy_rf=metrics.r2_score(y_test,y_pred_rf)\n\nprint(\"Random Forest Regression r2: \",accuracy_rf)","9d6cb398":"rf_mae = mean_absolute_error(y_test, y_pred_rf)\nprint(\"Random Forest Regression  MAE: \",rf_mae)","236dc38b":"## LINEAR REGRESSION","53fa933f":"# Preparation of Model Data and Scaling of Data","a32a5ce7":"## DECISION TREE","b4923cae":"## **Data Read**","eccc2c4d":"# Modelling","d2d1a6d7":"## **DATA CLEANING AND PREPERAT\u0130ON**","99125c76":"## RANDOM FOREST REGRESSION"}}