{"cell_type":{"97e06d86":"code","605eac40":"code","8ac01ace":"code","cdddecab":"code","e21bef2c":"code","465d039e":"code","313a447f":"code","915497b1":"code","286ffbfa":"code","f0743ee0":"code","08c17f86":"code","42fda6ff":"code","254028d2":"code","634c9164":"code","60b4aae9":"code","4d338b23":"markdown","c7de30cf":"markdown","428cff5f":"markdown","9df1e348":"markdown","ee42146c":"markdown","0ad15ccc":"markdown","a3457bde":"markdown","4cc12930":"markdown","33f769df":"markdown","ab82db5d":"markdown","82ead5a4":"markdown","92694db3":"markdown","48944d58":"markdown","8442a623":"markdown","12e3c20a":"markdown"},"source":{"97e06d86":"import nltk.classify.util\nfrom nltk.classify import NaiveBayesClassifier\nfrom nltk.corpus import names\n \ndef gender_features(word): \n    return {'last_letter': word[-1]} \n \n# Load data and training \nnames = ([(name, 'male') for name in names.words('male.txt')] + \n\t [(name, 'female') for name in names.words('female.txt')])\n \nfeaturesets = [(gender_features(n), g) for (n,g) in names] \ntrain_set = featuresets\nclassifier = nltk.NaiveBayesClassifier.train(train_set) \n \n# Predict\nprint(classifier.classify(gender_features('Alexa')))\n\n# If you want to give the name during runtime, uncomment and comment above line\n# Predict\n# name = input(\"Name: \")\n# print(classifier.classify(gender_features(name)))","605eac40":"import numpy as np\nfeatures = np.load('..\/input\/temps-cleaned.csv.npy')\nlabels = np.load('..\/input\/temps-labels.csv.npy')\nfeature_list = ['year', 'month', 'day', 'temp_2', 'temp_1', 'average', 'friend', 'week_Fri', 'week_Mon', 'week_Sat', 'week_Sun', 'week_Thurs', 'week_Tues', 'week_Wed']\nprint(features.shape)\nprint(labels.shape)","8ac01ace":"# Using Skicit-learn to split data into training and testing sets\nfrom sklearn.model_selection import train_test_split\n\n# Split the data into training and testing sets\ntrain_features, test_features, train_labels, test_labels = train_test_split(features,\n                                                                            labels, \n                                                                            test_size = 0.25, \n                                                                            random_state = 42)\nprint('Training Features Shape:', train_features.shape)\nprint('Training Labels Shape:', train_labels.shape)\nprint('Testing Features Shape:', test_features.shape)\nprint('Testing Labels Shape:', test_labels.shape)","cdddecab":"# The baseline predictions are the historical averages\nbaseline_preds = test_features[:, feature_list.index('average')]\n\n# Baseline errors, and display average baseline error\nbaseline_errors = abs(baseline_preds - test_labels)\n\nprint('Average baseline error: ', round(np.mean(baseline_errors), 2))","e21bef2c":"# Import the model we are using\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Instantiate model with 1000 decision trees\nrf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n\n# Train the model on training data\nrf.fit(train_features, train_labels)","465d039e":"# Use the forest's predict method on the test data\npredictions = rf.predict(test_features)\n\n# Calculate the absolute errors\nerrors = abs(predictions - test_labels)\n\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')","313a447f":"# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors \/ test_labels)\n\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","915497b1":"from __future__ import absolute_import, division, print_function\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport numpy as np\n\nprint(tf.__version__)","286ffbfa":"boston_housing = keras.datasets.boston_housing\n\n(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()\n\n# Shuffle the training set\norder = np.argsort(np.random.random(train_labels.shape))\ntrain_data = train_data[order]\ntrain_labels = train_labels[order]\n\nprint(\"Training set: {}\".format(train_data.shape))  # 404 examples, 13 features\nprint(\"Testing set:  {}\".format(test_data.shape))   # 102 examples, 13 features\n","f0743ee0":"import pandas as pd\n\ncolumn_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n                'TAX', 'PTRATIO', 'B', 'LSTAT']\n\ndf = pd.DataFrame(train_data, columns=column_names)\ndf.head()\n","08c17f86":"# Test data is *not* used when calculating the mean and std\n\nmean = train_data.mean(axis=0)\nstd = train_data.std(axis=0)\ntrain_data = (train_data - mean) \/ std\ntest_data = (test_data - mean) \/ std\n\nprint(train_data[0])  # First training sample, normalized\n","42fda6ff":"def build_model():\n  model = keras.Sequential([\n    keras.layers.Dense(64, activation=tf.nn.relu,\n                       input_shape=(train_data.shape[1],)),\n    keras.layers.Dense(64, activation=tf.nn.relu),\n    keras.layers.Dense(1)\n  ])\n\n  optimizer = tf.train.RMSPropOptimizer(0.001)\n\n  model.compile(loss='mse',\n                optimizer=optimizer,\n                metrics=['mae'])\n  return model\n\nmodel = build_model()\nmodel.summary()\n","254028d2":"# Display training progress by printing a single dot for each completed epoch\nclass PrintDot(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs):\n    if epoch % 100 == 0: print('')\n    print('.', end='')\n\nEPOCHS = 500\n\n# Store training stats\nhistory = model.fit(train_data, train_labels, epochs=EPOCHS,\n                    validation_split=0.2, verbose=0,\n                    callbacks=[PrintDot()])\n","634c9164":"import matplotlib.pyplot as plt\n\n\ndef plot_history(history):\n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Abs Error [ INR 72,499.35 ]')\n  plt.plot(history.epoch, np.array(history.history['mean_absolute_error']),\n           label='Train Loss')\n  plt.plot(history.epoch, np.array(history.history['val_mean_absolute_error']),\n           label = 'Val loss')\n  plt.legend()\n  plt.ylim([0, 5])\n\nplot_history(history)\n","60b4aae9":"[loss, mae] = model.evaluate(test_data, test_labels, verbose=0)\n\nprint(\"Testing set Mean Abs Error: ${:7.2f}\".format(mae * 1000))\n","4d338b23":"The problem we will tackle is predicting the max temperature for tomorrow Seatle using one year of past weather data.\n\nWhat we do have access to is one year of historical max temperatures, the temperatures for the previous two days, and an estimate from a friend who is always claiming to know everything about the weather. \n\nThis is a supervised, regression machine learning problem. It\u2019s supervised because we have both the features (data for the city) and the targets (temperature) that we want to predict. \n\nDuring training, we give the random forest both the features and targets and it must learn how to map the data to a prediction. \n\nMoreover, this is a regression task because the target value is continuous (as opposed to discrete classes in classification).\n\n[source](https:\/\/towardsdatascience.com\/random-forest-in-python-24d0893d51c0)","c7de30cf":"### Exercise 2: Predicting weather","428cff5f":"Normalization of dataset","9df1e348":"Train the model","ee42146c":"## Practical\n### Exercise 1: Predict gender","0ad15ccc":"## References\n### Theory\nhttps:\/\/medium.com\/deep-math-machine-learning-ai\/different-types-of-machine-learning-and-their-types-34760b9128a2\n\nhttps:\/\/towardsdatascience.com\/types-of-machine-learning-algorithms-you-should-know-953a08248861\n\nhttps:\/\/www.analyticsvidhya.com\/blog\/2017\/09\/common-machine-learning-algorithms\/\n\n### Libraries\n[scikit-learn](https:\/\/scikit-learn.org\/stable\/)\n\n[NLTK](https:\/\/pythonspot.com\/en\/category\/nltk\/)\n\n[openCV](https:\/\/opencv.org\/)\n\n[tensorflow](https:\/\/www.tensorflow.org\/)\n\n[keras](https:\/\/keras.io\/)","a3457bde":"# ML102","4cc12930":"Testing","33f769df":"Create the model.","ab82db5d":"## Theory\nLabeled data: Data consisting of a set of training examples, where each example is a pair consisting of an input and a desired output value\n\n![types](https:\/\/cdn-images-1.medium.com\/max\/1600\/1*ZCeOEBhvEVLmwCh7vr2RVA.png)\n\n### Supervised learning\nWhere there is a traning and testing data \n#### Regression\nThis is a type of problem where we need to predict the continuous-response value (ex : above we predict number which can vary from -infinity to +infinity)\n\nSome examples are\n* what is the price of house in a specific city?\n* what is the value of the stock?\n* how many total runs can be on board in a cricket game?\n#### Classification\nThis is a type of problem where we predict the categorical response value where the data can be separated into specific \u201cclasses\u201d (ex: we predict one of the values in a set of values).\n\nSome examples are :\n\n* this mail is spam or not?\n* will it rain today or not?\n* is this picture a cat or not?\n\nBasically \u2018Yes\/No\u2019 type questions called binary classification.\n\nOther examples are :\n\n* this mail is spam or important or promotion?\n* is this picture a cat or a dog or a tiger?\n\nThis type is called multi-class classification.\n\n#### List of Common Algorithms\n\n* Nearest Neighbor\n* Naive Bayes\n* Decision Trees\n* Linear Regression\n* Support Vector Machines (SVM)\n* Neural Networks\n\n### Unsupervised learning\nThe training data does not include Targets here so we don\u2019t tell the system where to go , the system has to understand itself from the data we give.\n#### Clustering\nThis is a type of problem where we group similar things together.\n\nBit similar to multi class classification but here we don\u2019t provide the labels, the system understands from data itself and cluster the data.\n\nSome examples are :\n\n* given news articles,cluster into different types of news\n* given a set of tweets ,cluster based on content of tweet\n* given a set of images, cluster them into different objects\n\n### List of Common Algorithms\n* k-means clustering\n* Association Rules\n\n### Reinforcement learning\naims at using observations gathered from the interaction with the environment to take actions that would maximize the reward or minimize the risk. Reinforcement learning algorithm (called the agent) _continuously learns from the environment in an iterative fashion._\n\n\n","82ead5a4":"Get Boston housing prices dataset","92694db3":"Visualize model's training progress","48944d58":"Each feature is represented in different scales.","8442a623":"### Exercise 3: Deep Learning","12e3c20a":"From [tensorflow](https:\/\/www.tensorflow.org\/tutorials\/keras\/basic_regression)\n\nUses tensorflow, keras and numpy"}}