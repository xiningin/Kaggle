{"cell_type":{"c6c7ec6b":"code","d1582f85":"code","7e49fa73":"code","eec472df":"code","2d07aba2":"code","b9f28aa0":"code","84ca5e82":"code","e3df6b96":"code","470e242a":"code","e33afcc2":"code","0b57b393":"code","4dcae42c":"code","3b26ee51":"code","ab03aae4":"code","8362bd5f":"code","be5349b3":"code","40117e4d":"code","b826aadf":"code","f7a33f6f":"code","ea03bd4b":"code","771bed42":"code","b1bd6022":"code","608ab414":"code","86c9cc45":"code","bfb98421":"code","1b3c408b":"code","23472233":"code","3e32cfca":"code","b4a187f9":"code","71a1efc7":"code","f933147f":"code","2d4fcb68":"markdown","2c4c3a88":"markdown","f5d389a6":"markdown","ab7a95cb":"markdown","d7475102":"markdown"},"source":{"c6c7ec6b":"import keras\nfrom keras.models import Sequential\nfrom keras.regularizers import l2, l1\nfrom keras.layers import Dense, Dropout\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nimport numpy\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\n%matplotlib inline\nimport seaborn as sn","d1582f85":"!pwd","7e49fa73":"df = pd.read_csv('..\/input\/dataset.csv', encoding='latin-1')\npd.options.display.max_columns=None\ndf.head(2)","eec472df":"X = df['label'].value_counts()\n\nclasses = X.keys()\n\nlabel = {}\n\nfor c in classes:\n    label[c] = X[c]\n\nplt.bar(label.keys(), label.values())\nplt.xlabel('Class Name')\nplt.ylabel('Number of Instances')\n\nprint(X)","2d07aba2":"import numpy as np","b9f28aa0":"data_adhunik = df[df['label'] == 'adhunik']\ndata_band = df[df['label'] == 'band']\ndata_hiphop = df[df['label'] == 'hiphop']\ndata_nazrul = df[df['label'] == 'nazrul']\ndata_palligeeti = df[df['label'] == 'palligeeti']\ndata_rabindra = df[df['label'] == 'rabindra']","84ca5e82":"data_list = [data_adhunik, data_band, data_hiphop, data_nazrul, data_palligeeti, data_rabindra]\nclasses = np.array(['adhunik', 'band', 'hiphop', 'nazrul', 'palligeeti', 'rabindra'])","e3df6b96":"# Zero Crossings Visualization\ncol_name = 'zero_crossing'\nprint(col_name)\ny = []\nfor data in data_list:\n    print(data[col_name].mean())\n    y.append(data[col_name].mean())\ny = np.array(y)\ncolors = cm.hsv(y \/ float(max(y)))\nplot = plt.scatter(y, y, c = y, cmap = 'hsv')\nplt.clf()\nplt.colorbar(plot)\nplt.bar(classes, y, color = colors, width=0.6)\nplt.show()","470e242a":"# Zero Crossings Visualization\ncol_name = 'spectral_centroid'\nprint(col_name)\ny = []\nfor data in data_list:\n    print(data[col_name].mean())\n    y.append(data[col_name].mean())\ny = np.array(y)\ncolors = cm.hsv(y \/ float(max(y)))\nplot = plt.scatter(y, y, c = y, cmap = 'hsv')\nplt.clf()\nplt.colorbar(plot)\nplt.bar(classes, y, color = colors, width=0.6)\nplt.show()","e33afcc2":"# Zero Crossings Visualization\ncol_name = 'spectral_rolloff'\nprint(col_name)\ny = []\nfor data in data_list:\n    print(data[col_name].mean())\n    y.append(data[col_name].mean())\ny = np.array(y)\ncolors = cm.hsv(y \/ float(max(y)))\nplot = plt.scatter(y, y, c = y, cmap = 'hsv')\nplt.clf()\nplt.colorbar(plot)\nplt.bar(classes, y, color = colors, width=0.6)\nplt.show()","0b57b393":"# Zero Crossings Visualization\ncol_name = 'spectral_bandwidth'\nprint(col_name)\ny = []\nfor data in data_list:\n    print(data[col_name].mean())\n    y.append(data[col_name].mean())\ny = np.array(y)\ncolors = cm.hsv(y \/ float(max(y)))\nplot = plt.scatter(y, y, c = y, cmap = 'hsv')\nplt.clf()\nplt.colorbar(plot)\nplt.bar(classes, y, color = colors, width=0.6)\nplt.show()","4dcae42c":"# Zero Crossings Visualization\ncol_name = 'chroma_frequency'\nprint(col_name)\ny = []\nfor data in data_list:\n    print(data[col_name].mean())\n    y.append(data[col_name].mean())\ny = np.array(y)\ncolors = cm.hsv(y \/ float(max(y)))\nplot = plt.scatter(y, y, c = y, cmap = 'hsv')\nplt.clf()\nplt.colorbar(plot)\nplt.bar(classes, y, color = colors, width=0.6)\nplt.show()","3b26ee51":"# Zero Crossings Visualization\ncol_name = 'tempo'\nprint(col_name)\ny = []\nfor data in data_list:\n    print(data[col_name].mean())\n    y.append(data[col_name].mean())\ny = np.array(y)\ncolors = cm.hsv(y \/ float(max(y)))\nplot = plt.scatter(y, y, c = y, cmap = 'hsv')\nplt.clf()\nplt.colorbar(plot)\nplt.bar(classes, y, color = colors, width=0.6)\nplt.show()","ab03aae4":"# Zero Crossings Visualization\ncol_name = 'zero_crossing'\nprint(col_name)\ny = []\nfor data in data_list:\n    print(data[col_name].mean())\n    y.append(data[col_name].mean())\ny = np.array(y)\ncolors = cm.hsv(y \/ float(max(y)))\nplot = plt.scatter(y, y, c = y, cmap = 'hsv')\nplt.clf()\nplt.colorbar(plot)\nplt.bar(classes, y, color = colors, width=0.6)\nplt.show()","8362bd5f":"# Zero Crossings Visualization\ncol_name = 'rmse'\nprint(col_name)\ny = []\nfor data in data_list:\n    print(data[col_name].mean())\n    y.append(data[col_name].mean())\ny = np.array(y)\ncolors = cm.hsv(y \/ float(max(y)))\nplot = plt.scatter(y, y, c = y, cmap = 'hsv')\nplt.clf()\nplt.colorbar(plot)\nplt.bar(classes, y, color = colors, width=0.6)\nplt.show()","be5349b3":"# Splitting data\ny = df['label']\nX = df.drop(['file_name', 'label'], axis=1)\n\n# Scaling values by normal distribution\nsc = StandardScaler()\nX = sc.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8) #4\n\nencoder = LabelEncoder()\ny_train = encoder.fit_transform(y_train)\ny_test = encoder.fit_transform(y_test)","40117e4d":"encoder.classes_","b826aadf":"encoder.inverse_transform([0, 1, 2, 3, 4, 5])","f7a33f6f":"print(X_train.shape, X_test.shape)","ea03bd4b":"# Creating model\nmodel = Sequential()\nmodel.name=\"Bangla Music Genre Classifier\"\nmodel.add(Dense(256, activation='relu', input_dim=29, name=\"First_Layer\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.002)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128, activation='relu', name=\"Second_Layer\", kernel_regularizer=l2(0.002), bias_regularizer=l2(0.0001)))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(64, activation='relu', name=\"Third_Layer\", kernel_regularizer=l1(0.002), bias_regularizer=l2(0.001)))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(64, activation='relu', name=\"Fourth_Layer\", kernel_regularizer=l2(0.001), bias_regularizer=l2(0.0001)))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(6, activation='softmax', name=\"Output_Layer\", kernel_regularizer=l2(0.001), bias_regularizer=l2(0.002)))\nmodel.summary()","771bed42":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(X_train, y_train, batch_size=200, validation_data=(X_test, y_test), validation_split=0.2, epochs=100)","b1bd6022":"y_predict = model.predict_classes(X_test)\ny_predict","608ab414":"history.history.keys()","86c9cc45":"score, acc = model.evaluate(X_test, y_test)\nprint(score, acc)","bfb98421":"# model.save('model.h5')","1b3c408b":"# Summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Train vs Validation Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['training accuracy', 'validation accuracy'], loc='lower right')\nplt.show()\n\n# Summarize history for loss\n# plt.plot(history.history['loss'])\n# plt.title('model loss')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['train', 'test'], loc='upper left')\n# plt.show()","23472233":"# Summarize history for accuracy\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Train Loss vs Validation Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['training loss', 'vaidation loss'], loc='upper right')\nplt.show()","3e32cfca":"history.history.keys()","b4a187f9":"# Confusion Matrix\ncon_mat = confusion_matrix(y_test, y_predict)\ndf_cm = pd.DataFrame(con_mat, columns=encoder.classes_, index=encoder.classes_)\nsn.heatmap(df_cm, annot=True)","71a1efc7":"print(classification_report(y_test, y_predict, target_names=encoder.classes_))","f933147f":"false = 0\ntrue = 0\nfor i in range(len(y_predict)):\n    if y_predict[i] == y_test[i]:\n        true += 1\n    else:\n        false += 1\nprint('Total: ', false + true, 'True: ', true, 'False: ', false)","2d4fcb68":"# Model Training","2c4c3a88":"# Data Visualization","f5d389a6":"<h2 style=\"color: green\">Testing Extracted Features w\/ Keras<\/h2>\nAuthor: [Afif Al Mamun](https:\/\/afifaniks.me)<br>\nDate: August 23, 2019","ab7a95cb":"# Visualization","d7475102":"# Preparing Data"}}