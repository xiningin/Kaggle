{"cell_type":{"4e7e19bd":"code","127f6a23":"code","97e5539c":"code","77ce889e":"code","c579c77f":"code","3e42406b":"code","1e5165cc":"code","cae78b56":"code","a17f6ba5":"code","c9890790":"code","f9bf84f3":"code","2b6eb83d":"code","0c72d4bd":"code","4043b94b":"code","aef57b5a":"code","28425907":"code","86d3a399":"code","0c7d9441":"code","b50618b7":"code","0caa2a5f":"code","1dd47e74":"code","7fe3c134":"code","acae85d6":"code","0471e346":"code","2b949109":"code","b488f0b3":"code","4555bc5a":"code","3e732c3d":"code","4d4f08a4":"code","937a60fd":"markdown","48eb698e":"markdown","27144fd9":"markdown","c51fbd9f":"markdown","57137a64":"markdown","e95c8a57":"markdown","5dc7bdbc":"markdown"},"source":{"4e7e19bd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","127f6a23":"# Installation for auto-sklearn\n# !apt-get remove swig\n# !apt-get install swig3.0 build-essential -y\n# !ln -s \/usr\/bin\/swig3.0 \/usr\/bin\/swig\n# !apt-get install build-essential\n# !pip install --upgrade setuptools\n# !pip install auto-sklearn\n# !pip install -U scikit-learn\n# !pip freeze | grep scikit-learn","97e5539c":"pd.set_option('colwidth', None)\npd.set_option('display.max_columns', None)\npd.options.display.float_format = '{:.2f}'.format","77ce889e":"# import data\ndf = pd.read_csv('\/kaggle\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf.head()","c579c77f":"# Inital EDA\nprint(df.shape)\nprint('\\n')\nprint(df.describe())\nprint('\\n')\nprint(df.info())\nprint('\\n')\nprint(df.isnull().sum())\nprint('\\n')\nprint(df.nunique())","3e42406b":"# See what the unique values for columns with 4 or less unique values\nfor col in df.loc[:, df.nunique() <= 4].columns:\n    print(col)\n    print(df[col].unique())\n    print(df[col].value_counts())\n    print('\\n')","1e5165cc":"# Total charges should be float value\ndf['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce', downcast='float')","cae78b56":"# See what the null values are\nprint(df.TotalCharges.isna().sum())\nprint('\\n')\ndf.loc[df.TotalCharges.isna()]","a17f6ba5":"# Drop NAs\ndf.dropna(axis=0,\n          how='any',\n          subset=['TotalCharges'],\n          inplace=True)\n\nprint(df.isna().sum()) # should be 0","c9890790":"# Change datatype to match with MonthlyCharges\ndf['TotalCharges'] = df.TotalCharges.astype(float)\ndf.dtypes","f9bf84f3":"# Change values to Yes or No like the other columns\ndf['SeniorCitizen'] = np.select(condlist=[df.SeniorCitizen == 0, df.SeniorCitizen == 1], \n                                choicelist=['No', 'Yes'])\n\ndf['SeniorCitizen'].unique()","2b6eb83d":"import matplotlib.pyplot as plt\nimport seaborn as sns","0c72d4bd":"# See all features with 4 or less unique values and its relationship with customers churning\nfor i, col in enumerate(df.loc[:, df.nunique() <= 4].columns):\n    plt.figure(i)\n    sns.histplot(x=col, data=df, hue='Churn', multiple='stack').set_title(col+' & Churn')","4043b94b":"# Let's see how charges and tenure are affecting customer churn\nfor i, col in enumerate(df.select_dtypes(include=['int64','float64']).columns):\n    plt.figure(i)\n    sns.histplot(x=col, data=df, hue='Churn', multiple='stack').set_title(col+' & Churn')","aef57b5a":"# How much money has been made from customers churning vs not\ndf.groupby('Churn').agg({'TotalCharges':'sum', 'tenure':'mean', 'MonthlyCharges':'mean'})","28425907":"from sklearn.preprocessing import LabelEncoder","86d3a399":"# Encode categorical variables and change column type to category\nlb = LabelEncoder()\nfor col in df.loc[:, df.nunique() <= 4].columns:\n    df[col] = lb.fit_transform(df[col])\n    df[col] = df[col].astype('category')","0c7d9441":"from sklearn.preprocessing import MinMaxScaler","b50618b7":"# Normalize data\nscaler = MinMaxScaler()\ndf[df.select_dtypes(include=['int64','float64']).columns] = scaler.fit_transform(df.select_dtypes(include=['int64','float64']))","0caa2a5f":"from autosklearn.classification import AutoSklearnClassifier","1dd47e74":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","7fe3c134":"# Split data into X and y\nX = df.iloc[:, 1:-1] # The numeric and categorical features, excluding CustomerID and Churn\ny = df.iloc[:, -1] # Churn\n\n# Train test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)","acae85d6":"# define search\nautoml = AutoSklearnClassifier(time_left_for_this_task=2*60, per_run_time_limit=30, n_jobs=8)\nautoml.fit(X_train, y_train)\npreds = automl.predict(X_test)\n# Change to series and data type as category\ny_preds = pd.Series(data=preds, \n                    index=y_test.index,\n                    dtype='category',\n                    name='ChurnPreds')\n\n# performance\nautoml.performance_over_time_.plot(\n    x='Timestamp',\n    kind='line',\n    legend=True,\n    title='Auto-sklearn accuracy over time',\n    grid=True,\n)\nplt.show()\n\n# summarize\nprint(automl.sprint_statistics())\nprint(automl.show_models())\n\n# evaluate best model\nacc = accuracy_score(y_test, y_preds)\nprint(\"Accuracy: %.3f\" % acc)","0471e346":"automl.leaderboard()","2b949109":"# Evaluate model with dataset\ndf['ChurnPreds'] = y_preds\n\n# Create ConfusionMatrix\ndf['ConfusionMatrix'] = np.select(condlist=[(df.Churn == 1) & (df.ChurnPreds == 1), \n                                            (df.Churn == 1) & (df.ChurnPreds == 0), \n                                            (df.Churn == 0) & (df.ChurnPreds == 1), \n                                            (df.Churn == 0) & (df.ChurnPreds == 0)],\n                                  choicelist=['TP', 'FP', 'FN', 'TN'],\n                                  default=None)\n\n# Customers likely to churn\nprint(str(df.loc[df.ConfusionMatrix == 'FN'].shape[0]) + ' customers likely to churn')\ndf.loc[df.ConfusionMatrix == 'FN'].head()","b488f0b3":"# Get original dataset and bring in the ConfusionMatrix column to evaluate results\ndf_orig = pd.read_csv('\/kaggle\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf_orig['ConfusionMatrix'] = df.ConfusionMatrix","4555bc5a":"# See all features with 4 or less unique values and its relationship with Churning Predictions\nfor i, col in enumerate(df_orig.loc[:, df_orig.nunique() <= 4].columns):\n    plt.figure(i)\n    sns.histplot(x=col, \n                 data=df_orig, \n                 hue='ConfusionMatrix', \n                 multiple='stack',\n                 palette={'TP':'green', 'TN':'blue', 'FP':'red', 'FN':'orange'}).set_title(col+' & ConfusionMatrix')\n","3e732c3d":"# Let's see how charges and tenure evaluate with customer churn\nfor i, col in enumerate(df_orig.select_dtypes(include=['int64','float64']).columns):\n    plt.figure(i)\n    sns.histplot(x=col, \n                 data=df_orig, \n                 hue='ConfusionMatrix', \n                 multiple='stack',\n                 palette={'TP':'green', 'TN':'blue', 'FP':'red', 'FN':'orange'}).set_title(col+' & ConfusionMatrix')","4d4f08a4":"# Customers likely to churn\ndf_orig.loc[df_orig.ConfusionMatrix == 'FN']","937a60fd":"It seems customers that churn are getting charged more in total and monthly than charges of customers that do not churn","48eb698e":"autosklearn does a good job with predicting which customers will churn. Performance could be improved by bootstrapping the churns since the data is imbalanced with more No Churns than Churns.\n\nIt seems the business model already does a good job with addressing customers churning by increasing monthly rates and overall charges to those likely to churn.\n\nIn order to prevent future customers from churning, try reaching out to the current customers and set them up with a longer term contract and lowering their monthly rate. These two features have almost none or least likeliness for churn.","27144fd9":"Customers with added a particular set of services (Online Security, Online Backup, Tech Support, Device Protection) are **less likely to churn**\n\nCustomers with more flexibility (no partner, not dependent, month-to-month contract) are **more likely to churn**\n\nCustomers with streaming are **more likely to churn**. Most likely bc many streaming services do not have every movie or TV show packaged, so it makes customers more likely to hop around streaming services\n\nCustomers with Electronic Payments, Fiber Optic Internet, and Paperless Billing are **more likely to churn**","c51fbd9f":"**Goal**\n* See why customers are churning\n* How to stop customers from churning (retention)\n* Predict customers likely to churn\n\n**Useful insights**\n* Lost revenue due to customers churning\n* Revenue gained in x time from current customers not churning","57137a64":"No null values.. There are a few columns with less than 5 unique values. These can probably be used as features in the model. Let's see what the unique values are","e95c8a57":"Customers churn early, indicated by the high churn rate in Total Charges and Tenure in the lower tail of the distribution\n\nCustomers are likely to churn when their monthly rates are ~ $70 to 110","5dc7bdbc":"11 rows of NaN TotalCharges. These rows can be dropped so the dataset doesn't negatively affect the analysis. This drop affects less than 1% of the dataset"}}