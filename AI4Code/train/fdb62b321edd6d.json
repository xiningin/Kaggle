{"cell_type":{"bdc674ff":"code","3535576b":"code","495cd4cf":"code","19c09bbc":"code","8e8c476f":"code","536ca281":"code","4f54e3fc":"code","5f1d4245":"code","f892ee28":"code","025bd3d7":"code","fa4e273a":"code","daf59cfc":"code","09ab41b2":"code","0d680f93":"code","6e6b3e52":"code","13698baf":"code","b8217a19":"code","311068e6":"code","cdd79609":"code","0cce5b22":"code","791da68f":"code","7fd67ad7":"code","2cac1b75":"code","1e2b1ad4":"code","38e1c733":"code","9057367f":"code","0883a54d":"markdown","fa210ddb":"markdown","74fbd940":"markdown","6366ca72":"markdown","865cc5f4":"markdown","35143b36":"markdown","0ac9e170":"markdown","8326cff6":"markdown","22be1910":"markdown"},"source":{"bdc674ff":"import pandas as pd\nimport numpy as np\nimport cv2\nimport tensorflow as tf\nimport seaborn as sns\nfrom tensorflow.keras.utils import Sequence, to_categorical\nfrom tensorflow.keras import backend as K\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import *\nimport matplotlib.pyplot as plt\nimport os\nfrom tensorflow.keras.metrics import Precision, Recall, MeanIoU\nfrom tensorflow.keras.optimizers import Adam, Nadam, SGD\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\nfrom tensorflow.keras.models import load_model, Model\nfrom tensorflow.keras.applications import *\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\nprint(\"libraries are imported\")","3535576b":"df_train = pd.read_csv(\"..\/input\/trains\/df_train\").drop([\"Unnamed: 0\"],axis=1)\ndf_valid = pd.read_csv(\"..\/input\/trains\/df_test\").drop([\"Unnamed: 0\"],axis=1)","495cd4cf":"df_train[\"mask_type\"] = df_train[\"mask_type\"].replace(\"kanama\",\"hemorrhage\")\ndf_train[\"mask_type\"] = df_train[\"mask_type\"].replace(\"iskemi\",\"ischemic\")\n\ndf_valid[\"mask_type\"] = df_valid[\"mask_type\"].replace(\"kanama\",\"hemorrhage\")\ndf_valid[\"mask_type\"] = df_valid[\"mask_type\"].replace(\"iskemi\",\"ischemic\")","19c09bbc":"df_train = df_train[(df_train[\"mask_type\"]!=\"ischemic\") & (df_train[\"mask_type\"]!=\"normal\")].reset_index(drop = True)\ndf_valid = df_valid[(df_valid[\"mask_type\"] != \"ischemic\") & (df_valid[\"mask_type\"]!=\"normal\")].reset_index(drop = True)","8e8c476f":"df_train.head()","536ca281":"df_valid.head()","4f54e3fc":"df = pd.concat([df_valid,df_train],axis=0).sample(frac=1).reset_index(drop = True)\ndf.head()","5f1d4245":"count = 0\nfig, axs = plt.subplots(3,3, figsize=(8,8))\n\nfor i in range(len(df)):\n    if  count<3:\n    \n        #read  images\n        rnd = np.random.randint(0,len(df))\n        img = cv2.imread(df.loc[rnd,\"image_path\"],1)\n        img = cv2.resize(img,(512,512))\n        axs[count][0].imshow(img)\n        print(rnd)\n        axs[count][0].title.set_text('image')\n        \n        #read  mask\n        mask = cv2.imread(df.loc[rnd,\"mask_path\"],0)\n        axs[count][1].imshow(mask)\n        label = df.loc[rnd,\"mask_type\"]\n\n        axs[count][1].title.set_text('Mask '+label)\n\n        mask = cv2.resize(mask,(512,512))\n        s = np.where((mask.reshape(512,512,1) == np.max(mask)).any(axis=2))\n        color = (0,0,255)\n        img[s] = color\n        axs[count][2].imshow(img)\n        axs[count][2].title.set_text('Overlay')\n\n        count +=1\n    if (count==3):\n        break\n\nfig.tight_layout() ","f892ee28":"count = 0\nfig, axs = plt.subplots(3,3, figsize=(8,8))\n\nfor i in range(len(df)):\n    if  count<3:\n        #read  images\n        rnd = np.random.randint(0,len(df))\n        img = cv2.imread(df.loc[rnd,\"image_path\"],1)\n        img = cv2.resize(img,(512,512))\n        img[np.where((img == (255,255,255)).all(axis=2))] = (0,0,0)\n        axs[count][0].imshow(img)\n        print(rnd)\n        axs[count][0].title.set_text('image')\n        \n        #read original mask\n        mask = cv2.imread(df.loc[rnd,\"mask_path\"],0)\n        axs[count][1].imshow(mask)\n        label = df.loc[rnd,\"mask_type\"]\n\n        axs[count][1].title.set_text('Mask '+label)\n        mask = cv2.resize(mask,(512,512))\n        s = np.where((mask.reshape(512,512,1) == np.max(mask)).any(axis=2))\n       \n        color = (0,0,255)\n        img[s] = color\n        axs[count][2].imshow(img)\n        axs[count][2].title.set_text('Overlay')\n        \n        count +=1\n    if (count==3):\n        break\n\nfig.tight_layout() ","025bd3d7":"df_train, df_valid = train_test_split(df, test_size = 0.1, random_state = 1)","fa4e273a":"f\" size of train: {len(df_train)}, size of valid: {len(df_valid)}\"","daf59cfc":"df_train = df_train.reset_index(drop=True)\ndf_valid = df_valid.reset_index(drop=True)","09ab41b2":"df_train.head()","0d680f93":"df_valid.head()","6e6b3e52":"class DataGen(Sequence):\n    def __init__(self, image_size, images_path, masks_path, batch_size=5):\n        self.image_size = image_size\n        self.images_path = images_path\n        self.masks_path = masks_path\n        self.batch_size = batch_size\n        self.on_epoch_end()\n\n    def __getitem__(self, index):\n        if(index+1)*self.batch_size > len(self.images_path):\n            self.batch_size = len(self.images_path) - index*self.batch_size\n\n        images_path = self.images_path[index*self.batch_size : (index+1)*self.batch_size]\n        masks_path = self.masks_path[index*self.batch_size : (index+1)*self.batch_size]\n\n        images_batch = []\n        masks_batch = []\n\n        for i in range(len(images_path)):\n            ## Read image and mask\n            image = cv2.imread(images_path[i],1)\n            image = cv2.resize(image,(512,512))\n            image[(image==(255,255,255)).all(axis=2)] = (0,0,0)\n            image = image\/255\n            mask = cv2.imread(masks_path[i],0)\n            mask = cv2.resize(mask,(512,512))\n            mask = np.expand_dims(mask, -1)\n            mask = mask\/2\n            images_batch.append(image)\n            mask = np.array(mask,dtype = \"float\")\n            \n            masks_batch.append(mask)\n\n        return np.array(images_batch), np.array(masks_batch)\n\n    def on_epoch_end(self):\n        pass\n\n    def __len__(self):\n        return int(np.ceil(len(self.images_path)\/float(self.batch_size)))","13698baf":"batch_size = 5\ntrain_gen = DataGen(512, df_train.loc[:,\"image_path\"].values, df_train.loc[:,\"mask_path\"].values, batch_size=batch_size)\nvalid_gen = DataGen(512, df_valid.loc[:,\"image_path\"].values, df_valid.loc[:,\"mask_path\"].values, batch_size=batch_size)","b8217a19":"train_steps = len(df_train.loc[:,\"image_path\"].values)\/\/batch_size\nvalid_steps = len(df_valid.loc[:,\"image_path\"].values)\/\/batch_size","311068e6":"def squeeze_excite_block(inputs, ratio=8):\n    init = inputs\n    channel_axis = -1\n    filters = init.shape[channel_axis]\n    se_shape = (1, 1, filters)\n\n    se = GlobalAveragePooling2D()(init)\n    se = Reshape(se_shape)(se)\n    se = Dense(filters \/\/ ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n\n    x = Multiply()([init, se])\n    return x\n\ndef stem_block(x, n_filter, strides):\n    x_init = x\n\n    ## Conv 1\n    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=strides)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Conv2D(n_filter, (3, 3), padding=\"same\")(x)\n\n    ## Shortcut\n    s  = Conv2D(n_filter, (1, 1), padding=\"same\", strides=strides)(x_init)\n    s = BatchNormalization()(s)\n\n    ## Add\n    x = Add()([x, s])\n    x = squeeze_excite_block(x)\n    return x\n\n\ndef resnet_block(x, n_filter, strides=1):\n    x_init = x\n\n    ## Conv 1\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=strides)(x)\n    ## Conv 2\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=1)(x)\n\n    ## Shortcut\n    s  = Conv2D(n_filter, (1, 1), padding=\"same\", strides=strides)(x_init)\n    s = BatchNormalization()(s)\n\n    ## Add\n    x = Add()([x, s])\n    x = squeeze_excite_block(x)\n    return x\n\ndef aspp_block(x, num_filters, rate_scale=1):\n    x1 = Conv2D(num_filters, (3, 3), dilation_rate=(6 * rate_scale, 6 * rate_scale), padding=\"same\")(x)\n    x1 = BatchNormalization()(x1)\n\n    x2 = Conv2D(num_filters, (3, 3), dilation_rate=(12 * rate_scale, 12 * rate_scale), padding=\"same\")(x)\n    x2 = BatchNormalization()(x2)\n\n    x3 = Conv2D(num_filters, (3, 3), dilation_rate=(18 * rate_scale, 18 * rate_scale), padding=\"same\")(x)\n    x3 = BatchNormalization()(x3)\n\n    x4 = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n    x4 = BatchNormalization()(x4)\n\n    y = Add()([x1, x2, x3, x4])\n    y = Conv2D(num_filters, (1, 1), padding=\"same\")(y)\n    return y\n\ndef attetion_block(g, x):\n    \"\"\"\n        g: Output of Parallel Encoder block\n        x: Output of Previous Decoder block\n    \"\"\"\n\n    filters = x.shape[-1]\n\n    g_conv = BatchNormalization()(g)\n    g_conv = Activation(\"relu\")(g_conv)\n    g_conv = Conv2D(filters, (3, 3), padding=\"same\")(g_conv)\n\n    g_pool = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(g_conv)\n\n    x_conv = BatchNormalization()(x)\n    x_conv = Activation(\"relu\")(x_conv)\n    x_conv = Conv2D(filters, (3, 3), padding=\"same\")(x_conv)\n\n    gc_sum = Add()([g_pool, x_conv])\n\n    gc_conv = BatchNormalization()(gc_sum)\n    gc_conv = Activation(\"relu\")(gc_conv)\n    gc_conv = Conv2D(filters, (3, 3), padding=\"same\")(gc_conv)\n\n    gc_mul = Multiply()([gc_conv, x])\n    return gc_mul\n\nclass ResUnetPlusPlus:\n    def __init__(self, input_size=512):\n        self.input_size = input_size\n\n    def build_model(self):\n        n_filters = [16, 32, 64, 128, 256,512]\n        inputs = Input((self.input_size, self.input_size, 3))\n\n        c0 = inputs\n        c1 = stem_block(c0, n_filters[0], strides=1)\n\n        ## Encoder\n        c2 = resnet_block(c1, n_filters[1], strides=2)\n        c3 = resnet_block(c2, n_filters[2], strides=2)\n        c4 = resnet_block(c3, n_filters[3], strides=2)\n\n        ## Bridge\n        b1 = aspp_block(c4, n_filters[4])\n\n        ## Decoder\n        d1 = attetion_block(c3, b1)\n        d1 = UpSampling2D((2, 2))(d1)\n        d1 = Concatenate()([d1, c3])\n        d1 = resnet_block(d1, n_filters[3])\n\n        d2 = attetion_block(c2, d1)\n        d2 = UpSampling2D((2, 2))(d2)\n        d2 = Concatenate()([d2, c2])\n        d2 = resnet_block(d2, n_filters[2])\n\n        d3 = attetion_block(c1, d2)\n        d3 = UpSampling2D((2, 2))(d3)\n        d3 = Concatenate()([d3, c1])\n        d3 = resnet_block(d3, n_filters[1])\n\n        ## output\n        outputs = aspp_block(d3, n_filters[0])\n        outputs = Conv2D(1, (1, 1), padding=\"same\")(outputs)\n        outputs = Activation(\"sigmoid\")(outputs)\n\n        ## Model\n        model = Model(inputs, outputs)\n        return model","cdd79609":"smooth = 1.\ndef dice_coef(y_true, y_pred):\n    y_true_f = tf.keras.layers.Flatten()(y_true)\n    y_pred_f = tf.keras.layers.Flatten()(y_pred)\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n\n\ndef dice_loss(y_true, y_pred):\n    return 1.0 - dice_coef(y_true, y_pred)","0cce5b22":"image_size = 512\nlr = 0.01\nepochs = 30","791da68f":"arch = ResUnetPlusPlus(input_size=image_size)\nmodel = arch.build_model()\ncheckpoint = ModelCheckpoint(\"segmente_model.h5\", verbose=1, save_best_only=True,mode = \"max\", monitor = \"val_mean_io_u\")\nreduce_lr = ReduceLROnPlateau(monitor='val_mean_io_u', factor=0.1, patience=5, min_lr=0.000001, verbose=1, mode = \"max\")\ncallbacks = [checkpoint, reduce_lr]\noptimizer = Nadam(lr)\nmetrics = [MeanIoU(num_classes=2)]\nmodel.compile(loss=dice_loss, optimizer=optimizer, metrics=metrics)","7fd67ad7":"model.summary()","2cac1b75":"model.fit(train_gen,\n            validation_data=valid_gen,\n            steps_per_epoch=train_steps,\n            validation_steps=valid_steps,\n            epochs=epochs,\n            callbacks=callbacks)","1e2b1ad4":"plt.figure(figsize=(12,5))\nplt.subplot(1,2,1)\nplt.plot(model.history.history[\"val_mean_io_u\"],label = \"val_mean_iou\")\nplt.plot(model.history.history[\"mean_io_u\"],label = \"train_mean_iou\")\nplt.legend()\nplt.xlim(0, 16)\nplt.ylim(0,1)\nplt.title(\"mean iou\")\nplt.subplot(1,2,2)\nplt.plot(model.history.history[\"val_loss\"],label = \"val_dice_loss\")\nplt.plot(model.history.history[\"loss\"],label = \"train_dice_loss\")\nplt.title(\"dice loss\")\nplt.legend()\nplt.xlim(0, 16)\nplt.ylim(0,1)\nplt.savefig(\"results.png\")\nplt.show()","38e1c733":"model = load_model(\".\/segmente_model.h5\", custom_objects = {\"dice_loss\":dice_loss})","9057367f":"count = 0\nfig, axs = plt.subplots(3,4, figsize=(8,8))\n\nfor i in range(len(df_valid)):\n    if  count<3:\n        #read  images\n        rnd = np.random.randint(0,len(df_valid))\n        img = cv2.imread(df_valid.loc[rnd,\"image_path\"],1)\n        img = cv2.resize(img,(512,512))\n        img[np.where((img == (255,255,255)).all(axis=2))] = (0,0,0)\n        axs[count][0].imshow(img)\n        print(rnd)\n        axs[count][0].title.set_text('Image')\n        \n        #read original mask\n        mask = cv2.imread(df_valid.loc[rnd,\"mask_path\"],0)\n        axs[count][1].imshow(mask)\n        axs[count][1].title.set_text(\"Original Mask\")\n        \n        # prediction mask\n        pred = model.predict(img.reshape((1, 512, 512, 3))\/255).round()[0]                             \n        mask = cv2.resize(pred,(512,512))\n        axs[count][2].imshow(pred)\n        axs[count][2].title.set_text('Prediction Mask')\n        \n                                     \n        # overlay\n        s = np.where((pred.reshape(512,512,1) == np.max(pred)).any(axis=2))\n       \n        color = (0,0,255)\n        img[s] = color\n                                  \n        axs[count][3].imshow(img)\n        axs[count][3].title.set_text('Overlay')                             \n        \n        count +=1\n    if (count==3):\n        break\n\nfig.tight_layout() ","0883a54d":"## import libraries","fa210ddb":"## preprocessed image  vizualizing","74fbd940":"# Vizualizing","6366ca72":"# prepare data","865cc5f4":"# Results","35143b36":"# train-test split","0ac9e170":"# Prediction","8326cff6":"# get data and prepare","22be1910":"## Model"}}