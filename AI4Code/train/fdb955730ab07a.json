{"cell_type":{"dabc5062":"code","5b058081":"code","718e3939":"code","8ad15486":"code","06ecf9fe":"code","0036e724":"code","73262eaa":"code","2eb9bafa":"code","9c10c72b":"code","aa7ec800":"code","b7b51745":"code","45c95941":"code","1eb987e6":"code","b812f391":"code","865e9632":"code","159cf8da":"code","bf31b542":"code","8c9f92f0":"code","286c5bf5":"code","60518f81":"code","fe13de56":"code","2a667165":"code","69638eb8":"code","7306a223":"code","1d9d9a14":"code","8d2708b1":"code","f90ee288":"code","15610f87":"code","ff96ac17":"code","68c2a9a1":"code","e9aabf5b":"markdown","a5a211fa":"markdown","1a721d49":"markdown","2455879e":"markdown","faaaed6c":"markdown","f668e862":"markdown","365ba1a4":"markdown","e0b60059":"markdown","7b74fc77":"markdown","e3805b05":"markdown","5df82673":"markdown","89137eea":"markdown","fa285ddb":"markdown","29642075":"markdown","5caa9e19":"markdown","09b56797":"markdown","adde9026":"markdown","80b767fb":"markdown","b1c36976":"markdown","9811eb90":"markdown","b3685157":"markdown","245d28c6":"markdown","eb1bcd40":"markdown","ea93cf12":"markdown"},"source":{"dabc5062":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5b058081":"# Supress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","718e3939":"# Importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","8ad15486":"# Data display coustomization\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', -1)","06ecf9fe":"# To perform Hierarchical clustering\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.cluster import KMeans","0036e724":"# import all libraries and dependencies for machine learning\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import IncrementalPCA\nfrom sklearn.neighbors import NearestNeighbors\nfrom random import sample\nfrom numpy.random import uniform\nfrom math import isnan","73262eaa":"mall= pd.read_csv(r\"\/kaggle\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv\")\nmall.head()","2eb9bafa":"mall.shape","9c10c72b":"mall.info()","aa7ec800":"mall.describe()","b7b51745":"mall_d= mall.copy()\nmall_d.drop_duplicates(subset=None,inplace=True)","45c95941":"mall_d.shape","1eb987e6":"mall.shape","b812f391":"(mall.isnull().sum() * 100 \/ len(mall)).value_counts(ascending=False)","865e9632":"mall.isnull().sum()","159cf8da":"(mall.isnull().sum(axis=1) * 100 \/ len(mall)).value_counts(ascending=False)","bf31b542":"mall.isnull().sum(axis=1).value_counts(ascending=False)","8c9f92f0":"plt.figure(figsize = (5,5))\ngender = mall['Gender'].sort_values(ascending = False)\nax = sns.countplot(x='Gender', data= mall)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nplt.xticks(rotation=90)\nplt.show()","286c5bf5":" \nplt.figure(figsize = (20,5))\ngender = mall['Age'].sort_values(ascending = False)\nax = sns.countplot(x='Age', data= mall)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\n\nplt.show()","60518f81":"plt.figure(figsize = (25,5))\ngender = mall['Annual Income (k$)'].sort_values(ascending = False)\nax = sns.countplot(x='Annual Income (k$)', data= mall)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\n\nplt.show()","fe13de56":"plt.figure(figsize = (27,5))\ngender = mall['Spending Score (1-100)'].sort_values(ascending = False)\nax = sns.countplot(x='Spending Score (1-100)', data= mall)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\n\nplt.show()","2a667165":"# Let's check the correlation coefficients to see which variables are highly correlated\n\nplt.figure(figsize = (5,5))\nsns.heatmap(mall.corr(), annot = True, cmap=\"rainbow\")\nplt.savefig('Correlation')\nplt.show()","69638eb8":"sns.pairplot(mall,corner=True,diag_kind=\"kde\")\nplt.show()","7306a223":"# Data before Outlier Treatment \nmall.describe()","1d9d9a14":"f, axes = plt.subplots(1,3, figsize=(15,5))\ns=sns.violinplot(y=mall.Age,ax=axes[0])\naxes[0].set_title('Age')\ns=sns.violinplot(y=mall['Annual Income (k$)'],ax=axes[1])\naxes[1].set_title('Annual Income (k$)')\ns=sns.violinplot(y=mall['Spending Score (1-100)'],ax=axes[2])\naxes[2].set_title('Spending Score (1-100)')\nplt.show()\n","8d2708b1":"Q3 = mall['Annual Income (k$)'].quantile(0.99)\nQ1 = mall['Annual Income (k$)'].quantile(0.01)\nmall['Annual Income (k$)'][mall['Annual Income (k$)']<=Q1]=Q1\nmall['Annual Income (k$)'][mall['Annual Income (k$)']>=Q3]=Q3","f90ee288":"# Data After Outlier Treatment \nmall.describe()","15610f87":"f, axes = plt.subplots(1,3, figsize=(15,5))\ns=sns.violinplot(y=mall.Age,ax=axes[0])\naxes[0].set_title('Age')\ns=sns.violinplot(y=mall['Annual Income (k$)'],ax=axes[1])\naxes[1].set_title('Annual Income (k$)')\ns=sns.violinplot(y=mall['Spending Score (1-100)'],ax=axes[2])\naxes[2].set_title('Spending Score (1-100)')\nplt.show()","ff96ac17":"# Dropping CustomerID,Gender field to form cluster\n\nmall_c = mall.drop(['CustomerID','Gender'],axis=1,inplace=True)","68c2a9a1":"mall.head()","e9aabf5b":"Null Count: Columns","a5a211fa":"# Exploratory Data Analytics","1a721d49":"Null Percentage: Columns","2455879e":"Audience are having Spending Score (1-100) between 1 to 99 ","faaaed6c":"Audience are from Annual Income(k$) range between 15 to 137","f668e862":"**Annual Income (k$)**","365ba1a4":"Null Percentage: Rows","e0b60059":"There are no missing \/ Null values either in columns or rows","7b74fc77":"**Age**","e3805b05":"Null Count: Rows","5df82673":"# Data Preparation","89137eea":"# Duplicate Check","fa285ddb":"## We use Percentile Capping (Winsorization) for outliers handling","29642075":"## Data Loading","5caa9e19":"# Data Cleaning","09b56797":"**Spending Score (1-100)**","adde9026":"There is an outlier in Annual Income (k$) field but Income & Spending Score(1-100) has no outliers ","80b767fb":"The shape after running the drop duplicate command is same as the original dataframe.\n\nHence we can conclude that there were zero duplicate values in the dataset.","b1c36976":"## Outlier Analysis","9811eb90":"Data is not balanced, 6% more Females have participated  than males ","b3685157":"**Gender**","245d28c6":"- Age and Spending Score (1-100) are moderately correlated with correlation of -0.33","eb1bcd40":"Audience are from Age 18 to 70","ea93cf12":"Univariate Analysis"}}