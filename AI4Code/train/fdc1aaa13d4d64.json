{"cell_type":{"682907bd":"code","dfae10f6":"code","283f91b0":"code","9d4739e2":"code","ef6c0ba4":"code","de2fa1d3":"code","3ce1c6e8":"code","6916ba64":"code","a87bf06c":"code","05d70de7":"code","111f0469":"code","384ff42f":"code","1062e255":"markdown"},"source":{"682907bd":"import pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\nimport numpy as np\nfrom sklearn.ensemble import GradientBoostingClassifier","dfae10f6":"df_train = pd.read_csv(\"..\/input\/student-shopee-code-league-marketing-analytics\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/student-shopee-code-league-marketing-analytics\/test.csv\")\ndf_users = pd.read_csv(\"..\/input\/student-shopee-code-league-marketing-analytics\/users.csv\")","283f91b0":"df_train = df_train.fillna(-1)\ndf_users = df_users.fillna(-1)\ndf_test = df_test.fillna(-1)","9d4739e2":"user_dict = {}\nfor row in df_users.itertuples():\n    user_dict[row.user_id] = (row.attr_1,row.attr_2,row.attr_3,row.age,row.domain)","ef6c0ba4":"def get_user_feature(user_id,i):\n    if user_id in user_dict:\n        return user_dict[user_id][i]\n    else:\n        return -2","de2fa1d3":"def fill_ints(data):\n    if isinstance(data,int):\n        return data\n    if data.isnumeric():\n        return data\n    else:\n        return -1","3ce1c6e8":"def time_to_categorical_series(df,type=\"hour\"):\n    if type == \"hour\":\n        return df['date_time'].dt.hour.astype('category')\n    elif type == \"dayofweek\":\n        return df['date_time'].dt.dayofweek.astype('category')\n    elif type == \"month\":\n        return df['date_time'].dt.month.astype('category')\n    else:\n        return None\n    \ndef time_to_categorical(df):\n    hour_series = time_to_categorical_series(df,type='hour')\n    dayofweek_series = time_to_categorical_series(df,type='dayofweek')\n    month_series = time_to_categorical_series(df,type='month')\n\n    df['hour'] = hour_series\n    df['dayofweek'] = dayofweek_series\n    df['month'] = month_series","6916ba64":"cat_features = ['country_code','hour','dayofweek','month','domain']\nnumerical_features = [ 'subject_line_length',\n       'last_open_day', 'last_login_day', 'last_checkout_day',\n       'open_count_last_10_days', 'open_count_last_30_days',\n       'open_count_last_60_days', 'login_count_last_10_days',\n       'login_count_last_30_days', 'login_count_last_60_days',\n       'checkout_count_last_10_days', 'checkout_count_last_30_days',\n       'checkout_count_last_60_days','attr1', 'attr2',\n       'attr3', 'age']","a87bf06c":"def make_df_features(df,train=None,encoder=None):\n    df['attr1'] = df['user_id'].apply(lambda x: get_user_feature(x,0))\n    df['attr2'] = df['user_id'].apply(lambda x: get_user_feature(x,1))\n    df['attr3'] = df['user_id'].apply(lambda x: get_user_feature(x,2))\n    df['age'] = df['user_id'].apply(lambda x: get_user_feature(x,3))\n    df['domain'] = df['user_id'].apply(lambda x: get_user_feature(x,4))\n    df['date_time'] = pd.to_datetime(df['grass_date'])\n    df['last_open_day'] = df['last_open_day'].apply(fill_ints)\n    df['last_login_day'] = df['last_login_day'].apply(fill_ints)\n    df['last_checkout_day'] = df['last_checkout_day'].apply(fill_ints)\n    time_to_categorical(df)\n    cat = df.loc[:,cat_features].values\n    if train:\n        encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n        cat = encoder.fit_transform(cat).astype(np.float64)\n    else:\n        cat = encoder.transform(cat).astype(np.float64)\n    val = df.loc[:,numerical_features].values.astype(np.float64)\n    return np.concatenate([cat,val],axis=1),encoder","05d70de7":"train_features,encoder = make_df_features(df_train,True)\ntrain_labels = df_train['open_flag'].values\n\ntest_features,_ = make_df_features(df_test,False,encoder=encoder)","111f0469":"clf = GradientBoostingClassifier()\nclf.fit(train_features,train_labels)\npredictions = clf.predict(test_features)","384ff42f":"df_test = df_test.drop([col for col in df_test.columns if col!='row_id'],axis=1)\ndf_test['open_flag'] = predictions\ndf_test.to_csv('sub.csv',index=False)","1062e255":"# Just a lazy man's way of producing something\nPast kaggle competitions have shown that tabular data requires alot of data analysis and feature extraction to produce good results. They usually are an ensemble of gradient boosting techniques."}}