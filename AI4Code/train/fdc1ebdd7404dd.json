{"cell_type":{"8ff68284":"code","525f1fd1":"code","ffa083d1":"code","6023d3eb":"code","aa9529eb":"code","2c06acb6":"code","969560e9":"code","19e68c78":"code","91677896":"code","e6207e16":"code","e509dfc6":"markdown","a7bf36a8":"markdown","ad26d47c":"markdown","1441a9a6":"markdown","778aaa39":"markdown"},"source":{"8ff68284":"!wget -O gold.parquet https:\/\/www.dropbox.com\/s\/3m0xqogz5gi2moy\/gold.parquet?dl=1","525f1fd1":"import pandas as pd\nimport numpy as np\n\nwork_dir = \"\/content\"\n\n#leitura dos dados de entrada\ndf_bruto = pd.read_parquet(work_dir +\"\/gold.parquet\", engine=\"pyarrow\")\ndf_bruto.shape\n\n# n\u00e3o iremos utilizar estas duas colunas no treinamento e no teste\ndf_preparado = df_bruto.drop([\"key\", \"timestamp\"], axis=1)\n\n\n# Substitui valores nulos por 0 nas colunas num\u00e9ricas\ncolunas_numericas = ['pedidos_4_meses','pedidos_8_meses','pedidos_12_meses','itens_4_meses','itens_8_meses','itens_12_meses']\ndf_preparado[colunas_numericas] = df_preparado[colunas_numericas].fillna(value=0)\n\n# transformar colunas categ\u00f3ricas em num\u00e9ricas\ndf_preparado = pd.get_dummies(df_preparado, columns=[\"city\", \"state\", \"cnae_id\"])","ffa083d1":"now = pd.to_datetime(\"now\");\ndf_preparado['fez_ultima_compra'] = None\n\nfor idx, row in df_preparado.iterrows():\n  if row['ultima_compra']== None and int(row['pedidos_4_meses']) == 0 and int(row['pedidos_8_meses']) == 0 and int(row['pedidos_12_meses']) == 0:\n    df_preparado.loc[idx,'ultima_compra'] = 0\n    df_preparado.loc[idx,'fez_ultima_compra'] = 0\n  elif row['ultima_compra']!= None: #and int(row['pedidos_4_meses']) > 0.0 : #and int(row['pedidos_8_meses']) > 0 and int(row['pedidos_12_meses']) > 0:\n    compra = pd.to_datetime(row['ultima_compra'], infer_datetime_format=True, format=\"%Y-%m-%d\", errors='coerce')\n    dif = now - compra\n    df_preparado.loc[idx,'ultima_compra'] = int(dif\/np.timedelta64(1, 'h'))\n    df_preparado.loc[idx,'fez_ultima_compra'] = 1\n  #else:\n    #df_preparado.loc[idx,'ultima_compra'] = None\n    #df_preparado.loc[idx,'fez_ultima_compra'] = 0\n\ndf_preparado['fez_ultima_compra'] = df_preparado['fez_ultima_compra'].fillna(value=0)\ndf_preparado['ultima_compra'] = df_preparado['ultima_compra'].fillna(value=999999999)\n\n#df_preparado = pd.get_dummies(df_preparado, columns=[\"fez_ultima_compra\", \"ultima_compra\"])\n\ndf_preparado.head(20)","6023d3eb":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# seleciona as tuplas com r\u00f3tulos\ndf_to_train = df_preparado[df_preparado[\"defaulting\"].notnull()]\n\n# remove a coluna defaulting dos dados de treinamento para n\u00e3o gerar overfiting\nX = df_to_train.drop('defaulting', axis=1)\n\n# Transforma a vari\u00e1vel a predizer de boolean para inteiro\nle = LabelEncoder()\ny = le.fit_transform(df_to_train.defaulting.values)\n\n# Divis\u00e3o em conjunto de treinamento e valida\u00e7\u00e3o\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1)\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_valid.shape)\nprint(y_valid.shape)","aa9529eb":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import linear_model, datasets\nfrom sklearn import svm, datasets\nfrom sklearn import datasets\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#clf = DecisionTreeClassifier()\n#clf = linear_model.LinearRegression()\n#clf = svm.SVC(gamma = 0.001, C = 100)\n#clf = KNeighborsClassifier(n_neighbors=6)\nclf = linear_model.BayesianRidge()\n","2c06acb6":"#train model\n#clf.fit(X,y)\nclf.fit(X,y)\n\n#predict\ny_pred = clf.predict(X_valid)\n#pd.DataFrame(clf.coef_).describe()","969560e9":"df_test = df_preparado[df_preparado[\"defaulting\"].isnull()]\nX_test = df_test.drop('defaulting', axis=1)\ny_test = clf.predict(X_test)\n\noutput = df_test.assign(inadimplente=y_test)\noutput = output.loc[:, ['client_id','inadimplente']]\n#output.describe()","19e68c78":"from datetime import date\nfrom google.colab import files\nfrom datetime import datetime\n\ntaxa = 0.56\ntemp = output.copy()\nfor idx, row in temp.iterrows():\n  if row['inadimplente'] >= taxa:\n    temp.loc[idx,'inadimplente'] = int(1)\n  else:\n    temp.loc[idx,'inadimplente'] = int(0)\n\n#out = 'ouput_sklearn_' + datetime.now().strftime(\"%m_%d_%Y\") + '.csv'\n#temp.to_csv(work_dir +\"\/\"+out, index=False)\n#files.download(out) ","91677896":"y_pred_temp = np.array(y_pred, copy=True)","e6207e16":"import sklearn.metrics as metrics\n#taxa = 0.56 - RESJUSTES MANUAIS\nfor idx, item in enumerate(y_pred):\n  if item >= taxa:\n    y_pred[idx] = int(1)\n  else:\n    y_pred[idx] = int(0)\n\nprint(\"ROC AUC:\",metrics.roc_auc_score(y_valid, y_pred))\nprint(\"Acur\u00e1cia:\",metrics.accuracy_score(y_valid, y_pred))\nprint(\"F1 score:\",metrics.f1_score(y_valid, y_pred))\n\ny_pred = np.array(y_pred_temp, copy=True)","e509dfc6":"**CLASSIFICADOR ESCOLHIDO**\n \nAP\u00d3S V\u00c1RIOS TESTES O MELHOR RESULTADO OBTIDO FOI COM A REGRESS\u00c3O BAYESIANA\n \n**MOTIVOS**\n \n \n \n*   SEMELHANTE A REGRESS\u00c3O LINEAR POR\u00c9M COM RESULTADOS MAIS PRECISOS, A REGRESS\u00c3O DE BAYES NESSE CONTEXTO ONDE O DATASET N\u00c3O POSSUI MUITAS INFORMA\u00c7\u00d5ES(CONSIDERO ESSE UM DATASET DE CORRELA\u00c7\u00c3O ESPARSA ENTRE AS VARI\u00c1VEIS) JA QUE ESTOU OLHANDO PARA UMA SIMPLIFICA\u00c7\u00c3O FEITO PELO S\u00c1VIO.\n*   COMO BAYES FAZ UMA AN\u00c1LISE INDIVIDUAL PARA CADA VARI\u00c1VEL DO MODELO, SUA CAPACIDADE DE LIDAR COM DATASET MAIS ESPARSOS OBT\u00c9M MAIOR EFIC\u00c1CIA NA ACUR\u00c1CIA FINAL DE PREDI\u00c7\u00c3O. (BAYES CALCULA A PROBABILIDADE DE UM EVENTO OCORRER DADO QUE OUTRO TENHA OCORRIDO rsrsrs LEMBRETE)\n\n","a7bf36a8":"**N\u00c3O \u00c9 POSS\u00cdVEL CONFIAR NA ACUR\u00c1CIA CALCULADA COM y_pred POIS SEU DADOS FORAM USADOS PARA TREINAR O MODELO. EST\u00c1 ENVIESADO.**","ad26d47c":"**CLASSIFICA\u00c7\u00c3O**\n \nA INTERPRETA\u00c7\u00c3O DOS RESULTADOS DESSE ALGORITMO \u00c9 MAIS COMPLEXA, POIS SUA L\u00d3GICA \u00c9 DIFERENTE DOS ALGORITMOS CL\u00c1SSICOS QUE RESPONDEM 0 OU 1 PARA TOMADA DE DECIS\u00d5ES. COMO O ALGORITMO PADR\u00c3O USADO NA AULA(\u00c1RVORE DE DECIS\u00c3O)\n \nPARA EXTRAIR O RESULTADO FINAL CONSIDEREI UM N\u00daMERO X COMO METRICA. ESSE N\u00daMERO EST\u00c1 ENTRE UM INTERVALO OFERECIDO COMO RESPOSTA PARA CADA PREDI\u00c7\u00c3O FEITA PELO CLASSIFICADOR (CONHECIDO COMO L\u00d3GICA FUZZY)\n \nAP\u00d3S V\u00c1RIOS TESTES COM DATASET'S MENORES, OBTIVE 0.56 COMO PONTO DE CHAVEAMENTO.\nENT\u00c3O DEFINIDO COMO TRUE AS TUPLAS QUE OBTIVERAM UM VALOR MAIOR OU IGUAL A ESSA TAXA.\n \nESSA DECIS\u00c3O \u00c9 COMPLEXA E PODE LEVAR SEU RESULTADO A RU\u00cdNA OU A UM MAJESTOSO RESULTADO. INFELIZMENTE N\u00c3O CONSEGUI ENTENDER COM PERFEI\u00c7\u00c3O O ALGORITMO, POR ISSO USEI \n \n```\noutput.describe()\n```\n \nPARA IR AJUSTANDO ESTE VALOR. COM OS DADOS DO DESVIO PADR\u00c3O E A M\u00c9DIA J\u00c1 \u00c9 POSS\u00cdVEL OBTER UM PALPITE BEM PR\u00d3XIMO DO PERFEITO.(PERFEITO DO MODELO E N\u00c3O DO MUNDO)\n","1441a9a6":"**ALTERA\u00c7\u00d5ES NO DATASET**\n \n*   CRIAR UMA NOVA COLUNA PARA MEDIR A DIST NCIA ENTRE A \u00daLTIMA COMPRA E DATA CORRENTE\n*   CRIAR UMA COLUNA PARA DIZER SE FEZ \u00daLTIMA COMPRA\n \n**OBJETIVOS**\n \n*    AUMENTAR A CORRELA\u00c7\u00c3O ENTRE AS VARI\u00c1VEIS, TORNANDO A DATA DA \u00daLTIMA COMPRA UM PESO QUE PODE VARIAR ENTRE X1 M\u00cdNIMO E X2 MAXIMO.\n \n*    ANALISANDO O DATASET NOTA-SE QUE EXISTE CLIENTES SEM NENHUMA COMPRA, ASSIM POSSO CONSIDER\u00c1-LOS SEM D\u00cdVIDAS E ATRIBUIR UM DIST NCIA ZERO PARA SUA \u00daLTIMA COMPRA.\n \n*     A COLUNA QUE DIZ SE POSSUI OU N\u00c3O \u00daLTIMA COMPRA \u00c9 UM PESO EXTRA QUE DECIDE COLOCAR PARA REALIZAR O BALAN\u00c7O DA CORRELA\u00c7\u00c3O, CASO O DATASET POSSUI CLIENTES SEM COMPRAS POREM INADIMPLENTES(PASSIVEL DE ERRO)","778aaa39":"USEI TODO O DATASET DE TESTE NA CALIBRAGEM DO MODELO. ASSIM O MODELO AUMENTA SUA ACUR\u00c1CIA DEVIDO A MAIOR AMOSTRA DE DADOS PARA APRENDIZAGEM.\n \n**GANHOS:** ACUR\u00c1CIA AUMENTA\n \n**PERDAS:** N\u00c3O SOBRA DADOS PARA VALIDAR O MODELO"}}