{"cell_type":{"b0d5cb9b":"code","1e60b49c":"code","cf81b7e0":"code","68c15af3":"code","961e30f5":"code","a78c4ca4":"code","ddae8242":"code","c3dd29e7":"code","a05a40eb":"code","57d3b7f5":"code","7fe0b0fa":"code","461a7fc3":"code","b1ed2683":"code","a3e33d05":"code","3b2d7de3":"code","939ba420":"code","98aa379b":"code","12ed694f":"code","9ef11964":"code","530843f2":"code","7eef0bc6":"code","5eeae5a1":"code","f25b9dba":"code","8bee106f":"code","605d64fb":"code","82adbc03":"code","fa8bc845":"code","ecb1288f":"code","2411f67c":"code","9edac8b6":"code","940bb84a":"code","ab55a887":"code","6dc4c5ff":"code","eb861145":"code","dd7ec0da":"code","2d91deaf":"code","08341efe":"code","c4b9c8c9":"markdown"},"source":{"b0d5cb9b":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pandas.tools import plotting\nfrom scipy import stats\nplt.style.use(\"ggplot\")\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom scipy import stats\nprint(os.listdir(\"..\/input\"))\n\n","1e60b49c":"data = pd.read_csv(\"..\/input\/data.csv\")\ndata = data.drop(['Unnamed: 32','id'],axis = 1)\n","cf81b7e0":"\nprint(data.shape)\nprint\nprint(data.columns)\ndata.head()","68c15af3":"data.diagnosis.unique()","961e30f5":"\n\nm = plt.hist(data[data[\"diagnosis\"] == \"M\"].radius_mean,bins=30,fc = (1,0,0,0.5),label = \"Malignant\")\nb = plt.hist(data[data[\"diagnosis\"] == \"B\"].radius_mean,bins=30,fc = (0,1,0,0.5),label = \"Bening\")\nplt.legend()\nplt.xlabel(\"Radius Mean Values\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Histogram of Radius Mean for Bening and Malignant Tumors\")\nplt.show()","a78c4ca4":"frequent_malignant_radius_mean = m[0].max()\nindex_frequent_malignant_radius_mean = list(m[0]).index(frequent_malignant_radius_mean)\nmost_frequent_malignant_radius_mean = m[1][index_frequent_malignant_radius_mean]\nprint(\"Most frequent malignant radius mean is: \",most_frequent_malignant_radius_mean)","ddae8242":"data_bening = data[data[\"diagnosis\"] == \"B\"]\ndata_malignant = data[data[\"diagnosis\"] == \"M\"]","c3dd29e7":"desc = data_bening.radius_mean.describe()\nQ1 = desc[4]\nQ3 = desc[6]\nIQR = Q3-Q1\nlower_bound = Q1 - 1.5*IQR\nupper_bound = Q3 + 1.5*IQR\nprint(\"Anything outside this range is an outlier: (\", lower_bound ,\",\", upper_bound,\")\")","a05a40eb":"print(\"Outliers: \",data_bening[(data_bening.radius_mean < lower_bound) | (data_bening.radius_mean > upper_bound)].radius_mean.values)","57d3b7f5":"melted_data = pd.melt(data,id_vars = \"diagnosis\",value_vars = ['radius_mean', 'texture_mean'])","7fe0b0fa":"sns.boxplot(x = \"variable\", y = \"value\", hue=\"diagnosis\",data= melted_data)\nplt.show()","461a7fc3":"plt.hist(data_bening.radius_mean,bins=50,fc=(0,1,0,0.5),label='Bening',normed = True,cumulative = True)\nsorted_data = np.sort(data_bening.radius_mean)\ny = np.arange(len(sorted_data))\/float(len(sorted_data)-1)\nplt.plot(sorted_data,y,color='red')\nplt.title('CDF of bening tumor radius mean')\nplt.show()","b1ed2683":"plt.figure(figsize = (15,10))\nsns.jointplot(data.radius_mean,data.area_mean,kind=\"regg\")\nplt.show()","a3e33d05":"\n\n# Also we can look relationship between more than 2 distribution\nsns.set(style = \"white\")\ndf = data.loc[:,[\"radius_mean\",\"area_mean\",\"fractal_dimension_se\"]]\ng = sns.PairGrid(df,diag_sharey = False,)\ng.map_lower(sns.kdeplot,cmap=\"Blues_d\")\ng.map_upper(plt.scatter)\ng.map_diag(sns.kdeplot,lw =3)\nplt.show()\n\n","3b2d7de3":"f,ax=plt.subplots(figsize = (18,18))\nsns.heatmap(data.corr(),annot= True,linewidths=0.5,fmt = \".1f\",ax=ax)\nplt.xticks(rotation=90)\nplt.yticks(rotation=0)\nplt.title('Correlation Map')\nplt.savefig('graph.png')\nplt.show()","939ba420":"ranked_data = data.rank()\nspearman_corr = ranked_data.loc[:,[\"area_mean\",\"radius_mean\"]].corr(method= \"pearson\")\nprint(\"Spearman's correlation: \")\nprint(spearman_corr)","98aa379b":"statistic, p_value = stats.ttest_rel(data.radius_mean,data.area_mean)\nprint('p-value: ',p_value)","12ed694f":"df = pd.read_csv(\"..\/input\/data.csv\",header = 0)\ndf.drop('id',axis=1,inplace=True)\ndf.drop('Unnamed: 32',axis=1,inplace=True)\ndf['diagnosis'] = df['diagnosis'].map({'M':1,'B':0})\nfeatures_mean=list(df.columns[1:11])\n# split dataframe into two based on diagnosis\ndfM=df[df['diagnosis'] ==1]\ndfB=df[df['diagnosis'] ==0]","9ef11964":"plt.rcParams.update({'font.size': 8})\nfig, axes = plt.subplots(nrows=5, ncols=2, figsize=(8,10))\naxes = axes.ravel()\nfor idx,ax in enumerate(axes):\n    ax.figure\n    binwidth= (max(df[features_mean[idx]]) - min(df[features_mean[idx]]))\/50\n    ax.hist([dfM[features_mean[idx]],dfB[features_mean[idx]]], bins=np.arange(min(df[features_mean[idx]]), max(df[features_mean[idx]]) + binwidth, binwidth) , alpha=0.5,stacked=True, normed = True, label=['M','B'],color=['r','g'])\n    ax.legend(loc='upper right')\n    ax.set_title(features_mean[idx])\nplt.tight_layout()\nplt.show()\n","530843f2":"fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(8,10))\naxes = axes.ravel()\nfor idx,ax in enumerate(axes):\n    ax.figure\n    binwidth= (max(df[features_mean[idx]]) - min(df[features_mean[idx]]))\/50\n    ax.hist([dfM[features_mean[idx]],dfB[features_mean[idx]]], bins=np.arange(min(df[features_mean[idx]]), max(df[features_mean[idx]]) + binwidth, binwidth) , alpha=0.5,stacked=True, normed = True, label=['M','B'],color=['r','g'])\n    ax.legend(loc='upper right')\n    ax.set_title(features_mean[idx])\nplt.tight_layout()\nplt.show()","7eef0bc6":"data = pd.read_csv(\"..\/input\/data.csv\")\ndata = data.drop(['Unnamed: 32','id'],axis = 1)\ndata['diagnosis'].replace(to_replace='M', value = 1, inplace=True)\ndata['diagnosis'].replace(to_replace='B', value = 0, inplace=True)\nX = data.drop(['diagnosis'], axis=1)\ny = data['diagnosis']\nfrom sklearn import ensemble, linear_model, svm, neighbors, gaussian_process, naive_bayes, tree \nfrom sklearn.model_selection import cross_val_score","5eeae5a1":"scoreFrame = pd.DataFrame(columns = ['Algorithm Name', 'Average', 'Standard Deviation'])","f25b9dba":"algList=[\n    #linear\n    linear_model.Ridge(),\n    linear_model.SGDClassifier(),\n    #Neighbors\n    neighbors.KNeighborsClassifier(),\n    #SVM\n    svm.SVC(),\n    #Gaussian Process\n    gaussian_process.GaussianProcessClassifier(),\n    #Naive Bayes\n    naive_bayes.GaussianNB(),\n    #Tree\n    tree.DecisionTreeClassifier(),\n    #Ensemble\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.AdaBoostClassifier()\n]","8bee106f":"for alg in algList:\n    scores = cross_val_score(alg, X, y, cv = 10)\n    algName = alg.__class__.__name__\n    scoreAverage = scores.mean()\n    scoreSTD = scores.std() * 2\n    scoreFrame.loc[len(scoreFrame)] = [algName, scoreAverage, scoreSTD]\n    print(algName, \"is done.\")\n\nscoreFrame.sort_values('Average', ascending=False)\n","605d64fb":"svmFrame = pd.DataFrame(columns = ['Gamma', 'Average', 'Standard Deviation'])\n\nfor g in range(1,1000):\n    g = g\/1000000\n    alg = svm.SVC(gamma=g)\n    scores = cross_val_score(alg, X, y, cv = 3)\n    scoreAverage = scores.mean()\n    scoreSTD = scores.std() * 2\n    svmFrame.loc[len(svmFrame)] = [g, scoreAverage, scoreSTD]\n  \nsvmFrame.sort_values('Average', ascending=False).head(10)","82adbc03":"svmFrame = pd.DataFrame(columns = ['Kernel', 'Average', 'Standard Deviation'])\nkernelList = [ 'linear', 'poly', 'rbf', 'sigmoid']\nfor k in kernelList:\n    alg = svm.SVC(gamma=0.000148, kernel=k)\n    scores = cross_val_score(alg, X, y, cv = 3)\n    scoreAverage = scores.mean()\n    scoreSTD = scores.std() * 2\n    svmFrame.loc[len(svmFrame)] = [k, scoreAverage, scoreSTD]\n    \nsvmFrame.sort_values('Average', ascending=False).head(10)","fa8bc845":"svmFrame = pd.DataFrame(columns = ['Degrees', 'Average', 'Standard Deviation'])\n\nfor d in range(1,5):\n    alg = svm.SVC(gamma=0.000148, kernel='poly', degree=d)\n    scores = cross_val_score(alg, X, y, cv = 3)\n    scoreAverage = scores.mean()\n    scoreSTD = scores.std() * 2\n    svmFrame.loc[len(svmFrame)] = [d, scoreAverage, scoreSTD]\n   \nsvmFrame.sort_values('Average', ascending=False).head(10)","ecb1288f":"data = pd.read_csv('..\/input\/data.csv')\ndel data['Unnamed: 32']\nX = data.iloc[:, 2:].values\ny = data.iloc[:, 1].values\n\n# Encoding categorical data\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder_X_1 = LabelEncoder()\ny = labelencoder_X_1.fit_transform(y)\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\n\n#Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","2411f67c":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","9edac8b6":"classifier = tf.keras.Sequential()\n\nclassifier.add(layers.Dense(16, activation='relu', input_shape=(30,)))\nclassifier.add(layers.Dropout(0.1))\n\nclassifier.add(layers.Dense(16, activation='relu', input_shape=(30,)))\nclassifier.add(layers.Dropout(0.1))","940bb84a":"classifier.add(layers.Dense(1, activation='sigmoid'))","ab55a887":"classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","6dc4c5ff":"classifier.fit(X_train, y_train, batch_size=100, nb_epoch=150)","eb861145":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)\n","dd7ec0da":"# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)","2d91deaf":"print(\"Our accuracy is {}%\".format(((cm[0][0] + cm[1][1])\/57)*100))","08341efe":"sns.heatmap(cm,annot=True)\nplt.savefig('h.png')","c4b9c8c9":"# deep learning"}}