{"cell_type":{"b7118aa9":"code","747d6c40":"code","fb3a129a":"code","e942eda3":"code","95f59256":"code","0a755ec1":"code","474f54f6":"code","8c3f9dcc":"code","66e7e8cf":"code","c90d3fad":"code","0130e734":"code","9d1bc777":"code","092c28a0":"code","0a449a05":"code","77663e7a":"code","50f1b320":"code","224ebe00":"code","e77a8e15":"code","025cb3ef":"code","a1654a91":"code","ef7b9aee":"code","5add32e0":"code","d82cf442":"code","ef4237dc":"code","e0128050":"code","a2e9b33d":"code","c9c897b6":"code","75bb5970":"code","6db8af3f":"code","991813ec":"code","61105afc":"code","213b6b18":"code","6c245b2b":"code","e2aa32c7":"code","4773daa0":"code","c4823d15":"code","77493808":"code","9797d467":"code","d7ad03df":"code","d16db576":"code","6cb1a7ab":"code","63bace25":"code","2cdbc197":"code","6241b038":"code","ead8b8c4":"code","89c3db16":"code","083a6380":"code","c960030f":"code","0132f6e3":"code","7a16c97c":"code","845c4eb9":"code","afeca96b":"markdown","9cd50ad3":"markdown","67d4af3d":"markdown","a1dbbb94":"markdown","60e56319":"markdown","9da7c641":"markdown","59efedf2":"markdown","8d25ddb9":"markdown","66ac5903":"markdown","b5dcd526":"markdown","778d05d9":"markdown","1bbfa187":"markdown","9d2381b9":"markdown","7beb7c4a":"markdown","941a64f8":"markdown","d650762b":"markdown","8f9414ff":"markdown","cb208e47":"markdown","e3f6065e":"markdown","c3a81a4c":"markdown","0ac06721":"markdown","1173e858":"markdown","84ff291b":"markdown","19f7af2a":"markdown","d4679a40":"markdown","fa73e464":"markdown","d15b0247":"markdown","6312d8f6":"markdown","882c936f":"markdown","0aae3b0a":"markdown","9e9c0201":"markdown","c92f9d09":"markdown","35da42e5":"markdown","34a84cd5":"markdown","77002333":"markdown","ce5f20af":"markdown","b02f86ba":"markdown","57b6f065":"markdown","30e7e8b6":"markdown","67657307":"markdown","8a746dc1":"markdown","eb39643f":"markdown","1999577d":"markdown","a10ab08d":"markdown","12a33e90":"markdown","200a1891":"markdown","b0369f50":"markdown","146f89c5":"markdown","8f5d7799":"markdown","4ef4e57f":"markdown","b8c7b82e":"markdown"},"source":{"b7118aa9":"import os\nimport math\n\n\n#\n#\nfrom skimage.segmentation import flood as flood\nimport h5py \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy as sp\nfrom scipy.stats import skew\nfrom scipy.stats import kurtosis\nimport scipy.ndimage as ndi\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn import svm\nfrom skimage.measure   import shannon_entropy\nimport cv2\nfrom skimage import io\nfrom skimage import color\nfrom skimage.draw import polygon\nfrom skimage.feature import greycomatrix, greycoprops\nfrom sklearn.decomposition import PCA\n\n\n# from skimage.feature import canny\n# from skimage.filters import sobel\n# from skimage.transform import hough_line, hough_line_peaks\n\n\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n\nfrom IPython.display import Image","747d6c40":"with h5py.File('..\/input\/mias-mammography\/all_mias_scans.h5', 'r') as scan_h5:\n    print(\"Keys: %s\" % scan_h5.keys())\n    bg = scan_h5['BG'][:]\n    clas = scan_h5['CLASS'][:]\n    radius =  scan_h5['RADIUS'][:]\n    severity =  scan_h5['SEVERITY'][:]\n    scan_lr = scan_h5['scan'][:]\n    print('\\n|||||||File read successfuly|||||||')","fb3a129a":"plt.imshow(scan_lr[1], cmap='gray')","e942eda3":"scan_lr.shape","95f59256":"def right_orient_mammogram(image):\n    left_nonzero = cv2.countNonZero(image[:, 0:int(image.shape[1]\/2)])\n    right_nonzero = cv2.countNonZero(image[:, int(image.shape[1]\/2):])\n    \n    if(left_nonzero < right_nonzero):\n        image = cv2.flip(image, 1)\n\n    return image","0a755ec1":"flippedImg = np.zeros((330,1024,1024))\n","474f54f6":"for i in range(330):\n    flippedImg[i] = right_orient_mammogram(scan_lr[i])\n    ","8c3f9dcc":"def forceFlip(img):\n    img = cv2.flip(img,1)\n    return img","66e7e8cf":"flippedImg[36]=forceFlip(flippedImg[36])\nflippedImg[76]=forceFlip(flippedImg[76])\nflippedImg[102]=forceFlip(flippedImg[102])\nflippedImg[153]=forceFlip(flippedImg[153])\nflippedImg[154]=forceFlip(flippedImg[154])\nflippedImg[259]=forceFlip(flippedImg[259])\nflippedImg[267]=forceFlip(flippedImg[267])\nflippedImg[275]=forceFlip(flippedImg[275])\nflippedImg[277]=forceFlip(flippedImg[277])\nflippedImg[289]=forceFlip(flippedImg[289])\nflippedImg[291]=forceFlip(flippedImg[291])\nflippedImg[293]=forceFlip(flippedImg[293])\nflippedImg[311]=forceFlip(flippedImg[311])\nflippedImg[329]=forceFlip(flippedImg[329])\n\n# plt.imshow((flippedImg[277]))","c90d3fad":"plt.imshow(flippedImg[275], cmap='gray')","0130e734":"def cropLeft(img):\n    mini = 0\n    pix = 0\n    \n    for i in range(1024):\n        if img[10][i]>10:\n            mini = i\n            break\n    newimg=np.ones((1024,800))*pix\n#     print(min,img[10][200])\n    diff = 1024-mini\n    if diff<800:\n        newimg[:,:diff] = img[:,mini:]\n#         print('in cropleft : shape :', newimg.shape)\n    elif diff>800:\n        newimg = img[:,mini:(mini+800)]\n    elif diff==800:\n        newimg = img[:,mini:]\n#     print(newimg.shape)\n\n#     plt.imshow(newimg)\n    return newimg","9d1bc777":"leftCropped = np.zeros((330,1024,800))\nfor i in range(330):\n#     img = right_orient_mammogram(scan_lr[i])\n#     print(i)\n    imgforcropleft = flippedImg[i]\n    leftCropped[i] = cropLeft(imgforcropleft)","092c28a0":"plt.imshow(leftCropped[58],cmap='gray')","0a449a05":"Image('..\/input\/explain\/artifact.png')","77663e7a":"def removeArt(img):\n    thresh = 30\n#     thresh = 10\n    minPix = 40\n\n\n#     print(start)\n        \n    newim = np.zeros((1024,800))\n    newim = img.copy()\n    for i in range(1024):\n        start = 0 \n        for k in range(800):\n            if img[100][k] != 0:\n                start = k\n                break\n        for j in range(start , 800-minPix):\n#         for j in range(768-minPix):\n            ar = newim[i][j:j+minPix]\n            if (all(x < thresh for x in ar)):\n                newim[i][j:] = 0 \n                break\n#     plt.imshow(newim)\n    return newim","50f1b320":"artImg = np.zeros((330,1024,800))\nfor i in range(330):\n    artImg[i]  = removeArt(leftCropped[i])","224ebe00":"def cropTop(img):\n    newim = np.zeros((1024,800))\n    newim[:1023,:]=img[1:,:]\n    return newim\n    ","e77a8e15":"topCropped = np.zeros((330,1024,800))\nfor i in range(330):\n    topCropped[i]  = cropTop(artImg[i])","025cb3ef":"new1 = np.zeros((1024,800))\nnew1[:934,:] = topCropped[1][90:,:]\ntopCropped[1] = new1\n\nnew1 = np.zeros((1024,800))\nnew1[:1002,:] = topCropped[10][22:,:]\ntopCropped[10] = new1\n\nnew1 = np.zeros((1024,800))\nnew1[:1009,:] = topCropped[308][15:,:]\ntopCropped[308] = new1","a1654a91":"def clahe(img, clip=2.0, tile=(8, 8)):\n    img = cv2.normalize(\n        img,\n        None,\n        alpha=0,\n        beta=255,\n        norm_type=cv2.NORM_MINMAX,\n        dtype=cv2.CV_32F,\n    )\n    img_uint8 = img.astype(\"uint8\")\n\n    clahe_create = cv2.createCLAHE(clipLimit=clip, tileGridSize=tile)\n    clahe_img = clahe_create.apply(img_uint8)\n\n    return clahe_img","ef7b9aee":"enhancedImg = np.zeros((330,1024,800))","5add32e0":"for i in range(330):\n    enhancedImg[i] = clahe(topCropped[i])\n    ","d82cf442":"plt.imshow(enhancedImg[0], cmap='gray')","ef4237dc":"del flippedImg\ndel leftCropped\ndel artImg\ndel topCropped","e0128050":"Image('..\/input\/explain\/cropRoi.png')","a2e9b33d":"def cropRoi(img): # making triangle\n    end = -1\n    for i in range(800):\n        if img[10][i]<10:\n            end =i\n            break\n    myROI = [(0,800),(0,1023),(800,1023),(800,0),(end,0)]\n    img = cv2.fillPoly(img, [np.array(myROI)], 0)\n    return img","c9c897b6":"Image('..\/input\/explain\/cropRoi1.png')","75bb5970":"def newClust(knimage):\n#     print(knimage.shape)\n#     knimage = cv2.cvtColor(knimage,cv2.COLOR_GRAY2RGB)\n    vectorized = knimage.reshape((-1,3))\n    pixel_values = vectorized.reshape((-1, 3))\n    pixel_values = np.float32(pixel_values)\n    \n    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n    \n    k = 3\n    _, labels, (centers) = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n    centers = np.uint8(centers)\n    labels = labels.flatten()\n    segmented_image = centers[labels.flatten()]\n    segmented_image = segmented_image.reshape(knimage.shape)\n    return segmented_image","6db8af3f":"Image('..\/input\/explain\/after-segmentation.png')","991813ec":"def findSeed(img):\n#     thresh = 162\n    pix =30\n    seed = (10,30)\n\n    maxi = 0\n    for i in range(800):\n        for j in range(800):\n            if img[i][j]>maxi:\n                if (all(x > maxi for x in img[i,j:j+pix])) and (all(y > maxi for y in img[i:i+pix,j])):\n                    maxi = img[i][j]\n                    seed=(i,j)\n                \n    return seed","61105afc":"Image('..\/input\/explain\/check-width-2.png')","213b6b18":"Image('..\/input\/explain\/check-width-new.png')","6c245b2b":"def checkWidth(mimg):\n    img =mimg.copy()\n    steepDist = 0\n    steepLoc=0\n    steepThresh=30\n    for i in range(800):\n        for j in range(799,0,-1):\n            localdist = 0\n            if img[i][j]==True:\n                localdist = j   \n                if steepDist ==0:\n                    steepDist=localdist\n                else:\n                    if localdist-steepDist>steepThresh:\n                        img[steepLoc:,:] = 0\n                        return img\n                    if localdist<steepDist:\n                        steepDist=localdist\n                        steepLoc=i\n                localdist=0\n                break\n    return img\n\n","e2aa32c7":"Image('..\/input\/explain\/width-checking.png')","4773daa0":"def findDiff(img1,img2):\n    for i in range(1024):\n        for j in range(800):\n            if img1[i][j] >0:\n                img2[i][j]=0\n#                 img2 =0\n#     plt.imshow(img2)\n    return img2","c4823d15":"def newRemove(mimg):\n    img=mimg.copy()\n    crpimg= cropRoi(img)\n    fimg = np.float32(crpimg)\n    gimg = cv2.cvtColor(fimg,cv2.COLOR_GRAY2RGB)\n    clustimg = newClust(gimg)\n    cvimg= cv2.cvtColor(clustimg, cv2.COLOR_BGR2GRAY)\n    seed = findSeed(cvimg)\n    floodimg  = flood(cvimg, seed)\n    widthImg = checkWidth(floodimg)\n    cpimg = mimg.copy()\n    result = findDiff(widthImg,cpimg)\n    \n#### UNCOMMENT BELOW LINES TO SEE WHAT'S HAPPENING IN EACH STEP ####\n\n#     fig, axes = plt.subplots(1, 5, figsize=(15,10))\n#     fig.tight_layout(pad=3.0)\n#     plt.xlim(0,img.shape[1])\n#     plt.ylim(img.shape[0])\n    \n#     axes[0].set_title('original')\n#     axes[0].imshow(mimg, cmap='gray')\n#     axes[0].axis('on') \n    \n#     axes[1].set_title('Segmented')\n#     axes[1].imshow(clustimg, cmap='gray')\n#     axes[1].axis('on')\n\n#     axes[2].set_title('flooding')\n#     axes[2].imshow(floodimg, cmap='gray')\n#     axes[2].axis('on')\n\n#     axes[3].set_title('width check')\n#     axes[3].imshow(widthImg, cmap='gray')\n#     axes[3].axis('on') \n\n#     axes[4].set_title('Pectoral muscle removed')\n#     axes[4].imshow(result, cmap='gray')\n#     axes[4].axis('on') \n#     plt.show()\n\n\n    return result","77493808":"newSliced= np.zeros((330,1024,800))","9797d467":"for i in range(330):\n    print(i)\n    newSliced[i] = newRemove(enhancedImg[i])","d7ad03df":"Image('..\/input\/explain\/output-remove.png')","d16db576":"\ndef checkWidthManual(mimg,steep):\n    img =mimg.copy()\n    steepDist = 0\n    steepLoc=0\n    steepThresh=steep\n    for i in range(800):\n        for j in range(799,0,-1):\n            localdist = 0\n            if img[i][j]==True:\n                localdist = j\n                if steepDist ==0:\n                    steepDist=localdist\n                else:\n\n                    if localdist-steepDist>steepThresh:\n                        img[steepLoc:,:] = 0\n                        return img\n                    if localdist<steepDist:\n                        steepDist=localdist\n                        steepLoc=i\n                localdist=0\n                break\n\n    return img","6cb1a7ab":"def newRemoveManual(mimg,steep):\n    img=mimg.copy()\n    crpimg= cropRoi(img)\n    fimg = np.float32(crpimg)\n    gimg = cv2.cvtColor(fimg,cv2.COLOR_GRAY2RGB)\n    clustimg = newClust(gimg)\n    cvimg= cv2.cvtColor(clustimg, cv2.COLOR_BGR2GRAY)\n    seed = findSeed(cvimg)\n    floodimg  = flood(cvimg, seed)\n    widthImg = checkWidthManual(floodimg,steep)\n    cpimg = mimg.copy()\n    result = findDiff(widthImg,cpimg)\n    return result","63bace25":"newSliced[34] = newRemoveManual(enhancedImg[34],80)\nnewSliced[94] = newRemoveManual(enhancedImg[94],50)\nnewSliced[116] = newRemoveManual(enhancedImg[116],80)\nnewSliced[138] = newRemoveManual(enhancedImg[138],0)\nnewSliced[163] = newRemoveManual(enhancedImg[163],95)\nnewSliced[171] = newRemoveManual(enhancedImg[171],40)\nnewSliced[222] = newRemoveManual(enhancedImg[222],45)\nnewSliced[296] = newRemoveManual(enhancedImg[296],220)\nnewSliced[312] = newRemoveManual(enhancedImg[312],210)\nnewSliced[315] = newRemoveManual(enhancedImg[315],100)\nnewSliced[322] = newRemoveManual(enhancedImg[322],200)","2cdbc197":"Image('..\/input\/explain\/smooth1.png')","6241b038":"def findDiff2(img1,img2):\n    img3 =img2.copy() \n    for i in range(1024):\n        for j in range(800):\n            if img1[i][j] ==0:\n                img3[i][j]=0\n#                 img2 =0\n#     plt.imshow(img2)\n    return img3","ead8b8c4":" def smoothImg(im):\n    ite =15\n    ke =3\n    image = newSliced[im]\n    image = image.astype(\"uint8\")\n    blur = cv2.GaussianBlur(image, (3,3), 0)\n    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n    # Filter using contour area and remove small noise\n    cnts = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n    for c in cnts:\n        area = cv2.contourArea(c)\n        if area < 1:\n            cv2.drawContours(thresh, [c], -1, (0,0,0), -1)\n    # Morph close and invert image\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (ke,ke))\n    close = 255 - cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=ite)\n    result = findDiff2(close,enhancedImg[im])\n    plt.imshow(result)\n    return result\n","89c3db16":"smoothedImg = np.zeros((330,1024,800))","083a6380":"for i in range(330):\n    print(i)\n    smoothedImg[i]= smoothImg(i)","c960030f":"plt.imshow(smoothImg(25))","0132f6e3":"# h5f = h5py.File('SLICE_SECONDLAST.h5', 'w')\n# h5f.create_dataset('img', data=newSliced)\n# h5f.create_dataset('severity',data=severity)\n# h5f.close()","7a16c97c":"# h5f = h5py.File('ENHANCE_SECONDLAST.h5', 'w')\n# h5f.create_dataset('img', data=enhancedImg)\n# h5f.create_dataset('severity',data=severity)\n# h5f.close()\n","845c4eb9":"# h5f = h5py.File('slicedImgNEW1.h5', 'w')\n# h5f.create_dataset('img', data=smoothedImg)\n# h5f.create_dataset('severity',data=severity)\n# h5f.close()","afeca96b":"\nEach step is done as seperate functions. Algorithms for each steps can be found along with each functions.<br>\n\nAlgorithm for removePectoral()\n\n1. First cropping the ROI ina a triangle shape give in the image below.\n2. Segmentation of the image using k-means\n3. Doing a region-growing algorithm to find the pectorial muscle.\n4. some pectoral muscles joins with the breast tissues , so it is necessary to identify this and remove the pectoral muscle only.(we will use checkWidth function for this)\n5. Taking the difference of the enhanced image and the image got in above step to get the image without pectoral muscles\n6. now there will be some noises in the image we will do morphological closing and again taking a difference of the enhanced image and the image we got after doing 'closing' operation.","9cd50ad3":"The resultant image is given below","67d4af3d":"### Algorithm of widthCheck()\n\nThis algorithm works on thew assumption that pectoral muscles appear in in the top left corner and the width of the same decreases when coming down.\n\n1. loop through the image\n2. Initialize 'steep' with 0.\n2. if current pixel is black :\n    * difference = width of white pixels - steep\n    * if difference < 'steep_threshold':\n        * steep = current row\n    * else\n        * make all pixels down the current row as black.\n        * return image\n    * break\n        \n3. return image\n    ","a1dbbb94":"# Before starting\n\n\n- This notebook is divided into 2 parts . 2nd part can be found by clicking the below link.\n- https:\/\/www.kaggle.com\/ananthan123\/cancer-part2\n\n- In this notebook we will be doing the preprocessing of the image and in next part we will be doing the rest .\n\n- You can find more information about the techniques used in this notebook by checking the 'REFERENCES' section\n\n","60e56319":"### Region growing algorithm","9da7c641":"### Saving (h5)","59efedf2":"- we have to apply a region growing algorithm to get the required section.(see above image)\n- for that we have to find a 'seed point'.(seed point is the starting point of the region growing)\n- in our case the first occuring bright point will be the seed point.\n- we will find seed point using the 'findSeed()' .\n\nAlgorithm for findSeed()\n\n1. loop through the image.\n     * store the intensity of pixel in 'max' variable.\n     * if find a pixel larger than 'max' :\n          - max = current point\n2. return max\n  ","8d25ddb9":"# Preprocessing","66ac5903":"# Read data","b5dcd526":"#### finding difference","778d05d9":"# Cropping top","1bbfa187":"### checkWidth() function","9d2381b9":"### Manually slicing.","7beb7c4a":"We will use this data in the next part","941a64f8":"This step is done in the removePectoral() method.\nusing the below two steps \n>     seed = findSeed(cvimg)\n>     floodimg  = flood(cvimg, seed)     ","d650762b":"We will be cropping the left side of images .\nAll the images should be 1024* 800 after this step .\n\n\nAlgorithm for cropLeft()\n\n1. crop left side\n2. If the resultant image width == 800 then return the image\n3. if size of resultant image <800 then add pixels at right to make it 800\n4. if resultant image width > 800 crop the right pixels to make it 800","8f9414ff":"### Cropping left side of image","cb208e47":"### Individual cropping of some images","e3f6065e":"This part is very cruicial.\n- Pectorial muscles appear in top left corners of the mammograms .\n- This muscles have same density as of the cancer tissues . \n- so it is necessary to remove these muscles.\n- As these muscles have same density as the cancer cells , it is little bit difficult to remove these.","c3a81a4c":"Some images have all zero values in top row , so we are cropping it.","0ac06721":"- Above figures show that the parts that we don't want are also grouped together with the pectoral muscle.\n- So we have to take only the pectoral muuscle.\n- if a black pixel is found then break the loop and go to the next row.\n- Check width function loop through each rows and calculate the width of bright pixels in each row.\n- If a sudden increase in width is found then make all the pixels down it as black.\n- The algorithm and explanation is given below.","1173e858":"### Flip all image to right","84ff291b":"### Smoothing ","19f7af2a":"# Import libraries","d4679a40":"- Output after removing the pectoral muscles is given above.\n- We need to remove the noises in the images to get the required section\n- we will do morphological closing operation to remove the noises in the image.","fa73e464":"Output of each stage is given below","d15b0247":"Algorithm for finding difference\n\nfunction findDiff2(image1,image2){\n\n\/\/ image 1 is the image after close operation and image2 is the ehanced image.\n\n1. loop through image1\n2. if current pixel == 0:\n    * image2[current_pixel] = 0\n3. return image2\n\n}","6312d8f6":"### Finding the difference of enhanced image and the above image","882c936f":"The 'severity' feature will be our target feature.","0aae3b0a":"As we can see some images are right oriented and some are left oriented , first we will make all the images right oriented.","9e9c0201":"### Finding seed point","c92f9d09":"### Image enhancement","35da42e5":"### Combining all the algorithms","34a84cd5":"Normalizing image and Enhancing it using cv2.createCLAHE ","77002333":"1. h5py\n- https:\/\/docs.h5py.org\/en\/stable\/quick.html\n2. Image enhancement (clahe)\n- https:\/\/docs.opencv.org\/4.5.2\/d5\/daf\/tutorial_py_histogram_equalization.html","ce5f20af":"### Segmentation","b02f86ba":"### Manually flipping ","57b6f065":"#### cropRoi() Algorithm\n\n1. find the point(end of bright area) [given in above picture].\n2. Draw a polygon and fill it with black with points given below:\n   * end of bright area . -> We can see that pectoral muscle will be before this point\n   * 800,0                -> Pectoral muscle will be above this point\n   * Bottom left\n   * Bottom right\n   * Top right\n \nIf we look at the images the pectoral muscle will be above this region always.\n\n","30e7e8b6":"# Introduction\n\n- We will be using the MIAS dataset .\n- There are 330 rows.\n- The methodology will be as follows:\n\n#### Pre-processing -> Feature extraction -> Feture selection -> Modelling\n\n","67657307":"Algorithm for finding difference\n\n1. loop through image\n2. if current pixel > 0:\n    * enhancedImage[current_pixel] = 0\n3. return image","8a746dc1":"# Exploratory data analysis","eb39643f":"# Remove pectoral","1999577d":"Now some images have some more top zero value rows , so removing it manually. ","a10ab08d":"- clust() function is to do segmentation and the result is given below.","12a33e90":"### remove artifacts","200a1891":"But some images are still not flipped , so we are doing it manually.. (We can improve our algorithm to remove this manual flipping)","b0369f50":"# References","146f89c5":"- Artifacts are the labels in the mammograms . (Refer to the above picture.)\n- This will give negative results so it is important to remove all these.\n\nAlgorithm for removeArt()\n\n1. Find the starting of thhe bright part and store it in variable 'start' .\n2. Find the ending of the bright part and store it in the variable 'end' .\n3. make all the pixels right of 'end' to zero\n4. return the image\n","8f5d7799":"### Algorithm for smoothImg()\n\n1. blur := Blur the image (gaussian blur)\n2. thresh := threshold of 'blur'\n3. contour := find contours from 'thresh'\n4. close := perform closing operation in image\n5. resullt := findDiff2(close,enhanced_image)\n6. return result","4ef4e57f":"### Cropping ROI","b8c7b82e":"Some images were not properly processed in above step , so doing it manually by changing the values."}}