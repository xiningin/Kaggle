{"cell_type":{"157ccc1f":"code","e754fd3c":"code","5309b475":"code","4a74fa89":"code","deaef95f":"code","39f9fc37":"code","1b5230a1":"code","783a61d0":"code","e8ea884d":"code","a15da3be":"code","aaf802d8":"code","e79ade88":"code","bb5f3399":"code","637f3c2d":"code","8755321d":"code","6b865366":"code","acc63885":"code","e83a9681":"code","2880cce6":"code","14889fd2":"code","1db3aed2":"code","5c528a20":"code","9a7546a6":"code","2962ce31":"code","f0ee2497":"code","aadf71d3":"code","b6792a6e":"code","3ebd65f6":"code","4be45111":"code","418c382b":"code","11e23291":"code","c9ed26df":"code","80b173ab":"code","ef383c82":"code","5099387c":"code","fbab26b2":"code","d5da5c47":"code","951d1b04":"code","694963ae":"code","87bdcf8f":"code","4097a7be":"code","9585d1cb":"code","8b644d8e":"code","3c4f35b4":"code","86f5298d":"code","4824ec79":"code","fbf3c68f":"code","7e4f2afd":"code","d9e5e5a6":"code","a5f2dde2":"code","ead52568":"code","b8f89a06":"code","4e09704f":"markdown","db23e032":"markdown","30ef4eea":"markdown"},"source":{"157ccc1f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e754fd3c":"# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\n# Import model libraries\nfrom sklearn.linear_model import LinearRegression\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\n# Suppress the warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","5309b475":"# Import the price data\ndf = pd.read_csv(\"..\/input\/gold-prices\/monthly_csv.csv\")\ndf.head()","4a74fa89":"df.shape","deaef95f":"print(f\"Date range of gold prices available from - {df.loc[:,'Date'][0]} to {df.loc[:,'Date'][len(df)-1]}\")","39f9fc37":"date = pd.date_range(start='1\/1\/1950', end='8\/1\/2020', freq='M')\ndate","1b5230a1":"df['month'] = date\ndf.drop('Date',axis=1,inplace=True)\ndf = df.set_index('month')\ndf.head()","783a61d0":"df.plot(figsize=(20,8))\nplt.title(\"Gold price (Monthly) since 1950\")\nplt.xlabel(\"Months\")\nplt.ylabel(\"Price\")\nplt.grid();","e8ea884d":"round(df.describe(),3)","a15da3be":"_, ax = plt.subplots(figsize=(25,8))\nsns.boxplot(x = df.index.year,y = df.values[:,0],ax=ax)\nplt.title(\"Gold price (Monthly) since 1950\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Price\")\nplt.xticks(rotation=90)\nplt.grid();","aaf802d8":"_, ax = plt.subplots(figsize=(22,8))\nsns.boxplot(x = df.index.month_name(),y = df.values[:,0],ax=ax)\nplt.title(\"Gold price (Monthly) since 1950\")\nplt.xlabel(\"Months\")\nplt.ylabel(\"Price\")\nplt.grid();","e79ade88":"from statsmodels.graphics.tsaplots import month_plot\n\nfig, ax = plt.subplots(figsize=(22,8))\n\nmonth_plot(df,ylabel='Gold price',ax=ax)\nplt.title(\"Gold price (Monthly) since 1950\")\nplt.xlabel(\"Months\")\nplt.ylabel(\"Price\")\nplt.grid();","bb5f3399":"# Average gold price per year trend since 1950\ndf_yearly_sum = df.resample('A').mean()\ndf_yearly_sum.plot();\nplt.title(\"Average Gold price (Yearly) since 1950\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Price\")\nplt.grid()","637f3c2d":"# Average gold price per quarter trend since 1950\ndf_quarterly_sum = df.resample('Q').mean()\ndf_quarterly_sum.plot();\nplt.title(\"Average Gold price (Quarterly) since 1950\")\nplt.xlabel(\"Quarter\")\nplt.ylabel(\"Price\")\nplt.grid()","8755321d":"# Average gold price per decade trend since 1950\ndf_decade_sum = df.resample('10Y').mean()\ndf_decade_sum.plot();\nplt.title(\"Average Gold price (Decade) since 1950\")\nplt.xlabel(\"Decade\")\nplt.ylabel(\"Price\")\nplt.grid()","6b865366":"# Coefficient of variation in price\ndf_1 = df.groupby(df.index.year).mean().rename(columns={'Price':'Mean'})\ndf_1 = df_1.merge(df.groupby(df.index.year).std().rename(columns={'Price':'Std'}),left_index=True,right_index=True)\ndf_1['CoV_pct'] = ((df_1['Std']\/df_1['Mean'])*100).round(2)\ndf_1.head()","acc63885":"# Average gold price per year trend since 1950\nfig, ax = plt.subplots(figsize=(15,10))\ndf_1['CoV_pct'].plot();\nplt.title(\"Average Gold price (Yearly) since 1950\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Coefficient of Variation in %\")\nplt.grid()","e83a9681":"train    =   df[df.index.year <= 2015] \ntest     =   df[df.index.year > 2015]","2880cce6":"train['Price'].plot(figsize=(13,5), fontsize=14)\ntest['Price'].plot(figsize=(13,5), fontsize=14)\nplt.grid()\nplt.legend(['Training Data','Test Data'])\nplt.show()","14889fd2":"train_time = [i+1 for i in range(len(train))]\ntest_time = [i+len(train)+1 for i in range(len(test))]\nlen(train_time), len(test_time)","1db3aed2":"LR_train = train.copy()\nLR_test = test.copy()","5c528a20":"LR_train['time'] = train_time\nLR_test['time'] = test_time","9a7546a6":"lr = LinearRegression()\nlr.fit(LR_train[['time']],LR_train['Price'].values)","2962ce31":"test_predictions_model1         = lr.predict(LR_test[['time']])\nLR_test['forecast'] = test_predictions_model1\n\nplt.figure(figsize=(13,6))\nplt.plot( train['Price'], label='Train')\nplt.plot(test['Price'], label='Test')\nplt.plot(LR_test['forecast'], label='Regression On Time_Test Data')\nplt.legend(loc='best')\nplt.grid();","f0ee2497":"def mape(actual,pred):\n    return round((np.mean(abs(actual-pred)\/actual))*100,2)","aadf71d3":"mape_model1_test = mape(test['Price'].values,test_predictions_model1)\nprint(\"For RegressionOnTime forecast on the Test Data,  MAPE is %3.3f\" %(mape_model1_test),\"%\")","b6792a6e":"results = pd.DataFrame({'Test MAPE (%)': [mape_model1_test]},index=['RegressionOnTime'])\nresults","3ebd65f6":"Naive_train = train.copy()\nNaive_test = test.copy()","4be45111":"Naive_test['naive'] = np.asarray(train['Price'])[len(np.asarray(train['Price']))-1]\nNaive_test['naive'].head()","418c382b":"plt.figure(figsize=(12,8))\nplt.plot(Naive_train['Price'], label='Train')\nplt.plot(test['Price'], label='Test')\nplt.plot(Naive_test['naive'], label='Naive Forecast on Test Data')\nplt.legend(loc='best')\nplt.title(\"Naive Forecast\")\nplt.grid();","11e23291":"mape_model2_test = mape(test['Price'].values,Naive_test['naive'].values)\nprint(\"For Naive forecast on the Test Data,  MAPE is %3.3f\" %(mape_model2_test),\"%\")","c9ed26df":"resultsDf_2 = pd.DataFrame({'Test MAPE (%)': [mape_model2_test]},index=['NaiveModel'])\n\nresults = pd.concat([results, resultsDf_2])\nresults","80b173ab":"SimpleAvg_train = train.copy()\nSimpleAvg_test = test.copy()\nSimpleAvg_test['mean_forecast'] = train['Price'].mean()\nSimpleAvg_test.head()","ef383c82":"plt.figure(figsize=(12,8))\nplt.plot(SimpleAvg_train['Price'], label='Train')\nplt.plot(SimpleAvg_test['Price'], label='Test')\nplt.plot(SimpleAvg_test['mean_forecast'], label='Simple Average on Test Data')\nplt.legend(loc='best')\nplt.title(\"Simple Average Forecast\")\nplt.grid();","5099387c":"mape_model3_test = mape(test['Price'].values,SimpleAvg_test['mean_forecast'].values)\nprint(\"For Simple Average forecast on the Test Data,  MAPE is %3.3f\" %(mape_model3_test),\"%\")","fbab26b2":"resultsDf_3 = pd.DataFrame({'Test MAPE (%)': [mape_model3_test]},index=['SimpleAverageModel'])\n\nresults = pd.concat([results, resultsDf_3])\nresults","d5da5c47":"Mvg_Avg = df.copy()\nMvg_Avg['Trailing_2'] = Mvg_Avg['Price'].rolling(2).mean()\nMvg_Avg['Trailing_3'] = Mvg_Avg['Price'].rolling(3).mean()\nMvg_Avg['Trailing_5'] = Mvg_Avg['Price'].rolling(5).mean()\nMvg_Avg['Trailing_7'] = Mvg_Avg['Price'].rolling(7).mean()\nMvg_Avg.head()","951d1b04":"## Plotting on the whole data\n\nplt.figure(figsize=(16,8))\nplt.plot(Mvg_Avg['Price'], label='Train')\nplt.plot(Mvg_Avg['Trailing_2'],label='2 Point Moving Average')\nplt.plot(Mvg_Avg['Trailing_3'],label='3 Point Moving Average')\nplt.plot(Mvg_Avg['Trailing_5'],label = '5 Point Moving Average')\nplt.plot(Mvg_Avg['Trailing_7'],label = '7 Point Moving Average')\n\nplt.legend(loc = 'best')\nplt.grid();","694963ae":"#Creating train and test set \ntrailing_Mvg_Avg_train=Mvg_Avg[Mvg_Avg.index.year <= 2015] \ntrailing_Mvg_Avg_test=Mvg_Avg[Mvg_Avg.index.year > 2015]","87bdcf8f":"## Plotting on both the Training and Test data\n\nplt.figure(figsize=(16,8))\nplt.plot(trailing_Mvg_Avg_train['Price'], label='Train')\nplt.plot(trailing_Mvg_Avg_test['Price'], label='Test')\n\nplt.plot(trailing_Mvg_Avg_train['Trailing_2'],label='2 Point Trailing Moving Average on Training Set')\nplt.plot(trailing_Mvg_Avg_train['Trailing_3'],label='3 Point Trailing Moving Average on Training Set')\nplt.plot(trailing_Mvg_Avg_train['Trailing_5'],label = '5 Point Trailing Moving Average on Training Set')\nplt.plot(trailing_Mvg_Avg_train['Trailing_7'],label = '7 Point Trailing Moving Average on Training Set')\n\nplt.plot(trailing_Mvg_Avg_test['Trailing_2'], label='2 Point Trailing Moving Average on Test Set')\nplt.plot(trailing_Mvg_Avg_test['Trailing_3'], label='3 Point Trailing Moving Average on Test Set')\nplt.plot(trailing_Mvg_Avg_test['Trailing_5'],label = '5 Point Trailing Moving Average on Test Set')\nplt.plot(trailing_Mvg_Avg_test['Trailing_7'],label = '7 Point Trailing Moving Average on Test Set')\nplt.legend(loc = 'best')\nplt.grid();","4097a7be":"## Test Data - MAPE --> 2 point Trailing MA\n\nmape_model4_test_2 = mape(test['Price'].values,trailing_Mvg_Avg_test['Trailing_2'].values)\nprint(\"For 2 point Moving Average Model forecast on the Training Data,  MAPE is %3.3f\" %(mape_model4_test_2),\"%\")\n\n## Test Data - MAPE  --> 3 point Trailing MA\n\nmape_model4_test_3 = mape(test['Price'].values,trailing_Mvg_Avg_test['Trailing_3'].values)\nprint(\"For 3 point Moving Average Model forecast on the Training Data,  MAPE is %3.3f\" %(mape_model4_test_3),\"%\")\n\n## Test Data - MAPE --> 5 point Trailing MA\n\nmape_model4_test_5 = mape(test['Price'].values,trailing_Mvg_Avg_test['Trailing_5'].values)\nprint(\"For 5 point Moving Average Model forecast on the Training Data,  MAPE is %3.3f\" %(mape_model4_test_5),\"%\")\n\n## Test Data - MAPE  --> 7 point Trailing MA\n\nmape_model4_test_7 = mape(test['Price'].values,trailing_Mvg_Avg_test['Trailing_7'].values)\nprint(\"For 7 point Moving Average Model forecast on the Training Data,  MAPE is %3.3f \" %(mape_model4_test_7),\"%\")","9585d1cb":"resultsDf_4 = pd.DataFrame({'Test MAPE (%)': [mape_model4_test_2,mape_model4_test_3\n                                          ,mape_model4_test_5,mape_model4_test_7]}\n                           ,index=['2pointTrailingMovingAverage','3pointTrailingMovingAverage'\n                                   ,'5pointTrailingMovingAverage','7pointTrailingMovingAverage'])\n\nresults = pd.concat([results, resultsDf_4])\nresults","8b644d8e":"SES_train = train.copy()\nSES_test = test.copy()\nmodel_SES = SimpleExpSmoothing(SES_train['Price'])\nmodel_SES_autofit = model_SES.fit(optimized=True)","3c4f35b4":"model_SES_autofit.params","86f5298d":"SES_test['predict'] = model_SES_autofit.forecast(steps=len(test))\nSES_test.head()","4824ec79":"plt.figure(figsize=(16,8))\nplt.plot(SES_train['Price'], label='Train')\nplt.plot(SES_test['Price'], label='Test')\n\nplt.plot(SES_test['predict'], label='Alpha =0.995 SES predictions on Test Set')\n\nplt.legend(loc='best')\nplt.grid()\nplt.title('Alpha =0.995 Predictions');","fbf3c68f":"## Test Data\n\nmape_model5_test_1 = mape(SES_test['Price'].values,SES_test['predict'].values)\nprint(\"For Alpha =0.995 SES Model forecast on the Test Data, MAPE is %3.3f\" %(mape_model5_test_1),\"%\")","7e4f2afd":"resultsDf_5 = pd.DataFrame({'Test MAPE (%)': [mape_model5_test_1]},index=['Alpha=0.995,SimpleExponentialSmoothing'])\n\nresults = pd.concat([results, resultsDf_5])\nresults","d9e5e5a6":"\nresultsDf_6 = pd.DataFrame({'Alpha Values':[],'Train MAPE':[],'Test MAPE': []})\n\nfor i in np.arange(0.3,1,0.1):\n    model_SES_alpha_i = model_SES.fit(smoothing_level=i,optimized=False,use_brute=True)\n    SES_train['predict',i] = model_SES_alpha_i.fittedvalues\n    SES_test['predict',i] = model_SES_alpha_i.forecast(steps=55)\n    \n    mape_model5_train_i = mape(SES_train['Price'].values,SES_train['predict',i].values)\n    \n    mape_model5_test_i = mape(SES_test['Price'].values,SES_test['predict',i].values)\n    \n    resultsDf_6 = resultsDf_6.append({'Alpha Values':i,'Train MAPE':mape_model5_train_i \n                                      ,'Test MAPE':mape_model5_test_i}, ignore_index=True)","a5f2dde2":"resultsDf_6.sort_values(by=['Test MAPE'],ascending=True)","ead52568":"## Plotting on both the Training and Test data\n\nplt.figure(figsize=(18,9))\nplt.plot(SES_train['Price'], label='Train')\nplt.plot(SES_test['Price'], label='Test')\n\nplt.plot(SES_test['predict'], label='Alpha =1 SES predictions on Test Set')\n\nplt.plot(SES_test['predict', 0.3], label='Alpha =0.3 SES predictions on Test Set')\n\n\n\nplt.legend(loc='best')\nplt.grid();","b8f89a06":"resultsDf_6_1 = pd.DataFrame({'Test MAPE (%)': [resultsDf_6.sort_values(by=['Test MAPE'],ascending=True).values[0][2]]}\n                           ,index=['Alpha=0.3,SimpleExponentialSmoothing'])\n\nresults = pd.concat([results, resultsDf_6_1])\nresults","4e09704f":"Inference\n\nThe Average gold price in last 70 years is $416.56\n\nOnly 25% of the time, the gold price is above $447.07\n\nHighest Gold price ever touched is $1840.81","db23e032":"Analysis in Coefficient of variation\n1.The coefficient of variation (CV) is a statistical measure of the relative dispersion of data points in a data series around the mean.\n2.In finance, the coefficient of variation allows investors to determine how much volatility, or risk, is assumed in comparison to the amount of return expected from investments.\n3.The lower the ratio of the standard deviation to mean return, the better risk-return trade-off.","30ef4eea":"Inference\n\nThe CV value reached its highest in year 1978 near to 25%, which could have made the asset as highly risky\nBut in 2020, the CV value is closer to 5%, which makes the asset viable for good investment"}}