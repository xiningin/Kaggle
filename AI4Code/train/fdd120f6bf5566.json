{"cell_type":{"6c29c9b1":"code","c247f8f2":"code","864f2d8f":"code","494cd019":"code","4c880506":"code","5f621f12":"code","b5429b8d":"code","74934c2a":"code","71ce979a":"code","ba25360a":"code","21c0f5f7":"code","a22bc942":"code","0878f840":"code","f4702262":"code","a6077d1f":"code","feeceb8b":"code","f3e43c55":"markdown","d5d04831":"markdown","10ba0c5a":"markdown"},"source":{"6c29c9b1":"# !conda install -c conda-forge imagehash --yes","c247f8f2":"%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport glob\nimport itertools\nimport collections\n\nfrom PIL import Image\nimport cv2\nfrom tqdm import tqdm_notebook as tqdm\nimport pandas as pd\nimport numpy as np\nimport torch\nimport imagehash\n\nimport matplotlib.pyplot as plt\n\n","864f2d8f":"def run():\n\n    funcs = [\n        imagehash.average_hash,\n        imagehash.phash,\n        imagehash.dhash,\n        imagehash.whash,\n        #lambda x: imagehash.whash(x, mode='db4'),\n    ]\n\n    SOPInstanceUIDs = []\n    hashes = []\n    for path in tqdm(glob.glob('..\/input\/siim-covid19-resized-to-512px-png\/*\/*.png')):\n\n        image = Image.open(path)\n        imageid = path.split('\/')[-1].split('.')[0]\n\n        SOPInstanceUIDs.append(imageid)\n        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))\n\n    return SOPInstanceUIDs, np.array(hashes)\n\n%time SOPInstanceUIDs, hashes_all = run()\n\n","494cd019":"hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()","4c880506":"%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()\/256 for i in range(hashes_all.shape[0])])\n","5f621f12":"indices1 = np.where(sims > 0.99)\nindices2 = np.where(indices1[0] != indices1[1])\nSOPInstanceUID1 = [SOPInstanceUIDs[i] for i in indices1[0][indices2]]\nSOPInstanceUID2 = [SOPInstanceUIDs[i] for i in indices1[1][indices2]]\ndups = {tuple(sorted([SOPInstanceUID1,SOPInstanceUID2])):True for SOPInstanceUID1, SOPInstanceUID2 in zip(SOPInstanceUID1, SOPInstanceUID2)}\nprint('found %d duplicates' % len(dups))","b5429b8d":"dups","74934c2a":"train = pd.read_csv('..\/input\/read-dicom-metadate\/alldicomtrain.csv')\ntest = pd.read_csv('..\/input\/read-dicom-metadate\/alldicomtest.csv')\ntrainbox = pd.read_csv('..\/input\/siim-covid19-detection\/train_image_level.csv')\ntrainbox['SOPInstanceUID']=trainbox.id.str[:-6]\ntrain.loc[:,'Category'] = 'train'\ntrainmerge=pd.merge(train, trainbox,on='SOPInstanceUID')\n\ntest.loc[:,'Category'] = 'test'\ntest.loc[:,'boxes'] = np.nan\n\ndf1 = pd.concat([trainmerge, test], sort=False)\n","71ce979a":"df=df1[['SOPInstanceUID','PatientName','Category', 'PatientID', 'PatientSex','ImageType', 'boxes','SeriesInstanceUID', 'StudyID', 'SeriesNumber', 'InstanceNumber']]","ba25360a":"# df1[['SOPInstanceUID','PatientName', 'PatientID', 'PatientSex','ImageType','fname', 'boxes','SeriesInstanceUID', 'StudyID', 'SeriesNumber', 'InstanceNumber']]","21c0f5f7":"# testbox['SOPInstanceUID']=testbox.id.str[:-7]","a22bc942":"df.columns","0878f840":"detail = {SOPInstance:df[df.SOPInstanceUID == SOPInstance] for SOPInstance in itertools.chain.from_iterable(list(dups))}","f4702262":"\n\ntype(detail)","a6077d1f":"def show(row1, row2):\n    try:\n        print('Image: %s \/ %s' % (row1.SOPInstanceUID.iloc[-1], row2.SOPInstanceUID.iloc[-1]))\n        print('boxes: %s \/ %s' % (row1.boxes.iloc[-1],row2.boxes.iloc[-1]))\n        print('Category: %s \/ %s' % (row1.Category.iloc[-1], row2.Category.iloc[-1]))\n#         print('Box: %s \/ %s' % (row1.boxes.iloc[-1], row2.boxes.iloc[-1]))\n        #     print('Breed1: %d \/ %d' % (row1.Breed1, row2.Breed1))\n        #     print('Age: %d \/ %d' % (row1.Age, row2.Age))\n        #     print('RescuerID:\\n%s\\n%s' % (row1.RescuerID, row2.RescuerID))\n    \n\n    \n        image1 = cv2.imread(f'..\/input\/siim-covid19-resized-to-512px-png\/{row1.Category.iloc[-1]}\/{row1.SOPInstanceUID.iloc[-1]}.png' )\n        image2 = cv2.imread(f'..\/input\/siim-covid19-resized-to-512px-png\/{row2.Category.iloc[-1]}\/{row2.SOPInstanceUID.iloc[-1]}.png' )\n        image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n        image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n    \n    \n        fig = plt.figure(figsize=(10, 20))\n        fig.add_subplot(1,2,1)\n        plt.imshow(image1,cmap='gray')\n        fig.add_subplot(1,2, 2)\n        plt.imshow(image2,cmap='gray')\n        plt.show()\n    except:\n        print('SOPInstanceUID.iloc[-1]')","feeceb8b":"for SOPInstanceUID1, SOPInstanceUID2 in sorted(list(dups)):\n    \n        row1 = detail[SOPInstanceUID1]\n#         \n        row2 = detail[SOPInstanceUID2]\n#         try:\n#             if row1.Category.iloc[-1] != row2.Category.iloc[-1]:\n        show(row1, row2)\n#         except:\n#             print(f'error {SOPInstanceUID1}-{SOPInstanceUID2}')","f3e43c55":"# Find Duplicates\nModified from https:\/\/www.kaggle.com\/appian\/let-s-find-out-duplicate-images-with-imagehash","d5d04831":"\nCalc similalities between all image pairs\n\nI use imagehash library to calculate hash value of image. https:\/\/github.com\/JohannesBuchner\/imagehash\n\nThere are several hash functions provided and I used 4 of them and combined the calculated hash values.\n\n    average hashing (aHash)\n    perception hashing (pHash)\n    difference hashing (dHash)\n    wavelet hashing (wHash)\n\nI used profile image(1st image) of pet images to calculate hash values.\n","10ba0c5a":"\n\nCalculate similarities among all image pairs. Divide the value by 256 to normalize (0-1).\n"}}