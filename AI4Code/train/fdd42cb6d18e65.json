{"cell_type":{"91bbab19":"code","9092ee6b":"code","5eec1093":"code","55fe5269":"code","3aa84b66":"code","abb1ce27":"code","7bc2427b":"code","8b1a4d1f":"code","d1f48af8":"code","cdc1e1d9":"code","927633f9":"code","c19b084c":"code","f2cb6687":"code","dc9b6c9e":"code","cd1bac74":"markdown","cb92450b":"markdown","ef22c59a":"markdown","03f30fb4":"markdown","613f2d7e":"markdown","390af70e":"markdown"},"source":{"91bbab19":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom warnings import filterwarnings as fw\nfw('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","9092ee6b":"train = pd.read_csv('..\/input\/drugsComTrain_raw.csv')\ntest = pd.read_csv('..\/input\/drugsComTest_raw.csv')","5eec1093":"train.head()","55fe5269":"top_30_drugs = train.drugName.value_counts()[:30]\nplt.figure(figsize = (15,7))\ntop_30_drugs.plot(kind = 'bar');\nplt.title('Top 30 Drugs by Count',fontsize = 20);","3aa84b66":"top_30_problems = train.condition.value_counts()[:30]\nplt.figure(figsize = (15,7))\ntop_30_problems.plot(kind = 'bar');\nplt.title('Top 30 Problems',fontsize = 20);","abb1ce27":"import string\ntrain['review_clean']=train['review'].str.replace('[{}]'.format(string.punctuation), '')\ntrain.head()","7bc2427b":"train = train.fillna({'review':''})  # fill in N\/A's in the review column","8b1a4d1f":"plt.figure(figsize = (15,7))\ntrain.rating.value_counts().plot(kind = 'bar');\nplt.xlabel('Ratings',fontsize = 15);\nplt.title('Ratings by count',fontsize = 18);","d1f48af8":"train['sentiment'] = train['rating'].apply(lambda rating : +1 if rating > 5 else -1)\ntrain.head()","cdc1e1d9":"from sklearn.model_selection import train_test_split\ntrain_data,test_data = train_test_split(train,test_size = 0.20)\nprint('Size of train_data is :', train_data.shape)\nprint('Size of test_data is :', test_data.shape)","927633f9":"import gc\nfrom sklearn.feature_extraction.text import HashingVectorizer\n\nvectorizer = HashingVectorizer()\n\ntrain_matrix = vectorizer.transform(train_data['review_clean'].values.astype('U'))\ntest_matrix = vectorizer.transform(test_data['review_clean'].values.astype('U'))\n\ngc.collect()","c19b084c":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier()\nrf = clf.fit(train_matrix,train_data['sentiment'])","f2cb6687":"y_pred = rf.predict(test_matrix)\nfrom sklearn.metrics import f1_score\nf1_score(y_pred,test_data.sentiment)","dc9b6c9e":"from sklearn import tree\nimport graphviz\n\n\nclf = tree.DecisionTreeClassifier() # init the tree\nclf = clf.fit(train_matrix, train_data.sentiment) # train the tree\n# export the learned decision tree\ndot_data = tree.export_graphviz(clf,\n                         filled=True, rounded=True,\n                         special_characters=True)\ngraph = graphviz.Source(dot_data)\ngraph.render(\"sentiment\") ","cd1bac74":"## Train a sentiment classifier with logistic regression.","cb92450b":"### Split into training and test sets\n#### Let's perform a train\/test split with 80% of the data in the training set and 20% of the data in the test set. \n![](https:\/\/cdn-images-1.medium.com\/max\/1600\/1*-8_kogvwmL1H6ooN1A1tsQ.png)","ef22c59a":"#### Here, we can see the problems faced by people by count.  Birth Control followed by Deprerssion , anxiety, pain and Bipolar disorder are the top problems faced by people\n","03f30fb4":"Precision and recall In statistical analysis of binary classification, the F1 score (also F-score or F-measure) is a measure of a test's accuracy. It considers both the precision p and the recall r of the test to compute the score: p is the number of correct positive results divided by the number of all positive results returned by the classifier, and r is the number of correct positive results divided by the number of all relevant samples (all samples that should have been identified as positive). The F1 score is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.\n\nThe traditional F-measure or balanced F-score (F1 score) is the harmonic mean of precision and recall:\n![](https:\/\/wikimedia.org\/api\/rest_v1\/media\/math\/render\/svg\/057ffc6b4fa80dc1c0e1f2f1f6b598c38cdd7c23)","613f2d7e":"#### Build the word count vector for each review\nWe will now compute the word count for each word that appears in the reviews. A vector consisting of word counts is often referred to as bag-of-word features. Since most words occur in only a few reviews, word count vectors are sparse. For this reason, scikit-learn and many other tools use sparse matrices to store a collection of word count vectors. Refer to appropriate manuals to produce sparse word count vectors. General steps for extracting word count vectors are as follows:\n\nLearn a vocabulary (set of all words) from the training data. Only the words that show up in the training data will be considered for feature extraction. Compute the occurrences of the words in each review and collect them into a row vector. Build a sparse matrix where each row is the word count vector for the corresponding review. Call this matrix train_matrix. Using the same mapping between words and columns, convert the test data into a sparse matrix test_matrix. The following cell uses CountVectorizer in scikit-learn. Notice the token_pattern argument in the constructor.","390af70e":"#### We'll consider ratings more than 5 as positive and less than or equal to 5 as negative.\n#### For the sentiment column, we use +1 for the positive class label and -1 for the negative class label. A good way is to create an anonymous function that converts a rating into a class label and then apply that function to every element in the rating column."}}