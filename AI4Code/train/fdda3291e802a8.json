{"cell_type":{"0955182d":"code","4762c626":"code","7060cfb3":"code","0a8139f6":"code","5210e9c2":"code","848d3f1c":"code","3d7fb99c":"code","7db0de31":"code","c839ac99":"code","f37dfab4":"code","5d0b0e97":"code","48268387":"code","afbd5a24":"code","ad4036a3":"code","c24df609":"code","3bd06987":"code","926ca027":"code","64a2b5ba":"code","f0f220a6":"code","4f58fed1":"code","94ff60f2":"code","29093d74":"code","cfb34bc9":"code","3839213d":"code","621bd9d6":"code","0a333efc":"code","12531a50":"code","773b8030":"code","2a3873ac":"code","3e2a9548":"code","15c0227e":"code","e2fb27a9":"code","b07d5b26":"code","534f70af":"code","9e3f2477":"code","399824a5":"code","c78194ad":"code","99966a98":"code","8847ad40":"code","cdad922f":"code","56a75801":"code","12b0362c":"code","aa21d3bd":"code","62e9098d":"code","b8ff978a":"code","5f52ce3e":"code","0efff643":"code","a4452b5a":"code","079e4358":"code","1e559cb2":"code","74e538a3":"code","472921d7":"code","c221aa3a":"code","0afb57de":"code","349f1d5c":"code","993f5cce":"code","49aa7c55":"code","65cde1ba":"code","bc22b3ad":"code","08868649":"code","93746fd2":"code","1a600fcc":"markdown","ecf4e670":"markdown","f017ebb3":"markdown","19d027ab":"markdown","3286ac94":"markdown","7acd0cb7":"markdown","590064b8":"markdown","f7c8b34d":"markdown","459f7c3c":"markdown","2046399f":"markdown","1cb2f8b7":"markdown","1de3f40d":"markdown","997c4080":"markdown","81209bf0":"markdown","73bcb74b":"markdown","27a8acf8":"markdown","f8083b77":"markdown","354ae8ea":"markdown","1e2d3d5a":"markdown","385bfcdc":"markdown","6909c2f1":"markdown","ac61176b":"markdown","4d7b016d":"markdown","7e58ed7f":"markdown","3e320a8b":"markdown","3d8f343f":"markdown","021839a2":"markdown","1000a847":"markdown","7f4cf8e9":"markdown","2a2dac4a":"markdown","9e549f63":"markdown","bcd03687":"markdown","fed8320e":"markdown","9bfa8451":"markdown","169b600a":"markdown","ce909d3d":"markdown"},"source":{"0955182d":"# [Import packages here]\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n    \nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n","4762c626":"# First import just the trainset for inspection\ntrainset = torchvision.datasets.CIFAR10(root='.\/data', train=True, # 50,000 images\n                                       download=True)","7060cfb3":"# Are the image intensity ranges normalized?\n\n# Sample the first picture of the CIFAR10 trainset as a representation of the whole set.\nnp_im = np.array(trainset[0][0]) \nmin_val = np.amin(np_im)\nmax_val = np.amax(np_im)\n\nprint('The data type of the trainset image values is {}.'.format(type(min_val)))\nprint('The intensity range is [{},{}].'.format(min_val, max_val))\nif max_val != 1.0:\n    print(\"We should normalize the dataset!\")\nelse:\n    print(\"The trainset seems to be normalized!\")","0a8139f6":"# Let's load both the train and test sets and normalize the intensity ranges using ToTensor() and Normalize().\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = torchvision.datasets.CIFAR10(root='.\/data', train=True, # 50,000 images\n                                       download=True, transform=transform)\n\ntestset = torchvision.datasets.CIFAR10(root='.\/data', train=False, # 10,000 images\n                                       download=True, transform=transform)\n\nnp_im = np.array(trainset[0][0]) \nmin_val = np.amin(np_im)\nmax_val = np.amax(np_im)\n\nprint('\\nThe data type of the trainset image values is {}.'.format(type(min_val)))\nprint('The intensity range is [{},{}].'.format(min_val, max_val))\nif min_val != -1.0 and max_val != 1.0:\n    print(\"We should normalize it! \\n\")\nelse:\n    print(\"The trainset is normalized! \\n\")\n    \nprint('The data type of the testset image values is {}.'.format(type(min_val)))\nprint('The intensity range is [{},{}].'.format(min_val, max_val))\nif min_val != -1 and max_val != 1.0:\n    print(\"We should normalize it!\")\nelse:\n    print(\"The testset is normalized!\")","5210e9c2":"# Pull samples from each class in trainset and testset, with labels\n# and convert to numpy for better handling downstream.\n\nN = 10 # mumber of classes\n\ntrain_ims = [[None, None]] * N\nfor (x,y) in trainset:\n     if train_ims[y][0] is None:\n        train_ims[y] = (x.numpy(),y)  # image tensors to arrays, label as int\n\n# repeat for testset\ntest_ims = [[None, None]] * N\nfor (x,y) in testset:\n     if test_ims[y][0] is None:\n        test_ims[y] = (x.numpy(),y)","848d3f1c":"# Create a function that returns a histogram of intensities for each color channel.\ndef GetHistograms(img):\n    histograms = []\n    for i in range(3):\n        hist, edge = np.histogram(img[i], bins=100, range=[0.0,1.0])\n        edge = (edge[:-1] + edge[1:])\/2\n        histograms.append((edge,hist))\n        \n    return histograms\n\ncolors = ('Red','Green','Blue') # color channel label strings for plotting","3d7fb99c":"# Create a function to display images and histograms in a grid.\n\ndef ImsAndHists(trainset,testset):\n\n    fig,ax = plt.subplots(nrows = N, ncols = 4, figsize=(20,20))\n\n    for index, im in enumerate(trainset):\n\n        img = im[0]  \n        img = img \/ 2 + 0.5 # unnormalize\n\n        ax[index][0].imshow(np.transpose(img, (1, 2, 0)))\n        ax[index][0].title.set_text(classes[im[1]]+' (trainset)')\n        ax[index][0].axis('off')\n\n        histograms = GetHistograms(img)\n        for i in range(3):\n            ax[index][1].plot(histograms[i][0], histograms[i][1], c=colors[i], label='Channel {0}'.format(colors[i]))\n\n        ax[index][1].title.set_text(classes[im[1]]+' histogram (trainset)')\n        ax[index][1].set_xlabel('Intensity')\n        ax[index][1].set_ylabel('Abundance')\n        ax[index][1].legend()\n        plt.tight_layout()\n\n\n    for index, im in enumerate(testset):\n\n        img = im[0]  \n        img = img \/ 2 + 0.5 # unnormalize\n\n        ax[index][2].imshow(np.transpose(img, (1, 2, 0)))\n        ax[index][2].title.set_text(classes[im[1]]+' (testset)')\n        ax[index][2].axis('off')\n\n        histograms = GetHistograms(img)\n        for i in range(3):\n            ax[index][3].plot(histograms[i][0], histograms[i][1], c=colors[i], label='Channel {0}'.format(colors[i]))\n\n        ax[index][3].title.set_text(classes[im[1]]+' histogram (testset)')\n        ax[index][3].set_xlabel('Intensity')\n        ax[index][3].set_ylabel('Abundance')\n        ax[index][3].legend()\n        plt.tight_layout()\n\n    plt.show()\n\nclasses = ('airplane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck') # image label strings for plot titles","7db0de31":"ImsAndHists(train_ims,test_ims)","c839ac99":"# Obtain just the targets from the trainset\ntrain_targets = trainset.targets","f37dfab4":"# Obtain indices to create samplers\ntrain_idx, valid_idx = train_test_split(\nnp.arange(len(train_targets)),\ntest_size=0.2,\nshuffle=True,\nstratify=train_targets)","5d0b0e97":"# Create samplers\ntrain_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\nval_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)","48268387":"# Create a DataLoader for each dataset\ntrainloader = DataLoader(dataset=trainset, \n                         shuffle=False, batch_size=32, \n                         sampler=train_sampler)\n\nvalloader = DataLoader(dataset=trainset, \n                        shuffle=False, batch_size=32, \n                        sampler=val_sampler)\n\ntestloader = DataLoader(dataset=testset, \n                         shuffle=False, batch_size=32)","afbd5a24":"# Define a function to obtain a list of targets from the DataLoader\ndef TargetsList(set_y,dataloader):\n    for _, target in dataloader:\n        for y in target:\n            set_y.append(target[y].item()) # index the specific sample","ad4036a3":"# Create lists of targets from our dataloaders\ntrain_y=[]\nTargetsList(train_y,trainloader)\n\nval_y=[]\nTargetsList(val_y,valloader)\n\ntest_y = testset.targets # already as int type","c24df609":"# Create a stacked bar plot to display the distribution of samples between the datasets\n\n(_, train_count) = np.unique(train_y, return_counts=True)\n(_, val_count) = np.unique(val_y, return_counts=True)\n(_, test_count) = np.unique(test_y, return_counts=True)\n\nplt.figure(figsize=(12,8))\nplt.title('CIFAR10 Data Distribution')\nplt.xticks(range(N), labels=range(N))\nplt.xlabel('Class')\nplt.ylabel('Number of samples')\nplt.bar(range(N), train_count, label='Train',tick_label=classes)\nplt.bar(range(N), val_count, label='Validation')\nplt.bar(range(N), test_count, label='Test',bottom=train_count)\nplt.legend()\nplt.savefig('DataDistribution.png')\nplt.show()","3bd06987":"# Implement the LeNet architecture\n## The dimensions of our inputs are 32x32x3\n## By the kernel formula, the dimensions of conv1 imply that \n## we will need a 5x5 kernel\n\nclass Net(nn.Module):\n    def __init__(self):\n        # 3 input image channels, 6 output channels, 5x5 square conv kernel\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        # Max pooling over a (2,2) window\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()\n\n# Assuming GPU is available, move the model to GPU.\nnet.cuda()\n\nprint(net)","926ca027":"# Define our Adam optimizer\noptimizer = Adam(net.parameters(), lr=0.0001)","64a2b5ba":"# Create an instance of the MSE Loss Function\ncriterion = nn.MSELoss()","f0f220a6":"# Create a folder to save our trained model at the end of each epoch.\n!mkdir saved_models","4f58fed1":"EPOCHS = 50\n\ntrain_epoch_loss = []\nvalidation_epoch_loss = []\n\nfor epoch in range(EPOCHS):\n    train_loss = []\n    validation_loss = []\n\n    for batch_index, (train_image, train_label) in enumerate(trainloader):\n        #######################################################\n        ###################### Validation #####################\n        #######################################################\n    \n        # Assume GPU is available\n        net.train()\n\n        train_ohe = F.one_hot(train_label, num_classes=N)\n        train_ohe = train_ohe.type(torch.FloatTensor)\n        train_label_predicted = net(train_image.cuda())\n\n        # compute the loss\n        loss = criterion(train_label_predicted, train_ohe.cuda())\n        train_loss.append(loss.cpu().data.item())\n        \n        # reset the gradient \n        optimizer.zero_grad()\n        # backpropagate the loss\n        loss.backward()\n        # update the parameters\n        optimizer.step()\n\n        #######################################################\n        ###################### Validation #####################\n        #######################################################\n        # Set the model to evaluation mode so that parameters are fixed.\n        net.eval()\n        \n    for batch_index, (val_image, val_label) in enumerate(valloader):\n        \n        val_ohe = F.one_hot(val_label, num_classes=N)\n        val_ohe = val_ohe.type(torch.FloatTensor)\n        validation_label_predicted = net(val_image.cuda())\n\n        loss = criterion(validation_label_predicted, val_ohe.cuda())\n        validation_loss.append(loss.cpu().data.item())\n\n    train_epoch_loss.append(np.mean(train_loss))\n    validation_epoch_loss.append(np.mean(validation_loss))\n    \n    # save models\n    torch.save(net.state_dict(), '.\/saved_models\/checkpoint_epoch_%s.pth' % (epoch))\n\n    print(\"Epoch: {} | train_loss: {} | validation_loss: {}\".format(epoch, train_epoch_loss[-1], validation_epoch_loss[-1]))","94ff60f2":"# Draw the learning curve\nplt.figure(figsize = (12, 8))\nplt.title('Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.plot(train_epoch_loss, '-o', label = 'training loss', markersize = 3)\nplt.plot(validation_epoch_loss, '-o', label = 'validation loss', markersize = 3)\nplt.legend(loc = 'upper right');","29093d74":"# Display the best epoch\nbest_epoch = np.argmin(validation_epoch_loss)\nprint('Best epoch: ', best_epoch)","cfb34bc9":"# Load the best model\nstate_dict = torch.load('.\/saved_models\/checkpoint_epoch_%s.pth' % (best_epoch))\nprint(state_dict.keys())\nnet.load_state_dict(state_dict)","3839213d":"# Evaluate the model on the test set\n\nnet.eval()\ntest_label_predicted_all = []\n\nfor batch_index, (test_image, test_label) in enumerate(testloader):\n        \n    test_label_predicted_one_hot = net(test_image.cuda())\n    test_label_predicted_probability, test_label_predicted_index = torch.max(test_label_predicted_one_hot.data, 1)\n    \n    for current_prediction in test_label_predicted_index:\n        test_label_predicted_all.append(current_prediction.detach().cpu().numpy().item())\n\ntest_label_predicted = test_label_predicted_all","621bd9d6":"# Validate that the length of the predicted labels matches the ground truth (10,000)\nlen(test_label_predicted)","0a333efc":"# Gauge the accuracy of the model\n\naccuracy = accuracy_score(test_y, test_label_predicted)\n\nprint(\"Accuracy:\", accuracy * 100, \"%\")","12531a50":"# Display a confusion matrix to better understand the results\nCM = confusion_matrix(test_y, test_label_predicted)\n\nplt.figure(figsize = (12,10))\nsns.heatmap(CM, annot = True, annot_kws = {\"size\": 10})\nplt.ylim([0, 10]);\nplt.xticks(range(len(classes)), classes);\nplt.yticks(range(len(classes)), classes);\nplt.ylabel('True labels');\nplt.xlabel('Predicted labels');","773b8030":"# Present a classification report\nprint(classification_report(test_y, test_label_predicted,target_names=classes))","2a3873ac":"# Create list of five random indices from the length of testet (10,000)\n# (The list is re-randomized on every run allowing for ability to view new samples)\nrand_test_samples = np.random.randint(0,10000,(1,5))\nrand_test_samples = rand_test_samples.tolist()\nrand_test_samples = [item for sublist in rand_test_samples for item in sublist]","3e2a9548":"# Create list of five random samples from testset\nrand_test_ims = [[None, None]] * 5\nfor i,r in enumerate(rand_test_samples):\n    rand_test_ims[i] = testset[r]","15c0227e":"# Plot five random samples from the testset with actual label and predicted label\nfig = plt.figure(figsize=(12, 4))\nfig.suptitle('Five random samples from the test set and their estimated labels\\nActual lable -> Estimated label')\n\nfor index, im in enumerate(rand_test_ims):\n\n    img = im[0]  \n    img = img \/ 2 + 0.5 # unnormalize\n\n    fig.add_subplot(1,5,index+1)\n    plt.imshow(np.transpose(img, (1, 2, 0)))\n    plt.title('%s -> %s' % (classes[test_y[rand_test_samples[index]]], classes[test_label_predicted[rand_test_samples[index]]]))\n    plt.axis('off')\n\n    plt.tight_layout()\n\nplt.show()","e2fb27a9":"# Implement the LeNet architecture again for CE Loss\n## The dimensions of our inputs are 32x32x3\n## By the kernel formula, the dimensions of conv1 imply that \n## we will need a 5x5 kernel\n\nclass NetCE(nn.Module):\n    def __init__(self):\n        # 3 input image channels, 6 output channels, 5x5 square conv kernel\n        super(NetCE, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        # Max pooling over a (2,2) window\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnetCE = NetCE()\n\n# Assuming GPU is available, move the model to GPU.\nnetCE.cuda()\n\nprint(netCE)","b07d5b26":"# Define our Adam optimizer\noptimizer = Adam(netCE.parameters(), lr=0.005)\n\n# Create an instance of the MSE Loss Function\ncriterion = nn.CrossEntropyLoss()","534f70af":"# Create new directory for saving models trained with CE Loss \n!mkdir saved_models_CE","9e3f2477":"EPOCHS = 50\n\ntrain_epoch_loss = []\nvalidation_epoch_loss = []\n\nfor epoch in range(EPOCHS):\n    train_loss = []\n    validation_loss = []\n\n    for batch_index, (train_image, train_label) in enumerate(trainloader):\n        #######################################################\n        ###################### Validation #####################\n        #######################################################\n    \n        # Assume GPU is available\n        netCE.train()\n\n        train_label_predicted = netCE(train_image.cuda())\n\n        # compute the loss\n        loss = criterion(train_label_predicted, train_label.cuda())\n        train_loss.append(loss.cpu().data.item())\n        \n        # reset the gradient \n        optimizer.zero_grad()\n        # backpropagate the loss\n        loss.backward()\n        # update the parameters\n        optimizer.step()\n\n        #######################################################\n        ###################### Validation #####################\n        #######################################################\n        # Set the model to evaluation mode so that parameters are fixed.\n        netCE.eval()\n        \n    for batch_index, (val_image, val_label) in enumerate(valloader):\n        \n        validation_label_predicted = netCE(val_image.cuda())\n\n        loss = criterion(validation_label_predicted, val_label.cuda())\n        validation_loss.append(loss.cpu().data.item())\n\n    train_epoch_loss.append(np.mean(train_loss))\n    validation_epoch_loss.append(np.mean(validation_loss))\n    \n    # save models\n    torch.save(netCE.state_dict(), '.\/saved_models_CE\/checkpoint_epoch_%s.pth' % (epoch))\n\n    print(\"Epoch: {} | train_loss: {} | validation_loss: {}\".format(epoch, train_epoch_loss[-1], validation_epoch_loss[-1]))","399824a5":"# Draw the learning curve\nplt.figure(figsize = (12, 8))\nplt.title('Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.plot(train_epoch_loss, '-o', label = 'training loss', markersize = 3)\nplt.plot(validation_epoch_loss, '-o', label = 'validation loss', markersize = 3)\nplt.legend(loc = 'upper right');","c78194ad":"# Display the best epoch\nbest_epoch = np.argmin(validation_epoch_loss)\nprint('Best epoch: ', best_epoch)","99966a98":"# Load the best model\nstate_dict = torch.load('.\/saved_models_CE\/checkpoint_epoch_%s.pth' % (best_epoch))\nprint(state_dict.keys())\nnet.load_state_dict(state_dict)","8847ad40":"# Evaluate the model on the test set\n\nnetCE.eval()\ntest_label_predicted_all = []\n\nfor batch_index, (test_image, test_label) in enumerate(testloader):\n        \n    test_label_predicted_one_hot = netCE(test_image.cuda())\n    test_label_predicted_probability, test_label_predicted_index = torch.max(test_label_predicted_one_hot.data, 1)\n    \n    for current_prediction in test_label_predicted_index:\n        test_label_predicted_all.append(current_prediction.detach().cpu().numpy().item())\n\ntest_label_predicted = test_label_predicted_all","cdad922f":"# Validate that the length of the predicted labels matches the ground truth (10,000)\nlen(test_label_predicted)","56a75801":"# Gauge the accuracy of the model\n\naccuracy = accuracy_score(test_y, test_label_predicted)\n\nprint(\"Accuracy:\", accuracy * 100, \"%\")","12b0362c":"# Display a confusion matrix to better understand the results\nCM = confusion_matrix(test_y, test_label_predicted)\n\nplt.figure(figsize = (12,10))\nsns.heatmap(CM, annot = True, annot_kws = {\"size\": 10})\nplt.ylim([0, 10]);\nplt.xticks(range(len(classes)), classes);\nplt.yticks(range(len(classes)), classes);\nplt.ylabel('True labels');\nplt.xlabel('Predicted labels');","aa21d3bd":"# Present a classification report\nprint(classification_report(test_y, test_label_predicted,target_names=classes))","62e9098d":"# Create list of five random indices from the length of testet (10,000)\nrand_test_samples = np.random.randint(0,10000,(1,5))\nrand_test_samples = rand_test_samples.tolist()\nrand_test_samples = [item for sublist in rand_test_samples for item in sublist]","b8ff978a":"# Create list of five random samples from testset\nrand_test_ims = [[None, None]] * 5\nfor i,r in enumerate(rand_test_samples):\n    rand_test_ims[i] = testset[r]","5f52ce3e":"# Plot five random samples from the testset with actual label and predicted label\n# (The list is re-randomized on every run allowing for ability to view new samples)\nfig = plt.figure(figsize=(12, 4))\nfig.suptitle('Five random samples from the test set and their estimated labels\\nActual lable -> Estimated label')\n\nfor index, im in enumerate(rand_test_ims):\n\n    img = im[0]  \n    img = img \/ 2 + 0.5 # unnormalize\n\n    fig.add_subplot(1,5,index+1)\n    plt.imshow(np.transpose(img, (1, 2, 0)))\n    plt.title('%s -> %s' % (classes[test_y[rand_test_samples[index]]], classes[test_label_predicted[rand_test_samples[index]]]))\n    plt.axis('off')\n\n    plt.tight_layout()\n\nplt.show()","0efff643":"class AlexNet(nn.Module):\n    def __init__(self, num_classes=N):\n        super(AlexNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2),\n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 2 * 2, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), 256 * 2 * 2)\n        x = self.classifier(x)\n        return x\n    \nAlexNet = AlexNet()\n# Assuming GPU is available, move the model to GPU.\nAlexNet.cuda()\n\nprint(AlexNet)","a4452b5a":"# Define our Adam optimizer\noptimizer = Adam(AlexNet.parameters(), lr=0.005)\n\n# Create an instance of the MSE Loss Function\ncriterion = nn.MSELoss()","079e4358":"# Create new directory for saving models trained with CE Loss \n!mkdir saved_models_AlexNet","1e559cb2":"EPOCHS = 50\n\ntrain_epoch_loss = []\nvalidation_epoch_loss = []\n\nfor epoch in range(EPOCHS):\n    train_loss = []\n    validation_loss = []\n\n    for batch_index, (train_image, train_label) in enumerate(trainloader):\n        #######################################################\n        ###################### Validation #####################\n        #######################################################\n    \n        # Assume GPU is available\n        AlexNet.train()\n\n        train_ohe = F.one_hot(train_label, num_classes=N)\n        train_ohe = train_ohe.type(torch.FloatTensor)\n        train_label_predicted = AlexNet(train_image.cuda())\n\n        # compute the loss\n        loss = criterion(train_label_predicted, train_ohe.cuda())\n        train_loss.append(loss.cpu().data.item())\n        \n        # reset the gradient \n        optimizer.zero_grad()\n        # backpropagate the loss\n        loss.backward()\n        # update the parameters\n        optimizer.step()\n\n        #######################################################\n        ###################### Validation #####################\n        #######################################################\n        # Set the model to evaluation mode so that parameters are fixed.\n        AlexNet.eval()\n        \n    for batch_index, (val_image, val_label) in enumerate(valloader):\n        \n        val_ohe = F.one_hot(val_label, num_classes=N)\n        val_ohe = val_ohe.type(torch.FloatTensor)\n        validation_label_predicted = AlexNet(val_image.cuda())\n\n        loss = criterion(validation_label_predicted, val_ohe.cuda())\n        validation_loss.append(loss.cpu().data.item())\n\n    train_epoch_loss.append(np.mean(train_loss))\n    validation_epoch_loss.append(np.mean(validation_loss))\n    \n    # save models\n    torch.save(AlexNet.state_dict(), '.\/saved_models_AlexNet\/checkpoint_epoch_%s.pth' % (epoch))\n\n    print(\"Epoch: {} | train_loss: {} | validation_loss: {}\".format(epoch, train_epoch_loss[-1], validation_epoch_loss[-1]))","74e538a3":"# Draw the learning curve\nplt.figure(figsize = (12, 8))\nplt.title('Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.plot(train_epoch_loss, '-o', label = 'training loss', markersize = 3)\nplt.plot(validation_epoch_loss, '-o', label = 'validation loss', markersize = 3)\nplt.legend(loc = 'upper right');","472921d7":"# Display the best epoch\nbest_epoch = np.argmin(validation_epoch_loss)\nprint('Best epoch: ', best_epoch)","c221aa3a":"# Load the best model\nstate_dict = torch.load('.\/saved_models_AlexNet\/checkpoint_epoch_%s.pth' % (best_epoch))\nprint(state_dict.keys())\nAlexNet.load_state_dict(state_dict)","0afb57de":"# Evaluate the model on the test set\n\nAlexNet.eval()\ntest_label_predicted_all = []\n\nfor batch_index, (test_image, test_label) in enumerate(testloader):\n        \n    test_label_predicted_one_hot = AlexNet(test_image.cuda())\n    test_label_predicted_probability, test_label_predicted_index = torch.max(test_label_predicted_one_hot.data, 1)\n    \n    for current_prediction in test_label_predicted_index:\n        test_label_predicted_all.append(current_prediction.detach().cpu().numpy().item())\n\ntest_label_predicted = test_label_predicted_all","349f1d5c":"# Validate that the length of the predicted labels matches the ground truth (10,000)\nlen(test_label_predicted)","993f5cce":"# Gauge the accuracy of the model\n\naccuracy = accuracy_score(test_y, test_label_predicted)\n\nprint(\"Accuracy:\", accuracy * 100, \"%\")","49aa7c55":"# Display a confusion matrix to better understand the results\nCM = confusion_matrix(test_y, test_label_predicted)\n\nplt.figure(figsize = (12,10))\nsns.heatmap(CM, annot = True, annot_kws = {\"size\": 10})\nplt.ylim([0, 10]);\nplt.xticks(range(len(classes)), classes);\nplt.yticks(range(len(classes)), classes);\nplt.ylabel('True labels');\nplt.xlabel('Predicted labels');","65cde1ba":"# Present a classification report\nprint(classification_report(test_y, test_label_predicted,target_names=classes))","bc22b3ad":"# Create list of five random indices from the length of testet (10,000)\nrand_test_samples = np.random.randint(0,10000,(1,5))\nrand_test_samples = rand_test_samples.tolist()\nrand_test_samples = [item for sublist in rand_test_samples for item in sublist]","08868649":"# Create list of five random samples from testset\nrand_test_ims = [[None, None]] * 5\nfor i,r in enumerate(rand_test_samples):\n    rand_test_ims[i] = testset[r]","93746fd2":"# Plot five random samples from the testset with actual label and predicted label\nfig = plt.figure(figsize=(12, 4))\nfig.suptitle('Five random samples from the test set and their estimated labels\\nActual lable -> Estimated label')\n\nfor index, im in enumerate(rand_test_ims):\n\n    img = im[0]  \n    img = img \/ 2 + 0.5 # unnormalize\n\n    fig.add_subplot(1,5,index+1)\n    plt.imshow(np.transpose(img, (1, 2, 0)))\n    plt.title('%s -> %s' % (classes[test_y[rand_test_samples[index]]], classes[test_label_predicted[rand_test_samples[index]]]))\n    plt.axis('off')\n\n    plt.tight_layout()\n\nplt.show()","1a600fcc":"### 7. (10 pts.) According to the LeNet architecture below, create a fully-connected model. Also, identify the architeture's hyper-parameters, activation functions, and tensor shapes.\nArchitecture hyper-parameter includes the number of layers, number of kernels in each layer, size of the kernels, stride, zero-padding size. Just by looking at the architecture itself, you should be able to identify the hyper-parameters. Keep in mind that you identified the $W, H$, and $N$ (Which refers to the number of classes) in the first question.\nFor more help, look at this [implementation](https:\/\/github.com\/icpm\/pytorch-cifar10\/blob\/master\/models\/LeNet.py).\n![LeNet Architecture](https:\/\/raw.githubusercontent.com\/soroush361\/DeepLearningInBME\/main\/Ass1_Arch1.png)","ecf4e670":"# **Extra Credit: AlexNet Architecture**","f017ebb3":"**I elected to train my model for only 50 epochs due to time constraints, and with consideration for multiple models to train.**","19d027ab":"**The number of samples per class is expected to be the same; however, there is an unequal distribution that has occurred after the data split. This may be due to the random shuffling of indices before the split occurs. I tried to solve this by using stratify=train_targets in my train_test_split, but the outcome is not as I expected.**","3286ac94":"<font color='red'>[Comment about the model's performance]<\/font>\n\nThe model performs at _%. The model performs best in the _ class. The loss curve starts at a rather low value (~0.08) and drops incrementally to ~0.0_ after 200 epochs.","7acd0cb7":"### 12. (5 pts.) Display five random samples of each class titled with the true label and the predicted label. Comment on your model's performance.\nSamples must be pulled from the test set.","590064b8":"### 11. (10 pts.) Load the model's weights at the best epoch and test your model performance on the test set. Display the confusion matrix and classification report.","f7c8b34d":"### 4. (10 pts.) Using the 'matplotlib' library, make a figure with $N\\times4$ grid cells where $N$ is the number of classes. Display one random sample of each class pulled from the train set in its corresponding row that depends on its class index and the first column and its histogram in the second column. Repeat this for the third and fourth columns but pull images from the test set.","459f7c3c":"### 3. (5 pts.) Load train and test sets using Pytorch datasets functions.\nMake sure the intensity range is between $[0, 1]$ and images are stored as 'tensor' type. \nYou may use transformers while downloading the dataset to do the job. Look at this tutorial: [Pytorch CIFAR10](https:\/\/pytorch.org\/tutorials\/beginner\/blitz\/cifar10_tutorial.html))","2046399f":"### 13. (20 pts.) Repeat the training, validation, and testing with the [Cross-Entropy](https:\/\/pytorch.org\/docs\/stable\/generated\/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) loss function and initial learning rate of $0.005$. Explain how the model's performance changed.\nEssentially you need to copy all the codes above and just change the loss function and edit the learning rate. Obviously, you don't need to re-import the dataset and the libraries. However, you need to create a new instance of the architecture. Otherwise, the weights would be the same as the last epoch (or the best epoch) in the last part. To avoid overwriting your previously trained model, change the save directories in the training loop.","1cb2f8b7":"## George Kenefati - gk2577","1de3f40d":"### 6. (5 pts.) Display the number of samples for each class in the train, validation, and test sets as a stacked bar plot similar to the '[FirstTutorial](https:\/\/www.kaggle.com\/soroush361\/deeplearninginbme-firsttutorial)'.","997c4080":"# Deep Learning in Biomedical Engineering","81209bf0":"**Citations:**\n* Learning Multiple Layers of Features from Tiny Images.\n    Alex Krizhevsky, \n    April 8, 2009. http:\/\/www.cs.toronto.edu\/~kriz\/learning-features-2009-TR.pdf\n    \n* DeepLearningInBME_FirstTutorial, Soroush Arabshahi. https:\/\/www.kaggle.com\/soroush361\/deeplearninginbme-firsttutorial\n\n* cifar10 with CNN for beginer, https:\/\/www.kaggle.com\/roblexnana\/cifar10-with-cnn-for-beginer    \n\n* TRAINING A CLASSIFIER, http:\/\/pytorch.org\/tutorials\/beginner\/blitz\/cifar10_tutorial.html\n\n* PyTorch [Basics] \u2014 Sampling Samplers, https:\/\/towardsdatascience.com\/pytorch-basics-sampling-samplers-2a0f29f0bf2a\n\n\n* ImageNet Classification with Deep Convolutional\nNeural Networks - AlexNet, https:\/\/papers.nips.cc\/paper\/2012\/file\/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf","73bcb74b":"### **AlexNet Architecture Implementation on CIFAR10**\n![AlexNet Architecture](https:\/\/analyticsindiamag.com\/wp-content\/uploads\/2020\/06\/Architecture-768x248.png)","27a8acf8":"**a) 60,000 \\\nb) 10 \\\nc) 32 x 32 \\\nd) 0. airplane, 1. automobile, 2. bird, 3. cat, 4. deer, 5. dog, 6. frog, 7. horse, 8. ship, 9. truck \\\ne) [0, 255] (uint8)**","f8083b77":"### Output the model's accuracy, a confusion matrix, and a classification report","354ae8ea":"### 1. (5 pts.) According to the [CIFAR10](http:\/\/www.cs.toronto.edu\/~kriz\/cifar.html) dataset descriptions and other online resources, please identify the quantities below:\n\na) Total Number of samples \\\nb) Number of classes \\\nc) Image size \\\nd) Write class names and their corresponding label index (e.g., 0. cats, 1. dogs, ...) \\\ne) Intensity range","1e2d3d5a":"### Train the model with Cross Entropy Loss and lr = 0.005","385bfcdc":"### 9. (15 pts.) Train the model for 200 epochs using the train set and validate your model's performance at the end of each epoch using the validation sets.\nTo increase the training speed, use the GPU accelerator.\nLook at the '[FirstTutorial](https:\/\/www.kaggle.com\/soroush361\/deeplearninginbme-firsttutorial)' for more help.\nDo not forget to save the model at the end of each epoch.","6909c2f1":"**The architecture's hyperparameters are as follows:**\n* Number of layers: 4 (two convolutional layers, two fully connected layers)\n* Number of kernels in conv layer 1: 6\n* Number of kernels in conv layer 2: 16\n* There are no kernels in the 2 fully connected layers.\n\n* Size of kernel in conv layer 1: 5x5\n* Size of kernel in conv layer 2: 5x5\n\n* Stride = 1\n\n* Zero-padding = 0","ac61176b":"### Load the best model and evaluate it on the testset","4d7b016d":"## Introduction\nIn this assignment, you will implement, train, and test [LeNet](https:\/\/en.wikipedia.org\/wiki\/LeNet) model to classify [CIFAR10](http:\/\/www.cs.toronto.edu\/~kriz\/cifar.html) dataset.\n\n## Instructions\nDepending on each question, there are empty blocks you need to fill. The code blocks are only for Python codes and comments and currently have a comment like ```# [Your code here]```. The markdown blocks are only for plain or laTex text that you may use for answering descriptive questions. Currently, the markdown blocks have a comment like <font color='red'>[your answer here]<\/font>. Please remove the comments before filling the blocks. You can always add more blocks if you need to, or it just makes your answers well-organized.\n\nAlthough you may use other available online resources (such as GitHub, Kaggle Notebooks), it is highly recommended to try your best to do it yourself. If you are using an online code or paper, make sure you cite their work properly to avoid plagiarism. Using other students' works is absolutely forbidden and considered cheating.\n\nWrite comments for your codes in the big picture mode. One comment line at the top of each code block is necessary to explain what you did in that block. Don't comment on every detail.\n\nName your variables properly that represent the data they are holding, such as ``` test_set = ..., learning_rate = ...``` not ```a = ..., b = ...```.\n\nImplementing and reporting results using other architectures than LeNet will grant you an extra 20% on grade.\n\nIn this [Kaggle Notebook](https:\/\/www.kaggle.com\/roblexnana\/cifar10-with-cnn-for-beginer), you may find useful information about how your outputs must look. Just remember, they are using a different architecture, and they are using TensorFlow for implementations.\n\n\n## How to submit:\nAfter you have completed the assignment: \n1. Save a version (You can use 'Quick Save' to avoid re-running the whole notebook)\n2. Make the saved version public (Share -> Public)\n3. Copy the 'Public URL'\n4. Download your completed notebook as a '.ipynb' file (File -> Download)\n5. Upload the 'Public URL' and the '.ipynb' files on the [CourseWorks](https:\/\/courseworks2.columbia.edu\/).","7e58ed7f":"### Display Five Random Samples","3e320a8b":"### 5. (5 pts.) Split up the train set into new train and validation sets so that the number of samples in the validation set is equal to the number of samples in the test set. Then create a [```DataLoader```](https:\/\/pytorch.org\/docs\/stable\/data.html#torch.utils.data.DataLoader) for each set, including the test set, with a batch size of 32.\nThe [Pytorch CIFAR10](https:\/\/pytorch.org\/tutorials\/beginner\/blitz\/cifar10_tutorial.html) tutorial will also help you here.\nMake sure none of the samples in the validation set exists in the new train set.","3d8f343f":"### 10. (5 pts.) Display the learning curve and illustrate the best epoch. Explain your criteria for the best epoch.\nThe learning curve shows the model's loss and accuracy at the end of each epoch for all epochs (200 epochs). The criteria for the best epoch can be the minimum loss or maximum accuracy or other criteria.","021839a2":"<font color='red'>[Describe your criteria for choosing the best epoch]<\/font>\n\nI chose minimum validation loss as my criterion for the best epoch. Train loss tends to flatten toward zero during later epochs while validation loss sometimes increases due to overfitting. The validation loss thus gives the clearest picture of the model's latest\/best performance, and should be used as a starting point for tuning hyperparameters, such as learning rate.","1000a847":"### Draw the learning curve","7f4cf8e9":"## Assignment 2\n### Due date:<font color='red'> 11:59 pm, Febraury 25, 2021<\/font>","2a2dac4a":"### 8. (5 pts.) Create an instance of [ADAM optimizer](https:\/\/pytorch.org\/docs\/stable\/optim.html#torch.optim.Adam) with an initial learning rate of $0.0001$ and an instance of [Mean Squared Error (MSE)](https:\/\/pytorch.org\/docs\/stable\/generated\/torch.nn.MSELoss.html#torch.nn.MSELoss) loss function. Briefly explain the ADAM optimizer algorithm and the MSE loss function.\nFor ADAM optimizer, keep other arguments as default. \n\nFor your information, here is the mathematics behind the ADAM optimizer: \\\nFor each parameter $w^j$\n$$\nv_t = \\beta_1v_{t-1}-(1-\\beta_1)g_t \\\\\ns_t = \\beta_2s_{t-1}-(1-\\beta_2)g_t^2 \\\\\n\\Delta w^j = -\\eta\\frac{v_t}{\\sqrt{s_t+\\epsilon}}g_t \\\\\nw^j_{t+1} = w^j_t+\\Delta w^j\n$$\nWhere $\\eta$ is the initial learning rate, $g_t$ is the gradient at time $t$ along $w^j$, $v_t$ is the exponential average of gradients along $w^j$, $s_t$ is the exponential average of squares of gradients along $w^j$, $\\beta_1, \\beta_2$ are the hyper-parameters, and $\\epsilon$ is a small number to avoid dividing by zero.\n\nThe MSE loss function is:\n$$\nL(y,\\hat{y}) = \\frac{1}{N}\\sum_{i=1}^N{(y_i-\\hat{y}_i)^2}\n$$\nWhere $y$ is the true value, $\\hat{y}$ is the predicted value, $N$ is the number of classes. Keep in mind that $y$ is a one-hot vector like $y=\\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\ \\vdots \\end{bmatrix}$ (This example of $y$ indicates that the sample belongs to class ID 2, remember it is zero-indexed) and $\\hat{y}=\\begin{bmatrix} 0.1 \\\\ 0.03 \\\\ 0.8 \\\\ \\vdots \\end{bmatrix}$ shows the probability of belonging to each class for the same sample and predicted by the model.\n\nFor other optimization algorithms and loss functions, check the links below:\n\n[Optimizers list](https:\/\/pytorch.org\/docs\/stable\/optim.html#algorithms) \n\n[Loss function list](https:\/\/pytorch.org\/docs\/stable\/nn.html#loss-functions)","9e549f63":"<font color='red'>[Explaine ADAM and MSE here]<\/font>\n\n**ADAM Optimizer**\n* ADAM stands for Adaptive Moment Estimation and combines a momentum-based gradient descent algorithm with the RMSprop algorithm. B1 computes the mean of the derivatives (first moment) while B2 computes the exponential weight average of the squares (second moment). The two combine to create a more balanced optimizing algorithm that generalizes more than either a momentum-based GD algorithm or the RMSprop algorithm alone. The learning rate acts as a scaling factor, requiring the most tuning of all hyperparameters. 0.9 is recommended for the value of B1 and 0.999 is recommended for the value of B2. 10e-8 is recommended for epsilon.\n\n\n**MSE Loss Function**\n* MSE stands for Mean Squared Error Loss. It is calculated as the average of the squared differences between the predicted values of a model and the actual values of a dataset. MSE has the disadvantage of being heavily influenced by outliers, which may require extra data-cleaning. \n","bcd03687":"### **My histograms appear to display a distribution different than what is expected. I suspect the loop plotting the histograms may be the source of issue.**","fed8320e":"### 2. (0 pts.) Import the required packages in the following code block. \nYou can always come back here and import another package; please keep them all in the following block to make your code well-organized.","9bfa8451":"**The AlexNet implementation with MSE Loss appears to have significantly less accuracy (23%) than both LeNet implementations. The learning curve of AlexNet shows a large dive from the first epoch at ~64 loss to ~0.09. This architecture will require further tuning of hyperparameters to yield favorable results, or at least similar to that of the LeNet implemenations.**","169b600a":"**I elected to train my model for only 50 epochs due to time constraints, and with consideration for multiple models to train.**","ce909d3d":"<font color='red'>[Comment about the performance changes]<\/font>\n\n**The LeNet implementation with CrossEntropy Loss overall has a worse performance (54% compared to 63% accuracy). The latter model also had poor validation loss reduction, increasing instead and reaching best epoch too early (3 compared to 38). The validation loss curve was more jagged, potentially hinting at a need to alter the optimizer learning rate, perhaps dynamically. Nonetheless, this model did not encounter any other obstacles and did produce a confusion matrix that suggests further improvement is feasible. The AlexNet architecture below, on the other hand, has poor performance compared to those of both LeNet models.**"}}