{"cell_type":{"7bb53fd4":"code","11d73ef3":"code","1481ce57":"code","b057aa4b":"code","0831e9c1":"code","c365a2d3":"code","42bb84a2":"code","cc3f0583":"code","3d29ac8d":"code","353b9206":"code","25f27c6a":"code","aadb3ab5":"code","f388a00b":"markdown","19de0d85":"markdown","ac2931f8":"markdown","53be2ce8":"markdown","75a3b11f":"markdown","d3b6dd81":"markdown","fe8f18f7":"markdown","aa588f52":"markdown","47b04140":"markdown","60cd7198":"markdown","d7fbc138":"markdown","dc85f898":"markdown"},"source":{"7bb53fd4":"# Imports\nimport os\nimport pickle\nimport datetime\nimport pandas as pd\nimport numpy as np\nfrom scipy import integrate\nfrom matplotlib import pyplot as plt\nfrom keras.optimizers import Adam\nfrom keras.layers import Dense, GRU\nfrom keras.models import Sequential, load_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix","11d73ef3":"# Utilities functions\n\ndef clean_dataframe(dataframe):\n    \"\"\" La fonction permet de nettoyer le dataset des incidents afin de cr\u00e9er une version th\u00e9orique d'un comportement id\u00e9al \n        de l'application dans un environnement qui ne conna\u00eet pas les incidents.\n    \"\"\"\n    incidents = dataframe.loc[dataframe['Label'] == 1, ['TimeStamp']]\n    for incident in incidents.values:\n        dataframe.loc[(dataframe['TimeStamp'] == incident[0]), 'Value'] = np.nan\n        dataframe.loc[(dataframe['TimeStamp'] == incident[0]), 'Label'] = 0\n    dataframe = dataframe.interpolate()\n    return dataframe\n\ndef count_incidents(dataframe):\n    \"\"\" La fonction permet de compter le nombre d'incidents dans un dataset.\n    \"\"\"\n    incidents = dataframe.loc[dataframe['Label'] == 1, ['TimeStamp']]\n    nb_incidents = len(incidents.values)\n    return nb_incidents\n\ndef inter_area_variation(ideal_curve, pred_curve, window):\n    \"\"\" La fonction permet de calculer l'aire entre deux courbes. Dans le cas pratique, l'aire calcul\u00e9e est celui entre la\n        projection du comportement id\u00e9al du syst\u00e8me faite par le LSTM et le comportement suivi en temps r\u00e9el par le monitoring.\n    \"\"\"\n    max_x = len(ideal_curve)\n    cursor = 0\n    area_variation = []\n    while cursor + window < max_x:\n        x = np.arange(cursor, cursor + window)\n        area_ideal = integrate.simps(ideal_curve[cursor:cursor+window], x)\n        area_pred = integrate.simps(pred_curve[cursor:cursor+window], x)\n        area_variation.append(area_pred - area_ideal)\n        cursor += 1\n    return np.array(area_variation)\n\ndef LSTM_preprocessing(dataframe):\n    \"\"\" La fonction constitue la brique de preprocessing du LSTM. \n        Elle normalise les donn\u00e9es et produit des s\u00e9quences de donn\u00e9es \u00e0 partir du dataset d'origine.\n        Les s\u00e9quences sont de la longueur d\u00e9finie par le \"lookback\", et les labels associ\u00e9s sont s\u00e9lectionn\u00e9s dans le futur (par rapport \n        au curseur) \u00e0 une longueur fixe d\u00e9finie par le \"delay\".\n    \"\"\"\n    timestamps = dataframe['TimeStamp'].values\n    values = dataframe['Value'].values\n    scaler = MinMaxScaler()\n    values = scaler.fit_transform(values.reshape([-1, 1]))\n    values = np.squeeze(values)\n    print('Data shape: timestamps {}   values {}'.format(timestamps.shape, values.shape))\n    batches = []\n    labels = []\n    for i in range(lookback, values.shape[0] - delay):\n        batch = [[x] for x in values[i - lookback:i]]\n        batches.append(batch)\n        labels.append(values[i + delay])\n    batches = np.array(batches)\n    labels = np.array(labels)\n    print('Sequences shape: batches {}   labels {}'.format(batches.shape, labels.shape))\n    return batches, labels, scaler\n\ndef LogReg_preprocessing(array_1, array_2, window):\n    \"\"\" La fonction constitue la brique de preprocessing du mod\u00e8le de r\u00e9gression (Logreg). \n        Elle produit les s\u00e9quences de donn\u00e9es \u00e0 partir de l'aire entre la courbe id\u00e9ale projet\u00e9e par le LSTM et la courbe r\u00e9elle.\n        Les s\u00e9quences sont de la longueur d\u00e9finie par \"window\", et les labels associ\u00e9s sont le statut d'anomalie correspondant (1 ou 0).\n        Les valeurs de \"window\" ne sont pas choisies au hasard: elles sont optimis\u00e9es apr\u00e8s analyse de la variation du score f1 (FN\/FP).\n    \"\"\"\n    inputs = inter_area_variation(array_1, array_2, window)\n    inputs = np.array(inputs).reshape([-1, 1])\n    scaler = StandardScaler()\n    inputs = scaler.fit_transform(inputs)\n    print('Inputs shape: {}'.format(inputs.shape))\n    return inputs","1481ce57":"# Parameters\ndataframe = pd.read_csv('..\/input\/cloud-monitoring-exemple\/ingress-01.csv')\nLSTM_model = '..\/input\/cloud-monitoring-models\/LSTM_model.h5'\nRegression_model = '..\/input\/cloud-monitoring-models\/Regressor_model.sav'\nmodel_save_path = '.\/'\nbonus_model = '..\/input\/cloud-monitoring-models\/LSTM_bonus_model.h5'\ncolors = ['turquoise', 'crimson', 'snow', 'dimgrey']\nlookback = 480\ndelay = 120\nvalidation_split = 0.1\ntest_split = 0.5\nbatch_size = 128\nepochs = 35\nwindow = 10","b057aa4b":"# Plot the entire dataset\ndataframe_sample = dataframe[::10]\nfig, ax = plt.subplots(nrows=1, ncols=1)\nax.set_facecolor(colors[-1])\nx_axis = range(len(dataframe_sample))\nax.plot(x_axis, dataframe_sample['Value'], color=colors[0], linewidth=0.5)\nax.set_ylabel('Data ingress rate')\nax.set_title('Data ingress rate full dataset')\nplt.show()\n\n# Split the dataset between training and testing\nindice = int((dataframe.shape[0] * (1-test_split)))\ntrain_dataframe = dataframe.loc[:indice]\ntest_dataframe = dataframe.loc[indice:]","0831e9c1":"# Data preprocessing\nnb_incidents = count_incidents(train_dataframe)\nprint('Number of incidents in the data before cleaning: {}'.format(nb_incidents))\nideal_dataframe = clean_dataframe(train_dataframe.copy(deep=True))\nnb_incidents = count_incidents(ideal_dataframe)\nprint('Number of incidents in the ideal data: {}'.format(nb_incidents))\nbatches, labels, scaler = LSTM_preprocessing(ideal_dataframe)\n\n# Build and compile model\nmodel = Sequential()\nmodel.add(GRU(32, dropout=0.1, recurrent_dropout=0.5, return_sequences=False, input_shape=(lookback, 1)))\nmodel.add(Dense(1))\nmodel.compile(optimizer=Adam(1e-5), loss='mae')\n\n# Train the model\nhistory = model.fit(batches, labels, batch_size=batch_size, epochs=epochs, validation_split=validation_split)\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","c365a2d3":"# Save the model\nmodel.save(os.path.join(model_save_path, 'LSTM_model.h5'))","42bb84a2":"# Data preprocessing\nbatches, labels, scaler = LSTM_preprocessing(train_dataframe)\nmodel = load_model(LSTM_model)\nprediction = model.predict(batches)\nprediction = scaler.inverse_transform(prediction)\ninputs = LogReg_preprocessing(np.squeeze(prediction), np.squeeze(train_dataframe['Value'].values[lookback + delay:]), window)\nlabels = train_dataframe['Label'].values[lookback + delay + window:]\n\n# Train the model\nmodel = LogisticRegression()\nmodel.fit(inputs, labels)\n\n# Save the model\npickle.dump(model, open(os.path.join(model_save_path, 'Regressor_model.sav'), 'wb'))","cc3f0583":"# Plot the test split of the original dataset along with the corresponding anomalies\nplot_frame = test_dataframe[lookback + delay + window:]\nprint('Plot dataframe shape: {}'.format(plot_frame.shape))\nfig, ax1 = plt.subplots(nrows=1, ncols=1)\nfig.autofmt_xdate()\nax1.set_title('Anomaly detection using data ingress rate')\nax1.set_facecolor(colors[-1])\ndates = plot_frame['TimeStamp']\nx_axis = list(map(datetime.datetime.strptime, dates, len(dates) * ['%Y-%m-%dT%H:%M:%SZ']))\nl1, = ax1.plot(x_axis, plot_frame['Label'].values, color=colors[1], linewidth=1)\nax2 = ax1.twinx()\nl2, = ax2.plot(x_axis, plot_frame['Value'].values, color=colors[2], linewidth=0.3)\nax1.set_ylabel('Anomaly state')\nax2.set_ylabel('Data ingress rate')\nplt.legend([l1, l2], ['anomaly state', 'data ingress'])\nplt.show()","3d29ac8d":"# Data preprocessing\nbatches, labels, scaler = LSTM_preprocessing(test_dataframe)\n\n# Load the model\nmodel = load_model(LSTM_model)\n\n# Run the model\nprediction = model.predict(batches)\n\n# Evaluate the model\nresults = model.evaluate(batches, labels, batch_size=batch_size)\nresults = np.array(results).reshape([1, -1])\nmae = scaler.inverse_transform(results)\nprint('Test loss : {}'.format(results))\nprint('Average error : {}'.format(mae))\n\n# Results post processing\nprediction = scaler.inverse_transform(prediction)\nideal = scaler.inverse_transform(labels.reshape([-1, 1]))\nideal = np.squeeze(ideal)\nprint('Prediction length: {}   Test data length: {}'.format(len(prediction), len(ideal)))\n\n# Visualize results\nprediction_sample = prediction[::20]\nideal_sample = ideal[::20]\nfig, ax = plt.subplots(nrows=1, ncols=1)\nax.set_facecolor(colors[-1])\nx_axis = range(len(ideal_sample))\nax.plot(x_axis, ideal_sample, color=colors[0], linewidth=0.5, label='ideal')\nax.plot(x_axis, prediction_sample, color=colors[1], linewidth=0.5, label='predicted')\nax.set_ylabel('Data ingress rate')\nax.set_title('Ideal vs predicted data ingress')\nax.legend()\nplt.show()","353b9206":"# Data preprocessing\ninputs = LogReg_preprocessing(np.squeeze(prediction), np.squeeze(test_dataframe['Value'].values[lookback + delay:]), window)\n\n# Visualize area variation between predicted curve and actual curve\nfig, ax = plt.subplots(nrows=1, ncols=1)\nx = np.arange(len(inputs))\nax.set_facecolor(colors[-1])\nax.plot(x, inputs, color=colors[0], linewidth=0.5)\nplt.show()","25f27c6a":"# Load the model\nmodel = pickle.load(open(Regression_model, 'rb'))\n\n# Predict anomalies\nanomaly_prediction = model.predict(inputs)\nprint('Anomaly prediction shape: {}'.format(anomaly_prediction.shape))\n\n# Evaluate results\nprint(confusion_matrix(plot_frame['Label'].values, anomaly_prediction))\nprint(classification_report(plot_frame['Label'].values, anomaly_prediction))","aadb3ab5":"# Data preprocessing\nlabels = test_dataframe['Label']\ndata = np.array(test_dataframe['Value'].values)\nscaler = StandardScaler()\ndata = scaler.fit_transform(data.reshape([-1, 1]))\ndata = np.squeeze(data)\nbatches = []\nlabels = labels[lookback:data.shape[0]-delay]\nfor i in range(lookback, data.shape[0]-delay):\n    batch = [[x] for x in data[i-lookback:i]]\n    batches.append(batch)\nbatches = np.array(batches)\nlabels = np.array(labels)\nprint('Test dataset shape: {}   Test labels shape: {}'.format(batches.shape, labels.shape))\n\n# Load the model\nmodel = load_model(bonus_model)\n\n# Predict anomalies\npredictions = model.predict(batches)\npredictions = np.where(predictions > 0.8, 1, 0)\n\n# Evaluate results\nprint(confusion_matrix(labels, predictions))\nprint(classification_report(labels, predictions))","f388a00b":"# R\u00e9utilisation du pipeline sur un autre jeu de donn\u00e9es\n\n\nAdaptation des param\u00e8tres initiaux du pipeline pour cette nouvelle m\u00e9trique:\n\n- dataframe = pd.read_csv('..\/input\/cloud-monitoring-exemple\/ingress-01.csv')\n- lookback = 240\n- delay = 60\n- validation_split = 0.1\n- test_split = 0.2\n- batch_size = 64\n- epochs = 35\n- window = 360\n\n\n**Visualisation du jeu de donn\u00e9es**\n\n![MongoDB_application_requests.png](attachment:a4d494ed-7a1c-462f-ab86-6e5528545138.png)\n\n\n**Entra\u00eenement du mod\u00e8le**\n\n![training_and_validation_loss.png](attachment:291de4f0-a2b7-47d5-95ef-dbafd646f77d.png)\n\n\n**Comportement id\u00e9al pr\u00e9dit**\n\n![ideal_vs_predicted_requests.png](attachment:7cddb673-0002-454f-8a74-1590ad2a8177.png)\n\n\n**Variation de l'aire entre le comportement id\u00e9al pr\u00e9dit et le comportement r\u00e9el**\n\n![area_variation.png](attachment:7b54525a-2283-43af-b07e-185d7a0bcb01.png)\n\n\n**R\u00e9sultats de la d\u00e9tection d'anomalies**\n\n    Train set shape: X_train (12144, 1) y_train (12144,)\n    Test set shape: X_test (3036, 1) y_test (3036,)\n    [[3036]]\n                  precision    recall  f1-score   support\n\n               0       1.00      1.00      1.00      3036\n\n        accuracy                           1.00      3036\n       macro avg       1.00      1.00      1.00      3036\n    weighted avg       1.00      1.00      1.00      3036\n\n\n**Interpr\u00e9tation des r\u00e9sultats**\n\nOn se trouve dans un cas particulier int\u00e9ressant: le sous-ensemble de test ne contient aucun incident, mais comporte des variations importantes en plus du motif p\u00e9riodique apparrent. L'absence de faux-positifs malgr\u00e9 ces variations est donc encourageante pour confirmer la solidit\u00e9 de la base du pipeline.","19de0d85":"**Interpr\u00e9tation des r\u00e9sultats**\n\nSur 72 anomalies labellis\u00e9es:\n- 67 anomalies ont \u00e9t\u00e9 correctement d\u00e9tect\u00e9es (93%)\n- Aucune anomalie n'a \u00e9t\u00e9 d\u00e9tect\u00e9e \u00e0 tort (Faux positifs)\n- 5 anomalies ont \u00e9t\u00e9 manqu\u00e9es (Faux n\u00e9gatifs)","ac2931f8":"# Pr\u00e9diction vs d\u00e9tection\n\n\nLe pipeline pr\u00e9sent\u00e9 dans le notebook permet de d\u00e9tecter un comportement anormal d'une application en suivant les m\u00e9triques en temps r\u00e9el, cependant il ne permet pas de pr\u00e9dire \u00e0 l'avance si un incident risque probablement d'arriver ou non. Il s'agit d'un test int\u00e9ressant \u00e0 faire puisque cela pourrait permettre d'anticiper les incidents plut\u00f4t que d'alerter lorsqu'un incident est d\u00e9tect\u00e9.\n\nIci les param\u00e8tres de \"lookback\" et \"delay\" sont \u00e0 d\u00e9finir par les m\u00e9tiers, selon les attendus d'un responsable d'application par exemple. Arbitrairement pour le test, j'ai choisi un lookback de 4 heures (240 minutes) et un delay de 60 minutes. Cela correspond \u00e0 un mod\u00e8le qui pr\u00e9dit les incidents 1 heure \u00e0 l'avance en se basant sur les m\u00e9triques des 4 derni\u00e8res heures.\n\nmod\u00e8le entra\u00een\u00e9: GRU\n\n    model = Sequential()\n    model.add(GRU(64, dropout=0.1, recurrent_dropout=0.5, return_sequences=False, input_shape=(lookback \/\/ step, 1)))\n    model.add(Dense(units=1, activation='sigmoid'))\n    model.compile(optimizer=Adam(1e-5), loss='binary_crossentropy', metrics=['acc'])","53be2ce8":"**Entra\u00eenement du bloc de regression**","75a3b11f":"# Objectif du projet\n\nL'objectif du projet est de d\u00e9tecter les anomalies dans le cadre du monitoring d'un cloud microsoft.\n\nsource des donn\u00e9es: https:\/\/github.com\/Microsoft\/cloud-monitoring-dataset\n\nLe raisonnement suivi pour l'impl\u00e9mentation du pipeline est comme suit: un premier bloc sera entra\u00een\u00e9 sur un jeu de donn\u00e9es dit \"id\u00e9al\", \u00e0 savoir qu'il aura \u00e9t\u00e9 pr\u00e9alablement vid\u00e9 des incidents et les points manquants compl\u00e9t\u00e9s par interpolation lin\u00e9aire. Ce bloc a pour objectif d'apprendre le comportement id\u00e9al de la m\u00e9trique monitor\u00e9e dans un monde sans incidents.\n\nLors du monitoring en temps r\u00e9el, la valeur de la m\u00e9trique monitor\u00e9e est compar\u00e9e avec sa projection id\u00e9ale fournie par notre premier bloc. Le diff\u00e9rentiel de l'aire entre les deux courbes produit une nouvelle s\u00e9quence de donn\u00e9es. Cette s\u00e9quence est utilis\u00e9e pour entra\u00eener un second bloc afin de d\u00e9tecter les anomalies en se basant sur les variations de la s\u00e9quence nouvellement calcul\u00e9e.\n\nLe pipeline mis en place pour atteindre l'objectif est pr\u00e9sent\u00e9 succintement dans le sch\u00e9ma ci-dessous :\n\n![cloud_monitoring.jpg](attachment:db3b5672-b100-4f7d-ad15-45d7087d6054.jpg)\n\n1. Normalisation des donn\u00e9es\n2. Pr\u00e9diction du comportement dit \"id\u00e9al\" de l'application monitor\u00e9e\n3. Calcul du diff\u00e9rentiel entre le comportement id\u00e9al obtenu \u00e0 l'\u00e9tape pr\u00e9c\u00e9dente et le comportement r\u00e9el monitor\u00e9\n4. D\u00e9tection des anomalies en fonction du diff\u00e9rentiel calcul\u00e9 \u00e0 l'\u00e9tape pr\u00e9c\u00e9dente\n\n\nCi-dessous il est possible de consulter le code d\u00e9finissant les imports, les fonctions utilitaires et les param\u00e8tres du pipeline.","d3b6dd81":"Jeu de donn\u00e9es \u00e0 l'\u00e9tude : data ingress rate\n\nSegmentation 50\/50 respectivement pour l'entra\u00eenement (donn\u00e9es consid\u00e9r\u00e9es comme historiques) et pour le test (donn\u00e9es consid\u00e9r\u00e9es comme inconnues, soit l'\u00e9quivalent du monitoring en temps r\u00e9el).","fe8f18f7":"**Entra\u00eenement du bloc LSTM**","aa588f52":"**Interpr\u00e9tation des r\u00e9sultats**\n\nSur 72 anomalies labellis\u00e9es:\n- 68 anomalies ont \u00e9t\u00e9 correctement pr\u00e9dites (94%)\n- 11 anomalies ont \u00e9t\u00e9 pr\u00e9dites \u00e0 tort (Faux positifs)\n- 4 anomalies ont \u00e9t\u00e9 manqu\u00e9es (Faux n\u00e9gatifs)","47b04140":"# Entra\u00eenement des mod\u00e8les composant le pipeline","60cd7198":"# Test de bout en bout du pipeline de d\u00e9tection des anomalies","d7fbc138":"Le notebook est d\u00e9compos\u00e9 en 5 parties:\n\n1. Code de l'entra\u00eenement des mod\u00e8les\n2. Test de bout en bout du pipeline de d\u00e9tection des anomalies\n3. R\u00e9utilisation du pipeline pour un second jeu de donn\u00e9es\n4. Test d'un mod\u00e8le de pr\u00e9diction des anomalies\n5. Am\u00e9liorations et autres approches","dc85f898":"# Axes d'am\u00e9lioration du projet et autres approches\n\nAm\u00e9liorer les performances de la pr\u00e9diction du comportement id\u00e9al afin de mieux d\u00e9tecter les anomalies\n- Mont\u00e9e en puissance du mod\u00e8le propos\u00e9 par exemple avec l'augmentation du nombre de neurones, ou encore l'empilement de plusieurs LSTM pour les s\u00e9ries complexes.\n- Interpoler plus finement les points qui remplacent les incidents pour l'apprentissage du comportement id\u00e9al. L'interpolation lin\u00e9aire donne facilement des r\u00e9sultats mais reste une solution simpliste.\n\nD\u00e9multiplier les pipelines de d\u00e9tection des anomalies pour combiner plusieurs apprentissages dans une m\u00eame prise de d\u00e9cision. Par exemple avec un syst\u00e8me de vote avec poids du m\u00eame type qu'une Random Forest, ou encore une cascade de mod\u00e8les sur le m\u00eame type qu'un arbre de d\u00e9cision.\n\n*ref: https:\/\/www.cmpe.boun.edu.tr\/~ethem\/i2ml2e\/2e_v1-0\/i2ml2e-chap17-v1-0.pdf*\n\nLa source des donn\u00e9es propose plusieurs fichiers de monitoring, mais qui sont malheureusement ind\u00e9pendants les uns des autres. Dans le cas o\u00f9 plusieurs m\u00e9triques seraient disponibles pour un m\u00eame syst\u00e8me, il sera possible de faire \u00e9voluer le mod\u00e8le pour qu'il prenne en entr\u00e9e un ensemble de m\u00e9triques pour d\u00e9tecter les anomalies (multi-input single-output)."}}