{"cell_type":{"9d5e1267":"code","62e4c934":"code","7ee96837":"code","2e74e51f":"code","bbf85809":"code","96e6fb7b":"code","3a82b10e":"code","efc25dc9":"code","f92adc88":"code","29523231":"code","1e25ad32":"code","f7375ce0":"code","2593e11e":"code","853f384b":"code","1e07d43d":"code","8421de6a":"code","201e6df5":"code","a8f2f16b":"code","4c499c98":"code","08567fa2":"code","2f83af37":"code","550a9fa2":"code","92b27f98":"code","37947423":"code","76f0a77e":"code","1ec5e9cd":"markdown","224d0f19":"markdown","577bc5bd":"markdown","014c1c4b":"markdown","2c0c9d60":"markdown","3fc461bb":"markdown","461e3da0":"markdown","5fbe8853":"markdown","5a7f3a13":"markdown","8b0d2c9a":"markdown","5b162e9e":"markdown","deb355be":"markdown","7600d918":"markdown","9e24254e":"markdown","70a13701":"markdown","c7e8cac2":"markdown","1527dd38":"markdown","0274522e":"markdown","aa7341bd":"markdown","ea8c37c9":"markdown","5787c097":"markdown","21e978b0":"markdown"},"source":{"9d5e1267":"import gc\nimport os\nimport warnings\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score\nfrom keras import backend as K\n# for\ubb38 \uc2dc\uac04\uacc4\uc0b0 lib\nfrom tqdm import tqdm_notebook\n# \uad50\ucc28\uac80\uc99d lib\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\n#\ubaa8\ub378 lib\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, GlobalAveragePooling2D\nfrom keras import layers\nfrom keras.optimizers import Adam,RMSprop,SGD,Nadam\n#\uacbd\uace0\uba54\uc138\uc9c0 \ubb34\uc2dc\nimport warnings\nwarnings.filterwarnings(action='ignore')\n#input \ud558\uc704 \ub514\ub809\ud1a0\ub9ac \ud3f4\ud130\nimport os\nprint(os.listdir(\"..\/input\"))","62e4c934":"#efficientnet download\n!pip install git+https:\/\/github.com\/qubvel\/efficientnet\nfrom efficientnet import EfficientNetB3","7ee96837":"#crop data directory\nDATA_PATH = '..\/input\/car-crop'\nos.listdir(DATA_PATH)","2e74e51f":"#original data directory\nDATA_PATH2 = '..\/input\/2019-3rd-ml-month-with-kakr'\nos.listdir(DATA_PATH2)","bbf85809":"# \uc774\ubbf8\uc9c0 \ud3f4\ub354 \uacbd\ub85c\nTRAIN_IMG_PATH = os.path.join(DATA_PATH, 'train')\nTEST_IMG_PATH = os.path.join(DATA_PATH, 'test')\n\n# CSV \ud30c\uc77c \uacbd\ub85c\ndf_train = pd.read_csv(os.path.join(DATA_PATH2, 'train.csv'))\ndf_test = pd.read_csv(os.path.join(DATA_PATH2, 'test.csv'))\ndf_class = pd.read_csv(os.path.join(DATA_PATH2, 'class.csv'))","96e6fb7b":"df_train[\"class\"] = df_train[\"class\"].astype('str')\n\ndf_train = df_train[['img_file', 'class']]\ndf_test = df_test[['img_file']]\n\nits = np.arange(df_train.shape[0])\ntrain_idx, val_idx = train_test_split(its, train_size = 0.8, random_state=42)\n\nX_train = df_train.iloc[train_idx, :]\nX_val = df_train.iloc[val_idx, :]\n\nprint(X_train.shape)\nprint(X_val.shape)\nprint(df_test.shape)","3a82b10e":"def recall_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives \/ (possible_positives + K.epsilon())\n        return recall\n\ndef precision_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives \/ (predicted_positives + K.epsilon())\n        return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))","efc25dc9":"# Parameter\nimg_size = (299, 299)\nimage_size = 299\nnb_train_samples = len(X_train)\nnb_validation_samples = len(X_val)\nnb_test_samples = len(df_test)\nepochs = 20\nbatch_size = 32\n\n# Define Generator config\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=False,\n    zoom_range=0.2,\n    fill_mode='nearest')\nval_datagen = ImageDataGenerator(rescale=1.\/255)","f92adc88":"#generator\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=X_train, \n    directory='..\/input\/car-crop\/train_crop',\n    x_col = 'img_file',\n    y_col = 'class',\n    target_size = img_size,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=batch_size,\n    seed=42\n)\n\nvalidation_generator = val_datagen.flow_from_dataframe(\n    dataframe=X_val, \n    directory='..\/input\/car-crop\/train_crop',\n    x_col = 'img_file',\n    y_col = 'class',\n    target_size = img_size,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=batch_size,\n    shuffle=False,\n    seed=42\n)","29523231":"def get_steps(num_samples, batch_size):\n    if (num_samples % batch_size) > 0 :\n        return (num_samples \/\/ batch_size) + 1\n    else :\n        return num_samples \/\/ batch_size","1e25ad32":"%%time\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\n#model path\nMODEL_SAVE_FOLDER_PATH = '.\/model\/'\nif not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n\nmodel_path = MODEL_SAVE_FOLDER_PATH + '{epoch:02d}-{val_loss:.4f}.hdf5'\n\npatient = 2\ncallbacks_list = [\n    EarlyStopping(\n        # \ubaa8\ub378\uc758 \uac80\uc99d \uc815\ud655\ub3c4 \ubaa8\ub2c8\ud130\ub9c1\n        monitor='val_loss', \n        # patient(\uc815\uc218)\ubcf4\ub2e4 \uc815\ud655\ub3c4\uac00 \ud5a5\uc0c1\ub418\uc9c0 \uc54a\uc73c\uba74 \ud6c8\ub828 \uc885\ub8cc\n        patience=patient, \n        # \uac80\uc99d\uc5d0 \ub300\ud574 \ud310\ub2e8\ud558\uae30 \uc704\ud55c \uae30\uc900, val_loss\uacbd\uc6b0 \uac10\uc18c\ub418\ub294 \uac83\uc774\ubbc0\ub85c min\n        mode='min', \n        #\uc5bc\ub9c8\ub098 \uc790\uc138\ud558\uac8c \uc815\ubcf4\ub97c \ub098\ud0c0\ub0bc\uac83\uc778\uac00.\n        verbose=1\n                          \n    ),\n    ReduceLROnPlateau(\n        monitor = 'val_loss', \n        #\ucf5c\ubc31 \ud638\ucd9c\uc2dc \ud559\uc2b5\ub960(lr)\uc744 \uc808\ubc18\uc73c\ub85c \uc904\uc784\n        factor = 0.5, \n        #\uc704\uc640 \ub3d9\uc77c\n        patience = patient \/ 2, \n        #\ucd5c\uc18c\ud559\uc2b5\ub960\n        min_lr=0.00001,\n        verbose=1,\n        mode='min'\n    ) ]\ngc.collect()","f7375ce0":"#model\ndef get_model():\n    EfficientNet_model = base_model = EfficientNetB3(weights='imagenet', include_top=False, \n                                                     input_shape=(299, 299, 3))\n\n\n    model = Sequential()\n    model.add(EfficientNet_model)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dense(2048, activation='relu'))\n    model.add(layers.Dropout(0.25))\n    model.add(layers.Dense(196, activation='softmax'))\n    #model.summary()\n    \n    return model","2593e11e":"#compile\nmodel_rmsprop = get_model()\nmodel_rmsprop.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc',f1_m])\nhist_rmsprop = model_rmsprop.fit_generator(\n    train_generator,\n    steps_per_epoch = get_steps(nb_train_samples, batch_size),\n    epochs=epochs,\n    validation_data = validation_generator,\n    validation_steps = get_steps(nb_validation_samples, batch_size),\n    callbacks = callbacks_list\n)","853f384b":"#compile\nmodel_adam = get_model()\nmodel_adam.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['acc',f1_m])\nhist_adam = model_adam.fit_generator(\n    train_generator,\n    steps_per_epoch = get_steps(nb_train_samples, batch_size),\n    epochs=epochs,\n    validation_data = validation_generator,\n    validation_steps = get_steps(nb_validation_samples, batch_size),\n    callbacks = callbacks_list\n)","1e07d43d":"#compile\nmodel_nadam = get_model()\nmodel_nadam.compile(loss='categorical_crossentropy', optimizer=Nadam(), metrics=['acc',f1_m])\nhist_nadam = model_nadam.fit_generator(\n    train_generator,\n    steps_per_epoch = get_steps(nb_train_samples, batch_size),\n    epochs=epochs,\n    validation_data = validation_generator,\n    validation_steps = get_steps(nb_validation_samples, batch_size),\n    callbacks = callbacks_list\n)","8421de6a":"#compile\nmodel_sgd = get_model()\nmodel_sgd.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc',f1_m])\nhist_sgd = model_sgd.fit_generator(\n    train_generator,\n    steps_per_epoch = get_steps(nb_train_samples, batch_size),\n    epochs=epochs,\n    validation_data = validation_generator,\n    validation_steps = get_steps(nb_validation_samples, batch_size),\n    callbacks = callbacks_list\n)","201e6df5":"#compile\nmodel_sgdnes = get_model()\nmodel_sgdnes.compile(loss='categorical_crossentropy', optimizer=SGD(nesterov=True), metrics=['acc',f1_m])\nhist_sgdnes = model_sgdnes.fit_generator(\n    train_generator,\n    steps_per_epoch = get_steps(nb_train_samples, batch_size),\n    epochs=epochs,\n    validation_data = validation_generator,\n    validation_steps = get_steps(nb_validation_samples, batch_size),\n    callbacks = callbacks_list\n)","a8f2f16b":"#compile\nmodel_sgdmo = get_model()\nmodel_sgdmo.compile(loss='categorical_crossentropy', optimizer=SGD(momentum=0.9), metrics=['acc',f1_m])\nhist_sgdmo = model_sgdmo.fit_generator(\n    train_generator,\n    steps_per_epoch = get_steps(nb_train_samples, batch_size),\n    epochs=epochs,\n    validation_data = validation_generator,\n    validation_steps = get_steps(nb_validation_samples, batch_size),\n    callbacks = callbacks_list\n)","4c499c98":"#compile\nmodel_sgdmones = get_model()\nmodel_sgdmones.compile(loss='categorical_crossentropy', optimizer=SGD(momentum=0.9, nesterov=True), metrics=['acc',f1_m])\nhist_sgdmones  = model_sgdmones.fit_generator(\n    train_generator,\n    steps_per_epoch = get_steps(nb_train_samples, batch_size),\n    epochs=epochs,\n    validation_data = validation_generator,\n    validation_steps = get_steps(nb_validation_samples, batch_size),\n    callbacks = callbacks_list\n)","08567fa2":"plt.figure(figsize=(10, 6))  \n\nplt.plot(hist_rmsprop.history['acc'])  \nplt.plot(hist_adam.history['acc'])  \nplt.plot(hist_nadam.history['acc']) \nplt.plot(hist_sgd.history['acc']) \nplt.plot(hist_sgdnes.history['acc']) \nplt.plot(hist_sgdmo.history['acc'])\nplt.plot(hist_sgdmones.history['acc'])\nplt.title('train. accuracy')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')  \nplt.legend(['rmsprop', 'adam', 'nadam', 'sgd', 'sgd+nesterov', 'sgd+momentum', 'sgd+nesterov+momentum'], loc='lower right')  \n\nplt.show()","2f83af37":"plt.figure(figsize=(10, 6))  \n\nplt.plot(hist_rmsprop.history['loss'])  \nplt.plot(hist_adam.history['loss'])  \nplt.plot(hist_nadam.history['loss']) \nplt.plot(hist_sgd.history['loss']) \nplt.plot(hist_sgdnes.history['loss']) \nplt.plot(hist_sgdmo.history['loss'])\nplt.plot(hist_sgdmones.history['loss'])\nplt.title('train. loss')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')  \nplt.legend(['rmsprop', 'adam', 'nadam', 'sgd', 'sgd+nesterov', 'sgd+momentum', 'sgd+nesterov+momentum'], loc='upper right')  \n\nplt.show()","550a9fa2":"plt.figure(figsize=(10, 6))  \n\nplt.plot(hist_rmsprop.history['val_acc'])\nplt.plot(hist_adam.history['val_acc'])\nplt.plot(hist_nadam.history['val_acc'])\nplt.plot(hist_sgd.history['val_acc'])\nplt.plot(hist_sgdnes.history['val_acc'])\nplt.plot(hist_sgdmo.history['val_acc'])\nplt.plot(hist_sgdmones.history['val_acc'])\n\nplt.title('valid. accuracy')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')  \nplt.legend(['rmsprop', 'adam', 'nadam', 'sgd', 'sgd+nesterov', 'sgd+momentum', 'sgd+nesterov+momentum'], loc='lower right')  \n\nplt.show()","92b27f98":"plt.figure(figsize=(10, 6))  \n\nplt.plot(hist_rmsprop.history['val_loss'])  \nplt.plot(hist_adam.history['val_loss'])  \nplt.plot(hist_nadam.history['val_loss']) \nplt.plot(hist_sgd.history['val_loss']) \nplt.plot(hist_sgdnes.history['val_loss']) \nplt.plot(hist_sgdmo.history['val_loss'])\nplt.plot(hist_sgdmones.history['val_loss'])\nplt.title('valid. loss')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')  \nplt.legend(['rmsprop', 'adam', 'nadam', 'sgd', 'sgd+nesterov', 'sgd+momentum', 'sgd+nesterov+momentum'], loc='upper right')  \n\nplt.show()","37947423":"plt.figure(figsize=(10, 6))  \n\nplt.plot(hist_rmsprop.history['f1_m'])  \nplt.plot(hist_adam.history['f1_m'])  \nplt.plot(hist_nadam.history['f1_m']) \nplt.plot(hist_sgd.history['f1_m']) \nplt.plot(hist_sgdnes.history['f1_m']) \nplt.plot(hist_sgdmo.history['f1_m'])\nplt.plot(hist_sgdmones.history['f1_m'])\nplt.title('train. f1_score')  \nplt.ylabel('f1_score')  \nplt.xlabel('epoch')  \nplt.legend(['rmsprop', 'adam', 'nadam', 'sgd', 'sgd+nesterov', 'sgd+momentum', 'sgd+nesterov+momentum'], loc='upper right')  \n\nplt.show()","76f0a77e":"plt.figure(figsize=(10, 6))  \n\nplt.plot(hist_rmsprop.history['val_f1_m'])  \nplt.plot(hist_adam.history['val_f1_m'])  \nplt.plot(hist_nadam.history['val_f1_m']) \nplt.plot(hist_sgd.history['val_f1_m']) \nplt.plot(hist_sgdnes.history['val_f1_m']) \nplt.plot(hist_sgdmo.history['val_f1_m'])\nplt.plot(hist_sgdmones.history['val_f1_m'])\nplt.title('valid. f1_score')  \nplt.ylabel('f1_score')  \nplt.xlabel('epoch')  \nplt.legend(['rmsprop', 'adam', 'nadam', 'sgd', 'sgd+nesterov', 'sgd+momentum', 'sgd+nesterov+momentum'], loc='upper right')  \n\nplt.show()","1ec5e9cd":"### Optimizer 3: Nadam","224d0f19":"# File Directory Setting","577bc5bd":"### valid loss","014c1c4b":"# <center>3rd ML Month - Compare optimizer of efficientNet <\/center>","2c0c9d60":"# Package","3fc461bb":"### Optimizer 5: SGD + Nesterov","461e3da0":"# \uacb0\ub860\n-  'sgd', 'sgd+nesterov' \ub294 \ub108\ubb34 \ub2a6\uac8c \uc218\ub834\ud558\uc5ec comp\uc5d0 \uc801\uc808\ud55c optimizer\ub294 \uc544\ub2cc\uac83 \uac19\uc2b5\ub2c8\ub2e4.\n-  'rmsprop', 'adam'\uc774 \ube44\uad50\uc801\uc73c\ub85c \ube60\ub978 \uc2dc\uac04\uc548\uc5d0 \ub192\uc740 acc\uc5d0 \ub3c4\ub2ec\ud569\ub2c8\ub2e4.","5fbe8853":"# acc \/ loss Plot","5a7f3a13":"### Optimizer 7: SGD + Nesterov with momentum=0.9","8b0d2c9a":"### train acc","5b162e9e":"# Model","deb355be":"### train f1 score","7600d918":"### valid f1 score","9e24254e":"### Optimizer 6: SGD with momentum=0.9","70a13701":"# train\/test data Split","c7e8cac2":"### Optimizer 2: Adam","1527dd38":"### Optimizer 4: SGD","0274522e":"### Optimizer 1: RMSprop","aa7341bd":"### valid acc","ea8c37c9":"# Reference\n- https:\/\/shaoanlu.wordpress.com\/2017\/05\/29\/sgd-all-which-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment\/\n- \ucee4\ub110 \uc2dc\uac04\uc81c\ud55c\uc73c\ub85c EarlyStopping \uc124\uc815, \ub3d9\uc77c epoch \ube44\uad50 X","5787c097":"### train loss","21e978b0":"# Parameter"}}