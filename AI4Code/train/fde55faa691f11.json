{"cell_type":{"9df0bce8":"code","149d76e0":"code","928b0a81":"code","e5ff5657":"code","900bbe97":"code","ac73a7fa":"code","9cd1426e":"code","65ea5978":"code","3d87df70":"code","b8417513":"code","7ea39f5a":"code","c99818c5":"code","a97da9a9":"code","a088eaa0":"code","17b97087":"code","68b542c6":"code","2485a413":"code","02c25b87":"code","32adbadc":"code","fe99f2cc":"code","eb13c65d":"code","aecba093":"code","ecb0591d":"code","49ff0610":"code","f930cfe7":"code","82bf20b6":"code","af5369aa":"code","6dec429e":"code","9c49c2f4":"code","ce04b1c3":"code","923a6b57":"code","86c81c68":"code","2695347b":"code","33d6c618":"code","1496e754":"code","192c5cf6":"code","5cab539e":"code","5c217f3e":"code","a3bc8eef":"code","49982bbb":"code","01f7b8cc":"code","d530de7e":"code","de9a5dcf":"code","2de0c1a6":"code","dd780c78":"code","60a76578":"code","80a23344":"code","3cd45812":"code","484e1108":"code","b58f18e6":"code","6397dead":"code","e96947c3":"code","6bd27084":"code","15710d7b":"code","c1658431":"code","d0a40908":"code","c85abd1e":"code","683f68fe":"code","890f8fd7":"code","053799b5":"markdown","35b39f98":"markdown","85bff5f6":"markdown","d5b59684":"markdown","ad608232":"markdown","468ebeca":"markdown"},"source":{"9df0bce8":"import pandas as pd\nimport numpy as np","149d76e0":"df_2010_2011 = pd.read_excel(\"..\/input\/online-retail-data-set-from-uci-ml-repo\/Online Retail.xlsx\")","928b0a81":"df = df_2010_2011.copy()","e5ff5657":"df.head()#first five","900bbe97":"df.nunique()#number of unique values in each column","ac73a7fa":"df[\"Description\"].value_counts()#shows that which product is found how many times in the dataframe.","9cd1426e":"df.groupby(\"Description\").agg({\"Quantity\":\"count\"}).sort_values(\"Quantity\",ascending=False)\n#which product had been bought how many times","65ea5978":"df[\"InvoiceNo\"].nunique()#Unique values in Invoice column","3d87df70":"df[\"TotalPrice\"] = df[\"Quantity\"]*df[\"UnitPrice\"]\n#creates a new column which is called TotalPrice. Multiplies Quantity and Price values for each row.","b8417513":"df.head()","7ea39f5a":"df.groupby(\"InvoiceNo\").agg({\"TotalPrice\":\"sum\"}).head()#Shows total price of each invoice.","c99818c5":"df.sort_values(\"UnitPrice\", ascending = False).head()#Sort price column. (higher to lower)","a97da9a9":"df[\"Country\"].value_counts()#Which country ordered how many times?","a088eaa0":"df.groupby(\"Country\").agg({\"TotalPrice\":\"sum\"}).sort_values(\"TotalPrice\", ascending = False).head()\n#Sorts each country's sum of TotalPrice.","17b97087":"df.isnull().sum()#Sums null values of each columns.","68b542c6":"df.dropna(inplace = True)#drops null values from dataframe","2485a413":"df.shape# (rows, columns)","02c25b87":"df.describe([0.01,0.05,0.10,0.25,0.50,0.75,0.90,0.95, 0.99]).T #descriptive statistics of dataframe","32adbadc":"for feature in [\"Quantity\",\"UnitPrice\",\"TotalPrice\"]:\n\n    Q1 = df[feature].quantile(0.01)\n    Q3 = df[feature].quantile(0.99)\n    IQR = Q3-Q1\n    upper = Q3 + 1.5*IQR\n    lower = Q1 - 1.5*IQR\n\n    if df[(df[feature] > upper) | (df[feature] < lower)].any(axis=None):\n        print(feature,\"yes\")\n        print(df[(df[feature] > upper) | (df[feature] < lower)].shape[0])\n    else:\n        print(feature, \"no\")\n        \n#To recognize if there is any outlier values. There are some outliers.","fe99f2cc":"df.head()","eb13c65d":"df.info() # info of dataframe. There is not any null values. I have dropped them above.","aecba093":"df[\"InvoiceDate\"].min()#oldest invoice date in the dataframe","ecb0591d":"df[\"InvoiceDate\"].max()#newest invoice date in the dataframe","49ff0610":"import datetime as dt # imports datetime library","f930cfe7":"today = dt.datetime(2011,12,9)\n# I assigned today's date. Suppose that today's date is 2011-12-09","82bf20b6":"today","af5369aa":"df.head()","6dec429e":"df[\"CustomerID\"] = df[\"CustomerID\"].astype(int)# converts customer id float to int (17850.0 -> 17850)","9c49c2f4":"df.head()","ce04b1c3":"temp_df = (today - df.groupby(\"CustomerID\").agg({\"InvoiceDate\":\"max\"}))\n#For rfm analysis, I need Customer ID and InvoiceDate. So I make a subtraction (today's date - InvoiceDate)","923a6b57":"temp_df","86c81c68":"temp_df.rename(columns={\"InvoiceDate\":\"Recency\"},inplace=True)\n#InvoiceDate column is Recency column anymore. Because it shows the recency value.","2695347b":"recency_df = temp_df[\"Recency\"].apply(lambda x: x.days)\n#takes the day value. I don't need hour and strings","33d6c618":"recency_df.head()","1496e754":"temp_df = df.groupby([\"CustomerID\",\"InvoiceNo\"]).agg({\"InvoiceNo\":\"count\"})\n#finding frequency value of each customer. Lists invoices and counts them","192c5cf6":"temp_df.head()","5cab539e":"freq_df = temp_df.groupby(\"CustomerID\").agg({\"InvoiceNo\":\"count\"})#counts all invoices for each customer","5c217f3e":"freq_df","a3bc8eef":"freq_df.rename(columns={\"InvoiceNo\":\"Frequency\"},inplace = True)#changes column name (Invoice -> Frequency)","49982bbb":"freq_df","01f7b8cc":"monetary_df = df.groupby(\"CustomerID\").agg({\"TotalPrice\":\"sum\"})#shows each customer's total spendings","d530de7e":"monetary_df.head()","de9a5dcf":"monetary_df.rename(columns={\"TotalPrice\":\"Monetary\"},inplace=True)#changes column name (TotalPrice -> Monetary)","2de0c1a6":"monetary_df.head()","dd780c78":"print(recency_df.shape,freq_df.shape,monetary_df.shape)#shape of each dataframes","60a76578":"rfm = pd.concat([recency_df,freq_df,monetary_df],axis=1)#concatenate recency,frequency and monetary dataframes.","80a23344":"rfm","3cd45812":"rfm[\"Recency Score\"] = pd.qcut(rfm[\"Recency\"],5,labels = [5,4,3,2,1])\n#Divides all recency scores to 5 part. If recency(days) gets higher, recency score will be decreased.","484e1108":"rfm[\"Frequency Score\"] = pd.qcut(rfm[\"Frequency\"].rank(method=\"first\"),5,labels = [1,2,3,4,5])\n#Divides all frequency scores to 5 part. If frequency gets higher,frequency score will be increased.","b58f18e6":"rfm[\"Monetary Score\"] = pd.qcut(rfm[\"Monetary\"],5,labels = [1,2,3,4,5])\n#Divides all monetary scores to 5 part. If monetary(spendings) gets higher, monetary score will be increased.","6397dead":"rfm.head()","e96947c3":"rfm[\"Recency Score\"].astype(str) + rfm[\"Frequency Score\"].astype(str) + rfm[\"Monetary Score\"].astype(str)\n#sums these scores as a string. (e.g. 1 + 3 + 2 = 132 this is the RFM score)","6bd27084":"rfm[\"RFM SCORE\"] = rfm[\"Recency Score\"].astype(str) + rfm[\"Frequency Score\"].astype(str) + rfm[\"Monetary Score\"].astype(str)\n#adds RFM score as a column.","15710d7b":"rfm.head()","c1658431":"rfm.describe()#descriptive stats of rfm","d0a40908":"seg_map = {\n    r'[1-2][1-2]': 'Hibernating',\n    r'[1-2][3-4]': 'At Risk',\n    r'[1-2]5': 'Can\\'t Loose',\n    r'3[1-2]': 'About to Sleep',\n    r'33': 'Need Attention',\n    r'[3-4][4-5]': 'Loyal Customers',\n    r'41': 'Promising',\n    r'51': 'New Customers',\n    r'[4-5][2-3]': 'Potential Loyalists',\n    r'5[4-5]': 'Champions'\n}\n#prepare the rfm table with respect to recency-frequency grid.","c85abd1e":"rfm['Segment'] = rfm['Recency Score'].astype(str) + rfm['Frequency Score'].astype(str)\nrfm['Segment'] = rfm['Segment'].replace(seg_map, regex=True)\n#creates segment column and gives the customer's segment according to RFM score.\n\nrfm.head()","683f68fe":"rfm.groupby(\"Segment\").agg([\"count\",\"mean\",\"std\",\"min\",\"median\",\"max\"])\n#count, mean, std, min, median, max values for segments","890f8fd7":"rfm[rfm[\"Segment\"] == \"Need Attention\"]\n#shows Need Attention segment's customers","053799b5":"# RFM Table","35b39f98":"## Frequency","85bff5f6":"## Recency","d5b59684":"# RFM","ad608232":"## MONETARY","468ebeca":"# Data Preparation"}}