{"cell_type":{"ff16377b":"code","a6ab59a2":"code","ec328f52":"code","20118742":"code","a58aa350":"code","0320b998":"code","f80c943d":"code","2723281e":"code","58ce966e":"code","daa44d3d":"code","7ae2b1da":"code","6469841a":"code","1497b14a":"code","2d2ccb9c":"code","b8ad90b4":"code","0518df5f":"code","42224a7f":"code","b6dd92e3":"code","5113e36f":"code","25e75974":"code","e5affb65":"code","19f30f75":"code","4d0e8d79":"code","8a1b3ff1":"code","d00e07b4":"code","e4ee967c":"code","98f4771b":"code","5e6ff693":"code","dc2b3640":"markdown","66b5a642":"markdown","61b93042":"markdown","27c25121":"markdown","c34be424":"markdown","936c5d00":"markdown","8c8edfb1":"markdown","3225b6a1":"markdown","90e2ff7d":"markdown","0051e8c3":"markdown","bc24d184":"markdown","4a8cc6c5":"markdown","b580cd92":"markdown"},"source":{"ff16377b":"#Importing required libraries\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n%matplotlib inline ","a6ab59a2":"#Reading training and testing data as dataframes\ntrain_df = pd.read_csv(\"\/kaggle\/input\/banking-dataset-marketing-targets\/train.csv\",sep =\";\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/banking-dataset-marketing-targets\/test.csv\", sep =\";\")\ntrain_df.head()","ec328f52":"#Dimensions of dataset\ntrain_df.shape","20118742":"#Information about the data types of features\ntrain_df.info()","a58aa350":"#Statistical summary of training dataset\ntrain_df.describe(include ='all')","0320b998":"#Checking if there are any missing values\ntrain_df.isnull().sum()","f80c943d":"sns.countplot(x=\"education\",data=train_df, hue = \"y\")\nplt.title(\"Education type vs Count\")","2723281e":"sns.countplot(x=\"marital\", data = train_df)\nplt.title(\"Martial Status vs Count\")","58ce966e":"sns.countplot(x=\"job\", data = train_df, hue =\"y\")\nplt.title(\"Job vs Count\")\nplt.xticks(rotation=90)","daa44d3d":"sns.countplot(x=\"loan\", data = train_df, hue =\"y\")\nplt.title(\"personal loan vs Count\")","7ae2b1da":"sns.countplot(x=\"housing\", data = train_df, hue =\"y\")\nplt.title(\"housing loan vs Count\")","6469841a":"sns.countplot(x=\"contact\", data = train_df, hue =\"y\")\nplt.title(\"Contact vs Count\")","1497b14a":"correlation_matrix = train_df.corr()\nsns.heatmap(correlation_matrix, annot =True)","2d2ccb9c":"#Combining training and testing data for the purpose of encoding\ndf = pd.concat([train_df,test_df], ignore_index=True)\ndf.shape","b8ad90b4":"df = pd.get_dummies(df,columns = ['job','marital','education','default','housing','month','loan','contact','poutcome'], drop_first = True)\ndf.head()","0518df5f":"df['y'].replace('yes', 1, inplace=True)\ndf['y'].replace('no', 0, inplace=True)\ndf.head()","42224a7f":"target = df['y']\ndf = df.drop('y',axis = 1)\ncolumns = df.columns\nscaler = MinMaxScaler()\ndf = scaler.fit_transform(df)\ndf = pd.DataFrame(df,columns=[columns])\ndf.head()","b6dd92e3":"y = np.array(target)\nX = df\n\n#Splitting the data into train and test data\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25, random_state = 20)","5113e36f":"#Initializing and fitting the logistic regression model\nlr_model = LogisticRegression(max_iter=125)\nlr_model.fit(X_train,y_train)\ny_pred = lr_model.predict(X_test)","25e75974":"print(confusion_matrix(y_test, y_pred))","e5affb65":"print(classification_report(y_test, y_pred))","19f30f75":"clf = SVC(kernel = 'linear')\nclf.fit(X_train, y_train)\ny_pred_svc = clf.predict(X_test)","4d0e8d79":"print(classification_report(y_test, y_pred_svc))","8a1b3ff1":"#Checkig for imbalances in the classes\ny = np.bincount(y_train)\ni = np.nonzero(y)[0]\nnp.vstack((i,y[i])).T","d00e07b4":"#Applying SMOTE on the trainingg data\nsm = SMOTE(random_state = 12)\nX_train_smote, y_train_smote = sm.fit_sample(X_train,y_train)","e4ee967c":"#Checking for imbalances in the training data\ny = np.bincount(y_train_smote)\ni = np.nonzero(y)[0]\nnp.vstack((i,y[i])).T","98f4771b":"#Logistic regression on new oversampled data\nlr_model = LogisticRegression(max_iter = 200)\nlr_model.fit(X_train_smote,y_train_smote)\ny_pred_smote = lr_model.predict(X_test)","5e6ff693":"print(classification_report(y_test, y_pred_smote))","dc2b3640":"# Data Profiling","66b5a642":"* It seems like more number of married people invested in Term deposits","61b93042":"Predicting whether the client will subscribe to Term deposit or not","27c25121":"# Feature Encoding","c34be424":"The accuracy of the logistic regression model is 90%","936c5d00":"The accuracy of the SVC model is 89%. But in both logistic regression and SVC, the recall value for class 1 is very less. Its due to imbalances in the classes. To overcome this issue, lets apply SMOTE technique to the training dataset.","8c8edfb1":"# Analysis","3225b6a1":"* It seems like more number of people working in management profiles have subscribed to term deposits","90e2ff7d":"Lets try with Support Vector Machine","0051e8c3":"* There is no multicollinearity between independent variables","bc24d184":"After applyting SMOTE, the class distribution is balanced","4a8cc6c5":"The accuracy of the logistic regression model is 84%. And also the recall value is higher for both the classes after applying SMOTE tecnique","b580cd92":"# SMOTE for oversampling minority class"}}