{"cell_type":{"6eb22f05":"code","3e84a8c2":"code","77d3d466":"code","648fe8fb":"code","28d9f482":"code","32bb26ee":"code","23e648c1":"code","d8b353fe":"code","db8c735b":"code","5056d340":"code","4d5b7d42":"code","1eddb7c4":"code","2693f325":"code","9272109a":"code","63851a62":"code","163536e9":"code","f7207f42":"code","d85a113a":"code","921f1b9d":"code","e0a1d6cb":"code","3dd9166c":"code","24aab386":"code","6dbcf196":"code","092c44cd":"code","7f78282f":"code","befe3bc6":"code","47ef5e18":"code","569a746c":"code","b0d23abe":"code","b54decc6":"code","7987bba6":"code","8043bbb7":"code","9e8581c2":"code","c73affd1":"code","5797fc32":"code","d36f9714":"code","323fd90b":"code","cd81a218":"code","63faebe2":"markdown","34a261c3":"markdown","c31de80e":"markdown","ad21cf70":"markdown","0785c9a7":"markdown","66fd2079":"markdown","d22cab02":"markdown","2703bbe3":"markdown","9cf93917":"markdown"},"source":{"6eb22f05":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb","3e84a8c2":"true=pd.read_csv(\"..\/input\/fake-and-real-news-dataset\/True.csv\")","77d3d466":"fake=pd.read_csv(\"..\/input\/fake-and-real-news-dataset\/Fake.csv\")","648fe8fb":"len(fake),len(true)","28d9f482":"true[\"category\"]=1\nfake[\"category\"]=0","32bb26ee":"data=pd.concat([true,fake])","23e648c1":"data[\"category\"].value_counts()","d8b353fe":"data.head()","db8c735b":"data.isnull().sum()","5056d340":"data.info()","4d5b7d42":"plt.figure(figsize =(15,10))\nsb.countplot(data['subject'])","1eddb7c4":"\ndata['fulltext'] = data.title + ' ' + data.text\ndata.drop(['title','text'], axis=1, inplace=True)","2693f325":"final = data[['fulltext', 'category']]\nfinal = data.reset_index()\nfinal.drop(['index'], axis=1, inplace=True)\n","9272109a":"import re\ni=0;\nfor sent in final['fulltext'].values:\n    if (len(re.findall('<.*?>', sent))):\n        print(i)\n        print(sent)\n        break;\n    i += 1; ","63851a62":"import string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\nstop = set(stopwords.words('english')) \nsno = nltk.stem.SnowballStemmer('english')\n\ndef cleanhtml(sentence): #function to clean the word of any html-tags\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, ' ', sentence)\n    return cleantext\ndef cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n    cleaned = re.sub(r'[?|!|\\'|\"|#.|,|)|(|\\|\/]',r'',sentence)\n    \n    return  cleaned\nprint(stop)\n","163536e9":"#Code for implementing step-by-step the checks mentioned in the pre-processing phase\n# this code takes a while to run as it needs to run on 500k sentences.\nimport re\ni=0\nstr1=' '\nfinal_string=[]\nall_true_words=[] # store words from +ve reviews here\nall_fake_words=[] # store words from -ve reviews here.\ns=''\nfor sent in final['fulltext'].values:\n    filtered_sentence=[]\n    #print(sent);\n    sent=cleanhtml(sent) # remove HTMl tags\n    for w in sent.split():\n        for cleaned_words in cleanpunc(w).split():\n            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n                if(cleaned_words.lower() not in stop):\n                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n                    filtered_sentence.append(s)\n                    if (final['category'].values)[i] == '1': \n                        all_true_words.append(s) #list of all words used to describe positive reviews\n                    if(final['category'].values)[i] == '0':\n                        all_fake_words.append(s) #list of all words used to describe negative reviews reviews\n                else:\n                    continue\n            else:\n                continue \n    #print(filtered_sentence)\n    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n    #print(\"***********************************************************************\")\n    \n    final_string.append(str1)\n    i+=1","f7207f42":"final['CleanedText']=final_string\nfinal.head(3)","d85a113a":"label=final[\"category\"]","921f1b9d":"sample=final['CleanedText']","e0a1d6cb":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(sample, label, test_size=0.30, random_state=0)","3dd9166c":"from sklearn.metrics import accuracy_score\n##from sklearn.cross_validation import cross_val_score\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sb\nfrom sklearn.metrics import classification_report\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\nimport gensim\nfrom gensim.models import Word2Vec, KeyedVectors\nfrom sklearn.metrics import f1_score","24aab386":"tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\nX_train = tf_idf_vect.fit_transform(X_train)\nX_test= tf_idf_vect.transform(X_test)","6dbcf196":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import cross_val_score\n# Creating alpha values in the range from 10^-4 to 10^4\nneighbors = []\ni = 0.0001\nwhile(i<=10000):\n    neighbors.append(np.round(i,3))\n    i *= 3\n\n\n# empty list that will hold cv scores\ncv_scores = []\n\n# perform 10-fold cross validation\nfor k in neighbors:\n    bn = MultinomialNB(alpha = k)\n    scores = cross_val_score(bn, X_train, Y_train, cv=10, scoring='f1_macro', n_jobs=-1)\n    cv_scores.append(scores.mean())  \n    \n# determining best value of alpha\noptimal_alpha = neighbors[cv_scores.index(max(cv_scores))]\nprint('\\nThe optimal value of alpha is %.3f.' % optimal_alpha)","092c44cd":"# plot f1_score vs alpha \nplt.plot(neighbors, cv_scores)\nplt.xlabel('Value of alpha',size=10)\nplt.ylabel('f1_score',size=10)\nplt.title('f1_score VS Alpha_Value Plot',size=16)\nplt.grid()\nplt.show()\n\nprint(\"\\n\\nAlpha values :\\n\",neighbors)\nprint(\"\\nf1_score for each alpha value is :\\n \", np.round(cv_scores,5))","7f78282f":"# ============================== Multinomial Naive Bayes with alpha = optimal_alpha ============================================\n# instantiate learning model alpha = optimal_alpha\nbn_optimal = MultinomialNB(alpha = optimal_alpha)\n\n# fitting the model\nbn_optimal.fit(X_train, Y_train)\n\n# predict the response\npredictions = bn_optimal.predict(X_test)\n\n# evaluate accuracy\nacc = accuracy_score(Y_test, predictions) * 100\nprint('\\nThe Test Accuracy of the Multinomial naive Bayes classifier for alpha = %.3f is %f%%' % (optimal_alpha, acc))\n\n# Variables that will be used for  making table in Conclusion part of this assignment\ntfidf_multinomial_alpha = optimal_alpha\ntfidf_multinomial_train_acc = max(cv_scores)*100\ntfidf_multinomial_test_acc = acc","befe3bc6":"bn_optimal.classes_","47ef5e18":"# Now we can find log probabilities of different features for both the classes\nclass_features = bn_optimal.feature_log_prob_\n\n#  row_0 is for 'Fake' class and row_1 is for 'True' class\nFake_features = class_features[0]\nTrue_features = class_features[1]\n\n# Getting all feature names\nfeature_names = tf_idf_vect.get_feature_names()\n\n# Sorting 'Fake_features' and 'True_features' in descending order using argsort() function\nsorted_Fake_features = np.argsort(Fake_features)[::-1]\nsorted_True_features = np.argsort(True_features)[::-1]\n\nprint(\"Top 20 Important Features and their log probabilities For Fake News :\\n\\n\")\nfor i in list(sorted_Fake_features[0:20]):\n    print(\"%s\\t -->\\t%f  \"%(feature_names[i],Fake_features[i]))\n    \nprint(\"\\n\\nTop 20 Important Features and their log probabilities For true news :\\n\\n\")\nfor i in list(sorted_True_features[0:20]):\n    print(\"%s\\t -->\\t%f  \"%(feature_names[i],True_features[i]))","569a746c":"\nMNB_f1 = round(f1_score(Y_test, predictions, average='weighted'), 3)\nMNB_accuracy = round((accuracy_score(Y_test, predictions)*100),2)\n\nprint(\"Accuracy : \" , MNB_accuracy , \" %\")\nprint(\"f1_score : \" , MNB_f1)","b0d23abe":"# Code for drawing seaborn heatmaps\nclass_names = ['Fake','True']\ndf_heatmap = pd.DataFrame(confusion_matrix(Y_test, predictions), index=class_names, columns=class_names )\nfig = plt.figure(figsize=(10,7))\nheatmap = sb.heatmap(df_heatmap, annot=True, fmt=\"d\")\n\n# Setting tick labels for heatmap\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nheatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nplt.ylabel('Predicted label',size=18)\nplt.xlabel('True label',size=18)\nplt.title(\"Confusion Matrix\\n\",size=24)\nplt.show()","b54decc6":"%time\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom scipy.stats import randint as sp_randint\n\ndepths=[1,5,50,100]\nestimators=[1,5,50,100]\nclf = RandomForestClassifier()\n\nparams = {'max_depth' : depths,\n          'n_estimators':estimators  \n          }\n\ngrid = GridSearchCV(estimator = clf,param_grid=params ,cv = 2,n_jobs = 3,scoring='roc_auc')\ngrid.fit(X_train, Y_train)\nprint(\"best depth = \", grid.best_params_)\nprint(\"AUC value on train data = \", grid.best_score_*100)\na1 = grid.best_params_","7987bba6":"\noptimal_depth1 = a1.get('max_depth')\noptimal_bases1 = a1.get('n_estimators')","8043bbb7":"clf = RandomForestClassifier(max_depth=optimal_depth1,n_estimators=optimal_bases1) \n\nclf.fit(X_train,Y_train)\n\npred = clf.predict(X_test)\n\n","9e8581c2":"from sklearn import metrics\nfpr, tpr, threshold = metrics.roc_curve(Y_test, pred)\nroc_auc = metrics.auc(fpr, tpr)\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\nprint(\"Best AUC value\")\nprint(roc_auc)","c73affd1":"# Code for drawing seaborn heatmaps\nclass_names = ['Fake','True']\ndf_heatmap = pd.DataFrame(confusion_matrix(Y_test, pred), index=class_names, columns=class_names )\nfig = plt.figure(figsize=(10,7))\nheatmap = sb.heatmap(df_heatmap, annot=True, fmt=\"d\")\n\n# Setting tick labels for heatmap\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nheatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nplt.ylabel('Predicted label',size=18)\nplt.xlabel('True label',size=18)\nplt.title(\"Confusion Matrix\\n\",size=24)\nplt.show()","5797fc32":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import confusion_matrix\nacc1 = accuracy_score(Y_test, pred) * 100\npre1 = precision_score(Y_test, pred) * 100\nrec1 = recall_score(Y_test, pred) * 100\nf11 = f1_score(Y_test, pred) * 100\nprint('\\nAccuracy=%f%%' % (acc1))\nprint('\\nprecision=%f%%' % (pre1))\nprint('\\nrecall=%f%%' % (rec1))\nprint('\\nF1-Score=%f%%' % (f11))","d36f9714":"# Calculate feature importances from decision trees\nimportances = clf.feature_importances_\n\n# Sort feature importances in descending order\nindices = np.argsort(importances)[::-1][:25]\n\n# Rearrange feature names so they match the sorted feature importances\nnames = tf_idf_vect.get_feature_names()\n\nsb.set(rc={'figure.figsize':(11.7,8.27)})\n\n# Create plot\nplt.figure()\n\n# Create plot title\nplt.title(\"Feature Importance\")\n\n# Add bars\nplt.bar(range(25), importances[indices])\n\n# Add feature names as x-axis labels\nnames = np.array(names)\nplt.xticks(range(25), names[indices], rotation=90)\n\n# Show plot\nplt.show()\n# uni_gram.get_feature_names()","323fd90b":"df=names[indices]\nprint(df)","cd81a218":"from wordcloud import WordCloud\n\nwordcloud = WordCloud(width = 800, height = 600,background_color ='white').generate(str(df))\nplt.imshow(wordcloud)\nplt.title(\" Frequent words\")\nplt.show()","63faebe2":"## Train and Test split","34a261c3":"# Data Visualization","c31de80e":"# Thank You ","ad21cf70":"# Ensemble models\n\n","0785c9a7":"# Fake and Real News Prediction","66fd2079":"# Model Creation","d22cab02":"## TFIDF Vectorizer","2703bbe3":"#  Data Preprocessing\n\n## Data Cleaning\n\n.Removing the repeated data.\n\n.Removing Stop-words\n\n.Remove any punctuations or limited set of special characters like , or . or # etc.\n\n.Snowball Stemming the word\n\n.Convert the word to lowercase.","9cf93917":"## Random Forest Classifier"}}