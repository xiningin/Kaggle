{"cell_type":{"d11f2eb7":"code","d37bfbf0":"code","45600af4":"code","645f411f":"code","2f55dfb5":"code","18063e8b":"code","a80e896d":"code","ede46caf":"code","445cf2c5":"code","472b3f10":"code","52524218":"code","403add21":"code","879a2b4f":"markdown","057d686e":"markdown","f63d428a":"markdown","fae9715b":"markdown","6d0c8205":"markdown","0a529533":"markdown","64570f2f":"markdown"},"source":{"d11f2eb7":"# datatable installation with internet\n!pip install datatable==0.11.0 > \/dev\/null\n\nimport numpy as np \nimport pandas as pd \nimport datatable as dt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d37bfbf0":"%%time\ntrain = pd.read_csv(\"..\/input\/g-research-crypto-forecasting\/train.csv\")","45600af4":"train.info()","645f411f":"# writing dataset as pickle\ntrain.to_pickle(\"g_research_crypto_forecasting.pkl.gzip\")\n\n# writing dataset as feather\ntrain.to_feather(\"g_research_crypto_forecasting.feather\")\n\n# writing dataset as parquet\ntrain.to_parquet(\"g_research_crypto_forecasting.parquet\")\n\n# writing dataset as jay\ndt.Frame(train).to_jay(\"g_research_crypto_forecasting.jay\")\n\n# writing dataset as hdf5\ntrain.to_hdf(\"g_research_crypto_forecasting.h5\", \"g_research_crypto_forecasting\")","2f55dfb5":"%%time\ntrain_pickle = pd.read_pickle(\"g_research_crypto_forecasting.pkl.gzip\")","18063e8b":"train_pickle.info()","a80e896d":"%%time\ntrain_feather = pd.read_feather(\"g_research_crypto_forecasting.feather\")","ede46caf":"train_feather.info()","445cf2c5":"%%time\ntrain_parquet = pd.read_parquet(\"g_research_crypto_forecasting.parquet\")","472b3f10":"train_parquet.info()","52524218":"%%time\ntrain_jay = dt.fread(\"g_research_crypto_forecasting.jay\")","403add21":"train_jay.shape","879a2b4f":"### 2.2 Feather","057d686e":"### 2.1 Pickle","f63d428a":"### 2.3 Parquet","fae9715b":"# 2. Reading and timing\nNow let's read each file and time them to see how long it will take for each one.","6d0c8205":"**Reference:**\n\nhttps:\/\/www.kaggle.com\/pedrocouto39\/fast-reading-w-pickle-feather-parquet-jay","0a529533":"# 1. Converting to multiple formatas\nThe formats that will be created are:\n1. *Pickle* - great for object serialization and though it has a slower performance when comparing with other formats, it may work for our porpuse.\n2. *Feather* - is a fast, lightweight, and easy-to-use binary file format for storing data frames.\n3. *Parquet* - compared to a traditional approach where data is stored in row-oriented approach, parquet is more efficient in terms of storage and performance.\n4. *Jay* - also a binary format, that means it is fast, lightweight, and easy-to-use binary file format for storing data frames.","64570f2f":"### 2.4 Jay"}}