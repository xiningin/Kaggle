{"cell_type":{"5911f022":"code","6284d27b":"code","4b91e1fd":"code","df737b23":"code","15201266":"code","4112022c":"code","5f3559b7":"code","40fc087c":"code","162e636f":"code","260b2254":"code","690d95b5":"code","fb40424d":"code","36a1cee3":"code","57b736f7":"code","2067a7f5":"code","e250d50f":"code","dfb83b18":"markdown","99d1a694":"markdown","82c2f50b":"markdown","8327e41a":"markdown","362fd069":"markdown","db87e6b6":"markdown","f2573b3a":"markdown","a520fc77":"markdown","9dccc063":"markdown","2bc1c52a":"markdown","48cf8178":"markdown","4740f743":"markdown","be766e14":"markdown","18e54d90":"markdown"},"source":{"5911f022":"#read the data and show the first 5 rows\nimport pandas as pd\nimport numpy as np\ndf = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")\ndf.head()","6284d27b":"#check for missing values and basic informations\n\ndf.info()","4b91e1fd":"df.describe().T.style.bar(subset=['mean'], color='#205ff2')\\\n                            .background_gradient(subset=['std'], cmap='Reds')\\\n                             .background_gradient(subset=['50%'], cmap='coolwarm')","df737b23":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib as mpl\n%matplotlib inline\n\nplt.figure(figsize = (12,10))\n\nsns.heatmap(df.corr(), annot =True)","15201266":"plt.figure(figsize=(20,15))\nsns.set_theme(style='dark')\nplt.subplot(2,3,1)\nsns.countplot(data=df,x='fbs',hue='target')\nplt.subplot(2,3,2)\nsns.countplot(data=df,x='restecg',hue='target')\nplt.subplot(2,3,3)\nsns.countplot(data=df,x='slope',hue='target')\nplt.subplot(2,3,4)\nsns.countplot(data=df,x='ca',hue='target')\nplt.subplot(2,3,5)\nsns.countplot(data=df,x='exang',hue='target')\nplt.subplot(2,3,6)\nsns.countplot(data=df,x='thal',hue='target')\nplt.show()","4112022c":"df.hist(figsize=(20,16))\nplt.show()","5f3559b7":"\n\nplt.figure(figsize=(13,13))\n\nsns.set_theme(style='darkgrid')\nplt.subplot(2,3,1)\nsns.boxplot(x='thal',data=df)\nplt.subplot(2,3,2)\nsns.boxplot(x='oldpeak',data=df)\nplt.subplot(2,3,3)\nsns.boxplot(x='thalach',data=df)\nplt.subplot(2,3,4)\nsns.boxplot(x='chol',data=df)\nplt.subplot(2,3,5)\nsns.boxplot(x='trestbps',data=df)\nplt.subplot(2,3,6)\nsns.boxplot(x='age',data=df)\nplt.show()","40fc087c":"import plotly.express as px\n\nfig = px.box(df,x = 'trestbps')\nfig.show()","162e636f":"X = df.drop(['target'], axis = 1)\ny = df['target']\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 42)\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","260b2254":"#imports\n\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier, ExtraTreesClassifier\nfrom sklearn.naive_bayes import GaussianNB,BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import RidgeClassifier, LogisticRegression\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score","690d95b5":"models = []\nmodels.append(['RidgeClassifier',RidgeClassifier()])\nmodels.append(['XGBClassifier',XGBClassifier(use_label_encoder=False,objective='binary:logistic',random_state=0,eval_metric='logloss')])\nmodels.append(['Logistic Regression',LogisticRegression(random_state=0)])\nmodels.append(['SVM',SVC(random_state=0)])\nmodels.append(['KNeigbors',KNeighborsClassifier()])\nmodels.append(['GaussianNB',GaussianNB()])\nmodels.append(['BernoulliNB',BernoulliNB()])\nmodels.append(['DecisionTree',DecisionTreeClassifier(random_state=0)])\nmodels.append(['RandomForest',RandomForestClassifier(random_state=0)])\nmodels.append(['AdaBoostClassifier',AdaBoostClassifier()])\nmodels.append(['MLPClassifier',MLPClassifier(random_state = 42, max_iter=1000)])\nmodels.append(['ExtraTreesClassifier',ExtraTreesClassifier()])\nmodels.append(['CatBoostClassifier', CatBoostClassifier(eval_metric = 'AUC', verbose = 0)])\nmodels.append(['GradientBoostingClassifier', GradientBoostingClassifier()])\nmodels.append(['SGDClassifier',SGDClassifier()])","fb40424d":"lst_1 = []\nfor m in range(len(models)):\n    lst_2 = []\n    model = models[m][1]\n    model.fit(X_train,y_train)\n    y_pred = model.predict(X_test)\n    cm = confusion_matrix(y_test,y_pred)\n    accuracies = cross_val_score(estimator= model, X = X_train,y = y_train, cv=10)\n\n# k-fOLD Validation\n    roc = roc_auc_score(y_test,y_pred)\n    \n    print(models[m][0],':')\n    print(cm)\n    print('Accuracy Score: ',accuracy_score(y_test,y_pred))\n    print('')\n    print('K-Fold Validation Mean Accuracy: {:.2f} %'.format(accuracies.mean()*100))\n    print('')\n    print('ROC AUC Score: {:.2f}'.format(roc))\n    print('-'*40)\n    print('')\n    lst_2.append(models[m][0])\n    lst_2.append(accuracy_score(y_test,y_pred)*100)\n    lst_2.append(accuracies.mean()*100)\n    lst_2.append(roc)\n    lst_1.append(lst_2)","36a1cee3":"df2 = pd.DataFrame(lst_1,columns=['Model','Accuracy','K-Fold Mean Accuracy','ROC_AUC'])\n\ndf2.sort_values(by=['ROC_AUC'],inplace=True,ascending=False)\ndf2","57b736f7":"fig = plt.figure(figsize=(12,12))\nsns.barplot(x='ROC_AUC',y='Model',data=df2,color='r')\nplt.title('Model Comparison');","2067a7f5":"grid_models = [\n               (KNeighborsClassifier(),[{'n_neighbors':np.arange(1, 100), 'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski']}]), \n               (DecisionTreeClassifier(),[{'criterion':['gini','entropy'],'max_depth':np.arange(1, 50), 'min_samples_leaf':[1,2,4]}]), \n               (RandomForestClassifier(),[{'n_estimators':[100,150,200],'criterion':['gini','entropy'], 'min_samples_leaf':[2, 10, 30]}]),\n               (MLPClassifier(max_iter = 1000),[{'solver':['lbfgs', 'sgd', 'adam'], 'learning_rate' :['constant', 'invscaling', 'adaptive']}]), \n               (RidgeClassifier(),[{'alpha':[0.1,0.5,1], 'solver':['auto', 'svd', 'cholesky']}]),\n               (GaussianNB(),[{'var_smoothing': np.logspace(0,-9, num=100)}]),\n               (XGBClassifier(use_label_encoder = False), [{'learning_rate': [0.01, 0.05, 0.1], 'eval_metric': ['error', 'logloss']}])\n               ]","e250d50f":"for i,j in grid_models:\n    grid = GridSearchCV(estimator=i,param_grid = j, scoring = 'roc_auc',cv = 5)\n    grid.fit(X_train,y_train)\n    best_score = grid.best_score_\n    best_param = grid.best_params_\n    print(' {}: \\n Best score: {:.1f} %'.format(i,best_score*100))\n    print('')\n    print('-'*25)\n    print('')","dfb83b18":"This is a histogram plot.\n\nThis also depicts the counts of each value of each column.\nHere we can see the imblances in data too.\n\nFor example the fbs column has around 250 zero values, and about 20 one values.\n\n*You get the rest, readers are advised to study each column and make mental notes to get most out of this notebook*","99d1a694":"# Basic Plots","82c2f50b":"![](https:\/\/jumpstartyourheart.org\/wp-content\/uploads\/2018\/11\/penn-research-team-identifies-novel-therapeutic-target-for-heart-disease.jpg)","8327e41a":"**Attribute Information:**\n\nage\n\nsex\n\nchest pain type (4 values)\n\nresting blood pressure\n\nserum cholestoral in mg\/dl\n\nfasting blood sugar > 120 mg\/dl\n\nresting electrocardiographic results (values 0,1,2)\n\nmaximum heart rate achieved\n\nexercise induced angina\n\noldpeak = ST depression induced by exercise relative to rest\n\nthe slope of the peak exercise ST segment\n\nnumber of major vessels (0-3) colored by flourosopy\n\nthal: 3 = normal; 6 = fixed defect; 7 = reversable defect","362fd069":"No NULL values.","db87e6b6":"## Top performing model is KNeighborsClassifier and then Random Forest Classifier.\n\n## Do upvote if you like it or fork it. This motivates us to produce more notebooks for the community. Thank you!","f2573b3a":"Cholesterol has the highest mean value of 246.26 & also he highest standard deviation of 51.83\n","a520fc77":"**Acknowledgements**\nCreators:\n\n**Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.**\n\n**University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.**\n\n**University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.**\n\n**V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D.**\n\n**Donor:\nDavid W. Aha (aha '@' ics.uci.edu) (714) 856-8779**","9dccc063":"# Scaling after train_test_split","2bc1c52a":"This plot depicts an important relationship.\n\n**For example, in the 1st subplot of \"fbs\", it says that when fbs is zero, the target value zero is about 120 and target value 1 is 140, again when fbs is one, the target value for zero is about 20 and target value for one is just above 20.**\n\n*You get the rest*","48cf8178":"slope and old peak has high negative correlation of -0.58. This means if slope value increases then old peak will decrease and vice versa.\n\nTarget and cp(chest pain) has the highest positive correlation of 0.43.","4740f743":"A clear representation of box plot for \"trestbps\"\n\nHere the median value is 130, quartile 1 is 120, quartile 3 is 140, max = 170, min = 94, max outlier value is 200","be766e14":"# Applying diiferent models","18e54d90":"The middle line in boxplot represents median value, the dots outside represents outliers"}}