{"cell_type":{"6aa9806a":"code","9636d8e8":"code","277ce65d":"code","3a0bbed5":"code","f1e0dbe9":"code","73995cda":"code","c656f609":"code","e8c33673":"code","7a67bf55":"code","40c1b6f6":"code","212ab555":"code","615cc655":"code","13b06915":"code","a5b97e90":"code","e4e3dcb6":"code","95014606":"code","ce681e3b":"code","4c404229":"code","a9f9f2ed":"code","5276f7a5":"code","b2b09fdd":"code","ca65833d":"code","5d4f6f80":"code","b5594967":"code","f87a03fa":"code","1c960fed":"code","3a696f4a":"code","42fb4223":"markdown","c13d0f7c":"markdown","99b7bf96":"markdown"},"source":{"6aa9806a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9636d8e8":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom matplotlib.pyplot import figure\nfrom sklearn.tree import DecisionTreeRegressor","277ce65d":"df = pd.read_csv(\"..\/input\/iris-dataset\/Iris.csv\")\ndf.head()","3a0bbed5":"print(df.shape)","f1e0dbe9":"print(df.info())","73995cda":"df.describe()","c656f609":"df.columns","e8c33673":"df.dtypes","7a67bf55":"#numeric columns from datasets\ndf_numeric_col=df.select_dtypes(include=[np.number])\nnumeric_cols=df_numeric_col.columns.values\nprint(numeric_cols)","40c1b6f6":"#non-numeric columns from datasets \ndf_non_numeric_col=df.select_dtypes(exclude=[np.number])\nnon_numeric_cols=df_non_numeric_col.columns.values\nprint(non_numeric_cols)","212ab555":"df.corr()","615cc655":"sns.heatmap(df.corr())\nplt.show()","13b06915":"#missing data through percentage list method \nfor col in df.columns:\n    pct_missing=np.mean(df[col].isnull())\n    print('{} - {}%'.format(col,round(pct_missing*100)))","a5b97e90":"df['Id'].unique()","e4e3dcb6":"df['SepalLengthCm'].unique()","95014606":"df['SepalWidthCm'].unique()","ce681e3b":"df['PetalLengthCm'].unique()","4c404229":"df['PetalWidthCm'].unique()","a9f9f2ed":"df['Species'].unique()","5276f7a5":"df.hist(figsize=(16,20),bins=50,xlabelsize=8,ylabelsize=8)","b2b09fdd":"for i in range(0, len(df.columns), 5):\n    sns.pairplot(data=df,\n                x_vars=df.columns[i:i+5],\n                y_vars=['PetalLengthCm'])","ca65833d":"plt.figure(figsize=(16,6))\nheatmap= sns.heatmap(df.corr(),vmin=1,vmax=1,annot=True)\nheatmap.set_title('Correlation heatmap ', fontdict={'fontsize':12},pad=12)","5d4f6f80":"sns.set_style(\"whitegrid\")\nsns.boxplot(x='PetalLengthCm',y='Species',data=df)","b5594967":"sns.set_style(\"whitegrid\")\nsns.boxplot(x='SepalLengthCm',y='Species',data=df)","f87a03fa":"sns.set_style(\"whitegrid\")\nsns.boxplot(x='PetalWidthCm',y='Species',data=df)","1c960fed":"sns.set_style(\"whitegrid\")\nsns.boxplot(x='SepalWidthCm',y='Species',data=df)","3a696f4a":"import pandas as pd\nimport numpy as np \nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\ndef printdata():\n    print(\"Dataset Length: \",len(df))\n    print(\"Dataset shape: \",df.shape)\n    \n    #printing dataset observations\n    print(\"dataset: \",df.head())\n    return df\n\n#function to split dataset \ndef splitdataset(df):\n    #seperating target variables \n    x=df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\n    y=df[['Species']]\n         \n    #spliting dataset in test and train dataset \n    x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=100)\n    \n    return x,y,x_train,x_test,y_train,y_test\n\n#function to perform training from gini_index\ndef train_using_gini(x_train,x_test,y_train):\n    #creating classifier object \n    clf_gini=DecisionTreeClassifier(criterion=\"gini\",random_state=100,max_depth=3,min_samples_leaf=5)\n    \n    #performing training \n    clf_gini.fit(x_train,y_train)\n    return clf_gini\n\n#function to perform training with entropy \ndef train_using_entropy(x_train,x_test,y_train):\n    \n    #decision tree with entropy \n    clf_entropy =DecisionTreeClassifier(criterion=\"entropy\",random_state=100,max_depth=3,min_samples_leaf=5)\n    \n    #performing training \n    clf_entropy.fit(x_train,y_train)\n    return clf_entropy\n\ndef prediction(x_test,clf_object):\n    \n    #prediction on test with giniIndex\n    y_pred=clf_object.predict(x_test)\n    print(\"predicted values: \")\n    print(y_pred)\n    return y_pred\n\n#function to calculate accuracy \ndef cal_accuracy(y_test,y_pred):\n    print(\"Confusion matrix: \",\n         confusion_matrix(y_test,y_pred))\n    print(\"accuracy: \",\n         accuracy_score(y_test,y_pred))\n    print(\"report: \",\n         classification_report(y_test,y_pred))\n    \n#driver code\ndef main():\n    \n    #building phase \n    data=df\n    x,y,x_train,x_test,y_train,y_test= splitdataset(df)\n    clf_gini=train_using_gini(x_train,x_test,y_train)\n    \n    #operational phase \n    print(\"results using gini index: \")\n    \n    #prediction using gini \n    y_pred_gini=prediction(x_test,clf_gini)\n    cal_accuracy(y_test,y_pred_gini)\n    \n\n    \n    # Calling main function\nif __name__==\"__main__\":\n    main()\n       ","42fb4223":"**cleaning of data ****","c13d0f7c":"**Decision Tree Classifier****","99b7bf96":"now we will find missing values from data "}}