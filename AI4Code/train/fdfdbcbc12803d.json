{"cell_type":{"3993b06a":"code","a87df689":"code","ada92a1b":"code","ac17b46d":"code","a893e7c3":"code","bd61b150":"code","acffd029":"code","bfd233de":"code","cae94334":"code","77a0500d":"code","fa654b6e":"code","e02dc91c":"code","a52ddb4f":"code","880cddd4":"code","ca749e58":"code","36c8c408":"code","c0d669a5":"code","e90bc18a":"code","dd6e0d95":"code","ccb273c1":"code","b2769dec":"code","b19b6589":"code","c39d78ce":"code","fb029f8e":"code","92240307":"code","3eb1ea39":"code","54215d90":"code","ce92d403":"code","ad2aa15f":"code","9f0e786e":"code","55a73361":"code","9655ebe3":"code","af243b95":"code","27d8af20":"code","915e8018":"code","7b206369":"code","0bf0bb86":"code","a01642ef":"code","0a93a719":"code","29814654":"code","9711d4e0":"code","cd0af598":"code","09f4215a":"code","832a51ec":"code","4bbb7eaf":"code","6ecfffd8":"code","66b9770e":"markdown","2c88ef76":"markdown","0e00f92a":"markdown","bc065fb5":"markdown","ebdc5ab0":"markdown","58106695":"markdown","842c4abd":"markdown","b64f1c4e":"markdown"},"source":{"3993b06a":"# As a first step towards your solution, we need to understand the data and hence we load the same and the libraries required\nimport pandas as pd               # for Data Manipulation\nimport matplotlib.pyplot as plt   # for Visualization\nimport numpy as np                #for Mathematical calculations\nimport seaborn as sns             #for Advanced visualizations","a87df689":"tele = pd.read_csv(\"..\/input\/telcocustomerchurn\/Telco_customer_churn.csv\")","ada92a1b":"tele.info()","ac17b46d":"# As a part of the Data cleansing we check the data for any missing\/ na values\ntele.isna().sum()","a893e7c3":"# Additionally we check the data for any duplicate values, now this can be an optional check depending on the data being used\ntele1 = tele.duplicated()\nsum(tele1)","bd61b150":"# Now we import the label encoder function from scikit learn\nfrom sklearn.preprocessing import LabelEncoder\n\n#creating instance of labelencoder\nlabelencoder=LabelEncoder()\n\nx = tele.iloc[:, [3,6,7,9,10,11,13,14,15,16,17,18,19,20,21,22,23]]   # moving columns neede for encoding into x\nx.isna().sum()       \ny = tele.iloc[:, [0,1,2,4,5,8,12,24,25,26,27,28,29]]     # moving columns which are not needed for encoding into y\n","acffd029":"# We start creating labels for the categorical features for the ease of working on the data,\n# in other words easier for the system or program to understand and interpret\n\nx['Referred a Friend']=labelencoder.fit_transform(x['Referred a Friend'])\nx['Offer']=labelencoder.fit_transform(x['Offer'])\nx['Phone Service']=labelencoder.fit_transform(x['Phone Service'])\nx['Multiple Lines']=labelencoder.fit_transform(x['Multiple Lines'])\nx['Internet Service']=labelencoder.fit_transform(x['Internet Service'])\nx['Internet Type']=labelencoder.fit_transform(x['Internet Type'])\nx['Online Backup']=labelencoder.fit_transform(x['Online Backup'])\nx['Online Security']=labelencoder.fit_transform(x['Online Security'])\nx['Device Protection Plan']=labelencoder.fit_transform(x['Device Protection Plan'])\nx['Premium Tech Support']=labelencoder.fit_transform(x['Premium Tech Support'])\nx['Streaming TV']=labelencoder.fit_transform(x['Streaming TV'])\nx['Streaming Movies']=labelencoder.fit_transform(x['Streaming Movies'])\nx['Streaming Music']=labelencoder.fit_transform(x['Streaming Music'])\nx['Unlimited Data']=labelencoder.fit_transform(x['Unlimited Data'])\nx['Contract']=labelencoder.fit_transform(x['Contract'])\nx['Paperless Billing']=labelencoder.fit_transform(x['Paperless Billing'])\nx['Payment Method']=labelencoder.fit_transform(x['Payment Method'])","bfd233de":"# label encode y ##\ny = pd.DataFrame(y)","cae94334":"# concatenate x and y\ntele_new=pd.concat([x,y],axis=1)\ntele_new.columns\ntele_new.isna().sum()\ntele_new.describe()\ntele_new.info()","77a0500d":"# Univariate and Bivariate analysis on the dataset\nplt.hist(tele[\"Referred a Friend\"])   #Univariate","fa654b6e":"plt.hist(tele[\"Offer\"])","e02dc91c":"plt.hist(tele[\"Phone Service\"])","a52ddb4f":"plt.hist(tele[\"Multiple Lines\"])","880cddd4":"plt.hist(tele[\"Internet Service\"])","ca749e58":"plt.hist(tele[\"Internet Type\"])","36c8c408":"plt.hist(tele[\"Online Security\"])","c0d669a5":"plt.hist(tele[\"Online Backup\"])","e90bc18a":"plt.hist(tele[\"Device Protection Plan\"])","dd6e0d95":"plt.hist(tele[\"Premium Tech Support\"])","ccb273c1":"plt.hist(tele[\"Streaming TV\"])","b2769dec":"plt.hist(tele[\"Streaming Movies\"])","b19b6589":"plt.hist(tele[\"Streaming Music\"])","c39d78ce":"plt.hist(tele[\"Unlimited Data\"])","fb029f8e":"plt.hist(tele[\"Contract\"])","92240307":"plt.hist(tele[\"Paperless Billing\"])","3eb1ea39":"plt.hist(tele[\"Payment Method\"])","54215d90":"plt.hist(tele[\"Number of Referrals\"])","ce92d403":"plt.hist(tele[\"Tenure in Months\"])","ad2aa15f":"plt.hist(tele[\"Avg Monthly Long Distance Charges\"])","9f0e786e":"plt.hist(tele[\"Avg Monthly GB Download\"])","55a73361":"plt.hist(tele[\"Monthly Charge\"])","9655ebe3":"plt.hist(tele[\"Total Charges\"])","af243b95":"plt.hist(tele[\"Total Refunds\"])","27d8af20":"plt.hist(tele[\"Total Extra Data Charges\"])","915e8018":"plt.hist(tele[\"Total Long Distance Charges\"])","7b206369":"plt.hist(tele[\"Total Revenue\"])","0bf0bb86":"plt.scatter(tele[\"Tenure in Months\"], tele[\"Total Revenue\"]);plt.xlabel('Tenure in Months');plt.ylabel('Total Revenue')   #Bivariate","a01642ef":"tele_new.skew(axis = 0, skipna = True)   #skewness","0a93a719":"tele_new.kurtosis(axis = 0, skipna = True)    #kurtosis","29814654":"pip install gower","9711d4e0":"import gower\nfrom scipy.cluster.hierarchy import linkage, fcluster, dendrogram\nimport scipy.cluster.hierarchy as sch \ndm = gower.gower_matrix(tele_new)","cd0af598":"##### linkage using complete method ####takes time\nz = linkage(dm, method='complete')","09f4215a":"# We plot the dendogram to see clearly the clusters formed using the pyplot and help to get the groups\/clusters\nplt.figure(figsize=(15, 8));plt.title('Hierarchical Clustering Dendrogram');plt.xlabel('Index');plt.ylabel('Distance')\nsch.dendrogram(z, leaf_rotation = 0,  leaf_font_size = 5 ) ","832a51ec":"# For creating 3 clusters we define the same\ntele_clust = fcluster(z, 3, criterion='maxclust')","4bbb7eaf":"tele_clust","6ecfffd8":"# We aggregate the mean of each cluster to put the data into cluster perspective\ntele_new.iloc[:, :].groupby(tele_clust).mean()","66b9770e":"**Clustering Problem 2:**\n\nPerform clustering analysis on the telecom data set. The data is a mixture of both categorical and numerical data. It consists of the number of customers who churn out. Derive insights and get possible information on factors that may affect the churn decision. Refer to Telco_customer_churn.xlsx dataset.","2c88ef76":"Looking at the data we note that we have most of the data in the form of category which needs to be changed to work on. \n\nHence we do label encoding for the features to encode the labesl within the features","0e00f92a":"We see that the three cluster were formed and the classification could be inferred as follows:\n\nCluster 1 = These are the customers that are frequent users and take up the offers as well, Internet used by them is moderate to heavy, but take on offers as well. The revenue earned through these is also the best. Hence, these are the customers that are least likely to churn.\n\nCluster 2 = These are the customers that are least on all the criterias whether being using the services, to net usage, and dont take up the offers as well, additionally the revenue earned through them is the least. Hence we infer that these are the ones that churn the most.\n\nCluster 3 = These are the customers that stand in the middle of the two extremes and may or may not churn that frequently.","bc065fb5":"The data is bound to have outliers, but depending on the data we know that not all outliers are to be treated. The data given might require the data for proper interpretation and hence we don't treat the outliers here.","ebdc5ab0":"**Looking into the dendogram we can clearly infer that the plot shows the data being split exhaustively on 3 clusters or group**","58106695":"**Heirarchical Clustering using Gower Distance matrix**\n\nAfter all the analyses we now start with the Heirarchical Clustering procedure which would require us with \nbuilding the dendogram\n\nNow, one of the advantages of hierarchical clustering is that we do not have to specify the number of clusters. \nIn order to determine the optimal number of clusters we plot the dendogram, which is a diagram representation \nof the tree based approach.\n\nThe Gower distance is a metric that measures the dissimilarity of two items with mixed numeric and non-numeric data. Gower distance is also called Gower dissimilarity.\n\nBriefly, to compute the Gower distance between two items you compare each element and compute a term. If the element is numeric, the term is the absolute value of the difference divided by the range. If the element is non-numeric the term is 1 if the elements are different or the term is 0 if the elements are the same. The Gower distance is the average of the terms.","842c4abd":"**Univariate and Bivariate analysis**","b64f1c4e":"**HIERARCHICAL CLUSTERING!!** - Telco_customer_churn dataset\n\nClustering algorithms are unsupervised machine learning algorithms so there is no label associated with data points.\nClustering algorithms look for similarities or dissimilarities among data points so that similar ones can be grouped together.\n\nHierarchical clustering (also called hierarchical cluster analysis or HCA) is a method of cluster analysis which seeks to\nbuild a hierarchy of clusters. Strategies for hierarchical clustering generally fall into two types:\n\n  Agglomerative : This is a \"bottom-up\" approach: each observation starts in its own cluster, and pairs of clusters are merged \n                as one moves up the hierarchy.\n\n  Divisive :      This is a \"top-down\" approach: all observations start in one cluster, and splits are performed recursively as \n                one moves down the hierarchy."}}