{"cell_type":{"fa1cf423":"code","1783628c":"code","94732a41":"code","2c810f7e":"code","1773f9f1":"code","b193d429":"code","09d8c050":"code","147b84d8":"code","e92ec765":"code","240f2317":"code","84a0fe43":"code","dabef35c":"code","1a66e461":"code","376f763b":"code","f02b3e14":"code","f5f03fd8":"code","55367079":"code","88356b53":"code","08e98e55":"code","aa7f6c6e":"code","131322f9":"code","7fe83532":"code","74b3d903":"code","a30eaef5":"code","96078129":"code","f3468f91":"markdown","452512da":"markdown","738b7be7":"markdown","0085d841":"markdown"},"source":{"fa1cf423":"!pip install imutils\n!apt-get install tree","1783628c":"import numpy as np \nfrom tqdm import tqdm\nimport cv2\nimport os\nimport shutil\nimport itertools\nimport imutils\nfrom collections import Counter\n\nimport matplotlib.pyplot as plt\n\n\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input as vgg_preprocess\n\nfrom keras.applications import MobileNet\nfrom keras.applications.mobilenet import preprocess_input as mn_preprocess\n\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_v3 import preprocess_input as in_preprocess\n\nfrom keras import layers, metrics, callbacks\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam, RMSprop\n\n\nRANDOM_SEED = 123","94732a41":"# create new folders\n!mkdir TRAIN TEST VAL TRAIN\/YES TRAIN\/NO TEST\/YES TEST\/NO VAL\/YES VAL\/NO\n!tree -d","2c810f7e":"IMG_PATH = '..\/input\/brain-mri-images-for-brain-tumor-detection\/brain_tumor_dataset\/'\n# split the data by train\/val\/test\nfor CLASS in os.listdir(IMG_PATH):\n    if not CLASS.startswith('.'):\n        IMG_NUM = len(os.listdir(IMG_PATH + CLASS))\n        for (n, FILE_NAME) in enumerate(os.listdir(IMG_PATH + CLASS)):\n            img = IMG_PATH + CLASS + '\/' + FILE_NAME\n            if n < 5:\n                shutil.copy(img, 'TEST\/' + CLASS.upper() + '\/' + FILE_NAME)\n            elif n < 0.8*IMG_NUM:\n                shutil.copy(img, 'TRAIN\/'+ CLASS.upper() + '\/' + FILE_NAME)\n            else:\n                shutil.copy(img, 'VAL\/'+ CLASS.upper() + '\/' + FILE_NAME)","1773f9f1":"def load_data(dir_path, img_size=(100,100)):\n    X = []\n    y = []\n    i = 0\n    labels = dict()\n    for path in tqdm(sorted(os.listdir(dir_path))):\n        if not path.startswith('.'):\n            labels[i] = path\n            for file in os.listdir(dir_path + path):\n                if not file.startswith('.'):\n                    img = cv2.imread(dir_path + path + '\/' + file)\n                    X.append(img)\n                    y.append(i)\n            i += 1\n    X = np.array(X)\n    y = np.array(y)\n    print(f'{len(X)} images loaded from {dir_path} directory.')\n    return X, y, labels\n","b193d429":"TRAIN_DIR = 'TRAIN\/'\nTEST_DIR = 'TEST\/'\nVAL_DIR = 'VAL\/'\nIMG_SIZE = (224,224)\n\n# use predefined function to load the image data into workspace\nX_train, y_train, labels = load_data(TRAIN_DIR, IMG_SIZE)\nX_test, y_test, _ = load_data(TEST_DIR, IMG_SIZE)\nX_val, y_val, _ = load_data(VAL_DIR, IMG_SIZE)","09d8c050":"def plot_samples(X, y, labels_dict, n=50):\n    \"\"\"\n    Creates a gridplot for desired number of images (n) from the specified set\n    \"\"\"\n    for index in range(len(labels_dict)):\n        imgs = X[np.argwhere(y == index)][:n]\n        j = 10\n        i = int(n\/j)\n\n        plt.figure(figsize=(15,6))\n        c = 1\n        for img in imgs:\n            plt.subplot(i,j,c)\n            plt.imshow(img[0])\n\n            plt.xticks([])\n            plt.yticks([])\n            c += 1\n        plt.suptitle('Tumor: {}'.format(labels_dict[index]))\n        plt.show()","147b84d8":"plot_samples(X_train, y_train, labels, 30)","e92ec765":"def crop_imgs(set_name, add_pixels_value=0):\n    \"\"\"\n    Finds the extreme points on the image and crops the rectangular out of them\n    \"\"\"\n    set_new = []\n    for img in set_name:\n        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        gray = cv2.GaussianBlur(gray, (5, 5), 0)\n\n        # threshold the image, then perform a series of erosions +\n        # dilations to remove any small regions of noise\n        thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n        thresh = cv2.erode(thresh, None, iterations=2)\n        thresh = cv2.dilate(thresh, None, iterations=2)\n\n        # find contours in thresholded image, then grab the largest one\n        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        cnts = imutils.grab_contours(cnts)\n        c = max(cnts, key=cv2.contourArea)\n\n        # find the extreme points\n        extLeft = tuple(c[c[:, :, 0].argmin()][0])\n        extRight = tuple(c[c[:, :, 0].argmax()][0])\n        extTop = tuple(c[c[:, :, 1].argmin()][0])\n        extBot = tuple(c[c[:, :, 1].argmax()][0])\n\n        ADD_PIXELS = add_pixels_value\n        new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n        set_new.append(new_img)\n\n    return np.array(set_new)","240f2317":"# apply this for each set\nX_train_crop = crop_imgs(set_name=X_train)\nX_val_crop = crop_imgs(set_name=X_val)\nX_test_crop = crop_imgs(set_name=X_test)","84a0fe43":"plot_samples(X_train_crop, y_train, labels, 30)","dabef35c":"def save_new_images(x_set, y_set, folder_name):\n    i = 0\n    for (img, imclass) in zip(x_set, y_set):\n        if imclass == 0:\n            cv2.imwrite(folder_name+'NO\/'+str(i)+'.jpg', img)\n        else:\n            cv2.imwrite(folder_name+'YES\/'+str(i)+'.jpg', img)\n        i += 1\n","1a66e461":"!mkdir TRAIN_CROP TEST_CROP VAL_CROP TRAIN_CROP\/YES TRAIN_CROP\/NO TEST_CROP\/YES TEST_CROP\/NO VAL_CROP\/YES VAL_CROP\/NO\n\nsave_new_images(X_train_crop, y_train, folder_name='TRAIN_CROP\/')\nsave_new_images(X_val_crop, y_val, folder_name='VAL_CROP\/')\nsave_new_images(X_test_crop, y_test, folder_name='TEST_CROP\/')","376f763b":"TRAIN_DIR = 'TRAIN_CROP\/'\nVAL_DIR = 'VAL_CROP\/'\ndef get_generators(preprocess_funct, train_dir, val_dir):\n    train_datagen = ImageDataGenerator(\n        rotation_range=15,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        shear_range=0.1,\n        brightness_range=[0.5, 1.5],\n        horizontal_flip=True,\n        vertical_flip=True,\n        preprocessing_function=preprocess_funct\n    )\n\n    test_datagen = ImageDataGenerator(\n        preprocessing_function=preprocess_funct\n    )\n\n\n    train_generator = train_datagen.flow_from_directory(\n        train_dir,\n        color_mode='rgb',\n        target_size=IMG_SIZE,\n        batch_size=32,\n        class_mode='binary',\n        seed=RANDOM_SEED\n    )\n\n\n    validation_generator = test_datagen.flow_from_directory(\n        val_dir,\n        color_mode='rgb',\n        target_size=IMG_SIZE,\n        batch_size=16,\n        class_mode='binary',\n        seed=RANDOM_SEED\n    )\n    return train_generator, validation_generator","f02b3e14":"def model_performance(history):\n# plot model performance\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    epochs_range = range(1, len(history.epoch) + 1)\n\n    plt.figure(figsize=(15,5))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, acc, label='Train Set')\n    plt.plot(epochs_range, val_acc, label='Val Set')\n    plt.legend(loc=\"best\")\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title('Model Accuracy')\n    plt.tight_layout()\n    plt.show()","f5f03fd8":"def get_model(base, res):\n    if base ==\"VGG16\":\n        vgg16_weight_path = '..\/input\/keras-pretrained-models\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n        base_model = VGG16(\n            weights=vgg16_weight_path,\n            include_top=False, \n            input_shape=res + (3,)\n        )\n    elif base == \"MobileNet\":\n        base_model = MobileNet(\n            weights='imagenet',\n            include_top=False, \n            input_shape=res + (3,)\n        )\n        \n    elif base == \"Inception\":\n        inceptionv3_weight_path = '..\/input\/keras-pretrained-models\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n        base_model = InceptionV3(\n            weights= inceptionv3_weight_path,\n            include_top=False, \n            input_shape=res + (3,)\n        )\n        \n    NUM_CLASSES = 1\n\n    model = Sequential()\n    model.add(base_model)\n    model.add(layers.Flatten())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(NUM_CLASSES, activation='sigmoid'))\n\n    model.layers[0].trainable = False\n\n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=RMSprop(lr=1e-4),\n        metrics=['accuracy']\n    )\n\n    model.summary()\n    return model","55367079":"def train_model(epochs, model, train_generator, validation_generator):\n    es = callbacks.EarlyStopping(\n        monitor='val_acc', \n        mode='max',\n        patience=6\n    )\n\n    history = model.fit_generator(\n        train_generator,\n        epochs=epochs,\n        validation_data=validation_generator,\n        callbacks=[es]\n    )\n    return history","88356b53":"def plot_roc(model, y_val, y_pred):\n    y_pred_prob = y_pred\n    y_true = y_val\n\n    fp, tp, _ = roc_curve(y_true, y_pred_prob)\n\n    plt.plot(fp, tp, label='ROC', linewidth=3)\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.plot(\n      [0, 1], [0, 1], \n      linestyle='--', \n      linewidth=2, \n      color='r',\n      label='Chance', \n      alpha=.8\n    )\n    plt.grid(True)\n    ax = plt.gca()\n    ax.set_aspect('equal')\n    plt.legend(loc=\"lower right\")","08e98e55":"def preprocess_imgs(preprocess_input,set_name, img_size):\n    \"\"\"\n    Resize and apply VGG-15 preprocessing\n    \"\"\"\n    set_new = []\n    for img in set_name:\n        img = cv2.resize(\n            img,\n            dsize=img_size,\n            interpolation=cv2.INTER_CUBIC\n        )\n        set_new.append(preprocess_input(img))\n    return np.array(set_new)","aa7f6c6e":"res = (224,224)\ntrain_generator, validation_generator = get_generators(vgg_preprocess,TRAIN_DIR, VAL_DIR)\nEPOCHS = 30\nmodel = get_model('VGG16', res)\nprint(\"Training VGG16\")\nhistory = train_model(EPOCHS, model, train_generator, validation_generator)","131322f9":"X_test_prep = preprocess_imgs(vgg_preprocess,set_name=X_test_crop, img_size=IMG_SIZE)\npredictions = model.predict(X_test_prep)\nplot_roc(model, y_test, predictions)\nroc_auc_score(y_test, predictions)","7fe83532":"res = (224,224)\ntrain_generator, validation_generator = get_generators(in_preprocess,TRAIN_DIR, VAL_DIR)\nEPOCHS = 30\nmodel = get_model('Inception', res)\nprint(\"Training InceptionV3\")\nhistory = train_model(EPOCHS, model, train_generator, validation_generator)","74b3d903":"X_test_prep = preprocess_imgs(in_preprocess,set_name=X_test_crop, img_size=IMG_SIZE)\npredictions = model.predict(X_test_prep)\nplot_roc(model, y_test, predictions)\nroc_auc_score(y_test, predictions)","a30eaef5":"res = (224,224)\ntrain_generator, validation_generator = get_generators(mn_preprocess,TRAIN_DIR, VAL_DIR)\nEPOCHS = 30\nmodel = get_model('MobileNet', res)\nprint(\"Training MobileNet\")\nhistory = train_model(EPOCHS, model, train_generator, validation_generator)","96078129":"X_test_prep = preprocess_imgs(mn_preprocess,set_name=X_test_crop, img_size=IMG_SIZE)\npredictions = model.predict(X_test_prep)\nplot_roc(model, y_test, predictions)\nroc_auc_score(y_test, predictions)","f3468f91":"### MobileNet","452512da":"### VGG16","738b7be7":"### ResNet50","0085d841":"## Importing required packages"}}