{"cell_type":{"a0dbaa2f":"code","dd445b0c":"code","837a1887":"code","88e43a05":"code","9fe3c68b":"code","ebfc6eda":"code","674bbf76":"code","7d58c0ba":"code","8781b3ed":"code","40d00472":"code","58ad2838":"code","246e3b7a":"code","9ad3c5e4":"code","bcf7b88c":"code","446ff127":"code","69936f90":"code","f2988286":"code","6c96e5d2":"code","670fcb45":"code","8519a42f":"code","b0a3e306":"code","b637d59d":"markdown","0f8dc0e2":"markdown","9cb6d994":"markdown","234272f0":"markdown","ba24405e":"markdown","e4ae93ea":"markdown"},"source":{"a0dbaa2f":"import h2o\nh2o.init()","dd445b0c":"url = \"https:\/\/raw.githubusercontent.com\/pandas-dev\/pandas\/master\/pandas\/tests\/data\/iris.csv\"","837a1887":"df = h2o.import_file(url)","88e43a05":"from h2o.estimators.pca import H2OPrincipalComponentAnalysisEstimator","9fe3c68b":"df.pca = H2OPrincipalComponentAnalysisEstimator(k=4)","ebfc6eda":"response = \"Name\"","674bbf76":"fm = df.col_names","7d58c0ba":"fm.remove(response)","8781b3ed":"df.pca.train(x=fm, training_frame=df)","40d00472":"df","58ad2838":"df.pca.varimp(use_pandas=True)","246e3b7a":"df.pca","9ad3c5e4":"df_new = df.pca.predict(df)","bcf7b88c":"from h2o.estimators.naive_bayes import H2ONaiveBayesEstimator","446ff127":"nv = H2ONaiveBayesEstimator()","69936f90":"df_new  = df_new.cbind(df[response])","f2988286":"df_new","6c96e5d2":"fm = df_new.col_names\nresponse = \"Name\"\nfm.remove(response)","670fcb45":"nv.train(fm,response,df_new)","8519a42f":"nv","b0a3e306":"### tou can split the data in train and test\n### but i leave it their","b637d59d":"![](http:\/\/i.stack.imgur.com\/jPw90.png)","0f8dc0e2":"## Lets apply the H2O program in famous iris data set","9cb6d994":"#### PCA will find the best line accroding to two criteria\n# 1) Variation value should be maximum\n### lets explain this: the variation values along this line should be maxium. pay attention to the spread (in stat we call it 'varience') of the red dot. the position of the red dot changes when the line rotates.you can see in some position of the line the variation become maximum\n\n### now  we reconstruct the original two charactaristictics of soda (position of blue dot) from the new one (position of red dot) \n\n# 2) Reconstruction error\n\n### so we reconstruct the error now we need to find the reconstruction errir. its easy you will find it with length of the connecting red line\n\n## you already understand what is the line\n## when the line is inline with the purple line that is our position\n## and you probably understand the new thing that\n# when the variation become maximum the reconstruction error become minimum\n\n# so this is the line that will be constructed by the PCA\n# thats how PCA find the main charctaristics that have a high varience","234272f0":"![](http:\/\/i.stack.imgur.com\/Q7HIP.gif)","ba24405e":"### suppose two soda charastics suppose the soda concentration and acidity are correlated so depending on them every blue dot is a particular soda. now if you want to create  a new property you can draw a line through the center of the soda cloud and project all points into the line .dont understand ??? see the picture","e4ae93ea":"# What is a PCA ??\n## remember there are some math involved i am not going to cover it\n## because we have high lavel API. so i am just giving the intuation about the PCA\n\n### suppose you drink a lot of soda and you have different kinds of soda bottle in your table\n### if i tell you to make a list you can make list based on many charastics like\n#### 1) how old it is\n#### 2) the color\n#### 4) the color  etc etc\n\n####  so like that we can compose a various different kind of list but you see some of them has related propertise (common propertise) so what you are doing is redundent. what you can do to make it a little bit easier is suumarize the list with less charastices. this summarization is called PCA(principle component analysis).so what pca does is not exactly discard the redundant .it actually constructs some new charastics using the old one .may be like a combination of characteristics like [age-acidity+someting\/someting] in Fact PCA find the best possible charastics among all the liner combination.\n\n### now lets explain what i mean by the word \"summery\"\n\n### what are you looking for ??\n#### you are looking for some strong properties that make difference. there are a lot of properties that almost every soda can have and this is not a useful information.because they make them all the same.so PCA will find data that actually make the variation\n\n### What do you want??\n\n#### so if you want to predict some information that classify a certian soda from that information you need a data that have different variation in the training set .not almost the same.because if the data has greater varience you can do it better. look at the picture"}}