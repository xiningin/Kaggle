{"cell_type":{"8d870809":"code","8ed25b03":"code","b97409a2":"code","04367be7":"code","ea9a97d9":"code","78a5423a":"code","18ed2afe":"code","9ddd8b08":"code","8fa3fc8c":"code","e8b712f5":"code","636377c2":"code","00d9a341":"code","5bcd6857":"code","1393f6e1":"code","d92294c0":"markdown"},"source":{"8d870809":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pyarrow.parquet as pq\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8ed25b03":"op_dict = {}\nn_agg = 2000\n\n\nloop = int(round(8712\/1000))\nfor counter in range(loop):\n    st = counter * 1000\n    if(((counter+1) * 1000) > 8712):\n        en = 8712\n    else:\n        en = (counter+1)*1000\n    start = 0\n    end = n_agg\n    train = pq.read_pandas('..\/input\/train.parquet', columns=[str(i) for i in range(st,en)]).to_pandas()\n    agg_measure_list = []\n    print(\"column start = \"+ str(st)+\" column end = \"+str(en))\n    for loc2 in range(400):\n        mn = list(train.loc[start:end].mean(axis = 0,skipna = True))\n        agg_measure_list.append(mn)\n        start += n_agg\n        end += n_agg\n    print(\"List length = \"+ str(len(agg_measure_list)))\n    op_dict[str(counter)] = agg_measure_list\n    print(\"dict length = \"+ str(len(op_dict)))","b97409a2":"df0 = pd.DataFrame(op_dict[\"0\"])\ndf0.columns = [list(range(0,1000))]\ndf1 = pd.DataFrame(op_dict[\"1\"])\ndf1.columns = [list(range(1000,2000))]\ndf2 = pd.DataFrame(op_dict[\"2\"])\ndf2.columns = [list(range(2000,3000))]\ndf3 = pd.DataFrame(op_dict[\"3\"])\ndf3.columns = [list(range(3000,4000))]\ndf4 = pd.DataFrame(op_dict[\"4\"])\ndf4.columns = [list(range(4000,5000))]\ndf5 = pd.DataFrame(op_dict[\"5\"])\ndf5.columns = [list(range(5000,6000))]\ndf6 = pd.DataFrame(op_dict[\"6\"])\ndf6.columns = [list(range(6000,7000))]\ndf7 = pd.DataFrame(op_dict[\"7\"])\ndf7.columns = [list(range(7000,8000))]\ndf8 = pd.DataFrame(op_dict[\"8\"])\ndf8.columns = [list(range(8000,8712))]","04367be7":"df = pd.concat([df0, df1, df2, df3, df4, df5, df6, df7, df8], axis = 1)","ea9a97d9":"plt.plot(df)","78a5423a":"df.to_csv('train_compressed.csv', index=False)","18ed2afe":"test = pq.read_pandas('..\/input\/test.parquet', columns=[str(i) for i in range(8712,8715)]).to_pandas()\ntest_meta = pd.read_csv(\"..\/input\/metadata_test.csv\")","9ddd8b08":"start_loc = 8712\nend_loc = 8712 + 20337","8fa3fc8c":"op_dict = {}\nn_agg = 2000\nimport math\n\nloop = int(math.ceil(20337\/2000))\nfor counter in range(loop):\n    st = start_loc + (counter * 2000)\n    if(((counter+1) * 2000) > end_loc):\n        en = start_loc + end_loc\n    else:\n        en = start_loc + ((counter+1)*2000)\n    start = 0\n    end = n_agg\n    train = pq.read_pandas('..\/input\/test.parquet', columns=[str(i) for i in range(st,en)]).to_pandas()\n    agg_measure_list = []\n    print(\"column start = \"+ str(st)+\" column end = \"+str(en))\n    for loc2 in range(400):\n        mn = list(train.loc[start:end].mean(axis = 0,skipna = True))\n        agg_measure_list.append(mn)\n        start += n_agg\n        end += n_agg\n    print(\"List length = \"+ str(len(agg_measure_list)))\n    op_dict[str(counter)] = agg_measure_list\n    print(\"dict length = \"+ str(len(op_dict)))","e8b712f5":"df0 = pd.DataFrame(op_dict[\"0\"])\ndf0.columns = [list(range(8712,10712))]\ndf1 = pd.DataFrame(op_dict[\"1\"])\ndf1.columns = [list(range(10712,12712))]\ndf2 = pd.DataFrame(op_dict[\"2\"])\ndf2.columns = [list(range(12712,14712))]\ndf3 = pd.DataFrame(op_dict[\"3\"])\ndf3.columns = [list(range(14712,16712))]\ndf4 = pd.DataFrame(op_dict[\"4\"])\ndf4.columns = [list(range(16712,18712))]\ndf5 = pd.DataFrame(op_dict[\"5\"])\ndf5.columns = [list(range(18712,20712))]\ndf6 = pd.DataFrame(op_dict[\"6\"])\ndf6.columns = [list(range(20712,22712))]\ndf7 = pd.DataFrame(op_dict[\"7\"])\ndf7.columns = [list(range(22712,24712))]\ndf8 = pd.DataFrame(op_dict[\"8\"])\ndf8.columns = [list(range(24712,26712))]\ndf9 = pd.DataFrame(op_dict[\"9\"])\ndf9.columns = [list(range(26712,28712))]\ndf10 = pd.DataFrame(op_dict[\"10\"])\ndf10.columns = [list(range(28712,29049))]","636377c2":"df = pd.concat([df0, df1, df2, df3, df4, df5, df6, df7, df8,df9,df10], axis = 1)","00d9a341":"test_meta = pd.read_csv(\"..\/input\/metadata_test.csv\")\nmax(test_meta['signal_id'])","5bcd6857":"df.head()","1393f6e1":"df.to_csv('test_compressed.csv', index=False)","d92294c0":"The training data consists of 800,000 measurements per signal, for 20 miliseconds. In this notebook, I reduce the 800,000 metrics to 400 metrics per signal, by averaging out 2000 signals at a time. The model will be build on top of the output of the transformed training data."}}