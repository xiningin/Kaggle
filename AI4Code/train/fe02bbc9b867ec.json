{"cell_type":{"a66b3721":"code","f1587486":"code","d0630ea8":"code","bf19f586":"code","52db552b":"code","0ba693ad":"code","04dde900":"code","16bad2a3":"code","9415eab8":"code","d4084345":"code","b33f3fcc":"code","0573f54e":"code","87c75919":"code","1385096a":"code","be6fabe3":"code","5b505df4":"code","d3e2a058":"code","93fb81b1":"code","1bc8c3e2":"code","0f906024":"code","1acd058d":"code","976cb63a":"code","76d944fc":"markdown","df90c22c":"markdown","ef0bfa00":"markdown","dbf9c8b9":"markdown","31cb3c5d":"markdown"},"source":{"a66b3721":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f1587486":"import pandas as pd\nimport numpy as np\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","d0630ea8":"# Importing House prices  dataset\ntrain_data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntrain_data = pd.get_dummies(train_data)\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\n#print(train_data)","bf19f586":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ntrain = train_data.select_dtypes(include=numerics)\ntest = test.select_dtypes(include=numerics)","52db552b":"d_train = train.fillna((np.mean(train)))","0ba693ad":"target=d_train['SalePrice']","04dde900":"mean = d_train.mean(axis=0)\nd_train-= mean\nstd = d_train.std(axis=0)\nd_train \/= std\ntest -= mean\ntest \/= std","16bad2a3":"from sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(d_train, target, test_size = 0.3, random_state = 0)","9415eab8":"from keras import models\nfrom keras import layers\n\ndef build_model():\n    # Because we will need to instantiate\n    # the same model multiple times,\n    # we use a function to construct it.\n    model=models.Sequential()\n    model.add(layers.Flatten())\n    model.add(layers.Dense(64, activation='relu'))\n    model.add(layers.Dense(64, activation='relu'))\n    model.add(layers.Dense(128, activation='relu'))# Add the proper output and activation\n    model.add(layers.Dense(1, activation='relu'))# Add the proper output and activation\n    #model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])# Add the proper loss\n    return model","d4084345":"from sklearn.linear_model import LinearRegression\nAH = LinearRegression() \nAH.fit(d_train, target)","b33f3fcc":"y_predict = AH.predict(d_train)","0573f54e":"plt.scatter(target, y_predict)\nplt.xlabel(\"Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title(\"SalePrices vs Predicted prices\")\nplt.show()","87c75919":"from sklearn.linear_model import SGDRegressor\nAH = SGDRegressor() \nAH.fit(d_train, target)","1385096a":"y_predict = AH.predict(d_train)","be6fabe3":"plt.scatter(target, y_predict)\nplt.xlabel(\"Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title(\"SalePrices vs Predicted prices\")\nplt.show()","5b505df4":"train.shape","d3e2a058":"test.shape","93fb81b1":"# Build the Keras model (already compiled)\nmodel = build_model()\n# Train the model (in silent mode, verbose=0)\nmodel.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])# Add the proper loss\n\nhistory = model.fit(d_train,target,\n                    epochs=20, batch_size=4, verbose=0)","1bc8c3e2":"from sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.linear_model import LinearRegression, Ridge, \\\nRidgeCV, Lasso, LassoCV, \\\nElasticNet, ElasticNetCV\nrr = Ridge(alpha=0.01)\nrr.fit(d_train, target)\npred_train_rr= rr.predict(d_train)\nprint(np.sqrt(mean_squared_error(target,pred_train_rr)))\nprint(r2_score(target, pred_train_rr))\npred_test_rr= rr.predict(d_train)\nprint(np.sqrt(mean_squared_error(target,pred_test_rr)))\nprint(r2_score(target, pred_test_rr))","0f906024":"from sklearn.linear_model import Lasso\nmodel_lasso = Lasso(alpha=0.01)\nmodel_lasso.fit(d_train, target)\npred_train_lasso= model_lasso.predict(d_train)\nprint(np.sqrt(mean_squared_error(target,pred_train_lasso)))\nprint(r2_score(target, pred_train_lasso))\n\n\n\npred_test_lasso= model_lasso.predict(d_train)\nprint(np.sqrt(mean_squared_error(target,pred_test_lasso)))\nprint(r2_score(target, pred_test_lasso))","1acd058d":"from sklearn.linear_model import ElasticNet\nmodel_enet = ElasticNet(alpha = 0.01)\nmodel_enet.fit(d_train, target)\npred_train_enet= model_enet.predict(d_train)\nprint(np.sqrt(mean_squared_error(target,pred_train_enet)))\nprint(r2_score(target, pred_train_enet))\n\n\n\npred_test_enet= model_enet.predict(d_train)\nprint(np.sqrt(mean_squared_error(target,pred_test_enet)))\nprint(r2_score(target, pred_test_enet))","976cb63a":"# Import SVM Regressor\nfrom sklearn import svm\nreg = svm.SVR()","76d944fc":"# A- LinearRegression\n","df90c22c":"# D-Ridge, Lasso, Elastic - Add proper regularization\n","ef0bfa00":"# E- SVM","dbf9c8b9":"# C- Try different batch sizes, lr, ....\n","31cb3c5d":"# B- SGDRegressor\n"}}