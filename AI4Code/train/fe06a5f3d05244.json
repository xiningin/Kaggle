{"cell_type":{"78e0d254":"code","1cf46117":"code","554c539c":"code","4990ca0a":"code","5c74be22":"code","b6a6a299":"code","56000099":"code","59cad2ee":"code","bc40f17e":"code","39e0bd91":"code","e350a2b3":"code","f45c7e85":"code","0e7b6cdf":"code","e3282b22":"code","41a88a11":"code","b2d6cdff":"code","a94ffebd":"code","bb1347a5":"code","3ad4e770":"code","3443b416":"code","a6faeab8":"code","4f054e65":"code","9f24be6c":"code","bc251979":"code","285e15f1":"code","57f9bb87":"code","0c6e3534":"code","a464b02a":"code","733c57ff":"code","4f5ecc0c":"code","09ad8a22":"code","e7ed48f5":"code","10d251f0":"code","131163e1":"code","b634b0e6":"code","59241c68":"code","76f5987d":"code","7bbace6d":"code","50e93396":"code","b079fa35":"markdown","b8f2d165":"markdown","811488d1":"markdown","f282117e":"markdown","6c888a37":"markdown","5aade827":"markdown","8a6fd53d":"markdown"},"source":{"78e0d254":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy.stats as stat\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import classification_report,confusion_matrix,f1_score\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('fivethirtyeight')","1cf46117":"df = pd.read_csv('..\/input\/loan-predication\/train_u6lujuX_CVtuZ9i (1).csv')\ndf.head()","554c539c":"df.describe()\n\n# ApplicantIncome, CoapplicantIncome, LoanAmount columns are skewed.","4990ca0a":"df.describe(include='object')","5c74be22":"df.shape","b6a6a299":"df.head()","56000099":"# Checking outliers\n\nplt.figure(figsize=(18,6))\nplt.subplot(131)\nsns.boxplot(df['ApplicantIncome'],color='b')\nplt.subplot(132)\nsns.boxplot(df['CoapplicantIncome'],color='b')\nplt.subplot(133)\nsns.boxplot(df['LoanAmount'],color='b')\nplt.suptitle('Checking Outliers',fontsize = 20)\nplt.show()","59cad2ee":"# Impact of categories in variables\n\nplt.figure(figsize=(18,10))\nplt.subplot(231)\ndf['Gender'].value_counts().plot(kind='pie',shadow=True,autopct = '%.2f%%',colors=['orange','y'])\n\nplt.subplot(232)\ndf['Married'].value_counts().plot(kind='pie',shadow=True,autopct = '%.2f%%')\n\nplt.subplot(233)\ndf['Education'].value_counts().plot(kind='pie',shadow=True,autopct = '%.2f%%',colors=['m','violet'])\n\nplt.subplot(234)\ndf['Self_Employed'].value_counts().plot(kind='pie',shadow=True,autopct = '%.2f%%',colors=['orange','y'])\n\nplt.subplot(235)\ndf['Property_Area'].value_counts().plot(kind='pie',shadow=True,autopct = '%.2f%%')\n\nplt.subplot(236)\ndf['Loan_Status'].value_counts().plot(kind='pie',shadow=True,autopct = '%.2f%%',colors=['m','violet'])\nplt.suptitle('Univariate Analysis - Impact of categories',fontsize = 20)\nplt.show()\n\n","bc40f17e":"# Checking counts of categories in variables\n\nplt.figure(figsize=(20,10))\nplt.subplot(231)\nsns.countplot(df['Gender'],palette='rocket_r')\n\nplt.subplot(232)\nsns.countplot(df['Married'],palette='viridis')\n\nplt.subplot(233)\nsns.countplot(df['Education'],palette='magma')\n\nplt.subplot(234)\nsns.countplot(df['Self_Employed'],palette='rocket_r')\n\nplt.subplot(235)\nsns.countplot(df['Property_Area'],palette='viridis')\n\nplt.subplot(236)\nsns.countplot(df['Loan_Status'],palette='magma')\nplt.suptitle('Univariate Analysis - Count plot',fontsize = 20)\nplt.show()","39e0bd91":"# Checking Distribution of variables\n\nplt.figure(figsize=(20,10))\nplt.subplot(221)\nsns.distplot(df['ApplicantIncome'],color='black')\n\nplt.subplot(222)\nsns.distplot(df['CoapplicantIncome'],color='m')\n\nplt.subplot(223)\nsns.distplot(df['LoanAmount'],color='g')\n\nplt.subplot(224)\nsns.distplot(df['Loan_Amount_Term'],color='r')\nplt.suptitle('Univariate Analysis - Distplot',fontsize = 20)\nplt.show()","e350a2b3":"df.head()","f45c7e85":"# Comparing variables with Loan status\n\nplt.figure(figsize=(20,10))\nplt.subplot(231)\nsns.countplot(df['Gender'],hue=df['Loan_Status'],palette='rocket_r')\n\nplt.subplot(232)\nsns.countplot(df['Married'],hue=df['Loan_Status'],palette='viridis')\n\nplt.subplot(233)\nsns.countplot(df['Education'],hue=df['Loan_Status'],palette='cubehelix')\n\nplt.subplot(234)\nsns.countplot(df['Self_Employed'],hue=df['Loan_Status'],palette='rocket_r')\n\nplt.subplot(235)\nsns.countplot(df['Credit_History'],hue=df['Loan_Status'],palette='viridis')\n\nplt.subplot(236)\nsns.countplot(df['Property_Area'],hue=df['Loan_Status'],palette='cubehelix')\nplt.suptitle('Bivariate Analysis - Count plot',fontsize = 20)\nplt.show()","0e7b6cdf":"# Impact of ApplicantIncome, CoapplicantIncome and LoanAmount on Loan_Status\n\nplt.figure(figsize=(18,6))\nplt.subplot(131)\nsns.boxplot(df['ApplicantIncome'],df['Loan_Status'])\nplt.subplot(132)\nsns.boxplot(df['CoapplicantIncome'],df['Loan_Status'])\nplt.subplot(133)\nsns.boxplot(df['LoanAmount'],df['Loan_Status'])\nplt.suptitle('Checking Outliers',fontsize = 20)\nplt.show()","e3282b22":"# Removing the outliers from data\n\nprint('Before removing outliers {}'.format(df.shape))\ndf=df[df['ApplicantIncome']<20000]\ndf=df[df['CoapplicantIncome']<10000]\ndf=df[df['LoanAmount']<350]\nprint('After removing outliers {}'.format(df.shape))","41a88a11":"df.drop('Loan_ID',axis=1,inplace=True)","b2d6cdff":"df.isnull().sum()","a94ffebd":"# Assigning values for null values\n\ndf['Gender']=df['Gender'].fillna(df['Gender'].mode()[0])\ndf['Married']=df['Married'].fillna(df['Married'].mode()[0])\ndf['Dependents']=df['Dependents'].fillna(df['Dependents'].mode()[0])\ndf['Self_Employed']=df['Self_Employed'].fillna(df['Self_Employed'].mode()[0])\ndf['Loan_Amount_Term']=df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].median())\ndf['Credit_History']=df['Credit_History'].fillna(df['Credit_History'].median())","bb1347a5":"df.isnull().sum().sum()","3ad4e770":"df.select_dtypes(include='object').head()","3443b416":"# Converting categorical to numerical\n\ndf['Gender']=df['Gender'].replace(('Male','Female'),(2,1))\ndf['Married']=df['Married'].replace(('Yes','No'),(2,1))\ndf['Education']=df['Education'].replace(('Graduate','Not Graduate'),(2,1))\ndf['Self_Employed']=df['Self_Employed'].replace(('No','Yes'),(2,1))\ndf['Property_Area']=df['Property_Area'].replace(('Semiurban','Urban','Rural'),(3,2,1))\ndf['Dependents']=df['Dependents'].replace(('3+','2','1','0'),(3,2,1,0))\ndf['Loan_Status']=df['Loan_Status'].replace(('Y','N'),(2,1))","a6faeab8":"df.head()","4f054e65":"# splitting dependent and independent variable\n\nx=df.drop('Loan_Status',axis=1)\ny=df['Loan_Status']","9f24be6c":"# Resampling for balancing the data\n\nsm=SMOTE()\nx_sm,y_sm = sm.fit_resample(x,y)","bc251979":"# Visualizing dependent variable\n\nprint('Before Resampling {}'.format(y.shape))\nprint('After Resampling {}'.format(y_sm.shape))\nplt.figure(figsize=(10,8))\nplt.subplot(121)\ny.value_counts().plot(kind='pie',autopct = '%.2f%%',colors=['orange','y'])\nplt.subplot(122)\ny_sm.value_counts().plot(kind='pie',autopct = '%.2f%%',colors=['orange','y'])\nplt.show()","285e15f1":"# Train test split\n\nxtrain,xtest,ytrain,ytest=train_test_split(x_sm,y_sm,test_size=0.2,random_state=10)","57f9bb87":"print('Shape of xtrain {}'.format(xtrain.shape))\nprint('Shape of ytrain {}'.format(ytrain.shape))\nprint('Shape of xtest {}'.format(xtest.shape))\nprint('Shape of ytest {}'.format(ytest.shape))","0c6e3534":"# Creating Logistic regression model\n\ndef logistic_reg(xtrain,xtest,ytrain,ytest):\n    lr=LogisticRegression(solver='liblinear')\n    lr.fit(xtrain,ytrain)\n    ypred=lr.predict(xtest)\n    print('***LogisticRegression***')\n    print('Confusion matrix')\n    print(confusion_matrix(ytest,ypred))\n    print('Classification report')\n    print(classification_report(ytest,ypred))\n    print('f1_score : {}'.format(f1_score(ytest,ypred)))","a464b02a":"# Creating RandomForestClassifier model\n\ndef random_forest(xtrain,xtest,ytrain,ytest):\n    rf=RandomForestClassifier()\n    rf.fit(xtrain,ytrain)\n    ypred=rf.predict(xtest)\n    print('***RandomForestClassifier***')\n    print('Confusion matrix')\n    print(confusion_matrix(ytest,ypred))\n    print('Classification report')\n    print(classification_report(ytest,ypred))\n    print('f1_score : {}'.format(f1_score(ytest,ypred)))","733c57ff":"# Creating GradientBoostingClassifier model\n\ndef g_boosting(xtrain,xtest,ytrain,ytest):\n    gb=GradientBoostingClassifier()\n    gb.fit(xtrain,ytrain)\n    ypred=gb.predict(xtest)\n    print('***GradientBoostingClassifier***')\n    print('Confusion matrix')\n    print(confusion_matrix(ytest,ypred))\n    print('Classification report')\n    print(classification_report(ytest,ypred))\n    print('f1_score : {}'.format(f1_score(ytest,ypred)))","4f5ecc0c":"# Creating GradientBoostingClassifier model\n\ndef d_tree(xtrain,xtest,ytrain,ytest):\n    dt=DecisionTreeClassifier()\n    dt.fit(xtrain,ytrain)\n    ypred=dt.predict(xtest)\n    print('***DecisionTreeClassifier***')\n    print('Confusion matrix')\n    print(confusion_matrix(ytest,ypred))\n    print('Classification report')\n    print(classification_report(ytest,ypred))\n    print('f1_score : {}'.format(f1_score(ytest,ypred)))","09ad8a22":"# Comparing three models\n\ndef compare_model(xtrain,xtest,ytrain,ytest):\n    logistic_reg(xtrain,xtest,ytrain,ytest)\n    print('-'*100)\n    random_forest(xtrain,xtest,ytrain,ytest)\n    print('-'*100)\n    g_boosting(xtrain,xtest,ytrain,ytest)\n    print('-'*100)\n    d_tree(xtrain,xtest,ytrain,ytest)","e7ed48f5":"compare_model(xtrain,xtest,ytrain,ytest)","10d251f0":"# When compared with all models Random forest model performs well. It is small dataset if more data in dataset the accuracy will be high.\n\n# Trying hyperparameter tunning\n\nfrom sklearn.model_selection import GridSearchCV, cross_val_score","131163e1":"#Creating Parameters for GridSearchCV\n\nparams={'n_estimators':np.arange(100,500,100),\n    'criterion':['gini','entropy'],\n    'max_depth':[1,2,3],\n    'min_samples_split':[2,3,4],\n    'min_samples_leaf':[1,2,3]}\n\nparams","b634b0e6":"# Creating tunning model\n\nrf=RandomForestClassifier()\n\ngrid_search=GridSearchCV(rf,params)\ngrid_search.fit(xtrain,ytrain)","59241c68":"# Finding best parameters\n\ngrid_search.best_params_","76f5987d":"# Creating new model with best parameters\n\nrf_gcv=grid_search.best_estimator_\nrf_gcv.fit(xtrain,ytrain)","7bbace6d":"# Analysing performance of tuned model\n\nypred_gcv=rf_gcv.predict(xtest)\nprint('***RandomForestClassifier***')\nprint('Confusion matrix')\nprint(confusion_matrix(ytest,ypred_gcv))\nprint('Classification report')\nprint(classification_report(ytest,ypred_gcv))\nprint('f1_score : {}'.format(f1_score(ytest,ypred_gcv)))","50e93396":"cv_score=cross_val_score(rf,x,y,cv=5)\nprint('Score of normal(default) model')\nprint(cv_score)\nprint(np.mean(cv_score))\nprint('-'*100)\n\ncv_score=cross_val_score(rf_gcv,x,y,cv=5)\nprint('Score of tuned model')\nprint(cv_score)\nprint(np.mean(cv_score))","b079fa35":"# Machine Learning Models","b8f2d165":"# Data Preprocessing","811488d1":"# Descriptive analysis","f282117e":"# Data Cleaning","6c888a37":"# Univariate analysis","5aade827":"# Bivariate Analysis","8a6fd53d":"# Model Improvement"}}