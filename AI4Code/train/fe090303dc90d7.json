{"cell_type":{"72dded60":"code","471f5260":"code","f735bcde":"code","212bb427":"code","e8da23e4":"code","7cb2a5af":"code","ed26686f":"code","ab79e824":"code","d7b1572f":"code","036c1848":"code","aed8fe01":"code","f84ecce6":"code","20933d35":"code","b6d0ff7d":"code","1c352a0c":"code","7fa809bd":"markdown","972b86b7":"markdown","9eb35fa6":"markdown","d88044ac":"markdown","dcf8d913":"markdown","07229f56":"markdown","8c1da208":"markdown","6ecbe59d":"markdown"},"source":{"72dded60":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","471f5260":"from keras.datasets.fashion_mnist import load_data\nfrom keras.layers import Conv2D,LeakyReLU,Flatten,Dense,Reshape,Conv2DTranspose,Dropout,Input,Embedding,Concatenate\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential,load_model,Model\nfrom matplotlib import pyplot","f735bcde":"(trainX,trainY),(testX,testY)=load_data()\nprint(trainX.shape,trainY.shape)\nprint(testX.shape,testY.shape)","212bb427":"for i in range(100):\n    # define subplot\n    pyplot.subplot(10, 10, 1 + i)\n    # turn off axis\n    pyplot.axis('off')\n    # plot raw pixel data\n    pyplot.imshow(trainX[i], cmap='gray_r')\npyplot.show()","e8da23e4":"def discriminatorModel(inp_shape=(28,28,1),n_classes=10):\n    in_label=Input(shape=(1,))\n    li=Embedding(n_classes,50)(in_label)\n    n_nodes=inp_shape[0]*inp_shape[1]\n    li=Dense(n_nodes)(li)\n    li=Reshape((inp_shape[0],inp_shape[1],1))(li)\n    in_image=Input(shape=inp_shape)\n    merge=Concatenate()([in_image,li])\n  \n    fe=Conv2D(128,(3,3),strides=(2,2),padding=\"same\")(merge)\n    fe=LeakyReLU(alpha=0.2)(fe)\n\n    fe=Conv2D(128,(3,3),strides=(2,2),padding=\"same\")(merge)\n    fe=LeakyReLU(alpha=0.2)(fe)\n\n    fe=Flatten()(fe)\n    fe=Dropout(0.4)(fe)\n    out_layer=Dense(1,activation='sigmoid')(fe)\n\n    model=Model([in_image,in_label],out_layer)\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n    return model","7cb2a5af":"def generatorModel(latent_dim,n_classes=10):\n    in_label=Input(shape=(1,))\n    li=Embedding(n_classes,50)(in_label)\n    n_nodes=7*7\n    li=Dense(n_nodes)(li)\n    li=Reshape((7,7,1))(li)\n    in_lat=Input(shape=(latent_dim,))\n\n    n_nodes=(128*7*7)\n    gen=Dense(n_nodes)(in_lat)\n    gen=LeakyReLU(alpha=0.2)(gen)\n    gen = Reshape((7, 7, 128))(gen)\n\n    merge = Concatenate()([gen, li])\n    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merge)\n    gen = LeakyReLU(alpha=0.2)(gen)\n\n    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n    gen = LeakyReLU(alpha=0.2)(gen)\n\n    out_layer = Conv2D(1, (7,7), activation='tanh', padding='same')(gen)\n\n    model = Model([in_lat, in_label], out_layer)  \n    return model","ed26686f":"def define_gan(generator,discriminator):\n    discriminator.trainable=False\n    model=Sequential()\n    gen_noise,gen_label=generator.input\n    gen_output = generator.output\n    gan_output = discriminator([gen_output, gen_label])\n    model = Model([gen_noise, gen_label], gan_output)\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt)\n    return model","ab79e824":"def load_real_samples():\n    (trainX,trainY),(_,_)=load_data()\n    X=np.expand_dims(trainX,axis=-1)\n    X=X.astype('float32')\n    X = (X - 127.5) \/ 127.5\n    return [X,trainY]","d7b1572f":"def generate_real_samples(dataset,n_samples):\n    images,labels=dataset\n    ix=np.random.randint(0,images.shape[0],n_samples)\n    X,labels=images[ix],labels[ix]\n    Y=np.ones((n_samples,1))\n    return [X,labels],Y","036c1848":"def generate_latent_points(latent_dim,n_samples,n_classes=10):\n    x_input=np.random.randn(latent_dim*n_samples)\n    z_input = x_input.reshape(n_samples, latent_dim)\n    labels = np.random.randint(0, n_classes, n_samples)\n    return [z_input, labels]","aed8fe01":"def generate_fake_samples(generator,latent_dim,n_samples):\n    z_input,labels=generate_latent_points(latent_dim,n_samples)\n    images=generator.predict([z_input,labels])\n    Y=np.zeros((n_samples,1))\n    return [images,labels],Y","f84ecce6":"def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=5, n_batch=128):\n    bat_per_epo = int(dataset[0].shape[0] \/ n_batch)\n    half_batch = int(n_batch \/ 2)\n    # manually enumerate epochs\n    for i in range(n_epochs):\n        # enumerate batches over the training set\n        for j in range(bat_per_epo):\n            # get randomly selected 'real' samples\n            [X_real,labels_real], y_real = generate_real_samples(dataset, half_batch)\n            # update discriminator model weights\n            d_loss1, _ = d_model.train_on_batch([X_real,labels_real], y_real)\n            # generate 'fake' examples\n            [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n            # update discriminator model weights\n            d_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n            # prepare points in latent space as input for the generator\n            [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n            # create inverted labels for the fake samples\n            y_gan = np.ones((n_batch, 1))\n            # update the generator via the discriminator's error\n            g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n            # summarize loss on this batch\n            print('>%d, %d\/%d, d1=%.3f, d2=%.3f g=%.3f' %\n                (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n    # save the generator model\n    g_model.save('generator.h5')","20933d35":"latent_dim=100\ndiscriminator=discriminatorModel()\ngenerator=generatorModel(latent_dim)\ngan_model=define_gan(generator,discriminator)\ndataset=load_real_samples()\ntrain(generator,discriminator,gan_model,dataset,latent_dim)","b6d0ff7d":"def save_plot(examples, n):\n    # plot images\n    for i in range(n * n):\n        # define subplot\n        pyplot.subplot(n, n, 1 + i)\n        # turn off axis\n        pyplot.axis('off')\n        # plot raw pixel data\n        pyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n    pyplot.show()","1c352a0c":"model = load_model('generator.h5')\n# generate images\nlatent_points, labels = generate_latent_points(100, 100)\n# specify labels\nlabels = np.asarray([x for _ in range(10) for x in range(10)])\n# generate images\nX  = model.predict([latent_points, labels])\n# scale from [-1,1] to [0,1]\nX = (X + 1) \/ 2.0\n# plot the result\nsave_plot(X, 1)","7fa809bd":"## Compiling Everything to train the Generator!","972b86b7":"## Lets Define the Generator\nWe have to train this model to create an image that can easily fool the generator. Notice here that I have not compiled the model. This is because it is trained along with the Discriminator","9eb35fa6":"## Here we Stack up both the Models and Define our GAN","d88044ac":"## Conditional Generation of Fashion Images!(Get over Classification)\nUsed Conditional GAN for image generation. Basically you tell the model to give Shoes and the model develops a new Shoe that does not exist. We are teaching the model to think uniquely.\n\nEasy Notebook in Keras","dcf8d913":"## This takes some time on CPU. Try Enabling your GPU","07229f56":"## GAN takes up data from something called a Latent Space\nWe need to train Generator to pick up appropriate points from the Latent(Imaginary) Space. this is basically a random distribution","8c1da208":"## Overview of type of Images","6ecbe59d":"## Lets define the Discriminator\nA Simple CNN Architecture. Helps to distinguish between real and fake images."}}