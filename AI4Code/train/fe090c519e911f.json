{"cell_type":{"b38c65a3":"code","2643d368":"code","6fda1206":"code","a7946295":"code","8bdca589":"code","b8168619":"code","050e89bd":"code","b13829d3":"code","a00dcc28":"code","889b83d7":"code","bde9add2":"code","08297c90":"code","63ea8a56":"code","47b62583":"code","7069581b":"code","555d6c17":"code","c14b8f44":"code","ade43792":"code","81d235e2":"code","70bc66fa":"code","c0570b18":"code","d127d1bc":"code","d44fdce7":"code","f21c0084":"code","6b557094":"code","0125d1dc":"code","25fc5d3b":"code","67f37729":"code","091acbd2":"code","a3ba3275":"code","65134d2a":"code","581146ef":"code","3601d76a":"code","cdeacccf":"code","117de2bd":"code","be8d0009":"code","9c8b397a":"code","847e7a67":"code","c41c984c":"code","20b5ac0a":"code","98c2c632":"code","62bbc519":"code","b8195c56":"code","452d6b96":"code","d3658a55":"code","7a1c1076":"code","1c334d0a":"code","9e1ef2a7":"code","0d83394b":"code","9bb43a44":"code","452d3310":"code","1d3fe1fa":"code","b24fdfe5":"code","abfeaf9f":"markdown","774689e2":"markdown","9907bf05":"markdown","bde3fea3":"markdown","5194b85d":"markdown","94116b9c":"markdown","e0095b5b":"markdown","a50af30f":"markdown","23bbb0f2":"markdown","a1e8d1c1":"markdown","624d27c8":"markdown","ef270eac":"markdown","643412cf":"markdown","d92c00da":"markdown","aafec3b1":"markdown","eda3a115":"markdown","8394f6b0":"markdown","c1287b5f":"markdown","188c25e0":"markdown","96c57386":"markdown","7c0e9932":"markdown","dbed97e1":"markdown","315a12b5":"markdown","4dc078b0":"markdown","ed0988eb":"markdown","088b1e54":"markdown","35b13bbf":"markdown","78ba119a":"markdown","4b3f2783":"markdown","32736c34":"markdown","ac596b9d":"markdown","2da8a870":"markdown","3acee896":"markdown","aedc65d2":"markdown","85826533":"markdown","d40896ce":"markdown","4be4eb90":"markdown","69884ebc":"markdown","1c0e5b7d":"markdown","61ed5d20":"markdown","98ebcd4c":"markdown","fe7d0b37":"markdown","47691088":"markdown","3c4486cc":"markdown","a0890d66":"markdown","a5515405":"markdown","146f52d4":"markdown","8b3d2cf6":"markdown"},"source":{"b38c65a3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2643d368":"df = pd.read_csv(\"..\/input\/drug-classification\/drug200.csv\")","6fda1206":"df.head()","a7946295":"df.describe()","8bdca589":"df.isnull().sum()","b8168619":"df.isna().sum()","050e89bd":"df.info()","b13829d3":"print(\"Max Age:\", df.Age.max())\nprint(\"Min Age:\", df.Age.min())","a00dcc28":"# Age distribution\nplt.figure(figsize = (9,5))\nsns.distplot(df.Age)\nplt.show()","889b83d7":"df.Sex.value_counts()","bde9add2":"# Sex Distribution\nplt.figure(figsize=(9,5))\nsns.countplot(x = df.Sex)\nplt.show()","08297c90":"df.BP.value_counts()","63ea8a56":"plt.figure(figsize = (9,5))\nsns.countplot(df.BP)\nplt.show()","47b62583":"df.Cholesterol.value_counts()","7069581b":"plt.figure(figsize = (9,5))\nsns.countplot(df.Cholesterol)\nplt.show()","555d6c17":"print(\"Max Na_to_K:\",df.Na_to_K.max())\nprint(\"Min Na_to_K:\",df.Na_to_K.min())\nprint(\"Mean Na_to_K:\",df.Na_to_K.mean())","c14b8f44":"plt.figure(figsize = (9,5))\nsns.distplot(df.Na_to_K)\nplt.show()","ade43792":"df.Drug.value_counts()","81d235e2":"plt.figure(figsize = (9,5))\nsns.countplot(df.Drug)\nplt.show()","70bc66fa":"plt.figure(figsize = (9,5))\nsns.swarmplot(x = \"Drug\", y = \"Age\",data = df)\nplt.legend(df.Drug.value_counts().index)\nplt.title(\"Age -- Drug\")\nplt.show()","c0570b18":"print(\"Minimum Age of DrugB\",df.Age[df.Drug == \"drugB\"].min())\nprint(\"Maximum Age of DrugA\",df.Age[df.Drug == \"drugA\"].max())","d127d1bc":"df_Sex_Drug = df.groupby([\"Drug\",\"Sex\"]).size().reset_index(name = \"Count\")\ndf_Sex_Drug","d44fdce7":"\nplt.figure(figsize = (9,5))\nsns.barplot(x = \"Drug\",y=\"Count\", hue = \"Sex\",data = df_Sex_Drug)\nplt.title(\"Sex -- Drug\")\nplt.show()","f21c0084":"df_BP_Drug = df.groupby([\"Drug\",\"BP\"]).size().reset_index(name = \"Count\")\ndf_BP_Drug","6b557094":"plt.figure(figsize = (9,5))\nsns.barplot(x = \"Drug\",y=\"Count\", hue = \"BP\",data = df_BP_Drug)\nplt.title(\"BP -- Drug\")\nplt.show()","0125d1dc":"plt.figure(figsize = (9,5))\nsns.swarmplot(x = \"Drug\", y = \"Na_to_K\",data = df)\nplt.title(\"Na_to_K -- Drug\")\nplt.show()","25fc5d3b":"print(\"Minimum Na_to_K for DrugY:\",df.Na_to_K[df.Drug == \"DrugY\"].min())","67f37729":"df_CH_Drug = df.groupby([\"Drug\",\"Cholesterol\"]).size().reset_index(name = \"Count\")\ndf_CH_Drug","091acbd2":"plt.figure(figsize = (9,5))\nsns.barplot(x = \"Drug\",y=\"Count\", hue = \"Cholesterol\",data = df_CH_Drug)\nplt.title(\"Cholesterol -- Drug\")\nplt.show()","a3ba3275":"plt.figure(figsize = (9,5))\nsns.swarmplot(x = \"Drug\", y = \"Na_to_K\",hue=\"BP\",data = df)\nplt.legend()\nplt.title(\"Na_to_K -- BP -- Drug\")\nplt.show()","65134d2a":"df['Na_to_K_Bigger_Than_15'] = [1 if i >=15.015 else 0 for i in df.Na_to_K]\ndf.head()","581146ef":"df_NaK15 = df.groupby([\"Drug\",\"Na_to_K_Bigger_Than_15\"]).size().reset_index(name = \"Count\")\ndf_NaK15","3601d76a":"plt.figure(figsize = (9,5))\nsns.barplot(x = \"Drug\",y=\"Count\", hue = \"Na_to_K_Bigger_Than_15\",data = df_NaK15)\nplt.title(\"Na_to_K_Bigger_Than_15 -- Drug\")\nplt.show()","cdeacccf":"from sklearn.preprocessing import LabelEncoder\n\ndef label_encoder(y):\n    le = LabelEncoder()\n    df[y] = le.fit_transform(df[y])","117de2bd":"label_list = [\"Sex\",\"BP\",\"Cholesterol\",\"Na_to_K\",\"Na_to_K_Bigger_Than_15\",\"Drug\"]\n\nfor l in label_list:\n    label_encoder(l)","be8d0009":"df.head()","9c8b397a":"from sklearn.model_selection import train_test_split\n\nx = df.drop([\"Drug\"],axis=1)\ny = df.Drug\n\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = 42, shuffle = True)\n\ny_train = y_train.values.reshape(-1,1)\ny_test = y_test.values.reshape(-1,1)\n\nprint(\"x_train shape:\",x_train.shape)\nprint(\"x_test shape:\",x_test.shape)\nprint(\"y_train shape:\",y_train.shape)\nprint(\"y_test shape:\",y_test.shape)","847e7a67":"# To store results of models\nresult_dict_train = {}\nresult_dict_test = {}","c41c984c":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\naccuracies = cross_val_score(knn, x_train, y_train, cv=5)\nknn.fit(x_train,y_train)\n\nprint(\"Train Score:\",np.mean(accuracies))\nprint(\"Test Score:\",knn.score(x_test,y_test))","20b5ac0a":"result_dict_train[\"KNN Default Train Score\"] = np.mean(accuracies)\nresult_dict_test[\"KNN Default Test Score\"] = knn.score(x_test,y_test)","98c2c632":"grid = {'n_neighbors':np.arange(1,120),\n        'p':np.arange(1,3),\n        'weights':['uniform','distance']\n       }\n\nknn = KNeighborsClassifier(algorithm = \"auto\")\nknn_cv = GridSearchCV(knn,grid,cv=5)\nknn_cv.fit(x_train,y_train)\n\nprint(\"Hyperparameters:\",knn_cv.best_params_)\nprint(\"Train Score:\",knn_cv.best_score_)\nprint(\"Test Score:\",knn_cv.score(x_test,y_test))","62bbc519":"result_dict_train[\"KNN GridSearch Train Score\"] = knn_cv.best_score_\nresult_dict_test[\"KNN GridSearch Test Score\"] = knn_cv.score(x_test,y_test)","b8195c56":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(random_state = 42)\naccuracies = cross_val_score(rfc, x_train, y_train, cv=5)\nrfc.fit(x_train,y_train)\n\nprint(\"Train Score:\",np.mean(accuracies))\nprint(\"Test Score:\",rfc.score(x_test,y_test))","452d6b96":"result_dict_train[\"Random Forest Default Train Score\"] = np.mean(accuracies)\nresult_dict_test[\"Random Forest Default Test Score\"] = rfc.score(x_test,y_test)","d3658a55":"grid = {'n_estimators':np.arange(100,1000,100),\n        'criterion':['gini','entropy']\n       }\n\nrf = RandomForestClassifier(random_state = 42)\nrf_cv = GridSearchCV(rf,grid,cv=5)\nrf_cv.fit(x_train,y_train)\n\nprint(\"Hyperparameters:\",rf_cv.best_params_)\nprint(\"Train Score:\",rf_cv.best_score_)\nprint(\"Test Score:\",rf_cv.score(x_test,y_test))","7a1c1076":"result_dict_train[\"Random Forest GridSearch Train Score\"] = rf_cv.best_score_\nresult_dict_test[\"Random Forest GridSearch Test Score\"] = rf_cv.score(x_test,y_test)","1c334d0a":"from sklearn.svm import SVC\nsvc = SVC(random_state = 42)\naccuracies = cross_val_score(svc, x_train, y_train, cv=5)\nsvc.fit(x_train,y_train)\n\nprint(\"Train Score:\",np.mean(accuracies))\nprint(\"Test Score:\",svc.score(x_test,y_test))","9e1ef2a7":"result_dict_train[\"SVM Default Train Score\"] = np.mean(accuracies)\nresult_dict_test[\"SVM Default Test Score\"] = svc.score(x_test,y_test)","0d83394b":"grid = {\n    'C':[0.01,0.1,1,10],\n    'kernel' : [\"linear\",\"poly\",\"rbf\",\"sigmoid\"],\n    'degree' : [1,3,5,7],\n    'gamma' : [0.01,1]\n}\n\nsvm  = SVC ();\nsvm_cv = GridSearchCV(svm, grid, cv = 5)\nsvm_cv.fit(x_train,y_train)\nprint(\"Best Parameters:\",svm_cv.best_params_)\nprint(\"Train Score:\",svm_cv.best_score_)\nprint(\"Test Score:\",svm_cv.score(x_test,y_test))\n","9bb43a44":"result_dict_train[\"SVM GridSearch Train Score\"] = svm_cv.best_score_\nresult_dict_test[\"SVM GridSearch Test Score\"] = svm_cv.score(x_test,y_test)","452d3310":"df_result_train = pd.DataFrame.from_dict(result_dict_train,orient = \"index\",columns=[\"Score\"])\ndf_result_train","1d3fe1fa":"df_result_test = pd.DataFrame.from_dict(result_dict_test,orient = \"index\",columns=[\"Score\"])\ndf_result_test","b24fdfe5":"fig,ax = plt.subplots(1,2,figsize=(20,5))\nsns.barplot(x = df_result_train.index,y = df_result_train.Score,ax = ax[0])\nsns.barplot(x = df_result_test.index,y = df_result_test.Score,ax = ax[1])\nax[0].set_xticklabels(df_result_train.index,rotation = 75)\nax[1].set_xticklabels(df_result_test.index,rotation = 75)\nplt.show()","abfeaf9f":"* If people have HIGH blood pressure and Na_to_K ratio is lower than 15 , they get drugA and drugB only.\n* If people have LOW blood pressure and Na_to_K ratio is lower than 15 , they get drugC only.","774689e2":"<a id='32'><\/a>\n# Conclusion","9907bf05":"* Drug is target column and you can see that it is unbalanced dataset. Using K Fold cross-validation would be better for reliable results.","bde3fea3":"<a id='5'><\/a>\n### Sex Variable","5194b85d":"Data was splitted as 80% train data and 20% test data.","94116b9c":"* People who have Na_to_K ratio is bigger than 15, get DrugY.\n* We can create a new feature from here.","e0095b5b":"<a id='29'><\/a>\n# SVM Classifier\n\nTo find best score of SVM model, I will try different value of C, kernel, degree and gamma parameters. The easy way to do this is GridSearchCV method. If you are not sure about what these parameters are you can check my another kernel [Understanding Parameters of SVM](https:\/\/www.kaggle.com\/gorkemgunay\/understanding-parameters-of-svm)","a50af30f":"<a id='1'><\/a>\n# Read Data and PreCheck","23bbb0f2":"<a id='25'><\/a>\n### GridSearchCV","a1e8d1c1":"<a id='13'><\/a>\n## BP -- Drug","624d27c8":"<a id='21'><\/a>\n## Train Test Split","ef270eac":"* DrugB is taken only by older than 51 years old. \n* DrugA is taken only by younger than 50 years old. ","643412cf":"* Age range is between 15 and 74.","d92c00da":"* Male people get drugA, drugB and drugC more than male people.\n* Female people get DrugY more than female people.\n* drugX seems equal for male and female people.\n* According to this graph, Sex feature is not an important feature for classification.","aafec3b1":"<a id='30'><\/a>\n### Default Parameters","eda3a115":"<a id='27'><\/a>\n### Default Parameters","8394f6b0":"<a id='12'><\/a>\n## Sex -- Drug","c1287b5f":"<a id='16'><\/a>\n## Na_to_K -- BP -- Drug","188c25e0":"<a id='4'><\/a>\n### Age Variable","96c57386":"<a id='19'><\/a>\n### Na_to_K_Bigger_Than_15 \n\nIf Na_to_K is bigger than 15, it is always drugY.","7c0e9932":"* drugA and drugB are got only by people who have HIGH blood pressure.\n* drugC is got by people who have LOW blood pressure.\n* drugX is got by people who have HIGH blood pressure.\n* BP is an important feature for classification.","dbed97e1":"<a id='6'><\/a>\n### BP Variable","315a12b5":"<a id='31'><\/a>\n### GridSearchCV","4dc078b0":"* Cholesterol is a balanced data. \n* It is categorical and label encoder will apply on it.","ed0988eb":"<a id='18'><\/a>\n## Create New Features","088b1e54":"<a id='7'><\/a>\n### Cholesterol Variable","35b13bbf":"<a id='23'><\/a>\n## KNN Classifier\n\nTo find best score of KNN model, I will try different value of n_neighbors, p, and weights parameters. If you are not sure about what these parameters are you can check my another kernel [Understanding Parameters of KNN](http:\/\/www.kaggle.com\/gorkemgunay\/understanding-parameters-of-knn)","78ba119a":"<a id='17'><\/a>\n# Preparing Data and Feature Engineering","4b3f2783":"<a id='2'><\/a>\n# Variable Description\n\n* Age: Age of patient\n* Sex: Gender of patient\n* BP: Blood pressure of patient\n* Cholesterol: Cholesterol of patient\n* Na_to_K: Sodium to Potassium Ratio in Blood \n* Drug: Drug Type","32736c34":"<a id='9'><\/a>\n### Drug Variable","ac596b9d":"<a id='8'><\/a>\n### Na_to_K Variable","2da8a870":"<a id='24'><\/a>\n### Default Parameters","3acee896":"* No missing value\n* 6 columns\n* 200 rows","aedc65d2":"<a id='11'><\/a>\n## Age -- Drug","85826533":"# Introduction\n\n1. [Read Data and PreCheck](#1)\n1. [Variable Description](#2)\n    * [Univariate Variable Analysis](#3)\n        1. [Age Variable](#4)\n        1. [Sex Variable](#5)\n        1. [BP Variable](#6)\n        1. [Cholesterol Variable](#7)\n        1. [Na_to_K Variable](#8)\n        1. [Drug Variable](#9)\n1. [Basic Data Analysis and Visualization](#10)\n    * [Age -- Drug](#11)\n    * [Sex -- Drug](#12)\n    * [BP -- Drug](#13)\n    * [Na_to_K -- Drug](#14)\n    * [Cholesterol -- Drug](#15)\n    * [Na_to_K -- BP -- Drug](#16)\n1. [Preparing Data and Feature Engineering](#17)\n    * [Create New Features](#18)\n        * [Na_to_K_Bigger_Than_15](#19)\n    * [Label Encoding](#20)\n    * [Train Test Split](#21)\n1. [Model Implementation](#22)\n    1. [KNN Classifier](#23)\n        * [Default Parameters](#24)\n        * [GridSearchCV](#25)\n    2. [Random Forest Classifier](#26)\n        * [Default Parameters](#27)\n        * [GridSearchCV](#28)\n    3. [SVM Classifier](#29)\n        * [Default Parameters](#30)\n        * [GridSearchCV](#31)\n1. [Conclusion](#32)","d40896ce":"<a id='3'><\/a>\n## Univariate Variable Analysis","4be4eb90":"<a id='10'><\/a>\n# Basic Data Analysis\n\n* Age -- Drug\n* Sex -- Drug\n* BP -- Drug\n* Cholesterol -- Drug","69884ebc":"<a id='14'><\/a>\n## Na_to_K -- Drug","1c0e5b7d":"* drugC is got by people who have HIGH cholesterol.\n* Cholesterol is an important feature to classify drugC","61ed5d20":"* The ratio of gender seems balanced in the data\n* This is a categorical variable. It would be better if we apply label encoder to avoid any error during model implementation.","98ebcd4c":"<a id='28'><\/a>\n### GridSearchCV","fe7d0b37":"<a id='20'><\/a>\n## Label Encoding\n\nWe will convert from object to int64\n\n* Sex\n* BP\n* Cholesterol\n* Na_to_K\n* Na_to_K_Bigger_Than_15","47691088":"<a id='15'><\/a>\n## Cholesterol -- Drug","3c4486cc":"* float64(1): Na_to_K\n* int64(1): Age\n* object(4): Sex, BP, Cholesterol, Drug","a0890d66":"<a id='22'><\/a>\n# Model Implementation\n\nI will try three models and compare their results. For all models, I apply GridSearchCV method to find best score. Also, to be sure our models performance are random, I will use 5 Fold Cross Validation method.","a5515405":"<a id='26'><\/a>\n# Random Forest\n\n\nTo find best score of Random Forest model, I will try different value of n_estimators and criterion parameters.","146f52d4":"* Random Forest classifier  and SVM classifier (after hyperparameter tuning) have a good scores.\n* KNN classifier has worst score in three clasifiers.","8b3d2cf6":"* Na_to_K_Bigger_Than_15 feature will be important feature to drugY classification."}}