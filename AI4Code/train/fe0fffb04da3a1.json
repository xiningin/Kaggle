{"cell_type":{"830a161f":"code","281f3195":"code","0d88db66":"code","7948d9ab":"code","c38ce060":"code","fa4be3c2":"code","c8f1173a":"code","bf7cc8e6":"code","637bfa53":"code","95522175":"code","b0c37be4":"code","48f00edb":"markdown","a894d347":"markdown","f8f5fa2e":"markdown"},"source":{"830a161f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","281f3195":"path = \"..\/input\/tabular-playground-series-nov-2021\"\nsample_submission_df = pd.read_csv(\"{}\/\/sample_submission.csv\".format(path))\ntest_df = pd.read_csv(\"{}\/\/test.csv\".format(path))\ntrain_df = pd.read_csv(\"{}\/\/train.csv\".format(path))","0d88db66":"## Check the shape of submission data sheet\nsample_submission_df\n\n## -> note: need to remove index column for upload","7948d9ab":"#drop \"id\" columns\ntry:\n    train_X = train_df.drop(\"id\", axis=1)\n    test_X = test_df.drop(\"id\", axis=1)\nexcept KeyError as e:\n    print(e)\n\ntrain_X_wid = train_df\ntest_X_wid = test_df","c38ce060":"# test_X\ntrain_X","fa4be3c2":"## check target population\nratio_label = round(float(train_X[\"target\"].value_counts()[0]\/train_X[\"target\"].value_counts()[1]),3)\nprint(f\"ratio:{ratio_label}\")\ntrain_df[\"target\"].hist()\n\n##-> almost 50\/50 on train_df","c8f1173a":"#drop \"target\" columns for building models\ntry :\n    train_X = train_X.drop(\"target\", axis=1)\nexcept KeyError as e:\n    print(e)\n\ntrain_y = train_df[\"target\"]","bf7cc8e6":"folds=3\nkf = KFold(n_splits=folds)\nlgb_params = {\"objective\":\"binary\",\n              \"metrics\":\"auc\",\n              \"random_seed\":1234}","637bfa53":"##\nmodels=[]\nfor train_index, valid_index in kf.split(train_X):\n    X_train = train_X.iloc[train_index]\n    y_train = train_y.iloc[train_index]\n    X_valid = train_X.iloc[valid_index]\n    y_valid = train_y.iloc[valid_index]\n    \n    lgb_train= lgb.Dataset(X_train, y_train)\n    lgb_valid = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n    \n    model_lgb = lgb.train(lgb_params, \n                          lgb_train, \n                          valid_sets=lgb_valid, \n                          num_boost_round=100,\n                          early_stopping_rounds=20,\n                          verbose_eval=10\n                         )\n                          \n    y_pred = model_lgb.predict(X_valid, num_iteration=model_lgb.best_iteration)\n#     print(accuracy_score(np.round(y_pred), y_valid))\n    \n    models.append(model_lgb)","95522175":"preds=[]\nfor model in models:\n    lgb.plot_importance(model, importance_type=\"gain\", max_num_features=15)\n    pred = model_lgb.predict(test_X)\n    preds.append(pred)","b0c37be4":"preds_array = np.array(preds)\npreds_mean = np.mean(preds_array, axis=0)\n# preds_mean\npreds_int = (preds_mean > 0.5).astype(int)","48f00edb":"### 2-1. using dataset without \"id\" column \n","a894d347":"## 2. Building a LightGBM Model for base line\nOf cousese I belive I can create better model with dataset which doesn't have \"id\" columns\nsince \"id\" have nothing to do with target lavel. \nBut I want to make sure how much \"id\" affects to the score.\nFist of all, I will create a model with dataset which doesn't have \"id\" columns","f8f5fa2e":"## 1. quick check on the dataset"}}