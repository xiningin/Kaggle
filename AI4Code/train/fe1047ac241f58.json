{"cell_type":{"9df1ab2d":"code","d693be8d":"code","18e6aeca":"code","ce3ccb72":"code","523f1f6b":"code","ca76b52e":"code","a077f328":"code","7291cb8a":"code","6c67568b":"code","a0834aa8":"code","c83c0a01":"code","d9663763":"code","9aa735e7":"code","db73608e":"code","9ff3ad1d":"code","1257b3b0":"code","955bd46c":"code","3e1b5750":"code","bcc96dc3":"code","3c1f986f":"code","2ed7add6":"code","e2de6d05":"code","ac09d0bf":"code","d125be24":"code","3dfeb0e4":"code","9d71684a":"code","cbe29b42":"code","42ba6d8d":"code","594958e3":"code","aef2ea1e":"code","34a889ed":"code","4a0a0d4c":"code","0240b611":"code","e285df74":"code","1a60021a":"code","7d356ec2":"code","42bd863e":"code","be8bb271":"code","fa5fb3d9":"code","726d316f":"code","28042006":"markdown","98ba759f":"markdown"},"source":{"9df1ab2d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d693be8d":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error","18e6aeca":"data = pd.read_csv('\/kaggle\/input\/girlsgoit-competition-2020\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/girlsgoit-competition-2020\/test.csv')\nsubmit = pd.read_csv('\/kaggle\/input\/girlsgoit-competition-2020\/sampleSubmission.csv')\ndata.head(20)","ce3ccb72":"data.describe()\ndata.info()\n# data.corr()","523f1f6b":"plt.figure(figsize=(18,18))\nsns.heatmap(data.corr(), cmap=\"YlGnBu\", annot = True)\nplt.show()","ca76b52e":"X, y = data[['year']], data[['popularity']]","a077f328":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=4)","7291cb8a":"reg1 = LinearRegression().fit(X_train, y_train)","6c67568b":"print(\"Score on train:\")\nprint(\"R^2\", reg1.score(X_train, y_train))\nprint(\"MAE:\", mean_absolute_error(y_train, reg1.predict(X_train)))\n\nprint()\n\nprint(\"Score on test:\")\nprint(\"R^2\", reg1.score(X_test,y_test))\nprint(\"MAE:\", mean_absolute_error(y_test, reg1.predict(X_test)))","a0834aa8":"from sklearn.metrics import accuracy_score, f1_score, recall_score\n\nY_predict = reg1.predict(X_test).astype('int32')\nprint(\"Accuracy score:\", accuracy_score(y_test, Y_predict))\nprint(\"F1 score:\", f1_score(y_test, Y_predict, average='micro'))\nprint(\"Recall score:\", recall_score(y_test, Y_predict, average='micro'))","c83c0a01":"data.columns","d9663763":"X, y = data[['acousticness', 'danceability', 'duration_ms',\n       'energy', 'explicit', 'instrumentalness', 'key', 'liveness', 'loudness',\n       'mode', 'speechiness', 'tempo', 'valence',\n       'year']], data[['popularity']]\n","9aa735e7":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nreg1 = LinearRegression().fit(X_train, y_train)","db73608e":"print(\"Score on train:\")\nprint(\"R^2\", reg1.score(X_train, y_train))\nprint(\"MAE:\", mean_absolute_error(y_train, reg1.predict(X_train)))\n\nprint()\n\nprint(\"Score on test:\")\nprint(\"R^2\", reg1.score(X_test,y_test))\nprint(\"MAE:\", mean_absolute_error(y_test, reg1.predict(X_test)))","9ff3ad1d":"importance = reg1.coef_\nfeatures = ['acousticness', 'danceability', 'duration_ms',\n       'energy', 'explicit', 'instrumentalness', 'key', 'liveness', 'loudness',\n       'mode', 'speechiness', 'tempo', 'valence',\n       'year']\n# summarize feature importance\nfor i,v in enumerate(importance[0]):\n    print(features[i],v)","1257b3b0":"from matplotlib import pyplot\n# plot feature importance\npyplot.bar([x for x in range(len(importance[0]))], importance[0])\npyplot.show()#0 - 1","955bd46c":"Y_predict = reg1.predict(X_test).astype('int32')\nprint(\"Accuracy score:\", accuracy_score(y_test, Y_predict))\nprint(\"F1 score:\", f1_score(y_test, Y_predict, average='micro'))\nprint(\"Recall score:\", recall_score(y_test, Y_predict, average='micro'))","3e1b5750":"from sklearn.preprocessing import Normalizer\n\ntransformer = Normalizer().fit(X_train, 'max')  # fit does nothing.\n\n\nreg1 = LinearRegression().fit(transformer.transform(X_train), y_train)","bcc96dc3":"print(\"Score on train:\")\nprint(\"R^2\", reg1.score(transformer.transform(X_train), y_train))\nprint(\"MAE:\", mean_absolute_error(y_train, reg1.predict(transformer.transform(X_train))))\n\nprint()\n\nprint(\"Score on test:\")\nprint(\"R^2\", reg1.score(transformer.transform(X_test),y_test))\nprint(\"MAE:\", mean_absolute_error(y_test, reg1.predict(transformer.transform(X_test))))","3c1f986f":"X1 = X_train.copy()\nX1['year'] = (X1['year']-X1['year'].min())\/(X1['year'].max()- X1['year'].min())\n# X1['year']","2ed7add6":"def transform_custom(X1):\n    for col in features:\n        X1[col] = (X1[col]-X1[col].min())\/(X1[col].max()- X1[col].min())\n    return X1\nX_train = transform_custom(X_train)","e2de6d05":"X_train.head()","ac09d0bf":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nreg1 = LinearRegression().fit(transform_custom(X_train), y_train)","d125be24":"print(\"Score on train:\")\nprint(\"R^2\", reg1.score(transform_custom(X_train), y_train))\nprint(\"MAE:\", mean_absolute_error(y_train, reg1.predict(transform_custom(X_train))))\n\nprint()\n\nprint(\"Score on test:\")\nprint(\"R^2\", reg1.score(transform_custom(X_test),y_test))\nprint(\"MAE:\", mean_absolute_error(y_test, reg1.predict(transform_custom(X_test))))","3dfeb0e4":"importance = reg1.coef_\nfeatures = ['acousticness', 'danceability', 'duration_ms',\n       'energy', 'explicit', 'instrumentalness', 'key', 'liveness', 'loudness',\n       'mode', 'speechiness', 'tempo', 'valence',\n       'year']\n# summarize feature importance\nfor i,v in enumerate(importance[0]):\n    print(features[i],v)\n# plot feature importance\npyplot.bar([x for x in range(len(importance[0]))], importance[0])\npyplot.show()#0 - 1","9d71684a":"data.head(20)","cbe29b42":"max_per_year = data.groupby(['year'])['popularity'].apply(lambda x: x.value_counts().index[0]).reset_index()\nmax_per_year\nplt.plot(max_per_year['year'],max_per_year['popularity'])","42ba6d8d":"# hai sa mai facem careva date","594958e3":"import json\ndata['artists_array'] = data['artists'].apply(lambda x: [i.strip() for i in x.replace('[','').replace(']','').split(',')])#json.loads(x) if type(x) is str else []) \ndata['artists_nr'] = data['artists_array'].apply(len)\ndata.head()","aef2ea1e":"data[data['artists_nr']>1]#['artists_nr'].hist()","34a889ed":"data['artists_nr'].hist()","4a0a0d4c":"df = data[['artists_array', 'popularity']]\nar = df['artists_array'].to_list()\nscore = df['popularity'].to_list()\n","0240b611":"data[['artists','popularity']].groupby(['artists']).mean().sort_values(['popularity'])","e285df74":"data[data['artists'] ==\"['Khalid']\" ]","1a60021a":"ar = data[['artists','popularity']].groupby(['artists']).mean().reset_index()\nartist_p = {}\nfor p in ar.iterrows():\n    #print(p[1][1])\n    artist_p[p[1][0]] =  p[1][1]\n    #break\n    ","7d356ec2":"data['artists_popularity'] = data['artists'].apply(lambda x: artist_p[x])","42bd863e":"data.head()","be8bb271":"X, y = data[['acousticness', 'danceability', 'duration_ms',\n       'energy', 'explicit', 'instrumentalness', 'key', 'liveness', 'loudness',\n       'mode', 'speechiness', 'tempo', 'valence', 'artists_popularity',\n          'year'\n            ]], data[['popularity']]\n","fa5fb3d9":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nreg1 = LinearRegression().fit(X_train, y_train)\nprint(\"Score on train:\")\nprint(\"R^2\", reg1.score(X_train, y_train))\nprint(\"MAE:\", mean_absolute_error(y_train, reg1.predict(X_train)))\n\nprint()\n\nprint(\"Score on test:\")\nprint(\"R^2\", reg1.score(X_test,y_test))\nprint(\"MAE:\", mean_absolute_error(y_test, reg1.predict(X_test)))","726d316f":"Y_predict = reg1.predict(X_test).astype('int32')\nprint(\"Accuracy score:\", accuracy_score(y_test, Y_predict))\nprint(\"F1 score:\", f1_score(y_test, Y_predict, average='micro'))\nprint(\"Recall score:\", recall_score(y_test, Y_predict, average='micro'))","28042006":"# folosim mai multe caracteristici","98ba759f":"# incercam sa normalizam"}}