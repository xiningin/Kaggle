{"cell_type":{"450a79b9":"code","0b1c488f":"code","3c8d081b":"code","0d08ae80":"code","010f7727":"code","5b09e613":"code","aa9848b6":"code","872c7a12":"code","4cba64c0":"code","f1ac5f24":"code","df33feb6":"code","dfec7d1c":"code","33bdac2c":"code","8db96f43":"code","2daeda99":"code","29a0ebdc":"code","c9fd18ba":"code","f894b018":"code","6dbfb76e":"code","5f3b57c3":"code","466ab496":"code","afa267df":"code","026b8f1f":"code","82713666":"code","61d3b3b9":"code","3a431d21":"code","c19792c3":"code","98824713":"code","2c3f5b11":"code","193d6baf":"code","5a64799d":"code","b46e8eaf":"code","246891ed":"code","49bb3a00":"code","f2649916":"code","9c095c9d":"markdown","6ecce214":"markdown","6369365d":"markdown","e3da92e8":"markdown","08a0dd7d":"markdown","270b3534":"markdown","57e90cc6":"markdown","6baea37b":"markdown","56902dce":"markdown","501f6c3a":"markdown","9bd05a66":"markdown","b971c82e":"markdown","c6e674c2":"markdown","fb83fb0a":"markdown","9af74081":"markdown"},"source":{"450a79b9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0b1c488f":"import keras\nimport numpy as np \nimport pandas as pd \nimport zipfile\nimport matplotlib.pyplot as plt\nimport os\nimport shutil","3c8d081b":"shutil.unpack_archive('..\/input\/dogs-vs-cats\/train.zip','.\/')\nshutil.unpack_archive('..\/input\/dogs-vs-cats\/test1.zip','.\/')","0d08ae80":"#with zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/train.zip\", 'r') as zip_ref:\n                #zip_ref.extractall(\".\/\")\n\n#with zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/test1.zip\", 'r') as zip_ref:\n                #zip_ref.extractall(\".\/\")","010f7727":"print(\"Total train images\")\nprint(len([files for files in os.listdir('.\/train') if os.path.isfile(os.path.join('.\/train', files))]))\nprint(\"Total test images\")\nprint(len([files for files in os.listdir('.\/test1') if os.path.isfile(os.path.join('.\/test1', files))]))","5b09e613":"print(\"Total no of cat images in train dataset:\")\nprint(len([files for files in os.listdir('.\/train') if os.path.isfile(os.path.join('.\/train', files)) and 'cat' in files]))\nprint(\"Total no of dog images in train dataset:\")\nprint(len([files for files in os.listdir('.\/train') if os.path.isfile(os.path.join('.\/train', files)) and 'dog' in files]))","aa9848b6":"print(\"Total no of cat images in test dataset:\")\nprint(len([files for files in os.listdir('.\/test1') if os.path.isfile(os.path.join('.\/test1', files)) and 'cat' in files]))\nprint(\"Total no of dog images in test dataset:\")\nprint(len([files for files in os.listdir('.\/test1') if os.path.isfile(os.path.join('.\/test1', files)) and 'dog' in files]))","872c7a12":"for img in os.listdir('.\/train'):\n    img_path = os.path.join('.\/train',img)\n    print(img_path)\n    img_arr = plt.imread(img_path)\n    plt.imshow(img_arr)\n    break","4cba64c0":"for img in os.listdir('.\/test1'):\n    img_path = os.path.join('.\/test1',img)\n    print(img_path)\n    img_arr = plt.imread(img_path)\n    plt.imshow(img_arr)\n    break","f1ac5f24":" base_dir = '.\/'\n\ntrain_dir = os.path.join(base_dir, 'train_dir')\nos.mkdir(train_dir)\nval_dir = os.path.join(base_dir, 'val_dir')\nos.mkdir(val_dir)\ntest_dir = os.path.join(base_dir, 'test_dir')\nos.mkdir(test_dir)\n\ntrain_cats = os.path.join(train_dir, 'cats')\nos.mkdir(train_cats) \ntrain_dogs = os.path.join(train_dir, 'dogs')\nos.mkdir(train_dogs)\n\nval_cats = os.path.join(val_dir, 'cats')\nos.mkdir(val_cats) \nval_dogs = os.path.join(val_dir, 'dogs')\nos.mkdir(val_dogs)\n\ntest_cats = os.path.join(test_dir, 'cats')\nos.mkdir(test_cats) \ntest_dogs = os.path.join(test_dir, 'dogs')\nos.mkdir(test_dogs)","df33feb6":"files = ['cat.{}.jpg'.format(i) for i in range(8750)]\nfor filename in files:\n    src = os.path.join('.\/train', filename)\n    dst = os.path.join(train_cats, filename)\n    shutil.copyfile(src, dst)\n    \nfiles = ['cat.{}.jpg'.format(i) for i in range(8750, 12500)]\nfor filename in files:\n    src = os.path.join('.\/train', filename)\n    dst = os.path.join(val_cats, filename)\n    shutil.copyfile(src, dst)\n    \n\n    \nfiles = ['dog.{}.jpg'.format(i) for i in range(8750)]\nfor filename in files:\n    src = os.path.join('.\/train', filename)\n    dst = os.path.join(train_dogs, filename)\n    shutil.copyfile(src, dst)\n\nfiles = ['dog.{}.jpg'.format(i) for i in range(8750, 12500)]\nfor filename in files:\n    src = os.path.join('.\/train', filename)\n    dst = os.path.join(val_dogs, filename)\n    shutil.copyfile(src, dst)","dfec7d1c":"from keras.preprocessing.image import ImageDataGenerator\n\n\ntrain_datagen = ImageDataGenerator(\n    zoom_range = 0.2,\n    horizontal_flip = True,\n    rotation_range = 30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    validation_split=0.2,\n    rescale=1.\/255)\n\nval_datagen = ImageDataGenerator(rescale=1.\/255)","33bdac2c":"IMAGE_SIZE = (120,120)\nBATCH_SIZE = 128\n\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size = IMAGE_SIZE,\n    batch_size = BATCH_SIZE,\n    class_mode='binary')   \n\n\n\nval_generator = val_datagen.flow_from_directory(\n    val_dir,\n    target_size = IMAGE_SIZE,\n    batch_size = BATCH_SIZE,\n    class_mode = 'binary')","8db96f43":"for data_batch, label_batch in train_generator:\n    print(\"Train data batch shape:\", data_batch.shape)\n    print(\"Train label batch shape:\", label_batch.shape)\n    break;\n    \nfor data_batch, label_batch in val_generator:\n    print(\"Val data batch shape:\", data_batch.shape)\n    print(\"Val label batch shape:\", label_batch.shape)\n    break;","2daeda99":"for data_batch, label_batch in train_generator:\n    print(\"Train data batch shape:\", data_batch.shape)\n    print(\"Train label batch shape:\", label_batch.shape)\n    break;","29a0ebdc":"from keras.applications.vgg16 import VGG16\n\nconv_base = VGG16(weights='imagenet',\n                 include_top=False,\n                 input_shape=(120,120, 3))","c9fd18ba":"conv_base.summary()","f894b018":"conv_base.trainable = False","6dbfb76e":"from keras.models import Sequential\nfrom keras import layers\n\nmodel = Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dense(1, activation = 'sigmoid'))","5f3b57c3":"model.summary()","466ab496":"model.compile(loss='binary_crossentropy',\n             optimizer = keras.optimizers.Adam(),\n             metrics = ['acc'])","afa267df":"callbacks_list = [keras.callbacks.EarlyStopping(\n        monitor = 'acc',\n        patience = 2),\n                  keras.callbacks.ModelCheckpoint(\n        filepath='vgg16_standart.h5',\n        monitor='loss',\n        save_best_only=True)]","026b8f1f":"train_generator.n","82713666":"model_training = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    steps_per_epoch=train_generator.n\/\/BATCH_SIZE,\n    validation_steps=val_generator.n\/\/BATCH_SIZE,\n    epochs = 5,\n    callbacks = callbacks_list)","61d3b3b9":"acc = model_training.history['acc']\nval_acc=model_training.history['val_acc']\nloss = model_training.history['loss']\nval_loss = model_training.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'o', label='Training accuracy')\nplt.plot(epochs, val_acc, 'bo', label='Validation accuracy')\n\nplt.title('Training accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'o', label='Training loss')\nplt.plot(epochs, val_loss, 'bo', label='Validation loss')\nplt.title('Training loss')\nplt.legend()","3a431d21":"from keras.applications import DenseNet201\n\nconv_base = DenseNet201(weights='imagenet',\n                 include_top=False,\n                 input_shape=(120,120, 3))","c19792c3":"conv_base.summary()","98824713":"conv_base.trainable = False","2c3f5b11":"from keras.models import Sequential\nfrom keras import layers\n\nmodel_DN = Sequential()\nmodel_DN.add(conv_base)\nmodel_DN.add(layers.Flatten())\nmodel_DN.add(layers.Dense(256, activation='relu'))\nmodel_DN.add(layers.Dense(1, activation = 'sigmoid'))","193d6baf":"model_DN.summary()","5a64799d":"model_DN.compile(loss='binary_crossentropy',\n             optimizer = keras.optimizers.Adam(),\n             metrics = ['acc'])","b46e8eaf":"callbacks_list = [keras.callbacks.EarlyStopping(\n        monitor = 'acc',\n        patience = 1),\n                  keras.callbacks.ModelCheckpoint(\n        filepath='densenet201.h5',\n        monitor='loss',\n        save_best_only=True)]","246891ed":"train_generator.n","49bb3a00":"model_training = model_DN.fit(\n    train_generator,\n    validation_data=val_generator,\n    steps_per_epoch=train_generator.n\/\/BATCH_SIZE,\n    validation_steps=val_generator.n\/\/BATCH_SIZE,\n    epochs = 5,\n    callbacks = callbacks_list)","f2649916":"acc = model_training.history['acc']\nval_acc= model_training.history['val_acc']\nloss =  model_training.history['loss']\nval_loss =  model_training.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'o', label='Training accuracy')\nplt.plot(epochs, val_acc, 'bo', label='Validation accuracy')\n\nplt.title('Training accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'o', label='Training loss')\nplt.plot(epochs, val_loss, 'bo', label='Validation loss')\nplt.title('Training loss')\nplt.legend()","9c095c9d":"# VGG-16 MODEL","6ecce214":"Another way of unzipping files is :","6369365d":"**Showing a random image from test dataset**","e3da92e8":"# Test Data","08a0dd7d":"Always use 'sigmoid' in the final layer for binary classification. If we use 'softmax', the loss will become very big and hard to converge.","270b3534":"**Showing a random image in train dataset**","57e90cc6":"# DenseNet201","6baea37b":"**Lets create 3 directories each for training, testing and validation**","56902dce":"Lets now prepare the data !\n","501f6c3a":"Since images in test dataset are unlabelled, hence model can't find any 'cat' and 'dog' images","9bd05a66":"## Image Data Pre-processing","b971c82e":"Our model name is 'model'.\nThe History object gets returned by the fit method of models. Hence I assigned it as different name 'model_training' where the History object gets stored.","c6e674c2":"Go to this link to know more about keras.callbacks.History   http:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/callbacks\/History","fb83fb0a":"Adding callbacks","9af74081":"> Data batch shape : No.of batches x Img_size x no.of channels"}}