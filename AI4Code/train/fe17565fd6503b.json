{"cell_type":{"8ad86510":"code","f562d386":"code","d4c06c33":"code","d2b72c95":"code","de54968d":"code","2023067b":"code","dcc7f68e":"code","c001b085":"code","f5a61df4":"code","e39d42e7":"code","69b81928":"code","313234da":"code","d6494936":"code","e22fc508":"code","c21dd914":"code","d03e42b6":"code","22eb1538":"code","6eb77732":"code","a5b400d3":"code","72578864":"code","0d5239cd":"code","c7d2b81d":"code","203bbd93":"code","cdc2a6a3":"code","dc6ebc98":"code","e8c42aef":"code","e654a562":"code","988831e2":"code","ed2027f7":"code","05bfbcd0":"code","088acb87":"code","361ba9df":"code","88e6c6fe":"code","4d8c54eb":"code","c31f313e":"markdown","fe9e3b0e":"markdown","e469f63a":"markdown","a49b4619":"markdown","12f26fc5":"markdown","ef7c0a91":"markdown","e1fe7e6d":"markdown","a1380eaa":"markdown","30e54935":"markdown","c7254763":"markdown","0de7d39e":"markdown","c687a2d7":"markdown","7c752add":"markdown","83ee7079":"markdown","851730ef":"markdown","345106a5":"markdown","5ae6e6ed":"markdown","6de7592a":"markdown","45a1a016":"markdown","08b29235":"markdown","391dc05e":"markdown","a4e91ae6":"markdown","d3d4fbc1":"markdown","9de7eac4":"markdown"},"source":{"8ad86510":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nfrom torchvision.utils import make_grid\n\nimport shutil\nimport os\nfrom PIL import Image, ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom IPython.display import display\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","f562d386":"def main():\n\n    count = 0\n    \n    for root, dirs, files in os.walk(\"..\/input\/disaster-images-dataset\", topdown=False):\n        for name in files:\n                try:\n                    img = Image.open(os.path.join(root, name))\n                    img.verify()\n                except (IOError, SyntaxError) as e:\n                    \n                    # Count number of corrupt images\n                    count = count + 1\n                    print('Bad file:', name)\n                    \n                    # Move corrupt images to a different folder on computer\n                    # shutil.move(os.path.join(root, name), '..\/Data\/Corrupted_Images')\n    print(f'Number of corrupted images found = {count}')\n\nif __name__ == '__main__':\n    main()","d4c06c33":"train_transform = transforms.Compose([\n    transforms.RandomRotation(30),\n    transforms.RandomHorizontalFlip(),\n    transforms.Resize(224),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                        [0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                        [0.229, 0.224, 0.225])\n])","d2b72c95":"root = '..\/input\/disasters\/Disasters'\n\ntrain_data = datasets.ImageFolder(os.path.join(root, 'train'), transform = train_transform)\ntest_data = datasets.ImageFolder(os.path.join(root, 'test'), transform = test_transform)\n\ntorch.manual_seed(42)\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n\nclass_names = train_data.classes\n\nprint(class_names)\nprint(f'Training images available: {len(train_data)}')\nprint(f'Testing images available:  {len(test_data)}')","de54968d":"use_cuda = torch.cuda.is_available()\ndevice = torch.device('cuda:0' if use_cuda else 'cpu')","2023067b":"class ConvolutionalNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 6, 3, 1)\n        self.conv2 = nn.Conv2d(6, 12, 3, 1)\n        self.fc1 = nn.Linear(54*54*12, 48)\n        self.fc2 = nn.Linear(48, 24)\n        self.fc3 = nn.Linear(24, 12)\n\n    def forward(self, X):\n        X = F.relu(self.conv1(X))\n        X = F.max_pool2d(X, 2, 2)\n        X = F.relu(self.conv2(X))\n        X = F.max_pool2d(X, 2, 2)\n        X = X.view(-1, 54*54*12)\n        X = F.relu(self.fc1(X))\n        X = F.relu(self.fc2(X))\n        X = self.fc3(X)\n        return F.log_softmax(X, dim=1)","dcc7f68e":"torch.manual_seed(101)\nDisasterModel = ConvolutionalNetwork()\nDisasterModel.to(device)","c001b085":"criterion = nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(DisasterModel.parameters(), lr=0.001)","f5a61df4":"import time\nstart_time = time.time()\n\nepochs = 20\n\n# Trackers\ntrain_losses = []\ntest_losses = []\ntrain_correct = []\ntest_correct = []\n\nfor i in range(epochs):\n    trn_corr = 0\n    tst_corr = 0\n    \n    # Training batches\n    for b, (X_train, y_train) in enumerate(train_loader):\n        b += 1\n        \n        X_train = X_train.to(device)\n        y_train = y_train.to(device)\n        \n        y_pred = DisasterModel(X_train)\n        loss = criterion(y_pred, y_train)\n \n        # Tracking correct predictions\n        predicted = torch.max(y_pred.data, 1)[1]\n        batch_corr = (predicted == y_train).sum()\n        trn_corr += batch_corr\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # Print epoch and loss results\n        if b%100==0:\n            print(f'EPOCH: {i}  LOSS: {loss.item():10.8f}')\n        \n    train_losses.append(loss)\n    train_correct.append(trn_corr)\n        \n    # Testing batches\n    with torch.no_grad():\n        for b, (X_test, y_test) in enumerate(test_loader):\n            \n            X_test = X_test.to(device)\n            y_test = y_test.to(device)\n\n            y_val = DisasterModel(X_test)\n\n            # Tracking correct predictions\n            predicted = torch.max(y_val.data, 1)[1] \n            tst_corr += (predicted == y_test).sum()\n            \n    loss = criterion(y_val, y_test)\n    test_losses.append(loss)\n    test_correct.append(tst_corr)\n        \nprint(f'\\nDuration: {(time.time() - start_time)\/60} minutes')","e39d42e7":"torch.save(DisasterModel.state_dict(), 'DisasterModel.pt')","69b81928":"plt.plot(train_losses, label='training loss')\nplt.plot(test_losses, label='test loss')\nplt.title('Loss')\nplt.legend();","313234da":"plt.plot([t\/108 for t in train_correct], label='training accuracy')\nplt.plot([t\/27 for t in test_correct], label='test accuracy')\nplt.title('Accuracy')\nplt.legend();","d6494936":"print(f' Test accuracy = {(test_correct[-1].item()\/2714)*100} %')","e22fc508":"inv_normalize = transforms.Normalize(\n    mean=[-0.485\/0.229, -0.456\/0.224, -0.406\/0.225],\n    std=[1\/0.229, 1\/0.224, 1\/0.225])","c21dd914":"use_cuda = False\ndevice = torch.device('cuda:0' if use_cuda else 'cpu')","d03e42b6":"DisasterModel.to(device)\nDisasterModel.eval()","22eb1538":"misses = np.array([])\n\nfor i in range(len(predicted.view(-1))):\n    \n    predicted = predicted.to(device)\n    y_test = y_test.to(device)\n    \n    if predicted[i] != y_test[i]:\n        misses = np.append(misses, i).astype('int64')","6eb77732":"r = 5\nrow = iter(np.array_split(misses, len(misses)\/\/r+1))\n\n\nnp.set_printoptions(formatter=dict(int=lambda x: f'{x:5}'))\n\nnextrow = next(row)\nnext_row = torch.tensor(nextrow).to(device)\nX_test = X_test.to(device)\n\nlbls = y_test.index_select(0, next_row).numpy()\ngues = predicted.index_select(0, next_row).numpy()\nprint(\"Label:\", lbls)\nprint(\"Real Class: \", *np.array([class_names[i] for i in lbls]))\nprint()\nprint(\"Guess:\", gues)\nprint(\"Predicted Class: \", *np.array([class_names[i] for i in gues]))\n\nimages = X_test.index_select(0, next_row)\nim = make_grid(images, nrow = r)\nim = inv_normalize(im)\nplt.figure(figsize = (8, 4))\nplt.imshow(np.transpose(im.numpy(), (1, 2, 0)));","a5b400d3":"im = inv_normalize(test_data[3][0])\nplt.imshow(np.transpose(im.numpy(), (1, 2, 0)));\n\nwith torch.no_grad():\n    new_pred = DisasterModel(test_data[3][0].view(1,3,224,224)).argmax()\nprint(f'Predicted value: {new_pred.item()} {class_names[new_pred.item()]}')","72578864":"root = '..\/input\/disasters-generalized\/Disasters_Generalized'\n\ntrain_data = datasets.ImageFolder(os.path.join(root, 'train'), transform = train_transform)\ntest_data = datasets.ImageFolder(os.path.join(root, 'test'), transform = test_transform)\n\ntorch.manual_seed(42)\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n\nclass_names = train_data.classes\n\nprint(class_names)\nprint(f'Training images available: {len(train_data)}')\nprint(f'Testing images available:  {len(test_data)}')","0d5239cd":"use_cuda = torch.cuda.is_available()\ndevice = torch.device('cuda:0' if use_cuda else 'cpu')","c7d2b81d":"class ConvolutionalNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 6, 3, 1)\n        self.conv2 = nn.Conv2d(6, 12, 3, 1)\n        self.fc1 = nn.Linear(54*54*12, 48)\n        self.fc2 = nn.Linear(48, 24)\n        self.fc3 = nn.Linear(24, 6)\n\n    def forward(self, X):\n        X = F.relu(self.conv1(X))\n        X = F.max_pool2d(X, 2, 2)\n        X = F.relu(self.conv2(X))\n        X = F.max_pool2d(X, 2, 2)\n        X = X.view(-1, 54*54*12)\n        X = F.relu(self.fc1(X))\n        X = F.relu(self.fc2(X))\n        X = self.fc3(X)\n        return F.log_softmax(X, dim=1)","203bbd93":"torch.manual_seed(101)\nGen_DisasterModel = ConvolutionalNetwork()\nGen_DisasterModel.to(device)","cdc2a6a3":"criterion = nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(Gen_DisasterModel.parameters(), lr=0.001)","dc6ebc98":"import time\nstart_time = time.time()\n\nepochs = 20\n\n# Trackers\ntrain_losses = []\ntest_losses = []\ntrain_correct = []\ntest_correct = []\n\nfor i in range(epochs):\n    trn_corr = 0\n    tst_corr = 0\n    \n    # Training batches\n    for b, (X_train, y_train) in enumerate(train_loader):\n        b += 1\n        \n        X_train = X_train.to(device)\n        y_train = y_train.to(device)\n        \n        y_pred = Gen_DisasterModel(X_train)\n        loss = criterion(y_pred, y_train)\n \n        # Tracking correct predictions\n        predicted = torch.max(y_pred.data, 1)[1]\n        batch_corr = (predicted == y_train).sum()\n        trn_corr += batch_corr\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # Print epoch and loss results\n        if b%100==0:\n            print(f'EPOCH: {i}  LOSS: {loss.item():10.8f}')\n        \n    train_losses.append(loss)\n    train_correct.append(trn_corr)\n        \n    # Testing batches\n    with torch.no_grad():\n        for b, (X_test, y_test) in enumerate(test_loader):\n            \n            X_test = X_test.to(device)\n            y_test = y_test.to(device)\n\n            y_val = Gen_DisasterModel(X_test)\n\n            # Tracking correct predictions\n            predicted = torch.max(y_val.data, 1)[1] \n            tst_corr += (predicted == y_test).sum()\n            \n    loss = criterion(y_val, y_test)\n    test_losses.append(loss)\n    test_correct.append(tst_corr)\n        \nprint(f'\\nDuration: {(time.time() - start_time)\/60} minutes')","e8c42aef":"torch.save(Gen_DisasterModel.state_dict(), 'GenDisasterModel.pt')","e654a562":"plt.plot(train_losses, label='training loss')\nplt.plot(test_losses, label='test loss')\nplt.title('Loss')\nplt.legend();","988831e2":"plt.plot([t\/108 for t in train_correct], label='training accuracy')\nplt.plot([t\/27 for t in test_correct], label='test accuracy')\nplt.title('Accuracy')\nplt.legend();","ed2027f7":"print(f' Test Accuracy = {(test_correct[-1].item()\/2714)*100} %')","05bfbcd0":"use_cuda = False\ndevice = torch.device('cuda:0' if use_cuda else 'cpu')","088acb87":"Gen_DisasterModel.to(device)","361ba9df":"misses = np.array([])\n\nfor i in range(len(predicted.view(-1))):\n    \n    predicted = predicted.to(device)\n    y_test = y_test.to(device)\n    \n    if predicted[i] != y_test[i]:\n        misses = np.append(misses, i).astype('int64')","88e6c6fe":"r = 5 \nrow = iter(np.array_split(misses, len(misses)\/\/r+1))\n\n\nnp.set_printoptions(formatter=dict(int=lambda x: f'{x:5}'))\n\nnextrow = next(row)\nnext_row = torch.tensor(nextrow).to(device)\nX_test = X_test.to(device)\n\nlbls = y_test.index_select(0, next_row).numpy()\ngues = predicted.index_select(0, next_row).numpy()\nprint(\"Label:\", lbls)\nprint(\"Real Class: \", *np.array([class_names[i] for i in lbls]))\nprint()\nprint(\"Guess:\", gues)\nprint(\"Predicted Class: \", *np.array([class_names[i] for i in gues]))\n\nimages = X_test.index_select(0, next_row)\nim = make_grid(images, nrow = r)\nim = inv_normalize(im)\nplt.figure(figsize = (8, 4))\nplt.imshow(np.transpose(im.numpy(), (1, 2, 0)));","4d8c54eb":"im = inv_normalize(test_data[2021][0])\nplt.imshow(np.transpose(im.numpy(), (1, 2, 0)));\n\nwith torch.no_grad():\n    new_pred = Gen_DisasterModel(test_data[2021][0].view(1, 3, 224, 224)).argmax()\nprint(f'Predicted value: {new_pred.item()} {class_names[new_pred.item()]}')","c31f313e":"## Disastermodel()","fe9e3b0e":"### Define Model","e469f63a":"## Gen_DisasterModel()","a49b4619":"### Standard Imports","12f26fc5":"### Define Model","ef7c0a91":"### Model Performance","e1fe7e6d":"### Define Transformations","a1380eaa":"### Model Performance","30e54935":"### Predicting New Image","c7254763":"# Disaster Classification Model\nAfter downloading the dataset, I just manually moved the files to different folders to create the structure I needed to build each model. The first model, DisasterModel(), identified 12 different classes of disasters and non-disasters: *Drought, Earthquake, Human, Human Damage, Infrastructure, Land Slide, Non-Damage Buildings Street, Non-Damage Wildlife Forest, Sea, Urban Fire, Water Disaster, Wild Fire*. While the second model, Gen_DisasterModel(), used a generalized dataset that categorizes the disasters into 5 groups of disasters and a non-disaster group as follows: \n1. **Damaged Infrastructure**\n    - Earthquake\n    - Infrastructure \n2. **Fire Disaster** \n    - Urban Fire\n    - Wild Fire\n3. **Human Damage**\n4. **Land Disaster**\n    - Drought\n    - Land Slide\n5. **Water Disaster** \n6. **Non-Damage**\n    - Human\n    - Non-Damage Buildings\n    - Non-Damage Wildlife Forest\n    - Sea ","0de7d39e":"### Define Loss and Optimization Functions","c687a2d7":"### Examining Misses","7c752add":"### Predicting New Image","83ee7079":"After downloading the dataset, I found 9 corrupted images. Running in Kaggle, it only found 1. ","851730ef":"### Prepare Test and Train Sets, Loaders","345106a5":"### Train Model","5ae6e6ed":"### Examining Misses","6de7592a":"## Acknowledgements \nMost of this code I learned from [Jose Portilla's Course on Pytorch](https:\/\/www.udemy.com\/course\/pytorch-for-deep-learning-with-python-bootcamp\/). I just adapted the code to better fit this dataset. Thanks for going through my notebook :) ","45a1a016":"### Define Loss and Optimization Functions","08b29235":"### Prepare Test and Train Sets, Loaders","391dc05e":"splitfolders.ratio('..\/Data\/Disaster_Dataset', output='..\/Data\/Disasters_Generalized', seed=1337, \n                               ratio=(.8, .2), group_prefix=None) ","a4e91ae6":"### Train Model","d3d4fbc1":"splitfolders.ratio('..\/Data\/Disaster_Dataset', output='..\/Data\/Disasters', seed=1337, \n                               ratio=(.8, .2), group_prefix=None) ","9de7eac4":"### Data Preprocessing\nWhile conducting exploratory analysis on the image dataset I ran into an IOError for some of the images. I found that these files were corrupted. Thus, I wrote a script to find, count and move the corrupted images into a separate folder. "}}