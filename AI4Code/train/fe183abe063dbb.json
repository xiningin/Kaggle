{"cell_type":{"03420aeb":"code","c93fb787":"code","54bfb185":"code","ceed4a91":"code","06485379":"code","b33d422a":"code","bd69b46d":"code","ce82ab33":"code","ba3c157e":"code","25e4d2f1":"code","a69e430e":"code","c57c9ca8":"code","c8a4f48a":"code","2c022a05":"code","8fc3eb5f":"code","b95d0793":"code","b0c3712a":"code","45b62b6b":"code","8d212603":"code","587d1ad6":"code","8ec8cc9e":"code","cc3f3d03":"code","00c55332":"code","156a9e1b":"code","fb3851e6":"code","178c28c7":"code","017b8001":"code","629cfa6f":"code","cc402c00":"code","904fee61":"code","098e149b":"code","e69dbf7f":"code","b53fd2f1":"code","4ca201d8":"code","ad91bc8c":"code","f55a1bed":"code","309604d9":"code","2673d4e7":"code","fc6c3ed5":"code","8607a794":"code","1f672056":"code","8563349d":"code","a929380f":"code","4edd6a41":"code","25e603a6":"code","8ad23856":"code","50335140":"code","dcc7cd70":"code","7a6323fe":"code","fa1795f2":"markdown","c2ee22ad":"markdown","df9b3a17":"markdown","d65772a4":"markdown","19299378":"markdown","0bbfc282":"markdown","a0967cd2":"markdown","abec11b4":"markdown","f5320c72":"markdown","ac402cd2":"markdown","4304da5d":"markdown","69620d0c":"markdown","6ae0e4ba":"markdown","b4f604d1":"markdown","d0b4a325":"markdown","36ecc375":"markdown","8c954e11":"markdown","6851c25b":"markdown","fcfe7ff7":"markdown"},"source":{"03420aeb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c93fb787":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n","54bfb185":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","ceed4a91":"train.head()","06485379":"train.isnull().sum()","b33d422a":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumeric_values = train.select_dtypes(include=numerics)\nnumeric_values.isnull().sum()","bd69b46d":"#select all category features and check which of them has nan values\ncategorical_values = train.select_dtypes(include=object)\ncategorical_values.isnull().sum() \/ len(train)","ce82ab33":"train.drop('Cabin', axis=1, inplace=True)","ba3c157e":"train['Embarked'].mode()\ntrain['Embarked'] = train['Embarked'].fillna(\"S\")","25e4d2f1":"plt.figure(figsize=(12,6))\nsns.distplot(train['Age'].dropna(), bins=60, kde=False)","a69e430e":"plt.figure(figsize=(12,6))\nsns.distplot(train['Age'].dropna(), bins=4, kde=False, color='r' )","c57c9ca8":"#show the age  groups in a pie chart\nage_groups = train['Age'].dropna().value_counts(bins=4, sort=False)\nplt.figure(figsize=(12,6))\nlabels = '0-20','21-40', '41-60', '60+'\nplt.pie(age_groups, labels=labels, autopct='%1.1f%%', shadow=True, startangle=140) ","c8a4f48a":"print(X_balanced.shape)\nprint(X_balanced[0])","2c022a05":"def average_age(dataset):\n    \n    ### Find out how many people are in a certain age group 0-20 , 21-40, 41-60, 60+\n    age_group_1 = []\n    age_group_2 = []\n    age_group_3 = []\n    age_group_4 = []\n\n    for i in range(len(dataset)):\n\n        if dataset['Age'][i] < 20:\n            age_group_1.append(dataset['Age'][i])\n        elif dataset['Age'][i] >= 20 and dataset['Age'][i] < 40:\n            age_group_2.append(dataset['Age'][i])\n        elif dataset['Age'][i] >= 40 and dataset['Age'][i] < 60:\n            age_group_3.append(dataset['Age'][i])\n        elif dataset['Age'][i] >= 60 and dataset['Age'][i] < 90:\n            age_group_4.append(dataset['Age'][i])\n\n    #calculate the average age for all age groups\n    avg_age_1 = round(np.mean(age_group_1),0) \n    avg_age_2 = round(np.mean(age_group_2),0) \n    avg_age_3 = round(np.mean(age_group_3),0)\n    avg_age_4 = round(np.mean(age_group_4),0)\n    \n    #calculate how many people (%) are in each group\n    total_people = dataset['Age'].notnull().sum()\n    percent_age_1 = round(len(age_group_1) \/ total_people,2)\n    percent_age_2 = round(len(age_group_2) \/ total_people,2)\n    percent_age_3 = round(len(age_group_3) \/ total_people,2)\n    percent_age_4 = round(len(age_group_4) \/ total_people,2)\n\n    #calculate how many people there should be in each group for the missing values\n    total_people_nan = dataset['Age'].isnull().sum()\n    ave_age_group_1 = round(percent_age_1 * total_people_nan,0)\n    ave_age_group_2 = round(percent_age_2 * total_people_nan,0)\n    ave_age_group_3 = round(percent_age_3 * total_people_nan,0)\n    ave_age_group_4 = round(percent_age_4 * total_people_nan,0)\n    \n    \n    #setting all nan to 0 and add them to a list\n    dataset['Age'] = dataset.fillna(0)['Age']\n\n    indices_with_age_0 = []\n\n    for z in range(len(dataset)):\n\n        if dataset['Age'][z] == 0:\n            indices_with_age_0.append(z)\n\n    #setup steps that will be checked in the for loop, first step is all people 0-19 next step is all people 20-39 and so on.\n    step_1 = ave_age_group_1              \n    step_2 = step_1 + ave_age_group_2      \n    step_3 = step_2 + ave_age_group_3\n    step_4 = step_3 + ave_age_group_4\n\n    #loop through all rows of age = 0 and add the average age for each age group. \n    for x in range(len(indices_with_age_0)):\n\n        if x <= step_1:\n            dataset.at[indices_with_age_0[x], 'Age'] = avg_age_1\n        elif x > step_1 and x <= step_2:\n             dataset.at[indices_with_age_0[x], 'Age'] = avg_age_2\n\n        elif x > step_2 and x <= step_3:\n             dataset.at[indices_with_age_0[x], 'Age'] = avg_age_3\n        elif x > step_3 and x <= step_4:\n             dataset.at[indices_with_age_0[x], 'Age'] = avg_age_4\n    \n    return dataset['Age']                                                                                                                                                                                                               ","8fc3eb5f":"train['Age'] = average_age(train)","b95d0793":"#All nan values  are handled.\ntrain.isnull().sum()","b0c3712a":"sns.countplot(x='Survived', hue='Sex', data=train,palette='viridis_r')","45b62b6b":"sns.countplot(x='Survived', hue='Pclass', data=train,palette='rainbow')","8d212603":"sns.countplot(x='Pclass', hue='Sex', data=train,palette='rainbow')","587d1ad6":"sns.countplot(x='Survived', hue='Embarked', data=train,palette='spring')","8ec8cc9e":"sns.countplot(x='Embarked', hue='Pclass', data=train,palette='winter')","cc3f3d03":"sns.countplot(x='Embarked', hue='Sex', data=train,palette='YlOrBr_r')","00c55332":"train.head()","156a9e1b":"categorical_values = train.select_dtypes(include=object)\ncategorical_values","fb3851e6":"train.drop(['Name', 'Ticket'], axis=1, inplace=True)","178c28c7":"train.head()\ncategorical_values = train.select_dtypes(include=object)\ncategorical_values","017b8001":"#create function to loop throug categorical features and add dummy values\ndef dummy_df(df, todummylist):\n    for x in todummylist:\n       dummies = pd.get_dummies(df[x], prefix=x, dummy_na = False, drop_first=True)\n       df = df.drop(x, 1)\n       df = pd.concat([df, dummies], axis = 1)\n    return df","629cfa6f":"#create dummies for all categorical features\ndummies = list(categorical_values)\ntrain = dummy_df(train, dummies)","cc402c00":"train.rename(columns={'Sex_male':'Male'}, inplace=True)\ntrain.head()","904fee61":"train[\"Pclass\"] = train[\"Pclass\"].astype(\"category\")\ntrain = pd.get_dummies(train, columns = [\"Pclass\"],prefix=\"Pc\", drop_first=True)","098e149b":"plt.figure(figsize=(12,6))\nsns.heatmap(train.corr(), annot=True)","e69dbf7f":"#create function to decide which features that are correlated which eachother.\ndef correlation(dataset, threshold):\n    \n    col_corr = set()\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) > threshold:\n                colname = corr_matrix.columns[i]\n                col_corr.add(colname)\n    return col_corr ","b53fd2f1":"#check if any feature correlate with eachother.\ncorr_features = correlation(train, 0.8)\nlen(set(corr_features))\ncorr_features","4ca201d8":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.feature_selection import SelectFromModel\n","ad91bc8c":"features = ['Male', 'Fare', 'Embarked_Q', 'Embarked_S', 'Pc_2', 'Pc_3', 'Age']\nX = train[features]\ny = train['Survived']","f55a1bed":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)","309604d9":"X_train.head()","2673d4e7":"#scaling the features\nscaler_X = MinMaxScaler()\nscale_X_train = scaler_X.fit_transform(X_train)\nscale_X_test = scaler_X.transform(X_test)","fc6c3ed5":"classifier = RandomForestClassifier(max_depth=10, n_estimators=300, criterion='gini')\nclassifier.fit(scale_X_train, y_train)","8607a794":"## Applying grid search  to find the best model and the best parameters\nparameters = [{'n_estimators': [200,300,400, 500,600,800],\n               'criterion': ['entropy', 'gini'],\n               'max_depth': [3,5,10,15,20]\n                }]\ngrid_search = GridSearchCV(estimator = classifier, param_grid = parameters, scoring = 'accuracy', cv=10)\n\ngrid_search = grid_search.fit(scale_X_train, y_train)\n\nbest_acc = grid_search.best_score_\nbest_para = grid_search.best_params_\nprint(best_acc)\nprint(best_para)","1f672056":"classifier = DecisionTreeClassifier(criterion='gini', max_depth=3, splitter='best')\nclassifier.fit(scale_X_train, y_train)","8563349d":"## Decision tree\nparameters = [{\n               'criterion': ['entropy', 'gini'],\n               'max_depth': [3,5,10,15,20],\n               'splitter': ['best', 'random'],               \n                }]\ngrid_search = GridSearchCV(estimator = classifier, param_grid = parameters, scoring = 'accuracy', cv=10)\n\ngrid_search = grid_search.fit(scale_X_train, y_train)\n\nbest_acc = grid_search.best_score_\nbest_para = grid_search.best_params_\n\nprint(best_acc)\nprint(best_para)","a929380f":"classifier = SVC(kernel = 'rbf', C = 1000, gamma = 0.08)\nclassifier.fit(scale_X_train, y_train)","4edd6a41":"parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear'], 'gamma': [0.09, 0.08,0.07,0.06,0.05],\n               'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.09, 0.08,0.07,0.06,0.05]\n                }]\ngrid_search = GridSearchCV(estimator = classifier, param_grid = parameters, scoring = 'accuracy', cv=10)\n\ngrid_search = grid_search.fit(scale_X_train, y_train)\n\nbest_acc = grid_search.best_score_\nbest_para = grid_search.best_params_\nprint(best_acc)\nprint(best_para)","25e603a6":"#check accuracy with Cross val score\naccuracies = cross_val_score(estimator = classifier, X = scale_X_train, y = y_train, cv=10)\nprint(accuracies.mean())\nprint(accuracies.std())","8ad23856":"#predict\ny_pred = classifier.predict(scale_X_test)","50335140":"#evaluate prediction\nfrom sklearn.metrics import confusion_matrix, classification_report\ncm = confusion_matrix(y_test, y_pred)\nclassification = classification_report(y_test, y_pred)\n","dcc7cd70":"print(cm)","7a6323fe":"print(classification)","fa1795f2":"**It looks like the Sex is a factor when it comes to who survived. More women than men survived according to the graphs above.**","c2ee22ad":"# Load Data","df9b3a17":"# Correlations","d65772a4":"# Test different classifiers","19299378":"**Random Forest**","0bbfc282":"***I decide to split up the age to 4 age groups. 0-20, 21-40, 41-60, 60+ and create a function to add the average age in each group***","a0967cd2":"# **Missing Values**","abec11b4":"# Exploratory Data Analysis","f5320c72":"**It looks like people who embarked from S survived more often than people who embarked from the other places. Why is this ?**","ac402cd2":"# **Prediction**","4304da5d":"# Categorical variables","69620d0c":"**Decision Tree**","6ae0e4ba":"# **Evaluate my classifier settings before prediction**\n**In this case I choose SVC **","b4f604d1":"**Try to find correlations between the features with different plots**","d0b4a325":"***It looks like a lot of the people from 1 and 2 class embarked from S and also alot of women. But in this case I would say it's because the majority of women embarked from S and therefore embarked from S has more survivals than the other places.***","36ecc375":"**Since Cabin have 77% missing values I decide to remove the column. \nEmbarked I choose to add the mode value to fill in the missing values. \nFor age I need to explore a little more to decide how to fill those missing values**","8c954e11":"# Model","6851c25b":"***I decide to drop Name and Ticket since they have to many uinique values and isn't a good fit for dummy variables. ***","fcfe7ff7":"**SVC **"}}