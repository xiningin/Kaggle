{"cell_type":{"f2fa44d7":"code","76fead13":"code","9ff0576c":"code","7b769bf9":"code","0880ee48":"code","33f42c08":"code","66367ff9":"code","51df1a40":"code","34f9fb6f":"code","25f1ea01":"code","dbcdd848":"code","3841bfcf":"code","5f789604":"code","387deceb":"code","a48088ef":"code","252cd155":"code","afe5498f":"code","2168c1cc":"code","4d7cb51d":"code","b72fdadc":"code","a36ccb00":"code","5d24b401":"code","5755e626":"code","9dc17a01":"code","df5ccf6a":"code","80172f03":"code","59f8f7fd":"code","b9186e82":"markdown","aa162be2":"markdown","7f8fbe2b":"markdown","7be1264a":"markdown","201f711c":"markdown","37275f74":"markdown","62fd42e7":"markdown","105cbe81":"markdown"},"source":{"f2fa44d7":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np","76fead13":"\ndf = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')#read in and store training data \ndf_test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv') #read in and store test data","9ff0576c":" #combine train and test sets to ensure all modifications made to train also are applied to test data\ndf_combo = pd.concat([df,df_test], ignore_index = True)","7b769bf9":"df_combo.info() #explore data","0880ee48":"y = df[\"SalePrice\"] #store target values before dropping\nid_test = df_test[\"Id\"] #save test ids before dropping as this will be reattached for final submittal","33f42c08":"#Find features that contain null values\nlist_nulls = df_combo.isnull().sum().sort_values(ascending = False) #creates series of total nulls for each feature\nlist_nulls=list_nulls[list_nulls > 0] #provides series of features that contain null values \nlist_nulls #view series of features with null values ","66367ff9":"list_nulls = list_nulls.reset_index() #reset index \na = list(list_nulls['index']) #convert series into a list\na #view list ","51df1a40":" #create function to examine characterics of each feature containing null values.\ndef filler (x):\n    print (x)\n    print(df_combo[x].unique())\n    print (len(df_combo[df_combo[x].isnull()]))\n    print (df_combo[x].mode())\n    \n#Uses a for loop to go through list of features with null values and prints the\n#feature name, unique values, and mode of each feature containing nulls  \nfor i in a: \n    filler(i)\n    print (\"----------------\") \n    ","34f9fb6f":"#Drop the features below because of lack of data. ID and SalePrice dropped and saved for later.\ndf_combo.drop(columns=([\"PoolQC\", \"FireplaceQu\",\"MiscFeature\", \"Alley\", \"Fence\", \"Id\", \"SalePrice\"]), inplace = True)","25f1ea01":"#create dictionary for fillna for features using mode for categorical and average values for numerical features\nmode_dict = {\"GarageType\":\"Attchd\", \"GarageFinish\":\"Unf\", \"GarageQual\":\"TA\", \"GarageCond\":\"TA\", \"BsmtExposure\":\"No\", \n            \"BsmtFinType2\":\"Unf\", \"BsmtQual\":\"TA\", \"BsmtCond\":\"TA\", \"BsmtFinType1\":\"Unf\", \"MasVnrType\":\"None\", \"Electrical\":\"SBrkr\", \"MSZoning\":'RL',\n            \"Utilities\":\"AllPub\", \"Exterior2nd\":\"VinlySd\", \"Exterior1st\":\"VinlySd\", \"BsmtFinSF1\":441,\n             \"BsmtFinSF2\":49.5, \"BsmtUnfSF\":560.77, \"TotalBsmtSF\":1051.78, \"BsmtFullBath\":0,\n             \"BsmtHalfBath\":0, \"KitchenQual\": \"TA\", \"Functional\":\"Typ\", \"GarageCars\":2, \"GarageArea\":472.87,\n             \"SaleType\":\"WD\", 'GarageYrBlt':1980, \"MasVnrArea\":103.69, \"LotFrontage\":70}\n","dbcdd848":"df_combo.fillna(value=mode_dict, inplace = True) #fill nulls with dictionary from above","3841bfcf":"df_combo.info() #check to see if all null values have been filled. They have been filled.","5f789604":"#Seperate out categorical features from numerical to assign dummy variables \ndf_cat = pd.DataFrame(df_combo.select_dtypes('object'))#all categorical features that will be converted to numeric\nnumerical_df = pd.DataFrame(df_combo.select_dtypes(['float','int'])) #all numeric features","387deceb":"from sklearn.preprocessing import OneHotEncoder #import OneHotEncoder to apply to categorical var","a48088ef":"one_hot = OneHotEncoder() ","252cd155":"cat = one_hot.fit_transform(df_cat)#fit_transform df of categorical features","afe5498f":"cat = pd.DataFrame(cat.toarray()) #currently in form of sparse matrix, need to convert back to dataframe","2168c1cc":"df_final = pd.concat([cat,numerical_df], axis = 1) \n#combine numerical_df with cat","4d7cb51d":"df_final.info() #check on new df","b72fdadc":"from sklearn.preprocessing import StandardScaler #need to scale data \nscaler = StandardScaler()","a36ccb00":"df_scaled = scaler.fit_transform(df_final) #Scale data","5d24b401":"df_final_test = pd.DataFrame(df_scaled).iloc[1460:] #Scaled test df","5755e626":"df_final_train = pd.DataFrame(df_scaled).iloc[0:1460] #Scaled train df","9dc17a01":"from sklearn.linear_model import ElasticNetCV #will use ElasticNetCV","df5ccf6a":"model_elastic_net = ElasticNetCV(l1_ratio = [.1,.5,.7,.9,.95,.99,1], eps = 0.001, n_alphas=100,\n                                max_iter=1000000) #est. model and hyperparameters\nmodel_elastic_net.fit(df_final_train, y) #fit model on training data and y target","80172f03":"#Predictions using elastic net model which result in an approxmiate .14 RMSLE.\nelastic_net_predict = model_elastic_net.predict(df_final_test) ","59f8f7fd":"e = pd.Series(elastic_net_predict) #convert to a series\nfinal_result = pd.concat([id_test,e], axis =1) #combine ids from test data and predictions from elastic net model\nfinal_result.rename(columns={0:\"SalePrice\"}, inplace=True) #rename column title\nfinal_result.to_csv(\"Housing_Prices.csv\",index=False) #Send to final csv file","b9186e82":"Scale Data","aa162be2":"Seperate Test Set from Training Set","7f8fbe2b":"Prepare and send to csv file","7be1264a":"EXPLORING NULL VALUES AND DECIDING HOW TO FILL THEM","201f711c":"DROP FEATURES","37275f74":"Create Model ","62fd42e7":"Predict with Test Data","105cbe81":"Convert Categorical Values to Numerical "}}