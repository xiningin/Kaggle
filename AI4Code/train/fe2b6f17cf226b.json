{"cell_type":{"2812800a":"code","5b6ae031":"code","0b259769":"code","276eabf4":"code","16264ec8":"code","add46be0":"code","02ceeef8":"code","5c25517c":"code","3e089d35":"code","d65cac4c":"code","ebe3cb2b":"code","9394436b":"code","34a9ec4e":"code","37c90aa5":"code","05aea318":"code","8a5d70e8":"code","33369aff":"markdown","24482fc5":"markdown","9803ff4e":"markdown","746c68e5":"markdown","7f136439":"markdown","65e916fa":"markdown","9463612c":"markdown","ce6ab7c8":"markdown","343f9284":"markdown","8781131b":"markdown","a9964ddb":"markdown","62b7756e":"markdown","e65568a4":"markdown","c431007f":"markdown"},"source":{"2812800a":"import os\nimport sys\nimport glob\nimport random\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport missingno as msno\n\nfrom random import choice, choices\nfrom tqdm import tqdm\nfrom itertools import cycle\nfrom scipy.stats import skewnorm\n\n\npd.set_option(\"display.max_columns\", None)\n\nplt.style.use(\"ggplot\")\ncolor_pal = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\ncolor_cycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])\n\nimport warnings\nwarnings.filterwarnings('ignore')","5b6ae031":"def plot_dist_box(value, title=''):\n    c = choice(color_pal)\n    f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw = {\"height_ratios\": (0.2, 1)}, figsize=(18, 9))\n    mean, median = np.mean(value), np.median(value)\n    \n    sns.boxplot(value, ax=ax_box, color=c)\n    #ax_box.axvline(mean, color='r', linestyle='--')\n    #ax_box.axvline(median, color='b')\n    \n    sns.distplot(value, ax=ax_hist, color=c)\n    #ax_hist.axvline(mean, color='r', linestyle='--')\n    #ax_hist.axvline(median, color='b')\n    plt.title(title)\n    plt.show()","0b259769":"%%time\ntrain_df = pd.read_parquet('..\/input\/ubiquant-parquet\/train.parquet')","276eabf4":"train_df.head()","16264ec8":"print(\"No of unique investment_id in test : \", train_df.investment_id.nunique())","add46be0":"time_stat_df = train_df.groupby(['investment_id'])['time_id'].agg(['count', 'min', 'max', 'std']).reset_index()\ntime_stat_df['diff'] = time_stat_df['max'] - time_stat_df['min']\ntime_stat_df.head()","02ceeef8":"plot_dist_box(time_stat_df['count'], title=\"Number of time_id's per investment_id distribution\")","5c25517c":"plot_dist_box(time_stat_df['min'], title=\"Started time_id's per investment_id distribution\")","3e089d35":"# chcking missing time_ids\nprint(f\"We have {time_stat_df.query('count != diff').shape[0]} no of investment_ids missing at least one time_id out of {time_stat_df.shape[0]}\")","d65cac4c":"time_stat_df['miss_count'] = time_stat_df['diff'] - time_stat_df['count']\n\nplot_dist_box(time_stat_df['miss_count'], title=\"Missing time_id's per investment_id distribution\")","ebe3cb2b":"fig, ax = plt.subplots(figsize=(30, 5))\ntrain_df.groupby('time_id')['investment_id'].count().plot(color=choice(color_pal))\nplt.title(\"unique investment_id's by time\")\nplt.show()","9394436b":"tmp_df = train_df[['time_id', 'investment_id']].copy()\ntmp_df['target'] = 0\ntmp_df = tmp_df.pivot(index='investment_id', columns=['time_id'])\n#tmp_df = tmp_df.loc[tmp_df.isna().sum(axis=1).sort_values().index]","34a9ec4e":"msno.matrix(tmp_df)\nplt.show()","37c90aa5":"plot_dist_box(train_df['target'], 'Target Distribution')\nprint(f\"Target Mean :{train_df['target'].mean()} - Std :{train_df['target'].std()} - Median :{train_df['target'].median()}\" )","05aea318":"# target over time\nfig, ax = plt.subplots(figsize=(30, 5))\ntrain_df.groupby('time_id')['target'].count().plot()\nplt.title(\"unique investment_ids over time\")\n\nfig, ax = plt.subplots(figsize=(30, 10))\nax = train_df.groupby('time_id')['target'].mean().plot()\nax = train_df.groupby('time_id')['target'].std().plot()\nax = train_df.groupby('time_id')['target'].median().plot()\nax.legend(['mean', 'std', 'median'])\nplt.title(\"target mean vs std vs median over time\")\nplt.show()","8a5d70e8":"# target vs investiment_ids\n\nfig, ax = plt.subplots(figsize=(30, 5))\ntmp_df = train_df.groupby('investment_id')['target'].agg(['count', 'min', 'max', 'std', 'mean', 'median']).reset_index()\ntmp_df = tmp_df.sort_values('count').reset_index(drop=True)\ntmp_df['count'].plot()\nplt.title(\"target count sort by investment_id frequency\")\n\nfig, ax = plt.subplots(figsize=(30, 5))\nax = tmp_df['mean'].plot()\nax = tmp_df['median'].plot()\nax.legend(['mean', 'median'])\nplt.title('meam vs median over investmet_id')\n\nfig, ax = plt.subplots(figsize=(30, 5))\nax = tmp_df['std'].plot()\nplt.title('std over investment_id')\nplt.show()","33369aff":"- We can observe that more then 50% investments are having > 100 missing time_ids","24482fc5":"- Above df exlpaines about unique `investment_id` \n- `count`: number of rows in training data for that investment_id\n- `min`: time id when that investment_id started\n- `max`: time id when that investment_id ended (1219 is max in training)\n- `std`: time_id spred for that investment_id ","9803ff4e":"- we can observe that when the less time_id's per investment_id more fluctuations in target.","746c68e5":"- We can observe that lots of investment_id's have missing time_ids ","7f136439":"- we can observe that when the less number of investment_ids over time more fluctuations in mean, std, median target over time ","65e916fa":"### time_id vs investment_id\n\n- In training data we have time_id range between `0` to `1219`.\n- We will try to understand time_id vs investment_id in next few cells.\n- I am extracting some stats from those two features","9463612c":"- We can observe that most of the investments started when time=0, some investments started in between 200 to 400 and 600 to 1000","ce6ab7c8":"### Please upvote if like it \ud83d\ude42 ","343f9284":"- We can observe that lot's of time_ids missing in between time_id 300 to 550.\n- And also after time_id 600 investment_ids increase a lot towards the end.","8781131b":"# Target","a9964ddb":"## Problem Statement\n\nIn this competition, you\u2019ll build a model that forecasts an `investment's return rate`.\n\n","62b7756e":"**train.csv**\n\n- `row_id` - A unique identifier for the row.\n- `time_id` - The ID code for the time the data was gathered. The time IDs are in order, but the real time between the time IDs is not constant and will likely be shorter for the final private test set than in the training set.\n- `investment_id` - The ID code for an investment. Not all investment have data in all time IDs.\n- `target` - The target.\n- `[f_0:f_299]` - Anonymized features generated from market data.\n","e65568a4":"### Missing time_ids","c431007f":"## Data\n\nDataset Link here: https:\/\/www.kaggle.com\/robikscube\/ubiquant-parquet\n\nRead about parquet files here: https:\/\/databricks.com\/glossary\/what-is-parquet\n\n5.5GB in size.\n\nThis is faster and keeps the dtypes of the original dataset."}}