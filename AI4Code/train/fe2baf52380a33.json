{"cell_type":{"1a9009a5":"code","6183edcc":"code","9e27357f":"code","e802b022":"code","cd4f0252":"code","0d69c72c":"code","0dbfed68":"code","740fccac":"code","7dd94d66":"code","2e1fef77":"code","53404464":"code","45e180b2":"code","a511a5ee":"code","2eebcfa0":"code","caa1a663":"code","48adb334":"code","f1542823":"code","47b79652":"code","9b2e7030":"code","8aebbaa1":"code","aa2c01be":"code","6d30ccce":"code","aaf7c3be":"code","86b0105d":"code","4333b2fb":"code","6606854d":"code","5bc3df1b":"code","90ae6789":"code","ad724d64":"code","288f5f18":"code","d400502a":"code","d6893332":"code","e767bb14":"code","4ac37555":"code","72aaa1e8":"code","a35b0658":"code","6b221a35":"code","ae0fbf04":"code","64fccd15":"code","49c3990d":"code","d8d52e22":"code","2e519783":"code","9d1142a5":"code","f49848f5":"code","e962b6ba":"code","bb47bdd8":"code","cb45801f":"code","2246ed09":"code","550121ab":"code","b33514bd":"code","e120fab2":"code","6a0286c5":"code","96570879":"code","9ef574c6":"code","878866c8":"code","47af6e55":"code","7881536a":"code","674b9d6a":"code","3b488909":"code","b554fa55":"code","40720ace":"code","42ff630e":"code","ef150c3e":"code","4e21b86f":"code","e7e62f87":"code","d6b181c9":"code","fdbb811b":"code","3a5aa1fd":"code","103eff06":"code","1551f819":"code","5d065dec":"code","55deec5c":"code","06c05b53":"code","a41c0e58":"code","88692029":"code","9c4d72b0":"code","b5bd5281":"code","24e2f407":"code","3c777d7e":"code","9b4de52a":"code","57d9732a":"code","0d43c6ea":"code","cbbb867e":"code","6ddecd85":"code","a91a9e00":"code","3333642a":"code","fe6360fb":"code","5cfa1a84":"markdown","317b3da8":"markdown","0d8c748c":"markdown","c0f72e06":"markdown","29e69096":"markdown","c1e75e82":"markdown","cbf1f11e":"markdown","4c6d2265":"markdown","95c4707e":"markdown","de6b6b4b":"markdown","38000602":"markdown","36bd7543":"markdown","9b329bde":"markdown","a34de86e":"markdown","ae3c62ec":"markdown","f5df2c6b":"markdown","b262f872":"markdown","c80dff38":"markdown","71119ff9":"markdown","19ecb483":"markdown","bc34ed6f":"markdown","370c467e":"markdown","29d4c09d":"markdown","abc0768f":"markdown","0af5d8af":"markdown","716f6eae":"markdown","27da086c":"markdown","b4ca433a":"markdown","9339a2df":"markdown","e7d77d88":"markdown","a0ef4a54":"markdown","7c0e5472":"markdown","e3120281":"markdown","72425848":"markdown","4e8664c9":"markdown","2bf5742b":"markdown","c05e69d6":"markdown","7d3f06d8":"markdown","d3fe58b2":"markdown","95036321":"markdown","4a5c0f0e":"markdown","bcbc8463":"markdown","055f2ef9":"markdown","4b9478fd":"markdown","499e079c":"markdown","4f4a1b26":"markdown","939d19ac":"markdown","af67f075":"markdown","77b1f2ab":"markdown","743f172d":"markdown","86185d0e":"markdown","190f2db4":"markdown","48112a79":"markdown","2e6519e3":"markdown","707bc3e4":"markdown","8d782b17":"markdown","d3062946":"markdown","900eef69":"markdown","61b4b526":"markdown","632da480":"markdown","59aa3b7e":"markdown","9f862d30":"markdown","8124c191":"markdown","aa227a78":"markdown","640b91c6":"markdown","580bfaf8":"markdown","17b77bf5":"markdown","9f00e0ff":"markdown","1bbaa18d":"markdown","532cc92d":"markdown","b987df6e":"markdown","e9f83b26":"markdown","71ba353d":"markdown","3d82fdfe":"markdown","9caecea7":"markdown","3170b577":"markdown","52425fb9":"markdown"},"source":{"1a9009a5":"import numpy as np\nimport pandas as pd\n\n# Viz Library\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import show","6183edcc":"# Reading the Response Dataset\nresponse = pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')\nresponse = response.drop(response.index[0], axis = 0)","9e27357f":"response.head()","e802b022":"response.info","cd4f0252":"response.describe()","0d69c72c":"response.shape","0dbfed68":"data = response['Q1'].sort_values(ascending=True)","740fccac":"sns.set(font_scale=1.4)\nsns.color_palette(\"tab10\")\nplt.figure(figsize=(15,10))\n\ntotal = float(len(response)) # one person per row \n\nax = sns.countplot(x = data, data = response)\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}%'.format((height\/total)*100),\n            ha=\"center\") \n\nplt.title('Age Distribution',\n         fontsize =30)\n\nplt.xlabel('Age', fontsize = 24)\nplt.ylabel('Percentage', fontsize = 24)","7dd94d66":"sns.set(font_scale=1.4)\nplt.figure(figsize=(15,10))\n\nax = sns.countplot(y = \"Q2\", data = response, palette = \"rainbow\")\n\nplt.title('Gender Distribution')\nplt.xlabel('Frequencies')\n\ntotal = len(response['Q2'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Data Scientist as per Gender',\n         fontsize =30)\n\nplt.xlabel('Count', fontsize = 24)\nplt.ylabel('Gender', fontsize = 24)\n\nplt.show()","2e1fef77":"'''\nPlotting Top 7 Countries which has More Number of Responses\n'''\n\nsns.set(font_scale=1.4)\nplt.figure(figsize=(15,10))\n\nsns.countplot(y = response['Q3'], palette = 'spring', data = response, order=['India', 'United States of America', 'Other', 'Brazil',\n                                                                                       'Japan', 'Russia', 'United Kingdom of Great Britain and Northern Ireland',\n                                                                                       'Nigeria', 'Germany', 'Spain'])\n\nplt.title('Top 7 Country Per Responses',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Country', fontsize = 24)\n\nplt.show()","53404464":"sns.set(font_scale=1.4)\nplt.figure(figsize=(15,10))\n\ndata = response['Q4'].sort_values(ascending=True)\n\nax = sns.countplot(y = data, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q4'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Formal Education',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Education', fontsize = 24)\n\nplt.show()","45e180b2":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\ndata = response['Q5'].sort_values(ascending=True)\n\nax = sns.countplot(y = data, data = response, palette = \"spring\")\n\ntotal = len(response['Q5'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Job Title',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Job', fontsize = 24)\n\nplt.show()","a511a5ee":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = 'Q6', data = response, palette = \"spring\")\n\ntotal = len(response['Q6'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Years of Programming Experience',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Code', fontsize = 24)\n\nplt.show()","2eebcfa0":"# Combining All the Question 7 answers\n\nquestion_7 = np.concatenate([response.Q7_Part_1,\n                             response.Q7_Part_2,\n                             response.Q7_Part_3,\n                             response.Q7_Part_4,\n                             response.Q7_Part_5,\n                             response.Q7_Part_6,\n                             response.Q7_Part_7,\n                             response.Q7_Part_8,\n                             response.Q7_Part_9,\n                             response.Q7_Part_10,\n                             response.Q7_Part_11,\n                             response.Q7_Part_12,\n                             response.Q7_OTHER,\n])\n\nques_7 = pd.concat([response, pd.DataFrame(question_7)], ignore_index = True, axis = 1)\n\nques_7.columns = np.append(response.columns.values, 'Q7')","caa1a663":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_7.Q7, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q7_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Programming Language Used Most Often!',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Programming Language', fontsize = 24)\n\nplt.show()","48adb334":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = 'Q8', data = response, palette = \"rainbow\")\n\ntotal = len(response['Q8'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Programming Language To Learn First For Data Science Aspirant!',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Programming Language', fontsize = 24)\n\nplt.show()","f1542823":"# Combining All the Question 9 answers\n\nquestion_9 = np.concatenate([response.Q9_Part_1,\n                             response.Q9_Part_2,\n                             response.Q9_Part_3,\n                             response.Q9_Part_4,\n                             response.Q9_Part_5,\n                             response.Q9_Part_6,\n                             response.Q9_Part_7,\n                             response.Q9_Part_8,\n                             response.Q9_Part_9,\n                             response.Q9_Part_10,\n                             response.Q9_Part_11,\n                             response.Q9_OTHER\n])\n\nques_9 = pd.concat([response, pd.DataFrame(question_9)], ignore_index = True, axis = 1)\n\nques_9.columns = np.append(response.columns.values, 'Q9')","47b79652":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_9.Q9, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q9_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('IDE\\'s Used Most Often',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('IDE\\'s', fontsize = 24)\n\nplt.show()","9b2e7030":"# Combining All the Question 10 answers\n\nquestion_10 = np.concatenate([response.Q10_Part_1,\n                              response.Q10_Part_2,\n                              response.Q10_Part_3,\n                              response.Q10_Part_4,\n                              response.Q10_Part_5,\n                              response.Q10_Part_6,\n                              response.Q10_Part_7,\n                              response.Q10_Part_8,\n                              response.Q10_Part_9,\n                              response.Q10_Part_10,\n                              response.Q10_Part_11,\n                              response.Q10_Part_12,\n                              response.Q10_Part_13,\n                              response.Q10_OTHER\n])\n\nques_10 = pd.concat([response, pd.DataFrame(question_10)], ignore_index = True, axis = 1)\n\nques_10.columns = np.append(response.columns.values, 'Q10')","8aebbaa1":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_10.Q10, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q10_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Hosted Notebook Commonly Used',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Hosted Notebooks\\'s', fontsize = 24)\n\nplt.show()","aa2c01be":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = 'Q11', data = response, palette = \"rainbow\")\n\ntotal = len(response['Q11'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Computing Platform Most used',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Computing Platform\\'s', fontsize = 24)\n\nplt.show()","6d30ccce":"# Combining All the Question 12 answers\n\nquestion_12 = np.concatenate([response.Q12_Part_1,\n                              response.Q12_Part_2,\n                              response.Q12_Part_3,\n                              response.Q12_OTHER\n])\n\nques_12 = pd.concat([response, pd.DataFrame(question_12)], ignore_index = True, axis = 1)\n\nques_12.columns = np.append(response.columns.values, 'Q12')","aaf7c3be":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_12.Q12, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q12_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Specialized Hardware Used Often',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Specialized Hardware', fontsize = 24)\n\nplt.show()","86b0105d":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = 'Q13', data = response, palette = \"rainbow\")\n\ntotal = len(response['Q13'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Number of times TPU used',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('TPU used', fontsize = 24)\n\nplt.show()","4333b2fb":"question_14 = np.concatenate([response.Q14_Part_1,\n                              response.Q14_Part_2,\n                              response.Q14_Part_3,\n                              response.Q14_Part_4,\n                              response.Q14_Part_5,\n                              response.Q14_Part_6,\n                              response.Q14_Part_7,\n                              response.Q14_Part_8,\n                              response.Q14_Part_9,\n                              response.Q14_Part_10,\n                              response.Q14_Part_11,\n                              response.Q14_OTHER\n])\n\nques_14 = pd.concat([response, pd.DataFrame(question_14)], ignore_index = True, axis = 1)\n\nques_14.columns = np.append(response.columns.values, 'Q14')","6606854d":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_14.Q14, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q14_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Visualization libraries or tools do you use on a regular basis?',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Visualization Tools', fontsize = 24)\n\nplt.show()","5bc3df1b":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = 'Q15', data = response, palette = \"rainbow\")\n\ntotal = len(response['Q15'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('For how many years have you used machine learning methods?',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Years', fontsize = 24)\n\nplt.show()","90ae6789":"question_16 = np.concatenate([response.Q16_Part_1,\n                              response.Q16_Part_2,\n                              response.Q16_Part_3,\n                              response.Q16_Part_4,\n                              response.Q16_Part_5,\n                              response.Q16_Part_6,\n                              response.Q16_Part_7,\n                              response.Q16_Part_8,\n                              response.Q16_Part_9,\n                              response.Q16_Part_10,\n                              response.Q16_Part_11,\n                              response.Q16_Part_12,\n                              response.Q16_Part_13,\n                              response.Q16_Part_14,\n                              response.Q16_Part_15,\n                              response.Q16_OTHER\n])\n\nques_16 = pd.concat([response, pd.DataFrame(question_16)], ignore_index = True, axis = 1)\n\nques_16.columns = np.append(response.columns.values, 'Q16')","ad724d64":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_16.Q16, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q16_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('ML FrameWorks used Often',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('ML', fontsize = 24)\n\nplt.show()","288f5f18":"question_17 = np.concatenate([response.Q17_Part_1,\n                              response.Q17_Part_2,\n                              response.Q17_Part_3,\n                              response.Q17_Part_4,\n                              response.Q17_Part_5,\n                              response.Q17_Part_6,\n                              response.Q17_Part_7,\n                              response.Q17_Part_8,\n                              response.Q17_Part_9,\n                              response.Q17_Part_10,\n                              response.Q17_Part_11,\n                              response.Q17_OTHER\n])\n\nques_17 = pd.concat([response, pd.DataFrame(question_17)], ignore_index = True, axis = 1)\n\nques_17.columns = np.append(response.columns.values, 'Q17')","d400502a":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_17.Q17, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q17_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('ML Algorithm Used Most Often',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('ML Algorithm', fontsize = 24)\n\nplt.show()","d6893332":"question_18 = np.concatenate([response.Q18_Part_1,\n                              response.Q18_Part_2,\n                              response.Q18_Part_3,\n                              response.Q18_Part_4,\n                              response.Q18_Part_5,\n                              response.Q18_Part_6,\n                              response.Q18_OTHER\n])\n\nques_18 = pd.concat([response, pd.DataFrame(question_18)], ignore_index = True, axis = 1)\n\nques_18.columns = np.append(response.columns.values, 'Q18')","e767bb14":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_18.Q18, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q18_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Computer Vision Technique Used Most Often',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('CV Technique', fontsize = 24)\n\nplt.show()","4ac37555":"question_19 = np.concatenate([response.Q19_Part_1,\n                              response.Q19_Part_2,\n                              response.Q19_Part_3,\n                              response.Q19_Part_4,\n                              response.Q19_Part_5,\n                              response.Q19_OTHER\n])\n\nques_19 = pd.concat([response, pd.DataFrame(question_19)], ignore_index = True, axis = 1)\n\nques_19.columns = np.append(response.columns.values, 'Q19')","72aaa1e8":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_19.Q19, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q19_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('NLP methods Used Most Often',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('NLP methods', fontsize = 24)\n\nplt.show()","a35b0658":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = 'Q20', data = response, palette = \"rainbow\")\n\ntotal = len(response['Q20'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Size of the Company where you are Working',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Company Size', fontsize = 24)\n\nplt.show()","6b221a35":"for name in dir():\n    if name[0:2] != \"__\":\n        del globals()[name]\n\ndel name\nprint(dir())","ae0fbf04":"import numpy as np\nimport pandas as pd\n\n# Viz Library\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import show\n\n# Reading the Response Dataset\nresponse = pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')\nresponse = response.drop(response.index[0], axis = 0)","64fccd15":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = 'Q21', data = response, palette = \"rainbow\")\n\ntotal = len(response['Q21'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Total People responsible for data science workload',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Size', fontsize = 24)\n\nplt.show()","49c3990d":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = 'Q22', data = response, palette = \"rainbow\")\n\ntotal = len(response['Q22'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Employer incorporate machine learning technique',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Responses', fontsize = 24)\n\nplt.show()","d8d52e22":"question_23 = np.concatenate([response.Q23_Part_1,\n                              response.Q23_Part_2,\n                              response.Q23_Part_3,\n                              response.Q23_Part_4,\n                              response.Q23_Part_5,\n                              response.Q23_Part_6,\n                              response.Q23_Part_7,\n                              response.Q23_OTHER\n])\n\nques_23 = pd.concat([response, pd.DataFrame(question_23)], ignore_index = True, axis = 1)\n\nques_23.columns = np.append(response.columns.values, 'Q23')","2e519783":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_23.Q23, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q23_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Role Done by you at the current Company',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Work', fontsize = 24)\n\nplt.show()","9d1142a5":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = 'Q24', data = response, palette = \"rainbow\")\n\ntotal = len(response['Q24'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Yearly Compensation',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Compensation', fontsize = 24)\n\nplt.show()","f49848f5":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = 'Q25', data = response, palette = \"rainbow\")\n\ntotal = len(response['Q25'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Money Spent in Cloud computing and Machine Learing by team in past 5 Year',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Money', fontsize = 24)\n\nplt.show()","e962b6ba":"question_26 = np.concatenate([response.Q26_A_Part_1,\n                              response.Q26_A_Part_2,\n                              response.Q26_A_Part_3,\n                              response.Q26_A_Part_4,\n                              response.Q26_A_Part_5,\n                              response.Q26_A_Part_6,\n                              response.Q26_A_Part_7,\n                              response.Q26_A_Part_8,\n                              response.Q26_A_Part_9,\n                              response.Q26_A_Part_10,\n                              response.Q26_A_Part_11,\n                              response.Q26_A_OTHER\n])\n\nques_26 = pd.concat([response, pd.DataFrame(question_26)], ignore_index = True, axis = 1)\n\nques_26.columns = np.append(response.columns.values, 'Q26')","bb47bdd8":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_26.Q26, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q26_A_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.5}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Cloud Computing Platform Uses Regular',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Cloud Service Provider', fontsize = 24)\n\nplt.show()","cb45801f":"question_26_b = np.concatenate([response.Q26_B_Part_1,\n                              response.Q26_B_Part_2,\n                              response.Q26_B_Part_3,\n                              response.Q26_B_Part_4,\n                              response.Q26_B_Part_5,\n                              response.Q26_B_Part_6,\n                              response.Q26_B_Part_7,\n                              response.Q26_B_Part_8,\n                              response.Q26_B_Part_9,\n                              response.Q26_B_Part_10,\n                              response.Q26_B_Part_11,\n                              response.Q26_B_OTHER\n])\n\nques_26_b = pd.concat([response, pd.DataFrame(question_26_b)], ignore_index = True, axis = 1)\n\nques_26_b.columns = np.append(response.columns.values, 'Q26')","2246ed09":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_26_b.Q26, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q26_B_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.5}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Cloud Service Provider', fontsize = 24)\n\nplt.show()","550121ab":"question_27 = np.concatenate([response.Q27_A_Part_1,\n                              response.Q27_A_Part_2,\n                              response.Q27_A_Part_3,\n                              response.Q27_A_Part_4,\n                              response.Q27_A_Part_5,\n                              response.Q27_A_Part_6,\n                              response.Q27_A_Part_7,\n                              response.Q27_A_Part_8,\n                              response.Q27_A_Part_9,\n                              response.Q27_A_Part_10,\n                              response.Q27_A_Part_11,\n                              response.Q27_A_OTHER\n])\n\nques_27 = pd.concat([response, pd.DataFrame(question_27)], ignore_index = True, axis = 1)\n\nques_27.columns = np.append(response.columns.values, 'Q27')","b33514bd":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_27.Q27, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q27_A_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.3}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Cloud Computing Products used',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Products', fontsize = 24)\n\nplt.show()","e120fab2":"question_27_b = np.concatenate([response.Q27_B_Part_1,\n                              response.Q27_B_Part_2,\n                              response.Q27_B_Part_3,\n                              response.Q27_B_Part_4,\n                              response.Q27_B_Part_5,\n                              response.Q27_B_Part_6,\n                              response.Q27_B_Part_7,\n                              response.Q27_B_Part_8,\n                              response.Q27_B_Part_9,\n                              response.Q27_B_Part_10,\n                              response.Q27_B_Part_11,\n                              response.Q27_B_OTHER\n])\n\nques_27_b = pd.concat([response, pd.DataFrame(question_27_b)], ignore_index = True, axis = 1)\n\nques_27_b.columns = np.append(response.columns.values, 'Q27_b')","6a0286c5":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_27_b.Q27_b, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q27_B_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.3}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products?',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Responses', fontsize = 24)\n\nplt.show()","96570879":"question_28 = np.concatenate([response.Q28_A_Part_1,\n                              response.Q28_A_Part_2,\n                              response.Q28_A_Part_3,\n                              response.Q28_A_Part_4,\n                              response.Q28_A_Part_5,\n                              response.Q28_A_Part_6,\n                              response.Q28_A_Part_7,\n                              response.Q28_A_Part_8,\n                              response.Q28_A_Part_9,\n                              response.Q28_A_Part_10,\n                              response.Q28_A_OTHER\n])\n\nques_28 = pd.concat([response, pd.DataFrame(question_28)], ignore_index = True, axis = 1)\n\nques_28.columns = np.append(response.columns.values, 'Q28')","9ef574c6":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_28.Q28, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q28_A_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.3}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Machine Learning Products used often',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('ML Products', fontsize = 24)\n\nplt.show()","878866c8":"question_28_b = np.concatenate([response.Q28_B_Part_1,\n                              response.Q28_B_Part_2,\n                              response.Q28_B_Part_3,\n                              response.Q28_B_Part_4,\n                              response.Q28_B_Part_5,\n                              response.Q28_B_Part_6,\n                              response.Q28_B_Part_7,\n                              response.Q28_B_Part_8,\n                              response.Q28_B_Part_9,\n                              response.Q28_B_Part_10,\n                              response.Q28_B_OTHER\n])\n\nques_28_b = pd.concat([response, pd.DataFrame(question_28_b)], ignore_index = True, axis = 1)\n\nques_28_b.columns = np.append(response.columns.values, 'Q28_b')","47af6e55":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_28_b.Q28_b, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q28_B_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.3}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('In the next 2 years, do you hope to become more familiar with any of these specific machine learning products?',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Responses', fontsize = 24)\n\nplt.show()","7881536a":"question_29 = np.concatenate([response.Q29_A_Part_1,\n                              response.Q29_A_Part_2,\n                              response.Q29_A_Part_3,\n                              response.Q29_A_Part_4,\n                              response.Q29_A_Part_5,\n                              response.Q29_A_Part_6,\n                              response.Q29_A_Part_7,\n                              response.Q29_A_Part_8,\n                              response.Q29_A_Part_9,\n                              response.Q29_A_Part_10,\n                              response.Q29_A_Part_11,\n                              response.Q29_A_Part_12,\n                              response.Q29_A_Part_13,\n                              response.Q29_A_Part_14,\n                              response.Q29_A_Part_15,\n                              response.Q29_A_Part_16,\n                              response.Q29_A_Part_17,\n                              response.Q29_A_OTHER\n])\n\nques_29 = pd.concat([response, pd.DataFrame(question_29)], ignore_index = True, axis = 1)\n\nques_29.columns = np.append(response.columns.values, 'Q29')","674b9d6a":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_29.Q29, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q29_A_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.3}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Big Data Products used often',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Big Data Products', fontsize = 24)\n\nplt.show()","3b488909":"question_29_B = np.concatenate([response.Q29_B_Part_1,\n                              response.Q29_B_Part_2,\n                              response.Q29_B_Part_3,\n                              response.Q29_B_Part_4,\n                              response.Q29_B_Part_5,\n                              response.Q29_B_Part_6,\n                              response.Q29_B_Part_7,\n                              response.Q29_B_Part_8,\n                              response.Q29_B_Part_9,\n                              response.Q29_B_Part_10,\n                              response.Q29_B_Part_11,\n                              response.Q29_B_Part_12,\n                              response.Q29_B_Part_13,\n                              response.Q29_B_Part_14,\n                              response.Q29_B_Part_15,\n                              response.Q29_B_Part_16,\n                              response.Q29_B_Part_17,\n                              response.Q29_B_OTHER\n])\n\nques_29_b = pd.concat([response, pd.DataFrame(question_29_B)], ignore_index = True, axis = 1)\n\nques_29_b.columns = np.append(response.columns.values, 'Q29_b')","b554fa55":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_29_b.Q29_b, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q29_B_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.3}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Which of the following big data products do you hope to become more familiar with in the next 2 years?\\n',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Big Data Products', fontsize = 24)\n\nplt.show()","40720ace":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = 'Q30', data = response, palette = \"rainbow\")\n\ntotal = len(response['Q30'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Which of the following big data products (relational database, data warehouse, data lake, or similar) do you use most often?',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Big Data Products', fontsize = 24)\n\nplt.show()","42ff630e":"question_31 = np.concatenate([response.Q31_A_Part_1,\n                              response.Q31_A_Part_2,\n                              response.Q31_A_Part_3,\n                              response.Q31_A_Part_4,\n                              response.Q31_A_Part_5,\n                              response.Q31_A_Part_6,\n                              response.Q31_A_Part_7,\n                              response.Q31_A_Part_8,\n                              response.Q31_A_Part_9,\n                              response.Q31_A_Part_10,\n                              response.Q31_A_Part_11,\n                              response.Q31_A_Part_12,\n                              response.Q31_A_Part_13,\n                              response.Q31_A_Part_14,\n                              response.Q31_A_OTHER\n])\n\nques_31 = pd.concat([response, pd.DataFrame(question_31)], ignore_index = True, axis = 1)\n\nques_31.columns = np.append(response.columns.values, 'Q31')","ef150c3e":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_31.Q31, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q31_A_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.3}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Business intelligence tools do you use on a regular basis?',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('BI tools', fontsize = 24)\n\nplt.show()","4e21b86f":"question_31_b = np.concatenate([response.Q31_B_Part_1,\n                              response.Q31_B_Part_2,\n                              response.Q31_B_Part_3,\n                              response.Q31_B_Part_4,\n                              response.Q31_B_Part_5,\n                              response.Q31_B_Part_6,\n                              response.Q31_B_Part_7,\n                              response.Q31_B_Part_8,\n                              response.Q31_B_Part_9,\n                              response.Q31_B_Part_10,\n                              response.Q31_B_Part_11,\n                              response.Q31_B_Part_12,\n                              response.Q31_B_Part_13,\n                              response.Q31_B_Part_14,\n                              response.Q31_B_OTHER\n])\n\nques_31_b = pd.concat([response, pd.DataFrame(question_31_b)], ignore_index = True, axis = 1)\n\nques_31_b.columns = np.append(response.columns.values, 'Q31')","e7e62f87":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_31_b.Q31, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q31_B_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.3}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('business intelligence tools do you hope to become more familiar with in the next 2 years?',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('BI tools', fontsize = 24)\n\nplt.show()","d6b181c9":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = 'Q32', data = response, palette = \"rainbow\")\n\ntotal = len(response['Q32'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Business Intelligence Tools used Often',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('BI tools', fontsize = 24)\n\nplt.show()","fdbb811b":"for name in dir():\n    if name[0:2] != \"__\":\n        del globals()[name]\n\ndel name\nprint(dir())","3a5aa1fd":"import numpy as np\nimport pandas as pd\n\n# Viz Library\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import show\n\n# Reading the Response Dataset\nresponse = pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')\nresponse = response.drop(response.index[0], axis = 0)","103eff06":"question_33 = np.concatenate([response.Q33_A_Part_1,\n                              response.Q33_A_Part_2,\n                              response.Q33_A_Part_3,\n                              response.Q33_A_Part_4,\n                              response.Q33_A_Part_5,\n                              response.Q33_A_Part_6,\n                              response.Q33_A_Part_7,\n                              response.Q33_A_OTHER\n])\n\nques_33 = pd.concat([response, pd.DataFrame(question_33)], ignore_index = True, axis = 1)\n\nques_33.columns = np.append(response.columns.values, 'Q33')","1551f819":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_33.Q33, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q33_A_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.3}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('automated machine learning tools used on a regular basis',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Automated ML tools', fontsize = 24)\n\nplt.show()","5d065dec":"question_33_b = np.concatenate([response.Q33_B_Part_1,\n                              response.Q33_B_Part_2,\n                              response.Q33_B_Part_3,\n                              response.Q33_B_Part_4,\n                              response.Q33_B_Part_5,\n                              response.Q33_B_Part_6,\n                              response.Q33_B_Part_7,\n                              response.Q33_B_OTHER\n])\n\nques_33_b = pd.concat([response, pd.DataFrame(question_33_b)], ignore_index = True, axis = 1)\n\nques_33_b.columns = np.append(response.columns.values, 'Q33')","55deec5c":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_33_b.Q33, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q33_B_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.3}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Which categories of machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Automated\/Partial ML tools', fontsize = 24)\n\nplt.show()","06c05b53":"question_34 = np.concatenate([response.Q34_A_Part_1,\n                              response.Q34_A_Part_2,\n                              response.Q34_A_Part_3,\n                              response.Q34_A_Part_4,\n                              response.Q34_A_Part_5,\n                              response.Q34_A_Part_6,\n                              response.Q34_A_Part_7,\n                              response.Q34_A_Part_8,\n                              response.Q34_A_Part_9,\n                              response.Q34_A_Part_10,\n                              response.Q34_A_Part_11,\n                              response.Q34_A_OTHER\n])\n\nques_34 = pd.concat([response, pd.DataFrame(question_34)], ignore_index = True, axis = 1)\n\nques_34.columns = np.append(response.columns.values, 'Q34')","a41c0e58":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_34.Q34, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q34_A_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.3}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Automated or Partial ML tools', fontsize = 24)\n\nplt.show()","88692029":"question_34_b = np.concatenate([response.Q34_B_Part_1,\n                              response.Q34_B_Part_2,\n                              response.Q34_B_Part_3,\n                              response.Q34_B_Part_4,\n                              response.Q34_B_Part_5,\n                              response.Q34_B_Part_6,\n                              response.Q34_B_Part_7,\n                              response.Q34_B_Part_8,\n                              response.Q34_B_Part_9,\n                              response.Q34_B_Part_10,\n                              response.Q34_B_Part_11,\n                              response.Q34_B_OTHER\n])\n\nques_34_b = pd.concat([response, pd.DataFrame(question_34_b)], ignore_index = True, axis = 1)\n\nques_34_b.columns = np.append(response.columns.values, 'Q34_b')","9c4d72b0":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_34_b.Q34_b, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q34_B_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.3}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Automated\/spartial machine learning tool do you hope to become more familiar with in the next 2 years?',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Automated or Partial ML tools', fontsize = 24)\n\nplt.show()","b5bd5281":"question_35 = np.concatenate([response.Q35_A_Part_1,\n                              response.Q35_A_Part_2,\n                              response.Q35_A_Part_3,\n                              response.Q35_A_Part_4,\n                              response.Q35_A_Part_5,\n                              response.Q35_A_Part_6,\n                              response.Q35_A_Part_7,\n                              response.Q35_A_Part_8,\n                              response.Q35_A_Part_9,\n                              response.Q35_A_Part_10,\n                              response.Q35_A_OTHER\n])\n\nques_35 = pd.concat([response, pd.DataFrame(question_35)], ignore_index = True, axis = 1)\n\nques_35.columns = np.append(response.columns.values, 'Q35')","24e2f407":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_35.Q35, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q35_A_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.3}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Do you use any tools to help manage machine learning experiments?',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Tools', fontsize = 24)\n\nplt.show()","3c777d7e":"question_35_b = np.concatenate([response.Q35_B_Part_1,\n                              response.Q35_B_Part_2,\n                              response.Q35_B_Part_3,\n                              response.Q35_B_Part_4,\n                              response.Q35_B_Part_5,\n                              response.Q35_B_Part_6,\n                              response.Q35_B_Part_7,\n                              response.Q35_B_Part_8,\n                              response.Q35_B_Part_9,\n                              response.Q35_B_Part_10,\n                              response.Q35_B_OTHER\n])\n\nques_35_b = pd.concat([response, pd.DataFrame(question_35_b)], ignore_index = True, axis = 1)\n\nques_35_b.columns = np.append(response.columns.values, 'Q35')","9b4de52a":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_35.Q35, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q35_A_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.3}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments?',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Tools', fontsize = 24)\n\nplt.show()","57d9732a":"question_36 = np.concatenate([response.Q36_Part_1,\n                              response.Q36_Part_2,\n                              response.Q36_Part_3,\n                              response.Q36_Part_4,\n                              response.Q36_Part_5,\n                              response.Q36_Part_6,\n                              response.Q36_Part_7,\n                              response.Q36_Part_8,\n                              response.Q36_Part_9,\n                              response.Q36_OTHER\n])\n\nques_36 = pd.concat([response, pd.DataFrame(question_36)], ignore_index = True, axis = 1)\n\nques_36.columns = np.append(response.columns.values, 'Q36')","0d43c6ea":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_36.Q36, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q36_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.3}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Where do you Publicly share or Deploy your DA or ML application',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Deploy tools', fontsize = 24)\n\nplt.show()","cbbb867e":"question_37 = np.concatenate([response.Q37_Part_1,\n                              response.Q37_Part_2,\n                              response.Q37_Part_3,\n                              response.Q37_Part_4,\n                              response.Q37_Part_5,\n                              response.Q37_Part_6,\n                              response.Q37_Part_7,\n                              response.Q37_Part_8,\n                              response.Q37_Part_9,\n                              response.Q37_Part_10,\n                              response.Q37_Part_11,\n                              response.Q37_OTHER\n])\n\nques_37 = pd.concat([response, pd.DataFrame(question_37)], ignore_index = True, axis = 1)\n\nques_37.columns = np.append(response.columns.values, 'Q37')","6ddecd85":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_37.Q37, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q37_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.3}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Which platforms have you have begin or completed data science course?',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Online Learning Platform', fontsize = 24)\n\nplt.show()","a91a9e00":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = 'Q38', data = response, palette = \"rainbow\")\n\ntotal = len(response['Q38'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Primary Tool for analyzing data',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Tools', fontsize = 24)\n\nplt.show()","3333642a":"question_39 = np.concatenate([response.Q39_Part_1,\n                              response.Q39_Part_2,\n                              response.Q39_Part_3,\n                              response.Q39_Part_4,\n                              response.Q39_Part_5,\n                              response.Q39_Part_6,\n                              response.Q39_Part_7,\n                              response.Q39_Part_8,\n                              response.Q39_Part_9,\n                              response.Q39_Part_10,\n                              response.Q39_Part_11,\n                              response.Q39_OTHER\n])\n\nques_39 = pd.concat([response, pd.DataFrame(question_39)], ignore_index = True, axis = 1)\n\nques_39.columns = np.append(response.columns.values, 'Q39')","fe6360fb":"sns.set(font_scale=1.4)\nplt.figure(figsize=(17,10))\n\nax = sns.countplot(y = ques_39.Q39, data = response, palette = \"rainbow\")\n\ntotal = len(response['Q39_Part_1'])\nfor p in ax.patches:\n        percentage = '{:.3}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n\n\nplt.title('Favorite media sources that report on data science topics',\n         fontsize =30)\n\nplt.xlabel('Frequency', fontsize = 24)\nplt.ylabel('Media Resources', fontsize = 24)\n\nplt.show()","5cfa1a84":"***Question 15: For how many years have you used machine learning methods?***","317b3da8":"***Question 28_A: Do you use any of the following machine learning products on a regular basis?***","0d8c748c":"***Question 17: Which of the following ML algorithms do you use on a regular basis?***","c0f72e06":"***Question 34_B: Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?***","29e69096":"***Question 3: In which country do you currently reside ?***","c1e75e82":"***Question 36: Where do you publicly share or deploy your data analysis or machine learning applications?***","cbf1f11e":"We can clearly see that 78.8% are Men which are dominating in this field, and 19.4% are Women, 0.3% Nonbinary, 0.3% Prefer to Self-descibe, 1.3% Prefer not to say, which in my thought is Very Less Numbers in DS\/ML responses.","4c6d2265":"***Question 23: Select any activities that make up an important part of your role at work?***","95c4707e":"***Question 31_b: Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years?***","de6b6b4b":"***Question 26 Part-B: Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years?***","38000602":"***Question 24: What is your current yearly compensation (approximate $USD)?***","36bd7543":"***Question 5: Select the title most similar to your current role (or most recent title if retired)***","9b329bde":"India has the Highest number of people who submitted their responses, followed by United States of America, Other, and so on...........","a34de86e":"Mostly People uses **`Kaggle`**, **`Youtube`** is ranked 2nd, followed by **`Blogs`**","ae3c62ec":"***Question 34: Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?***","f5df2c6b":"`Python` is treding Language to Learn first for data Science, `R` is 2nd Preference language followed by `SQL`","b262f872":"Most people are working where employee size is **0-49** which may be a startup company. 11.2% of users are working with company size more than **10,000**.","c80dff38":"**Matplotlib** Is used Very Often, followed by **Seaborn**. **Plotly and GGplot** Both stands at 20.6% of users. **Altair** is not used very often. ","71119ff9":"***Question 21: Approximately how many individuals are responsible for data science workloads at your place of business?***","19ecb483":"***Question 16: Which of the following machine learning frameworks do you use on a regular basis?***","bc34ed6f":"***Question 13: Approximately how many times have you used a TPU?***","370c467e":"***Question 37: On which platforms have you begun or completed data science courses?***","29d4c09d":"60% of people have never used **TPU's**. 10.5% of people has used **2-5 times**. Very less number of people have used it **More than 25 times**!","abc0768f":"***Question 18: Which categories of computer vision methods do you use on a regular basis?***","0af5d8af":"We can see that Most of the Data Scientist are in the Age Range of 18 to 29. There are also 0.38% People with 70+ Age which is Awesome \ud83d\ude0e. Also as the Age increases count of people also decreases...","716f6eae":"***Question 4: What is the highest level of formal education that you have attained or plan to attain within the next 2 years?***","27da086c":"***Question 32: Which of the following business intelligence tools do you use most often?***","b4ca433a":"Most of the Role done at the company is **Analyzing and understanding the data** which is very important before moving to ML\/DS work!!","9339a2df":"***Question 6: For how many years have you been writing code and\/or programming?***","e7d77d88":"There are less number of people those who have done their `Doctoral Degree` which is Great \ud83d\ude0e. We have 39.2% People those who have done their `Master's Degree`, followed by 34.8% People with their `Bachelor's degree`. Also we also have 1.2% people those who have not done their Formal Education, they may be learning by their own in ML\/DS field \ud83d\ude4c.","a0ef4a54":"***Question 8: What programming language would you recommend an aspiring data scientist to learn first?***","7c0e5472":"***Question 38: What is the primary tool that you use at work or school to analyze data?***","e3120281":"***Question 19: Which of the following natural language processing (NLP) methods do you use on a regular basis?***","72425848":"***Question 1: Age Distribution***","4e8664c9":"23.6 people said **No\/None** to become more familiar with any of these tools for managing ML experiments. ","2bf5742b":"***Question 31: Which of the following business intelligence tools do you use on a regular basis?***","c05e69d6":"Most people uses their **own Machine** for ML\/DS work. Only 11.8% people uses a **cloud Computing Platform**. 4.2% uses **Deep Learning Workstations**.","7d3f06d8":"**MySQL** is most used Big Data Products. **PostgresSQL** is used more after **MySQL**!","d3fe58b2":"5.6% People have never written Code. We can see as the years increases number of people also decreases! We have 22.5% of people with 1-2 Years of Experience and 22.7% of people with 3-5 years of expericence.","95036321":"***Question 29_B: Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years?***","4a5c0f0e":"***Question 30: Which of the following big data products (relational database, data warehouse, data lake, or similar) do you use most often?***","bcbc8463":"***Question 25: Approximately how much money have you (or your team) spent on machine learning and\/or cloud computing services at home (or at work) in the past 5 years (approximate $USD)?***","055f2ef9":"**Linear Regression** is used most often! followed by **Decision Tree** or **Random Forest**. **CNN** are used by 29.2% of people. Only 2% of people used other ML Algorithm.....","4b9478fd":"***Question 11: What type of computing platform do you use most often for your data science projects?***","499e079c":"***Question 29_A: Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis?***","4f4a1b26":"***Question 33: Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis?***","939d19ac":"***Question 35: Do you use any tools to help manage machine learning experiments?***","af67f075":"***Question 39: Who\/what are your favorite media sources that report on data science topics?***","77b1f2ab":"***Question 9: Which of the following integrated development environments (IDE's) do you use on a regular basis?***","743f172d":"***Question 28_B: In the next 2 years, do you hope to become more familiar with any of these specific machine learning products?***","86185d0e":"Most people are going to learn **Google Cloud Compute Engine** in the next 2 years!","190f2db4":"**GPU's** are used most often. Almost 40% of users **does not use** any Specialized hardware. Only 4.8% people uses **TPU**","48112a79":"***Question 27-Part_B: In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products?***","2e6519e3":"**Image Classification and Other GP networks** are uesd by 17.5% of people. **Object Detection, Image Segmentation and General purpose image\/video** have the same % of people using.","707bc3e4":"***Question 12: Which types of specialized hardware do you use on a regular basis?***","8d782b17":"The Results is very Clear, `Python` sits at a 1st Place on Programming Language Used Most Often, followed by `SQL` 2nd Place and `R` 3rd Place, and so on other languages..........","d3062946":"***Question 20: What is the size of the company where you are employed?***","900eef69":"Most of them are `Student`. There are 13.4% as Data Scientist and 5.4% Ml Engineer. We can also see Only 1.4% of Statistician in the Job Title. Also 8.2% people are `Not Employed` which is a SAD \ud83d\ude2d news. Hope they Get a Job Soon!","61b4b526":"31.5% of people have used it **Under 1 year**. 10.4% of people has **never** used it. We can also see that as the Number of years increases, ML methods are used not used very often!","632da480":"***Question 33_b: Which categories of automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?***","59aa3b7e":"***Question 7: What programming languages do you use on a regular basis?***","9f862d30":"Most people are using **Scikit-learn**. 34.6% of people are using **Tensorflow**. **Keras** are used by only 30.9% of users.\n**Pytorch** and **Xgboost** are used by 20.9% and 19.6% users respectively!","8124c191":"***Question 27-Part_A: Do you use any of the following cloud computing products on a regular basis?***","aa227a78":"**`Local Development environment`s** are the most used tools. We can see that 21.1 uses% **`Basic Statistical software`**. Only 3.4% people uses **`Cloud-based`** Data software.","640b91c6":"**Amazon EC-2** product is used by more than 8.24% of users.","580bfaf8":"**Word Embeddings\/vectors** are most common NLP methods which is used most Often! 5.2% people does not use **NLP technique**. Only .4% uses **Other technique**.","17b77bf5":"***Question 2: Gender Identity of Data Scientist***","9f00e0ff":"# ***Kaggle-ML-DS-Survey***\n\n**Description**\n\nThis year Kaggle is once again launching an annual Data Science Survey Challenge, where we will be awarding a prize pool of $30,000 to notebook authors who tell a rich story about a subset of the data science and machine learning community.\n\nIn our fourth year running this survey, we were once again awed by the global, diverse, and dynamic nature of the data science and machine learning industry. This survey data EDA provides an overview of the industry on an aggregate scale, but it also leaves us wanting to know more about the many specific communities comprised within the survey. For that reason, we\u2019re inviting the Kaggle community to dive deep into the survey datasets and help us tell the diverse stories of data scientists from around the world.\n\n<br><br>","1bbaa18d":"11.6% People **Does not share\/Deploy** their Application, which is a sad news \ud83d\ude22. Most people uses **GitHub** for deploying\/sharing the code. 9.37% people uses **Kaggle** ","532cc92d":"***Question 26: Which of the following cloud computing platforms do you use on a regular basis? Part-A***","b987df6e":"***Question 14: What data visualization libraries or tools do you use on a regular basis?***","e9f83b26":"***Question 10: Which of the following hosted notebook products do you use on a regular basis?***","71ba353d":"***Question 35_b: In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments?***","3d82fdfe":"31.6% people uses Hosted **Collab Notebooks** for their ML\/DS work. 29.9% people uses **Kaggle Notebooks**. 26.4% people **does not use any hosted Notebook.**","9caecea7":"Most people have completed courses from **Coursera**. 24.2% People have completed the course from **Kaggle Micro-course**. 23.1% people have completed their online course from **Udemy**. Only 5.28% people have completed courses from **Fast.ai**","3170b577":"56% of people uses **Jupyter** as most used IDE's. We can see that  29.3% people uses **VS Code**, followed by **PyCharm**. 1.9% people does not use any IDE's \ud83d\ude22.","52425fb9":"***Question 22: Does your current employer incorporate machine learning methods into their business?***"}}