{"cell_type":{"0929acbe":"code","ea21e706":"code","83c3f55b":"code","84398a97":"code","3aa1e2ff":"code","1b6483ed":"code","215b1741":"code","5602bf35":"code","2d7c4621":"code","f2c07689":"code","c915743b":"code","188df1ca":"code","4421ebc2":"code","b46a988b":"code","b3e99516":"code","26f894b5":"code","09eb8655":"code","5ec61108":"code","6d3a785f":"code","d2ec7fc2":"code","271309ea":"code","d6f098c9":"code","ae0261ff":"code","12b6c661":"code","dfc45818":"markdown","b54bf716":"markdown","d692c681":"markdown","3e5974bd":"markdown","812dd4a2":"markdown","bfd5e90d":"markdown","34d48a45":"markdown","be55d852":"markdown","71e7f4cd":"markdown","e2899b60":"markdown","627568fa":"markdown","4e535c90":"markdown","e45025e8":"markdown"},"source":{"0929acbe":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop, Adam, Adagrad, Adamax, Adadelta\n\nfrom sklearn.metrics import classification_report, confusion_matrix","ea21e706":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","83c3f55b":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","84398a97":"train.head()","3aa1e2ff":"train.shape","1b6483ed":"train.isna().any().sum()","215b1741":"df_digit_counts =  train.label.value_counts().reset_index()\n\nplt.figure(figsize=(20,8))\nax = sns.barplot(x='index', y='label', data=df_digit_counts)\n\nfor i in ax.patches:\n    v1 = round((i.get_height()\/len(train))*100, 2)\n    ax.annotate(f'{int(i.get_height())} ({v1}%)', (i.get_x()+0.4, i.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\n\nplt.title(\"Digit Count\")\nplt.ylabel(\"Counts\")\nplt.xlabel(\"Digits\")\nplt.show()","5602bf35":"train_X, train_y = train.drop(columns=['label']), train[\"label\"]","2d7c4621":"train_X = np.array(train_X)\ntrain_y = np.array(train_y)","f2c07689":"train_X = train_X \/ 255.0\ntest = test \/ 255.0","c915743b":"train_X = train_X.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","188df1ca":"train_y = to_categorical(train_y, num_classes = len(np.unique(train[\"label\"])))","4421ebc2":"X_train, X_test, y_train, y_test = train_test_split(train_X, \n                                                    train_y, \n                                                    test_size=0.2, \n                                                    random_state=42, \n                                                    stratify= train_y, \n                                                    shuffle=True)","b46a988b":"epochs = 50\nbatch_size = 32","b3e99516":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation = \"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(10, activation = \"softmax\"))","26f894b5":"model.summary()","09eb8655":"optimizer = Adamax()\nmodel.compile(optimizer=optimizer, \n              loss = 'categorical_crossentropy', \n              metrics=['accuracy'])","5ec61108":"# Set a learning rate annealer\nlr_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\nes = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=5,\n                              verbose=0, mode='auto')","6d3a785f":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.12,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.12,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\ndatagen.fit(X_train)\n","d2ec7fc2":"# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,y_train, \n                              batch_size=batch_size),\n                              epochs = epochs, \n                              validation_data = (X_test,y_test), \n                              steps_per_epoch=X_train.shape[0] \/\/ batch_size,\n                              callbacks=[lr_reduction, es], \n                              shuffle=True)","271309ea":"model.evaluate(X_train, y_train), model.evaluate(X_test, y_test)","d6f098c9":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","ae0261ff":"ypred = model.predict(X_test)\nypred = np.argmax(ypred, axis=1)\nytest = np.argmax(y_test, axis=1)\n\ncf_matrix = confusion_matrix(ytest, ypred)\n\nplt.figure(figsize=(20,8))\nax = sns.heatmap(cf_matrix, annot=True, fmt='g')\nplt.show()\n\nprint(\"\\n\\n\")\nprint(classification_report(ytest, ypred))","12b6c661":"# predict results\nresults = model.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"digit_reconizer_submission_rsb_updated.csv\",index=False)","dfc45818":"### Evaluate Model","b54bf716":"### Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])","d692c681":"## Load Train, Test data","3e5974bd":"### Split train data in features and lables","812dd4a2":"### Split Training data into train and validation data","bfd5e90d":"### Normalize Data","34d48a45":"## Submission","be55d852":"## Checking for NA","71e7f4cd":"**There is no NA record in train data**","e2899b60":"### Define Model","627568fa":"### Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)","4e535c90":"> ### Convert train_X, train_y into numpy array","e45025e8":"### There are 42000 rows and 785 columns"}}