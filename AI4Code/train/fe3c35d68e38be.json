{"cell_type":{"e7691e31":"code","c7393508":"code","0ffa9b5d":"code","82a9342f":"code","97de5b60":"code","5707adae":"code","ccbea9a8":"code","e5f0c397":"code","9aba6b05":"code","895c62a2":"code","c8ffa83e":"code","26440418":"code","b7783bd2":"code","89355ca5":"code","218b37d1":"code","580ea59b":"code","9fc6f1be":"code","72b1d1c6":"code","f8685ebc":"code","0a821a06":"code","58d67bc4":"code","ab92ce50":"code","b09f259f":"code","6b5503ea":"code","f34a7297":"code","91f8b947":"code","5148525a":"code","d06c7cee":"code","7e3d34eb":"code","4beb2a83":"code","38feb412":"code","650caf61":"code","80f7a026":"markdown","5faa571b":"markdown","8c8dca76":"markdown","91390744":"markdown","25372fe6":"markdown"},"source":{"e7691e31":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c7393508":" \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.gridspec as gridspec\nfrom wordcloud import WordCloud, STOPWORDS \nplt.style.use('seaborn')\nsns.set_style('whitegrid')\n%matplotlib inline\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\npd.options.mode.chained_assignment = None # Warning for chained copies disabled","0ffa9b5d":"a = pd.read_csv(\"\/kaggle\/input\/world-food-facts\/en.openfoodfacts.org.products.tsv\",\n                       delimiter='\\t',\n                       encoding='utf-8')","82a9342f":"#Use this code to show all the 163 columns\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)","97de5b60":"def msv1(data, thresh=20, color='black', edgecolor='black', width=15, height=3):\n    \"\"\"\n    SOURCE: https:\/\/www.kaggle.com\/amiiiney\/price-prediction-regularization-stacking\n    \"\"\"\n    \n    plt.figure(figsize=(width,height))\n    percentage=(data.isnull().mean())*100\n    percentage.sort_values(ascending=False).plot.bar(color=color, edgecolor=edgecolor)\n    plt.axhline(y=thresh, color='r', linestyle='-')\n    plt.title('Missing values percentage per column', fontsize=20, weight='bold' )\n    plt.text(len(data.isnull().sum()\/len(data))\/1.7, thresh+12.5, 'Columns with more than %s%s missing values' %(thresh, '%'), fontsize=12,weight='bold', color='crimson',\n         ha='left' ,va='top')\n    plt.text(len(data.isnull().sum()\/len(data))\/1.7, thresh - 5, 'Columns with less than %s%s missing values' %(thresh, '%'), fontsize=12,weight='bold', color='blue',\n         ha='left' ,va='top')\n    plt.xlabel('Columns', size=15, weight='bold')\n    plt.ylabel('Missing values percentage', weight='bold')\n    plt.yticks(weight ='bold')\n    \n    return plt.show()","5707adae":"msv1(a,30, color=('silver', 'gainsboro', 'lightgreen', 'white', 'lightpink'))","ccbea9a8":"ab=a.dropna(thresh=106800, axis=1)\nprint(f\"Data shape before cleaning {a.shape}\")\nprint(f\"Data shape after cleaning {ab.shape}\")\nprint(f\"We dropped {a.shape[1]- ab.shape[1]} columns\")","e5f0c397":"countries=ab['countries_en'].value_counts().head(10).to_frame()\ns = countries.style.background_gradient(cmap='Blues')\ns","9aba6b05":"brands= ab['brands'].value_counts().head(10).to_frame()\nk = brands.style.background_gradient(cmap='Reds')\nk","895c62a2":"#Filter the data and keep just the Meijer brand products:\nac=ab[ab['brands']=='Meijer']","c8ffa83e":"ac=ac.fillna(0, axis=1)","26440418":"ac_corr=ac.corr()\nf,ax=plt.subplots(figsize=(10,7))\nsns.heatmap(ac_corr, cmap='viridis')\nplt.title(\"Correlation between features\", \n          weight='bold', \n          fontsize=18)\nplt.xticks(weight='bold')\nplt.yticks(weight='bold')\n\nplt.show()","b7783bd2":"plt.figure(figsize=(15, 6))\n\nplt.scatter(x=ac['nutrition-score-uk_100g'], y=ac['energy_100g'], color='deeppink', alpha=0.5)\nplt.title(\"UK Nutrition score of Meijer's products based on calories \", \n          weight='bold', \n          fontsize=15)\nplt.xlabel('Nutrition score UK', weight='bold', fontsize=14)\nplt.ylabel('Calories', weight='bold', fontsize=14)\nplt.xticks(fontsize=12, weight='bold')\nplt.yticks(fontsize=12,weight='bold')\n\n\nplt.show()","89355ca5":"ad=ac[['product_name','energy_100g', 'fat_100g',\n       'saturated-fat_100g', 'carbohydrates_100g', 'sugars_100g',\n       'proteins_100g']]\nprint(f\"we have {ad.shape[0]} products in Meijer supermarkets and {ad.shape[1]} features\")","218b37d1":"keto= ad[(ad['energy_100g']<2000)&(ad['carbohydrates_100g']<40)&(ad['fat_100g']<165)&(ad['proteins_100g']<75)]\nprint(f'We have {keto.shape[0]} keto products in Meijer supermarkets')","580ea59b":"da=keto.sort_values(by=['energy_100g'],ascending=False).sample(5)\nn = da.style.background_gradient(cmap='Purples')\nn","9fc6f1be":"def label_cal (row):\n   if row['energy_100g'] < 250  :\n      return 'low'\n   if row['energy_100g'] > 250 and row['energy_100g'] < 500 :\n      return 'medium'\n   if row['energy_100g'] > 500 :\n      return 'high'\n   \n   return 'Other'\n\n\ndef label_fat (row):\n   if row['fat_100g'] < 10 :\n      return 'low'\n   if row['fat_100g'] >= 10 and row['fat_100g'] < 20 :\n      return 'medium'\n   if row['fat_100g'] >= 20 :\n      return 'high'\n   \n   return 'Other'\ndef label_pro (row):\n   if row['proteins_100g'] < 10 :\n      return 'low'\n   if row['proteins_100g'] >= 10 and row['proteins_100g'] < 20 :\n      return 'medium'\n   if row['proteins_100g'] >= 20 :\n      return 'high'\n   \n   return 'Other'\n\n\ndef label_carb (row):\n   if row['carbohydrates_100g'] < 4 :\n      return 'low'\n   if row['carbohydrates_100g'] >= 4 and row['carbohydrates_100g'] < 12 :\n      return 'medium'\n   if row['carbohydrates_100g'] >= 12 :\n      return 'high'\n   \n   return 'Other'\n\n# we add those new columns to the existing keto dataset:\nketo['calories'] = keto.apply (lambda row: label_cal(row), axis=1)\n\nketo['fat'] = keto.apply (lambda row: label_fat(row), axis=1)\n\nketo['protein'] = keto.apply (lambda row: label_pro(row), axis=1)\nketo['carbs'] = keto.apply (lambda row: label_carb(row), axis=1)\n\n#Create dataframe\n\ndb=keto.calories.value_counts().reset_index()\ndd= keto.fat.value_counts().reset_index()\nde=keto.protein.value_counts().reset_index()\ndg=keto['carbs'].value_counts().reset_index()\n\n#Merge them on the 'index' column:\nmerged=db.merge(dd,on='index').merge(de, on='index').merge(dg, on='index')\nmergedstyle = merged.style.background_gradient(cmap='Greens')\nmergedstyle","72b1d1c6":"label1=db['index']\nlabel2=dd['index']\nlabel3=de['index']\nlabel4=dg['index']\n\n\nfig = plt.figure(figsize=(15,10))\n#2 rows 2 cols\n#first row, first col\nax1 = plt.subplot2grid((2,2),(0,0))\nplt.pie(db.calories,colors=(\"grey\",\"r\",\"orange\"),labels=label1, autopct='%.2f',textprops={'fontsize': 14, 'weight':'bold'})\nplt.title('calories',weight='bold', fontsize=18)\n#first row sec col\nax1 = plt.subplot2grid((2,2), (0, 1))\nplt.pie(dd.fat,colors=(\"grey\",\"r\",\"orange\"),labels=label2, autopct='%.2f',textprops={'fontsize': 14, 'weight':'bold'})\nplt.title('fat',weight='bold', fontsize=18)\n#Second row first column\nax1 = plt.subplot2grid((2,2), (1, 0))\nplt.pie(de.protein,colors=(\"grey\",\"r\",\"orange\"),labels=label3, autopct='%.2f',textprops={'fontsize': 14, 'weight':'bold'})\nplt.title('protein',weight='bold', fontsize=18)\n#second row second column\nax1 = plt.subplot2grid((2,2), (1, 1))\nplt.pie(dg.carbs,colors=(\"grey\",\"r\",\"orange\"),labels=label4, autopct='%.2f',textprops={'fontsize': 14, 'weight':'bold'})\nplt.title('carbs',weight='bold', fontsize=18)\nplt.show()","f8685ebc":"ketocat=keto[['product_name', 'calories', 'protein','fat','carbs']]\nketo_low=ketocat.loc[ketocat['calories']=='low']\nketo_medium=ketocat.loc[ketocat['calories']=='medium']\nketo_high=ketocat.loc[ketocat['calories']=='high']","0a821a06":"wordcloud1 = WordCloud(width=600, height=500, background_color='white').generate(' '.join(keto_low['product_name']))\nWordCloud.generate_from_frequencies\n\n\nwordcloud2 = WordCloud(width=600, height=500, background_color='white').generate(' '.join(keto_medium['product_name']))\nWordCloud.generate_from_frequencies\n\n\nwordcloud3 = WordCloud(width=600, height=500, background_color='white').generate(' '.join(keto_high['product_name']))\nWordCloud.generate_from_frequencies\n\n\nfig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(15,8))\n\nfig.suptitle('Low, medium and high calories products', weight='bold', fontsize=20)\nax1.set_title('Low calories products', weight='bold', fontsize=15, color='b')\n# Display image, `aspect='auto'` makes it fill the whole `axes` (ax3)\nim1 = ax1.imshow(wordcloud1, aspect='auto')\n\n\nax2.set_title('Medium calories products', weight='bold', fontsize=15, color='b')\nim4 = ax2.imshow(wordcloud2, aspect='auto')\n\nax3.set_title('High calories products', weight='bold', fontsize=15, color='b')\nim4 = ax3.imshow(wordcloud3, aspect='auto')\n\n# Make space for title\nplt.subplots_adjust(top=0.85)\nplt.show()","58d67bc4":"ketoc=keto[['energy_100g','fat_100g', 'saturated-fat_100g','carbohydrates_100g', 'sugars_100g', 'proteins_100g']]","ab92ce50":"from scipy.stats import skew\nnumeric_feats = ketoc.dtypes[ketoc.dtypes != \"object\"].index\n\nskewed_feats = ketoc[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\nskewed_feats = skewed_feats[skewed_feats > 0.75]\nskewed_feats = skewed_feats.index\n\nketoc[skewed_feats] = np.log1p(ketoc[skewed_feats])","b09f259f":"from sklearn.preprocessing import RobustScaler\n\nscaler=RobustScaler()\nscaler.fit(ketoc)","6b5503ea":"from collections import defaultdict\nfrom scipy.spatial.distance import pdist, squareform\nfrom scipy.cluster.hierarchy import linkage, dendrogram\nfrom matplotlib.colors import rgb2hex, colorConverter\nfrom scipy.cluster.hierarchy import set_link_color_palette\nimport pandas as pd\nimport scipy.cluster.hierarchy as sch\n%pylab inline","f34a7297":"#ketoo=keto.drop(['calories', 'protein','fat','carbs'], axis=1 )\n#keton=ketoo.set_index('product_name')\n#ketonn=keton.T\n#ketom=ketonn.reset_index(drop=True)","91f8b947":"from sklearn.cluster import AgglomerativeClustering\nimport scipy.cluster.hierarchy as shc\n\nplt.figure(figsize=(20, 7))\nplt.title(\"Supermarket food products Dendograms\")\nplt.xticks(rotation='vertical')\n\n\ndend = shc.dendrogram(shc.linkage(ketoc, method='ward'))","5148525a":"agc = AgglomerativeClustering(n_clusters=8, affinity='euclidean', memory=None, connectivity=None, compute_full_tree='auto', linkage='ward')\npred_ag = agc.fit_predict(ketoc)","d06c7cee":"keto['ag_cluster']= agc.fit_predict(ketoc)","7e3d34eb":"plt.figure(figsize=(15,5))\nplt.style.use('seaborn')\nsns.set_style('whitegrid')\nketo['ag_cluster'].value_counts().plot(kind='bar', color=['tan', 'crimson', 'silver', 'darkcyan',\n                                                          'deeppink', 'deepskyblue','lightgreen', 'orchid'])\nplt.ylabel(\"Count\",fontsize=14, weight='bold')\nplt.xlabel(' Agglomerative Clusters', fontsize=14, weight='bold')\nplt.show()","4beb2a83":"#Clusters column\nagcluster0=keto[keto['ag_cluster']==0]\nagcluster1=keto[keto['ag_cluster']==1]\nagcluster2=keto[keto['ag_cluster']==2]\nagcluster3=keto[keto['ag_cluster']==3]\nagcluster4=keto[keto['ag_cluster']==4]\nagcluster5=keto[keto['ag_cluster']==5]\nagcluster6=keto[keto['ag_cluster']==6]\nagcluster7=keto[keto['ag_cluster']==7]\n\nwordcloud20 = WordCloud(width=400, height=300, background_color='white', colormap='Reds').generate(' '.join(agcluster0['product_name']))\nWordCloud.generate_from_frequencies\n\n\nwordcloud21 = WordCloud(width=400, height=300, background_color='white', colormap='Reds').generate(' '.join(agcluster1['product_name']))\nWordCloud.generate_from_frequencies\n\n\nwordcloud22 = WordCloud(width=400, height=300, background_color='white', colormap='Reds').generate(' '.join(agcluster2['product_name']))\nWordCloud.generate_from_frequencies\n\nwordcloud23 = WordCloud(width=400, height=300, background_color='white', colormap='Reds').generate(' '.join(agcluster3['product_name']))\nWordCloud.generate_from_frequencies\n\n\nwordcloud24 = WordCloud(width=400, height=300, background_color='white', colormap='Reds').generate(' '.join(agcluster4['product_name']))\nWordCloud.generate_from_frequencies\n\n\nwordcloud25 = WordCloud(width=400, height=300, background_color='white', colormap='Reds').generate(' '.join(agcluster5['product_name']))\nWordCloud.generate_from_frequencies\n\nwordcloud26 = WordCloud(width=400, height=300, background_color='white', colormap='Reds').generate(' '.join(agcluster6['product_name']))\nWordCloud.generate_from_frequencies\n\n\nwordcloud27 = WordCloud(width=400, height=300, background_color='white', colormap='Reds').generate(' '.join(agcluster7['product_name']))\nWordCloud.generate_from_frequencies\n\n#Create color dictionary for clusters\ncol_dic = {0:'darkblue',1:'green',2:'darkorange',3:'yellow',4:'magenta',5:'black', 6:'cyan', 7:'lime', 8:'red', 9:'darkviolet', 10:'grey'}\ncolors3 = [col_dic[x] for x in pred_ag]\n#Funciton to plot the clusters\ndef plot_ag_cluster(keto, color):\n    fig, ax = plt.subplots(2, 2, figsize=(12,11)) # define plot area         \n    x_cols = ['carbohydrates_100g', 'fat_100g', 'sugars_100g', 'proteins_100g']\n    y_cols = ['energy_100g', 'proteins_100g', 'energy_100g', 'carbohydrates_100g']\n    for x_col,y_col,i,j in zip(x_cols,y_cols,[0,0,1,1],[0,1,0,1]):\n        for x,y,c in zip(ketoc[x_col], ketoc[y_col], colors3):\n            ax[i,j].scatter(x,y, color = c)\n        ax[i,j].set_title('Scatter plot of ' + y_col + ' vs. ' + x_col) # Give the plot a main title\n        ax[i,j].set_xlabel(x_col) # Set text for the x axis\n        ax[i,j].set_ylabel(y_col)# Set text for y axis\n    plt.show()","38feb412":"plot_ag_cluster(ketoc, colors3)","650caf61":"from sklearn.cluster import KMeans, AgglomerativeClustering\nimport numpy as np\n\nkmeans = KMeans(n_clusters=8\n                       ,init = 'k-means++'\n                       , n_init = 10\n                       , tol = 0.0001\n                       , n_jobs = -1\n                       , random_state = 1).fit(ketoc)\nlabels2 = kmeans.labels_\n\ncenters=kmeans.cluster_centers_","80f7a026":"We started with a hierarchical cluster analysis. It is an algorithm that groups similar objects into groups, this helped us to guess an ideal cluster number to start our clustering (8 clusters), but it's not the best method. There is a popular method known as elbow method which is used to determine the optimal value of K to perform the K-Means Clustering Algorithm. The basic idea behind this method is that it plots the various values of cost with changing k. ... The lesser number of elements means closer to the centroid.\n\nEffectively, k=8 clusters was not the optimum value since we got 2 clusters that are not clear with mixed products, which means there is still significant room for improvement. However, in the other clusters, we could see a clear dominance of certain type of food, for example, cluster 5 has mainly: boneless meat, chicken, turkey, ham, bacon, sausages...\n\nThe clear clusters tend to be the smallest, with fewer products in comparison to other clusters. This invites us to increase the number of clusters in order to decrease the variation between clusters. The variation within the clusters should be as large as possible, while the variation between clusters should be as small as possible.","5faa571b":"This dendogram gives us an idea on how the algorithm clusters the data, it shows 4 different clusters of different sizes, the red cluster is very small in comparison to the green. For the sake of finding sub-clusters inside of big clusters, I will start my analysis with 8 clusters instead of 4. The idea is to split the green and cean clusters into 2 or 3 sub-clusters.\n\nThe ideal method to find the right number of clusters would be to try the measurement: Within Cluster Sum of Squares (WCSS), which measures the squared average distance of all the points within a cluster to the cluster centroid. (The Euclidean distance between a given point and the centroid to which it is assigned)","8c8dca76":"4.3 K-Means algorithm:\nK-Means is chosen with the following parameters:\n\n8 clusters (n_clusters);\nInitial cluster centres chosen using K-Means++ (init);\nThe algorithm will be run 10 times using different centroid seeds, with the best chosen using inertia (n_init);\nConvergence is declared when inertia falls below 1e-4 (tol);\nWe have overriden the default number of CPUs used (n_jobs) from no parallel computing (1) - eases debugging - to all CPUS (-1);\nSeed for the random selection of initial centres set to 1 (random_state)","91390744":"We can see clear clusters in the first figure. Calories is the sum of the other macromolecules, so having clear clusters that don't overlap much is essensial. However, we can't see clear clusters when plotting the products in terms of their proteins or fat values. This can be a good signal, because we don't want a \"calories based clustering\", otherwise we could just do it manually as we did in previous sections of this work.\n\nWe will evaluate those clusters further on, now, we try another clustering algorithm: Kmeans","25372fe6":"Here are some notes:\nMost of the products in this dataset are either French or American\n1057 out of 1995 products in Meijer supermarkets are suitable for a keto diet.\nMeijer has its own food brand: True goodness\nThere are 385 low calories products in Meijer supermarkets. Main products: Vegetable, pureed baby, beens, water beverage, carrot, strawberry...\nThere are 276 medium calories products in Meijer supermarkets. Main products: Beans, nonfat yogurt, pasta sauce, banana, tomato ketchup...\nThere are 396 high calories products in Meijer supermarkets. Main products: Cheese,chicken, ice cream, cheddar, sausage...."}}