{"cell_type":{"574024dd":"code","4f2651fc":"code","95c328d4":"code","8bf9f483":"code","fcaa759a":"code","babf0575":"code","939d5a23":"code","15e0431f":"code","edfa95eb":"code","8751fc03":"code","ca46a9aa":"code","da9b0388":"code","7a476db3":"code","e16b6eea":"code","17ce8aba":"code","2d24cc87":"code","4eef1dc0":"code","1552ed37":"code","500e9165":"markdown","528fb6a1":"markdown","c8c7b252":"markdown","e98d54f8":"markdown","b6efa2a6":"markdown","9023afbd":"markdown","e4e650a7":"markdown","30fdcaea":"markdown","29554bd9":"markdown","512c2cbf":"markdown","687aaa91":"markdown"},"source":{"574024dd":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import layers, losses\nfrom tensorflow.keras.datasets import fashion_mnist\nfrom tensorflow.keras.models import Model","4f2651fc":"(x_train, _), (x_test, _) = fashion_mnist.load_data()\n\nx_train = x_train.astype('float32') \/ 255.\nx_test = x_test.astype('float32') \/ 255.\n\nprint (x_train.shape)\nprint (x_test.shape)","95c328d4":"latent_dim = 64 \n\nclass Autoencoder(Model):\n  def __init__(self, latent_dim):\n    super(Autoencoder, self).__init__()\n    self.latent_dim = latent_dim   \n    self.encoder = tf.keras.Sequential([\n      layers.Flatten(),\n      layers.Dense(latent_dim, activation='relu'),\n    ])\n    self.decoder = tf.keras.Sequential([\n      layers.Dense(784, activation='sigmoid'),\n      layers.Reshape((28, 28))\n    ])\n\n  def call(self, x):\n    encoded = self.encoder(x)\n    decoded = self.decoder(encoded)\n    return decoded\n  \nautoencoder = Autoencoder(latent_dim) ","8bf9f483":"autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())","fcaa759a":"autoencoder.fit(x_train, x_train,\n                epochs=10,\n                shuffle=True,\n                validation_data=(x_test, x_test))","babf0575":"encoded_imgs = autoencoder.encoder(x_test).numpy()\ndecoded_imgs = autoencoder.decoder(encoded_imgs).numpy()","939d5a23":"n = 10\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n  # display original\n  ax = plt.subplot(2, n, i + 1)\n  plt.imshow(x_test[i])\n  plt.title(\"original\")\n  plt.gray()\n  ax.get_xaxis().set_visible(False)\n  ax.get_yaxis().set_visible(False)\n\n  # display reconstruction\n  ax = plt.subplot(2, n, i + 1 + n)\n  plt.imshow(decoded_imgs[i])\n  plt.title(\"reconstructed\")\n  plt.gray()\n  ax.get_xaxis().set_visible(False)\n  ax.get_yaxis().set_visible(False)\nplt.show()","15e0431f":"(x_train, _), (x_test, _) = fashion_mnist.load_data()","edfa95eb":"x_train = x_train.astype('float32') \/ 255.\nx_test = x_test.astype('float32') \/ 255.\n\nx_train = x_train[..., tf.newaxis]\nx_test = x_test[..., tf.newaxis]\n\nprint(x_train.shape)","8751fc03":"noise_factor = 0.2\nx_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape) \nx_test_noisy = x_test + noise_factor * tf.random.normal(shape=x_test.shape) \n\nx_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)\nx_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)","ca46a9aa":"n = 10\nplt.figure(figsize=(20, 2))\nfor i in range(n):\n    ax = plt.subplot(1, n, i + 1)\n    plt.title(\"original + noise\")\n    plt.imshow(tf.squeeze(x_test_noisy[i]))\n    plt.gray()\nplt.show()","da9b0388":"class Denoise(Model):\n  def __init__(self):\n    super(Denoise, self).__init__()\n    self.encoder = tf.keras.Sequential([\n      layers.Input(shape=(28, 28, 1)),\n      layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),\n      layers.Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)])\n\n    self.decoder = tf.keras.Sequential([\n      layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),\n      layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n      layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n\n  def call(self, x):\n    encoded = self.encoder(x)\n    decoded = self.decoder(encoded)\n    return decoded\n\nautoencoder = Denoise()","7a476db3":"autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())","e16b6eea":"autoencoder.fit(x_train_noisy, x_train,\n                epochs=10,\n                shuffle=True,\n                validation_data=(x_test_noisy, x_test))","17ce8aba":"autoencoder.encoder.summary()","2d24cc87":"autoencoder.decoder.summary()","4eef1dc0":"encoded_imgs = autoencoder.encoder(x_test).numpy()\ndecoded_imgs = autoencoder.decoder(encoded_imgs).numpy()","1552ed37":"n = 10\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n\n    # display original + noise\n    ax = plt.subplot(2, n, i + 1)\n    plt.title(\"original + noise\")\n    plt.imshow(tf.squeeze(x_test_noisy[i]))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    bx = plt.subplot(2, n, i + n + 1)\n    plt.title(\"reconstructed\")\n    plt.imshow(tf.squeeze(decoded_imgs[i]))\n    plt.gray()\n    bx.get_xaxis().set_visible(False)\n    bx.get_yaxis().set_visible(False)\nplt.show()","500e9165":"Train the model using x_train as both the input and the target. The encoder will learn to compress the dataset from 784 dimensions to the latent space, and the decoder will learn to reconstruct the original images. .","528fb6a1":"Plot the noisy images.","c8c7b252":"The decoder upsamples the images back from 7x7 to 28x28.","e98d54f8":"Now that the model is trained, let's test it by encoding and decoding images from the test set.","b6efa2a6":"Plotting both the noisy images and the denoised images produced by the autoencoder.","9023afbd":"Let's take a look at a summary of the encoder. Notice how the images are downsampled from 28x28 to 7x7.","e4e650a7":"9. Use MNIST fashion dataset. Construct an auto encoder model that can compress the given images of MNIST dataset.","30fdcaea":"## Define a convolutional autoencoder","29554bd9":"Import TensorFlow and other libraries","512c2cbf":"Adding random noise to the images","687aaa91":"Load the dataset\nTo start, you will train the basic autoencoder using the Fashon MNIST dataset. Each image in this dataset is 28x28 pixels."}}