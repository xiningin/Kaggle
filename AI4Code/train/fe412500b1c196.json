{"cell_type":{"423c7876":"code","eb215320":"code","601c39fb":"code","b8745025":"code","86b17459":"code","30b38407":"code","b457ef3b":"code","c3866e8c":"code","621c8ffa":"code","60829fab":"code","460a72da":"code","9ad2b454":"code","ad8b7393":"code","3f0e547d":"code","b9818349":"code","e8c385ad":"code","3a7a601a":"code","b2c121c5":"code","8dc186a8":"code","661d6e8c":"code","d715cd4f":"code","dab71e96":"code","fe426760":"code","0e22e568":"code","96f1f13e":"code","56fa770f":"code","0394b38f":"code","c6be200b":"code","ecc0513d":"code","b0af81ff":"code","059c4064":"markdown","12f3b170":"markdown","26ab0ca0":"markdown","39f7e2a2":"markdown","8562ad52":"markdown","889fc3c8":"markdown","8648acf8":"markdown","d80eb466":"markdown","c55af528":"markdown","c784f9ea":"markdown","6d948777":"markdown"},"source":{"423c7876":"import numpy as np\nimport pandas as pd\n\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nprint(os.listdir(\"..\/input\"))","eb215320":"import matplotlib as mpl\n\nmpl.rcParams['figure.figsize'] = [15, 7]\nmpl.rcParams['figure.dpi'] = 80\nmpl.rcParams['savefig.dpi'] = 100\n\nmpl.rcParams['font.size'] = 14\nmpl.rcParams['legend.fontsize'] = 'large'\nmpl.rcParams['figure.titlesize'] = 'medium'","601c39fb":"!head -n 5 ..\/input\/train.csv","b8745025":"!wc -l ..\/input\/train.csv","86b17459":"data = pd.read_csv(\"..\/input\/train.csv\", nrows=100000)","30b38407":"CATEGORICALS = [\"site_name\", \"posa_continent\", \"user_location_country\", \"user_location_region\", \"user_location_city\", \"is_mobile\", \"is_package\", \"channel\", \n               \"srch_destination_type_id\", \"hotel_continent\", \"hotel_country\", \"hotel_market\", \"srch_destination_id\"]\nNUMERICALS = [\"orig_destination_distance\", \"srch_adults_cnt\", \"srch_children_cnt\", \"srch_rm_cnt\", \"cnt\"]\nUSER_ID = \"user_id\"\nIS_BOOKING = \"is_booking\"\nHOTEL_CLUSTER = \"hotel_cluster\"","b457ef3b":"ax = data[HOTEL_CLUSTER].value_counts().plot.bar(color='dodgerblue')\nax.set_xticklabels([])\nplt.title(\"Hotel clusters' clicks - Looks like the beginnings of a power-law distribution\");","c3866e8c":"data_cat_dummies = pd.get_dummies(pd.get_dummies(data[CATEGORICALS].astype('category')))","621c8ffa":"def name_scores(featurecoef, col_names, label=\"Score\", sort=False):\n    df_feature_importance = pd.DataFrame([dict(zip(col_names, featurecoef))]).T.reset_index()\n    df_feature_importance.columns = [\"Feature\", label]\n    if sort:\n        return df_feature_importance.sort_values(ascending=False, by=label)\n    return df_feature_importance\n","60829fab":"from sklearn.feature_selection import chi2\n\nsample_n = 10000\ndata_cat_dummies_sample = data_cat_dummies.sample(sample_n)\nchi2_scores = chi2(data_cat_dummies_sample, data[HOTEL_CLUSTER].loc[data_cat_dummies_sample.index])\ndf_chi2_scores = name_scores(chi2_scores[0], data_cat_dummies_sample.columns)\ndf_chi2_scores = df_chi2_scores.sort_values(by=\"Score\", ascending=False)","460a72da":"# get the top 100 features and graph the categorical\nn = 100\ntop_n_features = df_chi2_scores[:n][\"Feature\"]","9ad2b454":"top_n_features.apply(lambda s : ' '.join(s.split(\"_\")[:len(s.split(\"_\"))-1])).value_counts()","ad8b7393":"def create_matrix(data, group_column, val_column):\n    grouped_data = data.groupby(group_column)[val_column].value_counts()\n    grouped_data = grouped_data.groupby(level=0).nlargest(3)\n    grouped_data.index = grouped_data.index.droplevel(0)\n    # transfrom to a square matrix\n    grouped_data_unstacked = grouped_data.unstack()\n    return grouped_data_unstacked.fillna(0)","3f0e547d":"hotel_user_city_vc_matrix = create_matrix(data, \"hotel_cluster\", \"user_location_city\")\nhotel_market_vc_matrix = create_matrix(data, \"hotel_cluster\", \"hotel_market\")\nhotel_country_vc_matrix = create_matrix(data, \"hotel_cluster\", \"hotel_country\")\nhotel_continent_vc_matrix = create_matrix(data, \"hotel_cluster\", \"hotel_continent\")\n\n# hotel user city\nfig, axes = plt.subplots(2, 2, figsize=(15, 15))\n\naxes[0][0].set_title(\"Looks like user city ~17 and ~90 is very active\\n all throughout the different hotel clusters\")\naxes[0][0].imshow(hotel_user_city_vc_matrix, cmap='gray')\n\naxes[0][1].set_title(\"Looks like hotel_market ~59 and 62 are\\nrelated to many hotel_clusters\")\naxes[0][1].imshow(hotel_market_vc_matrix, cmap='gray')\n\naxes[1][0].set_title(\"Looks like hotel_country ~8 is\\nrelated to many hotel_clusters (France?)\")\naxes[1][0].imshow(hotel_country_vc_matrix, cmap='gray');\n\naxes[1][1].set_title(\"I think hotel_continent 1 is Europe!\")\naxes[1][1].imshow(hotel_continent_vc_matrix, cmap='gray');","b9818349":"sns.distplot(data[\"orig_destination_distance\"].dropna())\n\nplt.title(\"Majority of destination places are close to the origin. \\nThus, let's just use the median for imputation.\");","e8c385ad":"sample_n = 10000\ndata_numericals_sample = data[NUMERICALS].sample(sample_n)\nchi2_scores = chi2(data_numericals_sample.fillna(data_numericals_sample.median()), data[HOTEL_CLUSTER].loc[data_numericals_sample.index])\ndf_chi2_scores = name_scores(chi2_scores[0], data_numericals_sample.columns)\n\ndf_chi2_pvalues = name_scores(chi2_scores[1], data_numericals_sample.columns)\ndf_chi2_pvalues.columns = [\"Feature\", \"PValue\"]\n\ndf_chi2_scores.merge(df_chi2_pvalues).sort_values(by=\"Score\", ascending=False)","3a7a601a":"sns.boxplot(data=data, x=HOTEL_CLUSTER, y=\"orig_destination_distance\")\n\nplt.title(\"There's a lot of outlier distances for each hotel_cluster\");","b2c121c5":"data_cluster = data[[HOTEL_CLUSTER]].copy()\ndata_cluster[\"cluster_num\"] = pd.cut(data_cluster[HOTEL_CLUSTER], bins=4, labels=range(4))","8dc186a8":"clusters_1 = data[data[HOTEL_CLUSTER].isin(data_cluster.loc[data_cluster[\"cluster_num\"] == 0, HOTEL_CLUSTER])]\nclusters_1_unstacked = clusters_1.groupby(HOTEL_CLUSTER)[\"srch_children_cnt\"].value_counts().unstack().fillna(0)\n\nclusters_1_unstacked= clusters_1_unstacked.drop(0, axis=1).sort_values(by=2,)\nax = clusters_1_unstacked.plot.barh(stacked=True)\nax.legend(loc='upper right')\n\nplt.title(\"Some hotel_clusters are more perceived to be family friendly\", );","661d6e8c":"print(\"Search destination id's nunique: \", data[\"srch_destination_id\"].nunique())\nprint(\"Search destination types nunique: \", data[\"srch_destination_type_id\"].nunique())","d715cd4f":"hotel_search_type_matrix = create_matrix(data, HOTEL_CLUSTER, \"srch_destination_type_id\")\nprint(\"Looks like the search types tend around 1 and 6.\")\ndisplay(hotel_search_type_matrix[:10])\nplt.imshow(hotel_search_type_matrix, cmap='gray');","dab71e96":"hotel_to_search_n = data.groupby(HOTEL_CLUSTER)[\"srch_destination_id\"].nunique()\nax = sns.distplot(hotel_to_search_n, bins=50, kde=False)\nax.set_xlabel(\"Number of unique search IDs per hotel cluster\")\n\ndisplay(data.groupby(HOTEL_CLUSTER)[\"srch_destination_id\"].nunique().describe().to_frame(\n    \"Stats of the number of unique search IDs per hotel cluster\"))","fe426760":"destinations = pd.read_csv(\"..\/input\/destinations.csv\")","0e22e568":"def create_latent_search_img(index, ax):\n    # to make the image 10x15, we create a 150th feature with the mean of the array\n    img = np.array(destinations.loc[index].values[1:].tolist() + [destinations.loc[index].values[1:].mean()])\n    img = img.reshape((15,10))\n    sns.heatmap(img, cmap='gray', ax=ax)\n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    return ax","96f1f13e":"ax1 = create_latent_search_img(0, plt.subplot(2, 3, 1))\nax2 = create_latent_search_img(1, plt.subplot(2, 3, 2))\nax3 = create_latent_search_img(2, plt.subplot(2, 3, 3))\nax4 = create_latent_search_img(3, plt.subplot(2, 3, 4))\nax5 = create_latent_search_img(3, plt.subplot(2, 3, 5))\nax6 = create_latent_search_img(3, plt.subplot(2, 3, 6))","56fa770f":"def get_latent_search_hotel_array(hotel_cluster_index):\n    values = data.loc[data[HOTEL_CLUSTER] == hotel_cluster_index, \"srch_destination_id\"].to_frame().merge(destinations)\n    values = values.drop(\"srch_destination_id\", axis=1)\n    values = values.sum()\n    return values\n\ndef create_latent_search_hotel_image(hotel_cluster_index, ax):\n    img = get_latent_search_hotel_array(hotel_cluster_index)\n    img = np.array(img.tolist() + [img.mean()])\n    img = img.reshape((15,10))\n    \n    ax.imshow(img, cmap='gray')\n    ax.set_title(\"Cluster \" + str(hotel_cluster_index))\n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    return ax","0394b38f":"hotel_arrays = []\nfor i in range(data[HOTEL_CLUSTER].nunique()):\n    hotel_arrays.append(get_latent_search_hotel_array(i))\nhotel_arrays = np.array(hotel_arrays)","c6be200b":"from scipy.cluster import hierarchy\nimport matplotlib.pyplot as plt\n\nZ = hierarchy.linkage(hotel_arrays, 'single')\nplt.figure(figsize=(20, 8))\ndn = hierarchy.dendrogram(Z)\n\n# We change the fontsize of minor ticks label \nplt.tick_params(axis='both', which='major', labelsize=10)\nplt.tick_params(axis='both', which='minor', labelsize=10)\nplt.xticks(rotation=0)\nplt.show()","ecc0513d":"fig = plt.figure(figsize=(20, 20))\n\nfor i in range(data[HOTEL_CLUSTER].nunique()):\n    create_latent_search_hotel_image(i, fig.add_subplot(10, 10, i+1))","b0af81ff":"user_id_col = \"user_id\"\nitem_id_col = HOTEL_CLUSTER\nratings = data[[user_id_col, item_id_col]]\n\nnum_users = ratings[user_id_col].nunique()\nnum_items = ratings[item_id_col].nunique()\npossible_combinations = num_users * num_items\nnnz = len(ratings)\nnnz_percent = nnz \/ possible_combinations\n\nprint(\"Num Users:\", num_users)\nprint(\"Num Items:\", num_items)\nprint(\"Sparsity:\", nnz_percent)\nprint(\"Not very sparse. CF will work wonders here.\")\n\n# average number of hotel_clusters per user\nhotel_per_user = ratings.groupby(user_id_col)[item_id_col].nunique()\n\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(211)\nsns.distplot(hotel_per_user, kde=False, ax=ax)\nax.set_title(\"Mean number of clusters per user: {:.2f}\".format(hotel_per_user.mean()))\n\n# # average number of users per hotel\nuser_per_hotel = ratings.groupby(item_id_col)[user_id_col].nunique()\nax = fig.add_subplot(212)\nsns.distplot(user_per_hotel, kde=False, ax=ax)\nax.set_title(\"Mean number of users per cluster: {:.2f}\".format(user_per_hotel.mean()))\n\nfig.tight_layout()","059c4064":"# Goals:\n- Hotel_clusters are dependent on which categorical variable?\n    - Graph the top 4\n- Hotel_clusters are dependent on which numerical variable?\n- How correlated are the user's country to the hotel's country? Continent?\n\n# Models to check out\n- The closest 5 hotels in the latent space clicked by each person should be recommended at the top 5 (Content-based filtering)\n- Create a pairwise ranking matrix factorization model of user to hotel cluster (Collaborative filtering)\n- Factorization machine of the dependent categoricals and numericals (Hybrid)","12f3b170":"### Hypotheses:\n- Distance is important to travelers. Hotel clusters seem to be dependent on the distance.\n- Certain hotel clusters seem to be children friendly\n- Certain hotel_clusters seem also to rake in \"bandwagoners\" (thru cnt variable)","26ab0ca0":"## Some basic findings\n- Looks like user city ~17 and ~90 is very active all throughout the different hotel clusters\n- Looks like hotel_market ~59 and 62 are related to many hotel_clusters\n- Looks like hotel_country ~8 is related to many hotel_clusters\n","39f7e2a2":"# Numericals\n- Since orig_destination_distance has null values, let's see its distribution then decide on the imputation method.","8562ad52":"## For each hotel cluster, how is search_id related. How many unique search ids are there for each hotel cluster?\n\n- Seems like there is a non-trivial amount of search id of just 1. These may be the \"weird\" searches that corresponded to some hotel clusters.\n- On the other hand, there's a lot of search ids per hotel cluster. Seems we can work with this for our content-based filtering algorithm. We can spend time tweaking embeddings for each hotel clsuter. Or we can just average them out.","889fc3c8":"* The graph below gets the features whose dummy variables contain the most entries in the top 100 by chi2 scores.\n* Let's graph hotel market, country and user's city with respect to the hotel clusters. \n* We'll dedicate a section for srch_destination_id, but that seems very relevant.\n* For ease of readability, we'll only get the top 5 hotel_clusters, their market, country and user location.","8648acf8":"# What is the relationship of srch_destination_id to hotel_clusters?","d80eb466":"## For each hotel cluster, how is srch type related?","c55af528":"# Latent space variables look like a 10-20 'expressed' variables out of a hundred fifty","c784f9ea":"# Analysis:\n- There's some minute differences across clusters although there are the same latent variables that are always expressed.\n- From the dendrogram, some clusters are very close while those on the left seem very unique.\n\n# Stats for Collaborative Filtering\n- Looks like we can do CF - Matrix Factorization here. Non-zero percentage is 28%, very trivial for CF.\n- We should use dimensionality lower than 100 as to not overfit.","6d948777":"# Let's average out the search ids per hotel cluster\n- Keep in mind the minimum number of unique search ids per hotel_cluster is 5, so we should have unique \"feature images\" per hotel_cluster.\n- When we search, we may click or not click on a hotel cluster. We take into account that act of clicking, which means the more search ids associated to a hotel_cluster, the more expressed the variables of those ids should be.\n   - We can either make this a sum or weighted mean aggregation operation. This can be for exploration in the modeling stage.\n   - For now, we'll do a sum."}}