{"cell_type":{"7524372b":"code","61ce1d53":"code","351fabb9":"code","59f1f78c":"code","0821bba7":"code","02d03f5c":"code","4b42e65c":"code","1f7d0717":"code","3c01469d":"code","eb065892":"code","df659b63":"code","79030941":"code","b4dd83fe":"code","56460fa6":"code","43732089":"code","90945dc0":"code","9525aabd":"code","2c2d852e":"code","7ce72275":"code","5bba2eb8":"code","3da449e9":"code","83f8ee4f":"code","34eb4207":"code","debb2690":"code","08849506":"code","87d72232":"code","fdd1d6b2":"code","7d94e8c4":"code","55a2d1c5":"code","8d7f6f2f":"markdown","b505bc84":"markdown","07bac7e2":"markdown","52bf908b":"markdown","38fda12b":"markdown","adaa7a0b":"markdown","65bb6479":"markdown"},"source":{"7524372b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","61ce1d53":"data=pd.read_csv('..\/input\/winequalityred\/winequality-red.csv')\ndata.head()","351fabb9":"data.info()","59f1f78c":"data.describe()","0821bba7":"data.corr()","02d03f5c":"import seaborn as sm\nsm.heatmap(data.corr(),center=0)","4b42e65c":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import SGDRegressor\n","1f7d0717":"x=data.drop(\"quality\",axis=1)\ny=data.quality","3c01469d":"x_train,x_test,y_train,y_test = train_test_split(x,y, test_size = 0.25,random_state=3)\nx_train.shape,y_train.shape","eb065892":"reg= LinearRegression()\nreg.fit(x_train,y_train)\ny_predict=reg.predict(x_test)","df659b63":"from sklearn.metrics import accuracy_score\n\nacc=accuracy_score(y_test,y_predict.round(),normalize=True)","79030941":"print(acc)","b4dd83fe":"model=SGDRegressor()\nmodel.fit(x_train,y_train)\npredict=model.predict(x_test)","56460fa6":"acc=accuracy_score(y_test,y_predict.round())\nacc","43732089":"from sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier()\nmodel.fit(x_train,y_train)","90945dc0":"Y_predict=model.predict(x_test)","9525aabd":"acc=accuracy_score(y_test,y_predict.round())\nacc","2c2d852e":"sm.barplot(x=data['quality'],y=data['fixed acidity'])","7ce72275":"sm.countplot(data['quality'])","5bba2eb8":"data[['quality']]=data['quality'].apply(lambda x: 0 if int(x)<6 else 1)","3da449e9":"data.quality.value_counts()","83f8ee4f":"y=data['quality']\nx=data.drop(\"quality\",axis=1)\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=20,random_state=2)","34eb4207":"from sklearn.linear_model import LogisticRegression\nmodel1=LogisticRegression(max_iter=10000)\nmodel1.fit(x_train,y_train)\nmodel1=model1.score(x_test,y_test)","debb2690":"from sklearn.ensemble import RandomForestClassifier\nmodel2=RandomForestClassifier()\nmodel2.fit(x_train,y_train)\nmodel2=model2.score(x_test,y_test)","08849506":"from sklearn.tree import DecisionTreeClassifier\nmodel3 = DecisionTreeClassifier()\nmodel3.fit(x_train,y_train)\nmodel3=model3.score(x_test,y_test)","87d72232":"from sklearn.naive_bayes import GaussianNB\nmodel4 = GaussianNB()\nmodel4.fit(x_train,y_train)\nmodel4=model4.score(x_test,y_test)","fdd1d6b2":"from  sklearn.neighbors import KNeighborsClassifier\nmodel5=KNeighborsClassifier()\nmodel5.fit(x_train,y_train)\nmodel5=model5.score(x_test,y_test)","7d94e8c4":"final_results=pd.DataFrame({'models':['LogisticRegression','RandomForset','Dessiontree','GaussianNB','KNeighborsClassifier'],'accuracy_score':[model1,model2,model3,model4,model5]})","55a2d1c5":"sm.barplot(x=final_results['models'],y=final_results['accuracy_score'])","8d7f6f2f":"CONCLUSION","b505bc84":"Relation between variables or correlation in visual","07bac7e2":"RANDOM FOREST has the highest accurancy with 85%","52bf908b":"machine learning by keeping quality as points(1 to 10)","38fda12b":"By keeping quality in points the accuracy is too low.","adaa7a0b":"**So change the quality in two groups '1' (this means good quality. 3,4,5 rated wines are in this group) '0' (this means low quality wine.6,7,8 rated wines are in this group) **","65bb6479":"importing data file"}}