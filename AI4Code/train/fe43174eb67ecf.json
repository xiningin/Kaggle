{"cell_type":{"abf068fa":"code","0f810c59":"code","012efb78":"code","1e884f6a":"code","c0cd3f83":"code","3c9d8b40":"code","8ede1cae":"code","607f8958":"code","881ac9f0":"code","10bea006":"code","0cf8f9cd":"code","974edd6b":"code","46e1d334":"code","3bba9e07":"code","753ab1d4":"code","0503c381":"code","5dc1ca3e":"code","0750a300":"code","86df94a0":"code","4b108fae":"code","e8532653":"code","dee00f49":"code","989506d8":"code","b34d3c17":"code","9bb6008c":"code","f9599637":"code","e3b00097":"code","51d9e099":"code","9beeed7e":"code","4cea508d":"code","dd83cde0":"code","081fe541":"code","fb2fd8f9":"code","472d0f56":"code","453764ed":"code","7323f0a0":"code","7401ec02":"code","3eb7c2ea":"code","99113feb":"code","0de1c6f5":"code","2429eeb0":"code","c15abee6":"code","6df389cc":"code","6eb38394":"code","e382a77f":"code","90b28474":"code","7b9c4ad4":"code","8503a066":"code","974d71c2":"code","607b2c5c":"code","3f2a41a8":"code","6dc14eb6":"code","bca6855b":"code","f0c76b5f":"code","8f69d98b":"code","ffe5da64":"code","b39268cf":"code","84aba717":"code","8e8b3108":"code","dce03381":"code","6c6eb602":"code","e21cacf8":"code","ffe7c6d1":"code","663e3809":"code","dea3c824":"code","2275b9c4":"markdown","d18b7169":"markdown","46fc807d":"markdown","39917076":"markdown","8950bbe8":"markdown","11297e2c":"markdown","20ee188e":"markdown","6122d94d":"markdown","f3ce81fb":"markdown","c031665d":"markdown","986c4b1a":"markdown","005983f7":"markdown","f2dce730":"markdown","2f70c5ab":"markdown","c1cbce21":"markdown","fddd071d":"markdown","49da3302":"markdown","54060afc":"markdown","3bc75788":"markdown","7a2f19a6":"markdown","d397b873":"markdown","fe1f05e1":"markdown","dbc38b01":"markdown","2192ba9d":"markdown","8bef8bf7":"markdown","e1361507":"markdown","b98e818f":"markdown","6e9df100":"markdown","838f4970":"markdown","9739a099":"markdown","a6bc50c8":"markdown","4dd8af0f":"markdown","ab0a5354":"markdown","2f2a52ec":"markdown","d63f0991":"markdown","ee900b7a":"markdown","d5cfc0cf":"markdown","59d59bfb":"markdown","4add4c6e":"markdown","648072ef":"markdown","5f10f477":"markdown","6566d473":"markdown","a350b709":"markdown","51ec1ccd":"markdown","80e3be75":"markdown","98ab52ec":"markdown","271f111c":"markdown","dc616791":"markdown","a18c7ec7":"markdown","98aff43d":"markdown","830f0bf0":"markdown","65cefb6a":"markdown","0e5686f6":"markdown"},"source":{"abf068fa":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import label\n%matplotlib inline\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nimport time\nimport calendar\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils.validation import check_is_fitted\nfrom sklearn.exceptions import NotFittedError\nfrom sklearn.linear_model import LogisticRegression,LogisticRegressionCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.metrics import precision_score, recall_score, auc,roc_curve\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\nfrom sklearn.metrics import average_precision_score","0f810c59":"#load the dataset\ndf_original = pd.read_csv('\/kaggle\/input\/kickstarter-projects\/ks-projects-201801.csv')","012efb78":"#Find the shape of original dataset\nprint(\"Original Dataset shape\",df_original.shape)","1e884f6a":"#Find Original dataset Info\ndf_original.info()","c0cd3f83":"#Convert the launched and deadline date info from Object to datetime format\ndf_original.launched = pd.to_datetime(df_original.launched)\n#filter out all the data prior to 2010\ndf=df_original[df_original.launched>='2010-01-01']","3c9d8b40":"#Data exploration\ndf.head()","8ede1cae":"#Data exploration\ndf.describe()","607f8958":"#Find Datatypes\ndf.dtypes","881ac9f0":"#Find any null values\ndf.isnull().sum()","10bea006":"#Drop irrelevant features \ndf = df.drop(columns=['goal','pledged','name','ID','currency']) ","0cf8f9cd":"#Filter dataset by failed and Successfull\ndf = df[df['state'].isin(['failed','successful'])]\ndf.shape","974edd6b":"#Removed the projects that would fail due to 0 backers\ndf.shape","46e1d334":"#Count by state of the project\nprint(\"Project counts by State or current Status \\n\" , str(df.state.value_counts()))","3bba9e07":"#data cleaning; replace null valuses to zeroes in usd pledged \ndf['usd pledged'] = df['usd pledged'].fillna(value=0,inplace = False)","753ab1d4":"#Parsing deadline and launched date for better results \ndf.deadline = pd.to_datetime(df.deadline)\ndf['duration(days)'] = (df['deadline'] - df.launched).dt.days #number of days from campaign start date to end date\ndf['deadline(y)']=pd.to_datetime(df.deadline).dt.year #deadline year of the campaign \ndf['deadline(d)']=pd.to_datetime(df.deadline).dt.day_name() #deadline week day of the campaign\ndf['deadline(m)']=pd.to_datetime(df.deadline).dt.month #deadline month of the campaign\ndf['launched(y)']=pd.to_datetime(df.launched).dt.year #year which campaign was released\ndf['launched(m)']=pd.to_datetime(df.launched).dt.month#month which campaign was released\ndf['launched(d)']=pd.to_datetime(df.launched).dt.day_name()#weekday which campaign was released","0503c381":"#dropping features deadline and launched as \ndf = df.drop(columns=['deadline','launched']) ","5dc1ca3e":"df.head()","0750a300":"plt.figure(figsize=(10,5))\ndf.groupby(\"main_category\").main_category.count().sort_values(ascending = False).plot(kind=\"bar\",grid =True, color = 'c')\nplt.ylabel(\"Number of projects\")\nplt.title(\"Main Category by Total number of projects\")","86df94a0":"plt.figure(figsize=(15,5))\ndf.groupby(\"category\").category.count().sort_values(ascending = False).head(10).plot(kind= 'bar', grid = True,color = 'm')\nplt.ylabel(\"Number of projects\")\nplt.title(\"Top 10 Categories by Number of projects\")","4b108fae":"plt.figure(figsize=(10,5))\ndf.groupby(\"launched(y)\").main_category.count().plot(kind = 'bar', color = 'r')\nplt.title(\"Number of projects by Year\")","e8532653":"plt.figure(figsize=(20,10))\nsns.set(style=\"darkgrid\")\ng = sns.jointplot(df.groupby('country').usd_pledged_real.mean(), df.groupby('country').usd_goal_real.mean(), data=df,\n                  kind=\"hex\", \n                  color=\"c\", height=7)\nplt.title(\"Mean of Pledged real amount Vs mean of Goal in USD\")\nplt.show()","dee00f49":"plt.figure(figsize=(20,10))\nsns.set(style=\"darkgrid\")\nsns.lmplot(x=\"usd pledged\", y=\"usd_goal_real\", hue='state',data=df,markers=[\"o\", \"x\"], palette=\"Set2\");\nplt.title(\"         Pledged and Goal amount in USD impact on Project Status\")","989506d8":"plt.figure(figsize=(10,5))\nsns.set(style=\"darkgrid\")\ndf.groupby('country').usd_goal_real.mean().sort_values(ascending=False).head(10).plot.bar()\nplt.title(\"Country by Mean of Goal real amount\")","b34d3c17":"plt.figure(figsize=(10,5))\ndf.groupby(['country'])['usd pledged'].mean().sort_values(ascending=False).head(10).plot(kind='bar',color = 'g',grid='yes')\nplt.title(\"Country by Mean of Pledged amount\")","9bb6008c":"plt.figure(figsize=(10,5))\nsns.set(style=\"darkgrid\")\ndf.groupby('country').usd_pledged_real.mean().sort_values(ascending=False).head(10).plot.bar(color = 'c')\nplt.title(\"Country by Mean of Pledged real amount \")","f9599637":"plt.figure(figsize=(10,20))\nsns.set(style=\"darkgrid\")\nsns.catplot(x='main_category', hue='state', kind='count', data=df.sort_values('main_category'));\nplt.xticks(rotation = 90)\nplt.title(\"Main Category by project Count and Status\")\nplt.show()","e3b00097":"#convert string or float values to 0 .. n classes.\nlab_enc = preprocessing.LabelEncoder() \ndf.main_category = lab_enc.fit_transform(df.main_category)\ndf.country = lab_enc.fit_transform(df.country)\ndf.category = lab_enc.fit_transform(df.category)\ndf['deadline(d)']= lab_enc.fit_transform(df['deadline(d)'])\ndf['launched(d)']= lab_enc.fit_transform(df['launched(d)'])","51d9e099":"#sns.pairplot(df, hue=\"state\"); #Comment it out as its taking too long to generate","9beeed7e":"#converting string values to 0 .. n classes.\ndf.state = lab_enc.fit_transform(df.state)","4cea508d":"#Box plot to visualize Outliers\nfig, axs = plt.subplots(ncols=5, nrows=3, figsize=(20, 10))\nindex = 0\naxs = axs.flatten()\nfor k,v in df.items():\n    sns.boxplot(y=k, data=df, ax=axs[index])\n    index += 1\nplt.tight_layout(pad=1.4, w_pad=0.2, h_pad=5.0)","dd83cde0":"#Finding percentage of Outliers \nfor k, v in df.items():\n    if (v.dtype != object):\n        q1 = v.quantile(0.25)\n        q3 = v.quantile(0.75)\n        irq = q3 - q1\n        v_col = v[(v <= q1 - 1.5 * irq) | (v >= q3 + 1.5 * irq)]\n        perc = np.shape(v_col)[0] * 100.0 \/ np.shape(df)[0]\n        print(\"Column %s outliers = %.2f%%\" % (k, perc))","081fe541":"df.describe()","fb2fd8f9":"df = df[~(df['duration(days)'] >= 91.0)]\ndf = df[~(df['usd pledged'] >= 1.397310e+06)]\ndf = df[~(df['usd_pledged_real'] >= 5.004495e+06)]\ndf = df[~(df['usd_goal_real'] >= 1.000000e+08)]","472d0f56":"df.shape","453764ed":"#Correlation Table\ndf.corr()","7323f0a0":"# Correlation Heatmap \nplt.subplots (figsize = (16,9))\nsns.heatmap (df.corr(), square = True, cbar = True, annot = True, annot_kws = {'size': 10}, fmt = '0.2f',linewidths=.5)","7401ec02":"df_y = df['state']\ndf_x = df.drop(columns = ['state','backers','deadline(y)','deadline(m)'], axis = 1)","3eb7c2ea":"print(df_x.shape)\ndf_x.head()","99113feb":"# prepare models\nmodels = []\n#models.append(('LR', LogisticRegression()))\nmodels.append(('RF', RandomForestClassifier()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('DT', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\n#models.append(('SVM', SVC())) #taking too long to return result","0de1c6f5":"# Evaluate each model \n# evaluate each model in turn\nresults = []\nnames = []\nscoring = 'accuracy'\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10)\n    cv_results = model_selection.cross_val_score(model, df_x, df_y, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","2429eeb0":"fig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","c15abee6":"# Evaluate each model \n# evaluate each model in turn\nModels = [\n    #Ensemble Methods\n    RandomForestClassifier(),\n    \n    #GLM\n    #LogisticRegressionCV(),\n    #Navies Bayes\n    GaussianNB(),\n\n    #Nearest Neighbor\n    KNeighborsClassifier(),\n\n    #Trees    \n    DecisionTreeClassifier()\n    \n    ]","6df389cc":"x_train, x_test, y_train, y_test = train_test_split(df_x,df_y,test_size=.25,random_state=1)","6eb38394":"Model_columns = []\nModel_compare = pd.DataFrame(columns = Model_columns)\nrow_index = 0\nfor model in Models:   \n    \n    predicted = model.fit(x_train, y_train).predict(x_test)\n    fp, tp, th = roc_curve(y_test, predicted)\n    Model_name = model.__class__.__name__\n    Model_compare.loc[row_index,'Model Name'] = Model_name\n    Model_compare.loc[row_index, 'Model Train Accuracy'] = round(model.score(x_train, y_train), 4)\n    Model_compare.loc[row_index, 'Model Test Accuracy'] = round(model.score(x_test, y_test), 4)\n    Model_compare.loc[row_index, 'Model Precission'] = precision_score(y_test, predicted)\n    Model_compare.loc[row_index, 'Model Recall'] = recall_score(y_test, predicted)\n    Model_compare.loc[row_index, 'Model AUC'] = auc(fp, tp)\n\n    row_index+=1\n    \nModel_compare.sort_values(by = ['Model Test Accuracy'], ascending = False, inplace = True)    \nModel_compare\n","e382a77f":"plt.subplots(figsize=(15,6))\nsns.barplot(x=\"Model Name\", y=\"Model Train Accuracy\",data=Model_compare,palette='Set3',edgecolor=sns.color_palette('dark',1))\nplt.xticks(rotation=90)\nplt.title('Model Train Accuracy Comparison')\nplt.show()","90b28474":"#Divding the dataset to training and testing.  current test size .25\nX_train,X_test, y_train, y_test = train_test_split(df_x,df_y,test_size=.25,random_state=1)","7b9c4ad4":"#Modeling with default parameters\ndt_model = DecisionTreeClassifier()\n#Fitting the Model\ndt_model.fit(X_train, y_train)","8503a066":"# Predictions using the testing set\ny_pred = dt_model.predict(X_test)","974d71c2":"#Evaluating the model using the Confusion Matrix\nprint(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\nprint(\"Accuracy Score: \",accuracy_score(y_test, y_pred))  ","607b2c5c":"# plot confusion matrix\ncm = confusion_matrix(y_test, y_pred)\ndf_cm = pd.DataFrame(cm, range(2),range(2))\nlabels = [i for i in df_cm.columns]\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16},fmt = 'd',xticklabels=labels,yticklabels=labels,cmap=plt.cm.Blues)\nplt.xlabel(\"PREDICTED\")\nplt.ylabel(\"ACTUAL\")\nplt.title(\"Confusion Matrix\")","3f2a41a8":"print(\"Classification Report: \\n\",classification_report(y_test, y_pred)) ","6dc14eb6":"#training_scores_encoded = lab_enc.fit_transform(y_train)\nmodel_dt = dt_model.fit(X_train, y_train)","bca6855b":"pred_dt = dt_model.predict(X_test)  ","f0c76b5f":"seconds = time.time()\nparameters = { \"criterion\"         : [\"gini\", \"entropy\"],\n               \"max_features\"      : ['sqrt','log2',0.2,0.5,0.8]}\n               \nStart = time.time()\nmodel = GridSearchCV(dt_model, parameters, cv=10)\nmodel.fit(X_train, y_train)","8f69d98b":"print(\"Best Parameters:\",model.best_params_)\ntime_taken = time.time()-Start","ffe5da64":"print(\"Time taken to tune Parameters\",time_taken)","b39268cf":"X_train, X_test, y_train, y_test = train_test_split(df_x, np.array(df_y), test_size=0.3, random_state=4)","84aba717":"dt = DecisionTreeClassifier(criterion = 'entropy', max_features = 0.8) \nModel_dt = dt.fit(X_train, y_train)","8e8b3108":"pred_dt = dt.predict(X_test)  ","dce03381":"#Evaluating the model using the Confusion Matrix\nprint(\"Confusion Matrix: \\n\", confusion_matrix(y_test, pred_dt))\nprint(\"Accuracy Score: \",accuracy_score(y_test, pred_dt))","6c6eb602":"# plot confusion matrix\ncm = confusion_matrix(y_test, pred_dt)\ndf_cm = pd.DataFrame(cm, range(2),range(2))\nlabels = [i for i in df_cm.columns]\nplt.grid(b=None)\nsns.set(font_scale=1.5)\nsns.heatmap(df_cm,center = 0, annot=True,fmt=\"d\",cmap=plt.cm.Blues,xticklabels=labels,yticklabels=labels)\nplt.xlabel(\"PREDICTED\")\nplt.ylabel(\"ACTUAL\")\nplt.title(\"Confusion matrix\")\nplt.show()","e21cacf8":"print(\"Classification Report: \\n\",classification_report(y_test, pred_dt)) ","ffe7c6d1":"average_precision = average_precision_score(y_test, pred_dt)\ndisp = plot_precision_recall_curve(dt, X_test, y_test)\ndisp.ax_.set_title('2-class Precision-Recall curve: '\n                   'AP={0:0.4f}'.format(average_precision))\n","663e3809":"feature_importances = pd.DataFrame(Model_dt.feature_importances_, index = X_train.columns, columns= ['Importance']).sort_values('Importance', ascending = False)\nfeature_importances","dea3c824":"def run_kfold(dt,df_x):\n    kf = KFold(n_splits=10)\n    outcomes = []\n    fold = 0\n    \n    for train_index, test_index in kf.split(df_x):\n        fold += 1\n        X_train, X_test = df_x.values[train_index], df_x.values[test_index]\n        y_train, y_test = df_y.values[train_index], df_y.values[test_index]\n        dt.fit(X_train, y_train)\n        predictions = dt.predict(X_test)\n        accuracy = accuracy_score(y_test, predictions)\n        outcomes.append(accuracy)\n        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))     \n    mean_outcome = np.mean(outcomes)\n    print(\"Mean Accuracy: {0}\".format(mean_outcome))\n    std_outcome = np.std(outcomes)\n    print(\"Std Accuracy: {0}\".format(std_outcome))\n\n    \nrun_kfold(Model_dt,df_x)","2275b9c4":"### Kickstarting campaigns from US and France trends to receive high Pledged Amount","d18b7169":"## Confusion Matrix and Accuracy Score","46fc807d":"#### USD Pledged seems to have null and filling it with zeros.","39917076":"# 5. Initial Data Cleaning and feature selection","8950bbe8":"## Parsing deadline and lauched date and removing those two","11297e2c":"## Classification Report","20ee188e":"# 8. Outliers and Feature Selection","6122d94d":"## Feature Selection and dividing dataset to Data and Target ","f3ce81fb":"## Plotting Main category by Total number of projects","c031665d":"   ### Most of the campaigns were from Film & Video and Music","986c4b1a":"## Using Kfold","005983f7":"## Plotting top 10 countries by Mean of pledged real amount","f2dce730":"## Below feature seems to have higher correlation with other features.  Hence removing them in next feature selection section\n\n1. Backer\n2. Deadline(y)\n3. Deadline(m)\n4. Main Category","2f70c5ab":"## Result of Modl Validation using KFOLD\n\n  ### Mean Accuracy of 0.9991493355129718 is returned which shows that the Modelling using Decision Tree was the best option\n    ","c1cbce21":"\n# Precision-Recall\n--------------------------------------\n## The relationship between recall and precision can be observed in the stairstep area of the plot - at the edges of these steps a small change in the threshold considerably reduces precision, with only a minor gain in recall.","fddd071d":"### Top category seems to be Product Design Campaign ","49da3302":"## Removing outliers from below features \n\n1. Duration in days\n2. Pledged amount in USD\n3. Goal amount in USD\n4. Pledged real amount in USD","54060afc":" ##### The goal amount of funding for each project is currently recorded in native currencies. \n ##### We will be using usd_goal_real which is the converted column\n ##### Dropping Currency and ID columns that are not useful. ","3bc75788":"# No significant change from the results before using the hyper-parameters. However, optimization is always nessecary.  \n## F1 for Successful projects are still 1 and 0.97 for failed projects\n---------------------------------------------------------------","7a2f19a6":"## Boxplot algorithm comparison","d397b873":"## Overall yes, it was right decision to choose Decision tree modeling. \n\n## Did the study answer the initial project goal I set?  I would say yes.  See below for detailed information\n\n-  Is Kickstarter a good funding option for your project? \n           Yes, if your project meets below important feature criteria\n-  What are your chances of success?  \n           Chances of success is also completely dependent on the important feature criterias we found\n   \n     ### Higher number of backers has a big impact on success of the project.   \n     ### Intesesting important features for higher success rate are \n      #### - usd_pledged_real \t\n      #### - usd_goal_real \t\n      #### - usd pledged\n      #### - launched(y)\n      #### - category \n   \n  ","fe1f05e1":"# 11. Feature Importance","dbc38b01":"### Pair plot by Status","2192ba9d":"# 9. Model Selection","8bef8bf7":"## Plotting Number of kickstarter project campaigns in each year\n","e1361507":"# 7. Preprocessing all the needed features","b98e818f":"## Dropping projects which are not successes or failures","6e9df100":"# 4. Obtaining and understanding the data","838f4970":"## Plotting Model Train Accuracy Comparison","9739a099":"## Classification Report","a6bc50c8":"## Best F1-Score of 1 is returned for successful Kickstarters and 0.97  is returned for failed Kickstarters ","4dd8af0f":"## Plotting Top 10 Categories by Number of projects; Listing top 10 category","ab0a5354":"## Plotting Mean of Pledged real amount Vs mean of Goal in USD grouped by country \n","2f2a52ec":"Import Packages","d63f0991":"### Year 2014 and 2015 had a lot of campaigns compared to rest of the years","ee900b7a":"# 10. Modeling using Decision Tree","d5cfc0cf":"# Table of contents\n\n1. Introduction\n2. Project Aim\n3. Data source and Dataset\n4. Obtaining and understanding the data\n5. Initial Data Cleaning and feature selection\n6. Visual analysis\n7. Preprocessing all the needed features\n8. Outliers and Feature Selection\n9. Model Selection\n10. Modeling using Decision Tree\n11. Feature Importance\n12. Model Validation\n13. Conclusions and recommendations\n\n","59d59bfb":"## Plotting pledged amount in USD and Real Goal amount in USD to show their relationship. ","4add4c6e":"### Kickstarting campaigns from China seems to be setting very high goal account compared to campaigns from rest of the countries","648072ef":"### Most failed campaign are from main category Film and Video\n### Most Successfull campaigns are from main category Music ","5f10f477":"# 12. Model validation using KFold","6566d473":"# 1. Introduction\n\n#### What is Kickstarter & How does it work?\n__[Kickstarter](https:\/\/www.kickstarter.com\/)__ is an American public benefit corporation based in Brooklyn, New York, that maintains a global crowdfunding platform focused on creativity. The company's stated mission is to \"help bring creative projects to life\".  Everything from film, games, and music to art, design, and technology. Kickstarter is full of ambitious, innovative, and imaginative projects that are brought to life through the direct support of others.\nEvery project creator sets their project's funding goal and deadline. If people like the project, they can pledge money to make it happen. If the project succeeds in reaching its funding goal, all backers' credit cards are charged when time expires. Funding on Kickstarter is all-or-nothing. If the project falls short of its funding goal, no one is charged.\nIf a project is successfully funded, Kickstarter applies a 5% fee to the funds collected.\n\n# 2. Project Aim\n\n   -  Is Kickstarter a good funding option for your project?\n   -  What are your chances of success?\n\n# 3. Data source and Dataset\n\n    The dataset used in this project was downloaded in .csv format from Kaggle. The dataset contains data all the projects from the day company launch date to 01\/01\/2018. In this work effort I have filtered out all the project that are not in either failed or successful status as wells as those are prior to 2010.   \n    \n     15 initial features:\n\n        ID: internal kickstarter id\n        name: name of project - A project is a finite work with a clear goal that you\u2019d like to bring to life. Think albums, books, or films.\n        category: category\n        main_category: category of campaign\n        currency: currency used to support\n        deadline: deadline for crowdfunding\n        goal: fundraising goal - The funding goal is the amount of money that a creator needs to complete their project.\n        launched: date launched\n        pledged: amount pledged by \"crowd\"\n        state: Current condition the project is in\n        backers: number of backers\n        country: country pledged from\n        usd pledged: Pledged amount in USD (conversion made by KS)\n        usd_pledged_real: Pledged amount in USD (conversion made by fixer.io api) \n        usd_goal_real: Goal amount in USD (conversion made by fixer.io api)","a350b709":"# 6. Visual analysis","51ec1ccd":"## Model Selection using Hold Out validation - 75\/25 Training and Testing set","80e3be75":"## Plotting top 10 countries by mean of goal amount to show which countries set high goals ","98ab52ec":"    \n## Decided to go ahead with DT as it seems to be the best option","271f111c":"## Plotting number of successfull and unsuccessful campigns by main category ","dc616791":"### Confusion Matrix and Accuracy Score","a18c7ec7":"# 13. Conclusion\n\n","98aff43d":"# Tuning the parameters or Hyperparameter Optimization the using Grid Search.","830f0bf0":"### Kickstarting campaigns from Hong Kong,China and Austria trends to receive high Pledged Real Amount","65cefb6a":"## Plotting top 10 country by mean pledged amount to show which counties supports kickstarters\n","0e5686f6":"## Modeling with optimized parameters\n ### Using Entropy as Criterion and 0.80 as max_features"}}