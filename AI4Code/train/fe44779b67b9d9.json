{"cell_type":{"80c0bd05":"code","975f1396":"code","b5953a98":"code","19de57ea":"code","2eed6f48":"code","9ace88ed":"code","c2db79e4":"code","7bb52d34":"code","dac4acd7":"code","9adb77ff":"code","83ab59b7":"code","89daa18c":"code","35fe9568":"code","36d52c1a":"code","d58a6aaf":"code","e6830f1c":"code","efaf6e14":"code","356df182":"code","5164bc31":"code","e8d3d4da":"code","3f9e6991":"code","6dfa62e6":"code","989a25a7":"code","3ff5f320":"code","a4a7eaa7":"code","a9b2a72e":"code","0d206022":"code","83868d5e":"code","707b52c6":"code","c2693867":"code","99537236":"code","cacae4c7":"markdown","4417108a":"markdown","4f939dd9":"markdown","5a6e9dd3":"markdown","31097928":"markdown","3e7285ef":"markdown","4014472f":"markdown","e18292d5":"markdown","72e239fb":"markdown","2406a9b9":"markdown"},"source":{"80c0bd05":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","975f1396":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pprint","b5953a98":"data=pd.read_csv('\/kaggle\/input\/data-analyst-jobs\/DataAnalyst.csv')","19de57ea":"print(data.shape)\nprint(data.columns)","2eed6f48":"data.head()","9ace88ed":"data.drop(['Unnamed: 0','Competitors','Easy Apply'],axis=1,inplace=True)","c2db79e4":"pd.set_option('max_colwidth',200)","7bb52d34":"data['Company Name']=data['Company Name'].str.split('\\n',expand=True)[0]","dac4acd7":"job_title_str=' '.join([x for x in data['Job Title']])","9adb77ff":"import nltk\ntokens = nltk.word_tokenize(job_title_str)\ntokens=[x.lower() for x in tokens]","83ab59b7":"from nltk.probability import FreqDist\nfdist = FreqDist(tokens)\ntops=fdist.most_common(100)\n\n# drop single word or symbol\ndelarr=[]\nfor key in fdist:\n    if len(key)<2:\n        delarr.append(key)\nfor key in delarr:\n    del fdist[key]\n    \ntops=fdist.most_common(100)\npprint.pprint(tops)","89daa18c":"import re\npat_lead=re.compile(r'lead|principal|iii|iv',re.I)\npat_sr=re.compile(r'senior|sr.|sr|ii',re.I)\npat_jr=re.compile(r'junior|jr|jr.|entry|i',re.I)","35fe9568":"def job_title(row):\n    if re.match(pat_lead,row['Job Title']):\n        return 'Lead'\n    if re.match(pat_sr,row['Job Title']):\n        return 'Senior'\n    if re.match(pat_jr,row['Job Title']):\n        return 'Junior'\n    \ndata['Job Level']=data.apply(job_title,axis=1)","36d52c1a":"pat=re.compile(r'\\d+')\nsal_df=(data['Salary Estimate'].str.findall(pat)).apply(pd.Series)\nsal_df.columns=['sal_low','sal_up']\ndata=pd.concat([data,sal_df],axis=1)","d58a6aaf":"data[['sal_low','sal_up']]=data[['sal_low','sal_up']].fillna(0)","e6830f1c":"data['sal_low']=data['sal_low'].astype('int')\ndata['sal_up']=data['sal_up'].astype('int')\ndata['sal_mean']=(data['sal_low']+data['sal_up'])\/2","efaf6e14":"def job_type(row):\n    if row['Job Title'].find('Business')!=-1:\n        return 'Business'\n    if row['Job Title'].find('Healthcare')!=-1:\n        return 'healthcare'\n    if row['Job Title'].find('quality')!=-1:\n        return 'quality'\n    if row['Job Title'].find('Reporting')!=-1:\n        return 'reporting'\n    if row['Job Title'].find('Financial')!=-1:\n        return 'financial'\n    if row['Job Title'].find('Security')!=-1:\n        return 'security'\n    if row['Job Title'].find('Product')!=-1:\n        return 'product'\n    if row['Job Title'].find('Marketing')!=-1:\n        return 'marketing'","356df182":"data['Job Type']=data.apply(job_type,axis=1)","5164bc31":"job_des_str=' '.join([x for x in data['Job Description']])\ntokens = nltk.word_tokenize(job_des_str)\nstopwords = nltk.corpus.stopwords.words('english')\n\n\nfiltered_words_1 = [w.lower() for w in tokens if not w in stopwords]\nfiltered_words_2 = [w for w in filtered_words_1 if re.match(r'\\w',w)]\nfdist = FreqDist(filtered_words_2)\ntops=fdist.most_common(100)\npprint.pprint(tops)","e8d3d4da":"pat_p_r=re.compile(r'python| R ',re.I)\npat_tab=re.compile(r'powerbi|tableau',re.I)\npat_vis=re.compile(r'visualization',re.I)\npat_c=re.compile(r' C |C#')\npat_exc=re.compile(r'excel',re.I)\npat_sql=re.compile(r'sql|mysql|database',re.I)\npat_had=re.compile(r'hadoop|hive|spark',re.I)\npat_stat=re.compile(r'statistics|statistical',re.I)\npat_code=re.compile(r'coding|programming',re.I)","3f9e6991":"def job_skill(row):\n    if re.search(pat_p_r,row['Job Description']):\n        return 'Python\/R'\n    if re.search(pat_tab,row['Job Description']):\n        return 'PowerBi\/Tableau'\n    if re.search(pat_vis,row['Job Description']):\n        return 'Visualization'\n    if re.search(pat_c,row['Job Description']):\n        return 'C\/C#'\n    if re.search(pat_sql,row['Job Description']):\n        return 'SQL\/MySQL'\n    if re.search(pat_had,row['Job Description']):\n        return 'Hadoop\/Hive\/Spark'\n    if re.search(pat_stat,row['Job Description']):\n        return 'Statistics'\n    if re.search(pat_code,row['Job Description']):\n        return 'Coding'\n    return None\n    \ndata['Job Skill']=data.apply(job_skill,axis=1)","6dfa62e6":"cities=data.Location.value_counts().head(10).index\nplt.figure(figsize=(12,6))\nsns.countplot(data[data.Location.isin(cities)]['Location'],order=cities,color='deepskyblue')\nax=plt.gca()\nax.tick_params(labelsize=10,rotation=45,axis='x') \nax.spines['top'].set_color('none')\nax.spines['left'].set_color('none')\nax.spines['right'].set_color('none')\nax.set_xlabel('Location',fontsize=20)\nax2 = ax.twinx() \n\nax2.spines['top'].set_color('none')\nax2.spines['right'].set_color('none')\nax2.spines['left'].set_color('none')\n\nax.set_ylabel('Analyst Demand',fontsize=20)\nsns.lineplot(data=data[data.Location.isin(cities)],x='Location',y='sal_mean',ax=ax2)\nax2.set_ylabel('Mean Salary (k)',fontsize=20)\nplt.title('Location VS Demand VS Salary',fontsize=20)\nplt.show()","989a25a7":"plt.figure(figsize=(12,8))\nsns.boxplot(data=data,x='Job Level',y='sal_mean',order=['Junior','Senior','Lead'],palette='Blues')\nax=plt.gca()\nax.spines['top'].set_color('none')\nax.spines['left'].set_color('none')\nax.spines['right'].set_color('none')\nax.set_ylabel('Mean Salary (k)',fontsize=25)\nax.set_xlabel('Job Level',fontsize=25)\nax.tick_params(labelsize=15) \nplt.title('Job Level VS Salary',fontsize=30)\nplt.show()","3ff5f320":"data['Company Name'].value_counts().head(10).to_frame().style.set_caption('Most Demand Company').background_gradient(cmap='Blues')","a4a7eaa7":"data.groupby('Company Name')['sal_mean'].mean().sort_values(ascending=False).head(20).to_frame().style.set_caption('Highest Mean Salary Company')","a9b2a72e":"plt.figure(figsize=(12,8))\nsns.boxplot(data=data,x='Job Type',y='sal_mean',palette='Blues')\nax=plt.gca()\nax.spines['top'].set_color('none')\nax.spines['left'].set_color('none')\nax.spines['right'].set_color('none')\nax.set_ylabel('Mean Salary (k)',fontsize=25)\nax.set_xlabel('Job Type',fontsize=25)\nax.tick_params(labelsize=15) \nplt.title('Job Type VS Salary',fontsize=30)\nplt.show()","0d206022":"plt.figure(figsize=(12,8))\nsns.heatmap(data[data.Location.isin(cities)].groupby(by=['Location','Job Type'])['sal_mean'].mean().unstack().fillna(0),cmap='Blues',annot=True)\nax=plt.gca()\nax.set_ylabel('Location',fontsize=25)\nax.set_xlabel('Job Type',fontsize=25)\nax.tick_params(labelsize=15,rotation=45) \nplt.title('Location VS Job Type VS Salary',fontsize=30)\nplt.show()","83868d5e":"plt.figure(figsize=(12,8))\nsns.boxplot(data=data,x='Job Skill',y='sal_mean',palette='Blues')\nax=plt.gca()\nax.spines['top'].set_color('none')\nax.spines['left'].set_color('none')\nax.spines['right'].set_color('none')\nax.set_ylabel('Mean Salary (k)',fontsize=25)\nax.set_xlabel('Job Skill',fontsize=25)\nax.tick_params(labelsize=15,rotation=45) \nplt.title('Job Skill VS Salary',fontsize=30)\nplt.show()","707b52c6":"plt.figure(figsize=(12,8))\nsns.heatmap(data.groupby(by=['Job Skill','Job Type'])['sal_mean'].mean().unstack().fillna(0),cmap='Blues',annot=True)\nax=plt.gca()\nax.set_ylabel('Job Skill',fontsize=25)\nax.set_xlabel('Job Type',fontsize=25)\nax.tick_params(labelsize=15,rotation=45) \nplt.title('Job Skill VS Job Type VS Salary',fontsize=30,pad=20)\nplt.show()","c2693867":"lists=['r','python','sql','database','powerbi','tableau','visualization',\n       'C','C#','excel','mysql','hadoop','hive','sparl','statistics','etl'\n       ,'a\/b','sas','bi','algorithm','ai','deep learning','machine learning']","99537236":"import wordcloud\nd_tmp = dict((key, value) for key, value in fdist.items() if key in lists)\nw=wordcloud.WordCloud(background_color='White',scale=4)\nfig = plt.figure(figsize=(12, 8))\nw.generate_from_frequencies(d_tmp)\nplt.axis('off')\nplt.imshow(w)","cacae4c7":"# 2. FEATURE ENGINEERING\n\n**what we know**\n1. some information are buried in columns like Job Title\/Job Description.\n2. Company Name need to be fixed.\n3. Salary Estimate need to be transformed so that we can calculate.\n\n**what we do**\n1. we fixed company name.\n2. we use NLP\/RegEX to extract information from Job Title\/Job description.\n3. we transform salary estimate to numbers.","4417108a":"## TRANSFORM SALARY COLUMN","4f939dd9":"## Skill Word cloud","5a6e9dd3":"### What we will do in this notebook\n- Data cleaning \/ basic data manipulation\n- Extract useful information from text and paragraphs using Regex\/NLP\n- EDA & Visualization on Salary VS Other factors,like City\/skill\/excperience\n\n### This notebook is stil under construction.\n### Feel free to <font color=deepskyblue> FORK  <\/font> this notebook, Please  <font color=deepskyblue> UPVOTE !! <\/font> if it's helpful to you  <font color=deepskyblue> : ) <\/font>","31097928":"## EXTRACT TITLE\n\nAfter analysing Job title field using NLTK, We can find the most common used term for Job level is as follows:\n1. lead | principal | iii | iv\n2. senior | sr. | sr | ii\n3. junior | jr | jr. | entry | i\n\nWe use Regular expression(RegEx) to combine those different level into 3 categories: Lead Senior Junior.\n\n\n**Tips**: In HR's system,the number after a job title often refers to the level of that job.For instance, Data Analyst III means a principal analyst,while  Data Analyst I means entry level, which sometimes varies from company to company.\n\n**ABOUT NLP**\n\n[Natural language processing (NLP)](https:\/\/en.wikipedia.org\/wiki\/Natural_language_processing) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\n\n**ABOUT NLTK LIBRARY**\n\n[NLTK](http:\/\/www.nltk.org\/) is a leading platform for building Python programs to work with human language data.\n\n**ABOUT REGEX**\n\nA regular expression (shortened as [regex](https:\/\/en.wikipedia.org\/wiki\/Regular_expression) or regexp also referred to as rational expression) is a sequence of characters that define a search pattern. ","3e7285ef":"![](https:\/\/i1.wp.com\/thedatascientist.com\/wp-content\/uploads\/2019\/06\/what-is-data-science.jpg)","4014472f":"# 3. VISUALIZATION\/EDA\n\n**What we know**\n1. TX has the highest demand for data analyst.\n2. CA has the highest mean salary,but its demand is pretty low.","e18292d5":"## EXTRACT JOB TYPE\n\nWe do the same thing here to extract the job type.","72e239fb":"## EXTRACT JOB SKILLS\n\nsame process here for the job skill.","2406a9b9":"# 1. KNOW YOUR DATA\n\nWe take a look at the data, and try to do some basic cleaning in this step.\n\n**what we know**\n1. we have 2253 entries and 16 features or columns.\n2. all of the features are strings.\n3. some columns need to be dropped.\n\n**what we do**\n1. we drop column Unnamed:0\n2. we drop columns Competitors\/easy apply since they are inreleven to our analysis."}}