{"cell_type":{"e2cb9a8b":"code","8b525a41":"code","a9020685":"code","e88d6f17":"code","2c85b206":"code","70665f1e":"code","e6582e82":"code","9acbdf77":"code","96711a41":"code","97532b87":"code","ec141533":"code","3e4d4ed4":"code","1df89b36":"code","c965f05a":"code","ac669c24":"code","2789ad97":"code","1773e8e8":"code","ab026ee6":"code","724e2b57":"code","787c0ab0":"code","9cfb70b3":"code","1376a809":"code","2dd716b5":"code","745a02c9":"code","cc147bd6":"code","ed4bb6e0":"code","3d956fb1":"code","11e0be6e":"code","b6fe89e5":"code","d4a07ded":"code","a02bd9db":"code","41d53f1c":"code","171687d1":"code","921078cb":"code","35a55198":"code","c66b4375":"code","9be7a96c":"code","f39aa71a":"code","fc6b6702":"code","ffd416dc":"code","f3697ad8":"code","98665e27":"markdown","477c281d":"markdown","7d18b5ea":"markdown","1d364c5b":"markdown","d19c436e":"markdown","5c1e3ddc":"markdown","750faae6":"markdown","7b90c27d":"markdown","656c1307":"markdown","6105bc51":"markdown","ddea0c2b":"markdown","a8f6b43e":"markdown"},"source":{"e2cb9a8b":"import riiideducation\n# import dask.dataframe as dd\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nenv = riiideducation.make_env()","8b525a41":"train = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/train.csv',\n                   usecols=[1, 2, 3, 4, 7, 8, 9],\n                   dtype={'timestamp': 'int64',\n                          'user_id': 'int32',\n                          'content_id': 'int16',\n                          'content_type_id': 'int8',\n                          'answered_correctly':'int8',\n                          'prior_question_elapsed_time': 'float32',\n                          'prior_question_had_explanation': 'boolean'}\n                   )","a9020685":"#removing True or 1 for content_type_id\n\ntrain = train[train.content_type_id == False]\n\n#arrange by timestamp\n\ntrain = train.sort_values(['timestamp'], ascending=True).reset_index(drop = True)\n\ntrain.head(10)","e88d6f17":"#getting final results ready for later, so we can clear memory\nresults_c_final = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\nresults_c_final.columns = [\"answered_correctly_content\"]\n\nresults_u_final = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum', 'count'])\nresults_u_final.columns = ['answered_correctly_user', 'sum', 'count']","2c85b206":"#saving value to fillna\nelapsed_mean = train.prior_question_elapsed_time.mean()","70665f1e":"train.loc[(train.timestamp == 0)].answered_correctly.mean()","e6582e82":"train.loc[(train.timestamp != 0)].answered_correctly.mean()","9acbdf77":"train.loc[(train.timestamp < 1000000) & (train.timestamp > 0)].answered_correctly.mean()","96711a41":"train.prior_question_had_explanation.value_counts()","97532b87":"train.answered_correctly.mean()","ec141533":"train.drop(['timestamp', 'content_type_id'], axis=1, inplace=True)","3e4d4ed4":"validation = pd.DataFrame()","1df89b36":"for i in range(4):\n    last_records = train.drop_duplicates('user_id', keep = 'last')\n    train = train[~train.index.isin(last_records.index)]\n    validation = validation.append(last_records)","c965f05a":"len(train)","ac669c24":"len(validation)","2789ad97":"validation.answered_correctly.mean()","1773e8e8":"train.answered_correctly.mean()","ab026ee6":"X = pd.DataFrame()","724e2b57":"for i in range(15):\n    last_records = train.drop_duplicates('user_id', keep = 'last')\n    train = train[~train.index.isin(last_records.index)]\n    X = X.append(last_records)","787c0ab0":"len(X)","9cfb70b3":"len(train)","1376a809":"X.answered_correctly.mean()","2dd716b5":"train.answered_correctly.mean()","745a02c9":"results_c = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\nresults_c.columns = [\"answered_correctly_content\"]\n\nresults_u = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum', 'count'])\nresults_u.columns = [\"answered_correctly_user\", 'sum', 'count']","cc147bd6":"#clearing memory\ndel(train)\n","ed4bb6e0":"X = pd.merge(X, results_u, on=['user_id'], how=\"left\")\nX = pd.merge(X, results_c_final, on=['content_id'], how=\"left\")","3d956fb1":"validation = pd.merge(validation, results_u, on=['user_id'], how=\"left\")\nvalidation = pd.merge(validation, results_c_final, on=['content_id'], how=\"left\")","11e0be6e":"from sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\n\nX.prior_question_had_explanation.fillna(False, inplace = True)\nvalidation.prior_question_had_explanation.fillna(False, inplace = True)\n\nvalidation[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(validation[\"prior_question_had_explanation\"])\nX[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(X[\"prior_question_had_explanation\"])\nX.head()","b6fe89e5":"#reading in question df\nquestions_df = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/questions.csv',\n                            usecols=[0, 3],\n                            dtype={'question_id': 'int16',\n                              'part': 'int8'}\n                          )","d4a07ded":"X = pd.merge(X, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')\nvalidation = pd.merge(validation, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')\nX.part = X.part - 1\nvalidation.part = validation.part - 1\n\nX.part.value_counts()","a02bd9db":"y = X['answered_correctly']\nX = X.drop(['answered_correctly'], axis=1)\nX.head()\n\ny_val = validation['answered_correctly']\nX_val = validation.drop(['answered_correctly'], axis=1)","41d53f1c":"X = X[['answered_correctly_user', 'answered_correctly_content', 'sum', 'count',\n       'prior_question_elapsed_time','prior_question_had_explanation_enc', 'part']]\nX_val = X_val[['answered_correctly_user', 'answered_correctly_content', 'sum', 'count',\n       'prior_question_elapsed_time','prior_question_had_explanation_enc', 'part']]","171687d1":"\n# Filling with 0.5 for simplicity; there could likely be a better value\nX['answered_correctly_user'].fillna(0.5,  inplace=True)\nX['answered_correctly_content'].fillna(0.5,  inplace=True)\n\nX['part'].fillna(4, inplace = True)\nX['sum'].fillna(0, inplace = True)\nX['count'].fillna(0, inplace = True)\nX['prior_question_elapsed_time'].fillna(elapsed_mean, inplace = True)\nX['prior_question_had_explanation_enc'].fillna(0, inplace = True)\n","921078cb":"# Filling with 0.5 for simplicity; there could likely be a better value\nX_val['answered_correctly_user'].fillna(0.5,  inplace=True)\nX_val['answered_correctly_content'].fillna(0.5,  inplace=True)\n\nX_val['part'].fillna(4, inplace = True)\nX_val['count'].fillna(0, inplace = True)\nX_val['sum'].fillna(0, inplace = True)\nX_val['prior_question_elapsed_time'].fillna(elapsed_mean, inplace = True)\nX_val['prior_question_had_explanation_enc'].fillna(0, inplace = True)","35a55198":"import lightgbm as lgb\n\nparams = {\n    'objective': 'binary',\n    'max_bin': 700,\n    'learning_rate': 0.0175,\n    'num_leaves': 80\n}\n\nlgb_train = lgb.Dataset(X, y, categorical_feature = ['part', 'prior_question_had_explanation_enc'])\nlgb_eval = lgb.Dataset(X_val, y_val, categorical_feature = ['part', 'prior_question_had_explanation_enc'], reference=lgb_train)","c66b4375":"model = lgb.train(\n    params, lgb_train,\n    valid_sets=[lgb_train, lgb_eval],\n    verbose_eval=50,\n    num_boost_round=10000,\n    early_stopping_rounds=12\n)","9be7a96c":"y_pred = model.predict(X_val)\ny_true = np.array(y_val)\nroc_auc_score(y_true, y_pred)","f39aa71a":"import matplotlib.pyplot as plt\nimport seaborn as sns","fc6b6702":"#displaying the most important features\nlgb.plot_importance(model)\nplt.show()","ffd416dc":"iter_test = env.iter_test()","f3697ad8":"for (test_df, sample_prediction_df) in iter_test:\n    test_df = pd.merge(test_df, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')\n    test_df = pd.merge(test_df, results_u_final, on=['user_id'],  how=\"left\")\n    test_df = pd.merge(test_df, results_c_final, on=['content_id'],  how=\"left\")\n    test_df['answered_correctly_user'].fillna(0.5,  inplace=True)\n    test_df['answered_correctly_content'].fillna(0.5,  inplace=True)\n    test_df['part'] = test_df.part - 1\n\n    test_df['part'].fillna(4, inplace = True)\n    test_df['sum'].fillna(0, inplace=True)\n    test_df['count'].fillna(0, inplace=True)\n    test_df['prior_question_elapsed_time'].fillna(elapsed_mean, inplace = True)\n    test_df['prior_question_had_explanation'].fillna(False, inplace=True)\n    test_df[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(test_df[\"prior_question_had_explanation\"])\n    test_df['answered_correctly'] =  model.predict(test_df[['answered_correctly_user', 'answered_correctly_content', 'sum', 'count',\n                                                                  'prior_question_elapsed_time','prior_question_had_explanation_enc', 'part']])\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","98665e27":"## Creating Validation Set (Most Recent Answers by User) ##","477c281d":"## Data Exploration ##","7d18b5ea":"## Examining Feature Importance ##","1d364c5b":"## Aggregating and Shaping Data ##","d19c436e":"Does it make sense to use last questions as validation? Why is the rate of correct answers so low?","5c1e3ddc":"## Reading Data and Importing Libraries ##","750faae6":"## Extracting Training Data ##","7b90c27d":"This is attempting to improve on my first simple LGBM model with only 3 features.\n","656c1307":"## Modeling ##","6105bc51":"## Making Predictions for New Data ##","ddea0c2b":"Are early questions fundamentally different? The best answer I could get was: not really","a8f6b43e":"Affirmatives (True) for content_type_id are only for those with a different type of content (lectures). These are not real questions."}}