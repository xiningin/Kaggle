{"cell_type":{"ee65116f":"code","1b2f3bb8":"code","15328c03":"code","0502ce92":"code","7ec32183":"code","0545b204":"code","d3f6358c":"code","a9116a50":"code","688db25d":"code","dcb9cffa":"code","6964a694":"code","052bdc6a":"code","227c3b24":"code","c079253d":"code","01102b58":"code","7da71256":"code","1a3e83dd":"code","207f7f2f":"code","ec8ad64c":"code","28b50954":"markdown","3cf6ddb4":"markdown","8ed14d7e":"markdown","0bc06cf3":"markdown","a512541e":"markdown"},"source":{"ee65116f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1b2f3bb8":"import pandas as ps\nimport numpy as ny\nimport seaborn as sn\nimport matplotlib.pyplot as plt\nfrom pandas_profiling import ProfileReport\n\n# reading the dataset(csv file)\n\n\necomm_records_dataset = ps.read_csv('\/kaggle\/input\/us-ecommerce-record-2020\/US  E-commerce records 2020.csv')\necomm_records_dataset.head(10)\n","15328c03":"# Primary checks\necomm_records_dataset.info","0502ce92":"ecomm_records_dataset.describe()","7ec32183":"pandas_profile_key = ProfileReport(ecomm_records_dataset,title=\"E-commerce records 2020 Report\")\npandas_profile_key.to_notebook_iframe()","0545b204":"## But hey, let's also checkout isnull, need to drop, etc.\n\necomm_records_dataset.isnull().sum() # Wow !","d3f6358c":"## Order date may seem relevant if time based records are needed. so keeping it as is. Dropping all others.\n\nclean_ecomm_records = ecomm_records_dataset.drop(columns=['Row ID','Order ID','Customer ID','Country','Postal Code','Product ID','Product Name'])\nclean_ecomm_records.head(10)","a9116a50":"plt.figure(figsize=(20,15))\nsn.barplot(x='Sales',y='State',data=clean_ecomm_records)","688db25d":"# Below is a pairplot code - but seems overwhelming, so ignoring for now.\n\"\"\"\nsales_pairplot_df = clean_ecomm_records[['City','State','Region','Sales']]\nplt.figure(figsize=(50,45))\nsn.pairplot(y_vars='Sales',x_vars=['City'],data=sales_pairplot_df,height=30)\n\"\"\"\n\nplt.figure(figsize=(20,10))\nsn.barplot(x='Sales',y='Region',data=clean_ecomm_records)","dcb9cffa":"# Plotting Sales against categories.\nplt.figure(figsize=(20,10))\nsn.barplot(x=clean_ecomm_records['Category'],y=clean_ecomm_records['Sales'],palette = \"Blues\")","6964a694":"# Plotting Sales against sub-categories.\nsubcat_vs_sales = clean_ecomm_records.groupby('Sub-Category')['Sales'].sum()\nplt.figure(figsize=(18,15))\nbarplot2 = sn.barplot(x=subcat_vs_sales.index,y=subcat_vs_sales.values,palette = \"Oranges\")\nbarplot2.set(xlabel=\"Sub-categories\", ylabel = \"Sales\")","052bdc6a":"# Pair plot for a region wise - larger view - a bit overwhelming ?\nplt.figure(figsize=(18,15))\nsn.pairplot(clean_ecomm_records,hue=\"Region\")","227c3b24":"# Plotting Region against Profits.\nregion_vs_profit = clean_ecomm_records.groupby('Region')['Profit'].sum()\nplt.figure(figsize=(18,15))\nbarplot3 = sn.barplot(x=region_vs_profit.index,y=region_vs_profit.values,palette = \"mako_r\")\nbarplot3.set(xlabel=\"Region\", ylabel = \"Profit\")\n\n# West and East lead on profits !","c079253d":"# Plotting Region against Profits.\nregion_vs_profit = clean_ecomm_records.groupby('Discount')['Profit'].sum()\nplt.figure(figsize=(18,15))\nbarplot4 = sn.barplot(x=region_vs_profit.index,y=region_vs_profit.values,palette = \"mako\")\nbarplot4.set(xlabel=\"Discount\", ylabel = \"Profit\")\n\n# More discount means more loss ? Interesting.","01102b58":"# Which states make for losses ?\nlosses_df = clean_ecomm_records.loc[clean_ecomm_records['Profit']<=0]\nlosses_df['Profit'] = losses_df['Profit'].abs()\nstates_vs_loss = losses_df.groupby('State')['Profit'].sum()\n\n# Same relationship with a Pie plot.\nplt.figure(figsize=(38,21))\npie_chart1 = states_vs_loss.plot.pie(autopct=\"%.1f%%\")\n\n# Loss making states( read all numbers as a % loss)","7da71256":"# Which Categories make for losses ?\n\nsubcats_vs_loss = losses_df.groupby('Sub-Category')['Profit'].sum()\n\n# Same relationship with a Pie plot.\nplt.figure(figsize=(38,21))\npie_chart3 = subcats_vs_loss.plot.pie(autopct=\"%.1f%%\")\n\n# Loss making categories( read all numbers as a % loss)","1a3e83dd":"# Which segments make for losses ?\nsegment_vs_loss = losses_df.groupby('Segment')['Profit'].sum()\n\n# Same relationship with a Pie plot.\nplt.figure(figsize=(38,21))\npie_chart3 = segment_vs_loss.plot.pie(autopct=\"%.1f%%\")\n\n# Loss making categories( read all numbers as a % loss)","207f7f2f":"# Lastly, Ship mode preferences among states\n# 1 - First Class vs States\n\n\nshipmode_dummies = ps.get_dummies(clean_ecomm_records['Ship Mode'])\n\nshipmode_ecom_records = ps.concat([clean_ecomm_records['State'],shipmode_dummies],axis = 1)\n\nstate_vs_fc = shipmode_ecom_records.groupby('State')['First Class'].sum()\nplt.figure(figsize=(28,19))\nbarplot6 = sn.barplot(y=state_vs_fc.index,x=state_vs_fc.values,palette = \"mako_r\")\nbarplot6.set(ylabel=\"State\", xlabel = \"FC\")\n","ec8ad64c":"# Lastly, Ship mode preferences among states\n# 2 - Same Day vs States\n\n\nstate_vs_sd = shipmode_ecom_records.groupby('State')['Same Day'].sum()\nplt.figure(figsize=(28,19))\nbarplot7 = sn.barplot(y=state_vs_sd.index,x=state_vs_sd.values,palette = \"seismic_r\")\nbarplot7.set(ylabel=\"State\", xlabel = \"SD\")\n","28b50954":"**EDA - Viz - 2. Let's see profits**","3cf6ddb4":"**A look at the first few rows may tell us, the IDs labels may not be of use to categorize data, similarly order date, postal code,region (since city may just be granular enough, just saying!) and product name have less relevance. Hence dropping them**","8ed14d7e":"**More insights could be built accordingly... All the best !**","0bc06cf3":"**EDA - Viz - 3. Let's see Losses**","a512541e":"**EDA - Viz - 1. Let's start with sales vs city \/ region \/ state**"}}