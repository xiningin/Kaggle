{"cell_type":{"767b5eb7":"code","5555488c":"code","151928a9":"code","a48a93c3":"code","5a5ebed9":"code","bce0bdaf":"code","7ccc83e1":"code","c5e3fdae":"code","f9b98e68":"code","ada58499":"code","13aca3e3":"code","c503e6a4":"code","4aa98fcd":"code","8282ed58":"code","a6249783":"code","5a4f68a6":"code","fb12190e":"code","40b7a42d":"code","41d040ce":"code","9ceffc7a":"code","e7be75aa":"code","f6771723":"code","4c5da946":"code","a914296a":"code","5426d339":"code","e9c4acdc":"code","b9441408":"code","97d35b8d":"code","5a1d00b8":"code","8fcc0d26":"code","d545ce0a":"code","7ee5e71f":"code","ca79cd94":"code","82ad8501":"code","c5cf1715":"code","2d5bf904":"code","787a138e":"code","4091814b":"code","df32ef63":"code","a3ccda93":"code","4332dd65":"code","4485a905":"code","98e97364":"code","c6fcc7fe":"code","d70dc096":"markdown","6d52ea9a":"markdown","82dd4593":"markdown","3e60e0dd":"markdown","57a21e59":"markdown","cc08d2b0":"markdown","3da05f0a":"markdown","5bba6c0a":"markdown","30020901":"markdown","2bdf4794":"markdown","c935ed7a":"markdown","d501b87f":"markdown","2ffdcfc2":"markdown","ceab483a":"markdown","3151c8d6":"markdown","84d731c8":"markdown","fb3cdcbe":"markdown","ec8e7d4b":"markdown","ea95b38b":"markdown","975a052c":"markdown","bf38616b":"markdown","392a2191":"markdown","5802efce":"markdown","2449f51a":"markdown","56c79d5b":"markdown","3f818c99":"markdown","f992875c":"markdown","cc5fbae7":"markdown","3be3f87c":"markdown","235b398b":"markdown","68487a24":"markdown"},"source":{"767b5eb7":"import numpy as np\nimport pandas as pd =\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import normalize\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom collections import defaultdict\n\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as Data\nimport torchvision.transforms as transforms\nimport torchvision\nimport PIL\n\ndevice = 'cuda' # running on Kaggle with a GPU, change to 'cpu' if no gpu available","5555488c":"def plot(config):\n    history = pd.DataFrame(config['history'])\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch number')\n    sns.lineplot(x=history.index, y=history['train_loss'], label = 'Train Loss')\n    sns.lineplot(x=history.index, y=history['valid_loss'], label = 'Valid Loss')\n    plt.legend(loc=\"center right\")\n    ax2 = plt.twinx()\n    ax2.set_ylabel('Accuracy')\n    sns.lineplot(x=history.index, y=history['valid_acc'], ax=ax2, color = 'red', label='Valid Acc.')\n\ndef train_model(model, config):\n    # train the model with the specified configuration\n    def train():\n        model.train()\n        epoch_loss = 0\n        for batch in train_loader:\n            x, y = batch\n            x = x.to(device)\n            y = y.to(device)\n\n            out = model(x)\n            loss = criterion(out, y)\n            epoch_loss += loss.item()\n            loss.backward()\n            \n            optim.step()\n            model.zero_grad()\n        \n        history['train_loss'].append(epoch_loss \/ len(train_loader))\n    \n    def evaluation():\n        correct = 0\n        eval_loss = 0\n        model.eval()\n        for batch in valid_loader:\n            with torch.no_grad():\n                x, y = batch\n                x = x.to(device)\n                y = y.to(device)\n\n                out = model(x)\n                eval_loss += criterion(out, y).item()\n                softmax_out = torch.softmax(out, axis=1)\n                correct += (softmax_out.argmax(1) == y).sum().item()\n\n        eval_acc = correct \/ len(valid_loader.dataset)\n            \n        history['valid_loss'].append(eval_loss \/ len(valid_loader))\n        history['valid_acc'].append(eval_acc)\n        \n    def earlystop():\n        nonlocal current_patience\n        nonlocal trials\n        \n        best_val_loss = min(history['valid_loss'])\n        current_val_loss = history['valid_loss'][-1]\n        if current_val_loss <= best_val_loss:\n            # save best model\n            torch.save(\n                {\n                    'model': model.state_dict(),\n                    'optim': optim.state_dict()\n                },\n                f'{name}.pt'\n            )\n\n        else:\n            current_patience -= 1\n            if current_patience == 0:\n                # load previous best model\n                checkpoint = torch.load(f'{name}.pt')\n                model.load_state_dict(checkpoint['model'])\n                optim.load_state_dict(checkpoint['optim'])\n                trials -= 1\n                if trials == 0:\n                    # end training and early stop\n                    print('Early Stopped at epoch', e+1)\n                    return True\n                                    \n               \n    epochs = config['epochs']\n    optim = config['optim']\n    criterion = config['criterion']\n    train_loader = config['train_loader']\n    valid_loader = config['valid_loader']\n    device = config['device']\n    history = config['history']\n    \n    if 'early_stop' in config.keys():\n        patience = current_patience = config['early_stop']['patience']\n        trials = config['early_stop']['trials']\n        name = config['early_stop']['name']    \n    \n    # training evaluation loop\n    for e in range(epochs):\n        train()\n        evaluation()\n        \n        if (e + 1) % 5 == 0: \n            print('Epoch', e+1)\n            print('Epoch Train Loss:', history['train_loss'][-1])\n            print('Epoch Valid Loss', history['valid_loss'][-1])\n            print('Epoch Valid Acc', history['valid_acc'][-1], '\\n')\n        \n        if 'early_stop' in config.keys():\n            if earlystop():\n                break\n    \n    # return the optimizer so we can continue training if we want\n    config[\"optim\"] = optim\n\ndef test_eval(model, config):\n    correct = 0\n    eval_loss = 0\n    model.eval()\n    criterion = config[\"criterion\"]\n    loader = config['test_loader']\n    for batch in loader:\n        with torch.no_grad():\n            x, y = batch\n            x = x.to(device)\n            y = y.to(device)\n\n            out = model(x)\n            eval_loss += criterion(out, y).item()\n            softmax_out = torch.softmax(out, axis=1)\n            correct += (softmax_out.argmax(1) == y).sum().item()\n            \n    print('Test Acc.:', correct \/ len(loader.dataset), 'Test Loss', eval_loss \/ len(loader))","151928a9":"# for formality, we will split the train set into a train and validation set an 8\/2 split.\ntrain_valid = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')\ntrain, valid = train_test_split(train_valid, test_size=0.2)\ntrain.head()","a48a93c3":"train_x, train_y = train.iloc[:, 1:].values, train['label'].values\nvalid_x, valid_y = valid.iloc[:, 1:].values, valid['label'].values\ntest_x, test_y = test.iloc[:, 1:].values, test['label'].values\n\ntrain_x = normalize(train_x)\nvalid_x = normalize(valid_x)\ntest_x = normalize(test_x)\n\nprint('Train set', train_x.shape, train_y.shape)\nprint('Valid set', valid_x.shape, valid_y.shape)\nprint('Test set',test_x.shape, test_y.shape)","5a5ebed9":"train_valid_test = {\n    'train': (train_x, train_y),\n    'valid': (valid_x, valid_y),\n    'test': (test_x, test_y)\n}\n\nclass FashionMNIST(Data.Dataset):\n    \n    def __init__(self, which, transform=None):\n        assert which in list(train_valid_test.keys())\n        self.x, self.y = train_valid_test[which]\n        self.x = torch.from_numpy(self.x).float()\n        self.y = torch.from_numpy(self.y)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, idx):\n        x, y = self.x[idx], self.y[idx]\n        if self.transform:\n            x = self.transform(x)\n        \n        return x, y\n    \n\ntrain_loader = Data.DataLoader(FashionMNIST('train'), batch_size = 64, shuffle = True)\nvalid_loader = Data.DataLoader(FashionMNIST('valid'), batch_size = 64, shuffle = True)\ntest_loader = Data.DataLoader(FashionMNIST('test'), batch_size = 64, shuffle = True)","bce0bdaf":"labels = np.array([\n    'T-shirt\/top', \n    'Trouser', \n    'Pullover', \n    'Dress', \n    'Coat', \n    'Sandal', \n    'Shirt', \n    'Sneaker', \n    'Bag', \n    'Ankle boot'\n])\n\nfig, ax = plt.subplots(3, 3, figsize=(9,9))\n\nfor i in range(3):\n    for j in range(3):\n        idx = random.randint(0, len(train_x))\n        ax[i][j].set_title(labels[train_y[idx]])\n        ax[i][j].xaxis.set_visible(False)\n        ax[i][j].yaxis.set_visible(False)\n        ax[i][j].imshow(train_x[idx].reshape(28, 28))","7ccc83e1":"simple_mlp = nn.Sequential(\n    nn.Linear(784, 300),\n    nn.Dropout(0.5),\n    nn.ReLU(),\n    nn.Linear(300, 150),\n    nn.Dropout(0.5),\n    nn.ReLU(),\n    nn.Linear(150, 10)\n).to(device)\n\nmlp_config = {\n    'criterion': nn.CrossEntropyLoss(),\n    'epochs': 20,\n    'optim': torch.optim.Adam(simple_mlp.parameters()),\n    'lr': 0.001,\n    'train_loader': train_loader,\n    'valid_loader': valid_loader,\n    'test_loader': test_loader,\n    'device': device,\n    \n    'history': {\n        'train_loss': [], 'valid_loss': [],'valid_acc': []\n               }\n}     ","c5e3fdae":"train_model(simple_mlp, mlp_config)","f9b98e68":"plt.title(\"Simple MLP\")\nplot(mlp_config)","ada58499":"test_eval(simple_mlp, mlp_config)","13aca3e3":"class chw(nn.Module): \n    # a custom layer to reshape in input of (batch_size, n_features) -> (batch_size, channel, height, width)\n    def __init__(self, dims):\n        super().__init__()\n        self.c, self.h, self.w = dims\n        \n\n    def forward(self, x):\n        return x.view(-1, self.c, self.h, self.w)","c503e6a4":"simple_cnn = nn.Sequential(\n    chw((1, 28, 28)), # custom layer for data transformation\n    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(3,3), stride=1, padding=1),\n    nn.ReLU(),\n    nn.MaxPool2d(kernel_size=2, stride=2),\n    nn.Conv2d(6, 12, 3, 1, 1),\n    nn.ReLU(),\n    nn.MaxPool2d(2, 2),\n    nn.Flatten(),\n    nn.Linear(588, 128),\n    nn.Dropout(0.5),\n    nn.ReLU(),\n    nn.Linear(128, 10)\n).to(device)\n\nsimple_cnn_config = {\n    'criterion': nn.CrossEntropyLoss(),\n    'epochs': 20,\n    'optim': torch.optim.Adam(simple_cnn.parameters()),\n    'lr': 0.001,\n    'train_loader': train_loader,\n    'valid_loader': valid_loader,\n    'test_loader': test_loader,\n    'device': device,\n    \n    'history': {\n        'train_loss': [], 'valid_loss': [],'valid_acc': []\n               }\n}","4aa98fcd":"train_model(simple_cnn, simple_cnn_config)","8282ed58":"plt.title('Simple CNN')\nplot(simple_cnn_config)","a6249783":"simple_cnn_config['epochs'] = 10 # train for 10 epochs this time\ntrain_model(simple_cnn, simple_cnn_config)","5a4f68a6":"plt.title('Simple CNN')\nplot(simple_cnn_config)","fb12190e":"test_eval(simple_cnn, simple_cnn_config)","40b7a42d":"class ResidualLayer(nn.Module):\n    \n    def __init__(self, in_c, out_c, stride=1, first=False):\n        super().__init__()\n        self.conv1 = nn.Conv2d(\n            in_channels=in_c, \n            out_channels=out_c, \n            kernel_size=3, \n            stride=stride, \n            padding=1)\n        \n        self.conv2 = nn.Conv2d(out_c, out_c, 3, 1, 1)\n        self.conv3 = nn.Conv2d(in_c, out_c, 1, stride) if first else None\n        self.relu = nn.ReLU()        \n        \n        self.bn1 = nn.BatchNorm2d(out_c)\n        self.bn2 = nn.BatchNorm2d(out_c)\n        \n    def forward(self, x):\n        y = self.conv1(x)\n        y = self.bn1(y)\n        y = self.relu(y)\n        y = self.conv2(y)\n        y = self.bn2(y)\n        y = self.relu(y)\n        if self.conv3:\n            return y + self.conv3(x)\n        else:\n            return y\n    \nclass ResidualBlock(nn.Module):\n    \n    def __init__(self, in_c, out_c, num_layers):\n        super().__init__()\n        self.layers = nn.ModuleList()\n        self.layers.append(ResidualLayer(in_c, out_c, 2, True))\n        for i in range(1, num_layers):\n            self.layers.append(ResidualLayer(out_c, out_c))\n    \n    def forward(self, x):\n        for layer in self.layers:\n            x = layer(x)\n            \n        return x\n    \nnn.Sequential(\n    nn.Conv2d(1, 64, 7, 2, 3),\n    nn.BatchNorm2d(64),\n    nn.ReLU(),\n    nn.MaxPool2d(3, 2, 1)\n)\n\nmy_resnet = nn.Sequential(\n    chw((1, 28, 28)),\n    torchvision.transforms.Resize((224, 224)),\n    # the base block is a little bit special compared the the rest of the network\n    # it takes in the one channel and is the only layer to use max pool\n    nn.Sequential(\n    nn.Conv2d(1, 64, 7, 2, 3),\n    nn.BatchNorm2d(64),\n    nn.ReLU(),\n    nn.MaxPool2d(3, 2, 1)\n    ), \n    # the resnet blocks, each made of 2 layers\n    # Note: the first layer of the resnet block is takes a stride of 2 \n    # to reduce the size of the feature maps for subsequent layers\n    ResidualBlock(64, 64, 2), \n    ResidualBlock(64, 128, 2), \n    ResidualBlock(128, 256, 2), \n    ResidualBlock(256, 512, 2),\n    \n    # the global average pool essentiall takes the averegre of each \"pixel\" for each feature map, \n    # this cuts down the useage of a fully connected layer, thus cutting the number of paremeters dramatically\n    nn.AdaptiveAvgPool2d((1,1)),\n    nn.Flatten(),\n    nn.Linear(512, 10)\n).to(device)\n\nresnet_config = {\n    'criterion': nn.CrossEntropyLoss(),\n    'epochs': 20,\n    'optim': torch.optim.Adam(my_resnet.parameters()),\n    'lr': 0.001,\n    'train_loader': train_loader,\n    'valid_loader': valid_loader,\n    'test_loader': test_loader,\n    'device': device,\n    \n    'history': {\n        'train_loss': [], 'valid_loss': [],'valid_acc': []\n               }\n}","41d040ce":"train_model(my_resnet, resnet_config)","9ceffc7a":"plot(resnet_config)","e7be75aa":"my_resnet = nn.Sequential(\n    chw((1, 28, 28)),\n    torchvision.transforms.Resize((224, 224)),\n    # the base block is a little bit special compared the the rest of the network\n    # it takes in the one channel and is the only layer to use max pool\n    nn.Sequential(\n    nn.Conv2d(1, 64, 7, 2, 3),\n    nn.BatchNorm2d(64),\n    nn.ReLU(),\n    nn.MaxPool2d(3, 2, 1)\n    ), \n    # the resnet blocks, each made of 2 layers\n    # Note: the first layer of the resnet block is takes a stride of 2 \n    # to reduce the size of the feature maps for subsequent layers\n    ResidualBlock(64, 64, 2), \n    ResidualBlock(64, 128, 2), \n    ResidualBlock(128, 256, 2), \n    ResidualBlock(256, 512, 2),\n    \n    # the global average pool essentiall takes the averegre of each \"pixel\" for each feature map, \n    # this cuts down the useage of a fully connected layer, thus cutting the number of paremeters dramatically\n    nn.AdaptiveAvgPool2d((1,1)),\n    nn.Flatten(),\n    nn.Linear(512, 10)\n).to(device)\n\nresnet_config = {\n    'criterion': nn.CrossEntropyLoss(),\n    'epochs': 20,\n    'optim': torch.optim.Adam(my_resnet.parameters()),\n    'lr': 0.001,\n    'train_loader': train_loader,\n    'valid_loader': valid_loader,\n    'test_loader': test_loader,\n    'device': device,\n    \n    'history': {\n        'train_loss': [], 'valid_loss': [],'valid_acc': []\n               },\n    # add early stopping criteria to the model config\n    'early_stop': {\n        'name': 'resnet',\n        'patience': 3,\n        'trials': 1\n    }\n}\n\ntrain_model(my_resnet, resnet_config)\nplot(resnet_config)","f6771723":"print('Resnet')\ntest_eval(my_resnet, resnet_config)\nprint('\\nSimple CNN')\ntest_eval(simple_cnn, simple_cnn_config)\nprint('\\nSimple MLP')\ntest_eval(simple_mlp, mlp_config)","4c5da946":"# extract the file names and class lables from the folder\nfishes = {\"id\": [], \"class\": [], 'label': []}\n\nlabels = defaultdict(lambda: len(labels))\n\nfor (root,dirs,files) in os.walk('..\/input\/a-large-scale-fish-dataset\/NA_Fish_Dataset', topdown=True):\n    if root != '..\/input\/a-large-scale-fish-dataset\/NA_Fish_Dataset':\n        for (r,d,f) in os.walk(root):\n            fish_class = r.split('\/')[-1]\n            fish_label = labels[fish_class]\n            for i in f:\n                fishes['id'].append(f'{root}\/{i}')\n                fishes['class'].append(fish_class)\n                fishes['label'].append(fish_label)\n\n\n# this dataframe is used to refer to the files when we make a custom dataset to load the data\nfishes_df = pd.DataFrame(fishes)\nfishes_df.head()","a914296a":"# a look at the class distributions\nprint('Sample size:', fishes_df.shape[0])\nprint(fishes_df['class'].value_counts())","5426d339":"# the 50\/10\/40 train, valid, test split\ntrain_val, test = train_test_split(fishes_df, test_size=4\/10, stratify=fishes['label'], random_state=23)\ntrain, valid = train_test_split(train_val, test_size=1\/6, stratify=train_val['label'], random_state=40)","e9c4acdc":"print('\\nTrain:',train.shape[0])\nprint(train[\"class\"].value_counts())\nprint('\\nValid:',valid.shape[0])\nprint(valid[\"class\"].value_counts())\nprint('\\nTest:',test.shape[0])\nprint(test[\"class\"].value_counts())","b9441408":"fishes_datasets = {\n    'train': train,\n    'valid': valid,\n    'test': test\n}\n\nclass FishesDataset(Data.Dataset):\n    \n    def __init__(self, which, transform=None):\n        self.data = fishes_datasets[which]\n        self.transform = transform\n        \n    def __len__(self):\n        return self.data.shape[0]\n    \n    def __getitem__(self, idx):\n        image = PIL.Image.open(fishes_df.loc[idx, 'id'])\n        x = transforms.functional.to_tensor(image)\n        x = transforms.Resize((224, 224))(x)\n        if self.transform:\n            x = self.transform(x)\n        \n        y = fishes_df.loc[idx, 'label']\n        return x, y\n        \ntrain_loader = Data.DataLoader(FishesDataset('train'), batch_size=64, shuffle=True)\nvalid_loader = Data.DataLoader(FishesDataset('valid'), batch_size=64, shuffle=True)\ntest_loader = Data.DataLoader(FishesDataset('test'), batch_size=64, shuffle=True)","97d35b8d":"fig, ax = plt.subplots(3, 3, figsize=(6, 6))\nx, y = list(train_loader)[0]\n\nfor i in range(3):\n    for j in range(3):\n        idx = random.randint(0,63)\n        ax[i][j].set_title(list(labels.keys())[y[idx]])\n        ax[i][j].xaxis.set_visible(False)\n        ax[i][j].yaxis.set_visible(False)\n        ax[i][j].imshow(x[idx].permute(1,2,0))","5a1d00b8":"simple_cnn = nn.Sequential(\n    nn.Conv2d(3, 6, 5, 2, 2),\n    nn.ReLU(),\n    nn.MaxPool2d(2, 2),\n    nn.Conv2d(6, 12, 5, 2, 2),\n    nn.ReLU(),\n    nn.MaxPool2d(2, 2),\n    nn.Conv2d(12, 16, 5, 2, 2),\n    nn.ReLU(),\n    nn.MaxPool2d(2, 2),\n    nn.Flatten(),\n    nn.Linear(144, 64),\n    nn.Dropout(0.5),\n    nn.ReLU(),\n    nn.Linear(64, 9)\n).to(device)\n\nsimple_cnn_config = {\n    'criterion': nn.CrossEntropyLoss(),\n    'epochs': 20,\n    'optim': torch.optim.Adam(simple_cnn.parameters()),\n    'lr': 0.001,\n    'train_loader': train_loader,\n    'valid_loader': valid_loader,\n    'test_loader': test_loader,\n    'device': device,\n    \n    'history': {\n        'train_loss': [], 'valid_loss': [],'valid_acc': []\n               }\n}","8fcc0d26":"train_model(simple_cnn, simple_cnn_config)","d545ce0a":"plot(simple_cnn_config)","7ee5e71f":"my_resnet = nn.Sequential(\n    # the base block is a little bit special compared the the rest of the network\n    # it takes in the one channel and is the only layer to use max pool\n    nn.Sequential(\n    nn.Conv2d(3, 64, 7, 2, 3),\n    nn.BatchNorm2d(64),\n    nn.ReLU(),\n    nn.MaxPool2d(3, 2, 1)\n    ), \n    # the resnet blocks, each made of 2 layers\n    # Note: the first layer of the resnet block is takes a stride of 2 \n    # to reduce the size of the feature maps for subsequent layers\n    ResidualBlock(64, 64, 2), \n    ResidualBlock(64, 128, 2), \n    ResidualBlock(128, 256, 2), \n    ResidualBlock(256, 512, 2),\n    \n    # the global average pool essentiall takes the averegre of each \"pixel\" for each feature map, \n    # this cuts down the useage of a fully connected layer, thus cutting the number of paremeters dramatically\n    nn.AdaptiveAvgPool2d((1,1)),\n    nn.Flatten(),\n    nn.Linear(512, 10)\n).to(device)\n\nresnet_config = {\n    'criterion': nn.CrossEntropyLoss(),\n    'epochs': 20,\n    'optim': torch.optim.Adam(my_resnet.parameters()),\n    'lr': 0.001,\n    'train_loader': train_loader,\n    'valid_loader': valid_loader,\n    'test_loader': test_loader,\n    'device': device,\n    \n    'history': {\n        'train_loss': [], 'valid_loss': [],'valid_acc': []\n               },\n    # add early stopping criteria to the model config\n    'early_stop': {\n        'name': 'resnet',\n        'patience': 3,\n        'trials': 1\n    }\n}\n\ntrain_model(my_resnet, resnet_config)\nplot(resnet_config)","ca79cd94":"test_eval(my_resnet, resnet_config)","82ad8501":"import torchvision.models as models\nresnet18 = models.resnet18(pretrained=True)\n\nfor params in resnet18.parameters():\n    params.requires_grad = False\n    \nresnet18.fc = nn.Linear(512, 9)","c5cf1715":"resnet_config = {\n    'criterion': nn.CrossEntropyLoss(),\n    'epochs': 20,\n    'optim': torch.optim.Adam(resnet18.fc.parameters()),\n    'lr': 0.001,\n    'train_loader': train_loader,\n    'valid_loader': valid_loader,\n    'test_loader': test_loader,\n    'device': device,\n    \n    'history': {\n        'train_loss': [], 'valid_loss': [],'valid_acc': []\n               },\n    # add early stopping criteria to the model config\n    'early_stop': {\n        'name': 'resnet',\n        'patience': 3,\n        'trials': 1\n    }\n}\n\ntrain_model(resnet18.to(device), resnet_config)\nplot(resnet_config)","2d5bf904":"print('Pretrained ResNet')\ntest_eval(resnet18, resnet_config)\nprint('\\nMy ResNet')\ntest_eval(my_resnet, resnet_config)\nprint('\\nSimple CNN')\ntest_eval(simple_cnn, simple_cnn_config)","787a138e":"batch_size = 64\ntransform = transforms.Compose([\n    transforms.Resize(32),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_loader = Data.DataLoader(torchvision.datasets.CIFAR10(\"data\", train=True, transform=transform, download=True), batch_size=batch_size)\nvalid_loader = Data.DataLoader(torchvision.datasets.CIFAR10(\"data\", train=False, transform=transform, download=True), batch_size=batch_size)","4091814b":"# get a batch from the loader\nfor batch in train_loader:\n    x, y = batch\n    break\n\n# plot 9 random images\nfig, ax = plt.subplots(3,3, figsize=(6, 6))\n\nlabels = np.array([\n    'plane',\n    'automobile',\n    'bird',\n    'cat',\n    'deer',\n    'dog',\n    'frog',\n    'horse',\n    'ship',\n    'truck'\n])\nfor i in range(3):\n    for j in range(3):\n        idx = random.randint(0,64)\n        ax[i][j].set_title(labels[y[idx]])\n        ax[i][j].xaxis.set_visible(False)\n        ax[i][j].yaxis.set_visible(False)\n        ax[i][j].imshow(x[idx].permute(1,2,0))","df32ef63":"resnet18 = torchvision.models.resnet18()\nresnet18.fc = nn.Linear(512, 10)\n\nresnet18.to(device)\nresnet_config = {\n    'criterion': nn.CrossEntropyLoss(),\n    'epochs': 30,\n    'optim': torch.optim.Adam(resnet18.parameters()),\n    'lr': 0.001,\n    'train_loader': train_loader,\n    'valid_loader': valid_loader,\n    'device': device,\n    \n    'history': {\n        'train_loss': [], 'valid_loss': [],'valid_acc': []\n               },\n    # add early stopping criteria to the model config\n    'early_stop': {\n        'name': 'resnet',\n        'patience': 5,\n        'trials': 2\n    }\n}\n\ntrain_model(resnet18, resnet_config)","a3ccda93":"plot(resnet_config)","4332dd65":"vgg16 = torchvision.models.vgg16(pretrained=True)\nvgg16.classifier = nn.Sequential(\n    nn.Linear(25088, 4096),\n    nn.ReLU(),\n    nn.Dropout(0.5),\n    nn.Linear(4096, 4096),\n    nn.ReLU(),\n    nn.Dropout(0.5),\n    nn.Linear(4096, 10)\n)\n\nvgg16.to(device)\nvgg16_config = {\n    'criterion': nn.CrossEntropyLoss(),\n    'epochs': 30,\n    'optim': torch.optim.Adam(vgg16.classifier.parameters()),\n    'lr': 0.001,\n    'train_loader': train_loader,\n    'valid_loader': valid_loader,\n    'device': device,\n    \n    'history': {\n        'train_loss': [], 'valid_loss': [],'valid_acc': []\n               },\n    # add early stopping criteria to the model config\n    'early_stop': {\n        'name': 'resnet',\n        'patience': 5,\n        'trials': 2\n    }\n}\n\ntrain_model(vgg16, vgg16_config)","4485a905":"plot(vgg16_config)","98e97364":"resnet18 = torchvision.models.resnet18(pretrained=True)\nresnet18.fc = nn.Linear(512, 10)\n\nresnet18.to(device)\nresnet_config = {\n    'criterion': nn.CrossEntropyLoss(),\n    'epochs': 30,\n    'optim': torch.optim.Adam(resnet18.fc.parameters()),\n    'lr': 0.001,\n    'train_loader': train_loader,\n    'valid_loader': valid_loader,\n    'device': device,\n    \n    'history': {\n        'train_loss': [], 'valid_loss': [],'valid_acc': []\n               },\n    # add early stopping criteria to the model config\n    'early_stop': {\n        'name': 'resnet',\n        'patience': 3,\n        'trials': 1\n    }\n}\n\ntrain_model(resnet18, resnet_config)","c6fcc7fe":"plot(resnet_config)","d70dc096":"Let's look at the each model's performance on the test set:","6d52ea9a":"This time we will use Pytorch's built in ResNet class and then we will compare with another popular architecture.","82dd4593":"As shown from the cell above, there are a whopping 430 fishes (not distinct fishes as some are just the same fish but different angles :) ) in the dataset! This is not a lot but perfect for us to see the power of a pretrained base as they would, ideally, give good predictive performance even with scarce training data. Motivated by this, we will perform a rather extreme split of 50\/10\/40 (train\/val.\/test) on the dataset.","3e60e0dd":"This notebook contains some CNN implementations and experiements using pytorch.\n\nClassification is the most common task we use CNN's for and we will experiment on three datasets, two of which are simple datasets with a relatively small number of classes and then we will scale upto a much larger dataset. \n\n\n","57a21e59":"### Pretrained CNN\n\nNow, we will use pytorch's pretrained ResNet to train on the same dataset under the same conditions to see the power of a pretrained network.\n\nFirst we need to download the set up the model and download it's weights, then we freeze every layer and assign a new head to the model. By default the new linear layer will have it's weigths \"requires_grad\" set to True.","cc08d2b0":"We will try with a VGG16 model, but we will use a pretrained base instead of training from sratch.","3da05f0a":"Now we try Resnet with pretrained base","5bba6c0a":"### An MLP benchmark\n\nWe first train an MLP on the f-mnist dataset as a benchmark for our CNN model.","30020901":"Evaluate our model on test set","2bdf4794":"A look at a few images of the dataset.\n","c935ed7a":"Now we separate the images and the truth labels","d501b87f":"Visualising the simple cnn again","2ffdcfc2":"# Fish dataset\n\nNow, we will shift from the f-mnist dataset to a slightly more complex dataset (instances have 3 channels instead of 1!), namely the Fish dataset. Let's begin with some data exploration and then some preprocessing to get the data ready for model consumption. The main goal of this section is to compare the performances between a pretrained cnn base and the same trained from scratch.\n\nThe dataset is split into two main directories, the \"Fish_Dataset\" is \"NA_Fish_Dataset\" after performing data augmentation, additionally, the augmented version also has a \"GT\" version for each class and they are for image segmentation tasks.\n\nFor our project, we will make use of the \"NA\" (stands for \"not augmented\"... I guess?) directory and perform data augmentation ourselves with the torchvision api.\n\nWe will make a custom dataset like before, but this time is a bit more tricky as some of the images are off different sizes and formats (png, and JPEG)","ceab483a":"Let's have a look at some of the fishes!","3151c8d6":"Visualize","84d731c8":"Note: We used stratify sampling for each split to ensure that each class is properly represented for each split. Now let's create out custom datasets!","fb3cdcbe":"It appears that the model started to overfit after 7 epochs, however the accuracy is not severly affected (if at all). We can remedy this by implementing an early stopping mechanism as follows: ","ec8e7d4b":"## ResNet\n\nNow, let's try the same dataset with one of the SOTA CNN architectured, namely the ResNet architecture. Pytorch has built in CNN architectures for many of the popular architectures, however the built in model takes in images with 3 input channels which is 2 more than what we have with our f-mnist dataset. There are various techniques we can employ to remedy this but I think it is more meaningful to build your own from scratch.","ea95b38b":"Create some custom datasets with the torch \"Dataset\" API.\n\nNote: admittedly there are better ways to load the data, but I thought this would be a good simple example to showcase the pytorch \"Dataset\" API","975a052c":"# Fashion MNIST\n\nFirst, let's start with a simple dataset, the Fashion MNIST (f-mnist); this dataset is small so we can read it entirely into RAM.","bf38616b":"Train our simple MLP","392a2191":"### A simple CNN\n\nBefore we build our CNN, we need to transform our data so that it can be used as input to a conv2d layer. Currently, we have our data represented as a 784 dimensional vector, and we need to reshape it into (1, 28, 28), where each entry stands for channel, height, and width, respectively.\n\nWe can do this easily by adding a transformation to our custom dataset but for simplicity, we will instead reshape it when the model receives the input, this can be ahieved by making a simple custom layer as follows:","5802efce":"It looks like there may still be some room for improvements, let's train for a few more epochs","2449f51a":"### Simple CNN\n\nWe will use a simple CNN as our benchmark for this dataset, we don't use an MLP because the model would be too large (the input dimension would be 3 * 224 * 224) and training would be too slow.","56c79d5b":"Let's train our simple CNN!","3f818c99":"Below are a few helper functions to train, test and visualise our models.","f992875c":"Visualise our MLP training progress","cc5fbae7":"Some helper functions to be used throughout the notebook. ","3be3f87c":"Again, let's visualise our model progress","235b398b":"Unsurpringsly, ResNet performed the best with 93% accuracy while the other two are at least 2% worse.","68487a24":"# CIFAR-10\n\nThe last dataset we will experiment on is the CIFAR-10 Dataset. "}}