{"cell_type":{"9bca0fb0":"code","683175b0":"code","5fdf5d15":"code","1cc4cffa":"code","1834f676":"code","c4f22522":"code","57f34001":"code","5f16f234":"code","cd4ea55b":"code","1e8e1f54":"code","4e2ffce9":"code","3d9356f4":"code","1870269a":"code","daee1152":"code","58a69a56":"markdown","2169943a":"markdown","2b3af576":"markdown","468bf475":"markdown","93252db8":"markdown","4c6c9d1a":"markdown"},"source":{"9bca0fb0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport re\nfrom IPython.display import clear_output\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","683175b0":"df_data = pd.read_excel(os.path.join(dirname, 'dataset.xlsx'))\ndf_data.columns = [x.lower().strip().replace(' ','_').replace(',', '') for x in df_data.columns]\ndf_data.columns = [re.sub('[^A-Za-z0-9\\\\_\\\\-]+', '', x) for x in df_data.columns]\nprint(df_data.columns)","5fdf5d15":"print(df_data.head())\nprint(df_data.shape)","1cc4cffa":"df_data = df_data.drop(np.where(df_data.isna().sum(axis=1) >= df_data.shape[1]-6)[0], axis=0)\ndf_data.reset_index()","1834f676":"import matplotlib.pyplot as plt\n\ndata_to_plot = ['hematocrit', 'hemoglobin', 'platelets', 'mean_platelet_volume', 'red_blood_cells', 'lymphocytes', \\\n 'mean_corpuscular_hemoglobin_concentrationmchc', 'leukocytes', 'basophils', 'mean_corpuscular_hemoglobin_mch', 'eosinophils', \\\n 'mean_corpuscular_volume_mcv', 'monocytes', 'red_blood_cell_distribution_width_rdw', 'serum_glucose', 'neutrophils', 'urea', \\\n 'proteina_c_reativa_mgdl', 'creatinine', 'potassium', 'sodium', 'alanine_transaminase', 'aspartate_transaminase', \\\n 'gamma-glutamyltransferase', 'total_bilirubin', 'direct_bilirubin', 'indirect_bilirubin', 'alkaline_phosphatase', 'ionized_calcium', \\\n 'magnesium', 'pco2_venous_blood_gas_analysis', 'hb_saturation_venous_blood_gas_analysis', 'base_excess_venous_blood_gas_analysis', \\\n 'po2_venous_blood_gas_analysis', 'fio2_venous_blood_gas_analysis', 'total_co2_venous_blood_gas_analysis', 'ph_venous_blood_gas_analysis', \\\n 'hco3_venous_blood_gas_analysis', 'rods_', 'segmented', 'promyelocytes', 'metamyelocytes', 'myelocytes', 'myeloblasts', 'urine_-_density', \\\n 'urine_-_red_blood_cells', 'relationship_patientnormal', 'international_normalized_ratio_inr', 'lactic_dehydrogenase', 'vitamin_b12', 'creatine_phosphokinasecpk', \\\n 'ferritin', 'arterial_lactic_acid', 'lipase_dosage', 'albumin', 'hb_saturation_arterial_blood_gases', 'pco2_arterial_blood_gas_analysis', \\\n 'base_excess_arterial_blood_gas_analysis', 'ph_arterial_blood_gas_analysis', 'total_co2_arterial_blood_gas_analysis', 'hco3_arterial_blood_gas_analysis', \\\n 'po2_arterial_blood_gas_analysis', 'arteiral_fio2', 'phosphor', 'cto2_arterial_blood_gas_analysis']\n\nfor column in data_to_plot:\n  fig, axs = plt.subplots(1, 3)\n  fig.set_size_inches(18, 5)\n  axs[0].set_title(column + ' mean value')\n  df_data.groupby('sars-cov-2_exam_result')[column].mean().plot(kind='barh', ax=axs[0])\n  axs[1].set_title(column + '- who tested positive for COVID-19')\n  df_data[df_data['sars-cov-2_exam_result'] == 'positive'][column].hist(ax=axs[1])\n  axs[2].set_title(column + '- who tested negative for COVID-19')\n  df_data[df_data['sars-cov-2_exam_result'] == 'negative'][column].hist(ax=axs[2])","c4f22522":"import tensorflow as tf\nprint(tf.version)","57f34001":"df_data = df_data.dropna(axis=1, how='all')  # Remove columns that does not have data\ntry:\n  df_data.pop('urine_-_leukocytes') # Remove column that does not present consistent data\nexcept:\n  pass\n\ndf_positive = df_data[df_data['sars-cov-2_exam_result'] == 'positive']\ndf_negative = df_data[df_data['sars-cov-2_exam_result'] == 'negative']\n\ndf_train_positive = df_positive.sample(frac=0.8, random_state=12576)\ndf_test_positive = df_positive.drop(df_train_positive.index)\n\ndf_train_negative = df_negative.sample(frac=0.8, random_state=9658)\ndf_test_negative = df_negative.drop(df_train_negative.index)\n\ndf_train = pd.concat([df_train_positive, df_train_negative], axis=0).reset_index()\ndf_train_patient = df_train.pop('patient_id')\ny_train = df_train.pop('sars-cov-2_exam_result').replace('negative', 0).replace('positive',1)\ndf_test = pd.concat([df_test_positive, df_test_negative], axis=0).reset_index()\ndf_test_patient = df_test.pop('patient_id')\ny_test = df_test.pop('sars-cov-2_exam_result').replace('negative', 0).replace('positive',1)\n\ndf_train.pop('index')\ndf_test.pop('index')","5f16f234":"CATEGORICAL_COLUMNS = ['patient_addmited_to_regular_ward_1yes_0no', 'patient_addmited_to_semi-intensive_unit_1yes_0no', 'patient_addmited_to_intensive_care_unit_1yes_0no', \\\n 'respiratory_syncytial_virus', 'influenza_a', 'influenza_b', 'parainfluenza_1', 'coronavirusnl63', 'rhinovirusenterovirus', 'coronavirus_hku1', \\\n 'parainfluenza_3', 'chlamydophila_pneumoniae', 'adenovirus', 'parainfluenza_4', 'coronavirus229e', 'coronavirusoc43', 'inf_a_h1n1_2009', 'bordetella_pertussis', \\\n 'metapneumovirus', 'parainfluenza_2', 'influenza_b_rapid_test', 'influenza_a_rapid_test', 'strepto_a',  'urine_-_esterase', 'urine_-_aspect', \\\n 'urine_-_ph', 'urine_-_hemoglobin',  'urine_-_bile_pigments', 'urine_-_ketone_bodies', 'urine_-_nitrite', 'urine_-_urobilinogen', 'urine_-_protein', \\\n 'urine_-_crystals', 'urine_-_hyaline_cylinders', 'urine_-_granular_cylinders', 'urine_-_yeasts', 'urine_-_color']\n\nNUMERIC_COLUMNS = ['patient_age_quantile', 'hematocrit', 'hemoglobin', 'platelets', 'mean_platelet_volume', 'red_blood_cells', 'lymphocytes', \\\n 'mean_corpuscular_hemoglobin_concentrationmchc', 'leukocytes', 'basophils', 'mean_corpuscular_hemoglobin_mch', 'eosinophils', \\\n 'mean_corpuscular_volume_mcv', 'monocytes', 'red_blood_cell_distribution_width_rdw', 'serum_glucose', 'neutrophils', 'urea', \\\n 'proteina_c_reativa_mgdl', 'creatinine', 'potassium', 'sodium', 'alanine_transaminase', 'aspartate_transaminase', \\\n 'gamma-glutamyltransferase', 'total_bilirubin', 'direct_bilirubin', 'indirect_bilirubin', 'alkaline_phosphatase', 'ionized_calcium', \\\n 'magnesium', 'pco2_venous_blood_gas_analysis', 'hb_saturation_venous_blood_gas_analysis', 'base_excess_venous_blood_gas_analysis', \\\n 'po2_venous_blood_gas_analysis', 'fio2_venous_blood_gas_analysis', 'total_co2_venous_blood_gas_analysis', 'ph_venous_blood_gas_analysis', \\\n 'hco3_venous_blood_gas_analysis', 'rods_', 'segmented', 'promyelocytes', 'metamyelocytes', 'myelocytes', 'myeloblasts', 'urine_-_density', \\\n 'urine_-_red_blood_cells', 'relationship_patientnormal', 'international_normalized_ratio_inr', 'lactic_dehydrogenase', 'vitamin_b12', 'creatine_phosphokinasecpk', \\\n 'ferritin', 'arterial_lactic_acid', 'lipase_dosage', 'albumin', 'hb_saturation_arterial_blood_gases', 'pco2_arterial_blood_gas_analysis', \\\n 'base_excess_arterial_blood_gas_analysis', 'ph_arterial_blood_gas_analysis', 'total_co2_arterial_blood_gas_analysis', 'hco3_arterial_blood_gas_analysis', \\\n 'po2_arterial_blood_gas_analysis', 'arteiral_fio2', 'phosphor', 'cto2_arterial_blood_gas_analysis']\n\n\nfor category in CATEGORICAL_COLUMNS:\n  df_train[category] = df_train[category].apply(lambda x: str(x))\n  df_test[category] = df_test[category].apply(lambda x: str(x))\n  df_positive[category] = df_positive[category].apply(lambda x: str(x))\n  df_negative[category] = df_negative[category].apply(lambda x: str(x))\n\nfor numeric in NUMERIC_COLUMNS:\n  df_train[numeric] = pd.to_numeric(df_train[numeric])\n  df_train[numeric].fillna(0, inplace=True)\n  df_test[numeric] = pd.to_numeric(df_test[numeric])\n  df_test[numeric].fillna(0, inplace=True)\n  df_positive[numeric] = pd.to_numeric(df_positive[numeric])\n  df_positive[numeric].fillna(0, inplace=True)\n  df_negative[numeric] = pd.to_numeric(df_negative[numeric])\n  df_negative[numeric].fillna(0, inplace=True)\n\ndf_train = df_train.replace('nan', 'None')\ndf_test = df_test.replace('nan', 'None')\ndf_positive = df_positive.replace('nan', 'None')\ndf_negative = df_negative.replace('nan', 'None')\n\n\nfeature_columns = []\n\nfor column in df_data.columns:\n  if column in CATEGORICAL_COLUMNS:\n    vocabulary = df_train[column].unique() \n    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(column, vocabulary))\n  elif column in NUMERIC_COLUMNS:\n    feature_columns.append(tf.feature_column.numeric_column(column, dtype=tf.float32))\n\nprint(len(CATEGORICAL_COLUMNS))\nprint(len(NUMERIC_COLUMNS))\nprint(len(feature_columns))","cd4ea55b":"# Create input function\n\ndef make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n  def input_function():\n    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n    if shuffle:\n      ds = ds.shuffle(1000)\n    ds = ds.batch(batch_size).repeat(num_epochs)\n    return ds\n  return input_function\n\ntrain_input_fn = make_input_fn(df_train, y_train, num_epochs=50, shuffle=True, batch_size=124)\ntest_input_fn = make_input_fn(df_test, y_test, num_epochs=1, shuffle=False, batch_size=len(y_test))\n\nlinear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)","1e8e1f54":"linear_est.train(train_input_fn, max_steps=30000)","4e2ffce9":"result = linear_est.evaluate(test_input_fn)\n\nclear_output()\nprint(result)","3d9356f4":"pred_dicts = list(linear_est.predict(test_input_fn))\nprobs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n\nprobs.plot(kind='hist', bins=20, title='predicted probabilities')","1870269a":"from sklearn.metrics import roc_curve\n\nfpr, tpr, _ = roc_curve(y_test, probs)\nplt.plot(fpr, tpr)\nplt.title('ROC curve')\nplt.xlabel('false positive rate')\nplt.ylabel('true positive rate')\nplt.xlim(0,)\nplt.ylim(0,)","daee1152":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\nout = probs.copy()\nout.iloc[np.where(probs >= 0.1)] = 1\nout.iloc[np.where(probs < 0.1)] = 0\n\ncm = confusion_matrix(y_test, out)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax = ax);\nax.set_xlabel('Predicted labels');\nax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['negative', 'positive']); ax.yaxis.set_ticklabels(['negative', 'positive']);","58a69a56":"## Plot Data","2169943a":"Data preparation for estimation","2b3af576":"## Data Loading","468bf475":"## Linear Classification Test - With all data and little interference in the algorithm","93252db8":"Drop data that is not relevant (index populated with NA only)","4c6c9d1a":"The linear classification model is fair, with only 7 errors in the test dataset, which was not used to train the model.\nThe model is easy to train and the threshold to determine wheter a person is positive for COVID-19 is easily changed.\nThe dataset is really hard to model, since there are many negative cases and only a few positive cases.\n"}}