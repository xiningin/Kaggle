{"cell_type":{"387264b6":"code","c42975e5":"code","00fe68d8":"code","c221de95":"code","9058af71":"code","1a548620":"code","6d1f621f":"code","e6b5395d":"code","fbd4d885":"code","47956777":"code","3f8b23ed":"code","dce81739":"code","a512653e":"code","ea08cacc":"code","a2e7d147":"code","024058de":"code","5c8efe1b":"code","fdfe5e64":"code","350896f7":"code","d20cf219":"code","233b140f":"code","f6a76d49":"code","da68ba94":"code","10cc7f97":"code","a86162ca":"code","ab3e9f79":"code","0647dd47":"code","e45aabf3":"code","03ceaa5e":"code","d1f02b29":"code","70bf7994":"code","7bd66ce1":"code","09962f97":"code","5afdbe12":"code","5ee2195f":"code","23dff383":"code","ab5f7dc8":"code","dc680704":"code","5d8e9c78":"code","ab3e308c":"code","67e142e7":"code","3a3eda87":"code","6079b3f2":"code","44ea1af5":"code","4e7fb073":"code","fbc07369":"code","582a40a6":"code","6a4917c8":"code","978fdbac":"code","4145524b":"code","4e9d3c3a":"code","259fcc50":"code","1b2f31d6":"code","4d900df4":"code","de6afef7":"code","ef75ee60":"code","fa911991":"code","6e64e517":"code","30cd8ec5":"code","efe57ea9":"code","b813c304":"code","b1958bca":"code","aa4565fc":"code","e2093918":"code","ebd07b15":"code","73d9ac6c":"code","11bfd0c1":"code","2aedb8ab":"code","72c471b0":"code","bed4f4d6":"markdown","2e15ba1a":"markdown","f3925fa2":"markdown","85c94b7b":"markdown","fe28832e":"markdown","2ead7ffb":"markdown","ceaa33c5":"markdown","9874ccd1":"markdown","6e472253":"markdown","bf9b649a":"markdown","2552855a":"markdown","4679ae5b":"markdown","7a0dcbd7":"markdown","824780f7":"markdown","af7a1857":"markdown","5a8ab83b":"markdown","95a3a96a":"markdown","b73580b9":"markdown","771e50ef":"markdown","14e40d39":"markdown","c7b9f58b":"markdown","f044fdbb":"markdown","ae5e0eae":"markdown","9556a0e1":"markdown","96ff9f74":"markdown"},"source":{"387264b6":"# load packages\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib as mpl\n\nfrom sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import scale\nfrom sklearn.decomposition import PCA\nfrom scipy.stats import skew, norm, probplot, boxcox, f_oneway\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_curve\nfrom matplotlib import pyplot as plt\n\n%matplotlib inline\nnp.random.seed(42)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn import svm \nfrom sklearn.neighbors import KNeighborsClassifier ","c42975e5":"# read the data\nwine_raw = pd.read_csv('..\/input\/winequality.csv').rename(columns=lambda x: x.replace(\" \",\"_\"))","00fe68d8":"print(\"Shape of Wine data:\\nrows:\", wine_raw.shape[0], '\\ncolumns:', wine_raw.shape[1])","c221de95":"wine_raw.head()","9058af71":"wine_raw.describe().T","1a548620":"# check missing data\ntotal = wine_raw.isnull().sum().sort_values(ascending = False)\npercent = (wine_raw.isnull().sum()\/wine_raw.isnull().count()*100).sort_values(ascending = False)\npd.concat([total, percent], axis=1, keys=['Total', 'Percent']).transpose().T","6d1f621f":"wine_raw = wine_raw.dropna(how = 'any')\nwine_raw.isnull().any()","e6b5395d":"features_wine = wine_raw.columns\nred_wine = round(wine_raw.loc[wine_raw.color == 'red', features_wine].describe(),2)\nwhite_wine = round(wine_raw.loc[wine_raw.color == 'white', features_wine].describe(),2)\npd.concat([red_wine, white_wine], axis=0, keys=['Red Wine', 'White Wine']).T","fbd4d885":"# check data unbalance (The data has not a large unbalance with respect of the target value.)\n# explore the target variable: quality\nqualitydata = wine_raw.quality.value_counts().sort_index()\nqualitydata_df = pd.DataFrame({'Quality Level': qualitydata.index,'Frequency': qualitydata.values})\nqualitydata_df","47956777":"# visualize target variable\nplt.figure(figsize=(7,5))\nsns.barplot(x = 'Quality Level', y =\"Frequency\", data = qualitydata_df,palette=\"Blues_d\")\nplt.title('Quality Level Distribution (level 3 - level 9)',fontsize=16)\nplt.show()","3f8b23ed":"fig = plt.figure(figsize = (15, 5))\ntitle = fig.suptitle(\"Wine Type Vs Quality (Original Dataset)\", fontsize=16)\nfig.subplots_adjust(top=0.85, wspace=0.3)\n\nax1 = fig.add_subplot(1,2, 1)\nax1.set_title(\"Red Wine\")\nax1.set_xlabel(\"Quality\")\nax1.set_ylabel(\"Frequency\") \nrw_q = wine_raw.quality[wine_raw.color == 'red'].value_counts()\nrw_q = (list(rw_q.index), list(rw_q.values))\nax1.set_ylim([0, 2500])\nax1.tick_params(axis='both', which='major', labelsize=8.5)\nbar1 = ax1.bar(rw_q[0], rw_q[1])\n\n\nax2 = fig.add_subplot(1,2, 2)\nax2.set_title(\"White Wine\")\nax2.set_xlabel(\"Quality\")\nax2.set_ylabel(\"Frequency\") \nww_q = wine_raw.quality[wine_raw.color == 'white'].value_counts()\nww_q = (list(ww_q.index), list(ww_q.values))\nax2.set_ylim([0, 2500])\nax2.tick_params(axis='both', which='major', labelsize=8.5)\nbar2 = ax2.bar(ww_q[0], ww_q[1])","dce81739":"corr = wine_raw.corr()\ntop_corr_cols = corr.quality.sort_values(ascending=False).keys() \ntop_corr = corr.loc[top_corr_cols, top_corr_cols]\ndropSelf = np.zeros_like(top_corr)\ndropSelf[np.triu_indices_from(dropSelf)] = True\nplt.figure(figsize=(12, 8))\nsns.heatmap(top_corr, cmap=sns.diverging_palette(600, 600, as_cmap=True), annot=True, fmt=\".2f\", mask=dropSelf)\n# sns.set(font_scale=1.0)\ncols = wine_raw.columns\ncols = cols.drop('quality')\n\nplt.show()","a512653e":"wine2 = wine_raw\nwine2['quality_label'] = (wine2['quality'] > 5.5)*1\n\nwine2.head()","ea08cacc":"wine_raw.head()","a2e7d147":"features_wine2 = wine2.columns\nlow_wine = round(wine2.loc[wine2.quality_label == 0, features_wine2].describe(),2)\nhigh_wine = round(wine2.loc[wine2.quality_label == 1, features_wine2].describe(),2)\npd.concat([low_wine, high_wine], axis=0, keys=['Low Quality', 'High Quality']).T","024058de":"# explore the binary target variable: quality_label\nqualitydata2 = wine2.quality_label.value_counts().sort_index()\nqualitydata2_df = pd.DataFrame({'Quality Label': qualitydata2.index,'Frequency': qualitydata2.values})\nqualitydata2_df","5c8efe1b":"plt.figure(figsize=(7,5))\nsns.barplot(x = 'Quality Label', y =\"Frequency\", data = qualitydata2_df,palette=\"Blues_d\")\nplt.title('Quality Label Distribution (High quality & Low quality)',fontsize=16)\nplt.show()","fdfe5e64":"wine3 = wine_raw\nwine3['quality_level'] = wine3.quality.apply(lambda q: 'Level C' if q <= 4 \n                                             else 'Level B' if q <= 6 \n                                             else 'Level A')\nwine3.head()","350896f7":"qualitydata3 = wine3.quality_level.value_counts().sort_index()\nqualitydata3_df = pd.DataFrame({'Quality Level': qualitydata3.index,'Frequency': qualitydata3.values})\nqualitydata3_df","d20cf219":"plt.figure(figsize=(7,5))\nsns.barplot(x = 'Quality Level', y =\"Frequency\", data = qualitydata3_df,palette=\"Blues_d\")\nplt.title('Quality Level Distribution (Level A, Level B & Level C)',fontsize=16)\nplt.show()","233b140f":"wine_raw.head()","f6a76d49":"# converting categorical variables into dummy variables\ndef categorize(l):\n    uniques = sorted(list(set(l)))\n    return [uniques.index(x) + 1 for x in l]\n\nwine_raw['color'] = categorize(wine_raw['color'])\nwine2['color'] = categorize(wine2['color'])","da68ba94":"numeric_features = list(wine_raw.dtypes[(wine_raw.dtypes != \"str\") & (wine_raw.dtypes !='object')].index)\nskewed_features = wine_raw[numeric_features].apply(lambda x : skew (x.dropna())).sort_values(ascending=False)\n\n#compute skewness\nskewness = pd.DataFrame({'Skewness' :skewed_features})   \n\n# Get only higest skewed features\nskewness = skewness[abs(skewness) > 0.7]\nskewness = skewness.dropna()\nprint (\"{} higest skewed numerical features need to be transformed\".format(skewness.shape[0]))\n\nl_opt = {}\n\nfor feat in skewness.index:\n    wine_raw[feat], l_opt[feat] = boxcox((wine_raw[feat]+1))\n\nskewed_features2 = wine_raw[skewness.index].apply(lambda x : skew (x.dropna())).sort_values(ascending=False)\n\n#compute skewness\nskewness2 = pd.DataFrame({'Skewness After Transformation' :skewed_features2})   \ndisplay(pd.concat([skewness, skewness2], axis=1).sort_values(by=['Skewness'], ascending=False))","10cc7f97":"pca = PCA(n_components='mle')\nfeatures = wine_raw.drop(['color','quality_level'],axis=1)\nfeatures = scale(features);features\nx_pca = pca.fit_transform(features)\nprint (pca.explained_variance_ratio_)\nprint ('\\n')\nsum_variance = np.cumsum(np.round(pca.explained_variance_ratio_, decimals=3)*100)\nprint (sum_variance)\n# print (pca.explained_variance_)\nprint ('\\n')\nprint (pca.n_components_)\n\nplt.ylabel('% Variance Explained')\nplt.xlabel('Number of Features')\nplt.title('PCA Analysis')\n# plt.ylim(0,100.5)\nplt.plot(sum_variance)\nplt.show()","a86162ca":"# Selecting the input and output features for multi-classification tasks\n\nfeatures = ['color',\n            'fixed_acidity',\n            'volatile_acidity',\n            'citric_acid',\n            'residual_sugar',\n            'chlorides',\n            'free_sulfur_dioxide',\n            'total_sulfur_dioxide',\n            'density',\n            'pH',\n            'sulphates',\n            'alcohol']\n\ntarget = ['quality_level']","ab3e9f79":"# Split dataset into training set & test set\nx = wine_raw[features]\ny = wine_raw[target].values.ravel()\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=200)","0647dd47":"# Selecting the input and output features for binary classification tasks\nfeatures2 = ['color',\n             'fixed_acidity',\n             'volatile_acidity',\n             'citric_acid',\n             'residual_sugar',\n             'chlorides',\n             'free_sulfur_dioxide',\n             'total_sulfur_dioxide',\n             'density',\n             'pH',\n             'sulphates',\n             'alcohol']\n\ntarget2 = ['quality_label']\n\n# x = wine_raw[features_all]\nx2 = wine2[features2]\ny2 = wine2[target2].values.ravel()\n# Visualize the combined table (which should looks the same as the original dataset)\n# pd.concat([X, y], axis=1, sort=False).head()","e45aabf3":"# Split dataset|\nx2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, test_size=0.2, random_state=200)\n# x2_train_pca = pca.fit(x2_train)","03ceaa5e":"def print_predict_vs_test_multi(clf,x_test,y_test):\n    prediction = clf.predict(x_test)\n    print('Predict values:')\n    print(prediction[:10])\n    print('-'*10)\n    print('True values in test set:')\n    print(y_test[:10])","d1f02b29":"def print_predict_vs_test_binary(clf,x_test,y_test):\n    prediction = clf.predict(x_test)\n    print('Predict values:')\n    print(prediction[:10])\n    print('-'*10)\n    print('True values in test set:')\n    print(y_test[:10])","70bf7994":"def get_results_multi(clf,clf_name,x_train,y_train,x_test,y_test):\n    y_pred = clf.predict(x_test)\n    print('Training Accuracy('+clf_name+'): {:2.2%}'.format(accuracy_score(y_train, clf.predict(x_train))))    \n    print('Test Accuracy('+clf_name+'): {:2.2%}\\n'.format(accuracy_score(y_test, clf.predict(x_test))))\n    print('Classification Report('+clf_name+'): \\n' + classification_report(y_test, y_pred))\n    \n    probs = clf.predict_proba(x_test) # Predict class probabilities of the input samples \n    preds = probs[:,1]\n    \n    \n    print('5 fold Cross Validation('+clf_name+'):')\n    cv_accuracy = cross_val_score(clf, x_train, y_train, cv=5, scoring='accuracy')\n    print('Accuracy: {:2.2%}'.format(np.mean(cv_accuracy)))\n    \n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8,8))\n    sns.heatmap(cm, annot = True, fmt=\"d\", linewidths=.5, square = True,cmap='Blues')\n    plt.ylabel('Actual Label')\n    plt.xlabel('Predicted Label')\n    plt.title('Confusion Matrix ('+clf_name+')',fontsize=16)\n    \n    tmp = pd.DataFrame({'Feature': features, 'Feature Importance': clf.feature_importances_})\n    tmp = tmp.sort_values(by='Feature Importance',ascending=False)\n    plt.figure(figsize = (10,6))\n    plt.title('Features Importance',fontsize=16)\n    s = sns.barplot(x='Feature',y='Feature Importance',data=tmp)\n    s.set_xticklabels(s.get_xticklabels(),rotation=90)\n    plt.show() ","7bd66ce1":"def get_results_binary(clf,clf_name,x_train,y_train,x_test,y_test):\n    y_pred = clf.predict(x_test)\n    print('Training Accuracy('+clf_name+'): {:2.2%}'.format(accuracy_score(y_train, clf.predict(x_train))))    \n    print('Test Accuracy('+clf_name+'): {:2.2%}\\n'.format(accuracy_score(y_test, clf.predict(x_test))))\n    print('Classification Report('+clf_name+'): \\n' + classification_report(y_test, y_pred))\n    \n    probs = clf.predict_proba(x_test) # Predict class probabilities of the input samples \n    preds = probs[:,1]\n    fpr,tpr,threshold = roc_curve(y_test, preds)\n    roc_auc = auc(fpr,tpr)\n    print('ROC AUC Score('+clf_name+'): {:2.2%}\\n'.format(roc_auc))\n    \n    \n    print('5 fold Cross Validation('+clf_name+'):')\n    cv_accuracy = cross_val_score(clf, x_train, y_train, cv=5, scoring='accuracy')\n    print('Accuracy: {:2.2%}'.format(np.mean(cv_accuracy)))\n    cv_recall = cross_val_score(clf, x_train, y_train, cv=5, scoring='recall')\n    print('Recall: {:2.2%}'.format(np.mean(cv_recall)))\n    cv_precision = cross_val_score(clf, x_train, y_train, cv=5, scoring='precision')\n    print('Precision: {:2.2%}'.format(np.mean(cv_precision)))\n    cv_f1 = cross_val_score(clf, x_train, y_train, cv=5, scoring='f1')\n    print('F1-score: {:2.2%}'.format(np.mean(cv_f1)))\n    cv_roc_auc = cross_val_score(clf, x_train, y_train, cv=5, scoring='roc_auc')\n    print('ROC AUC Score: {:2.2%}'.format(np.mean(cv_roc_auc)))\n\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8,8))\n    sns.heatmap(cm, annot = True, fmt=\"d\", linewidths=.5, square = True,cmap='Blues')\n    plt.ylabel('Actual Label')\n    plt.xlabel('Predicted Label')\n    plt.title('Confusion Matrix ('+clf_name+')',fontsize=16)\n    \n    \n    # calculate the Optimum Threshold\n    for i in range(len(fpr)):\n        if fpr[i] + tpr[i] >= 1:\n            i = i -1\n            break\n\n    plt.figure(figsize=(10,6))\n    plt.plot(fpr, tpr, lw=1,label='ROC Curve(area = %0.2f)    Optimum Threshold = %0.2f' % (roc_auc, threshold[i]))\n    plt.plot([0, 1], [0, 1], lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve ('+clf_name+')',fontsize=16)\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    \n    tmp = pd.DataFrame({'Feature': features, 'Feature Importance': clf.feature_importances_})\n    tmp = tmp.sort_values(by='Feature Importance',ascending=False)\n    plt.figure(figsize = (10,6))\n    plt.title('Features Importance',fontsize=16)\n    s = sns.barplot(x='Feature',y='Feature Importance',data=tmp)\n    s.set_xticklabels(s.get_xticklabels(),rotation=90)\n    plt.show() ","09962f97":"def get_results_multi_withoutFeatureImportance(clf,clf_name,x_train,y_train,x_test,y_test):\n    y_pred = clf.predict(x_test)\n    print('Training Accuracy('+clf_name+'): {:2.2%}'.format(accuracy_score(y_train, clf.predict(x_train))))    \n    print('Test Accuracy('+clf_name+'): {:2.2%}\\n'.format(accuracy_score(y_test, clf.predict(x_test))))\n    print('Classification Report('+clf_name+'): \\n' + classification_report(y_test, y_pred))\n    \n    probs = clf.predict_proba(x_test) # Predict class probabilities of the input samples \n    preds = probs[:,1]\n    \n    \n    print('5 fold Cross Validation('+clf_name+'):')\n    cv_accuracy = cross_val_score(clf, x_train, y_train, cv=5, scoring='accuracy')\n    print('Accuracy: {:2.2%}'.format(np.mean(cv_accuracy)))\n    \n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8,8))\n    sns.heatmap(cm, annot = True, fmt=\"d\", linewidths=.5, square = True,cmap='Blues')\n    plt.ylabel('Actual Label')\n    plt.xlabel('Predicted Label')\n    plt.title('Confusion Matrix ('+clf_name+')',fontsize=16)","5afdbe12":"def get_results_binary_withoutFeatureImportance(clf,clf_name,x_train,y_train,x_test,y_test):\n    y_pred = clf.predict(x_test)\n    print('Training Accuracy('+clf_name+'): {:2.2%}'.format(accuracy_score(y_train, clf.predict(x_train))))    \n    print('Test Accuracy('+clf_name+'): {:2.2%}\\n'.format(accuracy_score(y_test, clf.predict(x_test))))\n    print('Classification Report('+clf_name+'): \\n' + classification_report(y_test, y_pred))\n    \n    probs = clf.predict_proba(x_test) # Predict class probabilities of the input samples \n    preds = probs[:,1]\n    fpr,tpr,threshold = roc_curve(y_test, preds)\n    roc_auc = auc(fpr,tpr)\n    print('ROC AUC Score('+clf_name+'): {:2.2%}\\n'.format(roc_auc))\n    \n    \n    print('5 fold Cross Validation('+clf_name+'):')\n    cv_accuracy = cross_val_score(clf, x_train, y_train, cv=5, scoring='accuracy')\n    print('Accuracy: {:2.2%}'.format(np.mean(cv_accuracy)))\n    cv_recall = cross_val_score(clf, x_train, y_train, cv=5, scoring='recall')\n    print('Recall: {:2.2%}'.format(np.mean(cv_recall)))\n    cv_precision = cross_val_score(clf, x_train, y_train, cv=5, scoring='precision')\n    print('Precision: {:2.2%}'.format(np.mean(cv_precision)))\n    cv_f1 = cross_val_score(clf, x_train, y_train, cv=5, scoring='f1')\n    print('F1-score: {:2.2%}'.format(np.mean(cv_f1)))\n    cv_roc_auc = cross_val_score(clf, x_train, y_train, cv=5, scoring='roc_auc')\n    print('ROC AUC Score: {:2.2%}'.format(np.mean(cv_roc_auc)))\n\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8,8))\n    sns.heatmap(cm, annot = True, fmt=\"d\", linewidths=.5, square = True,cmap='Blues')\n    plt.ylabel('Actual Label')\n    plt.xlabel('Predicted Label')\n    plt.title('Confusion Matrix ('+clf_name+')',fontsize=16)\n    \n    \n    # calculate the Optimum Threshold\n    for i in range(len(fpr)):\n        if fpr[i] + tpr[i] >= 1:\n            i = i -1\n            break\n\n    plt.figure(figsize=(10,6))\n    plt.plot(fpr, tpr, lw=1,label='ROC Curve(area = %0.2f)    Optimum Threshold = %0.2f' % (roc_auc, threshold[i]))\n    plt.plot([0, 1], [0, 1], lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve ('+clf_name+')',fontsize=16)\n    plt.legend(loc=\"lower right\")\n    plt.show()","5ee2195f":"def compare_accuracy(clf,clf_name):\n    print('5 fold Cross Validation('+clf_name+'):')\n    cv_accuracy = cross_val_score(clf, x_train, y_train, cv=5, scoring='accuracy')\n    print('Accuracy: {:2.2%}'.format(np.mean(cv_accuracy)))","23dff383":"# Fit on train set\ndt_clf = DecisionTreeClassifier(random_state = 42, \n                             criterion = 'entropy',\n                             max_depth = 5,\n                             min_samples_leaf = 2,                                                   \n                            )\ndt_clf.fit(x_train, y_train)","ab5f7dc8":"print_predict_vs_test_multi(dt_clf,x_test,y_test)","dc680704":"get_results_multi(dt_clf,'Decision Tree - Multiclass Classification',x_train,y_train,x_test,y_test)","5d8e9c78":"# Fit on train set\n# wine_clf = DecisionTreeClassifier(max_depth=5, max_leaf_nodes=10, random_state=200)\ndt_clf2 = DecisionTreeClassifier(\n                              max_depth = 5,\n                              random_state = 42,\n                              criterion = 'entropy',                             \n                              min_samples_leaf = 2\n                             )\ndt_clf2.fit(x2_train, y2_train)","ab3e308c":"print_predict_vs_test_binary(dt_clf2,x2_test,y2_test)","67e142e7":"get_results_binary(dt_clf2,'Decision Tree - Binary Classification',x2_train,y2_train,x2_test,y2_test)","3a3eda87":"# import visualization libraries\nfrom IPython.display import Image  \nimport pydotplus\nfrom sklearn.externals.six import StringIO\nfrom sklearn import tree","6079b3f2":"# Multi-class\nfeature_names = np.array(features)\ntarget_names = ['Level 1','Level 2','Level 3']\n\ndot_data = tree.export_graphviz(dt_clf, out_file=None,\n                         feature_names=feature_names,\n                         class_names=target_names,  \n                         filled=True, rounded=True,  \n                         special_characters=True)  \ngraph = pydotplus.graph_from_dot_data(dot_data)  \ngraph.write_png(\"wine_dt_1.png\")\nImage(graph.create_png()) ","44ea1af5":"# Binary\nfeature_names2 = np.array(features)\ntarget_names2 = ['Bad','Good']\n\ndot_data = tree.export_graphviz(dt_clf2, out_file=None,\n                         feature_names=feature_names2,\n                         class_names=target_names2,  \n                         filled=True, rounded=True,  \n                         special_characters=True)  \ngraph = pydotplus.graph_from_dot_data(dot_data)  \ngraph.write_png(\"wine_dt_2.png\")\nImage(graph.create_png()) ","4e7fb073":"rf_clf = RandomForestClassifier(random_state = 42,\n                                criterion = 'entropy', \n                                max_depth=6,\n                                min_samples_leaf = 2,\n                                n_estimators = 150)\nrf_clf.fit(x_train, y_train)","fbc07369":"print_predict_vs_test_multi(rf_clf,x_test,y_test)","582a40a6":"get_results_multi(rf_clf,'Random Forest - Multiclass Classification',x_train,y_train,x_test,y_test)","6a4917c8":"rf_clf2 = RandomForestClassifier(random_state = 42,\n                                 criterion = 'entropy',                             \n                                 min_samples_leaf = 2,\n                                 max_depth=7,\n                                 n_estimators = 175)\nrf_clf2.fit(x2_train, y2_train)","978fdbac":"print_predict_vs_test_binary(rf_clf2,x2_test,y2_test)","4145524b":"get_results_binary(rf_clf2,'Random Forest - Binary Classification',x2_train,y2_train,x2_test,y2_test)","4e9d3c3a":"xgb_clf = XGBClassifier(random_state = 42, learning_rate = 0.08)\nxgb_clf.fit(x_train, y_train)","259fcc50":"print_predict_vs_test_multi(xgb_clf,x_test,y_test)","1b2f31d6":"get_results_multi(xgb_clf,'XGBoost - Multiclass Classification',x_train,y_train,x_test,y_test)","4d900df4":"xgb_clf2 = XGBClassifier(random_state = 42, \n                        learning_rate = 0.06,                                \n                                  )\nxgb_clf2.fit(x2_train, y2_train)","de6afef7":"print_predict_vs_test_binary(xgb_clf2,x2_test,y2_test)","ef75ee60":"get_results_binary(xgb_clf2,'XGBoost - Binary Classification',x2_train,y2_train,x2_test,y2_test)","fa911991":"svm_clf = svm.SVC(random_state = 42,gamma='scale',probability=True)\nsvm_clf.fit(x_train, y_train)","6e64e517":"print_predict_vs_test_multi(svm_clf,x_test,y_test)","30cd8ec5":"get_results_multi_withoutFeatureImportance(svm_clf,'SVM - Multiclass Classification',x_train,y_train,x_test,y_test)","efe57ea9":"svm_clf2 = svm.SVC(C = 1,random_state = 42, probability=True, gamma='scale')\nsvm_clf2.fit(x2_train, y2_train)","b813c304":"print_predict_vs_test_binary(svm_clf2,x2_test,y2_test)","b1958bca":"get_results_binary_withoutFeatureImportance(svm_clf2,'SVM - Binary Classification',x2_train,y2_train,x2_test,y2_test)","aa4565fc":"knn_clf = KNeighborsClassifier(n_neighbors=10)\nknn_clf.fit(x_train, y_train)","e2093918":"print_predict_vs_test_multi(knn_clf,x_test,y_test)","ebd07b15":"get_results_multi_withoutFeatureImportance(knn_clf,'KNN - Multiclass Classification',x_train,y_train,x_test,y_test)","73d9ac6c":"knn_clf2 = KNeighborsClassifier(n_neighbors=5)\nknn_clf2.fit(x2_train, y2_train)","11bfd0c1":"print_predict_vs_test_binary(knn_clf2,x2_test,y2_test)","2aedb8ab":"get_results_binary_withoutFeatureImportance(knn_clf2,'KNN - Binary Classification',x2_train,y2_train,x2_test,y2_test)","72c471b0":"# Best models for Multiclass and Binary classification: Random Forest and XGBoost\n\ncompare_accuracy(dt_clf,'Decision Tree - Multiclass')\ncompare_accuracy(dt_clf2,'Decision Tree - Binary')\ncompare_accuracy(rf_clf,'Random Forest - Multiclass')\ncompare_accuracy(rf_clf2,'Random Forest - Binary')\ncompare_accuracy(xgb_clf,'XGBoost - Multiclass')\ncompare_accuracy(xgb_clf2,'XGBoost - Binary')\ncompare_accuracy(svm_clf,'SVM - Multiclass')\ncompare_accuracy(svm_clf2,'SVM - Binary')\ncompare_accuracy(knn_clf,'KNN - Multiclass')\ncompare_accuracy(knn_clf2,'KNN - Binary')","bed4f4d6":"### **Content**\n\n* [1 Data Exploration and Processing](#0)\n* [__1.1 Data Exploration and Processing](#0)\n* [2 Modeling for wine quality](#1)\n* [__2.1 Decision Tree Modeling](#1)\n* [__2.2 Random Forest Modeling](#2)\n* [__2.3 XGBoots Modeling](#3)\n* [__2.4 Support Vector Machine (SVM) Modeling](#4)\n* [__2.5 K-Nearest Neighbors (KNN) Modeling](#5)\n\n* [Conclusion](#6)","2e15ba1a":"## 2.2.1 Multi-class Classification","f3925fa2":"## 2.3.2 Binary Classification","85c94b7b":"## 2.1.1 Multi-class Classification","fe28832e":"## 2.5.2 Binary Classification","2ead7ffb":"## 2.2.2 Binary Classification","ceaa33c5":"# 2.4. Support Vector Machine Modeling<a id=\"4\"><\/a> ","9874ccd1":"## 1.3 Data exploration for multi-class classification","6e472253":"## 2.1.3 Decision Tree Classifier Visualizations","bf9b649a":"# 2. Modeling<a id=\"1\"><\/a> ","2552855a":"## 1.1 Data exploration of raw dataset","4679ae5b":"## 2.5.1 Multi-class Classification","7a0dcbd7":"# 2.2. Random Forest Modeling<a id=\"2\"><\/a> ","824780f7":"## 2.4.2 Binary Classification","af7a1857":"## 1.2 Data Processing","5a8ab83b":"# 1. Data Exploration and Processing<a id=\"0\"><\/a> ","95a3a96a":"# Conclusion<a id=\"5\"><\/a> ","b73580b9":"## 1.2 Data exploration for binary classification","771e50ef":"## 2.1.2 Binary Classification","14e40d39":"## 2.3.1 Multi-class Classification","c7b9f58b":"# Wine Quality Prediction","f044fdbb":"# 2.1. Decision Tree Modeling<a id=\"1\"><\/a> ","ae5e0eae":"# 2.5 K-Nearest Neighbors (KNN) Modeling<a id=\"5\"><\/a> ","9556a0e1":"## 2.4.1 Multi-class Classification","96ff9f74":"# 2.3. XGBoots Modeling<a id=\"3\"><\/a> "}}