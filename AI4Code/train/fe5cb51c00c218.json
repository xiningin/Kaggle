{"cell_type":{"b68ac076":"code","af78b8b8":"code","666e3dab":"code","07332cde":"code","7040c880":"code","37d052b8":"code","bad524ab":"code","a600a195":"markdown","347e6d9c":"markdown","522514e5":"markdown","cb7b9538":"markdown","9a48730a":"markdown"},"source":{"b68ac076":"import nltk\nimport numpy as np\nimport random\nimport string","af78b8b8":"f=open('\/kaggle\/input\/cafe-chatbot-dataset\/conversationo.csv','r',errors = 'ignore')\nraw=f.read()\nraw=raw.lower()# converts to lowercase\nnltk.download('punkt') # first-time use only\nnltk.download('wordnet') # first-time use only\nsent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \nword_tokens = nltk.word_tokenize(raw)# converts to list of words","666e3dab":"lemmer = nltk.stem.WordNetLemmatizer()\ndef LemTokens(tokens):\n    return [lemmer.lemmatize(token) for token in tokens]\nremove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\ndef LemNormalize(text):\n    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n","07332cde":"GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\nGREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\ndef greeting(sentence):\n \n    for word in sentence.split():\n        if word.lower() in GREETING_INPUTS:\n            return random.choice(GREETING_RESPONSES)\n","7040c880":"from sklearn.feature_extraction.text import TfidfVectorizer # which is to convert a collection of raw documents to a matrix of TF-IDF features.\nfrom sklearn.metrics.pairwise import cosine_similarity #Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space","37d052b8":"def response(user_response):\n    robo_response=''\n    sent_tokens.append(user_response)\n    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n    tfidf = TfidfVec.fit_transform(sent_tokens)\n    vals = cosine_similarity(tfidf[-1], tfidf)\n    idx=vals.argsort()[0][-2]\n    flat = vals.flatten()\n    flat.sort()\n    req_tfidf = flat[-2]\n    if(req_tfidf==0):\n        robo_response=robo_response+\"I am sorry! I don't understand you\"\n        return robo_response\n    else:\n        robo_response = robo_response+sent_tokens[idx]\n        return robo_response","bad524ab":"flag=True\nprint(\"Cafebot: My name is Cafebot. I will answer your queries about Cafe. If you want to exit, type Bye!\")\nwhile(flag==True):\n    user_response = input()\n    user_response=user_response.lower()\n    if(user_response!='bye'):\n        if(user_response=='thanks' or user_response=='thank you' ):\n            flag=False\n            print(\"Cafebot: You are welcome..\")\n        else:\n            if(greeting(user_response)!=None):\n                print(\"Cafebot: \"+greeting(user_response))\n            else:\n                print(\"Cafebot: \",end=\"\")\n                print(response(user_response))\n                sent_tokens.remove(user_response)\n    else:\n        flag=False\n        print(\"ROBO: Bye! take care..\")","a600a195":"# Reading in the data","347e6d9c":"We will read in the corpus.txt file and convert the entire corpus into a list of sentences and a list of words for further pre-processing.","522514e5":"We shall now define a function called LemTokens which will take as input the tokens and return normalized tokens.","cb7b9538":"# Pre-processing the raw text","9a48730a":"# Importing the necessary libraries"}}