{"cell_type":{"cdd8e50f":"code","05e99bd4":"code","717cb073":"code","3a3f7b4b":"code","d6ada7fa":"code","0324ae56":"code","7225209b":"code","87bb6e4b":"code","d37177d2":"code","ca5c9b60":"code","ae7c4c98":"code","677fce1f":"markdown","55fef5ea":"markdown","898df15c":"markdown","f6914cd7":"markdown","8268fb64":"markdown","be97d4a7":"markdown","f6f0230c":"markdown","d4e29176":"markdown"},"source":{"cdd8e50f":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport PIL # to open and display image\nfrom PIL import Image\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.models import Sequential \nfrom tensorflow.keras import layers\n","05e99bd4":"image='..\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA\/person100_bacteria_475.jpeg'\nPIL.Image.open(image)","717cb073":"training_dir='..\/input\/chest-xray-pneumonia\/chest_xray\/train\/'\n#increases amount of data by making diff forms of image\ntraining_generator =ImageDataGenerator(rescale=1\/255,featurewise_center=False,\n         samplewise_center=False, \n         featurewise_std_normalization=False,\n         samplewise_std_normalization=False,\n         zca_whitening =False,\n         rotation_range=30,\n         zoom_range=0.2,\n         width_shift_range=0.1,\n         height_shift_range=0.1,        \n         horizontal_flip=False,\n         vertical_flip=False)\n                                      \ntraining_generator=training_generator.flow_from_directory(\n          training_dir,target_size=(200,200),batch_size=4,class_mode='binary')\n                                                                        \n                                      \n                                      \n                                      \n                                      \n    ","3a3f7b4b":"validation_dir='..\/input\/chest-xray-pneumonia\/chest_xray\/val'\nvalidation_generator=ImageDataGenerator(rescale=1\/255)\nval_generator=validation_generator.flow_from_directory(\n    validation_dir, target_size=(200,200),batch_size=4,class_mode='binary')\n\n","d6ada7fa":"test_dir=\"..\/input\/chest-xray-pneumonia\/chest_xray\/test\"\ntest_generator=ImageDataGenerator(rescale=1\/255)\ntest_generator=test_generator.flow_from_directory(test_dir,target_size=(200,200),batch_size=16,class_mode='binary')\n","0324ae56":"model=Sequential()\n\n#Conv2D=(filters,(kernels),filter_size,input image_shape,activation method) -convoluation layer\n#MaxPooling2D- (size of pooling window) -pooling layer\n#Dropout -(dropout percentage) -drops random edges in the data -> prevents overfitting\n#Flatten- flatten output of pooling layer into one vector\n#Dense-   (uints, activation method) - dense layer to condense\n\nmodel.add(layers.Conv2D(32,(3,3),input_shape=(200,200,3),activation='relu'))\nmodel.add(layers.MaxPooling2D(2,2))\n\nmodel.add(layers.Conv2D(64,(3,3),activation='relu'))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Dropout(0.2))\n\n# model.add(layers.Conv2D(128,(3,3),activation='relu'))\n# model.add(layers.MaxPooling2D(2,2))\n# model.add(layers.Dropout(0.2))\n\n\nmodel.add(layers.Conv2D(128,(3,3),activation='relu'))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Dropout(0.2))\n\nmodel.add(layers.Conv2D(256,(3,3), activation='relu'))\nmodel.add(layers.MaxPooling2D(2,2))\n\n# model.add(layers.Conv2D(512,(3,3), activation='relu'))\n# model.add(layers.MaxPooling2D(2,2))\n\n# model.add(layers.Conv2D(1024,(3,3), activation='relu'))\n# model.add(layers.MaxPooling2D(2,2))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(256,activation='relu'))\nmodel.add(layers.Dense(1,activation='sigmoid'))\n\n","7225209b":"model.summary()","87bb6e4b":"model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy',metrics=['acc'])","d37177d2":"#Fitting the model-  train data generator from before, validation data, \n# epochs (how many times the algorithm runs on the data),\n# verbose - gives animated progress bar e.g verbose=1\n\nhistory=model.fit_generator(training_generator,\n                           validation_data=val_generator,\n                           epochs=10,\n                           verbose=1)","ca5c9b60":"acc=history.history['acc']\nval_acc=history.history['val_acc']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc))\n\nplt.plot(epochs,acc,'r',label='Training Accuracy')\nplt.plot(epochs,val_acc,'b', label='Validation Accuracy')\nplt.title('Traning and Validation Accuracy Graph')\nplt.legend()\nplt.figure()\n","ae7c4c98":"print('loss of the model is :',model.evaluate(test_generator)[0]*100,'%')\nprint('accuracy of the model is: ',model.evaluate(test_generator)[1]*100, '%')","677fce1f":"# **Validation Data**\n\n## Validation data is using for evaluation of the model","55fef5ea":"# **Testing The Model**","898df15c":"# **Data Preprocessing** ","f6914cd7":"# **THE END**","8268fb64":"# **Compiling The Model**","be97d4a7":"## **Data Training**","f6f0230c":"# **Create The CNN Model**","d4e29176":"# **Testing Data**"}}