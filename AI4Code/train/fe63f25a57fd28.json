{"cell_type":{"6d450865":"code","6381b121":"code","17150d8c":"code","46844813":"code","7da82275":"code","981c9d4a":"code","1c05a360":"code","f2286aa8":"code","84c05dbf":"code","faedb777":"code","1fe028d8":"code","3fab9002":"code","3be0c50b":"code","59144475":"code","1ae04b3e":"code","5b4c8fd1":"code","c61d4091":"code","71d97c5d":"markdown","cb6762fd":"markdown","036ca209":"markdown"},"source":{"6d450865":"# First, we are going to load the file names and their respective target labels into numpy array! \nfrom sklearn.datasets import load_files\nimport numpy as np\nimport os\ntrain_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/train'\ntest_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/test'\nprint(\"Training PNEUMONIA data:\",len(os.listdir(train_dir+'\/'+'PNEUMONIA')))\nprint(\"Training NORMAL data:\",len(os.listdir(train_dir+'\/'+'NORMAL')))\nprint(\"Testing PNEUMONIA data:\",len(os.listdir(test_dir+'\/'+'PNEUMONIA')))\nprint(\"Testing NORMALdata:\",len(os.listdir(test_dir+'\/'+'NORMAL')))","6381b121":"import tensorflow as tf\ndevice_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","17150d8c":"import tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport os","46844813":"train_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# Flow training images in batches of 32 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(64, 64),\n        batch_size=32,\n        class_mode='binary')\n\n# Flow validation images in batches of 32 using test_datagen generator\nvalidation_generator = test_datagen.flow_from_directory(\n        test_dir,\n        target_size=(64, 64),\n        batch_size=32,\n        class_mode='binary')","7da82275":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('accuracy') > 0.98 ):\n            print(\"\\nReached 98% accuracy so cancelling training!\")\n            self.model.stop_training = True ","981c9d4a":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.summary()","1c05a360":"model.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\nprint('Compiled!')","f2286aa8":"callbacks = myCallback()\nhistory = model.fit(train_generator,\n        batch_size = 80,\n        epochs=30,\n        validation_data=validation_generator,\n        callbacks=[callbacks],\n        verbose=1, shuffle=True)","84c05dbf":"import matplotlib.pyplot as plt \nplt.figure(1)  \n# summarize history for accuracy  \nplt.subplot(211)  \nplt.plot(history.history['accuracy'])  \nplt.plot(history.history['val_accuracy'])  \nplt.title('model accuracy')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'test'], loc='upper left')  \n   \n # summarize history for loss  \n   \nplt.subplot(212)  \nplt.plot(history.history['loss'])  \nplt.plot(history.history['val_loss'])  \nplt.title('model loss')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'test'], loc='upper left')  \nplt.show()\n","faedb777":"# First, we are going to load the file names and their respective target labels into numpy array! \n\nval_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/val'\n\npred_set = ImageDataGenerator(rescale = 1.\/255)\npred_set = pred_set.flow_from_directory(\n                            val_dir,\n                            target_size = (64, 64),\n                            batch_size = 32,\n                            class_mode = 'binary')","1fe028d8":"pred=model.predict(pred_set)","3fab9002":"y_pred=[]\nfor i in pred:\n    if i>= 0.5:\n        y_pred.append(1)\n    else:\n        y_pred.append(0)","3be0c50b":"# First, we are going to load the file names and their respective target labels into numpy array! \nfrom sklearn.datasets import load_files\nimport numpy as np\n\ntest_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/val'\n\ndef load_dataset(path):\n    data = load_files(path)\n    files = np.array(data['filenames'])\n    targets = np.array(data['target'])\n    target_labels = np.array(data['target_names'])\n    return files,targets,target_labels\n    \nx_test, y_test,target_labels = load_dataset(test_dir)","59144475":"# We just have the file names in the x set. Let's load the images and convert them into array.\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img\nimport cv2\ndef convert_image_to_array(files):\n    images_as_array=[]\n    for file in files:\n        # Convert to Numpy Array\n        img = cv2.imread(file)\n        img=cv2.resize(img, (150, 150)) \n        images_as_array.append(img_to_array(img))\n    return images_as_array\n\nx_test = np.array(convert_image_to_array(x_test))\nprint('Test set shape : ',x_test.shape)","1ae04b3e":"y_test=y_test.tolist()","5b4c8fd1":"x_test = x_test.astype('float32')\/255","c61d4091":"# Let's visualize test prediction.\n\n# plot a random sample of test images, their predicted labels, and ground truth\nfig = plt.figure(figsize=(16, 9))\nfor i, idx in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):\n    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(x_test[idx]))\n    pred_idx = y_pred[idx]\n    true_idx = y_test[idx]\n    ax.set_title(\"{} ({})\".format(target_labels[pred_idx], target_labels[true_idx]),\n                 color=(\"green\" if pred_idx == true_idx else \"red\"))","71d97c5d":"## Visualization validation data result","cb6762fd":"# It's always wise decision to give some augmentation to the datasets","036ca209":"## Stop training when accuracy reach at 98%"}}