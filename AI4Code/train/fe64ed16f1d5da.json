{"cell_type":{"fd231503":"code","15a1d4e1":"code","95b0f16e":"code","17603b42":"code","9d69aaaa":"code","c71265eb":"code","957d4f9e":"code","b6790c48":"code","8e23de33":"code","4b49df75":"markdown"},"source":{"fd231503":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport shutil\nimport tensorflow as tf\nimport pathlib\nimport PIL\nimport time\nimport zipfile\nimport random\nfrom tensorflow.keras.layers import *","15a1d4e1":"import warnings\nwarnings.filterwarnings('ignore')","95b0f16e":"MAIN_PATH = '..\/input\/facemask-dataset\/dataset\/dataset'\n\nCLASSES = os.listdir(MAIN_PATH)\nNUM_CLASSES = 2\nHEIGHT,WIDTH = 32,32\nBATCH_SIZE = 32\nSPLIT = 0.2","17603b42":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=20,\n    horizontal_flip=True,\n    validation_split=SPLIT)\n\ntrain_ds = train_datagen.flow_from_directory(\n    MAIN_PATH,\n    target_size = (HEIGHT,WIDTH),\n    batch_size = BATCH_SIZE,\n    subset = \"training\",\n    class_mode = \"categorical\",\n    shuffle = True\n)\n\nval_ds = train_datagen.flow_from_directory(\n    MAIN_PATH,\n    target_size = (HEIGHT,WIDTH),\n    batch_size = BATCH_SIZE,\n    subset = \"validation\",\n    class_mode = \"categorical\",\n    shuffle = True\n)","9d69aaaa":"def create_model():\n    vgg16 = tf.keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=[HEIGHT,WIDTH, 3])\n            \n    x = vgg16.output\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.3) (x)\n    x = tf.keras.layers.Dense(128) (x)\n    x = tf.keras.layers.LeakyReLU(alpha=0.2) (x)\n    x = tf.keras.layers.GaussianDropout(0.4) (x)\n    outputs = tf.keras.layers.Dense(NUM_CLASSES,activation=\"sigmoid\", dtype='float32')(x)\n        \n    model = tf.keras.Model(vgg16.input, outputs)\n    return model\n\nmodel = create_model()\nmodel.summary()","c71265eb":"def compile_model(model, lr=0.0001):\n    \n    optimizer = tf.keras.optimizers.Adam(lr=1e-4)\n    \n    loss = tf.keras.losses.BinaryCrossentropy()\n        \n    metrics = [\n       tf.keras.metrics.BinaryAccuracy(name='accuracy')\n    ]\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","957d4f9e":"def create_callbacks():\n    \n    cpk_path = '.\/best_model.h5'\n    \n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=cpk_path,\n        monitor='val_accuracy',\n        mode='max',\n        save_best_only=True,\n        verbose=1,\n    )\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_accuracy',\n        mode='max',\n        factor=0.1,\n        patience=3,\n        verbose=0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_accuracy',\n        mode='max',\n        patience=10, \n        verbose=1\n    )\n    \n    callbacks = [checkpoint, reducelr, earlystop]         \n    \n    return callbacks","b6790c48":"EPOCHS= 60\nVERBOSE =1\n\ntf.keras.backend.clear_session()\n\nwith tf.device('\/device:GPU:0'):\n    \n    model = create_model()\n    model = compile_model(model, lr=0.0001)\n   \n    callbacks = create_callbacks()\n    \n    history = model.fit(train_ds, \n                        epochs=EPOCHS,\n                        callbacks=callbacks,\n                        validation_data = val_ds,\n                        verbose=VERBOSE)","8e23de33":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(history.history['val_loss']))\nplt.figure(figsize=(15, 10))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Binary Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Binary Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Binary Accuracy')\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","4b49df75":"It is very difficlut for us to enter shop or restaurant without wearing mask. On the other hand, checking wearing mask is heavy burden for shop or restaurant. So AI will help them to identify mask wearing automatically.\n\n![Mask-Mandate.png](attachment:4f756ba8-28a3-417f-b45c-c9a3cd454eb5.png)\n\npicture from https:\/\/www.detroitchamber.com\/covid19\/download-no-mask-no-entry-signs-in-multiple-languages\/\n\nI tried VGG16 by refering to Note Book 'Traffic Sign Recognition' https:\/\/www.kaggle.com\/shanmukh05\/traffic-sign-recognition to use basic TensorFlow framework. Thank you very much for sharing 'Traffic Sign Recognition' Note Book !"}}