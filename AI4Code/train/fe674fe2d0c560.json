{"cell_type":{"8d3b304e":"code","b46f5499":"code","e1a1782b":"code","f7cda2f8":"code","a3876068":"code","01e1bb03":"code","1c6b5bcb":"code","88fa155a":"code","65150969":"code","d5069e06":"code","7d8691f3":"code","7e8b7af0":"code","7f7daf29":"code","04619e0c":"code","9bf9ff7b":"code","d1671d66":"code","abb42941":"code","b13b66cb":"code","ccbb1e6c":"code","10310aaa":"code","f20a6585":"code","43d41d65":"code","9318210a":"code","cf805dc5":"code","fd1e579e":"code","8c11d2d6":"code","c4f1e5f6":"code","5615a4ad":"code","9e12f936":"code","5778b71e":"code","2203f1c2":"code","275afefe":"code","81dd9915":"code","33163625":"code","702e6a22":"code","a47d6326":"code","af376b7f":"code","f5c0c764":"code","52df2a34":"code","0ce09e67":"code","94c48026":"code","591ed47a":"code","53983b48":"code","a2e269d9":"code","4599bf86":"code","ea5d8bf1":"code","83c43317":"markdown","2ca104ca":"markdown","ca3ffc45":"markdown","2cd9f180":"markdown","d1bdc2d5":"markdown","92ced392":"markdown","417fa8d9":"markdown","edba0b9f":"markdown","d7f0bedc":"markdown","db7f08a1":"markdown","2c0b6596":"markdown","5d4a9593":"markdown","1791d2b1":"markdown","b1524bbc":"markdown","0ae013af":"markdown","3961919d":"markdown","b753fbd1":"markdown","51311230":"markdown","e1228d83":"markdown","6a4887e4":"markdown","3e865c4e":"markdown","45fcc149":"markdown","6d2ab4f2":"markdown","d11f15ec":"markdown","51ee3997":"markdown","0138ebb0":"markdown","1fff6d56":"markdown","5b69f0d5":"markdown","9a8adaef":"markdown","ad5a771c":"markdown","33a2968e":"markdown"},"source":{"8d3b304e":"# Import packages\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nimport sklearn.metrics as metrics\nimport math","b46f5499":"sample_submission = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\n#Creating a copy of the train and test datasets\nc_test  = test.copy()\nc_train  = train.copy()\n","e1a1782b":"c_train.head()","f7cda2f8":"c_test.head()","a3876068":"c_train['train']  = 1\nc_test['train']  = 0\ndf = pd.concat([c_train, c_test], axis=0,sort=False,ignore_index=True)\n# df.iloc[0:50,1] = np.NaN\ndf\n","01e1bb03":"#Percentage of NAN Values \nNAN = [(c, df[c].isna().mean()*100) for c in df]\n# NAN = df['MSSubClass'].isna()\n# NAN2 = df['MSSubClass'].isna().mean()\nNAN = pd.DataFrame(NAN, columns=[\"column_name\", \"percentage\"])\nprint(NAN)\n# print(NAN2)\n# print(type(NAN))\n# print(type(NAN2))","1c6b5bcb":"NAN = NAN[NAN.percentage > 50]\nNAN.sort_values(\"percentage\", ascending=False)\nprint(NAN)","88fa155a":"#Drop PoolQC, MiscFeature, Alley and Fence features\ndf = df.drop(['Alley','PoolQC','Fence','MiscFeature'],axis=1)","65150969":"object_columns_df = df.select_dtypes(include=['object'])\nnumerical_columns_df =df.select_dtypes(exclude=['object'])\nobject_columns_df ","d5069e06":"numerical_columns_df","7d8691f3":"object_columns_df.dtypes","7e8b7af0":"numerical_columns_df.dtypes","7f7daf29":"#Number of null values in each feature\nnull_counts = object_columns_df.isnull().sum()\nprint(\"Number of null values in each column:\\n{}\".format(null_counts))","04619e0c":"columns_None = ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','GarageType','GarageFinish','GarageQual','FireplaceQu','GarageCond']\nobject_columns_df[columns_None]= object_columns_df[columns_None].fillna('None')\nobject_columns_df","9bf9ff7b":"columns_with_lowNA = ['MSZoning','Utilities','Exterior1st','Exterior2nd','MasVnrType','Electrical','KitchenQual','Functional','SaleType']\n#fill missing values for each column (using its own most frequent value)\nobject_columns_df[columns_with_lowNA] = object_columns_df[columns_with_lowNA].fillna(object_columns_df.mode().iloc[0])\n","d1671d66":"#Number of null values in each feature\nnull_counts = numerical_columns_df.isnull().sum()\nprint(\"Number of null values in each column:\\n{}\".format(null_counts))\n","abb42941":"print((numerical_columns_df['YrSold']-numerical_columns_df['YearBuilt']).median())\nprint(numerical_columns_df[\"LotFrontage\"].median())\nprint(numerical_columns_df['YrSold'])\nprint(numerical_columns_df['YearBuilt'])","b13b66cb":"numerical_columns_df['GarageYrBlt'] = numerical_columns_df['GarageYrBlt'].fillna(numerical_columns_df['YrSold']-35)\nnumerical_columns_df['LotFrontage'] = numerical_columns_df['LotFrontage'].fillna(68)\n","ccbb1e6c":"numerical_columns_df= numerical_columns_df.fillna(0)\n","10310aaa":"object_columns_df['Utilities'].value_counts().plot(kind='bar',figsize=[8,3])\nobject_columns_df['Utilities'].value_counts() \n","f20a6585":"object_columns_df['Street'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['Street'].value_counts() ","43d41d65":"object_columns_df['Condition2'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['Condition2'].value_counts() \n","9318210a":"object_columns_df['RoofMatl'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['RoofMatl'].value_counts() ","cf805dc5":"object_columns_df['Heating'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['Heating'].value_counts() #======> Drop feature one Type\n","fd1e579e":"object_columns_df = object_columns_df.drop(['Heating','RoofMatl','Condition2','Street','Utilities'],axis=1)\n","8c11d2d6":"numerical_columns_df['Age_House']= (numerical_columns_df['YrSold']-numerical_columns_df['YearBuilt'])\nnumerical_columns_df['Age_House'].describe()\n","c4f1e5f6":"Negatif = numerical_columns_df[numerical_columns_df['Age_House'] < 0]\nNegatif\n","5615a4ad":"numerical_columns_df.loc[numerical_columns_df['YrSold'] < numerical_columns_df['YearBuilt'],'YrSold' ] = 2009\nnumerical_columns_df['Age_House']= (numerical_columns_df['YrSold']-numerical_columns_df['YearBuilt'])\nnumerical_columns_df['Age_House'].describe()\n","9e12f936":"numerical_columns_df['TotalBsmtBath'] = numerical_columns_df['BsmtFullBath'] + numerical_columns_df['BsmtFullBath']*0.5\nnumerical_columns_df['TotalBath'] = numerical_columns_df['FullBath'] + numerical_columns_df['HalfBath']*0.5 \nnumerical_columns_df['TotalSA']=numerical_columns_df['TotalBsmtSF'] + numerical_columns_df['1stFlrSF'] + numerical_columns_df['2ndFlrSF']\n","5778b71e":"numerical_columns_df.head()","2203f1c2":"object_columns_df.c","275afefe":"bin_map  = {'TA':2,'Gd':3, 'Fa':1,'Ex':4,'Po':1,'None':0,'Y':1,'N':0,'Reg':3,'IR1':2,'IR2':1,'IR3':0,\"None\" : 0,\n            \"No\" : 2, \"Mn\" : 2, \"Av\": 3,\"Gd\" : 4,\"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3,\"BLQ\" : 4, \"ALQ\" : 5, \"GLQ\" : 6\n            }\nobject_columns_df['ExterQual'] = object_columns_df['ExterQual'].map(bin_map)\nobject_columns_df['ExterCond'] = object_columns_df['ExterCond'].map(bin_map)\nobject_columns_df['BsmtCond'] = object_columns_df['BsmtCond'].map(bin_map)\nobject_columns_df['BsmtQual'] = object_columns_df['BsmtQual'].map(bin_map)\nobject_columns_df['HeatingQC'] = object_columns_df['HeatingQC'].map(bin_map)\nobject_columns_df['KitchenQual'] = object_columns_df['KitchenQual'].map(bin_map)\nobject_columns_df['FireplaceQu'] = object_columns_df['FireplaceQu'].map(bin_map)\nobject_columns_df['GarageQual'] = object_columns_df['GarageQual'].map(bin_map)\nobject_columns_df['GarageCond'] = object_columns_df['GarageCond'].map(bin_map)\nobject_columns_df['CentralAir'] = object_columns_df['CentralAir'].map(bin_map)\nobject_columns_df['LotShape'] = object_columns_df['LotShape'].map(bin_map)\nobject_columns_df['BsmtExposure'] = object_columns_df['BsmtExposure'].map(bin_map)\nobject_columns_df['BsmtFinType1'] = object_columns_df['BsmtFinType1'].map(bin_map)\nobject_columns_df['BsmtFinType2'] = object_columns_df['BsmtFinType2'].map(bin_map)\n\nPavedDrive =   {\"N\" : 0, \"P\" : 1, \"Y\" : 2}\nobject_columns_df['PavedDrive'] = object_columns_df['PavedDrive'].map(PavedDrive)\n\n","81dd9915":"object_columns_df","33163625":"#Select categorical features\nrest_object_columns = object_columns_df.select_dtypes(include=['object'])\n#Using One hot encoder\nobject_columns_df = pd.get_dummies(object_columns_df, columns=rest_object_columns.columns) ","702e6a22":"object_columns_df.head()","a47d6326":"df_final = pd.concat([object_columns_df, numerical_columns_df], axis=1,sort=False)\ndf_final.head()","af376b7f":"df_final = df_final.drop(['Id',],axis=1)\n\ndf_train = df_final[df_final['train'] == 1]\ndf_train = df_train.drop(['train',],axis=1)\n\n\ndf_test = df_final[df_final['train'] == 0]\ndf_test = df_test.drop(['SalePrice'],axis=1)\ndf_test = df_test.drop(['train',],axis=1)\n","f5c0c764":"target= df_train['SalePrice']\ndf_train = df_train.drop(['SalePrice'],axis=1)","52df2a34":"x_train,x_test,y_train,y_test = train_test_split(df_train,target,test_size=0.33,random_state=0)","0ce09e67":"\nxgb =XGBRegressor( booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.6, gamma=0,\n             importance_type='gain', learning_rate=0.01, max_delta_step=0,\n             max_depth=4, min_child_weight=1.5, n_estimators=2400,\n             n_jobs=1, nthread=None, objective='reg:linear',\n             reg_alpha=0.6, reg_lambda=0.6, scale_pos_weight=1, \n             silent=None, subsample=0.8, verbosity=1)\n\n\nlgbm = LGBMRegressor(objective='regression', \n                                       num_leaves=4,\n                                       learning_rate=0.01, \n                                       n_estimators=12000, \n                                       max_bin=200, \n                                       bagging_fraction=0.75,\n                                       bagging_freq=5, \n                                       bagging_seed=7,\n                                       feature_fraction=0.4, \n                                       )\n","94c48026":"#Fitting\nxgb.fit(x_train, y_train)\nlgbm.fit(x_train, y_train,eval_metric='rmse')\n","591ed47a":"predict1 = xgb.predict(x_test)\npredict = lgbm.predict(x_test)\n","53983b48":"print('Root Mean Square Error test = ' + str(math.sqrt(metrics.mean_squared_error(y_test, predict1))))\nprint('Root Mean Square Error test = ' + str(math.sqrt(metrics.mean_squared_error(y_test, predict))))\n","a2e269d9":"xgb.fit(df_train, target)\nlgbm.fit(df_train, target,eval_metric='rmse')\n","4599bf86":"predict3 = xgb.predict(df_test)\npredict4 = lgbm.predict(df_test)\npredict_y = ( predict3*0.45 + predict4 * 0.55)\n","ea5d8bf1":"submission = pd.DataFrame({\n        \"Id\": test[\"Id\"],\n        \"SalePrice\": predict_y\n    })\nsubmission.to_csv('submission.csv', index=False)\n","83c43317":"* <font color='black'>  Features with more than 50% of missing values. <\/font>","2ca104ca":"\n* <font color='black'> Like we see here tha the minimun is -1 ??? <font>\n* <font color='black'>It is strange to find that the house was sold in 2007 before the YearRemodAdd 2009.\n\n    So we decide to change the year of sold to 2009 <font>","ca3ffc45":"\n* <font color='black'>  Will we use One hot encoder to encode the rest of categorical features  <font>","2cd9f180":"* <font color='black'>  Now we will select numerical and categorical features  <font>","d1bdc2d5":"\n* <font color='black'>  **Ordinal categories features** - Mapping from 0 to N  <font>","92ced392":"* <font color='black'>   Now we have a clean categorical features <\/font>\n* <font color='black'>   In the next step we will deal with the **numerical** features <\/font>","417fa8d9":"* <font color='black'> **Now we will create some new features**  <font>","edba0b9f":"\n* <font color='black'>  Concat Categorical (after encoding) and numerical features  <font>\n","d7f0bedc":"1. <font color='black'>  Fill GarageYrBlt and LotFrontage <\/font>\n1. <font color='black'>  Fill the rest of columns with 0 <\/font>","db7f08a1":"\n* <font color='black'>  **Categorical Features** :  <font>","2c0b6596":"#  <font color='red'> Data preprocessing <\/font>","5d4a9593":"* <font color='black'>  Getting information about train dataset <\/font>","1791d2b1":"<font color='black'>  Importing **train** and **test** datasets <\/font>","b1524bbc":"\n* <font color='black'>  Concat Train and Test datasets <\/font>\n","0ae013af":"\n* <font color='black'>  Calculating the percentage of missing values of each feature <\/font>\n","3961919d":"* <font color='black'>  We finally end up with a clean dataset  <font>","b753fbd1":"* <font color='black'>  So we will fill the year with 1979 and the Lot frontage with 68 <\/font>\n","51311230":"\n* <font color='black'>  Getting information about test dataset <\/font>\n","e1228d83":"\n* <font color='black'> Fitting With all the dataset <font>","6a4887e4":"\n* <font color='black'>  Now the next step is to encode categorical features  <font>\n","3e865c4e":"\n* <font color='black'>   We will fill -- **BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, GarageType, GarageFinish, GarageQual, FireplaceQu, GarageCond** -- with \"None\" (Take a look in the data description). <\/font>\n* <font color='black'>    We will fill the rest of features with th most frequent value (using its own most frequent value). <\/font>","45fcc149":"\n* <font color='black'>  Separate Train and Targets  <font>","6d2ab4f2":"********\n** <font color='black'>  Deeling with **categorical** feature  <font> **","d11f15ec":"#  <font color='red'> House Prices : Data cleaning, visualization and modeling  <\/font>","51ee3997":"\n* <font color='black'> After making some plots we found that we have some colums with low variance so we decide to delete them  <font>\n","0138ebb0":"* <font color='black'>  We can drop PoolQC, MiscFeature, Alley and Fence features because they have more than 80% of missing values. <font>","1fff6d56":"* <font color='black'>  **Numerical Features** :  <font>","5b69f0d5":"#  <font color='red'> Modeling  <\/font>","9a8adaef":" <font color='black'> 1. We have 81 columns.\n2. Our target variable is SalePrice.\n3. Id is just an index that we can drop but we will need it in the final submission.\n1. We have many missing values <\/font>\n\n\n <font color='red'>   * * * * we have 79 features in our dataset. <\/font>\n\n","ad5a771c":"* <font color='black'> Fill the rest of columns with 0  <font>\n","33a2968e":" <font color='black'> \n* TotalBsmtBath : Sum of :\nBsmtFullBath and  1\/2 BsmtHalfBath\n\n* TotalBath : Sum of :\nFullBath and 1\/2 HalfBath\n\n* TotalSA : Sum of : \n1stFlrSF and 2ndFlrSF and basement area\n<\/font>\n\n\n\n"}}