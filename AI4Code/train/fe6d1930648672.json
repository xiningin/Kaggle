{"cell_type":{"8593b0a8":"code","664553b6":"code","e6facccd":"code","f09f2e53":"code","79680d1f":"code","71afcabc":"code","c72d158f":"code","09653b29":"code","94648d1a":"code","a02d3811":"code","3cbc43a2":"code","0b750a94":"code","e9cfe84b":"code","b2637b48":"code","75fdfd80":"code","c68ae46a":"code","c9dabec1":"code","15894bd7":"code","b623c438":"code","af026c03":"code","3cc321a3":"code","6ef63dfb":"code","428fe3af":"code","9c2803ad":"markdown","f5af84e0":"markdown","f3368c3f":"markdown","13bc66be":"markdown","0111500e":"markdown","bb9f2c6d":"markdown","0b912fcc":"markdown"},"source":{"8593b0a8":"!pip install keract","664553b6":"# IMPORTING LIBRARIES\n\n# Main Libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Libraries for preprocessing\n\nfrom sklearn.utils import class_weight\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n# Libraries for modeling\n\nfrom keras.models import Sequential\nfrom keras.optimizers import RMSprop, Adam\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom keras.layers import Conv2D,Dense,BatchNormalization,Flatten,MaxPooling2D\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\n# Libraries for CNN's visualizations\n\nfrom numpy import expand_dims\nfrom keract import get_activations, display_activations, display_heatmaps\n\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\n\n# Working Directory\n\nwork_dir = '..\/input\/digit-recognizer\/'","e6facccd":"# IMPORT DATA\n\ntrain = pd.read_csv(work_dir + 'train.csv')\ntest = pd.read_csv(work_dir + 'test.csv')\nindex = test.index\n\n# Looking at the data\n\ntrain.head()","f09f2e53":"# Loking at the labels\n\nsns.set_theme(context = 'paper')\n\nplt.figure(figsize = (10,5))\nsns.countplot(train['label'])\nplt.title('Frequency of classes in the data', fontsize = 14)\nplt.xlabel('Classes', fontsize = 12)\nplt.ylabel('Classes Frequency', fontsize = 12)\nplt.show()","79680d1f":"# Transforming the labels with one-hot encoding (from a value to an array of binary values)\n\nlabels = train['label']\nclass_weights = class_weight.compute_class_weight('balanced', np.unique(labels), labels)\nclass_weight_dict = dict(enumerate(class_weights))\nclasses = to_categorical(train['label'], num_classes = 10)\ntrain = train.drop(['label'],axis = 1)\n\n# Reshaping and normalization of train & test images\n\nX_train = train.values.reshape(-1,28,28,1)\/ 255.0 \nX_test = test.values.reshape(-1,28,28,1)\/ 255.0 ","71afcabc":"# Let's check the shape of our dataframes and labels\n\nprint(X_train.shape, X_test.shape)\nprint(classes[0])","c72d158f":"# Let's plot some images\n\nfig, (ax) = plt.subplots(1,5, figsize = (12,8))\n\nax[0].imshow(X_train[0], cmap = 'binary')\nax[1].imshow(X_train[1], cmap = 'binary')\nax[2].imshow(X_train[2], cmap = 'binary')\nax[3].imshow(X_train[3], cmap = 'binary')\nax[4].imshow(X_train[4], cmap = 'binary')\n\nplt.show()","09653b29":"# Let's plot some other images\n\nfig, (ax) = plt.subplots(1,5, figsize = (12,8))\n\nax[0].imshow(X_train[5], cmap = 'binary')\nax[1].imshow(X_train[6], cmap = 'binary')\nax[2].imshow(X_train[7], cmap = 'binary')\nax[3].imshow(X_train[8], cmap = 'binary')\nax[4].imshow(X_train[9], cmap = 'binary')\n\nplt.show()","94648d1a":"# Let's plot some other images\n\nfig, (ax) = plt.subplots(1,5, figsize = (12,8))\n\nax[0].imshow(X_train[10], cmap = 'binary')\nax[1].imshow(X_train[11], cmap = 'binary')\nax[2].imshow(X_train[12], cmap = 'binary')\nax[3].imshow(X_train[13], cmap = 'binary')\nax[4].imshow(X_train[14], cmap = 'binary')\n\nplt.show()","a02d3811":"# Split the train and the validation set for the fitting\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, classes,\n                                                  test_size = 0.05,\n                                                  stratify = classes,\n                                                  random_state=42)\n","3cbc43a2":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen_train = ImageDataGenerator(\n    horizontal_flip= True,\n    rotation_range= 10,\n    zoom_range = 0.1,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1)\n    #brightness_range = 0.1)\n\ndatagen_val = ImageDataGenerator()\n\ntrain_generator = datagen_train.flow(X_train, y_train, batch_size = 32)\nval_generator = datagen_val.flow(X_val, y_val, batch_size = 32)","0b750a94":"# define the cnn model for the cifar10 dataset \n\ndef define_model():\n    \n    # Define model\n    \n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), activation='relu', padding='same',kernel_initializer='he_uniform', input_shape=[28, 28, 1]))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(64, (3, 3), activation='relu', padding='same',kernel_initializer='he_uniform'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(BatchNormalization())\n    model.add(Dense(10, activation='softmax'))\n    \n    # Compile model\n    \n    model.compile(optimizer= Adam(learning_rate = 1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\ndigit_model = define_model()\ndigit_model.summary()","e9cfe84b":"# Callbacks creation\n\nes = EarlyStopping(monitor='val_loss', mode='min', patience=5,\n                       restore_best_weights=True, verbose=1)\n\n\n# Fit model\n\nhistory = digit_model.fit(train_generator,\n                    validation_data = val_generator,\n                    epochs = 50,\n                    batch_size = 100,\n                    class_weight = class_weight_dict,\n                    callbacks = [es],\n                    verbose = 1)","b2637b48":"# PLOTTING RESULTS (Train vs Validation FOLDER 1)\n\ndef Train_Val_Plot(acc,val_acc,loss,val_loss):\n    \n    fig, (ax1, ax2) = plt.subplots(1,2, figsize= (15,6))\n    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \", fontsize=18)\n\n    ax1.plot(range(1, len(acc) + 1), acc)\n    ax1.plot(range(1, len(val_acc) + 1), val_acc)\n    ax1.set_title('History of Accuracy', fontsize=15)\n    ax1.set_xlabel('Epochs', fontsize=15)\n    ax1.set_ylabel('Accuracy', fontsize=15)\n    ax1.legend(['training', 'validation'])\n\n\n    ax2.plot(range(1, len(loss) + 1), loss)\n    ax2.plot(range(1, len(val_loss) + 1), val_loss)\n    ax2.set_title('History of Loss', fontsize=15)\n    ax2.set_xlabel('Epochs', fontsize=15)\n    ax2.set_ylabel('Loss', fontsize=15)\n    ax2.legend(['training', 'validation'])\n    \n    plt.show()\n    \n\nTrain_Val_Plot(history.history['accuracy'],history.history['val_accuracy'],\n               history.history['loss'],history.history['val_loss'])","75fdfd80":"# Using the model to make predictions\n\npred_val_raw = digit_model.predict(X_val)\ny_val = np.argmax(y_val,axis = 1)\npred_val = np.argmax(pred_val_raw,axis = 1)\nprint(pred_val)\nprint(y_val)","c68ae46a":"# Let's look at some predictions\n\nfig, (ax) = plt.subplots(1,5, figsize = (12,8))\n\nax[0].imshow(X_val[0], cmap = 'binary')\nax[0].set_title('Prediction: ' + str(pred_val[0]))\nax[1].imshow(X_val[1], cmap = 'binary')\nax[1].set_title('Prediction: ' + str(pred_val[1]))\nax[2].imshow(X_val[2], cmap = 'binary')\nax[2].set_title('Prediction: ' + str(pred_val[2]))\nax[3].imshow(X_val[3], cmap = 'binary')\nax[3].set_title('Prediction: ' + str(pred_val[3]))\nax[4].imshow(X_val[4], cmap = 'binary')\nax[4].set_title('Prediction: ' + str(pred_val[4]))\nplt.show()","c9dabec1":"# Plotting the confusion matrix of the results\n\nconf_mx = confusion_matrix(y_val,pred_val)\n\nheat_cm = pd.DataFrame(conf_mx, columns=np.unique(y_val), index = np.unique(y_val))\nheat_cm.index.name = 'Actual'\nheat_cm.columns.name = 'Predicted'\nplt.figure(figsize = (10,8))\nsns.set(font_scale=1.4) # For label size\nsns.heatmap(heat_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16},fmt='g')# font size\nplt.show()","15894bd7":"# Plotting the classification report\n\nprint(classification_report(y_val, pred_val))","b623c438":"index = list(range(1,len(X_test) + 1))\nsubmission = pd.DataFrame(index, columns = ['ImageId'])\npred_raw = digit_model.predict(X_test)\npred = np.argmax(pred_raw,axis = 1)\nsubmission['Label'] = pred\nsubmission.head()","af026c03":"# Saving the csv with predictions\n\nsubmission.to_csv(\"result.csv\", index = False, header = True)","3cc321a3":"#TTA\n\n# from keras.preprocessing.image import ImageDataGenerator\n# from PIL import Image\n\n# # Test Time Augmentation Predictions\n\n# def tta_prediction(datagen, model, image, n_examples):\n#     # convert image into dataset\n#     samples = expand_dims(image, 0)\n#     # prepare iterator\n#     it = datagen.flow(samples, batch_size=n_examples)\n#     # make predictions for each augmented image\n#     yhats = model.predict_generator(it, steps=n_examples, verbose=0)\n#     # sum across predictions\n#     summed = np.sum(yhats, axis=0)\n#     # argmax across classes\n#     return np.argmax(summed)\n\n# def tta_evaluate_model(model, X_test):\n#     # configure image data augmentation\n#     datagen = ImageDataGenerator(horizontal_flip=True)\n#     # define the number of augmented images to generate per test set image\n#     n_examples_per_image = 2\n#     yhats = list()\n#     for i in range(len(X_test)):\n#         # make augmented prediction\n#         yhat = tta_prediction(datagen, digit_model, X_test[i], n_examples_per_image)\n#         # store for evaluation\n#         yhats.append(yhat)\n\n#     return y_hats\n\n# predictions = tta_evaluate_model(digit_model,X_test)\n#predictions ","6ef63dfb":"# Summarizing CNNs' layers shapes:\n\nfor i in range(len(digit_model.layers)):\n    layer = digit_model.layers[i]\n    # check for convolutional layer\n    if 'conv' not in layer.name:\n        continue\n    # summarize output shape\n    print(i, layer.name, layer.output.shape)","428fe3af":"# Keract visualizations\n\n# =============================================\n\nkeract_inputs = X_test[:1]\nkeract_targets = X_test[:1]\nactivations = get_activations(digit_model, keract_inputs)\ndisplay_heatmaps(activations, keract_inputs, save=False)","9c2803ad":"MODELING","f5af84e0":"Knowing how our labels are distributed in the dataset is a crucial step in classification tasks because balanced (almost the same distribution for each class) and unbalanced (mismatch in class' distribution) datasets are treated differently. Here we are lucky and the plot below shows how our classes (digits) are similarly represented in the data.","f3368c3f":"## CNN visualizations\n\n\nThe feature maps (also known as activation maps) that result from applying filters to input images and to feature maps output by prior layers could provide insight into the internal representation that the model has of a specific input at a given point in the model. This allows Convolutional Neural Networks to be more understandable. Looking at what CNN's layers see during the learning phase is important for several reasons:\n\n- first, we can see which parts (pixels) of the images are used, layer by layer by the algorithm to arrive to a final prediction.\n\n- second, we can even compare what the model sees with what humans see, comprehending similarities and differences.\n\nSome useful links to better understand CNN functioning can be found here:\n\n- https:\/\/www.cs.ryerson.ca\/~aharley\/vis\/conv\/ (Online Practice)\n- https:\/\/www.cs.ryerson.ca\/~aharley\/vis\/conv\/flat.html (Online Practice)\n\n- https:\/\/poloclub.github.io\/cnn-explainer\/ (Theory)","13bc66be":"**1. IMPORTING & PREPROCESSING OF DATA**\n\nAs for every project, after planning, there is coding. The first part of the coding is the importing of the necessary libraries to use and, of course, of the data.","0111500e":"This is a graphical representation of the model that we are using for the final predictions.\n\n![Model.png](attachment:Model.png)","bb9f2c6d":"## Digit Prediction With Test Time Augmentation\n\nThe main aim of this project is simple: leading image classification\/deep learning beginners in a step by step journey toward the creation of a model able to correctly classify handwritten digits. The project is divided into different steps:\n\n1. *Importing & Preprocessing of Data*\n- *Creation of a Convolutional Neural Network (using Keras)*\n- *Tuning of model's hyperparameters*\n- *Creation of Final Predictions*\n- *Using Test Time Augmentation (TTA) for better predictions*\n- *Visualizing what convolutional layers see*\n\nP.s: If you like this notebook don't forget to **UPVOTE**!","0b912fcc":"The TTA predictions part is coming!"}}