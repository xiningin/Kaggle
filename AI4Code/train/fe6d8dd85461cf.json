{"cell_type":{"dcd47e35":"code","d2499fdc":"code","1a9d30a6":"code","f371faed":"code","6e6acc0b":"code","55c4c2bb":"code","f86d0105":"code","b0fdd02a":"code","3b3ac3a7":"code","4b9ad8cb":"code","5b2e41bd":"code","3cdc3cac":"code","f44b129d":"code","7795137e":"code","4d7d3516":"code","45e6f3c6":"code","957cc935":"code","30715944":"code","5c442e19":"code","77f7be5f":"code","9da1ac51":"code","75590ba3":"code","6dc5b3e9":"code","aa9496a6":"code","abf65955":"code","87cbd2e1":"code","01f7565c":"code","232789e2":"code","d824473f":"code","5b4fd9c5":"code","92452b61":"code","32f2abbe":"code","8644a963":"code","cfd79328":"code","11c42e22":"code","63a86096":"code","8edca5c5":"code","c1a1448b":"code","e2956e1f":"code","e7f17435":"code","0e149f62":"code","e31e6f0a":"code","ce90eb77":"code","30bcf697":"markdown","17c88cdb":"markdown","09325c84":"markdown","56e52dbb":"markdown","b7cc2856":"markdown","07f95d43":"markdown","fe051078":"markdown","2b76f635":"markdown","190ed1fc":"markdown","e4413c9a":"markdown","ef0794b8":"markdown","f03643b4":"markdown","ab5baa94":"markdown"},"source":{"dcd47e35":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport lightgbm as lgbm\nimport eli5\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.tree import DecisionTreeClassifier","d2499fdc":"train_data = pd.read_csv('..\/input\/weather-dataset-rattle-package\/weatherAUS.csv')\ntest_data = pd.read_csv('..\/input\/weather-dataset-rattle-package\/weatherAUS.csv')","1a9d30a6":"train_data.head()","f371faed":"mapping = {'Yes': 1, 'No': 0}\n\ntrain_data = train_data.replace({'RainToday': mapping})\ntrain_data = train_data.replace({'RainTomorrow': mapping})\n\ntest_data = test_data.replace({'RainToday': mapping})","6e6acc0b":"# Drop useless coluns\ncols_to_remove = ['Date', 'Location', 'RISK_MM'] \ntrain_data.drop(cols_to_remove, axis=1, inplace=True)\n\ntest_data.drop(['RainTomorrow'], axis=1, inplace=True)","55c4c2bb":"train_data = train_data.dropna(how='any')\ntest_data = test_data.dropna(how='any')","f86d0105":"numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ncategorical_columns = []\nfeatures = train_data.columns.values.tolist()\nfor col in features:\n    if train_data[col].dtype in numerics: continue\n    categorical_columns.append(col)\nindexer = {}\nfor col in categorical_columns:\n    if train_data[col].dtype in numerics: continue\n    _, indexer[col] = pd.factorize(train_data[col])\n    \nfor col in categorical_columns:\n    if train_data[col].dtype in numerics: continue\n    train_data[col] = indexer[col].get_indexer(train_data[col])","b0fdd02a":"train_data.head()","3b3ac3a7":"train_data.info()","4b9ad8cb":"corr = train_data.corr()\nfig = plt.figure(figsize=(15,10))\nsns.heatmap(corr)","5b2e41bd":"corr.sort_values(by=[\"RainTomorrow\"],ascending=False).iloc[0].sort_values(ascending=False)","3cdc3cac":"plt.figure(figsize=(8,8))\nsns.FacetGrid(train_data, hue=\"RainTomorrow\", size=8).map(sns.kdeplot, \"Humidity3pm\").add_legend()\nplt.ioff() \nplt.show()","f44b129d":"plt.figure(figsize=(8,8))\nsns.countplot(data=train_data,x='RainToday')","7795137e":"plt.figure(figsize=(8,8))\nsns.FacetGrid(train_data, hue=\"RainTomorrow\", size=8).map(sns.kdeplot, \"MinTemp\").add_legend()\nplt.ioff() \nplt.show()","4d7d3516":"plt.figure(figsize=(8,8))\nsns.FacetGrid(train_data, hue=\"RainTomorrow\", size=8).map(sns.kdeplot, \"MaxTemp\").add_legend()\nplt.ioff() \nplt.show()","45e6f3c6":"plt.figure(figsize=(8,8))\nsns.countplot(data=train_data,x='WindGustDir')","957cc935":"plt.figure(figsize=(8,8))\nsns.countplot(data=train_data,x='WindDir9am')","30715944":"y = train_data['RainTomorrow']\ndel train_data['RainTomorrow']\n\nX = train_data;","5c442e19":"# data split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)","77f7be5f":"train_set = lgbm.Dataset(X_train, y_train, silent=False)\nvalid_set = lgbm.Dataset(X_valid, y_valid, silent=False)","9da1ac51":"params = {\n        'boosting_type':'gbdt',\n        'objective': 'regression',\n        'num_leaves': 31,\n        'learning_rate': 0.05,\n        'max_depth': -1,\n        'subsample': 0.8,\n        'bagging_fraction' : 1,\n        'max_bin' : 5000 ,\n        'bagging_freq': 20,\n        'colsample_bytree': 0.6,\n        'metric': 'rmse',\n        'min_split_gain': 0.5,\n        'min_child_weight': 1,\n        'min_child_samples': 10,\n        'scale_pos_weight':1,\n        'zero_as_missing': True,\n        'seed':0,        \n    }\n\nmodelL = lgbm.train(params, train_set = train_set, num_boost_round=1000,\n                   early_stopping_rounds=50,verbose_eval=10, valid_sets=valid_set)","75590ba3":"fig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nlgbm.plot_importance(modelL,ax = axes,height = 0.5)\nplt.show();plt.close()","6dc5b3e9":"feature_score = pd.DataFrame(X.columns, columns = ['feature']) \nfeature_score['score_lgb'] = modelL.feature_importance()","aa9496a6":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X, y)\ncoeff_logreg = pd.DataFrame(X.columns.delete(0))\ncoeff_logreg.columns = ['feature']\ncoeff_logreg[\"score_logreg\"] = pd.Series(logreg.coef_[0])\ncoeff_logreg.sort_values(by='score_logreg', ascending=False)","abf65955":"coeff_logreg[\"score_logreg\"] = coeff_logreg[\"score_logreg\"].abs()\nfeature_score = pd.merge(feature_score, coeff_logreg, on='feature')","87cbd2e1":"eli5.show_weights(logreg)","01f7565c":"# Linear Regression\n\nlinreg = LinearRegression()\nlinreg.fit(X, y)\ncoeff_linreg = pd.DataFrame(X.columns.delete(0))\ncoeff_linreg.columns = ['feature']\ncoeff_linreg[\"score_linreg\"] = pd.Series(linreg.coef_)\ncoeff_linreg.sort_values(by='score_linreg', ascending=False)","232789e2":"eli5.show_weights(linreg)","d824473f":"coeff_linreg[\"score_linreg\"] = coeff_linreg[\"score_linreg\"].abs()","5b4fd9c5":"feature_score = pd.merge(feature_score, coeff_linreg, on='feature')\nfeature_score = feature_score.fillna(0)\nfeature_score = feature_score.set_index('feature')\nfeature_score","92452b61":"feature_score = pd.DataFrame(\n    preprocessing.MinMaxScaler().fit_transform(feature_score),\n    columns=feature_score.columns,\n    index=feature_score.index\n)\n\n# Create mean column\nfeature_score['mean'] = feature_score.mean(axis=1)\n\n# Plot the feature importances\nfeature_score.sort_values('mean', ascending=False).plot(kind='bar', figsize=(20, 10))","32f2abbe":"feature_score['total'] = 0.7*feature_score['score_lgb'] + 0.15*feature_score['score_logreg'] + 0.15*feature_score['score_linreg']\n\n# Plot the feature importances\nfeature_score.sort_values('total', ascending=False).plot(kind='bar', figsize=(20, 10))","8644a963":"feature_score.sort_values('total', ascending=False)","cfd79328":"feature_columns = ['Humidity3pm', 'Pressure3pm', 'WindGustSpeed', 'Pressure9am', 'Sunshine', 'Temp9am']\nX = X[feature_columns];\n\nX.head()","11c42e22":"# data split for train\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)","63a86096":"# Decision Tree Classifier\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\npred = decision_tree.predict(X_valid)\n\nresults = []\nresult = accuracy_score(y_valid, pred) * 100\nresults.append(result)\n\nprint(result)","8edca5c5":"# Extra Trees Classifier\netr = ExtraTreesClassifier(n_estimators=100)\netr.fit(X_train, y_train)\npred = etr.predict(X_valid)\n\nresult = accuracy_score(y_valid, pred) * 100\nresults.append(result)\nprint(result)","c1a1448b":"#random forrest classifier\nclf = RandomForestClassifier(n_estimators=100)\nclf.fit(X_train, y_train)\npred = clf.predict(X_valid)\n\nresult = accuracy_score(y_valid, pred) * 100\nresults.append(result)\nprint(result)","e2956e1f":"x = np.arange(3)\n\nfig, ax = plt.subplots()\nplt.bar(x, results)\nax.set_ylim(bottom=78)\nplt.xticks(x, ('DecisionTree', 'ExtraTrees', 'RandomForest'))\nplt.show()","e7f17435":"clss = ExtraTreesClassifier(n_estimators=100)\nclss.fit(X, y)","0e149f62":"condition = [test_data[feature_columns].mean().values.tolist()]","e31e6f0a":"condition","ce90eb77":"pred = clss.predict(condition)\n\nprint(pred)","30bcf697":"## 6. Testing","17c88cdb":"## 1. Imports","09325c84":"## 2. Download dataset","56e52dbb":"#### FE - https:\/\/www.kaggle.com\/vbmokin\/feature-importance-xgb-lgbm-logreg-linreg\n#### Model tuning - https:\/\/www.kaggle.com\/vbmokin\/titanic-0-83253-comparison-20-popular-models","b7cc2856":"## 4. FE","07f95d43":"## 3. Preparing to analysis","fe051078":"## 5. Model tuning","2b76f635":"### 5.1 DecisionTreeClassifier","190ed1fc":"### 4.3 Logistic Regression","e4413c9a":"### 5.2 ExtraTreesClassifier","ef0794b8":"### 4.1 LGBM","f03643b4":"### 4.2 Logistic Regression","ab5baa94":"### 5.3 RandomForestClassifier"}}