{"cell_type":{"f15fe5d1":"code","6fdc46e0":"code","c8a1ed4c":"code","38016470":"code","704fd0ee":"code","7289c2c0":"code","16ae9302":"code","6417586b":"code","1697e578":"code","8ef32296":"code","e204e68e":"code","a85f009d":"code","1041cf36":"code","a205e34a":"code","8140d7cf":"code","b247309e":"code","b835911b":"code","adfa6a22":"code","114977e4":"code","7716b3aa":"code","00a47b3e":"code","cb3ca8f0":"code","c225bcf2":"code","95df7336":"code","7c815f59":"code","b00f0bed":"markdown","ec7697d4":"markdown","2b81c90f":"markdown","220c15ea":"markdown","8724beeb":"markdown"},"source":{"f15fe5d1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom matplotlib import dates\nimport matplotlib.style as style\n\nimport matplotlib\nimport statsmodels.tsa.api as tsa\n\n%matplotlib inline\n\nmatplotlib.style.use(\"Solarize_Light2\")\n\nfrom pylab import rcParams\nimport statsmodels.api as sm\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=Warning)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6fdc46e0":"df1 = pd.read_csv(\"\/kaggle\/input\/moroccan-darija\/darija-data\/proverbs.csv\", delimiter=',', encoding='utf8')\ndf1.tail(10)","c8a1ed4c":"df = pd.read_csv(\"\/kaggle\/input\/moroccan-darija\/darija-data\/imagenet_b_darija.csv\", delimiter=',', encoding='utf8')\ndf.head()","38016470":"df.isnull().sum()","704fd0ee":"import nltk \nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nimport re\nimport string\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import normalize\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB","7289c2c0":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'red',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"general_darija\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Imagenet General Darija\")\nplt.show()","16ae9302":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'black',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df1[\"darija\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Darija\")\nplt.show()","6417586b":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\ndef removePunctuation(x):\n    x = x.lower()\n    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n    x = x.replace('\\r','')\n    x = x.replace('\\n','')\n    x = x.replace('  ','')\n    x = x.replace('\\'','')\n    return re.sub(\"[\"+string.punctuation+\"]\", \" \", x)","1697e578":"#https:\/\/stackoverflow.com\/questions\/51534586\/add-and-remove-words-from-the-nltk-stopwords-list\n\nfrom nltk.corpus import stopwords\n\nstop_words = set(stopwords.words('english'))\n\n#add words that aren't in the NLTK stopwords list\nnew_stopwords = ['and', 'at', 'so', 'er']\nnew_stopwords_list = stop_words.union(new_stopwords)\n\n#remove words that are in NLTK stopwords list\nnot_stopwords = {'snake', 'lion', 'pigs'} \nfinal_stop_words = set([word for word in new_stopwords_list if word not in not_stopwords])\n\nprint(final_stop_words)","8ef32296":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\ndef processText(x):\n    x= removePunctuation(x)\n    #x= removeStopwords(x)\n    return x","e204e68e":"from nltk.tokenize import sent_tokenize, word_tokenize\ntin = pd.Series([word_tokenize(processText(x)) for x in df1['eng']])\ntin.head(10)","a85f009d":"sentences = [ \"hurry and you will be late\",\"a man bitten by a snake is afraid of rope\", \"he knocks and says who is there\", \"a friend in need is a friend indeed\", \"better luck next time\"]\n\nvocab = [s.encode('utf-8').split() for s in sentences]\n\nvoc_vec = word2vec.Word2Vec(vocab, min_count=1)","1041cf36":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\nfrom gensim.models import word2vec\nnum_features = 300    # Word vector dimensionality                      \nmin_word_count = 4   # Minimum word count #Changed 40 to 4 only avoid build a vocabulary 1st                       \nnum_workers = 4       # Number of threads to run in parallel\ncontext = 10          # Context window size                                                                                    \ndownsampling = 1e-3   # Downsample setting for frequent words\nmodel = word2vec.Word2Vec(tin, workers=num_workers, \n                          min_count = min_word_count,\n                          window = context, sample = downsampling)","a205e34a":"from gensim import utils\nimport logging\nfrom timeit import default_timer\nimport threading\nfrom six.moves import range\nfrom six import itervalues, string_types\nfrom gensim import matutils\nfrom numpy import float32 as REAL, ones, random, dtype\nfrom types import GeneratorType\nfrom gensim.utils import deprecated\nimport os\nimport copy","8140d7cf":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\ndef most_similar(self, positive=None, negative=None, topn=10, restrict_vocab=None, indexer=None):\n        \"\"\"Deprecated, use self.wv.most_similar() instead.\n        Refer to the documentation for :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar`.\n        \"\"\"\n        return self.wv.most_similar(positive, negative, topn, restrict_vocab, indexer)","b247309e":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\n#KeyError: \"Key 'further' not present\"  Any word didn't work her\n\n#model.wv.most_similar('further')","b835911b":"df1[\"darija\"].value_counts()","adfa6a22":"labels = 'zreb t3TTel', 'kaydo99 wigoul chkoun', 'lli khaf nja', 'khirha f ghirha'\nsizes = [1247, 182, 326, 1170]  #must have same number labels, sizes and explode\nexplode = (0, 0.2, 0, 0)  # only \"explode\" the 2nd slice \n\nfig1, ax1 = plt.subplots(figsize=(10,10))\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()","114977e4":"len(df1['darija'].unique())","7716b3aa":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\nfrom nltk.tokenize import sent_tokenize, word_tokenize\ntin = pd.Series([word_tokenize(processText(x)) for x in df1['darija']])\ntin.head(10)","00a47b3e":"sentences = [ \"zreb t3TTel\",\"lli 3DDo l7nch kaykhaf mn l7bel\", \"kaydo99 wigoul chkoun\", \"sdd tl9a mat7ell\", \"khirha f ghirha\"]\n\nvocab = [s.encode('utf-8').split() for s in sentences]\n\nvoc_vec = word2vec.Word2Vec(vocab, min_count=1)","cb3ca8f0":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\nfrom gensim.models import word2vec\nnum_features = 300    # Word vector dimensionality                      \nmin_word_count = 1   # Minimum word count #Changed 40 to 1 only                        \nnum_workers = 4       # Number of threads to run in parallel\ncontext = 10          # Context window size                                                                                    \ndownsampling = 1e-3   # Downsample setting for frequent words\nmodel = word2vec.Word2Vec(tin, workers=num_workers, #size=num_features - I removed unexpected argument\n                          min_count = min_word_count,\n                          window = context, sample = downsampling)","c225bcf2":"#Since most similar is now in KeyedVectors I copied the snippet below\n\n#https:\/\/github.com\/RaRe-Technologies\/gensim\/blob\/develop\/gensim\/models\/keyedvectors.py\n\nfrom gensim import models\nfrom gensim.models import KeyedVectors\n\n\nimport gensim.downloader as api\nword_vectors = api.load(\"glove-wiki-gigaword-100\")  # load pre-trained word-vectors from gensim-data \n# Check the \"most similar words\", using the default \"cosine similarity\" measure.\nresult = word_vectors.most_similar(positive=['zreb', 'walaw'], negative=['tart'])\n\nmost_similar_key, similarity = result[0]  # look at the first match\nprint(f\"{most_similar_key}: {similarity:.4f}\")","95df7336":"#https:\/\/github.com\/RaRe-Technologies\/gensim\/blob\/develop\/gensim\/models\/keyedvectors.py\n\nresult = word_vectors.most_similar(positive=['friend', 'luck'], negative=['late'])\n\nmost_similar_key, similarity = result[0]  # look at the first match\nprint(f\"{most_similar_key}: {similarity:.4f}\")","7c815f59":"#https:\/\/github.com\/RaRe-Technologies\/gensim\/blob\/develop\/gensim\/models\/keyedvectors.py\n\nresult = word_vectors.most_similar(positive=['time', 'rope'], negative=['bitten'])\n\nmost_similar_key, similarity = result[0]  # look at the first match\nprint(f\"{most_similar_key}: {similarity:.4f}\")","b00f0bed":"#Seems that they don't speak Darija.","ec7697d4":"That's all for now. Algorithms learn Darija.","2b81c90f":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #DC143C;\"><b style=\"color:#006400;\">Darija - Moroccan Arabic<\/b><\/h1><\/center>\n\n\"Moroccan Arabic, known as Darija in Morocco, is a form of vernacular Arabic spoken in Morocco. It is part of the Maghrebi Arabic dialect continuum and as such is mutually intelligible to some extent with Algerian Arabic and to a lesser extent with Tunisian Arabic.\"\n\n\"It is spoken as a first language by about 50% to 75% of Morocco's population. Most other Moroccans natively speak one of the Tamazight languages. Educated Moroccan Tamazight speakers can communicate in mainstream Moroccan Arabic.\"\n\nhttps:\/\/en.wikipedia.org\/wiki\/Moroccan_Arabic","220c15ea":"![](https:\/\/moroccanarabiclanguage.com\/wp-content\/uploads\/2020\/07\/learn-moroccan-arabic-transcription-with-prononciation-online-courses.jpg)moroccanarabiclanguage.com","8724beeb":"#Since all proverbs has only one darija, that pie above doesn't make any sense."}}