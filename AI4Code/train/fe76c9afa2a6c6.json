{"cell_type":{"baaa6825":"code","77ac4cab":"code","0ee9e07b":"code","d84d93ad":"code","0fbd0c8f":"code","1405009c":"code","f85233d6":"code","f3d5393a":"code","13bdf03a":"code","fb87fc56":"code","6d77899c":"code","df858716":"code","b6df75cd":"code","bbfcca57":"code","f7a2d726":"code","7320adce":"code","81c13d88":"code","63b9bba2":"code","95431305":"code","763d8ac2":"code","467205df":"code","0099e22b":"code","95d8b0a2":"markdown","8f58403e":"markdown","427a2a7f":"markdown","a1a8c80c":"markdown","e2124915":"markdown","84a0892a":"markdown","81fd7f6a":"markdown","23c7e709":"markdown","d4cb138c":"markdown","1d548852":"markdown","8012dfa1":"markdown","f081bbb2":"markdown","e4f3ccfa":"markdown","cac555b8":"markdown","d93efdb7":"markdown","34b72fcf":"markdown"},"source":{"baaa6825":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","77ac4cab":"import warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","0ee9e07b":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nstreeteasy = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/sonnynomnom\/Codecademy-Machine-Learning-Fundamentals\/master\/StreetEasy\/manhattan.csv\")\n\ndf = pd.DataFrame(streeteasy)\ndf.head()","d84d93ad":"x = df[['size_sqft','building_age_yrs']]\ny = df[['rent']]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8, test_size = 0.2, random_state=6)\n\nlinear = LinearRegression()\n\nlinear.fit(x_train, y_train)\n\n# Plot the figure\n\nfig = plt.figure(1, figsize=(12, 10))\nplt.clf()#plt. clf() clears the entire current figure with all its axes, but leaves the window opened, such that it may be reused for other plots. \n\nelev = 43.5\nazim = -110\n\nax = Axes3D(fig, elev=elev, azim=azim)\n\nax.scatter(x_train[['size_sqft']], x_train[['building_age_yrs']], y_train, c='k', marker='+',cmap=\"jet\")\n\nax.plot_surface(np.array([[0, 0], [4500, 4500]]), np.array([[0, 140], [0, 140]]), linear.predict(np.array([[0, 0, 4500, 4500], [0, 140, 0, 140]]).T).reshape((2, 2)), alpha=.7,cmap=\"viridis\")\n\nax.set_xlabel('Size (ft$^2$)')\nax.set_ylabel('Building Age (Years)')\nax.set_zlabel('Rent ($)')\n\n","0fbd0c8f":"plt.figure(figsize=(12,10))\nmask = np.zeros_like(df.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(data=df.corr(), cmap=\"jet\", annot=True,linewidths=1, linecolor='white',mask=mask)","1405009c":"sns.pairplot(df,\n                 markers=\"+\",\n                 kind='reg',\n                 diag_kind=\"kde\",\n                 plot_kws={'line_kws':{'color':'#aec6cf'},\n                           'scatter_kws': {'alpha': 0.5,\n                                           'color': '#82ad32'}},\n               corner=True,\n                 diag_kws= {'color': '#82ad32'})","f85233d6":"df.corr()[\"rent\"].sort_values(ascending=False)","f3d5393a":"plt.figure(figsize = (15,10))\nsns.regplot(data=df, x=\"size_sqft\", y=\"rent\",color=\"red\")","13bdf03a":"plt.figure(figsize = (15,10))\nsns.regplot(data=df, x=\"bathrooms\", y=\"rent\",color=\"green\")","fb87fc56":"plt.figure(figsize = (15,10))\nsns.regplot(data=df, x=\"bedrooms\", y=\"rent\",color=\"purple\")","6d77899c":"df.drop([\"rental_id\",\"neighborhood\",\"borough\"],axis=1,inplace=True)\nX = df.drop(\"rent\",axis=1)\ny= df[\"rent\"]\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\nmulti_lr = LinearRegression()\nmulti_lr.fit(X_train,y_train)\nprint(multi_lr.coef_)","df858716":"coef_table = pd.DataFrame(list(X_train.columns)).copy()\ncoef_table.insert(len(coef_table.columns),\"Coefs\",multi_lr.coef_.transpose())\ncoef_table ","b6df75cd":"print(\"Train score:\")\nprint(multi_lr.score(X_train, y_train))\nprint(\"**********************************\")\nprint(\"Train score:\")\nprint(multi_lr.score(X_test, y_test))","bbfcca57":"#Evaluation of  the explained variance score (R^2) with another coding method\nmetrics.explained_variance_score(y_test,predictions) #This shows our model predict %93 of the target correctly","f7a2d726":"from sklearn import metrics\nprint(\"MAE:\",metrics.mean_absolute_error(y_test,predictions))\nprint (\"MSE:\",metrics.mean_squared_error(y_test,predictions))\nprint(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test,predictions)))","7320adce":"predictions = multi_lr.predict(X_test)\nresiduals = predictions - y_test\nplt.figure(figsize=(15,10))\nplt.scatter(predictions, residuals, alpha=0.4,color=\"red\")\nplt.title('Residual Analysis')\nsns.set_style(\"darkgrid\")\nplt.xlabel(\"Predictions\")\nplt.ylabel(\"Residuals\")\nplt.show()","81c13d88":"# here I will visualize the real test values(y_test) versus the predicted values.\nplt.figure(figsize=(12,10))\nsns.scatterplot(predictions,y_test,color=\"red\")\nplt.title(\"The Scatterplot of Relationship between Actual Values and Predictions\")\nplt.xlabel(\"Predictions\")\nplt.ylabel(\"Actual Values\")","63b9bba2":"plt.figure(figsize=(12,10))\nsns.distplot(y_test-predictions,bins=50,color=\"red\") #this figure also proves that our model fits very good\n#There is no huge differences between our predictions and actual y data","95431305":"X.head()","763d8ac2":"print(f\" The Rent Price of House with these features is = {multi_lr.predict([[1.0,1,620,12,6,52,0,1,1,1,1,1,1,1]])} dolars.\")","467205df":"x = df[['bedrooms', 'bathrooms', 'size_sqft', 'floor', 'building_age_yrs', 'no_fee']]\ny = df[[\"rent\"]]\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)\nmulti_lr2 = LinearRegression()\nmulti_lr2.fit(x_train,y_train)\nprint(\"Performance of the Previous Model............\")\nprint(\"Train score:\")\nprint(multi_lr.score(X_train, y_train))\nprint(\"Train score:\")\nprint(multi_lr.score(X_test, y_test))\nprint(\"Performance of the Second Model............\")\nprint(\"Train score:\")\nprint(multi_lr2.score(x_train, y_train))\nprint(\"Train score:\")\nprint(multi_lr2.score(x_test, y_test))","0099e22b":"print(\"Performance of the Previous Model............\")\nprint(\"MAE:\",metrics.mean_absolute_error(y_test,predictions))\nprint (\"MSE:\",metrics.mean_squared_error(y_test,predictions))\nprint(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test,predictions)))\nprint(\"Performance of the Second Model............\")\npredictions2 = multi_lr2.predict(x_test)\nprint(\"MAE:\",metrics.mean_absolute_error(y_test,predictions2))\nprint (\"MSE:\",metrics.mean_squared_error(y_test,predictions2))\nprint(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test,predictions2)))","95d8b0a2":"<font color=\"red\">\nLinear regression is useful when we want to predict the values of a variable from its relationship with other variables. There are two different types of linear regression models (simple linear regression and multiple linear regression).\n\nIn predicting the price of a home, one factor to consider is the size of the home. The relationship between those two variables, price and size, is important, but there are other variables that factor in to pricing a home: location, air quality, demographics, parking, and more. When making predictions for price, our dependent variable, we\u2019ll want to use multiple independent variables. To do this, we\u2019ll use Multiple Linear Regression.\n\nMultiple Linear Regression uses two or more independent variables to predict the values of the dependent variable. It is based on the following equation that we\u2019ll explore later on:\n\ny = b + m1*x1} + m2*x2 + ... + \n    \n\nHere, m1, m2, m3, \u2026 mn refer to the coefficients, and b refers to the intercept that we want to find. ","8f58403e":"<font color=\"red\">\nNow we will visualize the differences between our predictions and actual y test data","427a2a7f":"<font color=\"red\">\nStreetEasy is New York City\u2019s leading real estate marketplace \u2014 from studios to high-rises, Brooklyn Heights to Harlem.\n\nIn this lesson, you will be working with a dataset that contains a sample of 5,000 rentals listings in Manhattan, Brooklyn, and Queens, active on StreetEasy in June 2016.\n\nIt has the following columns:\n\nrental_id: rental ID\n    \nrent: price of rent in dollars\n    \nbedrooms: number of bedrooms\n    \nbathrooms: number of bathrooms\n    \nsize_sqft: size in square feet\n    \nmin_to_subway: distance from subway station in minutes\n    \nfloor: floor number\n    \nbuilding_age_yrs: building\u2019s age in years\n    \nno_fee: does it have a broker fee? (0 for fee, 1 for no fee)\n    \nhas_roofdeck: does it have a roof deck? (0 for no, 1 for yes)\n    \nhas_washer_dryer: does it have washer\/dryer in unit? (0\/1)\n    \nhas_doorman: does it have a doorman? (0\/1)\n    \nhas_elevator: does it have an elevator? (0\/1)\n    \nhas_dishwasher: does it have a dishwasher (0\/1)\n    \nhas_patio: does it have a patio? (0\/1)\n    \nhas_gym: does the building have a gym? (0\/1)\n    \nneighborhood: (ex: Greenpoint)\n    \nborough: (ex: Brooklyn)","a1a8c80c":"<font color=\"red\">\nWe will evaluate our model performance by calculating the residual sum of squares and the explained variance score","e2124915":"<font color=\"red\">\nHere we can easliy see that size in square feet,number of bedrooms, number of bathrooms has major affect on the rent price. Lets visualize these relations.","84a0892a":"<font color=\"red\">\nWe can evaluate the performance by visualizing the predictions vs y_test values as follows:","81fd7f6a":"## 4. Evaluating the Model's Accuracy","23c7e709":"<font color=\"red\">\nRemove some of the features that don\u2019t have strong correlations and see if your scores improved!","d4cb138c":"## 1. Introduction","1d548852":"<font color=\"red\">\nWhen trying to evaluate the accuracy of our multiple linear regression model, one technique we can use is Residual Analysis.\n\nThe difference between the actual value y, and the predicted value \u0177 is the residual e. The equation is:\n\ne = y - yhat\n\n \nIn the StreetEasy dataset, y is the actual rent and the \u0177 is the predicted rent. The real y values should be pretty close to these predicted y values.\n\nsklearn\u2018s linear_model.LinearRegression comes with a .score() method that returns the coefficient of determination R\u00b2 of the prediction.\n\nThe coefficient R\u00b2 is defined as:\n\n1 - (u\/v)\n \nwhere u is the residual sum of squares:\n    \n    ((y - y_predict) ** 2).sum()\n    \nand v is the total sum of squares (TSS):\n    \n    ((y - y.mean()) ** 2).sum()","8012dfa1":"<font color=\"red\">\nAs we can see the comparison above the performance of the model has been improved even though we train the model with 5 features instead of 13 features as it is case in the first model.","f081bbb2":"<font color=\"red\">\nApartment Information\n\nBedrooms :1\n    \nBathrooms:1\n    \nSize (ft\u00b2):620\n    \nSubway Station (min):12\n    \nFloor:6\n    \nBuilding Age (years):52\n    \nNo Fee:0\n    \nHas Roofdeck:1\n    \nHas In-Unit Washer\/Dryer:1\n    \nHas Doorman:1\n    \nHas Elevator:1\n    \nHas Dishwasher:1\n    \nHas Patio:1\n    \nHas Gym:1\n","e4f3ccfa":"## 2. Exploratory Data Analysis","cac555b8":"## 3. Training Model","d93efdb7":"<font color=\"red\">\nThe .fit() method gives the model two variables that are useful to us:\n\n.coef_, which contains the coefficients\n.intercept_, which contains the intercept\nAfter performing multiple linear regression, we can print the coefficients using .coef_.\n\nCoefficients are most helpful in determining which independent variable carries more weight. For example, a coefficient of -1.345 will impact the rent more than a coefficient of 0.238, with the former impacting prices negatively and latter positively.\n    \nLets train the model with all features and find out the coefficients for each feature.","34b72fcf":"## 5. Rebuild the Model to Achieve Better Performance"}}