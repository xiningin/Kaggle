{"cell_type":{"209190a2":"code","2e7a74b4":"code","cf3a1e0a":"code","d0d97dac":"code","6294029b":"code","209fa368":"code","0d8734bd":"code","d6d5a98f":"code","9b0d7c4e":"code","e7d44fab":"code","175534b8":"code","78f50404":"code","2e010950":"code","e9bed5df":"code","e39f47ab":"code","a187eb6d":"markdown","44ae1825":"markdown","92ec3e12":"markdown","1422e398":"markdown","984a76ec":"markdown","e6e8a22c":"markdown","1d8e65b1":"markdown","530edf6e":"markdown","c1bc66d1":"markdown","535eb665":"markdown","1488ce52":"markdown","989e82ae":"markdown","5f462cbe":"markdown"},"source":{"209190a2":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport os\nimport shutil\nimport numpy as np\nimport pandas as pd\n\nfrom random import shuffle\nfrom tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, BatchNormalization, LeakyReLU\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report\n\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly import offline\noffline.init_notebook_mode(connected = False)","2e7a74b4":"BASE_DIR = '..\/input\/basicshapes\/shapes\/shapes'\nTRAIN_DIR = os.path.join('train')\nTEST_DIR = os.path.join('test')\nVAL_DIR = os.path.join('val')\nshapes = os.listdir(BASE_DIR)\nprint(shapes)","cf3a1e0a":"shapes_dict = {shape:os.listdir(os.path.join(BASE_DIR, shape)) for shape in shapes}\nfor i in shapes_dict:\n    shuffle(shapes_dict[i])\n","d0d97dac":"for shape, items in shapes_dict.items():\n    os.makedirs(os.path.join(TRAIN_DIR, shape))\n    os.makedirs(os.path.join(VAL_DIR, shape))\n    os.makedirs(os.path.join(TEST_DIR, shape))\n    \n    for item in items[:60]:\n        shutil.copy(os.path.join(BASE_DIR,shape,item ), os.path.join(TRAIN_DIR, shape, item))\n    \n    for item in items[60:80]:\n        shutil.copy(os.path.join(BASE_DIR,shape,item ), os.path.join(VAL_DIR, shape, item))\n        \n    for item in items[80:]:\n        shutil.copy(os.path.join(BASE_DIR,shape,item ), os.path.join(TEST_DIR, shape, item))","6294029b":"def list_files(startpath):\n    for root, dirs, files in os.walk(startpath):\n        level = root.replace(startpath, '').count(os.sep)\n        indent = ' ' * 4 * (level)\n        print('{}{}\/'.format(indent, os.path.basename(root)))\n        subindent = ' ' * 4 * (level + 1)\nlist_files(os.path.join('.\/'))","209fa368":"image_datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1,\n                                   rescale=1.\/255,\n     height_shift_range=0.1,zoom_range=0.1,\n     horizontal_flip=True, vertical_flip=True)\n\ntrain_generator= image_datagen.flow_from_directory(TRAIN_DIR,\n                                                    color_mode = 'grayscale',\n                                                 target_size=(28,28))\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_datagen.flow_from_directory(TEST_DIR, color_mode = 'grayscale',batch_size = 60 , target_size = (28,28))\nval_generator = test_datagen.flow_from_directory(VAL_DIR, color_mode = 'grayscale', batch_size = 60 ,target_size = (28,28))\n","0d8734bd":"fig, ax = plt.subplots(4,4,figsize=(16,16))\nfor i in range(16):\n    ind = np.random.randint(32)\n    image = train_generator[0][0][ind]\n    ax[i\/\/4][i%4].imshow(image, cmap='gray')\n    ","d6d5a98f":"model = Sequential([\n    Conv2D(16,(3,3), input_shape=(28,28,1)),\n    LeakyReLU(),\n    MaxPooling2D((2,2)),\n    Conv2D(32, (3,3)),\n    LeakyReLU(),\n    MaxPooling2D((2,2)),\n    Dropout(0.5),\n    Flatten(),\n    Dense(512),\n    Dropout(0.5),\n    LeakyReLU(),\n    Dense(256),\n    LeakyReLU(),\n    Dropout(0.5),\n    Dense(3, activation = 'softmax')\n])","9b0d7c4e":"model.summary()","e7d44fab":"decay = ExponentialDecay(initial_learning_rate=5*1e-3, decay_steps=1000,decay_rate=0.01)\noptimizer = Adam(learning_rate=decay)\n\n\nmodel.compile(loss='categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])","175534b8":"earlystop = EarlyStopping(patience = 30, restore_best_weights=True)\n\nhistory = model.fit(train_generator, epochs = 500, validation_data=val_generator, callbacks = [earlystop])","78f50404":"metrics = pd.DataFrame(history.history)\nfig = px.line(metrics, y=['loss','val_loss'])\nfig.show()","2e010950":"loss, accuracy = model.evaluate(test_generator)\nprint('Accuracy is {:.1f}%'.format(accuracy*100))","e9bed5df":"fig, ax = plt.subplots(1,3, figsize = (10,12))\nind = 0\nclasses = {v:k for k,v in test_generator.class_indices.items()}\n\nimages,true_labels = next(test_generator)\ntrue_labels = np.argmax(true_labels, axis=1)\npreds = np.argmax(model.predict(images),axis=1)\n\n\nfor i in range(60):\n    pred = classes[preds[i]]\n    true_label = classes[true_labels[i]]\n    if pred != true_label:\n        ax[ind].imshow(images[i], cmap='gray')\n        ax[ind].title.set_text(f'{true_label} - {pred}')\n        ind+=1\n","e39f47ab":"print(classification_report(true_labels, preds))\n","a187eb6d":"We can understand why model got confused for the last 2 images, they have similar shape to triangle. I don't think there is need for looking at confusion matrix, it is all clear, in my opinion. Bu  let's look at `classification_report`","44ae1825":"Let's look at some of the augmented images","92ec3e12":"Since this problem concerns images, Image Augmentation is the one of the first things that comes to my mind. Pay attention to `color_mode`, images are grayscale, so we have to pass `'grayscale'` as value.","1422e398":"# Preprocessing","984a76ec":"95% accuracy means only 3 of the 60 test images has been missclassified, let's look at the missclassified images","e6e8a22c":"We have three classes: circles, triangles and squares. There are 100 samples belonging to each class. Images are stored under subdirectories corresponding to their classes, but they aren't splitted to train\/validation\/test sets. I will do that manually.\n\nNote: Directory structure looks confusing. We have the same images under both *shapes* and *shapes\/shapes* subdirectories. I don't know reason for that and I choose to work with *shapes\/shapes*","1d8e65b1":"I collected all the image titles to dictionary to make things easier. After that I shuffle values of dictionary to get random samples","530edf6e":" Structure will look like this (I borrowed code from [here](https:\/\/stackoverflow.com\/a\/9728478\/11199298)):","c1bc66d1":"# Modelling","535eb665":"# Import libraries","1488ce52":"Here I create train, validation and test subdirectories and split data as 60%\/20%\/20%. Dataset is small and we can easily load all the images to memory, but I wanted to test my skills of working with file system. \n","989e82ae":"While trying different models, I saw that gradients are vanishing and chose LeakyRelu as activation function","5f462cbe":"Model shows 100%precision and recall for 2nd class (rectangle) and other metrics are also good. If you like my work please upvote and I am open to all kind of suggestions "}}