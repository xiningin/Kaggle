{"cell_type":{"9acac1e3":"code","17e1d7bb":"code","e0a93657":"code","8f97b09e":"code","65333e99":"code","3bea4538":"code","73ef2272":"code","3789a8c6":"code","4e609c66":"code","c5517bb7":"code","16b5194b":"code","e384dae6":"code","539b2e63":"code","25dce42b":"code","622143a9":"code","1af57633":"code","b00f9324":"markdown","33a443a5":"markdown","1bcae793":"markdown","c6e585bd":"markdown","d4d43cd9":"markdown","8509fcad":"markdown","eb5e035b":"markdown","d64ea573":"markdown","2b7df49b":"markdown","f8144a8d":"markdown","7c0e1a85":"markdown","ca4d648f":"markdown","5dad7aab":"markdown","bd53c42d":"markdown","42694072":"markdown","3150ca0d":"markdown","dd8b9cab":"markdown"},"source":{"9acac1e3":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.animation\nfrom sklearn.model_selection import train_test_split\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras.utils import to_categorical, plot_model\nfrom keras.datasets import mnist\nfrom keras import backend as K","17e1d7bb":"# load mnist dataset\ndata = pd.read_csv('..\/input\/train.csv')\n\n# split data into train and test sample\nx_train, x_test, y_train, y_test = train_test_split(data.iloc[:,1:785], data.iloc[:,0],  \n                                                    test_size = 0.1, random_state = 42)\n\nx_train = x_train.values.reshape(37800, 784)\nx_test = x_test.values.reshape(4200, 784)\n\n# compute the number of labels\nnum_labels = len(np.unique(y_train))\n\n# convert to one-hot vector\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# normalize\nx_train = x_train.astype('float32') \/ 255\nx_test = x_test.astype('float32') \/ 255\n\n# network parameters\ninput_size = x_train.shape[1]\nbatch_size = 64\ndropout = 0.45","e0a93657":"# this model is a 3-layer MLP with ReLU and dropout after each layer\nmodel = Sequential()\nmodel.add(Dense(256, input_dim=input_size))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout))\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout))\nmodel.add(Dense(num_labels))\nmodel.add(Activation('softmax'))\nmodel.summary()\n\n# loss function for one-hot vector using adam optimizer\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","8f97b09e":"# train the network\nmodel.fit(x_train, y_train, epochs=20, batch_size=batch_size)\n\n# validate the model on test dataset to determine generalization\nloss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\nprint(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))","65333e99":"get_layer_output = K.function([model.layers[0].input, model.layers[0].input, model.layers[0].input],\n                              [model.layers[1].output, model.layers[4].output, model.layers[7].output])\n\nlayer1_output, layer2_output, layer3_output = get_layer_output([x_train])","3bea4538":"train_ids = [np.arange(len(y_train))[y_train[:,i] == 1] for i in range(10)]","73ef2272":"%%capture\n%matplotlib inline\n\n# digit to be plotted\ndigit = 5\n\n# indices of frames to be plotted for this digit\nn = range(50)\n\n# initialize plots\nf, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(15,4))\n\n# prepare plots\nax1.set_title('Input Layer', fontsize=16)\nax1.axes.get_xaxis().set_visible(False)\nax1.axes.get_yaxis().set_visible(False)\n\nax2.set_title('Hidden Layer 1', fontsize=16)\nax2.axes.get_xaxis().set_visible(False)\nax2.axes.get_yaxis().set_visible(False)\n\nax3.set_title('Hidden Layer 2', fontsize=16)\nax3.axes.get_xaxis().set_visible(False)\nax3.axes.get_yaxis().set_visible(False)\n    \nax4.set_title('Output Layer', fontsize=16)\nax4.axes.get_xaxis().set_visible(False)\nax4.axes.get_yaxis().set_visible(False)   \n\n# add numbers to the output layer plot to indicate label\nfor i in range(3):\n    for j in range(4):\n        text = ax4.text(j, i, [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, '', '']][i][j],\n                        ha=\"center\", va=\"center\", color=\"w\", fontsize=16)    \n        \ndef animate(id):\n    # plot elements that are changed in the animation\n    digit_plot = ax1.imshow(x_train[train_ids[digit][id]].reshape((28,28)), animated=True)\n    layer1_plot = ax2.imshow(layer1_output[train_ids[digit][id]].reshape((16,16)), animated=True)\n    layer2_plot = ax3.imshow(layer2_output[train_ids[digit][id]].reshape((8,8)), animated=True)\n    output_plot = ax4.imshow(np.append(layer3_output[train_ids[digit][id]], \n                                       [np.nan, np.nan]).reshape((3,4)), animated=True)\n    return digit_plot, layer1_plot, layer2_plot, output_plot,\n\n# define animation\nani = matplotlib.animation.FuncAnimation(f, animate, frames=n, interval=100)","3789a8c6":"ani","4e609c66":"%%capture\n%matplotlib inline\n\n# digit to be plotted\ndigit = 6\n\n# numbers of frames to be summed over\nn = np.append([1], np.linspace(5, 100, 20, dtype=int))\n\n# initialize plots\nf, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(15,4))\n\n# add a counter indicating the number of frames used in the summation\ncounter = ax1.text(1, 2, 'n={}'.format(0), color='white', fontsize=16, animated=True)\n\n# prepare plots\nax1.set_title('Input Layer', fontsize=16)\nax1.axes.get_xaxis().set_visible(False)\nax1.axes.get_yaxis().set_visible(False)\n\nax2.set_title('Hidden Layer 1', fontsize=16)\nax2.axes.get_xaxis().set_visible(False)\nax2.axes.get_yaxis().set_visible(False)\n\nax3.set_title('Hidden Layer 2', fontsize=16)\nax3.axes.get_xaxis().set_visible(False)\nax3.axes.get_yaxis().set_visible(False)\n    \nax4.set_title('Output Layer', fontsize=16)\nax4.axes.get_xaxis().set_visible(False)\nax4.axes.get_yaxis().set_visible(False)   \n\n# add numbers to the output layer plot to indicate label\nfor i in range(3):\n    for j in range(4):\n        text = ax4.text(j, i, [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, '', '']][i][j],\n                        ha=\"center\", va=\"center\", color=\"w\", fontsize=16)    \n        \ndef animate(id):\n    # plot elements that are changed in the animation\n    digit_plot = ax1.imshow(np.sum(x_train[train_ids[digit][:id]], axis=0).reshape((28,28)), animated=True)\n    layer1_plot = ax2.imshow(np.sum(layer1_output[train_ids[digit][:id]], axis=0).reshape((16,16)), animated=True)\n    layer2_plot = ax3.imshow(np.sum(layer2_output[train_ids[digit][:id]], axis=0).reshape((8,8)), animated=True)\n    output_plot = ax4.imshow(np.append(np.sum(layer3_output[train_ids[digit][:id]], axis=0), \n                                       [np.nan, np.nan]).reshape((3,4)), animated=True)\n    counter.set_text('n={}'.format(id))\n    return digit_plot, layer1_plot, layer2_plot, output_plot, counter,\n\n# define animation\nani = matplotlib.animation.FuncAnimation(f, animate, frames=n, interval=100)","c5517bb7":"ani","16b5194b":"f, ax_arr = plt.subplots(2, 5, figsize=(15,10))\n\nf.subplots_adjust(wspace=0.05, bottom=0.5, top=0.95)\n\nfor i, ax in enumerate(np.ravel(ax_arr)):\n    ax.axes.get_xaxis().set_visible(False)\n    ax.axes.get_yaxis().set_visible(False)\n    if i <= 10:\n        ax.set_title('- {} -'.format(i), fontsize=16)\n        layer1_plot = ax.imshow(np.sum(layer1_output[train_ids[i]], axis=0).reshape((16,16)))","e384dae6":"similarity_layer1 = np.zeros((10,10))\n\nfor i in range(10):\n    for j in range(10):\n        sum_i_normalized = np.sqrt(np.sum(layer1_output[train_ids[i]], axis=0)\/np.sum(layer1_output[train_ids[i]]))\n        sum_j_normalized = np.sqrt(np.sum(layer1_output[train_ids[j]], axis=0)\/np.sum(layer1_output[train_ids[j]]))\n        similarity_layer1[i,j] = np.sum(sum_i_normalized*sum_j_normalized)","539b2e63":"f, ax = plt.subplots()\n\nsimilarity_layer1_plot = ax.imshow(similarity_layer1, origin='lower')\nplt.colorbar(similarity_layer1_plot)","25dce42b":"f, ax_arr = plt.subplots(2, 5, figsize=(15,10))\n\nf.subplots_adjust(wspace=0.05, bottom=0.5, top=0.95)\n\nfor i, ax in enumerate(np.ravel(ax_arr)):\n    ax.axes.get_xaxis().set_visible(False)\n    ax.axes.get_yaxis().set_visible(False)\n    if i <= 10:\n        ax.set_title('- {} -'.format(i), fontsize=16)\n        layer2_plot = ax.imshow(np.sum(layer2_output[train_ids[i]], axis=0).reshape((8,8)))","622143a9":"similarity_layer2 = np.zeros((10,10))\n\nfor i in range(10):\n    for j in range(10):\n        sum_i_normalized = np.sqrt(np.sum(layer2_output[train_ids[i]], axis=0)\/np.sum(layer2_output[train_ids[i]]))\n        sum_j_normalized = np.sqrt(np.sum(layer2_output[train_ids[j]], axis=0)\/np.sum(layer2_output[train_ids[j]]))\n        similarity_layer2[i,j] = np.sum(sum_i_normalized*sum_j_normalized)","1af57633":"f, ax = plt.subplots()\n\nsimilarity_layer2_plot = ax.imshow(similarity_layer2, origin='lower')\nplt.colorbar(similarity_layer2_plot)","b00f9324":"This model implementation reaches an accuracy of ~98%, which is remarkable, but better results are possible using, e.g., a [Convolutional Neural Network](https:\/\/en.wikipedia.org\/wiki\/Convolutional_neural_network). We use the simpler MLP to make the interpretation of the visualization results easier.","33a443a5":"We train the model on the entire MNIST training data set:","1bcae793":"### Second Hidden Layer\n\nWe repeat this analysis for the second hidden layer.","c6e585bd":"This matrix shows the similarity of the static pattern for the different digits. Values on the diagonal show by default the highest possible similarity, as they compare the same digits with each other. But even off the diagonal, there are cases that show high levels of similarity; these cases include the digits `3` and `5`, `7` and `9`, as well as `4` and `9`. Indeed, all of these digits show some level of similarity when written down - depending on your writing style...","d4d43cd9":"## Comparison of Layers for Different Digits\n\nFinally, we compare the static patterns that emerge in the hidden layers for the different labels, i.e., the different digits.\n\n### First Hidden Layer","8509fcad":"## Ensemble Visualization\n\nLet's check the similarity in behavior for frames showing the same digit by looking at the ensemble properties. In this case, ensemble properties refers to how the neurons behave on average for a large number of frames showing the same digit.\n\nWe look into this by cumulating the output values of each neurons for $5 < n < 100$ frames with the same digit. The brighter a neuron, the more often it fires and the higher is its output value and hence also its impact on the overall classification.\n\nFor comparison, we will also sum up the pixel values in the original frames.","eb5e035b":"These patterns look sufficiently random - except for the digits `4` and `9`, which look remarkably similar. This makes sense as the hand-written digits themselves strongly resemble each other in the writing style used in the US, on which the MNIST dataset is based. \n\nWe quantify the similarities between the normalized static first-hidden layer patterns for pairs of digits by multiplication and summation over these patterns.","d64ea573":"After summing up the responses of as little as 20-30 frames, the pattern in the second hidden layer is almost static. After combining about 70-80 frames, also the pattern in the first hidden layer appears static. This supports the idea that only a subset of all neurons is involved in the recognition of individual digits.","2b7df49b":"## Conclusions\n\n* Despite variations in the shapes of hand-written digits, the same groups of neurons is involved in the identification of the same digits.\n* Similarities in the shapes of digits translate into similarities in the groups of neurons that are involved in their identification in the first hidden layer, but not so much in the second hidden layer.","f8144a8d":"Interestingly, patterns for the digit combinations that showed a high level of similarity in the first hidden layer (`3|5`, `7|9`, `4|9`) do not seem to show the same level of similarity in hidden layer 2. \n\nKeep in mind that this second hidden layer is not based on the pixel values directly - it takes outputs from hidden layer 1 as input. Hence, it is much harder to interpret the patterns shown here as they are based on patterns found in the first hidden layer.","7c0e1a85":"## Visualization of  Individual Frames\n\nIn this visualization, we focus on individual training data (i.e., individual frames with hand-written digits).\n\nThe following panel shows from left to right \n* the original 28x28 pixel frame depicting a hand-written figure,\n* the output values of all neurons of the first hidden layer,\n* the output values of all neurons of the second hidden layer, and\n* the one-hot encoded output layer indicating the model classification result.\n\nNote that in those plots showing network layers, each pixel stands for the output of a single neuron. This output is based on the input parameters passed on from the previous layer, the trained weights for each neuron, and the activation function used in this layer. Dark blue pixels stand for low output values, while yellow pixels stand for high output values. The pixels have been arranged in two dimensions to save space; just think of these layers in linear arrangements to stay in the typical picture of layers in a network. ","ca4d648f":"Scrolling through the animation, it becomes clear that in most cases the same subset of neurons fires, while other neurons remain quiescent. This is much more obvious in the second hidden layer than in the first hidden layer and can be interpreted as the first layer pre-processesing the pixel data, while the second layer deals with pattern recognition. Note that in most cases the recognition of the digit shown is unambiguous; ambiguity only occurs in somewhat pathologic cases.\n\nYou can change the digit shown by changing the `digit` value in the code block above. ","5dad7aab":"# Neural Network Visualization for Digit Recognition\n\nThis kernel visualizes how a [Multi-layer Perceptron](https:\/\/en.wikipedia.org\/wiki\/Multilayer_perceptron) (MLP) Neural Network recognizes hand-written digits from the [MNIST](https:\/\/en.wikipedia.org\/wiki\/MNIST_database) data set. \n\nA three-layer MLP does a decent job at recognizing hand-written digits. While this is a rather small model compared to other applications, it is already a black box to most people: image data goes in, classification results come out. But what happens in-between? What are the individual layers of the model doing and how do they behave on training data?\n\nIn order to investigate this question, I created this kernel to visualize all the individual neurons in this model and their output values as a function of input frame and digit.","bd53c42d":"## Training a Neural Network\n\nWe use a simple three-layer MLP with ReLU activation and dropout after each layer - this model is a slightly modified version of a model presented in chapter 1 of the book \"Advanced Deep Learning with Keras\" by Rowel Atienza, whish is available [here](https:\/\/github.com\/PacktPublishing\/Advanced-Deep-Learning-with-Keras). \n\nHow does this model work?\n\nThe MLP takes every single pixel of the input frames as an input parameter. In the first hidden layer, each neuron takes every pixel value as input parameter. Every neuron in the second hidden layer then takes all the outputs of the first layer (after activation using ReLU) as input parameters. After applying a softmax activation, these results form the final output layer. \n\nThe optimizer then derives linear weights in such a way as to minimize the loss function (in this case the *categorical crossentropy*) and thus maximizing the accuracy of the classification.","42694072":"This reduced similarity is reflected by the similarity matrix, which is much smoother and has fewer digit combinations stick out with elevated similarities. ","3150ca0d":"## Extract Output and Group Information\n\nWe extract the outputs generated by each individual neuron and for each frame in the MNIST training sample and store them on a per-layer basis. ","dd8b9cab":"Finally, we extract and store the indices of frames showing the same digit."}}