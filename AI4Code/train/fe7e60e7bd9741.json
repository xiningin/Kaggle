{"cell_type":{"55880273":"code","f11d5d60":"code","a2edc56f":"code","2dc6978d":"code","48ad9971":"code","4ada0f2f":"code","b2ae996a":"code","0cbf1f21":"code","a3474a8a":"code","3664d1f8":"code","7e443627":"code","e4ac0f2b":"code","e96a76de":"code","f518f9d2":"code","e6305bab":"code","e3bdc417":"code","ef197353":"code","a64c0b5a":"code","6a13b9bc":"code","8fdeca85":"code","242eccf2":"code","e8d1cc4f":"code","4870fe49":"code","56c4b29d":"code","bb23fa7f":"code","8572142c":"code","980063bb":"code","735071e6":"code","d62e3ef3":"code","aca75f12":"code","157c47d7":"code","71121a97":"code","d2e40751":"code","f51f0c27":"code","231441cb":"code","4c7714e5":"code","1ab80b4e":"code","6ee61920":"code","0c531505":"code","83c455f1":"code","665af772":"code","4b1fba2e":"code","12810dc5":"code","a96f2bb5":"code","0b3ec2d2":"markdown","556bfe30":"markdown","5c644661":"markdown","97f0ebe1":"markdown"},"source":{"55880273":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\ntrain_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ngenderSub = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f11d5d60":"passengerid = test_data.PassengerId\n\n\ntrain_data.info()\n\ntest_data.info()","a2edc56f":"def missing_percentage(df):\n    \n    total = df.isnull().sum().sort_values(ascending=False)\n    percent = round(df.isnull().sum().sort_values(ascending=False) \/ len(df) * 100)\n    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    \nmissing_percentage(train_data)\n","2dc6978d":"missing_percentage(test_data)","48ad9971":"train_data[train_data.Embarked.isnull()]\n\n# Fares = 80,  Pclass = 1,    Try to guess Embarked","4ada0f2f":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nfig, ax = plt.subplots(figsize=(16,12),ncols=2)\nax1 = sns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Pclass\", data=train_data, ax = ax[0]);\nax2 = sns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Pclass\", data=test_data, ax = ax[1]);\nax1.set_title(\"Training Set\", fontsize = 18)\nax2.set_title('Test Set',  fontsize = 18)\n\nfig.show()","b2ae996a":"train_data.Embarked.fillna(\"C\", inplace=True)","0cbf1f21":"# CABIN HAS 77-778 % MISSING VALUE\n\nsurvivers = train_data.Survived\n\ntrain_data.drop([\"Survived\"], axis=1, inplace=True)\n\nall_data = pd.concat([train_data, test_data], ignore_index=False)\n\n#Assigning N to null(NaN) values\n\nall_data.Cabin.fillna(\"N\", inplace=True)","a3474a8a":"def percent_value_counts(df, feature):\n    \n    percent = pd.DataFrame(round(df.loc[:,feature].value_counts(dropna=False, normalize=True)*100,2))\n    ## creating a df with th\n    total = pd.DataFrame(df.loc[:,feature].value_counts(dropna=False))\n    ## concating percent and total dataframe\n\n    total.columns = [\"Total\"]\n    percent.columns = ['Percent']\n    return pd.concat([total, percent], axis = 1)","3664d1f8":"all_data.Cabin = [i[0] for i in all_data.Cabin]\n\npercent_value_counts(all_data, \"Cabin\")\n","7e443627":"all_data.groupby(\"Cabin\")['Fare'].mean().sort_values()","e4ac0f2b":"def cabin_estimator(i):\n    \n    a = 0\n    if i<16:\n        a = \"G\"\n    elif i>=16 and i<27:\n        a = \"F\"\n    elif i>=27 and i<38:\n        a = \"T\"\n    elif i>=38 and i<47:\n        a = \"A\"\n    elif i>= 47 and i<53:\n        a = \"E\"\n    elif i>= 53 and i<54:\n        a = \"D\"\n    elif i>=54 and i<116:\n        a = 'C'\n    else:\n        a = \"B\"\n    return a","e96a76de":"with_N = all_data[all_data.Cabin == \"N\"]\nwithout_N = all_data[all_data.Cabin != \"N\"]","f518f9d2":"# Estimating cabins based on the Passenger Fares(Ticket Prices)\nwith_N[\"Cabin\"] = with_N.Fare.apply(lambda x: cabin_estimator(x))\n\nall_data = pd.concat([with_N, without_N], axis=0)\n\nall_data.sort_values(by= 'PassengerId', inplace=True)\n\n#We were taken train and test into all_data and we are seperating them now\ntrain_data = all_data[:891]\n\ntest_data = all_data[891:]","e6305bab":"train_data['Survived'] = survivers","e3bdc417":"test_data[test_data.Fare.isnull()]","ef197353":"missing_value_fare = test_data[(test_data.Pclass == 3) & \n                               (test_data.Embarked == \"S\") &\n                               (test_data.Sex == \"male\")].Fare.mean()\n\ntest_data.Fare.fillna(missing_value_fare, inplace=True)","a64c0b5a":"# 20 % of Age is missing value","6a13b9bc":"train_data['Sex'] = train_data.Sex.apply(lambda x: 0 if x == \"female\" else 1)\ntest_data['Sex'] = test_data.Sex.apply(lambda x: 0 if x == \"female\" else 1)\ntrain_data.head()","8fdeca85":"train_data[\"title\"] = [i.split('.')[0] for i in train_data.Name]\ntrain_data[\"title\"] = [i.split(',')[1] for i in train_data.title]\n","242eccf2":"#Getting the spaces\ntrain_data.title = train_data.title.apply(lambda x: x.strip())\n","e8d1cc4f":"test_data['title'] = [i.split('.')[0].split(',')[1].strip() for i in test_data.Name]\n","4870fe49":"def fuse_title(feature):\n    \n    result = ''\n    if feature in ['the Countess','Capt','Lady','Sir','Jonkheer','Don','Major','Col', 'Rev', 'Dona', 'Dr']:\n        result = 'rare'\n    elif feature in ['Ms', 'Mlle']:\n        result = 'Miss'\n    elif feature == 'Mme':\n        result = 'Mrs'\n    else:\n        result = feature\n    return result\n\ntest_data.title = test_data.title.map(fuse_title)\ntrain_data.title = train_data.title.map(fuse_title)","56c4b29d":"train_data['family_size'] = train_data.SibSp + train_data.Parch + 1\ntest_data['family_size'] = test_data.SibSp + test_data.Parch + 1","bb23fa7f":"train_data['is_alone'] = [1 if i<2 else 0 for i in train_data.family_size]\ntest_data['is_alone'] = [1 if i<2 else 0 for i in test_data.family_size]","8572142c":"train_data.drop(['Ticket'], axis=1, inplace=True)\ntest_data.drop(['Ticket'], axis=1, inplace=True)","980063bb":"train_data['calculated_fare'] = train_data.Fare \/ train_data.family_size\ntest_data['calculated_fare'] = test_data.Fare \/ test_data.family_size","735071e6":"def fare_group(fare):\n    \n    a= ''\n    if fare <= 4:\n        a = 'Very_low'\n    elif fare <= 10:\n        a = 'low'\n    elif fare <= 20:\n        a = 'mid'\n    elif fare <= 45:\n        a = 'high'\n    else:\n        a = \"very_high\"\n    return a\n\ntrain_data['fare_group'] = train_data['calculated_fare'].map(fare_group)\ntest_data['fare_group'] = test_data['calculated_fare'].map(fare_group)\n","d62e3ef3":"passengerids = test_data['PassengerId']\ntrain_data.drop(['PassengerId'], axis=1, inplace=True)\ntest_data.drop(['PassengerId'], axis=1, inplace=True)\n\ntrain_data.drop(['Embarked'], axis=1, inplace=True)\ntest_data.drop(['Embarked'], axis=1, inplace=True)","aca75f12":"women = train_data.loc[train_data.Sex == 0][\"Survived\"]\n\nrate_women = sum(women) \/ len(women)\nprint(\"% of women who survived: \", rate_women)\n\n\nmen = train_data.loc[train_data.Sex == 1][\"Survived\"]\nrate_men = sum(men) \/ len(men)\nprint(\"% of men who survived: \", rate_men)","157c47d7":"train_data\n","71121a97":"train_data = pd.get_dummies(train_data, columns=['title', \"Pclass\",'Cabin', 'fare_group'], drop_first=False)\ntest_data = pd.get_dummies(test_data, columns=['title', \"Pclass\", 'Cabin', 'fare_group'], drop_first=False)\n\n\ntrain_data.drop(['Name', 'Fare'], axis=1, inplace=True)\ntest_data.drop(['Name', 'Fare'], axis=1, inplace=True)\n","d2e40751":"train_data.columns","f51f0c27":"train_data = pd.concat([train_data[[\"Survived\", \"Age\", \"Sex\", \"SibSp\", \"Parch\"]], train_data.loc[:, \"family_size\":]], axis=1)\ntest_data = pd.concat([test_data[[\"Age\", \"Sex\"]], test_data.loc[: , \"SibSp\":]], axis=1)\ntrain_data","231441cb":"from sklearn.ensemble import RandomForestRegressor\n\n## writing a function that takes a dataframe with missing values and outputs it by filling the missing values. \ndef completing_age(df):\n    ## gettting all the features except survived\n    age_df = df.loc[:,\"Age\":] \n\n    temp_train = age_df.loc[age_df.Age.notnull()] ## df with age values\n    temp_test = age_df.loc[age_df.Age.isnull()] ## df without age values\n    \n    y = temp_train.Age.values ## setting target variables(age) in y \n    x = temp_train.loc[:, \"Sex\":].values\n    \n    rfr = RandomForestRegressor(n_estimators=1500, n_jobs=-1)\n    rfr.fit(x, y)\n    \n    \n    predicted_age = rfr.predict(temp_test.loc[:, \"Sex\":])\n    \n    df.loc[df.Age.isnull(), \"Age\"] = predicted_age\n    \n\n    return df\n\n## Implementing the completing_age function in both train and test dataset. \ncompleting_age(train_data)\ncompleting_age(test_data)\n","4c7714e5":"## Let's look at the his\nplt.subplots(figsize = (22,10),)\nsns.distplot(train_data.Age, bins = 100, kde = True, rug = False, norm_hist=False);","1ab80b4e":"\n## create bins for age\ndef age_group_fun(age):\n\n    a = ''\n    if age <= 1:\n        a = 'infant'\n    elif age <= 4: \n        a = 'toddler'\n    elif age <= 13:\n        a = 'child'\n    elif age <= 18:\n        a = 'teenager'\n    elif age <= 35:\n        a = 'Young_Adult'\n    elif age <= 45:\n        a = 'adult'\n    elif age <= 55:\n        a = 'middle_aged'\n    elif age <= 65:\n        a = 'senior_citizen'\n    else:\n        a = 'old'\n    return a\n        \n## Applying \"age_group_fun\" function to the \"Age\" column.\ntrain_data['age_group'] = train_data['Age'].map(age_group_fun)\ntest_data['age_group'] = test_data['Age'].map(age_group_fun)\n\n## Creating dummies for \"age_group\" feature. \ntrain_data = pd.get_dummies(train_data,columns=['age_group'], drop_first=True)\ntest_data = pd.get_dummies(test_data,columns=['age_group'], drop_first=True);\n","6ee61920":"# separating our independent and dependent variable\nX = train_data.drop(['Survived'], axis = 1)\ny = train_data[\"Survived\"]","0c531505":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.33, random_state=42)\n\nheaders = X_train.columns","83c455f1":"from sklearn.preprocessing import StandardScaler\nstd_scale = StandardScaler()\n\n## transforming \"train_x\"\nX_train_scaled = std_scale.fit_transform(X_train)\n## transforming \"test_x\"\nX_test_scaled = std_scale.transform(X_test)","665af772":"from sklearn.preprocessing import StandardScaler\nstd_scale = StandardScaler()\n\n## transforming \"train_x\"\nX_scaled = std_scale.fit_transform(X)\n## transforming \"test_x\"\ntest_data_scaled = std_scale.transform(test_data)\n\n","4b1fba2e":"\"\"\"\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel =RandomForestClassifier(criterion='gini',\n                              n_estimators=1100,\n                              max_depth=5,\n                              min_samples_split=4,\n                              min_samples_leaf=5,\n                              max_features='auto',\n                              oob_score=True,\n                              random_state=42,\n                              n_jobs=-1,\n                              verbose=1)\n\nmodel.fit(X_scaled, y)\n\npredictions = model.predict(test_data_scaled)\n\n\n\noutput = pd.DataFrame({'PassengerId': passengerid, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n\"\"\"","12810dc5":"from sklearn.model_selection import cross_val_score,GridSearchCV,RepeatedStratifiedKFold\nfrom sklearn.neighbors import KNeighborsClassifier\n\nrandom_state = 7\n\n## Define grid params\nparam_grid = {\"n_neighbors\":[3,4,5,6,7],\\\n             \"weights\":[\"uniform\",\"distance\"],\\\n             \"p\":[1,2]}\n\n## Define Kfold\nkfold = RepeatedStratifiedKFold(n_splits=5,n_repeats=3,random_state=random_state)\n\n## Define model\nmodel = KNeighborsClassifier()\n\n## Define and execute Grid Search\ngrid_search = GridSearchCV(model, param_grid=param_grid,\\\n                                       scoring=\"accuracy\",cv=kfold)\ngrid_result = grid_search.fit(X_scaled, y)\n\n## Get and print results\nbest_acc_score=grid_result.best_score_\nbest_params=grid_result.best_params_\nbest_model=grid_result.best_estimator_\n\nprint(\"Accuracy: {:6f}\".format(best_acc_score))\nprint(\"Params: {}\".format(best_params))","a96f2bb5":"## Fit best model on all training data set\nbest_model.fit(X_scaled, y)\n\n## Predict using the best model from training\npredictions = best_model.predict(test_data_scaled)\n\n## Save file to submit\noutput = pd.DataFrame({'PassengerId': passengerid, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","0b3ec2d2":"Pclass = 1 and Fare = 80 is at Embarked C. So I will fill them as C","556bfe30":"# 2. Feature Engineering","5c644661":"# 4. MODELS","97f0ebe1":"# 1. Data Cleaning"}}