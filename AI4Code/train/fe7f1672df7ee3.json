{"cell_type":{"21fa22b8":"code","7da68eb3":"code","09144033":"code","476139ef":"code","644cf0d1":"code","2bb72e78":"code","60740ca5":"code","891e08e7":"code","44a47d59":"code","be3021ee":"code","194e853c":"code","c3b0e232":"code","8fb23fca":"code","c2cedeb5":"code","b1633b27":"code","aba7c0aa":"code","37d83bb1":"code","962f88e7":"code","11fc26f7":"code","b5747690":"code","f42c0fb6":"code","0884baa4":"markdown","bc534168":"markdown","d0b6c7c5":"markdown","484400a9":"markdown","706e215c":"markdown","145ad510":"markdown","3b13f017":"markdown","44f49ce6":"markdown","33a43ba2":"markdown","e690baf8":"markdown","ab9603ec":"markdown","980895d2":"markdown","b9518d42":"markdown","31356e63":"markdown","d00797a9":"markdown","fda2ee5f":"markdown","4c2a9d8d":"markdown","55b6841a":"markdown"},"source":{"21fa22b8":"import random as r\nimport math as m\ninside = 0\ntotal = 100000\n# Iterate for the number of darts.\nfor i in range(0, total):\n    # Generate random x, y in [0, 1].\n    x2 = r.random()**2\n    y2 = r.random()**2\n    # Increment if inside unit circle.\n    if m.sqrt(x2 + y2) < 1.0:\n        inside += 1\nmystery = (float(inside) \/ total) * 4\nprint(mystery)","7da68eb3":"text_file = open(\"Output.txt\", \"w\")\ntext_file.write(\"Number: %s\" % mystery)\ntext_file.close()\n\n#Lets download the file we have just created.\n#add a new markdown cell with the following content:\n#<a href=\"Output.txt\"> Download File <\/a>\n#Run the cell.","09144033":"\n##Don't forget to turn the internet on. Right menu->settings->Internet.\n!pip install git+https:\/\/github.com\/goolig\/dsClass.git","476139ef":"from dsClass.path_helper import get_file_path\n%matplotlib inline\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n#very important, let talk about it\nf_name = get_file_path('fruit_data_with_colors.csv')\n\n","644cf0d1":"fruits = pd.read_csv(f_name)\nfruits.head()\n","2bb72e78":"#How many samples and features?\nfruits.shape","60740ca5":"#Which fruits?\nfruits['fruit_name'].unique()","891e08e7":"fruits.describe()","44a47d59":"#Is the data balanced?\nfruits.groupby('fruit_name').size()\n","be3021ee":"import seaborn as sns\n#We can also visualize it:\nsns.countplot(fruits['fruit_name'],label=\"Count\")\nplt.show()","194e853c":"fruits.drop('fruit_label', axis=1).plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False, figsize=(9,9), \n                                        title='Box Plot for each input variable')\nplt.savefig('fruits_box')\nplt.show()\n#Discuss box and whiskers plots","c3b0e232":"import pylab as pl\nfruits.drop('fruit_label' ,axis=1).hist(bins=30, figsize=(9,9))\npl.suptitle(\"Histogram for each numeric input variable\")\nplt.savefig('fruits_hist')\nplt.show()\n","8fb23fca":"\nimport matplotlib.pyplot as plt\ncorr = fruits.corr()\ncorr.style.background_gradient()\n","c2cedeb5":"from sklearn.model_selection import train_test_split\nfeature_names = ['mass', 'width', 'height', 'color_score']\n\nX = fruits[feature_names]\nX['volume'] = X['height']*X['width']\ny = fruits['fruit_name']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n","b1633b27":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(X_train,y_train) #TODO: complete the fit. Try Shift + Tab. Try pressing it twice, 3 and 4 times.\nprint('Accuracy of Logistic regression classifier on training set: {:.2f}'\n     .format(logreg.score(X_train, y_train)))\nprint('Accuracy of Logistic regression classifier on test set: {:.2f}'\n     .format(logreg.score(X_test, y_test)))\n","aba7c0aa":"from sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier().fit(X_train, y_train)\nprint('Accuracy of Decision Tree classifier on training set: {:.2f}'\n     .format(clf.score(X_train, y_train)))\nprint('Accuracy of Decision Tree classifier on test set: {:.2f}'\n     .format(clf.score(X_test, y_test)))\n","37d83bb1":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nprint('Accuracy of K-NN classifier on training set: {:.2f}'\n     .format(knn.score(X_train, y_train)))\nprint('Accuracy of K-NN classifier on test set: {:.2f}'\n     .format(knn.score(X_test, y_test)))\n","962f88e7":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)\nprint('Accuracy of GNB classifier on training set: {:.2f}'\n     .format(gnb.score(X_train, y_train)))\nprint('Accuracy of GNB classifier on test set: {:.2f}'\n     .format(gnb.score(X_test, y_test)))\n","11fc26f7":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)  \nprint('Accuracy of rf classifier on training set: {:.2f}'\n     .format(clf.score(X_train, y_train)))\nprint('Accuracy of rf classifier on test set: {:.2f}'\n     .format(clf.score(X_test, y_test)))","b5747690":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\npred = knn.predict(X_test)\nprint(confusion_matrix(y_test, pred))\nprint(classification_report(y_test, pred))\n","f42c0fb6":"ans = pd.DataFrame(X_test)\nans['prediction'] = list(knn.predict(X_test))\nans","0884baa4":"Installing our package","bc534168":"# Data\nThe fruits dataset was created by Dr. Iain Murray from University of Edinburgh. He bought a few dozen oranges, lemons and apples of different varieties, and recorded their measurements in a table. And then the professors at University of Michigan formatted the fruits data slightly and it can be downloaded from here.\n","d0b6c7c5":"# Welcome \nMistery code, practice simple syntax, what does it do?","484400a9":"Adding our prediction to the test set:","706e215c":"# Random Forest","145ad510":"# What can we do to improve our performance? \n1. Feature engineering: sclaing. \n2. Let's add some features. After evaluating the results we can \n3. Are the results consistent?","3b13f017":"# Naive Bayes","44f49ce6":"# KNN","33a43ba2":"# Evaluation","e690baf8":"Print to file:","ab9603ec":"# Decision Tree\n\nAdd code to train a deicsion tree.","980895d2":"# Preprocessing","b9518d42":"Let's have a look at correlation:","31356e63":"# Data exploration\nLet\u2019s read it and have a look the first a few rows of the data.","d00797a9":"# Source for the following code: https:\/\/towardsdatascience.com\/solving-a-simple-classification-problem-with-python-fruits-lovers-edition-d20ab6b071d2","fda2ee5f":"What can you say about each of the features? let's invistigate","4c2a9d8d":"# Classification:","55b6841a":"Tips for using jupyter: https:\/\/www.dataquest.io\/blog\/jupyter-notebook-tips-tricks-shortcuts\/\n\nNew to python? Here is a short tutorial for python: https:\/\/www.tutorialspoint.com\/python3\/python_basic_syntax.htm"}}