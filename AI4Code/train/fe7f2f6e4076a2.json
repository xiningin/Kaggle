{"cell_type":{"ec8b7923":"code","5a25d3df":"code","0da8a6a3":"code","d525742d":"code","1734a545":"code","b6c7eb33":"code","beca3c98":"code","275ea8d7":"code","3d18dd49":"code","c1e0f65b":"code","f50eaf9f":"code","1e651624":"code","61a36dcc":"code","243516d7":"code","3f1a05df":"code","181443f1":"code","22259148":"code","f3e6dc61":"code","8205fd79":"code","b1c256d6":"markdown"},"source":{"ec8b7923":"import os\nimport cv2\nimport numpy as np\nimport time\nimport itertools\n\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom keras import callbacks\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model, load_model\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l1\nfrom keras.applications import ResNet50\nfrom keras.layers import Dense, LeakyReLU, Flatten, Dropout, GlobalAveragePooling2D, Conv2D, AveragePooling2D\nfrom keras.utils.np_utils import to_categorical\n\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nimport matplotlib.pyplot as plt\n%matplotlib inline","5a25d3df":"# some global constants\nsclasses = [\"brightpixel\",\n            \"narrowband\",\n            \"narrowbanddrd\",\n            \"noise\",\n            \"squarepulsednarrowband\",\n            \"squiggle\",\n            \"squigglesquarepulsednarrowband\"]\n\nmodel_name = \"seti_model\"\nepochs = 100\nlearning_rate = 0.00146\nbatch_size = 50\nsteps_per_epoch = 150\noutput_classes = len(sclasses)\nloss = \"categorical_crossentropy\"\nparameter_scaling = 36\nregularizer = 0.0 #1.0e-7\nmodel_location = \".\/model\"\ntensorboard = \".\/tensorboard\"\nchannels = 1\npreprocess = True\nclip_outliers = True\npreprocess = True\ngaussian_blurr = False\naugument = True\naugument_size = 200\nimage_width = 224\nimage_hieght = 224\ninput_shape = (image_width, image_hieght, channels)","0da8a6a3":"# pre process and image passed \ndef preprocess_image(image, resize=True, grayscale=False):\n    # if grayscale\n    if grayscale:\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    if clip_outliers:\n        mean = np.mean(image)\n        std = np.std(image)\n        # clip all the values which are 3.5 standard deviations away from mean\n        image = np.clip(image, mean-3.5*std, mean+3.5*std)\n    if gaussian_blurr:\n        image = cv2.GaussianBlur(image, (3, 3), 1)\n    # morph close \n    morphed = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel=np.ones((3, 3), dtype=np.float32))\n    # gradient in both directions\n    sobelx = cv2.Sobel(morphed, cv2.CV_64F, 1, 0, 2)\n    sobely = cv2.Sobel(morphed, cv2.CV_64F, 0, 1, 2)\n    # final weight with a concentration in horizontal gradient\n    blended = cv2.addWeighted(src1=sobelx, alpha=0.7, src2=sobely, beta=0.3, gamma=0)\n    if resize:\n        resized = cv2.resize(blended, (image_width, image_hieght))\n    reshaped = resized.reshape(image_width, image_hieght, channels)\n    _image = reshaped\/255.0\n    # start by resizing the image\n    \n    return _image","d525742d":"def augument_images(images=None):\n    datagen = ImageDataGenerator(width_shift_range=0.01,\n                                 height_shift_range=0.01,\n                                 zoom_range=0.01,\n                                 shear_range=0.01,\n                                 horizontal_flip=True,\n                                 vertical_flip=True,\n                                 preprocessing_function=preprocess_image,\n                                 rotation_range=3.0)\n    #datagen.fit(images)\n    #images_batch = next(datagen.flow(x=images, y=None, batch_size=augument_size))\n    return datagen","1734a545":"# gets the data from a directory, applies preprocessing to each image and stores in a numpy array\ndef get_data(primary_dir, augument=False):\n    X = np.empty(shape=(0, image_width, image_hieght, channels))\n    Y = np.empty(shape=(0, ))\n    _global_index = -1\n    for sclass in sclasses:\n        # loop through directories\n        sclass_dir = os.path.join(primary_dir, sclass)\n        print(\"Sclass: {}\".format(sclass))\n        _x = []\n        _y = []\n        for index, filename in enumerate(os.listdir(sclass_dir)):\n            if index % 200 == 0:\n                print(\"Pre-processing {}st image in {} class\".format(index+1, sclass))\n            _global_index += 1\n            _image = cv2.imread(os.path.join(sclass_dir, filename))\n            _image = preprocess_image(_image, resize=True, grayscale=True)\n            # into local list\n            _x.insert(index, _image)\n            _y.insert(index, sclass)\n        # augument to generate more training data\n        if augument:\n            x_aug = augument_images(np.array(_x))\n            y_aug = [sclass]*len(x_aug)\n            _x.extend(x_aug.tolist())\n            _y.extend(y_aug)\n            _global_index += augument_size\n            print(\"Augumented {} images for the class: \\\"{}\\\"\".format(augument_size, sclass))\n        _x = np.array(_x)\n        _y = np.array(_y)\n        # print(\"yshape: {}\".format(_y.shape))\n        # into global list\n        X = np.append(X, _x, axis=0)\n        Y = np.append(Y, _y, axis=0)\n        print(\"Data Extraction complete for class: \\\"{}\\\"\".format(sclass))\n        encoder = LabelEncoder()\n        Y = encoder.fit_transform(Y)\n        print(\"Encoded target labels...\")\n        # print(\"Global Index: {}\".format(_global_index))\n    return X, Y","b6c7eb33":"\"\"\"\ndef model():\n    scale = parameter_scaling\n    # model architecture\n    _model = Sequential()\n\n    # convolution 1\n    _model.add(Conv2D(scale, (3, 3), input_shape=input_shape))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(MaxPooling2D(pool_size=(2, 2)))\n    _model.add(Dropout(0.2))\n\n    # convolution 2\n    _model.add(Conv2D(2*scale, (3, 3)))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(MaxPooling2D(pool_size=(2, 2)))\n    _model.add(Dropout(0.1))\n\n    # convolution 3\n    _model.add(Conv2D(3*scale, (3, 3)))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(MaxPooling2D(pool_size=(2, 2)))\n    _model.add(Dropout(0.1))\n\n    # convolution 4\n    _model.add(Conv2D(4*scale, (3, 3)))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(MaxPooling2D(pool_size=(2, 2)))\n    _model.add(Dropout(0.1))\n\n    # convolution 5\n    _model.add(Conv2D(5*scale, (3, 3)))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(MaxPooling2D(pool_size=(2, 2)))\n    _model.add(Dropout(0.1))\n\n    # convolution 6\n    _model.add(Conv2D(6*scale, (3, 3)))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(MaxPooling2D(pool_size=(2, 2)))\n    _model.add(Dropout(0.1))\n\n    # convolution 7\n    _model.add(Conv2D(7*scale, (3, 3)))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(MaxPooling2D(pool_size=(2, 2)))\n    _model.add(Dropout(0.1))\n\n    # flattening layer\n    _model.add(Flatten())\n\n    # first dense layer\n    _model.add(Dense(units=7*scale))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(Dropout(0.5))\n\n    # second dense layer\n    _model.add(Dense(units=7*scale))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(Dropout(0.5))\n\n    # third dense layer\n    _model.add(Dense(units=7*scale))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(Dropout(0.5))\n\n    # output layer\n    _model.add(Dense(output_classes, activation=\"softmax\"))\n\n    # optimizer\n    _model.compile(Adam(lr=learning_rate), loss=loss, metrics=[\"accuracy\"])\n    print(_model.summary())\n    return _model\n\"\"\"\n\n\n\n\n","beca3c98":"def model():\n    _model = ResNet50(\n        weights= None, \n        include_top=False, \n        input_shape= (image_width, image_hieght, 1)\n    )\n    x = _model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.7)(x)\n    predictions = Dense(output_classes, activation= \"softmax\")(x)\n    model = Model(inputs = _model.input, outputs = predictions)\n    return model","275ea8d7":"def fit(model, train, X_val, y_val, save_model=False):\n        # callbacks\n        h_callbacks = [\n            callbacks.TensorBoard(\n                log_dir=tensorboard,\n                write_graph=True,\n                write_images=False\n            )\n        ]\n        # train on default gpu\n        with tf.device('\/gpu:0'):\n            config = tf.ConfigProto()\n            config.gpu_options.allow_growth = True\n            sess = tf.Session(config=config)\n            # fit the data\n            history = model.fit_generator(train,\n                                          epochs=epochs,\n                                          steps_per_epoch=steps_per_epoch,\n                                          validation_data=(X_val, y_val),\n                                          shuffle=True,\n                                          verbose=1,\n                                          callbacks=None)\n        if save_model:\n            # write model configs back\n            with open(os.path.join(model_location, \"{}.json\".format(model_name)), \"w\") as model_json:\n                model_json.write(model.to_json())\n                print(\"Saved Model json to disk\")\n            # save weights to h5\n            model.save_weights(os.path.join(model_location, \"{}.h5\".format(model_name)))\n            print(\"Saved Model weights to disk\")\n        return history","3d18dd49":"# wrapper for the fit just in case if needed additional functionality\ndef train(train, X_val, y_val):\n        _model = model()\n        _model.compile(loss=\"categorical_crossentropy\",\n                       optimizer=\"adam\",\n                       metrics=[\"accuracy\"])\n        history = fit(_model, train, X_val, y_val, save_model=False)\n        return _model, history","c1e0f65b":"# train generator because the training data is large and having it in memory is expensive\nimage_generator = augument_images()\ntrain_image_generator = image_generator.flow_from_directory(os.path.join(\"..\/input\/primary_small\/train\"),\n                                                           batch_size=batch_size,\n                                                           color_mode=\"grayscale\",\n                                                           target_size=(image_width, image_hieght))","f50eaf9f":"X_val, y_val = get_data(os.path.join(\"..\/input\/primary_small\/valid\"))\nX_test, y_test = get_data(os.path.join(\"..\/input\/primary_small\/test\"))","1e651624":"# encode labels\n#encoder = LabelEncoder()\n#encoder.fit(y_val)\n#encoded_ = encoder.transform(y_val)\ny_val = to_categorical(y_val, output_classes)","61a36dcc":"# train for the given configs\n__model, history = train(train_image_generator, X_val, y_val)","243516d7":"y_hat = __model.predict_classes(X_test)","3f1a05df":"encoder_test = LabelEncoder()\nencoder_test.fit(y_test)\nencoded_test = encoder_test.transform(y_test)\ny_test = to_categorical(encoded_test, output_classes)\ny_test = np.argmax(y_test, axis=1)","181443f1":"# plot the loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","22259148":"# plotting accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","f3e6dc61":"print(\"Classification Report\")\nprint(classification_report(y_test, y_hat, digits=5))","8205fd79":"print(\"Accuracy: {}\".format(accuracy_score(y_test, y_hat)))","b1c256d6":"We will start by defining some global constants which includes hyper-parameters as well. I will be adding more comments\/explanation about the model and classification as I get some time."}}