{"cell_type":{"bfe2cbea":"code","782ed311":"code","779c9f0c":"code","3f75f1f6":"code","f3c2d61d":"code","3ecdd546":"code","d1592364":"code","5fe8af3a":"code","5f2713cf":"code","10cd2d3f":"code","79149f5f":"code","825c0526":"code","538f7215":"code","397353cd":"code","646ce1a2":"code","cfa1bf9c":"code","603c6a41":"code","895562a9":"code","f85c60d1":"code","2472c165":"code","5430e4a8":"code","5310138d":"code","fced8cc2":"code","fec8a540":"code","eed1ab82":"code","747f36e2":"code","b32c6e14":"code","22f36174":"code","8e8c6524":"code","1708f808":"code","df421967":"code","70ac7e37":"code","749529bd":"markdown","02142f15":"markdown","2931e01b":"markdown","252752f4":"markdown","9169c01c":"markdown","c40b1d4d":"markdown","09dbb68d":"markdown","29782c70":"markdown","5937c015":"markdown","ae7c9369":"markdown","043fefb5":"markdown","28cd42ce":"markdown","8b6ea9a7":"markdown","3997fdde":"markdown","dccbf8fe":"markdown","a12d98ed":"markdown","4e74c515":"markdown","70e94ad5":"markdown","29778569":"markdown","8046822b":"markdown","9757f241":"markdown","92542077":"markdown","490bba51":"markdown","d9e5c042":"markdown","6d67cc7f":"markdown"},"source":{"bfe2cbea":"%reload_ext autoreload\n%autoreload 2","782ed311":"import pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom pathlib import Path\n\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate\n\nfrom PIL import Image","779c9f0c":"inputs=Path(\"..\/input\/digit-recognizer\")\nos.listdir(inputs)","3f75f1f6":"# load training data and explore the first three rows\ntrain=pd.read_csv(inputs\/\"train.csv\")\ntrain.head(3)","f3c2d61d":"# load test data and explore the first three rows\ntest=pd.read_csv(inputs\/\"test.csv\")\ntest.head(3)","3ecdd546":"# tfms can be passed directly to define a DataBunch object (see below) which is then associated with a model to begin training.\ntfms = get_transforms(do_flip=False) # if True the image is randomly flipped\ntr=Path(\"..\/train\")\nte=Path(\"..\/test\")","d1592364":"for index in range(10):\n    try:\n        os.makedirs(tr\/str(index))\n    except:\n        pass","5fe8af3a":"sorted(os.listdir(tr))","5f2713cf":"try:\n    os.makedirs(te)\nexcept:\n    pass\n","10cd2d3f":"for index, row in train.iterrows():\n    \n    label,digit = row[0], row[1:]\n    \n    filepath = tr\/str(label)\n    filename = f\"{index}.jpg\"\n    \n    digit = digit.values\n    digit = digit.reshape(28,28)\n    digit = digit.astype(np.uint8)\n    \n    img = Image.fromarray(digit)\n    img.save(filepath\/filename)\n    \n    ","79149f5f":"for index, digit in test.iterrows():\n\n    filepath = te\n    filename = f\"{index}.jpg\"\n    \n    digit = digit.values\n    digit = digit.reshape(28,28)\n    digit = digit.astype(np.uint8)\n    \n    img = Image.fromarray(digit)\n    img.save(filepath\/filename)","825c0526":"def displayRandomImagesFromEveryFolder(directory=tr, samplesPerDigit=5):\n\n    fig = plt.figure(figsize=(5,10))\n    \n    for rowIndex in range(1, 10):\n        subdirectory = str(rowIndex)\n        path = directory\/subdirectory\n        images = os.listdir(path)\n        for sampleIndex in range(1,samplesPerDigit+1):\n            randomNumber = random.randint(0, len(images)-1)\n            image = Image.open(path\/images[randomNumber])\n            ax = fig.add_subplot(10, 5, samplesPerDigit*rowIndex + sampleIndex)\n            ax.axis(\"off\")\n            \n            plt.imshow(image, cmap='gray')\n            \n    \n    plt.show()\n    \ndisplayRandomImagesFromEveryFolder()","538f7215":"data = ImageDataBunch.from_folder(path=\"..\/train\",test=\"..\/test\",ds_tfms=tfms, valid_pct=0.2,bs=32,size=24).normalize(imagenet_stats)","397353cd":"data.show_batch(rows=3 ,figsize=(5,5))","646ce1a2":"print(data.classes)","cfa1bf9c":"learn = cnn_learner(data, models.resnet50, metrics=accuracy, model_dir = Path('..\/kaggle\/input\/ResNet-50'), callback_fns=ShowGraph)","603c6a41":"# find optimal learning rate and plot the graph\nlearn.lr_find()\n# plot loss vs. learning rate\nlearn.recorder.plot()","895562a9":"learn.fit_one_cycle(5)","f85c60d1":"learn.save(\"501\")","2472c165":"learn.unfreeze()\nlearn.fit_one_cycle(5,max_lr=slice(1e-3,1e-1))","5430e4a8":"learn.save(\"502\")","5310138d":"interp=ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix(figsize=(8,8))","fced8cc2":"interp.most_confused(min_val=3)","fec8a540":"interp.plot_top_losses(9,figsize=(7,7))","eed1ab82":"class_score,y=learn.get_preds(DatasetType.Test)","747f36e2":"probs= class_score[0].tolist()\n[f\"{index}: {probs[index]}\" for index in range(len(probs))]","b32c6e14":"class_score=np.argmax(class_score,axis=1)","22f36174":"class_score[0].item()","8e8c6524":"samplesub=pd.read_csv(inputs\/\"sample_submission.csv\")\nsamplesub.head()","1708f808":"ImageId = [os.path.splitext(path)[0] for path in os.listdir(te)]\nImageId = [int(path) for path in ImageId]\nImageId = [ID+1 for ID in ImageId]\nImageId[:5]","df421967":"subs=pd.DataFrame({\"ImageId\":ImageId,\"Label\":class_score})","70ac7e37":"subs.to_csv(\"submission.csv\",index=False)\nsubs.head(3)","749529bd":"**From this, we can see which two numbers are confused most and the number of times.**","02142f15":"# What is Fastai?\n> Fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library.","2931e01b":"**The cnn_learner factory method helps you to automatically get a pretrained model from a given architecture with a custom head that is suitable for your data.**","252752f4":"# Results\n\n**We can interpret our results as well:**","9169c01c":"**And that's it. A Simple model that gives an accuracy of > 99% with such few lines.**","c40b1d4d":"# Display images ","09dbb68d":"**The dataset has been converted into images!**\n\n**We can move on to getting the data from folders, and seperating them into training and validation sets. Also normalization is very important to make sure all values lie between 0 and 1.**\n\n**It turns out that the PosixPath is not iterated by ImageDataBunch in Kaggle.So we can change the path created by pathlib library which was a PosixPath object to just a string which specifies the path to the training and testing directories, so in our case train path = \"..\/train\" and test path = \"..\/test\"**","29782c70":"# Importing the necessary libraries:","5937c015":"**These are the probabilities that the image is any of these numbers. But we don't want that. We only want the highest probability:**","ae7c9369":"# Prepare Data\n**Currently, it is not even an image, just a 0s and 1s, as seen from the training set. Using the functions below, we can convert them into images:**","043fefb5":"# Image transforms","28cd42ce":"**Now, let's try with the optimal learning rates:**","8b6ea9a7":"**97% accuracy, not bad at all.**\n\n**Saving this model:**","3997fdde":"**We can clearly see that the learning rate is most effective at 1e-01, but let's try without a predefined learning rate:**","dccbf8fe":"# Training \n\n* **The fastai library includes several pretrained resnet models from torchvision, namely:**\n  **resnet18, resnet34, resnet50, resnet101, resnet152**\n* **It makes it very easy to use Resnet50.** \n* **Then, we can use the cnn_learner function, and create a Convolutional Neural Network.** ","a12d98ed":"# MNIST using FastAI\n> MNIST (\"Modified National Institute of Standards and Technology\") is the de facto \u201chello world\u201d dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. \n\n> It is definitely possible to build a really well functioning digit recognizer for Kaggle's playground competition. In fact, this model gets more than  99% accuracy. For such a simple and elegant solution I have to say, that's not bad at all. ","4e74c515":"**Next, we can figure out what ideal learning rates are:**","70e94ad5":"# Prediction","29778569":"# Submission\n\nNow, creating the submission file based on the example given (which should contain ImageId and Label):","8046822b":"**The data has been successfully extracted from the folders.**\n\n**We can also check what classes exist:**","9757f241":"# *Please upvote the kernel if you find it useful*","92542077":"**To get a set of transforms with default values that work pretty well in a wide range of tasks, it's often easiest to use get_transforms.**                                                                                                     \n* **tfms is just a parameter used later during training, which is initalized here.** \n* **tr and te are paths to be used.**","490bba51":"**These are the images which had the highest loss, that is the biggest difference between the probability of being corect and actually being correct. Looking at these images, it is actually pretty difficult to distinguish some of these images, so we can be sure that the CNN is actually working pretty well, if it knows these are difficult to differentiate.**","d9e5c042":"# Read the train and test datasets:","6d67cc7f":"**We have to try and get the dataset into a folder format, from the existing format, which will make it easier to use fastai's functions.**"}}