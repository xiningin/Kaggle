{"cell_type":{"dbd66c9c":"code","fdad898e":"code","d810d0d7":"code","4722cea9":"code","bc91531b":"code","480dbffa":"code","0cf7126b":"code","54d9a029":"code","839c6528":"code","ff0b842c":"code","4520b403":"code","6c09a700":"code","ea405e84":"code","e99b0cbe":"code","23e91f6e":"code","6862ab33":"code","449e8b2f":"code","f146094a":"code","03131ff8":"code","0e016402":"code","0253fe30":"code","dae6333d":"code","b1367ab3":"code","1b2e442b":"code","4801c513":"code","ca026ac3":"code","da51bb42":"code","435b39c4":"code","33082e98":"code","fc1b350c":"code","14ae805a":"markdown","7a8e5544":"markdown","57bd2861":"markdown","e8449294":"markdown","37e1d848":"markdown","b775e56f":"markdown","a5804979":"markdown","9b3ef172":"markdown","8490fbd0":"markdown","fc91bbce":"markdown","716eabfb":"markdown","4bf20d22":"markdown"},"source":{"dbd66c9c":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('display.max_columns', None)  \npd.set_option('display.expand_frame_repr', False)\npd.set_option('max_colwidth', None)\n\nimport pandas_profiling\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\n\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fdad898e":"df = pd.read_csv('\/kaggle\/input\/credit-card-customers\/BankChurners.csv')\ndf = df.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1'], axis=1)\ndf","d810d0d7":"#let's explore our features\n\nprofile = pandas_profiling.ProfileReport(df)\nprofile","4722cea9":"sns.displot(df, x=\"Customer_Age\", hue=\"Attrition_Flag\")\nsns.displot(df, x=\"Dependent_count\", hue=\"Attrition_Flag\")","bc91531b":"sns.displot(df, x=\"Months_on_book\", hue=\"Attrition_Flag\")","480dbffa":"sns.displot(df, x=\"Total_Relationship_Count\", hue=\"Attrition_Flag\")","0cf7126b":"sns.displot(df, x=\"Months_Inactive_12_mon\", hue=\"Attrition_Flag\")","54d9a029":"sns.displot(df, x=\"Contacts_Count_12_mon\", hue=\"Attrition_Flag\")","839c6528":"sns.displot(df, x=\"Credit_Limit\", hue=\"Attrition_Flag\")","ff0b842c":"sns.displot(df, x=\"Total_Revolving_Bal\", hue=\"Attrition_Flag\")\nsns.displot(df, x=\"Avg_Open_To_Buy\", hue=\"Attrition_Flag\")\nsns.displot(df, x=\"Total_Amt_Chng_Q4_Q1\", hue=\"Attrition_Flag\")","4520b403":"sns.displot(df, x=\"Total_Trans_Amt\", hue=\"Attrition_Flag\")\nsns.displot(df, x=\"Total_Trans_Ct\", hue=\"Attrition_Flag\")\nsns.displot(df, x=\"Total_Ct_Chng_Q4_Q1\", hue=\"Attrition_Flag\")","6c09a700":"sns.displot(df, x=\"Avg_Utilization_Ratio\", hue=\"Attrition_Flag\")","ea405e84":"sns.countplot(x ='Gender', hue='Attrition_Flag', data=df)","e99b0cbe":"sns.countplot(x ='Education_Level', hue='Attrition_Flag', data=df)","23e91f6e":"sns.countplot(x ='Marital_Status', hue='Attrition_Flag', data=df)","6862ab33":"sns.countplot(x ='Income_Category', hue='Attrition_Flag', data=df)","449e8b2f":"sns.countplot(x ='Card_Category', hue='Attrition_Flag', data=df)","f146094a":"pip install ppscore","03131ff8":"def heatmap(df):\n    df = df[['x', 'y', 'ppscore']].pivot(columns='x', index='y', values='ppscore')\n    fig, ax = plt.subplots(figsize=(20,20)) \n    ax = sns.heatmap(df, vmin=0, vmax=1, cmap=\"Blues\", linewidths=0.5, annot=True)\n    ax.set_title(\"PPS matrix\")\n    ax.set_xlabel(\"feature\")\n    ax.set_ylabel(\"target\")\n    return ax\n\nimport ppscore as pps\nmatrix = pps.matrix(df)\nheatmap(matrix)","0e016402":"df.Attrition_Flag = df.Attrition_Flag.replace({'Attrited Customer':1,'Existing Customer':0})","0253fe30":"#using Label Encoder for categorical features in case wewill use them for a model\n\nfor column in df.columns:\n    if df[column].dtype == np.number:\n        continue\n    df[column] = LabelEncoder().fit_transform(df[column])\ndf.head(10)","dae6333d":"#making a function for evaluation model results, using confusion_matrix, classification_report\n\ndef evaluate(y_actual, y_hat):\n    matrix = confusion_matrix(y_actual, y_hat)\n\n    sns.heatmap(pd.DataFrame(matrix), annot = True, cmap ='PuBu', fmt = 'g')\n    plt.ylabel('Actual')\n    plt.xlabel('Predicted')\n    \n    labels = ['Existing', 'Churn']\n    print(classification_report(y_actual, y_hat, target_names = labels))","b1367ab3":"#dropping categorical features\nX = df.drop(['Attrition_Flag', 'CLIENTNUM', 'Education_Level', 'Credit_Limit', \"Customer_Age\", \n             'Dependent_count', 'Marital_Status','Card_Category', 'Gender', 'Income_Category'], axis = 1)\nX = RobustScaler().fit_transform(X)\n             \ny = df['Attrition_Flag']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)","1b2e442b":"#set a proportion between negative and positive results for further usage in XGBoost\nscale_num = int(y_train.value_counts().values[0]\/y_train.value_counts().values[1])\nscale_num","4801c513":"#modeling with handling imbalance in XGBoost \n\nxgb = XGBClassifier(n_estimators = 70, verbosity = 1, use_label_encoder=False, scale_pos_weight = scale_num)\nxgb.fit(X_train, y_train)\npredictions_xgb = xgb.predict(X_test)\nevaluate(y_test, predictions_xgb)","ca026ac3":"#checking AUC score\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, predictions_xgb)\nauc = metrics.auc(fpr, tpr)\nprint(auc)","da51bb42":"from imblearn.over_sampling import SMOTE\noversampler = SMOTE(random_state = 66)\nx_train_smote, x_test_smote, y_train_smote, y_test_smote = train_test_split(X, y, test_size = 0.3,\n                                                                            random_state = 66)\nx_oversample, y_oversample = oversampler.fit_sample(x_train_smote, y_train_smote)\ny_oversample.value_counts() ","435b39c4":"#modeling using XGBoost with smote sets and classical parameters\nxgb_smote = XGBClassifier(use_label_encoder=False)\nxgb_smote.fit(x_oversample, y_oversample)\n\npredictions_smote = xgb_smote.predict(x_test_smote)\nevaluate(y_test_smote, predictions_smote)","33082e98":"classifier = CatBoostClassifier(\n    random_state=42, border_count=100,\n    depth=6, iterations=100, l2_leaf_reg=100,\n    learning_rate=0.1,auto_class_weights='Balanced',\n    verbose=False\n)\n\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\nevaluate(y_test, y_pred)","fc1b350c":"fpr_cat, tpr_cat, thresholds_cat = metrics.roc_curve(y_test, y_pred)\nauc = metrics.auc(fpr_cat, tpr_cat)\nprint(auc)","14ae805a":"As we can't talk about nmal distribution here (after 3 number of attrited customers is pretty the same for 4, 5 and 6), so, this column may be important for our model. ","7a8e5544":"All previous graphs show that the more money customers spend the less likely they become churned. Again, with some outliers.  Seems like those people took credit once for a buying an expensive thing like a house or a flat.\nAverage Utilization Ratio shows that there is the highest chance for churn if this ratio equals 0.","57bd2861":"Clients are mostly active that can be notactive during 1-3 months period. There are a few of them who has been inanctive during 5 or6 months and surprisingly they still are existing customers.\nIn the graph below it is clea that the more contacts within 12 months, the highest probability for a client to attrite. ","e8449294":"Now let's try SMOTE - oversampling of positive samples to make equal quality of positive and negative examples","37e1d848":"We have 6 categorical and 15 numerical columns, no missing values. The dataset is imbalanced, there are 8500 and 1627 of existing and attrited clients respectively. Customer age distribution is normal, the numbers of femae and male clients are roughly equal. Numbers of married and single clients are also quite close. \nThe 'less than $40k' category incudes the biggest quantity of clients in this dataset. Most of the clients have Blue card, 555 have Silver one, 16 have Gold and only 20 clients have Platinum card.   Let's have a look at these and other features with respect to Attrition Flag if we can find some interesting patterns there.","b775e56f":"Generally, the lower credit limit is, the higher the probablity of attrition is. There is an outlier - maximum available credit limit - 35000. Roughly 1\/4 of clients with this limit are attrited.","a5804979":"It seems SMOTE didn't improve the results with XGBoost, recall became even lower than it was before.\nTime to try another classification algorithm - CatBoostClassifier.","9b3ef172":"**In the end, CatBoost did the best job. Recall 95% is pretty nice result for business in this case. Precision is very low - only 72%, but it is not very important here. Thank you for reading this notebook.**","8490fbd0":"Card Category and Income Category have roughly the same proportions in categories for Churn and Existing customers.\nLet's have a look at Predictive Power Score matrix and discover if there are other than linear relationships between features and target variable.","fc91bbce":"Here attrition is normally distributed, so we may think about excluding these features after looking at PPS matrix later.","716eabfb":"Nothing unusual in Gender, Education Level and Marital Status distribution of Churned clients.","4bf20d22":"Months on book looks very unsual, like there are a lot (2000) of clients who spent here exactly 36 months or so and almost 500 of them are attrited."}}