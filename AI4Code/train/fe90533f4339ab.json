{"cell_type":{"4d6da31f":"code","1900ee6c":"code","5e04af4a":"code","e47afb11":"code","40bdc902":"code","97ecb4e5":"code","4137214d":"code","dad0b350":"code","2e0bfe90":"code","0e8a27b8":"code","95bc1a32":"code","d21ef3b2":"code","d2205510":"code","084929bf":"code","f069b8e0":"code","50f2cfa2":"code","6f36a837":"markdown","8b9c394e":"markdown","e5dbad27":"markdown"},"source":{"4d6da31f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nos.listdir(\"\/kaggle\/input\/\")\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1900ee6c":"from keras import applications\nfrom keras.models import Model\nfrom keras.layers import Input,concatenate\nfrom keras.optimizers import Adam\nimport keras.backend as K\nimport tensorflow as tf\nimport cv2\n\nimport random","5e04af4a":"import tensorflow\nprint(tensorflow.__version__)","e47afb11":"gen=\"..\/input\/handwritten-signatures\/sample_signature\/sample_Signature\/genuine\"\nforg=\"..\/input\/handwritten-signatures\/sample_signature\/sample_Signature\/forged\"\n\ngentr=\"..\/input\/sigcomp-2009-train\/sigcomp 2009 train\/Sigcomp 2009 train\/genuine\"\nforgtr=\"..\/input\/sigcomp-2009-train\/sigcomp 2009 train\/Sigcomp 2009 train\/forgeries\"\n\ngent=\"..\/input\/sigcomp-2009\/sigcomp 2009\/genuines\"\nforgt=\"..\/input\/sigcomp-2009\/sigcomp 2009\/forgeries\"","40bdc902":"img_width, img_height, channels = 224, 224, 3\n\ndim = (img_width, img_height)\n\ndef to_rgb(img):\n    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA) \n    img_rgb = np.asarray(np.dstack((img, img, img)), dtype=np.uint8)\n    return img_rgb\n\ndef returnimages(path,img):\n    image=cv2.imread(path+\"\/\"+ img)                  #bringing the image\n    image=cv2.resize(image, (img_width, img_height))\n    image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    image=to_rgb(image).reshape(1,img_width, img_height,3)\/255.0       #resizing and normalizing    \n    return image\n\ndef getfiles(num,gen,forg):\n    a=os.listdir(gen)\n    b=os.listdir(forg)\n    c=str(num)\n    c=c[2:]\n    if(len(c)==2):\n        c=c+\"0\"\n    \n    n,m=[],[]\n    for i in b:\n        if i.endswith(c+\".png\"):\n            n=n+[i]\n        elif i.endswith(c+\".PNG\"):\n            n=n+[i]\n    for i in a:\n        if i.endswith(c+\".png\"):\n            m=m+[i]\n        elif i.endswith(c+\".PNG\"):\n            m=m+[i]\n    return m.pop(),n,m\n\ndef getfiles2(num):\n    a=os.listdir(gentr)\n    b=os.listdir(forgtr)\n    c=str(num)\n    c=c[2:]\n    if(len(c)==2):\n        c=c+\"0\"\n    n,m=[],[]\n    for i in b:\n        if (i.endswith(c+\"_001_6g.png\") or i.endswith(c+\"_002_6g.png\") or i.endswith(c+\"_003_6g.png\")\n            or i.endswith(c+\"_004_6g.png\") or i.endswith(c+\"_005_6g.png\")):\n            n=n+[i]\n        elif (i.endswith(c+\"_001_6g.PNG\") or i.endswith(c+\"_002_6g.PNG\") or i.endswith(c+\"_003_6g.PNG\")\n              or i.endswith(c+\"_004_6g.PNG\") or i.endswith(c+\"_005_6g.PNG\")):\n            n=n+[i]\n    for i in a:\n        if (i.endswith(c+\"_001_6g.png\") or i.endswith(c+\"_002_6g.png\") or i.endswith(c+\"_003_6g.png\")\n            or i.endswith(c+\"_004_6g.png\") or i.endswith(c+\"_005_6g.png\")):\n            m=m+[i]\n        elif (i.endswith(c+\"_001_6g.PNG\") or i.endswith(c+\"_002_6g.PNG\") or i.endswith(c+\"_003_6g.PNG\")\n              or i.endswith(c+\"_004_6g.PNG\") or i.endswith(c+\"_005_6g.PNG\")):\n            m=m+[i]\n    return m.pop(),n,m","97ecb4e5":"def triplet_loss(y_true, y_pred):\n    alpha = 0.5\n    anchor, positive, negative =y_pred[0,0:512], y_pred[0,512:1024], y_pred[0,1024:1536]\n    \n    positive_distance = K.mean(K.square(anchor - positive),axis=-1)\n    negative_distance = K.mean(K.square(anchor - negative),axis=-1)\n    return K.mean(K.maximum(0.0, positive_distance - negative_distance + alpha))","4137214d":"def lossless_triplet_loss(y_true, y_pred, beta=3, epsilon=1e-8):\n    anchor, positive, negative =y_pred[0,0:512], y_pred[0,512:1024], y_pred[0,1024:1536]\n    \n    pos_dist = K.mean(K.square(anchor - positive),axis=-1)\n    neg_dist = K.mean(K.square(anchor - negative),axis=-1)\n    \n    N=3\n    pos_dist = -tf.math.log(-tf.divide((pos_dist),beta)+1+epsilon)\n    neg_dist = -tf.math.log(-tf.divide((N-neg_dist),beta)+1+epsilon)\n    loss = neg_dist + pos_dist\n    \n    return loss\n\ndef contrastive_loss(y_true, y_pred):\n    margin = 1\n    square_pred = K.square(y_pred)\n    margin_square = K.square(K.maximum(margin - y_pred, 0))\n    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)","dad0b350":"def generator():\n    for i in range(1,31):\n        if(i<10):\n            anc,neg,pos=getfiles(float(\"0.00\"+str(i)),gen,forg)\n        else:\n            anc,neg,pos=getfiles(float(\"0.0\"+str(i)),gen,forg)\n        for i in range(len(neg)):\n            for j in range(len(pos)):\n                anchor=returnimages(gen,anc)\n                positive=returnimages(gen,pos[j])\n                negative=returnimages(forg,neg[i])\n               # yield ([anc,pos[j],neg[i]],[0])\n                yield ([anchor,positive,negative],[0])\n                \ndef generator2():\n    x=[\"0.001\",\"0.004\", \"0.005\", \"0.006\", \"0.007\",\"0.008\", \"0.009\", \"0.010\", \"0.011\"]\n    for k in x:\n        anc,neg,pos=getfiles2(k)\n        frac=0.95    \n        inds = set(random.sample(list(range(len(neg))), int(frac*len(neg))))\n        neg = [n for i,n in enumerate(neg) if i not in inds]\n    \n        for i in range(len(neg)):\n            for j in range(len(pos)):\n                anchor=returnimages(gentr,anc)\n                positive=returnimages(gentr,pos[j])\n                negative=returnimages(forgtr,neg[i])\n               # yield ([anc,pos[j],neg[i]])\n                yield ([anchor,positive,negative],[0])","2e0bfe90":"model1 = applications.vgg19.VGG19(weights='imagenet', include_top=False, pooling='max')\nfor layer in model1.layers[:15]:\n    layer.trainable = False\n\nanchor_in = Input(shape=(img_width, img_height, channels))\npos_in = Input(shape=(img_width, img_height, channels))\nneg_in = Input(shape=(img_width, img_height, channels))\n\nanchor_out = model1(anchor_in)\npos_out = model1(pos_in)\nneg_out = model1(neg_in)\nmerged_vector = concatenate([anchor_out, pos_out, neg_out],axis=1)\n\nmodel_triplet_loss = Model(inputs=[anchor_in, pos_in, neg_in], outputs=merged_vector)\nmodel_triplet_loss.compile(optimizer=Adam(lr=0.00001),loss=triplet_loss)","0e8a27b8":"for x in range(1):\n    model_triplet_loss.fit_generator(generator(),steps_per_epoch=100,epochs=6)\n    \n#for x in range(1):\n#    model_contrastive_loss.fit_generator(generator2(),steps_per_epoch=32,epochs=9)","95bc1a32":"model2 = applications.vgg19.VGG19(weights='imagenet', include_top=False, pooling='max')\nfor layer in model2.layers[:15]:\n    layer.trainable = False\n\nanchor_in = Input(shape=(img_width, img_height, channels))\npos_in = Input(shape=(img_width, img_height, channels))\nneg_in = Input(shape=(img_width, img_height, channels))\n\nanchor_out = model2(anchor_in)\npos_out = model2(pos_in)\nneg_out = model2(neg_in)\nmerged_vector = concatenate([anchor_out, pos_out, neg_out],axis=1)\n\nmodel_lossless_triplet_loss = Model(inputs=[anchor_in, pos_in, neg_in], outputs=merged_vector)\nmodel_lossless_triplet_loss.compile(optimizer=Adam(lr=0.0000019),loss=lossless_triplet_loss)","d21ef3b2":"for x in range(1):\n    model_lossless_triplet_loss.fit_generator(generator(),steps_per_epoch=100,epochs=6)\n    \n#for x in range(1):\n#    model_lossless_triplet_loss.fit_generator(generator2(),steps_per_epoch=32,epochs=9)","d2205510":"model3 = applications.vgg19.VGG19(weights='imagenet', include_top=False, pooling='max')\nfor layer in model3.layers[:15]:\n    layer.trainable = False\n\nanchor_in = Input(shape=(img_width, img_height, channels))\npos_in = Input(shape=(img_width, img_height, channels))\nneg_in = Input(shape=(img_width, img_height, channels))\n\nanchor_out = model3(anchor_in)\npos_out = model3(pos_in)\nneg_out = model3(neg_in)\nmerged_vector = concatenate([anchor_out, pos_out, neg_out],axis=1)\n\nmodel_contrastive_loss = Model(inputs=[anchor_in, pos_in, neg_in], outputs=merged_vector)\nmodel_contrastive_loss.compile(optimizer=Adam(lr=0.00001),loss=contrastive_loss)","084929bf":"for x in range(1):\n    model_contrastive_loss.fit_generator(generator(),steps_per_epoch=100,epochs=6)\n\n#for x in range(1):\n#    model_triplet_loss.fit_generator(generator2(),steps_per_epoch=32,epochs=9)","f069b8e0":"tneg,tpos=0,0\nx=[0.002, 0.008, 0.016, 0.018, 0.024, 0.033, 0.035, 0.044, 0.046, 0.063,\n   0.070, 0.071, 0.077, 0.084, 0.085, 0.086, 0.089, 0.092, 0.093]\nfor k in x: #the id of signatures you want to check\n    #print(\"When k is \", k)\n    anc,neg,pos=getfiles(k,gent,forgt)\n    tneg=tneg+len(neg)\n    tpos=tpos+len(pos)\nprint(tneg,tpos)","50f2cfa2":"# Save the weights\nmodel_triplet_loss.save_weights('model_triplet_loss_weights.h5')\nmodel_lossless_triplet_loss.save_weights('model_lossless_triplet_loss_weights.h5')\nmodel_contrastive_loss.save_weights('model_contrastive_loss_weights.h5')\n\n# Save the model architecture\nwith open('model_triplet_loss_architecture.json', 'w') as f:\n    f.write(model_triplet_loss.to_json())\n    \nwith open('model_lossless_triplet_loss_architecture.json', 'w') as f:\n    f.write(model_lossless_triplet_loss.to_json())\n    \nwith open('model_contrastive_loss_architecture.json', 'w') as f:\n    f.write(model_contrastive_loss.to_json())","6f36a837":"## Training contrastive loss","8b9c394e":"## Training triplet loss","e5dbad27":"## Training Lossless triplet loss"}}