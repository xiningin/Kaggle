{"cell_type":{"a9392622":"code","1e647263":"code","157ce8c4":"code","8b6d4a91":"code","7fb9569b":"code","02f4082e":"code","ee66a55d":"code","19b679ba":"code","f188cd53":"code","a1eb7e58":"code","6603b3dc":"code","7c4d3eb4":"code","eb5b55fe":"code","75023119":"code","daa2e47e":"code","3b35d7c1":"code","6328c859":"code","d5bd3647":"code","6534e2d8":"code","dacb4bf8":"code","147cad8c":"code","0bddee7d":"code","2b6d96ee":"code","cdd464a3":"code","f9e65003":"markdown","17c72cbf":"markdown","fcd32872":"markdown","a06a7910":"markdown","34d67f53":"markdown"},"source":{"a9392622":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport cv2\nimport glob\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport keras.backend as B\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nimport pycuda.driver as cuda\nfrom keras.preprocessing.image import ImageDataGenerator ,img_to_array\nfrom keras.metrics import binary_crossentropy\nfrom keras.models import Sequential , Model\nfrom keras.layers import BatchNormalization , Conv2D , Dense , Activation , Flatten , MaxPool2D , Dropout\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport warnings\nwarnings.filterwarnings('ignore')\nimport time\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","1e647263":"if (torch.cuda.is_available()):\n    cuda.init()\n\n    #Get ID of CUDA device\n    ID= torch.cuda.current_device()\n    #Get CUDA device name\n    print(cuda.Device(ID).name())\n\n    #set the GPU\n    os.environ['CUDA_VISIBLE_DEVICES'] = str(ID)","157ce8c4":"rcsv= pd.read_csv(\"..\/input\/train\/train.csv\")\ntestcvs = pd.read_csv(\"..\/input\/test_ApKoW4T.csv\")\ndata_path = \"..\/input\/train\/images\/\"\npath = os.path.join(data_path , \"*jpg\")","8b6d4a91":"files = glob.glob(path)\ndata=[]\nfor file in files:\n    image = cv2.imread(file)\n    data.append(image)","7fb9569b":"train_images = data[:6252]\ntest_images= data[6252:]","02f4082e":"sns.countplot(x='category' , data=rcsv)","ee66a55d":"category = {'Cargo': 1, \n'Military': 2, \n'Carrier': 3, \n'Cruise': 4, \n'Tankers': 5}","19b679ba":"def plot_class(cat):\n    \n    fetch = rcsv.loc[rcsv['category']== category[cat]][:9]\n    fig = plt.figure(figsize=(20,15))\n    \n    for i , index in enumerate(fetch.index ,1):\n        plt.subplot(3,3 ,i)\n        plt.imshow(train_images[index])\n        plt.xlabel(cat + \" (Index:\" +str(index)+\")\" )\n    plt.show()","f188cd53":"#plot_class('Cargo')","a1eb7e58":"#plot_class('Military')","6603b3dc":"#plot_class('Carrier')","7c4d3eb4":"#plot_class('Cruise')","eb5b55fe":"#plot_class('Tankers')","75023119":"class ImagePreprocessing:\n    \n    def __init__(self,train_images , test_imges , height , length , dataframe):\n        \n        self.train_images =train_images\n        self.test_images  =test_images\n        self.height = height\n        self.length = length\n        self.dataframe = dataframe\n    \n    def Resize(self,TAG):\n        processed_images =[]\n        if TAG == 'Train':\n            for i in range(len(self.train_images)):\n                im= cv2.resize(self.train_images[i] , dsize=(self.height , self.height))\n                processed_images.append(im)\n        elif TAG== 'Test':\n            for i in range(len(self.test_images)):\n                im= cv2.resize(self.test_images[i] , dsize=(self.height , self.height))\n                processed_images.append(im)\n        return processed_images\n    \n    def Reshape(self):\n        #resizing Images\n        self.rez_train_image = self.Resize('Train')\n        self.rez_test_image  = self.Resize('Test')\n        #fetching labels for training and testing\n        self.train_labels    = self.dataframe['category'][:self.length]\n        \n        #converting into array \n        self.label_array = self.toarray(self.train_labels)\n        \n        #reshaping label array\n        self.labels      = self.label_array.reshape(len(self.label_array) , 1)\n        \n        #reshaping images\n        self.pro_images = np.reshape(self.rez_train_image , (len(self.rez_train_image),self.height,self.height,3))\n        self.test_pro_images = np.reshape(self.rez_test_image , (len(self.rez_test_image) ,self.height,self.height,3))\n        \n        return  self.pro_images , self.labels , self.test_pro_images\n    \n    \n    def toarray(self,series):\n        return np.array(series)\n    \n    def splitdata(self,TRAIN_images, LABELS):\n        X_train , X_val , Y_train , Y_val = train_test_split(TRAIN_images , LABELS , test_size=0.2 , random_state=42)\n        return X_train , X_val , Y_train , Y_val\n    \n    def OneHot(self,x):\n        onehotencoder = OneHotEncoder(categorical_features = [0])\n        x = onehotencoder.fit_transform(x).toarray()\n        return x","daa2e47e":"datagen = ImageDataGenerator(featurewise_center=True,  \n                             featurewise_std_normalization =False ,\n                             rotation_range=20, \n                             horizontal_flip=True,\n                             width_shift_range=0.20 , fill_mode = 'nearest',\n                             height_shift_range=0.20  )","3b35d7c1":"preprocess = ImagePreprocessing(train_images , test_images , height=150 , length= 6252 , dataframe=rcsv)\nrez_images , LABELS , test_rez_images = preprocess.Reshape()\nonehot_labels = preprocess.OneHot(LABELS)\nX_train , X_val , Y_train , Y_val = preprocess.splitdata(rez_images , onehot_labels )","6328c859":"# save_image_path = \"\/kaggle\/working\/IMAGES\"\n# if not os.path.exists(save_image_path):\n#     os.mkdir(save_image_path)\n\n\n\n\n\n\n\n# T0 = time.time()\n# for image , label in zip(rez_images , LABELS):\n#     image =np.expand_dims(image ,0)\n#     datagen.fit(image)\n#     name = \"shiptype_{}\".format(label)\n#     for x , val in zip(datagen.flow(image,label,batch_size=1,save_to_dir=save_image_path,save_prefix=name,save_format='jpg'), range(5)):\n#         pass\n# print(\"Total time for training: {}\".format(time.time()-T0))\n\n\n\n\n\n# files = glob.glob(os.path.join(save_image_path,\"*jpg\"))\n# imagedata=[]\n# labeldata=[]\n# for file in files:\n#     label = file.split(\"\/\")[-1][10]\n#     image = cv2.imread(file)\n#     image = cv2.normalize(image, image, 0, 255, cv2.NORM_MINMAX)\n#     imagedata.append(image)\n#     labeldata.append(int(label))\n\n\n\n# imagedata = np.reshape(imagedata , (len(imagedata) , 150,150,3))\n# labeldata = np.reshape(labeldata , (len(labeldata) ,1))\n# IMAGES = np.concatenate((rez_images , imagedata), axis=0)\n# LABELDATA = np.concatenate((LABELS , labeldata) , axis=0)\n\n\n\n\n# IMAGESlist =[]\n# for i in range(len(IMAGES)):\n#     IMAGESlist.append(IMAGES[i].reshape(1,-1).transpose())\n\n\n\n\n# IMAGES.tolist()\n\n\n\n# df = pd.DataFrame([IMAGESlist])\n\n\n\n","d5bd3647":"# fig = plt.figure(figsize=(20,15))\n    \n# for i in range(1,10,1):\n#     plt.subplot(3,3 ,i)\n#     plt.imshow(IMAGES[i])\n#     plt.xlabel(LABELDATA[i])\n# plt.show()","6534e2d8":"# X_train , X_val , Y_train , Y_val = preprocess.splitdata(imagedata , labeldata )\n# Y_train = np.reshape(preprocess.toarray(Y_train) , (len(Y_train),1))\n# Y_val = np.reshape(preprocess.toarray(Y_val) , (len(Y_val),1))\n# X_train = np.reshape(preprocess.toarray(X_train) , (len(X_train),150,150,3))\n# X_val = np.reshape(preprocess.toarray(X_val) , (len(X_val),150,150,3))\n# Y_val = preprocess.toarray(Y_val)\n# labels = preprocess.OneHot(Y_train)\n# val_labels = preprocess.OneHot(Y_val)","dacb4bf8":"def Mymodel(input_shape , L2):\n    \n    model = Sequential()\n    model.add(Conv2D(32,kernel_size=(3,3),activation='relu', kernel_regularizer=L2,padding='same',input_shape=input_shape))\n    model.add(MaxPool2D((2,2) ,strides=(2,2), padding='same'))\n    model.add(Conv2D(64 , kernel_size=(3,3),activation='relu', padding='same'))\n    model.add(MaxPool2D((2,2) ,strides=(2,2), padding='same'))\n    #model.add(Conv2D(64 , kernel_size=(3,3),activation='relu', padding='same', kernel_regularizer=L2))\n    #model.add(MaxPool2D((2,2) ,strides=(2,2), padding='same'))\n    \n    #model.add(Conv2D(128 , kernel_size=(3,3),activation='relu', padding='same'))\n    #model.add(MaxPool2D((2,2) ,strides=(2,2), padding='same'))\n    #model.add(Conv2D(128 , kernel_size=(3,3),activation='relu', padding='same'))\n    #model.add(Conv2D(128 , kernel_size=(3,3),activation='relu', padding='same',  kernel_regularizer=L2))\n    #model.add(MaxPool2D((2,2) ,strides=(2,2), padding='same'))\n    \n    #model.add(Conv2D(256 , kernel_size=(3,3),activation='relu', padding='same'))\n    #model.add(Conv2D(256 , kernel_size=(3,3),activation='relu', padding='same'))\n    #model.add(Conv2D(256 , kernel_size=(3,3),activation='relu', padding='same', kernel_regularizer=L2))\n    #model.add(MaxPool2D((2,2) ,strides=(2,2), padding='same'))\n    \n    model.add(Flatten())\n    #model.add(Dense(512 , activation='relu'))\n    #model.add(BatchNormalization())\n    #model.add(Dropout(0.3))\n    \n    #model.add(Dense(256 , activation='relu'))\n    #model.add(BatchNormalization())\n    \n    #model.add(Dense(128 , activation='relu'))\n    #model.add(BatchNormalization())\n    #model.add(Dropout(0.3))\n    model.add(Dense(64 , activation='relu'))\n    model.add(BatchNormalization())\n    #model.add(Dropout(0.3))\n    model.add(Dense(32 , activation='relu', kernel_regularizer=None))\n    #model.add(BatchNormalization())\n    #model.add(Dropout(0.3))\n    model.add(Dense(16 , activation='relu', kernel_regularizer=None))\n    #model.add(BatchNormalization())\n    #model.add(Dropout(0.3))\n    model.add(Dense(8 , activation='relu'))\n    #model.add(BatchNormalization())\n    #model.add(Dropout(0.3))\n    model.add(Dense(5 , activation='softmax'))\n    \n    model.compile(optimizer=Adam(lr=0.001) , loss='categorical_crossentropy' , metrics=['accuracy'])\n    \n    return model","147cad8c":"#X_train = datagen.fit(X_train)\n#X_val = datagen.fit(X_val)\ntrain_generator = datagen.flow(X_train , Y_train)\nval_generator = datagen.flow(X_val , Y_val)","0bddee7d":"model = Mymodel((150,150,3), None)\nmodel.summary()","2b6d96ee":"# T0 = time.time()\n# history = model.fit_generator(train_generator , steps_per_epoch=300 , epochs=25 , validation_data=val_generator , validation_steps=300)\n# #history=model.fit(X_train,Y_train,validation_data=(X_val,Y_val),batch_size=512,epochs=20)\n# print(\"Total time for training: {}\".format(time.time()-T0))","cdd464a3":"# acc = history.history['acc']\n# val_acc = history.history['val_acc']\n# loss = history.history['loss']\n# val_loss = history.history['val_loss']\n \n# epochs = range(len(acc))\n \n# plt.plot(epochs, acc, 'b', label='Training acc')\n# plt.plot(epochs, val_acc, 'r', label='Validation acc')\n# plt.title('Training and validation accuracy')\n# plt.legend()\n# plt.savefig(\"..\/working\/Accuracy.png\") \n# plt.figure()\n \n# plt.plot(epochs, loss, 'b', label='Training loss')\n# plt.plot(epochs, val_loss, 'r', label='Validation loss')\n# plt.title('Training and validation loss')\n# plt.legend()\n# plt.savefig(\"..\/working\/Loss.png\")\n \n# plt.show()","f9e65003":"## Visualising Images in Each Class","17c72cbf":"## Image Augmentation\nI refer to the artilcle for the idea of Augmentation. **[Here](https:\/\/medium.com\/@ksusorokina\/image-classification-with-convolutional-neural-networks-496815db12a8)** For data generator I refered this [article](https:\/\/medium.com\/@arindambaidya168\/https-medium-com-arindambaidya168-using-keras-imagedatagenerator-b94a87cdefad)","fcd32872":"### Splitting the data","a06a7910":"* Since the data is imbalanced a bit, we will use keras inbuilt function for real time Data Augmentation of images","34d67f53":"## Image Preprocessing"}}