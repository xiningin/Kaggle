{"cell_type":{"0ef36ea9":"code","56ee9c44":"code","b666cfb0":"code","90e66a0a":"code","023bd255":"code","aef76d4a":"code","36ea2905":"code","60cdd260":"code","314985c0":"code","da9e394d":"code","6c09c0dc":"code","99e3cce4":"code","433686c6":"code","f72f2e0a":"code","26283e4d":"code","1cb24da6":"code","09914bd3":"code","9f019201":"code","0b905623":"code","c30f7251":"code","7c20026f":"code","32285365":"code","f52cf89c":"code","c35eca1f":"markdown"},"source":{"0ef36ea9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport os\nprint(os.listdir(\"..\/input\"))\n","56ee9c44":"data = pd.read_csv('..\/input\/data.csv')\ndata.head()","b666cfb0":"data['diagnosis'].value_counts().plot('bar');","90e66a0a":"data.isna().sum().plot('bar');","023bd255":"data.info()","aef76d4a":"cols = data.columns\ncols","36ea2905":"buffer = 128\nbatch_size = 128\nepochs = 1000\nsplit = 0.7\ny_label = 'diagnosis'","60cdd260":"default_type = []\nfor col in cols:\n    if data[col].dtype == object:\n        print(col)\n        default_type.append([''])\n    else:    \n        default_type.append([0.0])\nlen(default_type) ","314985c0":"default_type[-1] = [0]\ndef parsing(line):\n    parsed = tf.decode_csv(line,default_type[:32])\n    print('parsing_line')\n    features = dict(zip(cols,parsed))\n    #features.pop('Unnamed: 32')\n    features.pop('id')\n    labels = features.pop(y_label)\n    print(labels)\n    return features, tf.equal(labels, 'M')","da9e394d":"basedata = tf.data.TextLineDataset('..\/input\/data.csv')\nbasedata = basedata.skip(1)","6c09c0dc":"def in_train_set(line):\n    print('in_train_set')\n    num_buckets = 100000\n    bucket_id = tf.string_to_hash_bucket_fast(line, num_buckets)\n    return bucket_id < int(split * num_buckets)\n\ndef in_validate_set(line):\n    return ~in_train_set(line)","99e3cce4":"train = basedata.filter(in_train_set).map(parsing)\nvalidation = basedata.filter(in_validate_set).map(parsing)\ndef X():\n    print('X()')\n    return train.repeat().shuffle(buffer).batch(batch_size).make_one_shot_iterator().get_next()\ndef Y():\n    return validation.shuffle(buffer).batch(batch_size).make_one_shot_iterator().get_next()","433686c6":"cols","f72f2e0a":"fc = ['radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'symmetry_mean', 'fractal_dimension_mean',\n       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'symmetry_se',\n       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst',\n       'symmetry_worst', 'fractal_dimension_worst']\nfeature_columns = list(map(lambda c : tf.feature_column.numeric_column(c), fc))","26283e4d":"model = tf.estimator.DNNClassifier(hidden_units=[512,256],feature_columns=feature_columns)","1cb24da6":"model.train(input_fn= X, steps= epochs)","09914bd3":"eval_result = model.evaluate(input_fn=Y)","9f019201":"for key in sorted(eval_result):\n    print('%s: %s' % (key, eval_result[key]))","0b905623":"vald = data[150:250]\nprint(vald[y_label][150])","c30f7251":"pred_iter = model.predict(input_fn= tf.estimator.inputs.pandas_input_fn(vald[fc],shuffle=False))\nclasses = ['B','M']\npreds = []\nfor i,pred in enumerate(pred_iter):\n    #print(classes[int(pred['classes'][0])],':- probabilities',pred['probabilities'][0])\n    preds.append(int(pred['classes'][0]))","7c20026f":"x = vald[y_label].apply(lambda x: 0 if x == 'B' else 1)","32285365":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(8,8))\nwith tf.Graph().as_default():\n    cm = tf.confusion_matrix(x,preds)\n    with tf.Session() as sess:\n        cm_out = sess.run(cm)\n\n        sns.heatmap(cm_out, annot=True, xticklabels=classes, yticklabels=classes);\n    plt.xlabel(\"Predicted\");\n    plt.ylabel(\"True\");\n    plt.title('Confusion Matrix M\/B Cancer Type')","f52cf89c":"sess.close()","c35eca1f":"## The notebook use pure Tensorflow code to prepare a model.Even splits are done using hash not by scikit.(~2yrs old code)"}}