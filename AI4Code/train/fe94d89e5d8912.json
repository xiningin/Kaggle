{"cell_type":{"c9d3d222":"code","051e9d20":"code","17bc79e6":"code","50950cbd":"code","f68f4879":"code","4d1cad59":"code","c44365ea":"code","78e479d3":"code","020d1449":"code","d9f46a22":"code","0e8a5158":"code","0b676332":"code","e418a7fd":"code","8b246559":"code","4ed1973b":"code","2702bc9f":"code","3e4cd879":"code","e7cdc948":"code","5cbe0600":"code","30514dd1":"code","8efb0912":"code","c0f3cf7f":"code","0c7cf0ed":"code","18fdd8d8":"code","4c986805":"code","a78b5eeb":"code","6ee7b402":"code","26bb4b36":"code","ff3239e5":"code","9549358f":"code","ee4b3355":"code","98e92a91":"code","367b355e":"code","8658a16e":"code","591c4c1b":"code","8e0242ca":"code","4cf8d031":"code","92196bff":"code","93301842":"code","c45df4d3":"code","13a58ac5":"code","15b85e32":"code","2143dde7":"code","f60be3f9":"code","2223c1d0":"code","0be45a92":"code","4c70f98d":"code","b30f2d69":"code","46419e48":"code","6f5d389a":"code","a54557bb":"code","7a90245a":"code","db0b1b8b":"code","89baf17d":"code","09d3000b":"code","5fc9914d":"code","8cf931cd":"code","cdc30eb0":"code","ae9f5bbd":"code","5a6e6696":"code","fc373125":"code","8b83bdb6":"code","f19d8e6e":"code","b4a75dcb":"code","70b3b00c":"code","ffa551b9":"code","7d22233e":"code","b7b4168e":"code","5e216e41":"code","40802df6":"code","96456074":"code","6c2692ef":"code","77d37350":"code","0f34f3df":"code","8092345b":"code","81196eb8":"code","a1cf2caa":"code","5c993265":"markdown","862e745d":"markdown","b749702d":"markdown","474f6275":"markdown","31b898a6":"markdown","7551f2f1":"markdown","dc04158f":"markdown","c2d313ee":"markdown","558997cc":"markdown","e3153074":"markdown","cceb1bf0":"markdown","cd638447":"markdown","7a41e0f5":"markdown","0bc699c4":"markdown","c1653514":"markdown","7b1ab18f":"markdown","bcbd435a":"markdown","2fd97172":"markdown","ffec50e4":"markdown","d116bb7f":"markdown","e00716be":"markdown","b550915b":"markdown","f21dd08c":"markdown","739efe0e":"markdown","eb3d603c":"markdown","87d7d7e3":"markdown","d659f043":"markdown","62e87479":"markdown","6fda5036":"markdown","1578c8c6":"markdown","a1dc275a":"markdown","90751004":"markdown","34e88a5d":"markdown","ab6e888e":"markdown","a1a82532":"markdown","b6549460":"markdown","0fe2ecdb":"markdown","0467f5bd":"markdown","55efb3c1":"markdown","54dbaf7b":"markdown"},"source":{"c9d3d222":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","051e9d20":"from xgboost import XGBClassifier\n","17bc79e6":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns \nfrom scipy import stats\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.model_selection import KFold,RandomizedSearchCV,GridSearchCV,train_test_split,cross_val_score\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score,recall_score,precision_score\nfrom sklearn.cluster import KMeans\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, accuracy_score,precision_score,recall_score,f1_score\nfrom sklearn.metrics import classification_report,roc_curve,roc_auc_score","50950cbd":"Train_data=pd.read_csv('..\/input\/titanic\/train.csv')\nTest_data=pd.read_csv('..\/input\/titanic\/test.csv')\nprint('Complete')\nTrain_data.shape,Test_data.shape","f68f4879":"print('Train_data')\nprint(Train_data.info())\nprint('---------------------------------')\nprint('Test_data')\nprint(Test_data.info())\n","4d1cad59":"Train_data['Survived'].isnull().sum()","c44365ea":"Combined_Raw_data=pd.concat([Train_data,Test_data],ignore_index=True)","78e479d3":"Combined_Raw_data.info()","020d1449":"Combined_Raw_data['Pclass']=Combined_Raw_data['Pclass'].astype('object')\n\nprint('Done with Typecasting')","d9f46a22":"Num_var=[col for col in Combined_Raw_data.columns if Combined_Raw_data[col].dtypes!='object' and col not in ['PassengerId','Survived'] ]\nCat_var=[col for col in  Combined_Raw_data.columns if Combined_Raw_data[col].dtypes=='object' and col not in ['Name','Ticket']]\nprint(f'Numerical_Variables = {Num_var}')\nprint(f'Categorical_Variables= {Cat_var}')\n","0e8a5158":"Combined_Raw_data.isnull().sum()\/Combined_Raw_data.shape[0]*100","0b676332":"sns.kdeplot(Combined_Raw_data.Age,lw=3,shade=True)\n","e418a7fd":"sns.boxplot(Combined_Raw_data.Age)\nCombined_Raw_data['Age'].mean()","8b246559":"fig,axes=plt.subplots(nrows=1,ncols=3,figsize=(12,6))\nsns.kdeplot(Combined_Raw_data.Fare,lw=3,shade=True,ax=axes[0])\nsns.distplot(Combined_Raw_data.Fare,kde=False,ax=axes[1])\nsns.boxplot(Combined_Raw_data.Fare,ax=axes[2])","4ed1973b":"\nfig,axes=plt.subplots(nrows=1,ncols=2,figsize=(12,6))\nsns.kdeplot(np.log(Combined_Raw_data.Fare),lw=3,shade=True,ax=axes[0])\nsns.boxplot(np.log(Combined_Raw_data.Fare),ax=axes[1])","2702bc9f":"#Wait for it !!!!!!!!! we are gonna do this part later in order visulize properly\n#Combined_Raw_data['Fare']=np.log(Combined_Raw_data['Fare'])","3e4cd879":"sns.countplot(Combined_Raw_data.Sex)","e7cdc948":"sns.countplot(Combined_Raw_data.Sex ,hue=Combined_Raw_data.Survived)","5cbe0600":"sns.countplot(Combined_Raw_data.Pclass)","30514dd1":"sns.countplot(Combined_Raw_data.Pclass,hue=Combined_Raw_data.Survived)","8efb0912":"sns.countplot(Combined_Raw_data.Embarked)","c0f3cf7f":"sns.countplot(Combined_Raw_data.Embarked,hue=Combined_Raw_data.Survived)","0c7cf0ed":"Combined_Raw_data.info()","18fdd8d8":"fig,axes=plt.subplots(nrows=1,ncols=2,figsize=(12,6))\nsns.countplot(Combined_Raw_data['SibSp'],hue=Combined_Raw_data['Survived'],ax=axes[0])\nsns.countplot(Combined_Raw_data['Parch'],hue=Combined_Raw_data['Survived'],ax=axes[1])","4c986805":"Combined_Raw_data.isnull().sum()","a78b5eeb":"#Since 80% of missing of values in the cabin ,so dropping these variable \nCombined_Raw_data.drop(columns=['Cabin'],inplace=True)","6ee7b402":"Combined_Raw_data.isnull().sum()","26bb4b36":"Combined_Raw_data.head()","ff3239e5":"Combined_Raw_data['Name_Title']=Combined_Raw_data.Name.apply(lambda x: x.split(',')[1].split('.')[0])","9549358f":"Combined_Raw_data['Name_Title'].unique()","ee4b3355":"plt.figure(figsize=(20,6))\nsns.countplot(Combined_Raw_data['Name_Title'],hue=Combined_Raw_data['Survived'])","98e92a91":"def generalize(value):\n    if value in [' Don',' Rev',' Dr',' Mme',' Ms',' Major',' Lady',' Sir',' Mlle',' Col',' Capt',' the Countess',' Jonkheer',' Dona']:\n        value='Generalized_title'\n        return value \n    else:\n        return value\nCombined_Raw_data['Title'] = Combined_Raw_data['Name_Title'].apply(generalize)\n","367b355e":"#Combined_Raw_data['Title']=Combined_Raw_data['Name_Title'].apply(generalize)\nCombined_Raw_data['Title'].unique()\n","8658a16e":"Combined_Raw_data['Title'].unique()","591c4c1b":"#Combined_Raw_data.unique()\nsns.countplot(Combined_Raw_data['Title'])","8e0242ca":"Combined_Raw_data.drop(columns=['Name'],inplace=True)","4cf8d031":"Combined_Raw_data.drop(columns=['Name_Title'],inplace=True)","92196bff":"Combined_Raw_data.info()","93301842":"Combined_Raw_data.info()","c45df4d3":"Combined_Raw_data['is_child']=0\nCombined_Raw_data['is_child'][Combined_Raw_data['Age']>=15]=0\nCombined_Raw_data['is_child'][Combined_Raw_data['Age']<15]=1","13a58ac5":"Combined_Raw_data['is_child'].unique()","15b85e32":"plt.figure(figsize=(20,6))\nsns.countplot(Combined_Raw_data['is_child'],hue=Combined_Raw_data['Title'])","2143dde7":"Combined_Raw_data['Age_Filler']=Combined_Raw_data.groupby(['Sex','is_child']).Age.transform('median')\nCombined_Raw_data.loc[Combined_Raw_data.Age.isnull(),'Age']=Combined_Raw_data.loc[Combined_Raw_data.Age.isnull(),'Age_Filler']","f60be3f9":"Combined_Raw_data.info()","2223c1d0":"Combined_Raw_data.drop(columns=['Age_Filler'],inplace=True)","0be45a92":"mode=Combined_Raw_data['Embarked'].mode()\n#Combined_Raw_data['Embarked']=Combined_Raw_data['Embarked'].replace(np.nan,mode)","4c70f98d":"mode","b30f2d69":"Combined_Raw_data['Embarked']=Combined_Raw_data['Embarked'].replace(np.nan,'S')","46419e48":"mean=Combined_Raw_data['Fare'].mean()\nCombined_Raw_data['Fare']=Combined_Raw_data['Fare'].replace(np.nan,mean)","6f5d389a":"Combined_Raw_data.info()","a54557bb":"Combined_Raw_data['Family_num']=Combined_Raw_data['SibSp']+Combined_Raw_data['Parch']+1\nCombined_Raw_data['Family_num']","7a90245a":"ticket_count = Combined_Raw_data.groupby('Ticket').PassengerId.count()\nCombined_Raw_data['Ticket_count'] = Combined_Raw_data['Ticket'].map(ticket_count)\nCombined_Raw_data['Fare_individual'] =Combined_Raw_data['Fare']\/Combined_Raw_data['Ticket_count']","db0b1b8b":"Combined_Raw_data['GroupSize'] = Combined_Raw_data[['Ticket_count', 'Family_num']].max(axis = 1)","89baf17d":"sns.heatmap(Combined_Raw_data.corr(),annot=True)","09d3000b":"Combined_Raw_data.drop(columns=['Family_num','Ticket_count','SibSp','Parch','Fare','is_child','Ticket'],inplace=True)","5fc9914d":"Combined_Raw_data.info(\n)","8cf931cd":"Combined_Raw_data=pd.get_dummies(Combined_Raw_data,columns=['Embarked','Sex','Title','Pclass'],drop_first=True)","cdc30eb0":"Combined_Raw_data.info()","ae9f5bbd":"train_data=Combined_Raw_data.loc[:890,]\ntest_data=Combined_Raw_data.loc[891:,]\ntrain_data.shape,test_data.shape","5a6e6696":"X=train_data.drop(columns=['Survived','PassengerId'])\nY=train_data['Survived']","fc373125":"X.head()","8b83bdb6":"x_train,x_val,y_train,y_val=train_test_split(X,Y,train_size=0.8,random_state=42)\nx_train.shape,y_train.shape,x_val.shape,y_val.shape","f19d8e6e":"kf=KFold(n_splits=10,random_state=42)\nRFC=RandomForestClassifier()\nscore=cross_val_score(RFC,X,Y,cv=kf,n_jobs=-1)\nscore.max(),score.min(),score.mean()","b4a75dcb":"#HyperParameter Tunining\nparameter_dict={'n_estimators':list(range(100,501)),\n                'max_depth':list(range(1,10)),\n                 'criterian':['gini','entropy'],\n                 'max_samples':list(range(1,10))}\n","70b3b00c":"rf_param = {'n_estimators':list(range(100,500)) , \n         \n         'criterion':['gini','entropy']\n           \n}","ffa551b9":"rscv = RandomizedSearchCV(RFC ,param_distributions=rf_param ,  cv =kf , n_iter=10 , scoring = 'accuracy',n_jobs =-1 , verbose =10)","7d22233e":"rscv.fit(X,Y)","b7b4168e":"print(rscv.best_score_)\nprint(rscv.best_estimator_)\nprint(rscv.best_params_)","5e216e41":"\nfrom sklearn.metrics import classification_report\nRFC1=RandomForestClassifier(n_estimators=238, criterion='entropy')\nRFC1.fit(x_train,y_train)\npredictions=RFC1.predict(x_val)\n#Confusion Matrix ,Precision ,recall,f1,accuracy\ncm = confusion_matrix(y_val, predictions)\naccuracy=accuracy_score(y_val,predictions)\nreport=classification_report(y_val,predictions)\n\nprint(f'accuracy of the Random Forest Classifier is {accuracy}')\nprint(f'Confusion Matrix \\n{cm}')\nprint( report)","40802df6":"fpr,tpr,threshold=roc_curve(y_val,predictions)\nplt.plot(fpr,tpr,color='green')\nplt.plot([0,1],[0,1])\nroc_auc_score(y_val,predictions)\n","96456074":"sc= StandardScaler()\nsc.fit(x_train)\nX_train= sc.transform(x_train)\nsc.fit(x_val)\nX_test= sc.transform(x_val)\n\nknn= KNeighborsClassifier(n_neighbors=15)\nknn.fit(X_train,y_train)\ny_pred= knn.predict(X_test)\nacc=accuracy_score(y_val,y_pred)\n\nknnCV=cross_val_score(knn,X,Y,cv=kf,n_jobs=-1)\nprint(f'Accuracy Score for KNN is : {acc}')\nprint(f'Cross Validation Score for K nearest neighbors {knnCV.mean()} ')\n\ncm = confusion_matrix(y_val, y_pred)\nreportKNN=classification_report(y_val,y_pred)\nprint(f'Confusion Matrix = \\n {cm}')\nprint(f'Classification Report = \\n {reportKNN}')\n\n","6c2692ef":"fpr,tpr,threshold=roc_curve(y_val,y_pred)\nplt.plot(fpr,tpr,color='green')\nplt.plot([0,1],[0,1])\nroc_auc_score(y_val,y_pred)\n","77d37350":"final_pred=rscv.predict(test_data.drop(columns=['PassengerId','Survived']))","0f34f3df":"Submission=pd.DataFrame({'PassengerId':test_data.PassengerId,'Survived':final_pred})","8092345b":"Submission.reset_index(drop=True,inplace=True)\nSubmission.Survived=Submission.Survived.astype('int64')","81196eb8":"Submission.to_csv('submission.csv',index=False)","a1cf2caa":"Submission","5c993265":"We can clearly see that distribution after don is almost the same !!! so we would consider them as one category","862e745d":"**Now the Distribution of Fare**","b749702d":"Again the Median Value Lies between 25 to 30  and Moreover there are many outliers we can observe \n","474f6275":"**Now Visualization of  Embarked variable**","31b898a6":"1.  survival: Survival\t0 = No, 1 = Yes\n2.  pclass :Ticket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n3.  sex\t: Sex\t\n4.  Age\t:Age in years\t\n5.  sibsp :# of siblings \/ spouses aboard the Titanic\t\n6.  parch :# of parents \/ children aboard the Titanic\t\n7.  ticket :Ticket number\t\n8.  fare :Passenger fare\t\n9.  cabin:Cabin number\t\n10. embarked:Port of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton","7551f2f1":"We will find the missing percentage of all the variables","dc04158f":"**SPLITTIN AGAIN IN TRAIN AND TEST DATA**","c2d313ee":"**Now We will Check the Distribution of Categorical Variable**","558997cc":"so We will create a Variable which will indicate if the person is child or not ","e3153074":"# Heyy!!! Welcome to my kernel\n **In this kernel we going to look at some very basic steps a data scientist or ML engineer Must do to in order to Achieve better performance of the classification model ,Some of the steps include**\n1. Typecasting\n1. Data Visualization or Exploratory Data Analysis :\n       * Checking Missing Values\n       * Distribution of Numerical variable\n       * Distribution of Categorical Variable \n       * Bivariate Analysis\n       * Correlation using Heatmap \n       * Checking for Outliers using box plot \n       * Deeper Relations of categorical Variables with Numerical Ones\n       \n2. Data Preprocessing And Feature Engineering :\n       * Impuating or Dropping Missing Values \n       * Log or Exponential Transform  of Numerical Variable \n       * Feature Extraction from Useless Features\n       * Feature Scaling \n       * Splitting the Dataset into Training and Validation data\n       \n3. Building The Final Model :\n       * RandomForestClassifier \n       * Hyperparameter Tuning \n       * KNN Classifier\n       \n       \n\n\n","cceb1bf0":"Import Train and Test dataset\nAnd Check The shape to Verify Wether number of variable or preictors are same in Both the data set are same or Not","cd638447":"Analysis of SibSp,Parch","7a41e0f5":"people from Embarked S is having higher death counts compared to others\n","0bc699c4":"* The distribution of the Fare is Right Skewed \n   and there are hell lot of outliers\n* And the reason behind this skewness is : lesser the Fare More likely the people would buy the ticket\n","c1653514":"So The Next Question is Did Female Survived more or Male Did i.e In depth Analysis ","7b1ab18f":"Pclass ,as the name suggests it should be categorical\nSurvived on the other hand is categorical but its already encoded as 0:No 1:Yes so we will leave it as it is\nand all other variable looks fine for now \n","bcbd435a":"* Before combining Two dataset just make sure that target varibale in the training data is not having any missing values ,if it has any then consider dropping those rows \n* if you dont do this step then you have to take the rows with missing target as row in the test data (thats completely fine ) but while submiting the notebook to competition it will throw an error ","2fd97172":"Now we will fillMissing Age Values with respect to Sex,is_child","ffec50e4":"# EDA AND FEATURE ENGINEERING ","d116bb7f":"Treating Missing Values in Age Column is Not that Straight Forward First As we saw it for Cabin wherein we just dropped it \n","e00716be":"Great!! As Expected the pclass 3 are having higher number of People since the fare for this class would be very less comparetively","b550915b":"Holy Smokes!!Cabin Variable is having highest number of missing values\n* As a Beginner I would be very happy to Drop Cabin variable\nbut if  you analyse you would find many reason for this high number of missing values in the Cabin we would discuss about it later ","f21dd08c":"# Final Model","739efe0e":"people in pclass 1 survived more than the remaining classes ","eb3d603c":"Distribution of Each Numerical Variable \n","87d7d7e3":"Okay so S is having higher number of people comparetively","d659f043":"**K-NEAREST NEIGHBORS CLASSIFIER** ","62e87479":"We cant say its the best Symmetric curve ever but its little bit improved ","6fda5036":"Visualization is an Art of Thinking Logically \n1. Master is an English honorific for boys and young men And Young Men are Having Age Between 12 to 18","1578c8c6":"*So The Very first thing we should do is import required libraries*","a1dc275a":"# TYPECASTING","90751004":"We will use RFC for our submission","34e88a5d":"With symmetric Distribution we are more confident about are our result since the standard deviation from the either side of population mean curve is equal  \nKernal Desity estimate or KDE plot of Age is ver close to normally distributed curve and it says that most of the values lies between 25-40","ab6e888e":"* Now we are going to combine the two dataset so that we can do same feature enginering on both   Datasets all at once \n* then just before training we would split the dataset again into training and testing ","a1a82532":"We would drop similar features having less correlation with the target ,to avoid overwhelming results of the model ","b6549460":"Now We will Create dummies of Categorical Variables ","0fe2ecdb":"AUC ROC CURVE ","0467f5bd":"Okay!!!! so the Male's Are Much more than Female's ","55efb3c1":"Believe me I am not Sexist but Male's are more likely to die as we can observe from this visualization,One of the Reason behind this is Males are having comparetively higher population \n","54dbaf7b":" 1. We are Actually DONE with dealing Missing Values \n 2. Anybody can do these basic steps provided that they know basic programming but in my opinion what makes you a true data scientist is Curiosity about the data \n         * for every variation ,anomaly etc in data you should look for the possible reason ,like WHY or HOW this Happened\n         * And all those reasons you can give to the model  as one of the features which would improve the model accuracy\n         "}}