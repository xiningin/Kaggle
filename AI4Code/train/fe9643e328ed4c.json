{"cell_type":{"25907417":"code","23d1d319":"code","8e85d9e7":"code","4486ce73":"code","77b3bedb":"code","827780a1":"code","912a49ac":"code","4b03a113":"code","670d3e24":"code","69b88017":"code","6aa4d8ce":"code","18056d76":"code","8e5ab70e":"markdown","b0f0f274":"markdown"},"source":{"25907417":"import numpy as np\nimport pandas as pd\n\n#keep don't use scientific notation for large floats\n#and limit decimal places for now.\npd.options.display.float_format = '{:.2f}'.format","23d1d319":"#from kaggle presentation setup offline plotly graphs.\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode()","8e85d9e7":"# filename: data set to load from kernel\nfilename = \"..\/input\/turnstile-usage-data-2018.csv\"\n# readlimit: Number of rows to load from csv -- to load all, set to None.\nreadlimit = None\ndata = pd.read_csv(filename, parse_dates=['Date'], nrows=readlimit)","4486ce73":"#Fix columns with trailing spaces\ndata.columns = data.columns.str.strip()\n#Fix Columns with spaces in column name.\ndata.columns = [col.lower().replace(' ', '_') for col in data.columns]\n\n#narrow columns to only the ones that we're interested in.\n# ['station', 'date', 'endtries', 'exits']\ndata = data.filter(['station', 'date', 'entries', 'exits'], axis=1)\n\n#unique turnstile data by station by date.  \n#Problem is there are multiple reports per day for same station\ndata = data.set_index(['station','date'])","77b3bedb":"##group by station\n##for each station, set index to date\n##resample the date by 1D\n##sum the data columns by day\n##\nstationDaySum=data.groupby(by='station').apply(lambda x: x.resample(rule='1D',level='date').sum())","827780a1":"# Function to calculate several metrics on the dataset\n# Now that it's grouped by station, date\ndef calculateTotalsByRow(row):\n    d = row.entries - row.exits\n    return(row.entries + row.exits, d, abs(d))\n\n## row function returns tuple of values that need to be spread out to each new column\ndef applyTotals(df):\n    (df['flowtotal'], df['flowdelta'],df['flowabs']) = zip(*df.apply(calculateTotalsByRow, axis=1))\n\napplyTotals(stationDaySum)","912a49ac":"stationList = stationDaySum.groupby('station')['flowtotal'].mean().sort_values(ascending=False)\ndata = [go.Bar(x=stationList.index,y=stationList.values)]\nlayout = go.Layout(title='Total Volume By Station')\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)\n","4b03a113":"## Report the top n stations\nnstations = 6\ntopnStations = stationList.sort_values(ascending=False).nlargest(nstations).index\nprint(\"\\n\".join(topnStations))","670d3e24":"dsrank = stationDaySum[stationDaySum.index.get_level_values('station').isin(topnStations)].groupby(by=['date','station']).mean()","69b88017":"#i'm thinking that indexes suck.\ndsrank = dsrank.reset_index()","6aa4d8ce":"data = [go.Scatter(name=station, x=dm.date,y=dm.flowtotal)for (station,dm) in dsrank.groupby('station') ]\nlayout = go.Layout(title='Top {} Station Total Flow By Day'.format(nstations))\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)\n","18056d76":"\n\nfor (station,dm) in dsrank.groupby('station'):\n        data = [go.Scatter(name='entries', x=dm.date,y=dm.entries),\n                go.Scatter(name='exits', x=dm.date,y=dm.exits)]\n        layout = go.Layout(title='Station {} Entries and Exits By Day'.format(station))\n        fig = go.Figure(data=data, layout=layout) \n        iplot(fig)\n","8e5ab70e":"# Top N entries and exits over year","b0f0f274":"# Top N busiest stations by day\nBusy is total volume entries and exits"}}