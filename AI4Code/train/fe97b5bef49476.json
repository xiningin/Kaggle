{"cell_type":{"54231e80":"code","b2ad8186":"code","f37b749d":"code","21755afc":"code","001ffc53":"code","50396596":"code","af9273c6":"code","ca0ddec5":"code","e7a103e6":"code","e44b3213":"code","ef26c335":"code","255a506f":"code","87195ffc":"code","4a94ae9f":"code","753b26c1":"code","d4c823d6":"code","3a1f476d":"markdown","553420f3":"markdown","5dbee9fe":"markdown","623eb508":"markdown","dd97202d":"markdown","3cfe36f9":"markdown","0950dc16":"markdown","4276a93d":"markdown","b16ad7f4":"markdown","e1e8aee8":"markdown","629e372d":"markdown","ac7f33d7":"markdown","a023e53d":"markdown","c40a0dcf":"markdown","188f92c6":"markdown","55bafa71":"markdown","43985275":"markdown","dd2745d8":"markdown","1a13bcf7":"markdown","1b54740c":"markdown","3c3c7eb1":"markdown","0a78d62a":"markdown","a53a0f6e":"markdown","5b291bce":"markdown","dd85d680":"markdown","11961461":"markdown","b1da4b71":"markdown","b7d1f590":"markdown","824dd7b8":"markdown","3f8c0f29":"markdown","88e89dee":"markdown","0f278285":"markdown"},"source":{"54231e80":"import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.express as px # easy-to-use visualization package\nimport plotly.graph_objects as go # we'll use this for our geographic visualizations","b2ad8186":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f37b749d":"parks = pd.read_csv('\/kaggle\/input\/park-biodiversity\/parks.csv')\nspecies = pd.read_csv('\/kaggle\/input\/park-biodiversity\/species.csv')","21755afc":"parks.head()","001ffc53":"species.head()","50396596":"biodiversity_counts = species.groupby(\"Park Name\")[\"Species ID\"].count().reset_index(name='Count')\nbiodiversity_counts.head()","af9273c6":"parks[\"Biodiversity Count\"] = biodiversity_counts[\"Count\"]\nparks.head()","ca0ddec5":"parks[\"Biodiversity Density\"] = parks[\"Biodiversity Count\"]\/parks[\"Acres\"]\nparks.head()","e7a103e6":"parks[[\"Acres\", \"Biodiversity Count\", \"Biodiversity Density\"]].describe()","e44b3213":"parks['text'] = parks['Park Name'] + '<br>' + \\\n    (parks['Acres']).astype(str) + ' Acres' + '<br>' + \\\n    (parks['Biodiversity Count']).astype(str)+' Species'","ef26c335":"scale = 8000","255a506f":"fig = go.Figure()\n\n#for index, row in geo_parks.iterrows():\nfig.add_trace(go.Scattergeo(\n    locationmode = 'USA-states',\n    lon = parks['Longitude'],\n    lat = parks['Latitude'],\n    text = parks['text'],\n    marker = dict(\n        size = parks['Acres']\/scale,\n        color = parks['Biodiversity Count'],\n        line_color='rgb(40,40,40)',\n        line_width=0.5,\n        sizemode = 'area',\n        colorscale = 'ylgn',\n        cmax = parks['Biodiversity Count'].max(),\n        cmin = parks['Biodiversity Count'].min(),\n        colorbar = {'title': 'Number of Species'}\n        )))\n\n\nfig.update_layout(\n        title_text = 'US National Park Size and Biodiversity',\n        geo = dict(\n            scope = 'usa',\n            landcolor = 'rgb(217, 217, 217)',\n        )\n    )\n\nfig.show()","87195ffc":"no_outliers = parks.loc[parks[\"Biodiversity Density\"]!=parks[\"Biodiversity Density\"].max()]\nno_outliers[\"Biodiversity Density\"].max()","4a94ae9f":"parks['text'] = parks['Park Name'] + '<br>' + (parks['Acres']).astype(str) + ' Acres' + '<br>' + (parks['Biodiversity Density']).astype(str)+' Species per Acre'\n\nscale = 8000\n\nfig = go.Figure()\n\n#for index, row in geo_parks.iterrows():\nfig.add_trace(go.Scattergeo(\n    locationmode = 'USA-states',\n    lon = parks['Longitude'],\n    lat = parks['Latitude'],\n    text = parks['text'],\n    marker = dict(\n        size = parks['Acres']\/scale,\n        color = parks['Biodiversity Density'],\n        line_color='rgb(40,40,40)',\n        line_width=0.5,\n        sizemode = 'area',\n        colorscale = 'ylgn',\n        cmin = parks['Biodiversity Density'].min(),\n        cmax = 0.08867807795421737,\n        colorbar = {'title': 'Number of Species per Acre'}\n        )))\n\n\nfig.update_layout(\n        title_text = 'US National Park Size and Biodiversity Density',\n        geo = dict(\n            scope = 'usa',\n            landcolor = 'rgb(217, 217, 217)',\n        )\n    )\n\nfig.show()","753b26c1":"fig2 = px.histogram(parks, x=\"Biodiversity Count\", nbins=30, marginal='violin')\nfig2.show()","d4c823d6":"fig4 = px.histogram(no_outliers, x=\"Biodiversity Density\", nbins=30, marginal='violin')\nfig4.show()","3a1f476d":"## Visualizing the Distribution of Data","553420f3":"# Introduction","5dbee9fe":"First we load in the necessary packages: we'll use `pandas` to read and manage the data and `plotly`'s `express` and `graph_objects` modules to visualize it.","623eb508":"We'll start with the map. First, we'll need to format the text that we want to appear as we move our mouse cursor over each of the parks in our map. We want the tooltip to show us the park name, how many acres it is, and how many species live there (for our second map, we will replace this final piece of information with the biodiversity density). We'll store this information in a new column of `parks` named \"Text.\"","dd97202d":"# References and Future Work","3cfe36f9":"In order to explore biodiversity in these parks, the first statistic we need to compute is the number of species in each park. We'll do this using `pandas`' `groupby()`, `count()`, and `reset_index()` methods. We produce a new dataframe named `biodiversity_counts` in which the \"Count\" column contains the number of species for each park.","0950dc16":"Now we can actually produce the map. We need to first set the `locationmode` to 'USA-states' for the underlying map. Then, we'll use the \"Longitude\" and \"Latitude\" columns to place our markers on the map, the \"text\" column we just created for the tooltips, our \"Acres\" column and the scale value to set the marker size, and our \"Biodiversity Count\" column to determine the color. We'll use a yellow-green colorscale and set its min and max to our \"Biodiversity Count\" column's min and max. We'll also display a color bar in order to serve as a legend.","4276a93d":"# Visualizing Biodiversity in America's National Parks","b16ad7f4":"To map biodiversity density, we'll replace every instance of \"Biodiversity Count\" with \"Biodiversity Density,\" and edit our tooltip text accordingly. Because we have an outlier maximum in the \"Biodiversity Density\" column, our color range is liable to become skewed. In order to solve this problem, we'll replace our `cmax` value in the `marker` dictionary with the second highest value in the column, as opposed to the max. This will have a normalizing impact on the color range and allow us to properly visualize the geographic distribution of biodiversity density. Let's find this value:","e1e8aee8":"We print the top five rows of each dataframe using the `head()` method in order to find out what information is stored in each dataframe.","629e372d":"In this notebook we aim to analyze and visualize the distribution of biodiversity throughout America's national parks. We'll use the National Park Service's dataset. This project will answer questions like:\n* Which of America's national parks has the least\/most biodiversity?\n* Which of America's national parks has the smallest\/greatest density of biodiversity?\n* How are these measurements distributed? How are they distributed *geographically*?","ac7f33d7":"Substituting this value into the `cmax` field, we produce the following map:","a023e53d":"We can see here that the data skews even farther to the right when we consider biodiversity density. 29 parks -- over half of America's national parks -- have less than 0.005 species per acre. A large density of biodiversity is clearly even more rare than a large biodiversity count.","c40a0dcf":"To compute biodiversity density, we simply divide the number of species in each park by the park size in acres. This gives us each park's number of species per acre which we will refer to as \"Biodiversity Density.\"","188f92c6":"We use the National Park Service's \"Biodiversity in National Parks\" dataset, which can be found on kaggle [here][1]. Future work on this project will include:\n* An analysis of biodiversity counts broken down by category (such as mammals, birds, vascular and nonvascular plants, and fungi)\n* More granular geographic visualizations by region (particularly, treating Alaska and Hawai'i individually will allow us to better understand their parks, especially since the parks in Alaska are so large but relatively less biodiverse than many parks found in the contiguous states)\n* Interpolation of more geographic data that will allow us to plot the actual shapes of the national parks.\n* An analysis of how many unique species are found in each park, where we define a unique species as one which is found in only one national park.\n\n[1]: https:\/\/www.kaggle.com\/nationalparkservice\/park-biodiversity","55bafa71":"# Computing Biodiversity and Biodiversity Density","43985275":"# Visualizing the Data","dd2745d8":"Unsurprisingly, we see that smaller parks have a greater density of biodiversity. This should not surprise us since the range of the \"Acres\" column far exceeds the range of the \"Biodiversity Count,\" and so larger parks do not have as much biodiversity density as smaller parks do. Naturally, smaller parks will feature more dense biodiversity -- both because of the underlying mathematics as well as the fact that smaller national parks are generally established at sites featuring some unique natural phenomenon (like the hot springs of Hot Springs National Park or the volcanic crater of Mount Haleakala on the Hawaiian island Maui), and these natural phenomenon can tend to support a vast number of species in a small area.","1a13bcf7":"We'll use `plotly.express`'s `histogram()` method for both \"Biodiversity Count\" and \"Biodiversity Density\" (with no outliers). We'll split the variable range up into 30 bins by setting `nbins=30`, and we'll add an additional piece of visualization to display the distribution by including `marginal='violin'`. This will add a density diagram at the top of each histogram.","1b54740c":"We'll visualize the distribution of the data using histograms. A histogram displays a variable's distribution by breaking up the variable's range into equal-sized bins and displaying how many samples fall into each bin. This gives us a rough depiction of how the data is distributed since it will show us the ranges in which the most and least samples fall.","3c3c7eb1":"In each map, we'll use the marker size to indicate the size of the national park it represents, and we'll color the marker based on its biodiversity. We'll also need to scale down the size of our markers in order to fit them on the map, so let's set a `scale` variable which we'll divide our \"Biodiversity Count\" by in order to produce our marker size.","0a78d62a":"Next, we need to load kaggle's operating system and the data we have added to our notebook.","a53a0f6e":"We can now use `pandas`' `describe.()` method to produce summary statistics for the columns \"Acres,\" \"Biodiversity Count,\" and \"Biodiversity Density.\"","5b291bce":"Because we want to study the parks themselves, we'll store all of the additional information we compute in the parks dataframe itself. This will allow us to treat each park as a unit of study both for our analysis and our visualizations.","dd85d680":"Take a moment to zoom in and out and mouse over the map. We notice that there does not seem to be any strong correlation between size and biodiversity, although there are some surprisingly biodiverse smaller parks like Redwood National Park and Hot Springs National Park. Let's map the biodiversity density in order to develop a stronger sense of correlation.","11961461":"# Loading Packages and Data","b1da4b71":"We can see that the biodiversity counts are clearly skewed right, with the vast majority of parks have between 800 and 2800 species. To get even more granular, we can see that 32 of America's 56 national parks have between 1000 and 2000 species. Let's compare this histogram with one generated from \"Biodiversity Density.\"","b7d1f590":"Let's consider these columns one-by-one:\n1. **Acres**: this column has a huge amount of deviation, which should not surprise us since some national parks are colossal while others are relatively small. Of particular note is that the mean is greater than the upper quartile (the 75th percentile) -- this indicates to us that there are some outliers on the upper end of the spectrum. The scale of the max and the standard deviation further confirm this conclusion.\n2. **Biodiversity Count**: this column has a much smaller degree of deviation, which indicates that we are less likely to have any outliers. Again the max is much larger than the upper quartile, but the mean and median are much closer to each other so this large maximum has not had a particularly drastic influence on the mean.\n3. **Biodiversity Density**: this column has an upper outlier, which is evident in both the scale of the maximum and the magnitude of the standard deviation. The maximum is so much larger than the rest of the data points that we may need to remove it in order to adequately visualize the distribution of this statistic.","824dd7b8":"## Mapping the Data","3f8c0f29":"Following this, we simply read in the data. The National Park Service's dataset contains two .csv files: one containing metadata regarding each park (its location and size, for example), and another containing information on each species of life found in a national park. We'll store the former in the dataframe `parks` and the latter in the dataframe `species`.","88e89dee":"We'll produce two types of visuals: **maps** and **histograms**. We'll use maps to plot the geographic distribution of the data to give ourselves a baseline visualization of where America's national parks are, how large they are, and how biodiverse each park is. The histograms will allow us to visualize the numerical distribution of each of our statistics so we can further understand the statistics discussed above.","0f278285":"We then store the counts in the original `parks` dataframe. We can simply add the column because both dataframes are organized alphabetically by park name."}}