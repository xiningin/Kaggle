{"cell_type":{"4890603a":"code","7a35c096":"code","307ffc92":"code","33211c59":"code","b0926db4":"code","11649151":"code","96472ad7":"code","447b358a":"code","578b90e5":"code","ba6e0a4e":"code","ffea6b57":"code","5ec6be7e":"code","5afbde2e":"code","6a55fddd":"code","0730ed77":"code","e000e155":"code","7a5d5663":"code","af77f1b4":"code","248011a2":"code","ffd28942":"code","8873bf24":"code","7c6e29ab":"code","7ed09d42":"code","774754a8":"code","4c01fbd0":"code","831212b8":"code","e1b43ac3":"code","f89babb4":"code","af37a09c":"code","34fa3517":"code","31e8341b":"code","4da1fe0e":"code","0f467084":"code","82bbeb9f":"code","74ea8d20":"code","c478b136":"code","16a81250":"code","937efb28":"code","ccde0a82":"code","74c81f0c":"code","bb42110a":"code","cecb0e9e":"code","d91941ae":"code","d99a791d":"code","8294c338":"code","5ea0c9bd":"code","ac487e5e":"code","c8b10cf7":"code","2e086fe7":"code","e65f8887":"code","92872b61":"code","809daa41":"code","213ca7f4":"code","f0a4912c":"code","ca6f26fd":"markdown","2ebcbfda":"markdown","4af0f1fc":"markdown","55c6e470":"markdown","af0cff4c":"markdown","d1e758e5":"markdown","7574d34a":"markdown"},"source":{"4890603a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7a35c096":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np","307ffc92":"df = pd.read_csv('\/kaggle\/input\/credit-card-customers\/BankChurners.csv')\ndf.head()","33211c59":"df = df.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n              'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'], \n             axis=1)\ndf.head()","b0926db4":"df.isnull().sum()","11649151":"df = df.drop('CLIENTNUM', axis=1)\ndf.head()","96472ad7":"df['Attrition_Flag'].unique()","447b358a":"df['churn']= df['Attrition_Flag'].map({'Existing Customer':1,'Attrited Customer':0})\ndf = df.drop('Attrition_Flag', axis=1)\ndf.head()","578b90e5":"df['churn'].value_counts().plot(kind='bar')","ba6e0a4e":"df['Income_Category'].unique()","ffea6b57":"df['Income_Category'].value_counts()","5ec6be7e":"df.describe()","5afbde2e":"df.info()","6a55fddd":"df['Gender'].unique()","0730ed77":"fig, ax = plt.subplots()\n\nsns.catplot(\"Gender\", hue=\"churn\", data=df, kind=\"count\", \n            palette={1:\"blue\", 0:\"green\"}, ax=ax)\nplt.close(1)","e000e155":"fig, ax = plt.subplots()\n\nsns.catplot(\"Income_Category\", hue=\"churn\", data=df, kind=\"count\", \n            palette={1:\"blue\", 0:\"green\"}, ax=ax)\nplt.xticks(rotation=70)\nplt.close(1)","7a5d5663":"df['Income_Category']= df['Income_Category'].replace(['Unknown'], \n                                                     'NaN')","af77f1b4":"fig, ax = plt.subplots()\n\nsns.catplot(\"Income_Category\", hue=\"churn\", data=df, kind=\"count\", \n            palette={1:\"blue\", 0:\"green\"}, ax=ax)\nplt.xticks(rotation=70)\nplt.close(1)","248011a2":"df = df.drop(df[df['Income_Category'] == 'NaN'].index)","ffd28942":"fig, ax = plt.subplots()\n\nsns.catplot(\"Income_Category\", hue=\"churn\", data=df, kind=\"count\", \n            palette={1:\"blue\", 0:\"green\"}, ax=ax)\nplt.xticks(rotation=70)\nplt.close(1)","8873bf24":"fig, ax = plt.subplots()\n\nsns.catplot(\"Education_Level\", hue=\"churn\", data=df, kind=\"count\", \n            palette={1:\"blue\", 0:\"green\"}, ax=ax)\nplt.xticks(rotation=70)\nplt.close(1)","7c6e29ab":"df = df.drop(df[df['Income_Category'] == 'Unknown'].index)","7ed09d42":"fig, ax = plt.subplots()\n\nsns.catplot(\"Marital_Status\", hue=\"churn\", data=df, kind=\"count\", \n            palette={1:\"blue\", 0:\"green\"}, ax=ax)\nplt.xticks(rotation=70)\nplt.close(1)","774754a8":"df = df.drop(df[df['Marital_Status'] == 'Unknown'].index)","4c01fbd0":"df.corr()['churn'][:-1].sort_values().plot(kind='bar')","831212b8":"df['gender']= df['Gender'].map({'M':1,'F':0})\ndf = df.drop('Gender', axis=1)\ndf.head()","e1b43ac3":"df.select_dtypes(['object']).columns","f89babb4":"fig, ax = plt.subplots()\n\nsns.catplot(\"Card_Category\", hue=\"churn\", data=df, kind=\"count\", \n            palette={1:\"blue\", 0:\"green\"}, ax=ax)\nplt.xticks(rotation=70)\nplt.close(1)","af37a09c":"dummies = pd.get_dummies(df[['Education_Level', 'Marital_Status', 'Income_Category','Card_Category']], drop_first=True)\ndf = pd.concat([df.drop(['Education_Level', 'Marital_Status', 'Income_Category','Card_Category'], axis=1), dummies], axis=1)","34fa3517":"df.head()","31e8341b":"import xgboost as xgb","4da1fe0e":"df1 = df\ndf1.head()","0f467084":"X = df1.drop('churn', axis=1).values\ny = df1['churn'].values","82bbeb9f":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import train_test_split","74ea8d20":"X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=101)","c478b136":"model = xgb.XGBClassifier(objective='binary:logistic')\nparam_grid = {'colsample_bytree': [0.3, 0.7],\n                  'n_estimators': [50],\n                  'max_depth': [2, 5]}","16a81250":"model_roc_auc= RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n                                        n_iter=10,\n                                        scoring='roc_auc', cv=4)","937efb28":"model_roc_auc.fit(X_train, y_train)","ccde0a82":"y_pred = model_roc_auc.predict(X_test)","74c81f0c":"accuracy = float(np.sum(y_pred==y_test))\/y_test.shape[0]","bb42110a":"print('accuracy: %f' %(accuracy))","cecb0e9e":"churn_new = df1.drop('churn', axis=1).iloc[0]","d91941ae":"churn_new","d99a791d":"churn_new1 = churn_new.values.reshape(-1, 30)","8294c338":"model_roc_auc.predict(churn_new1)","5ea0c9bd":"df1.head(1)","ac487e5e":"def Definedata():\n    # define dataset\n    X = df1.drop('churn', axis=1).values\n    y = df1['churn'].values\n    return X, y","c8b10cf7":"def SMOTE():\n    # borderline-SMOTE for imbalanced dataset\n    from collections import Counter\n    from sklearn.model_selection import train_test_split\n    from sklearn.datasets import make_classification\n    from imblearn.over_sampling import SMOTE\n    from matplotlib import pyplot\n    from numpy import where\n    \n    X, y = Definedata()\n\n# summarize class distribution\n    counter = Counter(y)\n    print(counter)\n# transform the dataset\n    smt = SMOTE(random_state=0)\n    X, y = smt.fit_sample(X, y) \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=2)\n# summarize the new class distribution\n    counter = Counter(y)\n    print(counter)\n# scatter plot of examples by class label\n    for label, _ in counter.items():\n        row_ix = where(y == label)[0]\n        pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n    pyplot.legend()\n    pyplot.show()\n    return X_train, X_test, y_train, y_test","2e086fe7":"def ADASYN():\n    from collections import Counter\n    from sklearn.model_selection import train_test_split\n    from imblearn.over_sampling import ADASYN\n    from matplotlib import pyplot\n    from numpy import where\n\n    X, y = Definedata()\n\n# summarize class distribution\n    counter = Counter(y)\n    print(counter)\n# transform the dataset\n    X, y = ADASYN().fit_resample(X, y)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=2)\n# summarize the new class distribution\n    counter = Counter(y)\n    print(counter)\n# scatter plot of examples by class label\n    for label, _ in counter.items():\n        row_ix = where(y == label)[0]\n        pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n    pyplot.legend()\n    pyplot.show()\n    return X_train, X_test, y_train, y_test\n","e65f8887":"%time X_train1, X_test1, y_train1, y_test1 = SMOTE()\n%time X_train4, X_test4, y_train4, y_test4 = ADASYN()","92872b61":"def Models(models, X_train, X_test, y_train, y_test, title, graph):\n    model = models\n    model.fit(X_train,y_train)\n    \n    X, y = Definedata()\n    train_matrix = pd.crosstab(y_train, model.predict(X_train), rownames=['Actual'], colnames=['Predicted'])    \n    test_matrix = pd.crosstab(y_test, model.predict(X_test), rownames=['Actual'], colnames=['Predicted'])\n    matrix = pd.crosstab(y, model.predict(X), rownames=['Actual'], colnames=['Predicted'])\n    \n    if graph:\n        f,(ax1,ax2,ax3) = plt.subplots(1,3,sharey=True, figsize=(15, 2))\n    \n        g1 = sns.heatmap(train_matrix, annot=True, fmt=\".1f\", cbar=False,annot_kws={\"size\": 18},ax=ax1)\n        g1.set_title(title)\n        g1.set_ylabel('Total Churn = {}'.format(y_train.sum()), fontsize=14, rotation=90)\n        g1.set_xlabel('Accuracy score (TrainSet): {}'.format(accuracy_score(model.predict(X_train), y_train)))\n        g1.set_xticklabels(['Churn','Not Churn'],fontsize=12)\n\n        g2 = sns.heatmap(test_matrix, annot=True, fmt=\".1f\",cbar=False,annot_kws={\"size\": 18},ax=ax2)\n        g2.set_title(title)\n        g2.set_ylabel('Total Churn = {}'.format(y_test.sum()), fontsize=14, rotation=90)\n        g2.set_xlabel('Accuracy score (TestSet): {}'.format(accuracy_score(model.predict(X_test), y_test)))\n        g2.set_xticklabels(['Churn','Not Churn'],fontsize=12)\n        g3 = sns.heatmap(matrix, annot=True, fmt=\".1f\",cbar=False,annot_kws={\"size\": 18},ax=ax3)\n        g3.set_title(title)\n        g3.set_ylabel('Total Churn = {}'.format(y.sum()), fontsize=14, rotation=90)\n        g3.set_xlabel('Accuracy score (Total): {}'.format(accuracy_score(model.predict(X), y)))\n        g3.set_xticklabels(['Churn','Not Churn'],fontsize=12)\n\n        plt.show()\n\n    print(\"\\t\\tError Table\")\n    print('Accuracy on Traing set   : ', model.score(X_train,y_train))\n    print('Accuracy on Testing set  : ', model.score(X_test,y_test))\n    print('Overall Accuracy_Score   :',accuracy_score(y, model.predict(X))*100,'%')\n    print('Recall ratio             :',metrics.recall_score(y, model.predict(X))*100,'%')\n    print('AUC score                :', roc_auc_score(y, model.predict(X))*100,'%')\n\n    return y, model.predict(X)","809daa41":"from sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve","213ca7f4":"title = 'XGBClassifier\/SMOTE'\n%time Models(XGBClassifier(colsample_bytree=0.9, learning_rate=0.2, max_depth=7),X_train1, X_test1, y_train1, y_test1, title, True)","f0a4912c":"title = 'XGBClassifier\/ADASYN'\n%time Models(XGBClassifier(colsample_bytree=0.9, learning_rate=0.2, max_depth=7),X_train4, X_test4, y_train4, y_test4, title, True)","ca6f26fd":"INCOME CATEGORY IS NOT A GOOD WAY TO PREDICT THE CHURN","2ebcbfda":"referenced from Huynh Dong Nguyen","4af0f1fc":"marital status is not a good predictor of churn","55c6e470":"it is imbalanced","af0cff4c":"Education level is not also a good predictor","d1e758e5":"gender is not a good way to know churners","7574d34a":"even though there are few people on thee Gold category very few are likely to churn \nfollowed by the silver then Blue"}}