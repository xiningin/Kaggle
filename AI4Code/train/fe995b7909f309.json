{"cell_type":{"37f96989":"code","b99f5040":"code","cecdc60e":"code","a0b78787":"code","9f2f0205":"code","c74b773f":"code","79e0f1c2":"code","9702a433":"code","a1c7642e":"code","a0fb4369":"code","23d412dd":"code","fc0d7aa3":"code","136b8247":"code","1d672a7c":"code","e6acf21e":"code","7e1ca46f":"code","4572c68a":"code","a61b476b":"code","e0860e0c":"code","c75516bd":"code","22df3482":"code","10c6062f":"code","c28c2096":"code","2ceb374c":"code","22313062":"code","663d0294":"code","08714d18":"code","6a7dd561":"code","9c3ec20f":"code","149ecd4f":"code","20615118":"code","3d5e6956":"code","88ebc0a7":"code","f23aac6f":"code","1cd34ec8":"code","5851db27":"code","a1e9d715":"code","4ed7885f":"code","f80d111d":"code","8a20ccf9":"code","683dbb9c":"code","99660699":"code","e67b6f62":"code","b9a39bcc":"code","b5d23bc3":"code","cf258ff5":"code","a7aa9a01":"code","a3c94ace":"code","5659852d":"code","e0369aa7":"code","9050b6ce":"code","6402d88d":"code","98df0d9c":"code","fdb365ec":"markdown","97840d8c":"markdown","7307eba3":"markdown","4acaf642":"markdown","208cd746":"markdown","52e4bcb9":"markdown","c1d46772":"markdown","3bad6135":"markdown","c4b9402a":"markdown","6820f411":"markdown","12040190":"markdown","ce32a3fb":"markdown","516b0d66":"markdown","e7b66f3f":"markdown","f9462c17":"markdown","b527ba4e":"markdown","58306f9d":"markdown","efb4862d":"markdown","7e5b005e":"markdown","d9f54c3f":"markdown","469161a0":"markdown","7fb12b4d":"markdown","3ae05ca9":"markdown","cb58d617":"markdown","70fe6cf8":"markdown","eeac489e":"markdown","755f2eea":"markdown","55248ab2":"markdown","cd6a1c13":"markdown","9392009c":"markdown","830be5fb":"markdown","f7a840e5":"markdown","81ee985a":"markdown"},"source":{"37f96989":"# Install package for PEP8 verification\n!pip install pycodestyle\n!pip install --index-url https:\/\/test.pypi.org\/simple\/ nbpep8","b99f5040":"# Import Python libraries\nimport os\nimport warnings\nimport time\nimport joblib\nimport numpy as np\nimport pandas as pd\nfrom ast import literal_eval\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import set_config\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import NMF\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.multioutput import ClassifierChain\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nimport sklearn.metrics as metrics\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nimport gensim\nimport gensim.corpora as corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models import CoherenceModel\nimport pyLDAvis\nimport pyLDAvis.sklearn\nimport pyLDAvis.gensim_models as gensimvis\nfrom IPython.core.display import display, HTML\n\n#RNN\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.backend import clear_session\nfrom keras import backend as K\n\n# Library for PEP8 standard\nfrom nbpep8.nbpep8 import pep8","cecdc60e":"warnings.filterwarnings('ignore', category=DeprecationWarning)\nplt.style.use('seaborn-whitegrid')\nsns.set_style(\"whitegrid\")\nset_config(display='diagram')","a0b78787":"# Define path to data\npath = '..\/input\/stackoverflow-questions-filtered-2011-2021\/'\ndata = pd.read_csv(path+\"StackOverflow_questions_2009_2020_cleaned.csv\",\n                   sep=\";\", index_col=0,\n                   converters={\"Title\": literal_eval,\n                               \"Body\": literal_eval,\n                               \"Tags\": literal_eval})\ndata.head(3)","9f2f0205":"data.shape","c74b773f":"data[\"Full_doc\"] = data[\"Title\"] + data[\"Body\"]\ndata[\"Full_doc\"].head(3)","79e0f1c2":"# Define X and y\nX = data[\"Full_doc\"]\ny = data[\"Tags\"]\n\n# Initialize the \"CountVectorizer\" TFIDF for Full_doc\nvectorizer = TfidfVectorizer(analyzer=\"word\",\n                             max_df=.6,\n                             min_df=0.005,\n                             tokenizer=None,\n                             preprocessor=' '.join,\n                             stop_words=None,\n                             lowercase=False)\n\nvectorizer.fit(X)\nX_tfidf = vectorizer.transform(X)\n\nprint(\"Shape of X for Full_doc: {}\".format(X_tfidf.shape))\n\n# Multilabel binarizer for targets\nmultilabel_binarizer = MultiLabelBinarizer()\nmultilabel_binarizer.fit(y)\ny_binarized = multilabel_binarizer.transform(y)\n\nprint(\"Shape of y: {}\".format(y_binarized.shape))","9702a433":"# Create train and test split (30%)\nX_train, X_test, y_train, y_test = train_test_split(X_tfidf, y_binarized,\n                                                    test_size=0.3, random_state=8)\nprint(\"X_train shape : {}\".format(X_train.shape))\nprint(\"X_test shape : {}\".format(X_test.shape))\nprint(\"y_train shape : {}\".format(y_train.shape))\nprint(\"y_test shape : {}\".format(y_test.shape))","a1c7642e":"full_dense = X_tfidf.todense()\nprint(\"Full_doc sparsicity: {:.3f} %\"\\\n      .format(((full_dense > 0).sum()\/full_dense.size)*100))","a0fb4369":"# Create dictionnary (bag of words)\nid2word = corpora.Dictionary(X)\nid2word.filter_extremes(no_below=4, no_above=0.6, keep_n=None)\n# Create Corpus \ntexts = X  \n# Term Document Frequency \ncorpus = [id2word.doc2bow(text) for text in texts]  \n# View \nprint(corpus[:1])","23d412dd":"[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]","fc0d7aa3":"# Build LDA model\nfull_lda_model = gensim.models.ldamulticore\\\n                    .LdaMulticore(corpus=corpus,\n                                  id2word=id2word,\n                                  num_topics=20,\n                                  random_state=8,\n                                  per_word_topics=True,\n                                  workers=4)\n# Print Perplexity score\nprint('\\nPerplexity: ', full_lda_model.log_perplexity(corpus))\n\n#Print Coherence Score\ncoherence_model_lda = CoherenceModel(model=full_lda_model, \n                                     texts=texts, \n                                     dictionary=id2word, \n                                     coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nCoherence Score: ', coherence_lda)","136b8247":"pyLDAvis.enable_notebook()\n%matplotlib inline\n\ndisplay(HTML(\"<style>.container { max-width:100% !important; }<\/style>\"))\ndisplay(HTML(\"<style>.output_result { max-width:100% !important; }<\/style>\"))\ndisplay(HTML(\"<style>.output_area { max-width:100% !important; }<\/style>\"))\ndisplay(HTML(\"<style>.input_area { max-width:100% !important; }<\/style>\"))\n\ngensimvis.prepare(full_lda_model, corpus, id2word)","1d672a7c":"# Iter LDA for best number of topics\ncoherence_test = []\nfor k in np.arange(1,90,10):\n    print(\"Fitting LDA for K = {}\".format(k))\n    start_time = time.time()\n    lda_model = gensim.models.ldamulticore\\\n                    .LdaMulticore(corpus=corpus,\n                                  id2word=id2word,\n                                  num_topics=k,\n                                  random_state=8,\n                                  per_word_topics=True,\n                                  workers=4)\n    coherence_model_lda = CoherenceModel(model=lda_model,\n                                         texts=texts,\n                                         dictionary=id2word,\n                                         coherence='c_v')\n    coherence_lda = coherence_model_lda.get_coherence()\n    end_time = time.time()\n    coherence_test.append((k, coherence_lda,\n                           (end_time - start_time)))","e6acf21e":"# Create dataframe of results\ncoherence_test = pd.DataFrame(coherence_test,\n                              columns=[\"k\",\"coherence\",\"time\"])\n\n# Select best number of topics\nbest_nb_topics = coherence_test\\\n                    .loc[coherence_test.coherence.argmax(),\"k\"]\n\n# Plot results\nfig, ax1 = plt.subplots(figsize=(12,8))\nx = coherence_test[\"k\"]\ny1 = coherence_test[\"coherence\"]\ny2 = coherence_test[\"time\"]\n\nax1.plot(x, y1, label=\"Coherence score\")\nax1.axvline(x=best_nb_topics, color='r', alpha=.7,\n            linestyle='dashdot', label='Best param')\nax1.set_xlabel(\"Number of components\")\nax1.set_ylabel(\"Coherence score\")\n\nax2 = ax1.twinx()\nax2.plot(x, y2, label=\"Fit time\",\n         color='g', alpha=.5,\n         linestyle='--')\nax2.set_ylabel(\"Fitting time (s)\")\n\nplt.title(\"Choosing Optimal LDA Model\\n\",\n          color=\"#641E16\", fontsize=18)\nlegend = fig.legend(loc=1, bbox_to_anchor=(.92, .9))\n\nfig.tight_layout()\nplt.show()","7e1ca46f":"# Best LDA visualization\n# Construire le mod\u00e8le LDA\nbest_lda_model = gensim.models.ldamulticore\\\n                    .LdaMulticore(corpus=corpus,\n                                  id2word=id2word,\n                                  num_topics=best_nb_topics,\n                                  random_state=8,\n                                  per_word_topics=True,\n                                  workers=4)\ngensimvis.prepare(best_lda_model, corpus, id2word)","4572c68a":"# Calculate Document\/topic matrix with Gensim\ndoc_topic = pd.DataFrame(best_lda_model\\\n                             .get_document_topics(corpus,\n                                                  minimum_probability=0))\nfor topic in doc_topic.columns:\n    doc_topic[topic] = doc_topic[topic].apply(lambda x : x[1])\n\nprint('document\/tag : ', y_binarized.shape)\nprint('document\/topic : ', doc_topic.shape)","a61b476b":"# Print documents \/ topic matrix\ndoc_topic.head(3)","e0860e0c":"# Matricial multiplication with Document \/ Topics transpose\ntopic_tag = np.matmul(doc_topic.T, y_binarized)\ntopic_tag.shape","c75516bd":"topic_tag","22df3482":"y_results = pd.DataFrame(y)\ny_results[\"best_topic\"] = doc_topic.idxmax(axis=1).values\ny_results[\"nb_tags\"] = y_results[\"Tags\"].apply(lambda x : len(x))\n\ndf_y_bin = pd.DataFrame(y_binarized)\ndf_dict = dict(\n    list(\n        df_y_bin.groupby(df_y_bin.index)\n    )\n)\n\ntags_num = []\nfor k, v in df_dict.items():\n    check = v.columns[(v == 1).any()]\n    tags_num.append(check.to_list())\n\ny_results[\"y_true\"] = tags_num\ny_results.head(3)","10c6062f":"# Select predicted tags in Topics \/ Tags matrix\nlist_tag = []\nfor row in y_results.itertuples():\n    nb_tags = row.nb_tags\n    best_topic = row.best_topic\n    row_tags = list(topic_tag.iloc[best_topic]\\\n                    .sort_values(ascending=False)[0:nb_tags].index)\n    list_tag.append(row_tags)\n    \ny_results[\"y_pred\"] = list_tag\ny_results.head(3)","c28c2096":"def metrics_score(model, df, y_true, y_pred):\n    \"\"\"Compilation function of metrics specific to multi-label\n    classification problems in a Pandas DataFrame.\n    This dataFrame will have 1 row per metric\n    and 1 column per model tested. \n\n    Parameters\n    ----------------------------------------\n    model : string\n        Name of the tested model\n    df : DataFrame \n        DataFrame to extend. \n        If None : Create DataFrame.\n    y_true : array\n        Array of true values to test\n    y_pred : array\n        Array of predicted values to test\n    ----------------------------------------\n    \"\"\"\n    if(df is not None):\n        temp_df = df\n    else:\n        temp_df = pd.DataFrame(index=[\"Accuracy\", \"F1\",\n                                      \"Jaccard\", \"Recall\",\n                                      \"Precision\"],\n                               columns=[model])\n        \n    scores = []\n    scores.append(metrics.accuracy_score(y_true, \n                                         y_pred))\n    scores.append(metrics.f1_score(y_pred, \n                                   y_true, \n                                   average='weighted'))\n    scores.append(metrics.jaccard_score(y_true, \n                                        y_pred, \n                                        average='weighted'))\n    scores.append(metrics.recall_score(y_true, \n                                       y_pred, \n                                       average='weighted'))\n    scores.append(metrics.precision_score(y_true, \n                                          y_pred, \n                                          average='weighted'))\n    temp_df[model] = scores\n    \n    return temp_df","2ceb374c":"# Create matrix for pred and true y LDA\nlda_y_pred = np.zeros(y_binarized.shape)\nn = 0\nfor row in y_results.y_pred.values:\n    for i in range(len(row)):\n        lda_y_pred[n,row[i]] = 1\n    n+=1\n    \nlda_y_true = np.zeros(y_binarized.shape)\nm = 0\nfor row in y_results.y_true.values:\n    for i in range(len(row)):\n        lda_y_true[m,row[i]] = 1\n    m+=1","22313062":"df_metrics_compare = metrics_score(\"LDA\", df=None,\n                                   y_true=lda_y_true,\n                                   y_pred=lda_y_pred)\ndf_metrics_compare","663d0294":"def plot_top_words(model, feature_names, \n                   n_top_words, nb_topic_plot, title):\n    \"\"\"Function for displaying the plots of the \n    best x words representative of the categories of NMF.\n\n    Parameters\n    ----------------------------------------\n    model : NMF model\n        Fitted model of NMF to plot\n    feature_names : array\n        Categories result of the vectorizer (TFIDF ...)\n    n_top_words : int\n        Number of words for each topic.\n    title : string\n        Title of the plot.\n    ----------------------------------------\n    \"\"\"\n    rows = int(nb_topic_plot\/6)\n    fig, axes = plt.subplots(rows, 6, \n                             figsize=(30, rows*10), \n                             sharex=True)\n    axes = axes.flatten()\n    for topic_idx, topic in enumerate(model.components_):\n        if(topic_idx < nb_topic_plot):\n            top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n            top_features = [feature_names[i] for i in top_features_ind]\n            weights = topic[top_features_ind]\n\n            ax = axes[topic_idx]\n            bartopic = ax.barh(top_features, weights, height=0.7)\n            bartopic[0].set_color('#f48023')\n            ax.set_title(f'Topic {topic_idx +1}',\n                         fontdict={'fontsize': 30})\n            ax.invert_yaxis()\n            ax.tick_params(axis='both', which='major', labelsize=20)\n            for i in 'top right left'.split():\n                ax.spines[i].set_visible(False)\n            fig.suptitle(title, fontsize=36, color=\"#641E16\")\n\n    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n    plt.show()","08714d18":"# Define number of topics to test\nn_topics = best_nb_topics\n\nprint(\"-\"*50)\nprint(\"Start NMF fitting on Full_doc ...\")\nprint(\"-\" * 50)\nstart_time = time.time()\n# Initializing the NMF\nfull_nmf = NMF(n_components=n_topics,\n               init='nndsvd',\n               random_state=8)\n\n# Fit NMF on Body vectorized\nfull_nmf.fit(X_tfidf)\n\nexec_time = time.time() - start_time\nprint(\"End of training :\")\nprint(\"Execution time : {:.2f}s\".format(exec_time))\nprint(\"-\" * 50)\n\n# Plot the 12 first topics\nff_feature_names = vectorizer.get_feature_names()\nplot_top_words(full_nmf, ff_feature_names, 20, 12,\n               'Topics in NMF model for Full_doc')","6a7dd561":"# Initialize Logistic Regression with OneVsRest\nparam_logit = {\"estimator__C\": [100, 10, 1.0, 0.1],\n               \"estimator__penalty\": [\"l1\", \"l2\"],\n               \"estimator__dual\": [False],\n               \"estimator__solver\": [\"liblinear\"]}\n\nmulti_logit_cv = GridSearchCV(OneVsRestClassifier(LogisticRegression()),\n                              param_grid=param_logit,\n                              n_jobs=-1,\n                              cv=5,\n                              scoring=\"f1_weighted\",\n                              return_train_score = True,\n                              refit=True)\nmulti_logit_cv.fit(X_train, y_train)","9c3ec20f":"logit_cv_results = pd.DataFrame.from_dict(multi_logit_cv.cv_results_)\nprint(\"-\"*50)\nprint(\"Best params for Logistic Regression\")\nprint(\"-\" * 50)\nlogit_best_params = multi_logit_cv.best_params_\nprint(logit_best_params)","149ecd4f":"logit_cv_results[logit_cv_results[\"params\"]==logit_best_params]","20615118":"# Predict\ny_test_predicted_labels_tfidf = multi_logit_cv.predict(X_test)\n\n# Inverse transform\ny_test_pred_inversed = multilabel_binarizer\\\n    .inverse_transform(y_test_predicted_labels_tfidf)\ny_test_inversed = multilabel_binarizer\\\n    .inverse_transform(y_test)\n\nprint(\"-\"*50)\nprint(\"Print 5 first predicted Tags vs true Tags\")\nprint(\"-\" * 50)\nprint(\"Predicted:\", y_test_pred_inversed[0:5])\nprint(\"True:\", y_test_inversed[0:5])","3d5e6956":"df_metrics_compare = metrics_score(\"Logit\", \n                                   df=df_metrics_compare, \n                                   y_true = y_test,\n                                   y_pred = y_test_predicted_labels_tfidf)\ndf_metrics_compare","88ebc0a7":"# Initialize RandomForest with OneVsRest\nparam_rfc = {\"estimator__max_depth\": [5, 25, 50],\n             \"estimator__min_samples_leaf\": [1, 5, 10],\n             \"estimator__class_weight\": [\"balanced\"]}\n\nmulti_rfc_cv = GridSearchCV(OneVsRestClassifier(RandomForestClassifier()),\n                            param_grid=param_rfc,\n                            n_jobs=-1,\n                            cv=2,\n                            scoring=\"f1_weighted\",\n                            return_train_score = True,\n                            refit=True,\n                            verbose=3)\n# Fit on Sample data\nmulti_rfc_cv.fit(X_train[0:7000], y_train[0:7000])","f23aac6f":"rfc_cv_results = pd.DataFrame.from_dict(multi_rfc_cv.cv_results_)\nprint(\"-\"*50)\nprint(\"Best params for RandomForestClassifier\")\nprint(\"-\" * 50)\nrfc_best_params = multi_rfc_cv.best_params_\nprint(rfc_best_params)","1cd34ec8":"rfc_best_params_ok = {}\nfor k, v in rfc_best_params.items():\n    rfc_best_params_ok[k.replace(\"estimator__\",\"\")] = v","5851db27":"# Refit RandomForestClassifier best_params with full dataset\nrfc_final_model = OneVsRestClassifier(RandomForestClassifier(**rfc_best_params_ok))\nrfc_final_model.fit(X_train, y_train)\n\n# Predict\ny_test_predicted_labels_tfidf_rfc = rfc_final_model.predict(X_test)\n\n# Inverse transform\ny_test_pred_inversed_rfc = multilabel_binarizer\\\n    .inverse_transform(y_test_predicted_labels_tfidf_rfc)\n\nprint(\"-\"*50)\nprint(\"Print 5 first predicted Tags vs true Tags\")\nprint(\"-\" * 50)\nprint(\"Predicted:\", y_test_pred_inversed_rfc[0:5])\nprint(\"True:\", y_test_inversed[0:5])","a1e9d715":"df_metrics_compare = metrics_score(\"RandomForest\", \n                                   df=df_metrics_compare,\n                                   y_true = y_test,\n                                   y_pred = y_test_predicted_labels_tfidf_rfc)\ndf_metrics_compare","4ed7885f":"Tags_per_row_lr = y_test_predicted_labels_tfidf.sum(axis=1)\nnull_rate_lr = round(((Tags_per_row_lr.size - np.count_nonzero(Tags_per_row_lr))\n                      \/Tags_per_row_lr.size)*100,2)\nTags_per_row_rfc = y_test_predicted_labels_tfidf_rfc.sum(axis=1)\nnull_rate_rfc = round(((Tags_per_row_rfc.size - np.count_nonzero(Tags_per_row_rfc))\n                       \/Tags_per_row_rfc.size)*100,2)\nprint(\"-\"*50)\nprint(\"Percentage of non tagged question for each model\")\nprint(\"-\" * 50)\nprint(\"Logistic Regression: {}%\".format(null_rate_lr))\nprint(\"Random Forest: {}%\".format(null_rate_rfc))","f80d111d":"rfc_base_model = RandomForestClassifier(**rfc_best_params_ok)\nchain = ClassifierChain(rfc_base_model, order='random')\nchain.fit(X_train, y_train)","8a20ccf9":"# Predict\ny_test_predicted_labels_tfidf_chain = chain.predict(X_test)\n\n# Inverse transform\ny_test_pred_inversed_chain = multilabel_binarizer\\\n    .inverse_transform(y_test_predicted_labels_tfidf_chain)\n\nprint(\"-\"*50)\nprint(\"Print 5 first predicted Tags vs true Tags\")\nprint(\"-\" * 50)\nprint(\"Predicted:\", y_test_pred_inversed_chain[0:5])\nprint(\"True:\", y_test_inversed[0:5])","683dbb9c":"Tags_per_row_chain = y_test_predicted_labels_tfidf_chain.sum(axis=1)\nnull_rate_chain = round(((Tags_per_row_chain.size - np.count_nonzero(Tags_per_row_chain))\n                       \/Tags_per_row_chain.size)*100,2)\nprint(\"-\"*50)\nprint(\"Percentage of non tagged question for chain model\")\nprint(\"-\" * 50)\nprint(\"RandomForest with Classifier Chains: {}%\".format(null_rate_chain))","99660699":"df_metrics_compare = metrics_score(\"RFC Chains\", \n                                   df=df_metrics_compare,\n                                   y_true = y_test,\n                                   y_pred = y_test_predicted_labels_tfidf_chain)\ndf_metrics_compare","e67b6f62":"def recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))\n\ndef jaccard_m(y_true, y_pred, smooth=100):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return (1 - jac) * smooth","b9a39bcc":"def build_nn(input_dim, hidden_neurons, output_dim):\n    \"\"\"\n    Construct a Keras model which will be used to \n    fit\/predict in SKlearn pipeline.\n    \"\"\"\n    # Create brain\n    model = Sequential()\n    model.add(layers.Dense(hidden_neurons,\n                           input_dim=input_dim,\n                           activation='relu'))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.Dense(hidden_neurons,\n                           input_dim=input_dim,\n                           activation='relu'))\n    model.add(layers.Dropout(0.1))\n    model.add(layers.Dense(output_dim,\n                           activation='sigmoid'))\n    \n    # Compile model\n    model.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy', recall_m, precision_m, f1_m, jaccard_m])\n    model.summary()\n    \n    return model","b5d23bc3":"clear_session()\n\nmodel_params = {\n    'input_dim': X_train.shape[1],\n    'hidden_neurons': 150,\n    'output_dim': y_train.shape[1]}\n\nkeras_model = build_nn(**model_params)","cf258ff5":"history = keras_model.fit(X_train.toarray(), y_train,\n                          epochs=20,\n                          batch_size=256,\n                          verbose=0,\n                          validation_data=(X_test.toarray(), y_test),\n                          shuffle=True)","a7aa9a01":"# evaluate the model\nscores = keras_model.evaluate(X_test.toarray(), y_test)\ndf_metrics_compare[\"Keras NN\"] = [scores[i] for i in [1,4,5,2,3]]\ndf_metrics_compare","a3c94ace":"train_accuracy = history.history.get('accuracy', [])\ntrain_f1 = history.history.get('f1_m', [])\nval_accuracy = history.history.get('val_accuracy', [])\nval_f1 = history.history.get('val_f1_m', [])\n\nfig, axes = plt.subplots(1, 2, figsize=(25, 8))\naxes[0].plot(np.arange(0,20,1),\n             train_accuracy,\n             label=\"Train\")\naxes[0].plot(np.arange(0,20,1),\n             val_accuracy,\n             linestyle='--', color='g', alpha=.7,\n             label=\"Validation\")\naxes[0].set_xticks(np.arange(0,20,5))\naxes[0].set_xlabel(\"Epochs\")\naxes[0].set_ylabel(\"Accuracy score\")\naxes[0].set_title('Model accuracy through epochs',\n                  color='#f48023', fontweight='bold')\naxes[0].legend(loc=4)\n\naxes[1].plot(np.arange(0,20,1),\n             train_f1, label=\"Train\")\naxes[1].plot(np.arange(0,20,1),\n             val_f1,\n             linestyle='--', color='g', alpha=.7,\n             label=\"Validation\")\naxes[1].set_xticks(np.arange(0,20,5))\naxes[1].set_xlabel(\"Epochs\")\naxes[1].set_ylabel(\"F1 score\")\naxes[1].set_title('Model F1 score through epochs',\n                  color='#f48023', fontweight='bold')\naxes[1].legend(loc=4)\n\nplt.show()","5659852d":"# Make prediction with Keras Model\ny_test_predicted_labels_tfidf_keras = keras_model.predict(X_test.toarray())\ny_test_predicted_labels_tfidf_keras = np.where(y_test_predicted_labels_tfidf_keras >= 0.5, 1, 0)","e0369aa7":"# Inverse transform\ny_test_pred_inversed_keras = multilabel_binarizer\\\n    .inverse_transform(y_test_predicted_labels_tfidf_keras)\n\nprint(\"-\"*50)\nprint(\"Print 5 first predicted Tags vs true Tags\")\nprint(\"-\" * 50)\nprint(\"Predicted:\", y_test_pred_inversed_keras[0:5])\nprint(\"True:\", y_test_inversed[0:5])\n\nTags_per_row_keras = y_test_predicted_labels_tfidf_keras.sum(axis=1)\nnull_rate_keras = round(((Tags_per_row_keras.size - np.count_nonzero(Tags_per_row_keras))\n                       \/Tags_per_row_keras.size)*100,2)\nprint(\"\\n\")\nprint(\"-\"*50)\nprint(\"Percentage of non tagged question for Keras model\")\nprint(\"-\" * 50)\nprint(\"Keras model: {}%\".format(null_rate_keras))","9050b6ce":"x = np.arange(len(df_metrics_compare.columns))\nwidth = 0.35\n\nfig = plt.figure(figsize=(18,10))\nax1 = fig.add_subplot(111)\nf1_scores = ax1.bar(x - width\/2, df_metrics_compare.iloc[1,:], width, label=\"F1 score\")\njacc_scores = ax1.bar(x + width\/2, df_metrics_compare.iloc[2,:], width, label=\"Jaccard score\")\n\nax2 = ax1.twinx()\nnon_predict = ax2.plot(x, [0,30.08,4.45,1.45,21.88],\n                       linestyle='--',\n                       color=\"red\", alpha=.7,\n                       label='No predict (%)')\nax2.grid(None)\n\nax1.set_ylabel('Scores')\nax1.set_title('Comparison of scores by fitted models\\n',\n              color=\"#641E16\", \n              fontdict={'fontsize': 30})\nax1.set_xticks(x)\nax1.set_xticklabels(df_metrics_compare.columns)\n\nlines, labels = ax1.get_legend_handles_labels()\nlines2, labels2 = ax2.get_legend_handles_labels()\nax1.legend(lines + lines2, labels + labels2, loc=0,\n           fontsize=15)\n\nax1.bar_label(f1_scores, padding=3)\nax1.bar_label(jacc_scores, padding=3)\n\nfig.tight_layout()\n\nplt.show()","6402d88d":"# Export fitted model and Preprocessor\njoblib.dump(multi_logit_cv,'logit_nlp_model.pkl')\njoblib.dump(vectorizer,'tfidf_vectorizer.pkl')\njoblib.dump(multilabel_binarizer,'multilabel_binarizer.pkl')","98df0d9c":"import requests\n\nheaders = {'Content-type': 'application\/json'}\nresponse = requests.get('https:\/\/stackoverflow-ml-tagging.herokuapp.com\/autotag\/Test%20with%20Python%20question%20or%20Javascript%20integration%20problem',\n                        headers=headers)\nprint(\"-\"*50)\nprint(\"API test response :\")\nprint(\"-\"*50)\nprint(response.json())","fdb365ec":"# <span style=\"color: #641E16\">Contexte<\/span>\nNous allons ici d\u00e9velopper un algorithme de Machine Learning destin\u00e9 \u00e0 assigner automatiquement plusieurs tags pertinents \u00e0 une question pos\u00e9e sur le c\u00e9l\u00e9bre site Stack overflow.     \nCe programme s'adresse principalement aux nouveaux utilisateurs, afin de leur sugg\u00e9rer quelques tags relatifs \u00e0 la question qu'ils souhaitent poser.\n\n### Les donn\u00e9es sources\nLes donn\u00e9es ont \u00e9t\u00e9 clean\u00e9es dans le Notebook Kaggle [Stackoverflow questions - data cleaning](https:\/\/www.kaggle.com\/michaelfumery\/stackoverflow-questions-data-cleaning). Dans ce nettoyage ont par exemple \u00e9t\u00e9 appliqu\u00e9es les techniques de stop words, suppression de la ponctuation et des liens, tokenisation, lemmatisation ...\n\n### Objectif de ce Notebook\nDans ce Notebook, nous allons traiter la partie **mod\u00e9lisation des donn\u00e9es textuelles avec des mod\u00e8les supervis\u00e9s et non supervis\u00e9s**.     \n\nTous les Notebooks du projet seront **versionn\u00e9s dans Kaggle mais \u00e9galement dans un repo GitHub** disponible \u00e0 l'adresse https:\/\/github.com\/MikaData57\/Analyses-donnees-textuelles-Stackoverflow","97840d8c":"Le mod\u00e8le RandomForest avec Classifier Chains offre des m\u00e9triques similaires au mod\u00e8le avec OneVsRest mais le **taux de remplissage des valeurs pr\u00e9dites est encore meilleur**.\n\nNous allons \u00e0 pr\u00e9sent tester un dernier mod\u00e8le d'apprentissage profond avec Keras et un r\u00e9seau de neurones simple.","7307eba3":"<div style=\"text-align:center;\"><img src=\"http:\/\/www.mf-data-science.fr\/images\/projects\/intro.jpg\" style='width:98%; margin-left: auto; margin-right: auto; display: block;' \/><\/div>","4acaf642":"# <span style=\"color:#641E16\" id=\"section_1\">Preprocessing : Bag of Words \/ Tf-Idf<\/span>\n\nPour alimenter les mod\u00e8les de machine learning, nous avons besoin de traiter des donn\u00e9es num\u00e9riques. Le mod\u00e8le **Bag of Words** apprend un vocabulaire \u00e0 partir de tous les documents, puis mod\u00e9lise chaque document en comptant le nombre de fois o\u00f9 chaque mot appara\u00eet, convertissant donc les donn\u00e9es textuelles en donn\u00e9es num\u00e9riques.\n\nNos donn\u00e9es ayant d\u00e9j\u00e0 \u00e9t\u00e9 clean\u00e9es et tokenis\u00e9es dans le Notebook [stackoverflow-questions-data-cleaning](https:\/\/www.kaggle.com\/michaelfumery\/stackoverflow-questions-data-cleaning), nous allons initialiser l'algorithme du `CountVectorizer` sur les variables `Title` et `Body` *(X1 et X2)* sans preprocessing. Enfin, nous allons utiliser le module `TfidfVectorizer` de la librairie Scikit-Learn pour combiner le `CountVectorizer` et `TfidfTransformer`. Cela aura pour effet de pond\u00e9rer la fr\u00e9quence d'apparition des mots par un indicateur de similarit\u00e9 *(si ce mot est commun ou rare dans tous les documents)*. Dans cette partie, nous allons **\u00e9liminer les mots qui apparaissent dans plus de 60% des documents** (`max_df = 0.6`).\n\nla m\u00e9trique tf-idf ***(Term-Frequency - Inverse Document Frequency)*** utilise comme indicateur de similarit\u00e9 l'inverse document frequency qui est l'inverse de la proportion de document qui contient le terme, \u00e0 l'\u00e9chelle logarithmique.\n\nPour pr\u00e9parer nos targets *(pour les mod\u00e8les supervis\u00e9s)*, nous allons utiliser `MultiLabelBinarizer` de Scikit-Learn puisque nos `Tags` sont multiples.","208cd746":"### <span style=\"color:#641E16;\">Visualisation des r\u00e9sultats de LDA Gensim sur Full_doc avec 20 topics<\/span>","52e4bcb9":"D'apr\u00e8s les r\u00e9sulatas de cette mod\u00e9lisation LDA, il semble tr\u00e8s **difficile de \"nommer\" les topics cr\u00e9\u00e9s car les mots qui les composent sont tr\u00e8s vari\u00e9s et sans fil conducteur clairement \u00e9tabli**. On voit cependant par exemple que le topic repr\u00e9sent\u00e9 par \"server\" englobe \u00e9galement \"database\", \"sql\", \"connection\" ou encore \"query\" ce qui est coh\u00e9rent.\n\n### Am\u00e9lioration du mod\u00e8le LDA\n\nCependant, dans l'algoritmes LDA, nous avons fix\u00e9 arbitrairement \u00e0 20 le param\u00e8tre `num_topics` qui repr\u00e9sente le nombre de topics \u00e0 cr\u00e9er. Afin de s\u00e9lectionner le meilleur nombre de topics pour nos donn\u00e9es, nous allons **it\u00e9rer sur une fourchette de nombre de topics et tester le score de coh\u00e9rence pour chaque mod\u00e8le** :","c1d46772":"Gensim cr\u00e9e un identifiant unique pour chaque mot du document puis mappe word_id et word_frequency. Exemple : (6,3) ci-dessus indique que word_id 6 appara\u00eet 3 fois dans le document et ainsi de suite.      \nLes mots les plus fr\u00e9quents ont ici aussi \u00e9t\u00e9 filtr\u00e9s gr\u00e2ce \u00e0 la fonction `filter_extremes` r\u00e9gl\u00e9e \u00e0 60% comme pour le Tfidf.\n\nPour voir quel mot correspond \u00e0 un identifiant donn\u00e9, il faut transmettre l'identifiant comme cl\u00e9 du dictionnaire. Exemple : id2word[4] :","3bad6135":"## <span id=\"section_3_2\">Mod\u00e9lisation avec RandomForest<\/span>","c4b9402a":"Pour attribuer des Tags \u00e0 chaque question sur ces mod\u00e8les non-supervis\u00e9s, nous allons **cr\u00e9er une matrice Topic\/Tags** en r\u00e9alisant une multiplication matricielle des matrices Document \/ Topic et Document \/ Tags.","6820f411":"Le Random Forest semble donc plus appropri\u00e9 \u00e0 notre programme d'auto-tagging sur les donn\u00e9es Stackoverflow. Nous allons \u00e0 pr\u00e9sent **tester ce mod\u00e8le RandomForest avec Classifier Chains** pour remplacer la m\u00e9thode One versus rest :\n\n## <span id=\"section_3_3\">Mod\u00e8le RandomForest avec Classifier Chains<\/span>\n\nAvec la m\u00e9thode ClassifierChains, chaque mod\u00e8le fait une pr\u00e9diction dans l'ordre sp\u00e9cifi\u00e9 en utilisant toutes les fonctionnalit\u00e9s disponibles fournies au mod\u00e8le mais \u00e9galement les pr\u00e9dictions des mod\u00e8les pr\u00e9c\u00e9dents.","12040190":"Les m\u00e9triques sur le mod\u00e8le RandomForest sont moins bonnes mais semblent cependant plus coh\u00e9rente avec les donn\u00e9es, ce d'autant que les m\u00e9triques Jaccard et F1 sont proches. D'autre part, nous pouvons **v\u00e9rifier le nombre de lignes dont les Tags ne sont pas pr\u00e9dit** afin de voir si l'un des mod\u00e8les est meilleur :","ce32a3fb":"# <span style=\"color:#641E16\">Sommaire<\/span>\n1. [Preprocessing : Bag of Words \/ Tf-Idf](#section_1)\n2. [Mod\u00e8les non supervis\u00e9s](#section_2)     \n    2.1. [Mod\u00e8le LDA](#section_2_1)     \n    2.2. [Mod\u00e8le NMF](#section_2_2)     \n3. [Mod\u00e8les supervis\u00e9s](#section_3)     \n    3.1. [R\u00e9gression logistique avec multi-labels](#section_3_1)      \n    3.2. [Mod\u00e9lisation avec RandomForest](#section_3_2)       \n    3.3. [Mod\u00e8le RandomForest avec Classifier Chains](#section_3_3)       \n    3.4. [R\u00e9seau de neurones avec Keras](#section_3_4)       \n4. [S\u00e9lection du mod\u00e8le final](#section_4) ","516b0d66":"Nous allons \u00e0 pr\u00e9sent entrainer le mod\u00e8le LDA sur Full_doc puis afficher les m\u00e9triques : \n- **Perplexity** : $(\\exp(-1 \\times \\text{log-likelihood})$ *(Log likelihood : Densit\u00e9 de vraisemblance)*\n- **Coherence Score** : Les mesures de coh\u00e9rence de topics \u00e9valuent un seul topic en mesurant le degr\u00e9 de similitude s\u00e9mantique entre les mots \u00e0 score \u00e9lev\u00e9 dans ce dernier.       Pour en savoir plus sur ce Pipeline : [What is topic coherence ?](https:\/\/rare-technologies.com\/what-is-topic-coherence\/)","e7b66f3f":"Nous constatons que cette mesure est meilleure pour la varaible englobant Title et Body *(Full_doc)*.","f9462c17":"# <span style=\"color:#641E16\" id=\"section_4\">S\u00e9lection du mod\u00e8le final<\/span>\n\nPour s\u00e9lectionner le mod\u00e8le final, nous allons nous baser sur les scores obtenus aux m\u00e9triques Jaccard et F1. Nous prendrons \u00e9galement en compte le taux de \"non pr\u00e9dits\" pour trouver le meilleur compromis entre tout ces indicateurs de performance.","b527ba4e":"Le mod\u00e8le **NMF ne peut malheureusement pas \u00eatre scor\u00e9**. Nous allons donc nous baser sur les r\u00e9sultats de la LDA pour d\u00e9terminer un nombre correct de composants. Ici, nous prendrons **31 topics** pour avoir un bon compromis \"temps d'entrainement\" \/ pr\u00e9cision et utiliserons les matrices Tfidf cr\u00e9\u00e9es lors du preprocessing.","58306f9d":"## <span id=\"section_3_4\">R\u00e9seau de neurones avec Keras<\/span>","efb4862d":"Nous obtenons donc une matrice dont les lignes repr\u00e9sentent les Topics cr\u00e9\u00e9s et les colonnes les Tags associ\u00e9s et leurs distribution. Nous allons donc **cr\u00e9er nos pr\u00e9dictions en prenant les** $\\large n$ **premiers tags associ\u00e9s aux topics** de chaque document :","7e5b005e":"Affichons les scores des divers mod\u00e8le :","d9f54c3f":"Nous allons tester plusieurs m\u00e9triques sur ce mod\u00e8le LDA :\n- Accuracy score :\n- F1 score :\n- Jaccard similarity score : \n- Recall :\n- Precision :","469161a0":"Puis nous **calculons les diverses m\u00e9triques sur le meilleur mod\u00e8le** de r\u00e9gression logistique :","7fb12b4d":"L'appel \u00e0 l'API (autotag\/\\{question\\}) peut \u00e9galement \u00eatre test\u00e9e avec ***Curl*** par exemple : ","3ae05ca9":"Comme les matrices sont relativment importantes, nous allons **v\u00e9rifier le nombre de cellules qui ne sont pas \u00e0 0** :","cb58d617":"Nous allons \u00e9galement cr\u00e9er une variable `Full_doc` qui accueillera le document complet de chaque item (Title et Body) :","70fe6cf8":"**La mod\u00e9lisation avec NMF nous apporte des cat\u00e9gories aussi lisibles que celles de l'algorithme LDA**. 1 mot est toujours beaucoup plus repr\u00e9sentaif de cette cat\u00e9gorie mais les regroupements sont globalement coh\u00e9rents. Un topic par exemple illustre bien les sujets li\u00e9s SQL, aux requ\u00eates, un second traite les sujets li\u00e9s aux dictionnaires ...\n\nEn revanche, les topics g\u00e9n\u00e9r\u00e9s restent tr\u00e8s g\u00e9n\u00e9raux et ne permettent pas une cat\u00e9gorisation coh\u00e9rente pour notre probl\u00e8me d'auto-tagging. Nous allons donc tester des mod\u00e8les supervis\u00e9s.","eeac489e":"On peut constater que le **mod\u00e8le RandomForest avec Classifier Chain offre le meilleur compromis entre le taux de valeur pr\u00e9dites et les m\u00e9triques Jaccard, F1**. Ce mod\u00e8le est donc le meilleur mod\u00e8le test\u00e9 et devrait \u00eatre s\u00e9lectionn\u00e9 pour notre probl\u00e9matique de proposition de Tags Stockoverflow.\n\nNous allons cependant tester le mod\u00e8le de r\u00e9gression logistique pour alimenter l'**API de pr\u00e9diction de Tags** r\u00e9alis\u00e9e avec `Flask`, `Flask_RestFul` et `Swagger` *(Pour des raisons de restrictions sur la taille maximale des d\u00e9p\u00f4ts sur les principales plateformes d'hebergement gratuits)*. \n\nCette API est d\u00e9pos\u00e9e dans un repo ***Git*** (https:\/\/github.com\/MikaData57\/stackoverflow_swagger_api) puis d\u00e9ploy\u00e9e sur ***Heroku***. Une documentation est disponible sur Heroku pour tester le mod\u00e8le avec de nouvelles questions : https:\/\/stackoverflow-ml-tagging.herokuapp.com\/apidocs\/\n\nNous allons **exporter le mod\u00e8le entrain\u00e9** ainsi que les preprocessing Tfidf et multilaber_binarizer entrain\u00e9s pour les int\u00e9grer \u00e0 cette API.","755f2eea":"Nous allons d\u00e9finir une fonction pour constuire le r\u00e9seau de neurones assez simple. RNN avec une couche cach\u00e9e et compl\u00e9tement connect\u00e9e. Nous utiliserons \u00e9galement un Dropout pour \u00e9viter le sur-apprentissage.","55248ab2":"Nous pouvons maintenant **r\u00e9aliser les pr\u00e9dictions avec le mod\u00e8le de r\u00e9gression logistique sur le jeu de test** pour pouvoir les comparer avec le jeu y_test.","cd6a1c13":"On remarque ici que la mod\u00e9lisation non supervis\u00e9e avec LDA n'est pas adapt\u00e9e. En effet, le meilleur nombre de topics se situerait \u00e0 31, mais **l'algorithme ne parvient pas a \u00e9tablir de groupes bien distincts**. Un certain nombre de topics sont tr\u00e8s regroup\u00e9s et donc repr\u00e9sent\u00e9s par les m\u00eames termes.\n\nNous allons donc tester une seconde mod\u00e9lisation non supervis\u00e9e.\n\n## <span id=\"section_2_2\">Mod\u00e8le NMF<\/span>\n<details>\n  <summary style=\"color:blue;\">Explication du mod\u00e8le<\/summary>\n  \n  ## NMF\n  La factorisation matricielle non n\u00e9gative *(**N**on-negative **M**atrix **F**actorization)* est un mod\u00e8le lin\u00e9aire-alg\u00e9abrique, qui factorise des vecteurs de grande dimension dans une repr\u00e9sentation de faible dimension. Similaire \u00e0 l'analyse en composantes principales *(PCA)*, NMF profite du fait que **les vecteurs sont non n\u00e9gatifs**. En les factorisant dans la forme de dimension inf\u00e9rieure, NMF force les coefficients \u00e0 \u00eatre \u00e9galement non n\u00e9gatifs.<br\/><br\/>\n    Prenons une matrice d'origine $A$, nous pouvons obtenir deux matrices $W$ et $H$, telles que $A = WH$. NMF a une propri\u00e9t\u00e9 de clustering, telle que $W$ et $H$ repr\u00e9sentent les informations suivantes sur $A$ :\n    <ul><li>$A$ (Matrice Document-word) : Matrice qui contient \"quels mots apparaissent dans quels documents\".<\/li>\n    <li>$W$ (Vecteurs de base) : Topics d\u00e9couverts \u00e0 partir des documents.<\/li>\n    <li>$H$ (Matrice de coefficients) : les poids pour les topics dans chaque document.<\/li><\/ul><br\/>\n    Nous calculons $W$ et $H$ en optimisant sur une **fonction objectif**, en mettant \u00e0 jour \u00e0 la fois $W$ et $H$ de mani\u00e8re it\u00e9rative jusqu'\u00e0 convergence.<\/br><\/br>\n    $$\\large \\frac{1}{2} ||A - WH||^2_F = \\sum_{i=1}^{n} \\sum_{j=1}^{m} (A_{ij} - (WH)_{ij})^2$$<\/br>\n    Dans cette fonction objectif, nous mesurons l'erreur de reconstruction entre A et le produit de ses facteurs W et H, en fonction de la distance euclidienne. Les valeurs mises \u00e0 jour sont calcul\u00e9es dans des op\u00e9rations parall\u00e8les, et en utilisant les nouveaux W et H, nous recalculons l'erreur de reconstruction, en r\u00e9p\u00e9tant ce processus jusqu'\u00e0 la convergence.\n<\/details>","9392009c":"# <span style=\"color:#641E16\" id=\"section_2\">Mod\u00e8les non supervis\u00e9s<\/span>\n\n## <span id=\"section_2_1\">Mod\u00e8le LDA<\/span>\nLDA, ou **Latent Derelicht Analysis** est un mod\u00e8le probabiliste qui, pour obtenir des affectations de cluster, utilise deux valeurs de probabilit\u00e9 : $P(word | topics)$ et $P(topics | documents)$. Ces valeurs sont calcul\u00e9es sur la base d'une attribution al\u00e9atoire initiale, puis le calcul est r\u00e9p\u00e9t\u00e9 pour chaque mot dans chaque document, pour d\u00e9cider de leur attribution de sujet. Dans cette m\u00e9thode it\u00e9rative, ces probabilit\u00e9s sont calcul\u00e9es plusieurs fois, jusqu'\u00e0 la convergence de l'algorithme.\n\nNous allons entrainer 1 seul mod\u00e8le bas\u00e9 sur la variable `Full_doc` en utilisant la librairie sp\u00e9cialis\u00e9e **Gensim**. Pour cette partie, nous n'utiliserons pas le preprocessing TFIDF mais des fonctions propres aux m\u00e9thodes Gensim.\n\nDans une premi\u00e8re \u00e9tape, le Bag of words est cr\u00e9\u00e9 ainsi que la matrice de fr\u00e9quence des termes dans les documents :","830be5fb":"A pr\u00e9sent, cr\u00e9ons la matrice Topic \/ Tags gr\u00e2ce aux probabilit\u00e9s obtenues :","f7a840e5":"Testons \u00e0 pr\u00e9sent le mod\u00e8le avec le meilleur nombre th\u00e9orique de topics pour l'afficher avec LDAvis :","81ee985a":"# <span style=\"color:#641E16\" id=\"section_3\">Mod\u00e8les supervis\u00e9s<\/span>\n\n## <span id=\"section_3_1\">R\u00e9gression logistique avec multi-labels<\/span>\nNous avons d\u00e9j\u00e0 r\u00e9alis\u00e9 quelques Notebook traitant de la r\u00e9gression logistique : c'est une technique pr\u00e9dictive. Elle vise \u00e0 construire un mod\u00e8le permettant de pr\u00e9dire \/ expliquer les valeurs prises par une variable cible qualitative \u00e0 partir d\u2019un ensemble de variables explicatives quantitatives ou qualitatives encod\u00e9es.\n\nPour cette partie sur les mod\u00e9lisations supervis\u00e9es, nous allons utiliser la variable `Full_doc` qui regroupe le Title et le Body puis cr\u00e9er un Pipeline qui ne pourra pas inclure la transformation de notre variable cible *(MultiLabelBinarizer ne fonctionne pas dans les Pipeline SKlearn)*."}}