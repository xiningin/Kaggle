{"cell_type":{"53203ea3":"code","41c30c91":"code","66c971e2":"markdown"},"source":{"53203ea3":"from collections import Counter\n\nimport pandas as pd\nimport numpy as np\nimport Levenshtein\n\ndataset_path = \"..\/input\/moroccoaidatachallengeedition001\/\"\ntrain_df = pd.read_csv(dataset_path + \"train.csv\")\n\n# Calculate the length of plate_strings\nnum_digits = train_df[\"plate_string\"].map(len)\n# Get the most commun length of plate_strings\ncommun_length = Counter(num_digits).most_common()[0][0]\n# Find the most used character for each position\n# Build a plate with the most used characters\ncommun_characters = [[] for i in range(commun_length)]\nfor v in train_df[num_digits == commun_length][\"plate_string\"].apply(list):\n    for i in range(commun_length):\n        commun_characters[i].append(v[i])\nbaseline_plate = \"\".join([\n    max(set(characters), key=characters.count) for characters in commun_characters])\nprint(baseline_plate)\n# Calculate the Levenshtein distance between the real plates and baseline_plate\ntrain_df[\"most_freq_plate\"] = baseline_plate\nprint(np.mean([Levenshtein.distance(row[1], row[2]) for _, row in train_df.iterrows()]))","41c30c91":"# Prediction\ntest_df = pd.read_csv(dataset_path + \"test.csv\")\ntest_df[\"plate_string\"] = baseline_plate\ntest_df.to_csv(\"baseline_predictions.csv\", index=False)","66c971e2":"A **baseline** is a method that uses heuristics, simple summary statistics, randomness, or machine learning to create predictions for a dataset. You can use these predictions to measure the baseline's performance (here, the Levenshtein distance). This metric will then become what you compare any other machine learning algorithm against."}}