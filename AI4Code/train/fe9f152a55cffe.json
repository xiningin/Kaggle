{"cell_type":{"73eba4ab":"code","8c1f0479":"code","febe95a2":"code","5e3d81b4":"code","34a66789":"code","665b9cab":"code","436acca9":"code","cdc8ae3d":"code","0f0dbc75":"code","c8f4cc0d":"code","af2e0f51":"code","b9f8b2ee":"code","83c66452":"code","f07a23b9":"code","55c2092a":"code","a8003ac9":"code","e99492a9":"code","ff46d687":"code","aab592e2":"code","49d00127":"code","9877e3bc":"code","d09f4b7e":"code","7de1ec42":"code","bfd568a5":"code","9054d152":"code","f0b095d7":"code","1023c78e":"code","d4dc7070":"code","20c2e890":"code","fb81440c":"code","3f902d1f":"code","4bfe57f2":"code","cf9fb09e":"code","69be94b7":"code","0a68c748":"code","c47e9a50":"code","279e74cb":"code","78eac73a":"code","0dbd1c1b":"code","07ea437b":"code","c557c831":"code","5d43bfd4":"code","6528648c":"code","0c24c4f4":"code","9d6e9df4":"code","6fa71fe3":"code","4b8bb0e4":"code","6ed151f0":"code","2901de55":"code","31155657":"code","6c24c6e5":"code","826be073":"code","e6d81216":"code","2c5003b3":"code","d4bee1f0":"code","9e8d925c":"code","17e125e3":"code","26e17b76":"code","a95946d4":"code","e1fc4e74":"code","84fac346":"code","402ed071":"code","66009b1b":"code","76aa2a9e":"code","c8cf15c5":"code","366cffc7":"code","b5c9d755":"code","b5c4c33a":"code","ebc7d070":"code","705614fa":"code","3a3d612c":"code","1d42b683":"code","2555c09d":"code","ca55cc1c":"code","dbfb83c0":"code","a10f26da":"code","ace03c8b":"code","78ad73e3":"code","6c4cac5b":"code","c3394826":"code","abffae37":"code","a618c315":"code","66788af3":"code","d9ee4ce6":"code","b3eeda8b":"code","f6a43ae4":"code","1cccf6e3":"code","f8765675":"code","a6fef81a":"code","446f7375":"code","1ec27cc8":"code","3d0f41d8":"code","2817f69e":"code","23225650":"code","35892eff":"code","5493da52":"code","4717b1fa":"code","a453314f":"code","0ec1f94e":"code","485c8ed0":"code","ab669ac0":"code","95b8b0a5":"code","81c05b41":"code","dafdc0ff":"code","ed08f9db":"code","b9505ee4":"code","21739acb":"code","097237cb":"code","45094cda":"code","f30637ed":"code","9e941cc9":"code","45b6737a":"code","cff0b890":"code","dcdb0c86":"code","140bde8f":"code","7620ff4c":"code","997cf81c":"code","36623988":"code","35864096":"code","9ee5dc59":"code","63b6b5b5":"code","442ac3fb":"code","2a1477f5":"code","dcefb7ec":"code","e3244f2d":"code","74c68156":"code","b839581e":"code","92b2d5d1":"code","75bc28c1":"code","3115bbdb":"code","0373bcbc":"code","0e8a829b":"code","9b687d12":"code","255303eb":"code","27be83c0":"code","4bbcf9d7":"code","e12e98cb":"code","f8643aed":"code","a1bae8e7":"code","e4022eeb":"code","a2ddd9db":"code","afd5f14c":"code","c26dee85":"code","1ce998dc":"code","97bc54ea":"code","6fa97b07":"code","7edac286":"code","b3d49785":"code","10e0a5c5":"code","d8f790f5":"code","f149aff6":"code","8aca499f":"code","77f36dff":"code","13d79c6a":"code","d8ba8f23":"code","d2db6f0e":"code","6a7b5707":"code","ab5e2fe7":"code","e588f8c1":"code","25f41976":"code","7a5476c8":"code","38fb9ad2":"code","53614b34":"code","c50e46fa":"code","46099f29":"code","bc06b86b":"code","cd08553a":"markdown","8a19033c":"markdown","a255ec92":"markdown","cc335e47":"markdown","c0631e23":"markdown","950a1433":"markdown","25fe2498":"markdown","43730fcf":"markdown","d9778a72":"markdown","6e9404dd":"markdown","f4dd93a4":"markdown","8f155998":"markdown","15ff724f":"markdown","e6f39e55":"markdown","3f8c640a":"markdown","8f6cc7ee":"markdown","e02ab59f":"markdown","e74cfd3f":"markdown","e00748d0":"markdown","e36167d5":"markdown","92b8792a":"markdown","0982f5a7":"markdown","334a1f68":"markdown","2ffde60b":"markdown","02a90d4e":"markdown","1ff8dad0":"markdown","22d08870":"markdown","c647ded9":"markdown","03c396c3":"markdown","b7192a99":"markdown","3a431aab":"markdown","e7451b1d":"markdown","bd99423d":"markdown","464d0a7a":"markdown","c1e15ae3":"markdown","b7dc88d4":"markdown","fab9fa18":"markdown","bded9288":"markdown","a3b64e3e":"markdown","9ef334a5":"markdown","3cfc501e":"markdown","472b7585":"markdown","92140976":"markdown","e1be3121":"markdown","b862af7c":"markdown","9f297f77":"markdown","0be9742c":"markdown","c28e8680":"markdown","6200f36e":"markdown","4865efad":"markdown","4c29048a":"markdown"},"source":{"73eba4ab":"import numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8c1f0479":"train = pd.read_csv('..\/input\/open-shopee-code-league-marketing-analytics\/train.csv')\ntest = pd.read_csv('..\/input\/open-shopee-code-league-marketing-analytics\/test.csv')\nusers = pd.read_csv('..\/input\/open-shopee-code-league-marketing-analytics\/users.csv')\nsamp_sub = pd.read_csv('..\/input\/open-shopee-code-league-marketing-analytics\/sample_submission_0_1.csv')\n\nprint('train:', train.shape)\nprint('test:', test.shape)\nprint('users:', users.shape)\nprint('sample submission:', samp_sub.shape)","febe95a2":"train","5e3d81b4":"test","34a66789":"users","665b9cab":"samp_sub","436acca9":"train['open_flag'].value_counts()","cdc8ae3d":"train = pd.merge(train, users, on = 'user_id', how = 'left')\ntest = pd.merge(test, users, on = 'user_id', how = 'left')","0f0dbc75":"train.info()","c8f4cc0d":"# change type of categorical columns to str\ntrain['country_code'] = train['country_code'].astype(str)\ntrain['attr_1'] = train['attr_1'].astype(str)\ntrain['attr_2'] = train['attr_2'].astype(str)\ntrain['attr_3'] = train['attr_3'].astype(str)\n\ntest['country_code'] = test['country_code'].astype(str)\ntest['attr_1'] = test['attr_1'].astype(str)\ntest['attr_2'] = test['attr_2'].astype(str)\ntest['attr_3'] = test['attr_3'].astype(str)","af2e0f51":"import datetime as dt\n\ntrain['grass_date'] = pd.to_datetime(train['grass_date'])\ntest['grass_date'] = pd.to_datetime(test['grass_date'])","b9f8b2ee":"train_flag0 = train[train['open_flag'] == 0]\ntrain_flag1 = train[train['open_flag'] == 1]","83c66452":"train_flag1['country_code'].hist()","f07a23b9":"train_flag0['country_code'].hist()","55c2092a":"print(train['grass_date'].min(), train['grass_date'].max())\nprint(test['grass_date'].min(), test['grass_date'].max())","a8003ac9":"# add new column 'day_of_week'\ntrain['day_of_week'] = train['grass_date'].dt.day_name()\ntest['day_of_week'] = test['grass_date'].dt.day_name()\n\ntrain['day_of_month'] = train['grass_date'].dt.day\ntest['day_of_month'] = test['grass_date'].dt.day","e99492a9":"train['day_of_week'].value_counts()","ff46d687":"print(train['subject_line_length'].min(), test['subject_line_length'].max())","aab592e2":"train_flag1['subject_line_length'].hist()","49d00127":"train_flag0['subject_line_length'].hist()","9877e3bc":"last_open_day_train = train[train['last_open_day'] != 'Never open'].last_open_day.astype(int)\nlast_open_day_test = test[test['last_open_day'] != 'Never open'].last_open_day.astype(int)\nprint(last_open_day_train.min(), last_open_day_train.max())\nprint(last_open_day_test.min(), last_open_day_test.max())","d09f4b7e":"train[(train['last_open_day'] == 'Never open') & (train['open_flag'] == 1)]","7de1ec42":"train_temp1 = train[(train['last_open_day'] != 'Never open') & (train['open_flag'] == 1)]\ntrain_temp0 = train[(train['last_open_day'] != 'Never open') & (train['open_flag'] == 0)]\ntrain_temp1['last_open_day'] = train_temp1['last_open_day'].astype(int)\ntrain_temp0['last_open_day'] = train_temp0['last_open_day'].astype(int)","bfd568a5":"train_temp1['last_open_day'].hist()","9054d152":"train_temp1 = train_temp1[(train_temp1['last_open_day'] < 300)]\ntrain_temp1['last_open_day'].hist()","f0b095d7":"train_temp0['last_open_day'].hist()","1023c78e":"train_temp0[(train_temp0['last_open_day'] < 500)]['last_open_day'].hist()","d4dc7070":"test[(test['last_open_day'] == 'Never open')]","20c2e890":"last_login_day_train = train[train['last_login_day'] != 'Never login'].last_login_day.astype(int)\nlast_login_day_test = test[test['last_login_day'] != 'Never login'].last_login_day.astype(int)\nprint(last_login_day_train.min(), last_login_day_train.max())\nprint(last_login_day_test.min(), last_login_day_test.max())","fb81440c":"train_temp1 = train[(train['last_login_day'] != 'Never login') & (train['open_flag'] == 1)]\ntrain_temp0 = train[(train['last_login_day'] != 'Never login') & (train['open_flag'] == 1)]\ntrain_temp1['last_login_day'] = train_temp1['last_login_day'].astype(int)\ntrain_temp0['last_login_day'] = train_temp0['last_login_day'].astype(int)","3f902d1f":"train_temp1['last_login_day'].hist()","4bfe57f2":"train_temp1[train_temp1['last_login_day'] < 200]['last_login_day'].hist()","cf9fb09e":"train_temp0[train_temp0['last_login_day'] < 200]['last_login_day'].hist()","69be94b7":"train_temp1[train_temp1['last_login_day'] > 15000]","0a68c748":"len(test[test['last_login_day'] == 'Never login'])","c47e9a50":"train['last_checkout_day'].value_counts()","279e74cb":"last_checkout_day_train = train[train['last_checkout_day'] != 'Never checkout'].last_checkout_day.astype(int)\nlast_checkout_day_test = test[test['last_checkout_day'] != 'Never checkout'].last_checkout_day.astype(int)\nprint(last_checkout_day_train.min(), last_checkout_day_train.max())\nprint(last_checkout_day_test.min(), last_checkout_day_test.max())","78eac73a":"train[(train['last_checkout_day'] == 'Never checkout') & (train['open_flag'] == 1)]","0dbd1c1b":"train_temp = train[(train['last_checkout_day'] != 'Never checkout') & (train['open_flag'] == 1)]\ntrain_temp['last_checkout_day'] = train_temp['last_checkout_day'].astype(int)","07ea437b":"train_temp['last_checkout_day'].hist()","c557c831":"train_temp = train_temp[train_temp['last_checkout_day'] < 100]\ntrain_temp['last_checkout_day'].hist()","5d43bfd4":"train_temp = train[(train['last_checkout_day'] != 'Never checkout') & (train['open_flag'] == 0)]\ntrain_temp['last_checkout_day'] = train_temp['last_checkout_day'].astype(int)","6528648c":"train_temp['last_checkout_day'].hist()","0c24c4f4":"train_temp = train_temp[train_temp['last_checkout_day'] < 100]\ntrain_temp['last_checkout_day'].hist()","9d6e9df4":"train['open_count_last_10_days'].value_counts()","6fa71fe3":"train_flag1 = train[train['open_flag'] == 1]\ntrain_flag0 = train[train['open_flag'] == 0]","4b8bb0e4":"train_flag1['open_count_last_10_days'].hist()","6ed151f0":"train_flag0['open_count_last_10_days'].hist()","2901de55":"train_flag1['open_count_last_30_days'].hist()","31155657":"train_flag0['open_count_last_30_days'].hist()","6c24c6e5":"train_flag1['open_count_last_60_days'].hist()","826be073":"train_flag0['open_count_last_60_days'].hist()","e6d81216":"train_flag1['login_count_last_10_days'].hist()","2c5003b3":"train_flag0['login_count_last_10_days'].hist(bins = [0, 20, 40, 60, 80, 100])","d4bee1f0":"train_flag1['login_count_last_30_days'].hist()","9e8d925c":"train_flag0['login_count_last_30_days'].hist(bins = [0, 100, 200, 300])","17e125e3":"train_flag1['login_count_last_60_days'].hist()","26e17b76":"train_flag0['login_count_last_60_days'].hist()","a95946d4":"train_flag1['checkout_count_last_10_days'].hist()","e1fc4e74":"train_flag0['checkout_count_last_10_days'].hist()","84fac346":"train_flag1[train_flag1['checkout_count_last_30_days'] < 100]['checkout_count_last_30_days'].hist()","402ed071":"train_flag0[train_flag0['checkout_count_last_30_days'] < 100]['checkout_count_last_30_days'].hist()","66009b1b":"train_flag1[train_flag1['checkout_count_last_60_days'] < 100]['checkout_count_last_60_days'].hist()","76aa2a9e":"train_flag0[train_flag0['checkout_count_last_60_days'] < 100]['checkout_count_last_60_days'].hist()","c8cf15c5":"train.describe()","366cffc7":"test.describe()","b5c9d755":"train_flag1 = train[train['open_flag'] == 1]\ntrain_flag0 = train[train['open_flag'] == 0]","b5c4c33a":"train_flag1['age'].hist()","ebc7d070":"train_flag0['age'].hist()","705614fa":"train_flag1[train_flag1['age'] > 110]['age'].hist()","3a3d612c":"train_flag0[train_flag0['age'] > 110]['age'].hist()","1d42b683":"train[(train.age > 116)]","2555c09d":"train['age_class'] = train['age'].isna()\ntrain['age_class'] = train['age_class'].map({True:'Unknown',False:'<>'})\n\ntest['age_class'] = test['age'].isna()\ntest['age_class'] = test['age_class'].map({True:'Unknown',False:'<>'})\n\ntrain.loc[train['age'] >= 30, 'age_class'] = '>=30'\ntrain.loc[train['age'] < 30, 'age_class'] = '<30'\n\ntest.loc[test['age'] >= 30, 'age_class'] = '>=30'\ntest.loc[test['age'] < 30, 'age_class'] = '<30'","ca55cc1c":"train.loc[train['age'] > 110, 'age'] = np.nan\ntest.loc[test['age'] > 110, 'age'] = np.nan","dbfb83c0":"train.loc[train['age'] < 0, 'age'] = np.nan\ntest.loc[test['age'] < 0, 'age'] = np.nan","a10f26da":"train_flag1['domain'].value_counts()","ace03c8b":"train_flag0['domain'].value_counts()","78ad73e3":"train_flag1['domain'].hist()","6c4cac5b":"train_flag0['domain'].hist()","c3394826":"list_low_domain = ['@163.com','@gmail.com','@yahoo.com','@ymail.com'] # low open rate\nlist_med_domain = ['@outlook.com','@qq.com','@rocketmail.com'] # medium open rate\nlist_high_domain = ['@hotmail.com','@icloud.com','@live.com','other'] # high open rate\n\ndef make_domain_type(dom) :\n    if dom in list_low_domain :\n        res = 'low_domain'\n    elif dom in list_med_domain :\n        res = 'med_domain'\n    elif dom in list_high_domain :\n        res = 'high_domain'\n        \n    return res\n\ntrain['domain_type'] = train.apply(lambda x : make_domain_type(x['domain']), axis=1)\ntest['domain_type'] = test.apply(lambda x : make_domain_type(x['domain']), axis=1)","abffae37":"train_flag1['attr_1'].value_counts()","a618c315":"train_flag0['attr_1'].value_counts()","66788af3":"train[(train['open_flag'] == 1) & (train['attr_1'] == 'nan')]","d9ee4ce6":"train[(train['open_flag'] == 0) & (train['attr_1'] == 'nan')]","b3eeda8b":"train_flag1['attr_2'].value_counts()","f6a43ae4":"train_flag0['attr_2'].value_counts()","1cccf6e3":"train_flag1['attr_3'].value_counts()","f8765675":"train_flag0['attr_3'].value_counts()","a6fef81a":"train.isna().sum()","446f7375":"test.isna().sum()","1ec27cc8":"train[['attr_1', 'attr_2', 'attr_3']]","3d0f41d8":"# add a new unknown variable per attribute\ntrain['attr_1'] = train['attr_1'].replace(['nan'], '2.0')\ntrain['attr_2'] = train['attr_2'].replace(['nan'], '2.0')\ntest['attr_1'] = test['attr_1'].replace(['nan'], '2.0')\ntest['attr_2'] = test['attr_2'].replace(['nan'], '2.0')\n\n# print(train['attr_1'].isna().sum(), test['attr_1'].isna().sum())\n# print(train['attr_2'].isna().sum(), test['attr_1'].isna().sum())","2817f69e":"train['attr_1'].value_counts()","23225650":"train.isna().sum()","35892eff":"test.isna().sum()","5493da52":"train._get_numeric_data().columns","4717b1fa":"train['grass_date'] = train['grass_date'].dt.tz_convert(None)\ntrain['grass_date'] = (train['grass_date'] - dt.datetime(1970,1,1)).dt.total_seconds()\n\ntest['grass_date'] = test['grass_date'].dt.tz_convert(None)\ntest['grass_date'] = (test['grass_date'] - dt.datetime(1970,1,1)).dt.total_seconds()","a453314f":"# never_open, boolean\ntrain['never_open'] = train['last_open_day'].apply(lambda x: 'never_open' if x == 'Never open' else 'open')\ntest['never_open'] = test['last_open_day'].apply(lambda x: 'never_open' if x == 'Never open' else 'open')\n\n# never_login, boolean\ntrain['never_login'] = train['last_login_day'].apply(lambda x: 'never_login' if x == 'Never login' else 'login')\ntest['never_login'] = test['last_login_day'].apply(lambda x: 'never_login' if x == 'Never login' else 'login')\n\n# never_checkout, boolean\ntrain['never_checkout'] = train['last_checkout_day'].apply(lambda x: 'never_checkout' if x == 'Never checkout' else 'checkout')\ntest['never_checkout'] = test['last_checkout_day'].apply(lambda x: 'never_checkout' if x == 'Never checkout' else 'checkout')","0ec1f94e":"train['never_open'].value_counts()","485c8ed0":"train[['last_open_day', 'last_login_day', 'last_checkout_day']]","ab669ac0":"train['last_open_day'].value_counts()","95b8b0a5":"len(train[train['last_open_day'] == '0'])","81c05b41":"train['last_open_day'] = train['last_open_day'].replace(['Never open'], 1000)\ntrain['last_open_day'] = train['last_open_day'].astype(int)\ntrain['last_open_day'].value_counts()","dafdc0ff":"test['last_open_day'] = test['last_open_day'].replace(['Never open'], 1000)\ntest['last_open_day'] = test['last_open_day'].astype(int)\ntest['last_open_day'].value_counts()","ed08f9db":"train['last_login_day'] = train['last_login_day'].replace(['Never login'], 19000)\ntrain['last_login_day'] = train['last_login_day'].astype(int)\ntrain['last_login_day'].value_counts()","b9505ee4":"test['last_login_day'] = test['last_login_day'].replace(['Never login'], 19000)\ntest['last_login_day'] = test['last_login_day'].astype(int)\ntest['last_login_day'].value_counts()","21739acb":"train['last_checkout_day'].value_counts()","097237cb":"len(train[train['last_checkout_day'] == '0'])","45094cda":"train['last_checkout_day'] = train['last_checkout_day'].replace(['Never checkout'], 1500)\ntrain['last_checkout_day'] = train['last_checkout_day'].astype(int)\ntrain['last_checkout_day'].value_counts()","f30637ed":"test['last_checkout_day'] = test['last_checkout_day'].replace(['Never checkout'], 1500)\ntest['last_checkout_day'] = test['last_checkout_day'].astype(int)\ntest['last_checkout_day'].value_counts()","9e941cc9":"train.info()","45b6737a":"train_feat = train._get_numeric_data()\ntrain_feat","cff0b890":"test_feat = test._get_numeric_data()","dcdb0c86":"dom_flag = pd.get_dummies(train['domain'])\ntrain_feat = pd.concat([train_feat, dom_flag], axis = 1)\ntrain_feat","140bde8f":"dom_flag","7620ff4c":"dom_flag_test = pd.get_dummies(test['domain'])\ntest_feat = pd.concat([test_feat, dom_flag_test], axis = 1)\ntest_feat","997cf81c":"ccode_flag = pd.get_dummies(train['country_code'])\ntrain_feat = pd.concat([train_feat, ccode_flag], axis = 1)\ntrain_feat","36623988":"ccode_flag_test = pd.get_dummies(test['country_code'])\ntest_feat = pd.concat([test_feat, ccode_flag_test], axis = 1)\ntest_feat","35864096":"dweek_flag = pd.get_dummies(train['day_of_week'])\ntrain_feat = pd.concat([train_feat, dweek_flag], axis = 1)\ntrain_feat","9ee5dc59":"dweek_flag_test = pd.get_dummies(test['day_of_week'])\ntest_feat = pd.concat([test_feat, dweek_flag_test], axis = 1)\ntest_feat","63b6b5b5":"open_flag = pd.get_dummies(train['never_open'])\ntrain_feat = pd.concat([train_feat, open_flag], axis = 1)\nprint(train_feat.shape)\n\nopen_flag_test = pd.get_dummies(test['never_open'])\ntest_feat = pd.concat([test_feat, open_flag_test], axis = 1)\nprint(test_feat.shape)","442ac3fb":"login_flag = pd.get_dummies(train['never_login'])\ntrain_feat = pd.concat([train_feat, login_flag], axis = 1)\nprint(train_feat.shape)\n\nlogin_flag_test = pd.get_dummies(test['never_login'])\ntest_feat = pd.concat([test_feat, login_flag_test], axis = 1)\nprint(test_feat.shape)","2a1477f5":"checkout_flag = pd.get_dummies(train['never_checkout'])\ntrain_feat = pd.concat([train_feat, checkout_flag], axis = 1)\nprint(train_feat.shape)\n\ncheckout_flag_test = pd.get_dummies(test['never_checkout'])\ntest_feat = pd.concat([test_feat, checkout_flag_test], axis = 1)\nprint(test_feat.shape)","dcefb7ec":"attr1_mapper_encode = {'0.0': 'attr_10',\n                       '1.0': 'attr_11',\n                       '2.0': 'attr_12'}\n\ntrain['attr_1'] = train['attr_1'].map(attr1_mapper_encode)\ntest['attr_1'] = test['attr_1'].map(attr1_mapper_encode)","e3244f2d":"attr2_mapper_encode = {'0.0': 'attr_20',\n                       '1.0': 'attr_21',\n                       '2.0': 'attr_22'}\n\ntrain['attr_2'] = train['attr_2'].map(attr2_mapper_encode)\ntest['attr_2'] = test['attr_2'].map(attr2_mapper_encode)","74c68156":"attr3_mapper_encode = {'0.0': 'attr_30',\n                       '1.0': 'attr_31',\n                       '2.0': 'attr_32',\n                       '3.0': 'attr_33', \n                       '4.0': 'attr_34'}\n\ntrain['attr_3'] = train['attr_3'].map(attr3_mapper_encode)\ntest['attr_3'] = test['attr_3'].map(attr3_mapper_encode)","b839581e":"attr1_flag = pd.get_dummies(train['attr_1'])\ntrain_feat = pd.concat([train_feat, attr1_flag], axis = 1)\nprint(train_feat.shape)\n\nattr1_flag_test = pd.get_dummies(test['attr_1'])\ntest_feat = pd.concat([test_feat, attr1_flag_test], axis = 1)\nprint(test_feat.shape)","92b2d5d1":"attr2_flag = pd.get_dummies(train['attr_2'])\ntrain_feat = pd.concat([train_feat, attr2_flag], axis = 1)\nprint(train_feat.shape)\n\nattr2_flag_test = pd.get_dummies(test['attr_2'])\ntest_feat = pd.concat([test_feat, attr2_flag_test], axis = 1)\nprint(test_feat.shape)","75bc28c1":"attr3_flag = pd.get_dummies(train['attr_3'])\ntrain_feat = pd.concat([train_feat, attr3_flag], axis = 1)\nprint(train_feat.shape)\n\nattr3_flag_test = pd.get_dummies(test['attr_3'])\ntest_feat = pd.concat([test_feat, attr3_flag_test], axis = 1)\nprint(test_feat.shape)","3115bbdb":"train.dtypes","0373bcbc":"train_feat","0e8a829b":"test_feat","9b687d12":"features = [c for c in train_feat.columns if c not in ['open_flag', 'user_id', 'row_id', 'age_class', 'domain_type', 'day_of_month']]\nlen(features)","255303eb":"!pip install impyute","27be83c0":"print(list(train_feat[features].columns).index('age'), list(test_feat[features].columns).index('age'))","4bbcf9d7":"from impyute.imputation.cs import mice\n\ntrain_imputed = mice(train_feat[features].values)\nmice_ages = train_imputed[:, list(train_feat[features].columns).index('age')]\ntrain_feat['age'] = mice_ages\n\ntest_imputed = mice(test_feat[features].values)\nmice_ages_test = test_imputed[:, list(test_feat[features].columns).index('age')]\ntest_feat['age'] = mice_ages_test","e12e98cb":"train['age'].describe()","f8643aed":"train_feat['age'].describe()","a1bae8e7":"test['age'].describe()","e4022eeb":"test_feat['age'].describe()","a2ddd9db":"train['20_interval'] = train['open_count_last_30_days'] - train['open_count_last_10_days']\ntrain['30_interval'] = train['open_count_last_60_days'] - train['open_count_last_30_days']\ntrain['50_interval'] = train['open_count_last_60_days'] - train['open_count_last_10_days']\n\ntest['20_interval'] = test['open_count_last_30_days'] - test['open_count_last_10_days']\ntest['30_interval'] = test['open_count_last_60_days'] - test['open_count_last_30_days']\ntest['50_interval'] = test['open_count_last_60_days'] - test['open_count_last_10_days']","afd5f14c":"train['age'] = train_feat['age']\ntest['age'] = test_feat['age']\n\ntrain['domain'] = train['domain'].astype('category')\ntest['domain'] = test['domain'].astype('category')\n\ntrain['country_code'] = train['country_code'].astype('category')\ntest['country_code'] = test['country_code'].astype('category')\n\ntrain['day_of_week'] = train['day_of_week'].astype('category')\ntest['day_of_week'] = test['day_of_week'].astype('category')\n\ntrain['attr_1'] = train['attr_1'].astype('category')\ntest['attr_1'] = test['attr_1'].astype('category')\n\ntrain['attr_2'] = train['attr_2'].astype('category')\ntest['attr_2'] = test['attr_2'].astype('category')\n\ntrain['attr_3'] = train['attr_3'].astype('category')\ntest['attr_3'] = test['attr_3'].astype('category')\n\ntrain['never_open'] = train['never_open'].astype('category')\ntest['never_open'] = test['never_open'].astype('category')\n\ntrain['never_login'] = train['never_login'].astype('category')\ntest['never_login'] = test['never_login'].astype('category')\n\ntrain['never_checkout'] = train['never_checkout'].astype('category')\ntest['never_checkout'] = test['never_checkout'].astype('category')\n\ntrain['age_class'] = train['age_class'].astype('category')\ntest['age_class'] = test['age_class'].astype('category')\n\ntrain['domain_type'] = train['domain_type'].astype('category')\ntest['domain_type'] = test['domain_type'].astype('category')","c26dee85":"train.info()","1ce998dc":"train.describe()","97bc54ea":"train.to_csv('train_feat.csv', index = False)\ntest.to_csv('test_feat.csv', index = False)","6fa97b07":"# train_feat = pd.read_csv('..\/input\/shopee-code-league-2020-marketing-analytics\/train_feat.csv')\n# test_feat = pd.read_csv('..\/input\/shopee-code-league-2020-marketing-analytics\/test_feat.csv')\n# print(train_feat.shape, test_feat.shape)","7edac286":"# label = train_feat['open_flag']","b3d49785":"# samp_sub = pd.read_csv('..\/input\/open-shopee-code-league-marketing-analytics\/sample_submission_0_1.csv')\n# print(samp_sub.shape)","10e0a5c5":"train_feat_copy = train.copy()\ntest_feat_copy = test.copy()","d8f790f5":"features = [c for c in train.columns if c not in ['open_flag', 'user_id', 'row_id']]\nfeat_label = [c for c in train.columns if c not in ['user_id', 'row_id']]\nlabel = train['open_flag']","f149aff6":"import h2o\nh2o.init()","8aca499f":"X = features\nY = 'open_flag'\n\n\nlist_col = X + [Y]","77f36dff":"from sklearn.model_selection import train_test_split\ntrain_data, val_data = train_test_split(train[feat_label], stratify=train['open_flag'], test_size = 0.2, random_state=1111)","13d79c6a":"h2o_train = h2o.H2OFrame(train_data[list_col])\nh2o_val = h2o.H2OFrame(val_data[list_col])\nh2o_test = h2o.H2OFrame(test[X])","d8ba8f23":"X_cat = ['country_code', 'domain', 'day_of_week', 'attr_1', 'attr_2', 'attr_3',\n         'never_open', 'never_login', 'never_checkout', 'age_class', 'domain_type']\n\nfor var in X_cat :\n    h2o_train[var] = h2o_train[var].asfactor()\n    h2o_val[var] = h2o_val[var].asfactor()\n    h2o_test[var] = h2o_test[var].asfactor()\n    \nh2o_train[Y] = h2o_train[Y].asfactor()\nh2o_val[Y] = h2o_val[Y].asfactor()","d2db6f0e":"from h2o.estimators.gbm import H2OGradientBoostingEstimator\nfrom h2o.estimators.random_forest import H2ORandomForestEstimator\nfrom h2o.estimators.glm import H2OGeneralizedLinearEstimator\nfrom h2o.estimators import H2OXGBoostEstimator\nfrom h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\nimport time\n\ndef h2o_compare_models(df_train, df_test, X, Y) :\n    \n    start = time.time()\n    \n    # Initialize all model \n    glm = H2OGeneralizedLinearEstimator(family='binomial', nfolds=10, keep_cross_validation_predictions=True, fold_assignment='Modulo')\n    gbm = H2OGradientBoostingEstimator(distribution='bernoulli', nfolds=10, keep_cross_validation_predictions=True, fold_assignment='Modulo')\n    xgb = H2OXGBoostEstimator(distribution='bernoulli', nfolds=10, keep_cross_validation_predictions=True, fold_assignment='Modulo')\n    lgbm = H2OXGBoostEstimator(distribution='bernoulli', tree_method=\"hist\", grow_policy=\"lossguide\",\n                              nfolds=10, keep_cross_validation_predictions=True, fold_assignment='Modulo')\n    rf = H2ORandomForestEstimator(distribution='bernoulli', nfolds=10, keep_cross_validation_predictions=True, fold_assignment='Modulo')\n    ext = H2ORandomForestEstimator(distribution='bernoulli', histogram_type=\"Random\",\n                                  nfolds=10, keep_cross_validation_predictions=True, fold_assignment='Modulo')\n    \n    # Train model\n    glm.train(x=X, y=Y, training_frame=df_train)\n    gbm.train(x=X, y=Y, training_frame=df_train)\n    xgb.train(x=X, y=Y, training_frame=df_train)\n    lgbm.train(x=X, y=Y, training_frame=df_train)\n    rf.train(x=X, y=Y, training_frame=df_train)\n    ext.train(x=X, y=Y, training_frame=df_train)\n    \n    # Calculate train metrics \n    from sklearn.metrics import matthews_corrcoef\n    train_glm = matthews_corrcoef(h2o_train[Y].as_data_frame(), glm.predict(h2o_train)['predict'].as_data_frame())\n    train_gbm = matthews_corrcoef(h2o_train[Y].as_data_frame(), gbm.predict(h2o_train)['predict'].as_data_frame())\n    train_xgb = matthews_corrcoef(h2o_train[Y].as_data_frame(), xgb.predict(h2o_train)['predict'].as_data_frame())\n    train_lgbm = matthews_corrcoef(h2o_train[Y].as_data_frame(), lgbm.predict(h2o_train)['predict'].as_data_frame())\n    train_rf = matthews_corrcoef(h2o_train[Y].as_data_frame(), rf.predict(h2o_train)['predict'].as_data_frame())\n    train_ext = matthews_corrcoef(h2o_train[Y].as_data_frame(), ext.predict(h2o_train)['predict'].as_data_frame())\n\n    # Calculate CV metrics for all model \n    met_glm = matthews_corrcoef(h2o_train[Y].as_data_frame(), glm.cross_validation_holdout_predictions()['predict'].as_data_frame())\n    met_gbm = matthews_corrcoef(h2o_train[Y].as_data_frame(), gbm.cross_validation_holdout_predictions()['predict'].as_data_frame())\n    met_xgb = matthews_corrcoef(h2o_train[Y].as_data_frame(), xgb.cross_validation_holdout_predictions()['predict'].as_data_frame())\n    met_lgbm = matthews_corrcoef(h2o_train[Y].as_data_frame(), lgbm.cross_validation_holdout_predictions()['predict'].as_data_frame())\n    met_rf = matthews_corrcoef(h2o_train[Y].as_data_frame(), rf.cross_validation_holdout_predictions()['predict'].as_data_frame())\n    met_ext = matthews_corrcoef(h2o_train[Y].as_data_frame(), ext.cross_validation_holdout_predictions()['predict'].as_data_frame())\n    \n    # Calculate holdout metrics\n    from sklearn.metrics import matthews_corrcoef\n    hold_glm = matthews_corrcoef(h2o_val[Y].as_data_frame(), glm.predict(h2o_val)['predict'].as_data_frame())\n    hold_gbm = matthews_corrcoef(h2o_val[Y].as_data_frame(), gbm.predict(h2o_val)['predict'].as_data_frame())\n    hold_xgb = matthews_corrcoef(h2o_val[Y].as_data_frame(), xgb.predict(h2o_val)['predict'].as_data_frame())\n    hold_lgbm = matthews_corrcoef(h2o_val[Y].as_data_frame(), lgbm.predict(h2o_val)['predict'].as_data_frame())\n    hold_rf = matthews_corrcoef(h2o_val[Y].as_data_frame(), rf.predict(h2o_val)['predict'].as_data_frame())\n    hold_ext = matthews_corrcoef(h2o_val[Y].as_data_frame(), ext.predict(h2o_val)['predict'].as_data_frame())\n    \n    # Make result dataframe\n    result = pd.DataFrame({'Model':['GLM','GBM','XGB','LGBM','RF','ExtraTree'],\n                          'Train Metrics':[train_glm,train_gbm,train_xgb,train_lgbm,train_rf,train_ext],\n                          'CV Metrics':[met_glm,met_gbm,met_xgb,met_lgbm,met_rf,met_ext],\n                          'Holdout Metrics':[hold_glm,hold_gbm,hold_xgb,hold_lgbm,hold_rf,hold_ext]})\n    \n    end = time.time()\n    print('Time Used :',(end-start)\/60)\n    \n    return result.sort_values('Holdout Metrics')","6a7b5707":"res = h2o_compare_models(h2o_train, h2o_test, X, Y) \nres","ab5e2fe7":"from h2o.estimators.gbm import H2OGradientBoostingEstimator\nfrom h2o.estimators.random_forest import H2ORandomForestEstimator\nfrom h2o.estimators.glm import H2OGeneralizedLinearEstimator\nfrom h2o.estimators import H2OXGBoostEstimator\nfrom h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\nimport time","e588f8c1":"from h2o.estimators import H2OXGBoostEstimator\nfrom h2o.grid.grid_search import H2OGridSearch\nfrom sklearn.metrics import log_loss\n\nstart = time.time()\n\nxgb = H2OXGBoostEstimator(distribution='bernoulli', nfolds=10, keep_cross_validation_predictions=True, fold_assignment='Modulo')\n\nxgb_params = {'max_depth' : [7,9,11], # picked after max depth search\n                'sample_rate': [x\/100. for x in range(20,101)],\n                'col_sample_rate' : [x\/100. for x in range(20,101)],\n                'col_sample_rate_per_tree': [x\/100. for x in range(20,101)],\n                'min_split_improvement': [0,1e-8,1e-6,1e-4],\n              'reg_lambda':list(np.arange(0.5,1.05,0.05)),\n              'reg_alpha':list(np.arange(0.01,0.11,0.01)),\n             'learn_rate':list(np.arange(0.01,0.11,0.01)),\n             'booster':['dart','gbtree']}\n\n# Search criteria\nsearch_criteria = {'strategy': \"RandomDiscrete\",\n                   'max_runtime_secs': 3600,\n                   'max_models': 20,\n                   'seed' : 11,\n                   'stopping_rounds' : 5,\n                   'stopping_metric' : \"auc\",\n                   'stopping_tolerance': 1e-3\n                   }\n\n# Make grid model\nxgb_grid = H2OGridSearch(model=xgb,\n                          grid_id='best_xgb_cmon',\n                          hyper_params=xgb_params,\n                          search_criteria=search_criteria)\n\n# Train model\nxgb_grid.train(x=X, y=Y, training_frame=h2o_train, validation_frame=h2o_val)\n\n# Get best GLM\nxgb_res = xgb_grid.get_grid(sort_by='auc', decreasing=True)\nbest_xgb = xgb_res.models[0]","25f41976":"from sklearn.metrics import matthews_corrcoef\ntrain_xgb = matthews_corrcoef(h2o_train[Y].as_data_frame(), best_xgb.predict(h2o_train)['predict'].as_data_frame())\nmet_xgb = matthews_corrcoef(h2o_train[Y].as_data_frame(), best_xgb.cross_validation_holdout_predictions()['predict'].as_data_frame())\nhold_xgb = matthews_corrcoef(h2o_val[Y].as_data_frame(), best_xgb.predict(h2o_val)['predict'].as_data_frame())\n\n# Print result\nprint('Train metrics :',train_xgb)\nprint('CV metrics :',met_xgb)\nprint('Holdout metrics :',hold_xgb)\n\nend = time.time()\nprint('Time Used :',(end-start)\/60)","7a5476c8":"pred = best_xgb.predict(h2o_test)['predict'].as_data_frame()\nsub = pd.read_csv('..\/input\/open-shopee-code-league-marketing-analytics\/sample_submission_0_1.csv')\nsub['open_flag'] = pred\n\nsub.to_csv('submission_xgb.csv', index=False)","38fb9ad2":"sub['open_flag'].value_counts()","53614b34":"# Tune Model - LGBM - RandomGridSearch\nfrom h2o.estimators import H2OXGBoostEstimator\nfrom h2o.grid.grid_search import H2OGridSearch\nfrom sklearn.metrics import log_loss\n\nstart = time.time()\n\nlgbm = H2OXGBoostEstimator(distribution='bernoulli', tree_method=\"hist\", grow_policy=\"lossguide\",\n                           nfolds=10, keep_cross_validation_predictions=True, fold_assignment='Modulo',\n                           ntrees=100, seed=11, score_tree_interval = 10,\n                           stopping_rounds = 5, stopping_metric = \"AUC\", stopping_tolerance = 1e-4)\n\n# LGBM Params\nlgbm_params = {'max_depth' : [7,9,11],  # picked after max depth search\n                'sample_rate': [x\/100. for x in range(20,101)],\n                'col_sample_rate' : [x\/100. for x in range(20,101)],\n                'col_sample_rate_per_tree': [x\/100. for x in range(20,101)],\n                'min_split_improvement': [0,1e-8,1e-6,1e-4],\n              'reg_lambda':list(np.arange(0.5,1.05,0.05)),\n              'reg_alpha':list(np.arange(0.01,0.11,0.01)),\n             'learn_rate':list(np.arange(0.01,0.11,0.01)),\n             'booster':['dart','gbtree']}\n\n# Search criteria\nsearch_criteria = {'strategy': \"RandomDiscrete\",\n                   'max_runtime_secs': 3600,  # limit the runtime to 60 minutes\n                   'max_models': 20,  # build no more than 100 models\n                   'seed' : 11,\n                   'stopping_rounds' : 5,\n                   'stopping_metric' : \"auc\",\n                   'stopping_tolerance': 1e-3\n                   }\n\n# Make grid model\nlgbm_grid = H2OGridSearch(model=lgbm,\n                          grid_id='best_lgbm_cmon',\n                          hyper_params=lgbm_params,\n                          search_criteria=search_criteria)\n\n# Train model\nlgbm_grid.train(x=X, y=Y, training_frame=h2o_train, validation_frame=h2o_val)\n\n# Get best GLM\nlgbm_res = lgbm_grid.get_grid(sort_by='auc', decreasing=True)\nbest_lgbm = lgbm_res.models[0]","c50e46fa":"from sklearn.metrics import matthews_corrcoef\ntrain_lgbm = matthews_corrcoef(h2o_train[Y].as_data_frame(), best_lgbm.predict(h2o_train)['predict'].as_data_frame())\nmet_lgbm = matthews_corrcoef(h2o_train[Y].as_data_frame(), best_lgbm.cross_validation_holdout_predictions()['predict'].as_data_frame())\nhold_lgbm = matthews_corrcoef(h2o_val[Y].as_data_frame(), best_lgbm.predict(h2o_val)['predict'].as_data_frame())\n\n# Print result\nprint('Train metrics :',train_lgbm)\nprint('CV metrics :',met_lgbm)\nprint('Holdout metrics :',hold_lgbm)\n\nend = time.time()\nprint('Time Used :',(end-start)\/60)","46099f29":"pred = best_lgbm.predict(h2o_test)['predict'].as_data_frame()\nsub = pd.read_csv('..\/input\/open-shopee-code-league-marketing-analytics\/sample_submission_0_1.csv')\nsub['open_flag'] = pred\n\nsub.to_csv('submission_lgbm.csv', index=False)","bc06b86b":"sub['open_flag'].value_counts()","cd08553a":"**Age > 110** (supercentenarian) ? Let's set it to **NA**.","8a19033c":"One Hot Encoding: 'domain' column","a255ec92":"Let's add **new features** from what we know about: 'last_open_day', 'last_login_day', 'last_checkout_day'","cc335e47":"# EDA Part 2","c0631e23":"Last Login Day","950a1433":"Distribution Comparison","25fe2498":"One Hot Encoding: Day of Week","43730fcf":"Last Open Day","d9778a72":"Train and test **differ** in the range of date. \n\nThus, we could just extract the **day of week** from the 'grass_date' column, \n\nmake a **new column** 'day of week', then drop the 'grass_date' column from our features later.","6e9404dd":"**New feature: 'age_class'**","f4dd93a4":"One Hot Encoding: 'country_code' column","8f155998":"# Import data","15ff724f":"Last Checkout Day","e6f39e55":"Let's check the types again","3f8c640a":"**New features: 'day_of_week', 'day_of_month'**","8f6cc7ee":"Checking distribution","e02ab59f":"Last minute additional features","e74cfd3f":"Open Count Last 10 days","e00748d0":"Since columns **'country_code', 'attr_1\/2\/3', 'day_of_week'** are categorical, \n\nlet's change their type to string for convenience in later analysis","e36167d5":"Domain","92b8792a":"Also, since **'grass_date'** column consists of dates, let's change its type to **datetime**","0982f5a7":"**Age < 0** ? Let's set it to **NA** too.","334a1f68":"Best submission: submission_xgb.csv\n\nSecond best:     submission_lgbm.csv\n\n[Link to kernel](https:\/\/www.kaggle.com\/rareloto\/matrix-marketing-analytics-xgboost)","2ffde60b":"Last minute imputation on 'age' column","02a90d4e":"Save to file: train and test features","1ff8dad0":"# Modeling","22d08870":"One Hot Encoding: Never open, login, checkout","c647ded9":"# Import preprocessed train and test features","03c396c3":"# Extract features","b7192a99":"**Compare visualizations of open_flag == 0 df and open_flag == 1 to understand the patterns**","3a431aab":"# EDA","e7451b1d":"Subject Line Length","bd99423d":"**Features and label**","464d0a7a":"User Attributes","c1e15ae3":"Let's see what we have so far","b7dc88d4":"**Clean data**","fab9fa18":"**Merge users df to train df and test df**","bded9288":"Grass Date","a3b64e3e":"**XGB**","9ef334a5":"**Convert to numerical:**\n\nlast_open_day, last_login_day, last_checkout_day","3cfc501e":"**LGBM**","472b7585":"**New feature: 'domain_type'**","92140976":"Check this [public kernel](https:\/\/www.kaggle.com\/marcellosusanto\/shopee-ma-eda) for better visualizations and additional insights on 'age_class' and 'domain_type'.","e1be3121":"Age","b862af7c":"The implementation was copied over from this [public kernel](https:\/\/www.kaggle.com\/marcellosusanto\/shopee-ma-eda)","9f297f77":"Grass Date","0be9742c":"Dividing the 'age' column into some **age ranges** may get better performance\n\n*I'll try that later*","c28e8680":"**Convert non-numerical features to numerical features for modeling**","6200f36e":"Country Code","4865efad":"\"As of January 9, 2020, there were **31 living supercentenarians** on our list (30 females, 1 male)\"\n*Source: liebertpub.com*\n\nAs of 3 August 2020, the oldest known living person is Kane Tanaka of Japan, aged **117** years, 214 days.","4c29048a":"One Hot Encoding: attr_1\/2\/3"}}