{"cell_type":{"38613be4":"code","6e448d79":"code","db7cf8ae":"code","d72fbb43":"code","6cf6359f":"code","9693d824":"code","d0688d1a":"code","28dc2a39":"code","9195275b":"code","90d31070":"code","40f730e8":"code","2e759f36":"code","387f607b":"code","079bf4aa":"code","01015034":"code","66d7982a":"code","5b511a72":"code","2773c30c":"code","244766ef":"code","c9f55e76":"code","54908c6d":"code","fdd5b0a7":"code","de200c2b":"code","81fe0594":"code","5c805af9":"code","d8afe657":"code","464d8eef":"code","625d76dc":"markdown","5f1302d0":"markdown","26d36c4c":"markdown","1262414a":"markdown","1cd53a37":"markdown","697cb8a6":"markdown","5b1821a5":"markdown","fa53226e":"markdown","1606c2aa":"markdown","8622687c":"markdown","316f4ff4":"markdown","41e3b81e":"markdown","31629982":"markdown","521576a9":"markdown","3f78ec15":"markdown","9b3840d6":"markdown","71c9a6f0":"markdown","1957365d":"markdown","5ba8af16":"markdown","0011440f":"markdown","78ea5323":"markdown","10a68bd6":"markdown","d0fb8a8b":"markdown","c95f4db4":"markdown","dd225fd9":"markdown","0de2e03d":"markdown","eb1f6107":"markdown","7e70106f":"markdown","2a8e1bcd":"markdown","e7579a32":"markdown","8d5f9cb1":"markdown","4edeade7":"markdown","4e8237fa":"markdown","c59b8cbb":"markdown","b2d885b1":"markdown","9c9e799e":"markdown","ef6f76eb":"markdown","bd9ddc52":"markdown","8b4cf2d5":"markdown","a726630c":"markdown","39e942c4":"markdown","c2439c87":"markdown","e39f8125":"markdown","aac6b568":"markdown","5570a54c":"markdown","d784e622":"markdown","0314b7c8":"markdown","2031210b":"markdown","fc58ce80":"markdown","940dfd8b":"markdown","841432a6":"markdown","9654205d":"markdown"},"source":{"38613be4":"import pandas as pd\nfrom IPython.display import display\npd.set_option('display.max_rows', 76)\npd.set_option('display.max_columns', 40)\npd.set_option('display.max_colwidth', 1000)\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#plotly\n# thanks to https:\/\/www.kaggle.com\/parulpandey\/how-to-explore-the-ctds-show-data\n!pip install dexplot\n!pip install chart_studio\nimport dexplot as dxp\nimport plotly.express as px\nimport chart_studio.plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot","6e448d79":"predictions = pd.read_csv(\"..\/input\/ctds-audio-emotions\/predictions.csv\")\npredictions = predictions.drop(columns=[\"Unnamed: 0\"])","db7cf8ae":"predictions.iloc[4803:4808]","d72fbb43":"predictions.info()","6cf6359f":"predictions[~predictions[\"pred_num\"].isnull() & predictions[\"pred_label\"].isnull()].head(5)","9693d824":"data_dict = {0.0: 'angry', 1.0: 'calm', 2.0: 'disgust', 3.0: 'fearful', 4.0: 'happy', 5.0: 'neutral', 6.0: 'sad', 7.0: 'surprised'}\n\ndef pred_label(row):\n    if row in data_dict:\n        return data_dict[row]\n    return np.nan\n        \npredictions[\"pred_label\"] = predictions[\"pred_num\"].apply(pred_label)\npredictions[predictions[\"pred_label\"] == \"angry\"].sample(4)","d0688d1a":"predictions.info()","28dc2a39":"predictions[predictions[\"pred_num\"].isnull()][\"speaker\"].value_counts().nlargest(3)","9195275b":"predictions[\"pred_num_new\"] = predictions[\"pred_num\"].fillna(5.0, axis=0)\npredictions[\"pred_label_new\"] = predictions[\"pred_label\"].fillna(\"neutral\", axis=0)","90d31070":"predictions.info()","40f730e8":"predictions = predictions[(predictions[\"episode_num\"] != 46) & (predictions[\"episode_num\"] != 4)]\npredictions.info()","2e759f36":"sanyam_emotion = predictions[predictions[\"speaker\"]==\"Sanyam Bhutani\"].groupby(\"episode_num\")[\"pred_label\"].apply(lambda val: val.value_counts())\ncolor_map = {'angry': 'red', 'calm': 'cyan', 'disgust': 'pink', 'fearful': 'black', \n             'happy': 'orange', 'neutral': 'green', 'sad': 'grey', 'surprised': 'black'}\nfig = px.bar(sanyam_emotion.unstack() , color_discrete_map=color_map, title=\"Count of Predicted Emotions from Sanyam's Audio Clips\")\nfig.update_xaxes(title_text='Episode Number')\nfig.update_yaxes(title_text='Number of Predictions per Emotion')\nfig.update_layout(legend_title_text='Emotions')\nfig.update_layout(barmode='stack')\nfig.show()","387f607b":"sanyam_emotion = predictions[predictions[\"speaker\"]==\"Sanyam Bhutani\"].groupby(\"episode_num\")[\"pred_label\"].apply(lambda val: 100*val.value_counts()\/val.value_counts().sum())\nfig = px.bar(sanyam_emotion.unstack(), color_discrete_map=color_map,  title=\"Percentage of Predicted Emotions from Sanyam's Audio Clips\")\nfig.update_xaxes(title_text='Episode Number')\nfig.update_yaxes(title_text='Proportion of each Emotion')\nfig.update_layout(legend_title_text='Emotions')\nfig.update_layout(barmode='stack')\nfig.show()","079bf4aa":"emotion_percent = predictions[predictions[\"speaker\"]==\"Sanyam Bhutani\"].groupby(\"episode_num\")[\"pred_label\"].apply(lambda val: 100*val.value_counts().nlargest(1)\/val.value_counts().sum()).sort_values(ascending=False)\n\nemotion_percent.head(10)","01015034":"episodes = pd.read_csv(\"..\/input\/ctds-audio-emotions\/Episodes_cleaned.csv\")\n\n\ncolumns_to_use = [\"episode_id\",\"flavour_of_tea\",\"recording_time\", \"episode_duration\"]\nepisodes[columns_to_use].head()","66d7982a":"episodes = episodes[columns_to_use]\nepisodes[\"episode_num\"] = episodes[\"episode_id\"].str[1:].astype(int)\nepisodes = episodes.drop(columns=\"episode_id\")\npred_merged = predictions.merge(episodes, how=\"inner\", on=\"episode_num\")\npred_merged.head(5)","5b511a72":"# nlargest is 2 to avoid NaN values for \"happy\"\nhappiness_recording_time = pred_merged[pred_merged[\"speaker\"]==\"Sanyam Bhutani\"].groupby([\"episode_num\", \"recording_time\"])[\"pred_label\"].apply(lambda val: 100*val.value_counts().nlargest(2)\/val.value_counts().sum())\nhappiness_recording_time = happiness_recording_time.unstack().reset_index()\nfig = px.bar(happiness_recording_time, x=\"recording_time\", title=\"Number of Episodes per Time of Day\")\nfig.update_xaxes(title_text='Time of Day')\nfig.update_yaxes(title_text='Number of Episodes')\nfig.show()","2773c30c":"fig = px.scatter(happiness_recording_time, x=\"recording_time\", color=\"happy\",\n                 size=\"happy\", hover_data=[\"happy\"],\n                 title=\"Relationship between Time of Day and how happy the host was\")\nfig.update_xaxes(title_text='Time of Day')\nfig.update_yaxes(title_text='Episode Number')\nfig.show()","244766ef":"happiness_tea_flavour = pred_merged[pred_merged[\"speaker\"]==\"Sanyam Bhutani\"].groupby([\"episode_num\", \"flavour_of_tea\"])[\"pred_label\"].apply(lambda val: 100*val.value_counts().nlargest(2)\/val.value_counts().sum())\nhappiness_tea_flavour = happiness_tea_flavour.unstack().reset_index()\nhappiness_tea_flavour = happiness_tea_flavour[[\"episode_num\", \"flavour_of_tea\", \"happy\"]]","c9f55e76":"happiness_tea_flavour.sort_values(by=\"happy\", ascending=False).head(10)","54908c6d":"happiness_tea_flavour.sort_values(by=\"happy\").head(5)","fdd5b0a7":"fig = px.scatter(happiness_tea_flavour, x=\"flavour_of_tea\", color=\"happy\",\n                 size=\"happy\", hover_data=[\"happy\"],\n                 title=\"Relationship between flavour of tea and how happy the host was\")\nfig.update_xaxes(title_text='Tea Flavour')\nfig.update_yaxes(title_text='Episode Number')\nfig.show()","de200c2b":"happiness_tea_flavour.groupby(\"flavour_of_tea\").apply(lambda val: val[val[\"happy\"] > 75.0])[\"flavour_of_tea\"].value_counts().head(3)","81fe0594":"happiness_tea_flavour.groupby(\"flavour_of_tea\").apply(lambda val: val[val[\"happy\"] < 75.0])[\"flavour_of_tea\"].value_counts().head(3)","5c805af9":"pred_merged_sanyam = pred_merged[(pred_merged[\"speaker\"]==\"Sanyam Bhutani\")]\n\n\nfig = px.scatter(pred_merged_sanyam, x=\"episode_clip\", y=\"pred_label_new\", color=\"pred_label_new\", color_discrete_map=color_map,\n                 title=\"Emotional Journey through an Episode\", labels={\"pred_label_new\": \"Prediction Label\"},\n               animation_frame='episode_num')\nfig.update_xaxes(title_text='Episode Clips')\nfig.update_yaxes(title_text='Prediction Label')\n# https:\/\/community.plotly.com\/t\/how-to-slow-down-animation-in-plotly-express\/31309\/6\nfig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 1000\nfig.show()\n# emotion_episode_clip\n","d8afe657":"happiness_episode_duration = pred_merged[pred_merged[\"speaker\"]==\"Sanyam Bhutani\"].groupby([\"episode_num\", \"episode_duration\"]).apply(lambda val: 100*val[\"pred_label\"].value_counts().nlargest(2)\/val[\"pred_label\"].value_counts().sum())\nhappiness_episode_duration = happiness_episode_duration.unstack().reset_index()\nhappiness_episode_duration = happiness_episode_duration[[\"episode_num\", \"episode_duration\", \"happy\"]]\nfig = px.scatter(happiness_episode_duration, x=\"episode_num\",y=\"episode_duration\", color=\"happy\",\n                 size=\"episode_duration\", hover_data=[\"happy\", \"episode_duration\"],\n                 title=\"Relationship between episode duration and how happy the host was\")\nfig.update_xaxes(title_text='Episode Number')\nfig.update_yaxes(title_text='Episode Duration')\nfig.show()","464d8eef":"happiness_episode_duration.sort_values(by=[\"happy\"], ascending=False).head(5)","625d76dc":"By highest percentage of happiness","5f1302d0":"I haven't been able to figure out how to dynamically adjust the x-axis for each episode\/frame. But the above gives an idea of how Sanyam's emotions, predicted as per his audio clips, change during the episode.\n\nBecause of replacing NaNs with \"neutral\", we can see them to occur more frequently. \n\nEpisode 12 and Episode 7 were probably not Sanyam's best given how sad and angry he got.","26d36c4c":"Sanyam has the highest NaN predictions. Setting the values to \"Neutral\" might create additional bias. \n\nAlso, as I mentioned above, it's surprising to not have a prediction for so many clips. If the clip exists, there should have been a prediction. I believe, this is a result of a fault in my overall pipeline for this project.","1262414a":"The interesting part is that `pred_num` has fewer NaNs than `pred_label`. Which shouldn't be the case. If a `pred_num` exists, there should be a label.","1cd53a37":"This was evident from the plot above as well, but it seems Masala Chai doesn't lift up Sanyam's spirits much.\n\nGinger isn't far behind. So, as it turns out, Sanyam's pretty torn on Ginger by the looks of it. Maybe looking at the time of recording and the flavour of tea in the future might give a better understanding too.","697cb8a6":"## Future Work","5b1821a5":"Instead of relying on *just* the data provided, I decided to explore Sanyam's youtube videos. My broad goal, indeed, was to correlate his drinking habits to his emotions through his podcast interviews.\n\nWhile I had plans for 3 separate Kernels around this, thanks to my infinite wisdom around not planning things out, I can only manage this one. And I will be focusing on **Audio data** from CTDS' YouTube videos to predict Sanyam's and the guests' emotions throughout each episode.","fa53226e":"There are still some `NaN` values for the predictions. And it is possible I made a mistake somewhere. Hopefully, I can iterate over this.\n\nBut, more importantly, why is Sanyam sad during that part of the episode?!","1606c2aa":"For next aspects of my analysis, I will compare how Sanyam's emotions are predicted depending on different variables (not in any order) - \n\n- Flavor of tea\n- Time of recording\n- Change in emotions over an episode's length\n- Percentage of highest emotion in relation to the episode's duration\n- Percentage of highest emotion in relation to the guest","8622687c":"It's interesting to see his Tea preferences in batches. Like his streak of Herbal Tea, aand he mostly enjoyed it.","316f4ff4":"## Data Preparation","41e3b81e":"# Is tea beneficial for Sanyam's podcast?","31629982":"That's fixed, but at what cost? So much anger...","521576a9":"You can find my approach to train [here](https:\/\/github.com\/sahiljuneja\/kaggle-ctds\/blob\/master\/model_train.ipynb). It's mostly based on the same blog post.\n\nI got an accuracy of ~73%. Which isn't as accurate as I would have preferred, but as a proof-of-concept, I think it's great. And I can work on improving upon it later as well.\n\n![training_results.png](attachment:training_results.png)","3f78ec15":"# Emotional Analysis","9b3840d6":"As before, Sanyam's happiness is extremely prominent. That's really great to know, because if I end up on his podcast in a few years, I would love to have a mostly happy host. Episode 74 also shows an interesting outlier, so-to-speak. But based on the previous plot representing the value_counts, Sanyam didn't perhaps speak that much for that episode.","71c9a6f0":"## Data Cleaning\n\nFor simplicity, I am setting all NaN predictions to \"Neutral\". There are alternatives to this, like I coculd consider dropping the rows altogether, but \"Neutral\" as an emotion probably works as a good option given the context of an intervivew.","1957365d":"Sanyam's mostly happy when he's drinking Ginger Chai and Herbal Tea. But which tea flavour might be his least favorite (less than 75% happiness)?","5ba8af16":"### Happiness in relation to episode duration","0011440f":"So, most of the episodes are recorded at Night. This is understandable that Sanyam's hosts are mostly from the US, and other countries than India. And that Sanyam does seem to be a night owl.\n\nLet's also look at how happy he is per episode given the time of day. \n\n**NOTE:** I am currently only focusing on one emotion, \"happy\", for the sake of simplicity (and limited time). There are only a couple of episodes where \"happy\" is not the dominant emotion.","78ea5323":"The problem is quite clear. During generation of the above dataset, I made a check for if `pred_num` exists or not, and it disregarded the `0.0` values as well.\n\n**NOTE:** The `data_dict` used below does not have the same order as the RAVDESS one. This order is determined based on what the model I trained after re-structuring the dataset into a different format. This can be obtained at time of prediction using `learn.data.classes`.","10a68bd6":"### Time of Recording\n\nFirst, let's look at how happy Sanyam is for each episode depending on time of day. I need to modify the dataframe to account for the above categories. I will jmerge the two tables.","d0fb8a8b":"### RAVDESS\n\nTo train a model to detect emotions from audio data, I used the audio files from the [RAVDESS](https:\/\/www.kaggle.com\/uwrfkaggler\/ravdess-emotional-speech-audio) dataset.\n\nI found an extremely helpful [blog post](https:\/\/towardsdatascience.com\/detecting-emotions-from-voice-clips-f1f7cc5d4827) that utilized the same dataset to carry out model training based on what I wished to try out. The code for downloading and processing the data can be found through that blog post. But I modified and adapted it as well, [here](https:\/\/github.com\/sahiljuneja\/kaggle-ctds\/blob\/master\/utils\/modify_ravdess.py).\n\nRAVDESS has 8 emotion categories.\n\n> Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n\nWhile I hope some of them are not part of the predictions on Sanyam's episodes, the rest should be suitable for this task.\n\n\nThe Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)\" by Livingstone & Russo is licensed under CC BY-NA-SC 4.0.","c95f4db4":"I will start with looking at a general distribution of each predicted emotion for each episode's clips.","dd225fd9":"A general look at when Sanyam recorded his episodes.","0de2e03d":"# Predictions\n\n\nAfter the singificantly time consuming portions of downloading and processing the data, I finally managed to use my trained model and predict on the audio clips' spectograms.\n\nI created a new csv, `predictions.csv`, to store the predictions based on each episode's clips. [Here](https:\/\/github.com\/sahiljuneja\/kaggle-ctds\/blob\/master\/predict.ipynb) is the code for creating this csv. The code, is an effing mess.","eb1f6107":"### RAVDESS\n\nI have never worked with audio data before. I had no idea what could be done or what was the SOTA for it or anything. I scrounged github and paperswithcode.com, but... why is everything so overwhelming?!!\n\n[FastAi's book](https:\/\/github.com\/fastai\/fastbook\/blob\/master\/01_intro.ipynb) introduced me to a very interesting approach of converting audio to spectograms and using CNNs for classification. The blog post I shared earlier implemented this exact same approach in the context of emotion detection and I decided to follow that.\n\nIt's ridiculous how simple FastAi made this entire process once I had the RAVDESS data downloaded and converted into their corresponding Mel Spectograms.\n\n![image.png](attachment:image.png)\n\n\nYou can tell how happy the person must have been just from the above. I think.","7e70106f":"Episode 54, with Sylvain Gugger, he was in pure bliss.\n\nEpisode 69 didn't have any guest. It was entirely Sanyam. So, such a high percentage of clips where his emotions were predicted to be \"happy\" is understandable. \n\nEpisode 67 had multiple guests, so it's possible Sanyam spoke less (also evident from the plots above).\n\nNow, let's bring in the tea.","2a8e1bcd":"It does seem that Sanyam has a slight preference towards average sized episodes. But there isn't any concrete trend. He does seem to have gotten happier as he created more and more episodes though.","e7579a32":"Let's move on to the next session before you notice the validation loss.","8d5f9cb1":"By lowest percentage of happiness","4edeade7":"### Flavor of Tea\n\nDoes the flavor of tea influence his mood in any way?","4e8237fa":"# Conclusion (for now)","c59b8cbb":"Here are a few rows from this data.","b2d885b1":"I will remove Episodes 46 and 4 as well since I didn't have all of the corresponding data for those.","9c9e799e":"Let's look at some of the actual percentage values corresponding to the \"happy\" emotion.","ef6f76eb":"Episode 4 and 46 above are blank, and I haven't been able to figure out a simple way to be able to remove them entirely.\n\nRight away we can see that the most prominent emotion is \"happy\", which is great! I would have been genuinely surprised if it was anything else. My trained model can't be that bad, after all.\n\nSpeaking of poorly trained models, thtere is also a fair amount of anger and sadness too. Replacing the NaN values with \"neutral\" doesn't seem to have made much of an impact. So, that's a good thing for now.\n\nLet's also look at the percentage of each emotion per episode.\n","bd9ddc52":"# Model Training","8b4cf2d5":"## Possible Biases\n\nRAVDESS dataset contains neutral North-American accents. While they had an equal number of male and female [voice] actors record the data, there is still a lingering question of diversity. \n\nSanyam and his guests do cover a broader range than just \"neutral North-American\" accents. Plus, as other Kernels pointed out, the podcast, in its current form, is heavily skewed towards male guests. Also, the category of emotions used is quite basic as well. This ofcourse might bring up some biases during predictions. I haven't yet analyzed the data from that perspective. \n","a726630c":"### Change in Emotions Over an Episode's Length","39e942c4":"### CTDS\n\nI extracted audio segments from each episode's audio and the converted and saved their respective Mel Spectogram. I used the timestamps from each episode in the `Cleaned Subtitles` data folder. Episode 4's subtitles were missing, and Episode 46's complete audio wasn't available on YouTube either. So, I didn't include them. Episode 12 had the podcast introduction missing, and the timestamps were accordingly mislabeled. I corrected for that as well. \n\nI am attaching the updated E12 csv as well.\n\nI ignored the first and last audio from each episode. Mainly because those were usually the introduction and closing remarks.\n\nMy code to extract the audio clips can be found [here](https:\/\/github.com\/sahiljuneja\/kaggle-ctds\/blob\/master\/utils\/extract_audio_segments.py).\n\nQuestion for anyone who might read this - Do you notice any differences between how I processed RAVDESS audio vs the CTDS audio? The differences might actually help improve the model a little bit.","c2439c87":"Since the range of the percentage of emotions detected as \"happy\" is not that wide, it's difficult to distinguish between the sizes. But , it does seem that Sanyam is happier when recording at Night. \n\nThe question really ends up being whether Sanyam is happy because he records at Night, or he records at Night because he feels the most refreshed then on most days.","e39f8125":"I'll start by focusing on predictions on Sanyam's clips across all episodes. Just to look at a general count of which was the strongest emotion he likely exhibited.","aac6b568":"All right, with enough of the data cleaned, let's jump into some analysis.","5570a54c":"# Collecting Audio Data","d784e622":"## Overall Response","0314b7c8":"This was my attempt to challenge myself with a project that pushes me outside of my comfort zone where I piece things together to come up with an analysis. Purely as an attempt to learn more. Predicting emotions using audio was a fun way to approach this. And there's still a LOT to analyze as well. ","2031210b":"### CTDS\n\nI couldn't figure out a way to download the audio from any of the podcast sources othter than YouTube. Unfortunately, downloading and converting videos from YouTube to audio (using [youtube-dl](https:\/\/github.com\/ytdl-org\/youtube-dl)) can take quite a bit of time.\n\nI will avoid unnecessary details for now. But you can check out the code I used to download the audio [here](https:\/\/github.com\/sahiljuneja\/kaggle-ctds\/blob\/master\/utils\/download_ctds_data.py). \n\nI also had to clean `Episodes.csv` a little bit for this. Mainly to remove the episodes that start with 'M'. Code for that can be found [here](https:\/\/github.com\/sahiljuneja\/kaggle-ctds\/blob\/master\/utils\/clean_data.ipynb). I am also attaching the updated csv for this.","fc58ce80":"There is no shortage of what can be done here -\n\n- Explore more variables in relation to other predicted emotions\n- Explore emotions of Guests with the same variables\n- Incorporate transcripts for comparison with audio\n- Improve emotion detection model\n- Fix issues\n- etc.\n\nI included `predictions.csv` so that others could try things out. Downloading the audio data can be time consuming, but I could provide the spectogram images from the data if someone would like to play around with it.","940dfd8b":"# Approach: Audio Data","841432a6":"How can a single person drink this much tea?\n\nDoes Sanyam really prefer tea, or it's just to hide the fact that he might be actually fond of [whiskey](https:\/\/twitter.com\/abhi1thakur\/status\/1265660629295271943) mixed-in with tea?\n\nDoes drinking tea actually help him with his podcast?\n\nDoes he interview his guests differently depending on the tea flavor?\n\nDo his emotions change depending on what he's been drinking? \n\nLet's answer all of these questions! \n\nWell, okay, only some of them...","9654205d":"I have mostly looked at how happy Sanyam seemed to be. Let's now look at how the perceived (predicted) emotions changed as the episode progressed."}}