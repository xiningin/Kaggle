{"cell_type":{"396497c7":"code","69ffad04":"code","b0f2f639":"code","da625e2b":"code","591e411d":"code","1f211f5c":"code","2ed2d440":"code","28321e19":"code","4fc88adf":"code","03b64bba":"code","26d1699a":"code","bee938cb":"code","67204ffa":"code","8db59f53":"code","097fdc8b":"code","1ca97e42":"code","f0fbff7f":"code","58c9a90b":"code","6b9ae39b":"code","b5317983":"code","f93a4fe5":"code","b7dea00c":"code","4d0b81ca":"code","1a16d236":"code","dda63e21":"code","a0c1537d":"code","d9865001":"code","890a1041":"code","4dc13e36":"code","e2293a01":"code","e1e86f5c":"code","1da8948c":"code","617cbec9":"code","5acb8477":"code","3b79de5d":"code","64aac7a1":"code","e15c55d7":"code","11926c5e":"code","701425f3":"code","f4564efc":"code","ebaa244d":"code","920b43dd":"code","3b78b95a":"code","ed8965f1":"code","9a9404b5":"code","2ead6ebf":"code","ed4201eb":"code","96c4e606":"markdown","02119d77":"markdown","dd7ee3ce":"markdown","ccf71bec":"markdown","88daef80":"markdown","23b6be7a":"markdown","3aa0a670":"markdown","ef6c9383":"markdown","b184e5d7":"markdown","9fb9a608":"markdown","a670818f":"markdown","0da7b6ca":"markdown","59e7fed1":"markdown","7b49b4cc":"markdown","213e00f4":"markdown","5912f332":"markdown","22afc6df":"markdown","6f2a32d8":"markdown","0c973889":"markdown","b62a3e5e":"markdown","94a00348":"markdown","e5aa29f2":"markdown","808cb3df":"markdown","fe49e0c4":"markdown","426116e7":"markdown","ec63ca84":"markdown","b56a8387":"markdown","13a6a22e":"markdown","17e80020":"markdown","73fe1df3":"markdown","e710783d":"markdown","26c29ccf":"markdown","4322fcc1":"markdown","27a05428":"markdown","6ad359b5":"markdown","fa299c51":"markdown","6fc5ba3e":"markdown","8a19fcd1":"markdown","179b4ee4":"markdown","cc36c87b":"markdown","44c38763":"markdown"},"source":{"396497c7":"!pip install -q efficientnet","69ffad04":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf, tensorflow.keras.backend as K\nfrom tensorflow.keras import optimizers\nfrom kaggle_datasets import KaggleDatasets\nimport efficientnet.tfkeras as efn\nimport random\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport hashlib\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport cv2\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split,KFold,StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom tensorflow.keras.models import model_from_json, Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.layers import Convolution2D,Activation,MaxPooling2D,Flatten,Dense,Dropout,Input,Reshape,Lambda\nfrom keras.utils.vis_utils import plot_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tqdm.notebook import tqdm\nfrom PIL import Image\n\nimport warnings\nwarnings.filterwarnings('ignore')","b0f2f639":"def seed_everything(seed=13):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    os.environ['TF_KERAS'] = '1'\n    random.seed(seed)\n    \nseed_everything(42)","da625e2b":"def TPU():\n    # Detect hardware, return appropriate distribution strategy\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        tpu = None\n\n    if tpu:\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    else:\n        strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\n    print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n    return strategy\n\n\nstrategy = TPU()","591e411d":"GCS_DS_PATH = KaggleDatasets().get_gcs_path()\nAUTO = tf.data.experimental.AUTOTUNE","1f211f5c":"IMG_SIZE_h = 512 \nIMG_SIZE_w = 512\nFOLDS = 5\nSEED = 42\nEPOCHS = 50\nBATCH_SIZE = 8*strategy.num_replicas_in_sync","2ed2d440":"#Data Items\npath='..\/input\/plant-pathology-2020-fgvc7\/'\n\ntrain = pd.read_csv(path+'train.csv')\ntrain_id = train['image_id']\ntrain.pop('image_id')\n\ny_train = train.to_numpy().astype('float32')\ncategory_names = ['healthy','multiple_diseases','rust','scab']\nroot = 'images'\n\nimages_paths = [(os.path.join(GCS_DS_PATH,root,idee+'.jpg')) for idee in train_id]","28321e19":"DIR_INPUT = '\/kaggle\/input\/plant-pathology-2020-fgvc7'\ntrain_df = pd.read_csv(DIR_INPUT + '\/train.csv')\ntest_df = pd.read_csv(DIR_INPUT + '\/test.csv')\ncols = list(train_df.columns[1:])\n\ntrain_paths = train_df['image_id'].apply(lambda x: os.path.join(GCS_DS_PATH , 'images' , x + '.jpg')).values\ntest_paths = test_df['image_id'].apply(lambda x: os.path.join(GCS_DS_PATH , 'images' , x + '.jpg')).values\n\ntrain_labels = train_df.iloc[:,1:].values","4fc88adf":"(len(train_df), len(test_df))","03b64bba":"LABEL_COLS = ['healthy', 'multiple_diseases', 'rust', 'scab']\n\n_, axes = plt.subplots(ncols=4, nrows=1, constrained_layout=True, figsize=(10, 3))\nfor ax, column in zip(axes, LABEL_COLS):\n    train_df[column].value_counts().plot.bar(title=column, ax=ax)\nplt.show()","26d1699a":"plt.title('Label distribution')\ntrain_df[LABEL_COLS].idxmax(axis=1).value_counts().plot.bar()","bee938cb":"train_df.iloc[:,1:-1].sum(axis=1).value_counts()","67204ffa":"train_df[['healthy', 'multiple_diseases', 'rust', 'scab']].sum(axis=1).unique()","8db59f53":"def calculate_hash(im):\n    md5 = hashlib.md5()\n    md5.update(np.array(im).tostring())\n    \n    return md5.hexdigest()\n    \ndef get_image_meta(image_id, image_src, dataset='train'):\n    im = Image.open(image_src)\n    extrema = im.getextrema()\n\n    meta = {\n        'image_id': image_id,\n        'dataset': dataset,\n        'hash': calculate_hash(im),\n        'r_min': extrema[0][0],\n        'r_max': extrema[0][1],\n        'g_min': extrema[1][0],\n        'g_max': extrema[1][1],\n        'b_min': extrema[2][0],\n        'b_max': extrema[2][1],\n        'height': im.size[0],\n        'width': im.size[1],\n        'format': im.format,\n        'mode': im.mode\n    }\n    return meta","097fdc8b":"data = []\n\nfor i, image_id in enumerate(tqdm(train_df['image_id'].values, total=train_df.shape[0])):\n    data.append(get_image_meta(image_id, DIR_INPUT + '\/images\/{}.jpg'.format(image_id)))","1ca97e42":"for i, image_id in enumerate(tqdm(test_df['image_id'].values, total=test_df.shape[0])):\n    data.append(get_image_meta(image_id, DIR_INPUT + '\/images\/{}.jpg'.format(image_id), 'test'))","f0fbff7f":"meta_df = pd.DataFrame(data)\nmeta_df.head()","58c9a90b":"meta_df.groupby(by='dataset')[['width', 'height']].aggregate(['min', 'max'])","6b9ae39b":"duplicates = meta_df.groupby(by='hash')[['image_id']].count().reset_index()\nduplicates = duplicates[duplicates['image_id'] > 1]\nduplicates.reset_index(drop=True, inplace=True)\n\nduplicates = duplicates.merge(meta_df[['image_id', 'hash']], on='hash')\n\nduplicates.head(20)","b5317983":"fig, ax = plt.subplots(5, 2, figsize=(8, 16))\nax = ax.flatten()\n\nfor i in range(0, min(duplicates.shape[0], 10), 2):\n    image_i = cv2.imread(DIR_INPUT + '\/images\/{}.jpg'.format(duplicates.iloc[i, 2]), cv2.IMREAD_COLOR)\n    image_i = cv2.cvtColor(image_i, cv2.COLOR_BGR2RGB)\n    ax[i].set_axis_off()\n    ax[i].imshow(image_i)\n    ax[i].set_title(duplicates.iloc[i, 2])\n    \n    image_i_1 = cv2.imread(DIR_INPUT + '\/images\/{}.jpg'.format(duplicates.iloc[i + 1, 2]), cv2.IMREAD_COLOR)\n    image_i_1 = cv2.cvtColor(image_i_1, cv2.COLOR_BGR2RGB)\n    ax[i + 1].set_axis_off()\n    ax[i + 1].imshow(image_i_1)\n    ax[i + 1].set_title(duplicates.iloc[i + 1, 2])","f93a4fe5":"def show_images(image_ids):\n    \n    col = 5\n    row = min(len(image_ids) \/\/ col, 5)\n    \n    fig, ax = plt.subplots(row, col, figsize=(16, 8))\n    ax = ax.flatten()\n\n    for i, image_id in enumerate(image_ids):\n        image = cv2.imread(DIR_INPUT + '\/images\/{}.jpg'.format(image_id))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        ax[i].set_axis_off()\n        ax[i].imshow(image)\n        ax[i].set_title(image_id)","b7dea00c":"fig = go.Figure(data=[\n    go.Pie(labels=train_df.columns[1:],\n           values=train_df.iloc[:, 1:].sum().values)\n])\nfig.show()","4d0b81ca":"show_images(train_df.sample(n=15)['image_id'].values)","1a16d236":"show_images(test_df.sample(n=15)['image_id'].values)","dda63e21":"show_images(train_df[train_df['healthy'] == 1].sample(n=15)['image_id'].values)","a0c1537d":"show_images(train_df[train_df['rust'] == 1].sample(n=15)['image_id'].values)","d9865001":"show_images(train_df[train_df['scab'] == 1].sample(n=15)['image_id'].values)","890a1041":"show_images(train_df[train_df['multiple_diseases'] == 1].sample(n=15)['image_id'].values)","4dc13e36":"def prepare_train(train_paths, train_labels):\n    data = (\n        tf.data.Dataset\n        .from_tensor_slices((train_paths, train_labels))\n        .map(decode_image, num_parallel_calls=AUTO)\n        .map(data_augment, num_parallel_calls=AUTO)\n        .repeat()\n        .shuffle(512)\n        .batch(BATCH_SIZE)\n        .prefetch(AUTO)\n    )\n    return data\n\ndef prepare_val(val_paths, val_labels):\n    data = (\n        tf.data.Dataset\n        .from_tensor_slices((val_paths, val_labels))\n        .map(decode_image, num_parallel_calls=AUTO)\n        .batch(BATCH_SIZE)\n        .prefetch(AUTO)\n    )\n    return data\n\ndef prepare_test(test_paths):\n    data = (\n        tf.data.Dataset\n        .from_tensor_slices((test_paths))\n        .map(decode_image, num_parallel_calls=AUTO)\n        .batch(BATCH_SIZE)\n    )\n    return data","e2293a01":"def decode_image(filename, label=None, image_size=(IMG_SIZE_h, IMG_SIZE_w)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.resize(image, image_size)\n    \n    #convert to numpy and do some cv2 staff mb?\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\ndef data_augment(image, label=None, seed=5050):\n    image = tf.image.random_flip_left_right(image, seed=seed)\n    image = tf.image.random_flip_up_down(image, seed=seed)\n    image = tf.image.random_crop(image,size=[IMG_SIZE_h,IMG_SIZE_w,3],seed=seed )\n    image = tf.image.random_brightness(image,max_delta=0.5, seed=seed )\n           \n    if label is None:\n        return image\n    else:\n        return image, label","e1e86f5c":"def categorical_focal_loss_with_label_smoothing(gamma=2.0, alpha=0.25,ls=0.1,classes=4.0):\n    \"\"\"\n    Implementation of Focal Loss from the paper in multiclass classification\n    Formula:\n        loss = -alpha*((1-p)^gamma)*log(p)\n        y_ls = (1 - \u03b1) * y_hot + \u03b1 \/ classes\n    Parameters:\n        alpha -- the same as wighting factor in balanced cross entropy\n        gamma -- focusing parameter for modulating factor (1-p)\n        ls    -- label smoothing parameter(alpha)\n        classes     -- No. of classes\n    Default value:\n        gamma -- 2.0 as mentioned in the paper\n        alpha -- 0.25 as mentioned in the paper\n        ls    -- 0.1\n        classes     -- 4\n    \"\"\"\n    def focal_loss(y_true, y_pred):\n        # Define epsilon so that the backpropagation will not result in NaN\n        # for 0 divisor case\n        epsilon = K.epsilon()\n        # Add the epsilon to prediction value\n        #y_pred = y_pred + epsilon\n        #label smoothing\n        y_pred_ls = (1 - ls) * y_pred + ls \/ classes\n        # Clip the prediction value\n        y_pred_ls = K.clip(y_pred_ls, epsilon, 1.0-epsilon)\n        # Calculate cross entropy\n        cross_entropy = -y_true*K.log(y_pred_ls)\n        # Calculate weight that consists of  modulating factor and weighting factor\n        weight = alpha * y_true * K.pow((1-y_pred_ls), gamma)\n        # Calculate focal loss\n        loss = weight * cross_entropy\n        # Sum the losses in mini_batch\n        loss = K.sum(loss, axis=1)\n        return loss\n    \n    return focal_loss","1da8948c":"def outer_product(x):\n    #Einstein Notation  [batch,1,1,depth] x [batch,1,1,depth] -> [batch,depth,depth]\n    phi_I = tf.einsum('ijkm,ijkn->imn',x[0],x[1])\n    \n    # Reshape from [batch_size,depth,depth] to [batch_size, depth*depth]\n    phi_I = tf.reshape(phi_I,[-1,x[0].shape[3]*x[1].shape[3]])\n    \n    # Divide by feature map size [sizexsize]\n    size1 = int(x[1].shape[1])\n    size2 = int(x[1].shape[2])\n    phi_I = tf.divide(phi_I, size1*size2)\n    \n    # Take signed square root of phi_I\n    y_ssqrt = tf.multiply(tf.sign(phi_I),tf.sqrt(tf.abs(phi_I)+1e-12))\n    \n    # Apply l2 normalization\n    z_l2 = tf.nn.l2_normalize(y_ssqrt, axis=1)\n    return z_l2","617cbec9":"def f1(y_true, y_pred):\n    def recall(y_true, y_pred):\n        \"\"\"Recall metric.\n\n        Only computes a batch-wise average of recall.\n\n        Computes the recall, a metric for multi-label classification of\n        how many relevant items are selected.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives \/ (possible_positives + K.epsilon())\n        return recall\n\n    def precision(y_true, y_pred):\n        \"\"\"Precision metric.\n\n        Only computes a batch-wise average of precision.\n\n        Computes the precision, a metric for multi-label classification of\n        how many selected items are relevant.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives \/ (predicted_positives + K.epsilon())\n        return precision\n    precision = precision(y_true, y_pred)\n    recall = recall(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))","5acb8477":"def get_model():\n    \n    input_tensor = Input(shape=(IMG_SIZE_h,IMG_SIZE_w,3))\n    \n    model1 = efn.EfficientNetB3(weights='imagenet', include_top=False, input_tensor=input_tensor,input_shape=(IMG_SIZE_h, IMG_SIZE_w, 3))\n    model2 = efn.EfficientNetB3(weights='noisy-student', include_top=False, input_tensor=input_tensor,input_shape=(IMG_SIZE_h, IMG_SIZE_w, 3))\n    \n    for i, layer in enumerate(model1.layers):\n        layer._name = 'model1_' + layer.name\n\n    last_layer1 = model1.get_layer('model1_top_conv')\n    last_output1 = last_layer1.output\n\n    for i, layer in enumerate(model2.layers):\n        layer._name = 'model2_' + layer.name\n\n    last_layer2 = model2.get_layer('model2_top_conv')\n    last_output2 = last_layer2.output\n    \n    \n    model1_ = Model(inputs=model1.input, outputs=last_output1)\n    model2_ = Model(inputs=model2.input, outputs=last_output2)\n   \n    \n    model1_.compile(Adam(lr=0.0003, decay=1e-3),loss=categorical_focal_loss_with_label_smoothing(gamma=2.0, alpha=0.75, ls=0.125, classes=4.0))\n    model2_.compile(Adam(lr=0.0003, decay=1e-3),loss=categorical_focal_loss_with_label_smoothing(gamma=2.0, alpha=0.75, ls=0.125, classes=4.0))\n    \n    d1=model1_.output\n    d2=model2_.output\n\n    bilinear = Lambda(outer_product, name='outer_product1')([d1,d2])\n    \n    predictions=Dense(4, activation='softmax', name='predictions')(bilinear)\n    model = Model(inputs=model1.input, outputs=predictions)\n    \n    opt = Adam(lr=0.0003, decay=1e-3)\n    model.compile(optimizer=opt, loss=categorical_focal_loss_with_label_smoothing(gamma=2.0, alpha=0.75, ls=0.125, classes=4.0),metrics=[f1,'categorical_accuracy'])\n\n    return model","3b79de5d":"def Callbacks():\n    erl = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', \n                        restore_best_weights=True)\n    rdc = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=1, mode='min')\n    return [erl,rdc]","64aac7a1":"%%time\n\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\ntest_pred = []\nval_roc_auc = []\n\nfor i, (train_idx, val_idx) in enumerate(skf.split(train_paths, train_labels.argmax(1))):\n    print(); print('#'*25)\n    print('###      FOLD',i+1)\n    print('#'*25)\n    X_train, X_val = train_paths[train_idx], train_paths[val_idx]\n    y_train, y_val = train_labels[train_idx], train_labels[val_idx]\n    \n    strategy = TPU()\n    with strategy.scope():\n        model = get_model()\n        history = model.fit(\n                    prepare_train(X_train,y_train),\n                    steps_per_epoch=y_train.shape[0] \/\/ BATCH_SIZE,\n                    validation_data=prepare_val(X_val, y_val),\n                    validation_steps=y_val.shape[0] \/\/ BATCH_SIZE,\n                    callbacks=Callbacks(),\n                    epochs=EPOCHS,\n                    verbose=1\n                )\n\n    test_pred.append(model.predict(prepare_test(test_paths), verbose=1))\n    val_roc_auc.append(roc_auc_score(y_val,model.predict(prepare_val(X_val, y_val), verbose=1)))","e15c55d7":"model_json = model.to_json()\nwith open(\"Model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"Model.h5\")","11926c5e":"from tensorflow.keras.models import model_from_json\n\n# load json and create model\njson_file = open('Model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model.load_weights(\"Model.h5\")\n# loaded_model.summary()","701425f3":"val_roc_auc","f4564efc":"all_test = 0\nfor i in range(FOLDS):\n    all_test += test_pred[i]","ebaa244d":"#If I want to predict on particular test_pred\n\n#best_2_models = test_pred[0]*.7 + test_pred[3]*.3\n#best_2_models","920b43dd":"all_models = all_test\/FOLDS\nall_models","3b78b95a":"# best_2_models gives me better score on LB\nsumb = pd.read_csv('..\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv')\n#sumb.iloc[:,1:] = best_2_models \nsumb.iloc[:,1:] = all_models\nsumb.head()","ed8965f1":"sumb.to_csv('submission.csv', index=False)\npd.Series(np.argmax(sumb[cols].values,axis=1)).value_counts()","9a9404b5":"def preprocess(df,test=False):\n    paths = df.image_id.apply(lambda x: GCS_DS_PATH + '\/images\/' + x + '.jpg').values\n    labels = df.loc[:,'healthy':].values\n    if test==False:\n        return paths,labels\n    else:\n        return paths","2ead6ebf":"TTA = 4\n\ntest_pred_tta = np.zeros((len(test_df),4))\nfor i in range(TTA):\n    test_dataset_tta = (tf.data.Dataset\n    .from_tensor_slices(preprocess(test_df,test=True))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)    \n    .batch(BATCH_SIZE))\n    test_pred_tta += model.predict(test_dataset_tta, verbose=1)\nsumb = pd.read_csv(DIR_INPUT + '\/sample_submission.csv')\nsumb[['healthy', 'multiple_diseases', 'rust', 'scab']] = test_pred_tta\/TTA\nsumb.to_csv('submission_TTA.csv', index=False)\npd.Series(np.argmax(sumb[cols].values,axis=1)).value_counts()","ed4201eb":"sumb.head()","96c4e606":"## Target Distribution","02119d77":"* It seems like both(train and test) data frames have the same size, but how different categories contribute in the training dataset?","dd7ee3ce":"# Setup","ccf71bec":"![image](https:\/\/1.bp.blogspot.com\/-oNSfIOzO8ko\/XO3BtHnUx0I\/AAAAAAAAEKk\/rJ2tHovGkzsyZnCbwVad-Q3ZBnwQmCFsgCEwYBhgL\/s1600\/image3.png)","88daef80":"# <font color='#774633'>I very much appreciate the time you spent on reading this notebook. Please let me know if I messed up anything. Thank You! \ud83d\ude42 <\/font>","23b6be7a":"#### iii)F1 Score","3aa0a670":"![image](https:\/\/i.pinimg.com\/originals\/c9\/2f\/c9\/c92fc9abdcb11028dd0448d36c580f83.jpg)\n","ef6c9383":"## Duplications\nWe have a few duplications:\n\n* train Train_379 and Train_1173\n* test Test_683 and Test_1691\n* test Test_570 and Test_1212\n* mixed Train_1703 and Test_1407\n* mixed Train_1505 and Test_829","b184e5d7":"# Exploratory Data Analysis (EDA)","9fb9a608":"## Seeding","a670818f":"* I will resize the image later.","0da7b6ca":"# Loading Dependencies","59e7fed1":"* load input path by means of TPU","7b49b4cc":"# Training","213e00f4":"* To know what I've done in the following four cells, you might read this awesome [notebook](https:\/\/www.kaggle.com\/jimitshah777\/bilinear-efficientnet-focal-loss-label-smoothing)","5912f332":"Looks like never. So this appears to be multiclass but not multilabel classification. I copied few code fragments from this well-articulated [EDA Notebook](https:\/\/www.kaggle.com\/pestipeti\/eda-plant-pathology-2020). From where I got several insights that will unravel whether I should use k-fold or stratified k-fold cross fold and whether there are any noisy\/duplicate images or not.","22afc6df":"#### ii) BiLinear Layer (outer_product())","6f2a32d8":"## TPU Configuration","0c973889":"## Image Metadata","b62a3e5e":"# Path Delineation","94a00348":"# Preprocess for TTA","e5aa29f2":"* The image is the same. I must use Cross-Validation; otherwise, overfitting may occur.","808cb3df":"## Infected with Rust","fe49e0c4":"# Define Needed Functions","426116e7":"# Denoting My Base Model","ec63ca84":"* I'm going to use the efficient net as I said earlier. As the accuracies of base models provided by EfficientNet architecture are much better in contrast with others, I'm going to use them accordingly.","b56a8387":"Key Features :\n> * TPU as the accelerator\n* Efficient Architecture\n* EfficientNetB3 as a base model\n* Tensorflow's Data Augmentation\n* Focal Loss and Label Smoothening\n* Bilinear Layer\n* F1 Score\n* 'imagenet' and 'noisy-student' as weights\n* Stratified K-fold Cross-Validation\n* Test Time Augmentation (TTA)","13a6a22e":"# Testing and Saving Model ","17e80020":"## Random Images","73fe1df3":"# Test Time Augmentation","e710783d":"## Multiple Diseases","26c29ccf":"### from train","4322fcc1":"#### i)Focal Loss + Label Smoothing","27a05428":"### from test","6ad359b5":"## Have Scab","fa299c51":"## Image Orientations\n\nIt looks like we have both portrait and landscape modes in the train and the test set as well. The image size is always 2048x1368px (or 1365x2048).","6fc5ba3e":"## Healthy Images","8a19fcd1":"* If one wants to generate a sequence of random numbers and then be able to reproduce that same sequence of random numbers later one can set the random number seed generator with set.seed(). This is a critical aspect of reproducible research.","179b4ee4":"* As the label distribution is not the same, I must use stratified k-fold cross-validation","cc36c87b":"Let's see how many times the labels appear together.","44c38763":"* TPU expedites the ability of training speed. For more, you can have a look at this [documentation.](https:\/\/www.kaggle.com\/docs\/tpu)"}}