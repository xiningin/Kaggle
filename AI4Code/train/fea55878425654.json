{"cell_type":{"04979088":"code","d72c03cf":"code","a659d250":"code","9fe2dcde":"code","d7685a17":"code","11a8bab1":"code","e94cf94b":"code","2fffbe93":"code","beade903":"code","31c594ef":"code","d84d52d3":"code","5f4a6b05":"code","c3c94a1d":"code","61b130a3":"code","84cb355a":"code","09bccbbf":"code","e3de02ae":"code","c7eacbcd":"code","4d6036f5":"markdown"},"source":{"04979088":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom datetime import datetime\nimport calendar\nimport matplotlib.pyplot as plt\n\n# find file name\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","d72c03cf":"df=pd.read_csv('\/kaggle\/input\/market-basket-analysis\/sales_detail.csv')\n#change date to datetime and Price to int\ndf['Date']=df['Date'].astype('datetime64[ns]')\ndf['Price']=df['Price'].astype(int)","a659d250":"\ndf['Year']=df['Date'].dt.year\ndf['Month_id']=df['Date'].dt.month\ndf['Day']=df['Date'].dt.day\ndf['week']=df['Date'].dt.isocalendar().week.astype(str)\ndf['month'] = df['Month_id'].apply(lambda x: calendar.month_abbr[x])\ndf['weekday'] = df['Date'].apply(lambda time: time.dayofweek)\ndays = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\ndf['day_name']=df['weekday'].apply (lambda x : days[x])\ndf['Hour']=df['Hour'].astype(str)","9fe2dcde":"# Daily Trend Sales\nsales=df.groupby('Date')['Value'].sum().reset_index()\nsales['Average']=sales['Value'].mean()\nsales.set_index('Date').plot()\n\nplt.title('Daily Trendline Sales')","d7685a17":"# Weekdays trend Sales\nweekday=df.groupby(['weekday','day_name'])['Value'].sum().plot.bar()\nplt.title('Weedays Contribution Sales')\n#in weekend, sales decrease","11a8bab1":"# Top Category\n\ncategory=df.groupby('Type Product')['Value'].sum().sort_values(ascending=True).reset_index()\ncategory['ctr']=category['Value']\/category['Value'].sum()\ncategory.plot.barh(x='Type Product',y='ctr', figsize=(5, 15))\nplt.title('Category')","e94cf94b":"df=df.loc[df['Month_id']==9]\ntrans=df.groupby(['Date','Receiveno','Type Product','Product Name'])['Qty',\"Value\"].sum()\n\ntrans2=trans.groupby(['Date','Receiveno','Type Product','Product Name']).count()\ntrans01=trans[['Qty','Value']]\ntrans01['#sku']=1\n\ntransb=trans01.groupby(['Receiveno']).sum()\ntransb=transb[transb['Qty']<20]\ntransz=transb\n\ntransc=transb.groupby(['#sku']).count()\ntransd=transb.groupby(['Qty']).sum()","2fffbe93":"transA=trans2.groupby('Receiveno').count()\ntransA=transA[['Qty']]\ntransA.rename(columns={'Qty':'#sku'}, inplace=True)\ntransB=df.merge(transA, how='left', on ='Receiveno')\ntransB['Type Product']=transB['Type Product'].astype(str)","beade903":"transF=transB.sort_values('Receiveno')\ntransG=transB.merge(transF, how=\"left\", on = \"Receiveno\")\n","31c594ef":"# Category Apriori\n\nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules\n\ndf01=transG\nbasket2 = (df01.groupby(['Receiveno', 'Type Product_x'])['Qty_x']\n          .sum().unstack().reset_index().fillna(0)\n          .set_index('Receiveno'))\n\ndef encode_units(x):\n    if x <= 0:\n        return 0\n    if x >= 1:\n        return 1\n    \nbasket_sets = basket2.applymap(encode_units)\nfrequent_itemsets = apriori(basket_sets, min_support=0.005, use_colnames=True)\nrules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.0001)\napriori= rules.loc[ (rules['lift'] >= 1) & \n               (rules['confidence'] >= 0.01) ].sort_values('support', ascending=False).reset_index()\napriori.drop(columns='index', inplace=True)\napriori","d84d52d3":"## Top Category\n\na=frequent_itemsets.sort_values('support',ascending=True)\na.plot.barh(x='itemsets',figsize=(5, 15))\nplt.title('Contribution Category')\n","5f4a6b05":"# Combination product\n\ndfa=df01.loc[df01['#sku_y']==2]\n\ndfa1=dfa[dfa['Receiveno'].duplicated(keep=False)]\ndfa1['grouped']=dfa1.groupby('Receiveno')['Type Product_x'].transform(lambda x:','.join(x))\ndfa1=dfa1[['Receiveno','grouped']].drop_duplicates()\n","c3c94a1d":"from itertools import combinations\nfrom collections import Counter\n\ncount=Counter()\n\nfor row in dfa1['grouped']:\n    row_list=row.split(',')\n    count.update(Counter(combinations(row_list,2)))\nfor key,value in count.most_common (10):\n    print(key,value)","61b130a3":"# Combination transaction with 2 product per transaction\ndfa=df01.loc[df01['#sku_y']==2]\n\ndfa1=dfa[dfa['Receiveno'].duplicated(keep=False)]\ndfa1=dfa1.groupby(['Receiveno','Product Name_x'])['Qty_x'].sum().reset_index()\ndfa1['grouped']=dfa1.groupby('Receiveno')['Product Name_x'].transform(lambda x:','.join(x))\ndfa1=dfa1[['Receiveno','grouped']].drop_duplicates()\n","84cb355a":"from itertools import combinations\nfrom collections import Counter\n\ncount=Counter()\n\nfor row in dfa1['grouped']:\n    row_list=row.split(',')\n    count.update(Counter(combinations(row_list,2)))\nfor key,value in count.most_common (20):\n    print(key,value)","09bccbbf":"# Combination transaction with 2 product per transaction\n\ndfa=df01.loc[df01['#sku_y']==2]\n\ndfa1=dfa[dfa['Receiveno'].duplicated(keep=False)]\ndfa1=dfa1.groupby(['Receiveno','Type Product_x'])['Qty_x'].sum().reset_index()\ndfa1['grouped']=dfa1.groupby('Receiveno')['Type Product_x'].transform(lambda x:','.join(x))\ndfa1=dfa1[['Receiveno','grouped']].drop_duplicates()\n","e3de02ae":"from itertools import combinations\nfrom collections import Counter\n\ncount=Counter()\n\nfor row in dfa1['grouped']:\n    row_list=row.split(',')\n    count.update(Counter(combinations(row_list,2)))\nfor key,value in count.most_common (20):\n    print(key,value)","c7eacbcd":"df","4d6036f5":"Apriori by Category"}}