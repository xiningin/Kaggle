{"cell_type":{"6ffee140":"code","f6c0fd6d":"code","fbcae564":"code","d82ca245":"code","66647514":"code","ec2b96f1":"code","18491c6f":"code","3e95b279":"code","2f511204":"code","5634686d":"code","bf20bbf5":"code","38efb713":"code","f88b9c2b":"code","31ce1f9b":"code","07550bea":"code","fc4ad45d":"code","9807c029":"code","142c836d":"code","5d5071d3":"code","7eca07e0":"code","2ae23b3c":"code","c5190386":"code","9a30d656":"code","f15cc8d2":"code","1c02af8d":"code","8b233d58":"code","3fdb5032":"code","f8db5842":"code","9e7e823d":"code","725e33bd":"code","95db5303":"code","1a912bdf":"code","f707edd9":"code","a3caa38a":"code","8dcbdb81":"code","68731230":"code","3644776e":"code","90907d7e":"code","cb48a708":"code","b0126620":"code","860a926b":"code","f8a24c5e":"code","6aa500d9":"code","b2d6d241":"code","9ae3dd4e":"code","528c05b1":"code","bcd2ddd8":"code","ef4e5648":"code","1a2ff9b5":"code","8d66835f":"code","39c89179":"code","b58555d4":"code","369811ae":"markdown","0ab60c8b":"markdown"},"source":{"6ffee140":"import numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\nmatplotlib.rcParams['figure.figsize'] = (20.0, 10.0)","f6c0fd6d":"df = pd.read_csv('..\/input\/customer-churn-prediction-with-notebook\/Churn History Dataset.csv')","fbcae564":"df.head()","d82ca245":"df.info()","66647514":"#checking why phone number is float\ndf['phone number'] = df['phone number'].apply(lambda x: int(x.replace('-','')))\ndf['phone number']   \n","ec2b96f1":"df.dropna(inplace = True)\ndf.info()","18491c6f":"sns.countplot(df['state'])","3e95b279":"plt.subplot(1,2,1)\nsns.countplot(df['international plan'])\nplt.subplot(1,2,2)\nsns.countplot(df['voice mail plan'])","2f511204":"sns.countplot(df['Churn Indicator'])","5634686d":"len(df[df['Churn Indicator'] == ' False.'])","bf20bbf5":"#checking data balance\nl = len(df[df['Churn Indicator'] == ' True.'])\nr = len(df[df['Churn Indicator'] == ' False.'])\nprint('% of trues in data is {}'.format(round((l\/len(df))*100,2)))\nprint('% of falses in data is {}'.format(round((r\/len(df))*100,2)))","38efb713":"#plt.figure(figsize = (25,25))\n#sns.pairplot(df)","f88b9c2b":"sns.heatmap(df.corr(),annot = True, cmap = 'coolwarm')","31ce1f9b":"#dropping some feature due to correlation\ndf.drop(['phone number','total day charge','total eve charge','total intl charge',\n         'total intl minutes','total night calls','total night charge'],axis = 1,inplace =True)\nnew_df = df\ncolumns_for_test = new_df.columns","07550bea":"sns.heatmap(new_df.corr(),annot = True, cmap = 'coolwarm')","fc4ad45d":"new_df.info()","9807c029":"#seeing outliers\ni = 0\noutlier_col_list = []\nplt.subplots_adjust(hspace = 3.0)\nfor item in new_df.columns:\n    if new_df[item].dtypes != 'object':\n        outlier_col_list.append(item)\n        plt.subplot(10,2,i+1)\n        sns.boxplot(df[item])\n        plt.title(item,fontsize = 20)\n        i+=1","142c836d":"#outliers:\n#account length\n#number vmail messages(only 1 outlier )\n#total day minutes\n#total day calls (only 2 outlier)\n#total eve minutes\n#","5d5071d3":"\n#finding outliers:\n#interquartile method\ndef outlier_detect(df_col):\n    q75, q25 = np.percentile(df_col, [75 ,25])\n    iqr = q75 - q25\n    min_val = q25 - (iqr*1.5)\n    max_val = q75 + (iqr*1.5)\n    return min_val, max_val\n\ndef remove_outliers(df_col,a,b):\n    if df_col<a and df_col>b:\n        return np.nan\n    else:\n        return df_col\n\n#start removing outliers\nfrom scipy.stats.mstats import winsorize\nplt.figure(figsize=(18,6))\n\ndef outlier_treatment(new_df,target_col,pred_col='Churn Indicator'):\n    \n    l = len(new_df[new_df[pred_col] == ' True.'][target_col])\n    r = len(new_df[new_df[pred_col] == ' False.'][target_col])\n\n    print('before removing outliers % of trues in data is {}'.format(round((l\/len(df))*100,2)))\n    print('before removing outliers % of falses in data is {}'.format(round((r\/len(df))*100,2)))\n\n    a,b = outlier_detect(df[target_col])\n\n    df[target_col] = df[(df[target_col] >= a) & (df[target_col] <= b) ][target_col]\n\n    l = len(new_df[new_df[pred_col] == ' True.'][target_col].dropna())\n    r = len(new_df[new_df[pred_col] == ' False.'][target_col].dropna())\n    print('-------------------------------------------------------------------------------')\n    print('after removing outliers % of trues in data is {}'.format(round((l\/(l+r))*100,2)))\n    print('after removing outliers % of falses in data is {}'.format(round((r\/(l+r))*100,2)))\n\n    plt.subplot(1,2,1)\n    original_data_column = new_df[target_col]\n    plt.boxplot(new_df[target_col])\n    plt.title(\"original_data_column\")\n\n    plt.subplot(1,2,2)\n    plt.boxplot(new_df[target_col].dropna())                           \n    plt.title(\"removed_outliers\")\n\n    plt.show()","7eca07e0":"\nfor item in outlier_col_list:\n    outlier_treatment(new_df,item)","2ae23b3c":"i = 0\nplt.subplots_adjust(hspace = 3.0)\nfor item in new_df.columns:\n    if new_df[item].dtypes != 'object':\n        plt.subplot(9,2,i+1)\n        sns.boxplot(df[item])\n        plt.title(item,fontsize = 20)\n        i+=1","c5190386":"#checking data balance\nl = len(new_df[new_df['Churn Indicator'] == ' True.'])\nr = len(new_df[new_df['Churn Indicator'] == ' False.'])\nprint('% of trues in data is {}'.format(round((l\/len(df))*100,2)))\nprint('% of falses in data is {}'.format(round((r\/len(df))*100,2)))","9a30d656":"new_df.info()","f15cc8d2":"for item in new_df.columns:\n    if new_df[item].dtypes != 'object':\n        new_df.fillna(new_df[item].mean(),inplace = True)","1c02af8d":"df = new_df","8b233d58":"s = df.dtypes == 'object'\nobject_cols = s[s].index\nprint(object_cols)","3fdb5032":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nfor cols in object_cols:\n    df[cols] = encoder.fit_transform(df[cols])\ndf = df.astype(float)","f8db5842":"from sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\ny = df['Churn Indicator']\ndf.drop('Churn Indicator',axis =1, inplace =True)\ncolumns_to_be_keep = (df.columns)\nprint(df.columns)\nros = RandomOverSampler()\ndf = scaler.fit_transform(df)\nnew_X_train,new_y = ros.fit_sample(df,y)\n\nX_train,X_val,y_train,y_val = train_test_split(new_X_train,new_y,test_size = 0.3,random_state = 42)","9e7e823d":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix\n\nn = 100\nn_list_train = []\nn_list_val = []\nrange = [100,200,300,400,500,600,700,800,900,1000]\nfor i in [100,200,300,400,500,600,700,800,900,1000]:\n    model = RandomForestClassifier(n_estimators = i)\n    model.fit(X_train,y_train)\n    pred = model.predict(X_val)\n    val_score = accuracy_score(y_val,pred)\n    n_list_val.append(val_score)\n    pred_x = model.predict(X_train)\n    train_score = accuracy_score(y_train,pred_x)\n    n_list_train.append(train_score)\n\n","725e33bd":"plt.figure(figsize = (15,5))\nplt.plot([100,200,300,400,500,600,700,800,900,1000],n_list_train,label = 'train accuracy',marker = 'o')\nplt.plot([100,200,300,400,500,600,700,800,900,1000],n_list_val,label = 'validation accuracy',marker = 'o')\nplt.xlabel('n_estimators')\nplt.ylabel('accuracy')\nplt.legend()\nplt.title('Random Forest Classifier')\nplt.show()","95db5303":"model = RandomForestClassifier(n_estimators = 200)\nmodel.fit(X_train,y_train)\npred = model.predict(X_val)\nprint(confusion_matrix(y_val,pred))","1a912bdf":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split,cross_val_score,KFold,RandomizedSearchCV\nfrom sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\nfrom sklearn.metrics import r2_score","f707edd9":"def fit_model(model,X_train, y_train, X_val, y_val, cross_val=False, cv_folds=5):\n    \n    model.fit(X_train,y_train)\n    #Predict values:\n    training_predictions = model.predict(X_train)\n    validation_predictions = model.predict(X_val)\n    model_report(X_train,y_train, X_val,y_val, training_predictions, validation_predictions)\n\n    if cross_val:\n        evaluate_cross_validation(model, X_train, y_train, cv_folds)\n        \ndef model_report(X_train,y_train, X_val,y_val, training_predictions, validation_predictions):\n    #Print model report:\n    print(\"\\nModel Report\")\n    print(\"Training\")\n    print(\"accuracy score : {}\".format(accuracy_score(y_train, training_predictions)))\n    #print(\"Root Mean Squared Error : {}\".format(np.sqrt(mean_squared_error(y_train, training_predictions))))\n    #print(\"R2 Score: {}\".format(r2_score(y_train, training_predictions)))\n    print(\"\\n\")\n    print(\"Validation\")\n    print(\"accuracy score  : {}\".format(accuracy_score(y_val, validation_predictions)))\n    #print(\"Root Mean Squared Error : {}\".format(np.sqrt(mean_squared_error(y_val, validation_predictions))))\n    #print(\"R2 Score: {}\".format(r2_score(y_val, validation_predictions)))\n    \ndef evaluate_cross_validation(model, X_train, y_train, K):\n    \n    cv = KFold(n_splits=K, shuffle=True, random_state=2)\n    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring = 'accuracy')\n    print()\n    print(scores)\n    print(\"Mean score: {} max is {} and min {}\".format(scores.mean(), max(scores), min(scores)))   \n    \ndef random_search(model, param_grid, X_train, y_train, X_val, y_val, cv):\n    \n    random_search = RandomizedSearchCV(model, param_grid, scoring=\"accuracy\", n_jobs=2, cv=cv)\n    random_result = random_search.fit(X_train, y_train)\n\n    # summarize results\n    print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n    means = random_result.cv_results_['mean_test_score']\n    stds = random_result.cv_results_['std_test_score']\n    params = random_result.cv_results_['params']\n    for mean, stdev, param in zip(means, stds, params):\n        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n\n    validation_predictions = random_result.predict(X_val)\n\n    print(\"Validation\")\n    print(\"accuracy score : {}\".format(accuracy_score(y_val, validation_predictions)))\n    #print(\"Root Mean Squared Error : {}\".format(np.sqrt(mean_squared_error(y_val, validation_predictions))))\n    #print(\"R2 Score: {}\".format(r2_score(y_val, validation_predictions)))","a3caa38a":"model = RandomForestClassifier(n_estimators = 400)\nfit_model(model,X_train,y_train,X_val,y_val,cross_val=True)","8dcbdb81":"df_test = pd.read_csv('..\/input\/customer-churn-prediction-with-notebook\/Churn Test Dataset.csv')\n#columns_to_be_keep.append('Churn Indicator')\ndf_test = df_test[columns_for_test]","68731230":"s = df_test.dtypes == 'object'\nobject_cols = s[s].index\nfor col in object_cols:\n    df_test[col] = encoder.fit_transform(df_test[col])\ny_test = df_test['Churn Indicator']\ndf_test.drop('Churn Indicator',axis = 1,inplace = True)\ndf_test.astype(float)\ndf_test = scaler.transform(df_test)\n\npred = model.predict(df_test)\nscore = accuracy_score(y_test.astype(float),pred)\nprint(score)\nprint(confusion_matrix(y_test, pred))","3644776e":"columns = columns_to_be_keep\n\nimportances = model.feature_importances_\nweights = pd.Series(importances,\n                 index=columns)\nweights.sort_values()[:].plot(kind = 'barh')","90907d7e":"#decsion tree\n\n#model=DecisionTreeClassifier(random_state=n)\nn_list_train = []\nn_list_val = []\n\nfor i in [5,10,15,20,25]:\n    tree_model=DecisionTreeClassifier(random_state=i)\n    tree_model.fit(X_train,y_train)\n    pred = tree_model.predict(X_val)\n    val_score = accuracy_score(y_val,pred)\n    n_list_val.append(val_score)\n    pred_x = tree_model.predict(X_train)\n    train_score = accuracy_score(y_train,pred_x)\n    n_list_train.append(train_score)\n","cb48a708":"plt.figure(figsize = (15,5))\nplt.plot([5,10,15,20,25],n_list_train,label = 'train accuracy',marker = 'o')\nplt.plot([5,10,15,20,25],n_list_val,label = 'validation accuracy',marker = 'o')\nplt.xlabel('n_estimators')\nplt.ylabel('accuracy')\nplt.legend(loc='upper right')\nplt.title('Random Forest Classifier')\nplt.show()","b0126620":"tree_model=DecisionTreeClassifier(random_state=20)\nfit_model(tree_model,X_train,y_train,X_val,y_val,cross_val=True)","860a926b":"columns = columns_to_be_keep\nimportances = tree_model.feature_importances_\nweights = pd.Series(importances,\n                 index=columns)\nweights.sort_values()[-10:].plot(kind = 'barh')","f8a24c5e":"'''max_depth = [5, 10, 15, 20]\nmax_features = ['log2', 'sqrt', 'auto']\nmin_samples_leaf = [10, 50, 70, 100]\nparam_grid = dict(max_depth=max_depth, max_features=max_features, \n                  min_samples_leaf=min_samples_leaf)\nkfold = KFold(n_splits=5, shuffle=True, random_state=2)\n\nrandom_search(DecisionTreeRegressor(random_state=15), param_grid, X_train, y_train, X_val, y_val, kfold)'''","6aa500d9":"from sklearn.linear_model import LogisticRegression\n","b2d6d241":"#decsion tree\n\n#model=DecisionTreeClassifier(random_state=n)\nn_list_train = []\nn_list_val = []\n\nfor i in [0.0001,0.001,0.01]:\n    log_model=LogisticRegression(C = i)\n    log_model.fit(X_train,y_train)\n    pred = log_model.predict(X_val)\n    val_score = accuracy_score(y_val,pred)\n    n_list_val.append(val_score)\n    pred_x = log_model.predict(X_train)\n    train_score = accuracy_score(y_train,pred_x)\n    n_list_train.append(train_score)","9ae3dd4e":"plt.figure(figsize = (15,5))\nplt.plot([0.0001,0.001,0.01],n_list_train,label = 'train accuracy',marker = 'o')\nplt.plot([0.0001,0.001,0.01],n_list_val,label = 'validation accuracy',marker = 'o')\nplt.xlabel('C')\nplt.ylabel('accuracy')\nplt.legend(loc='upper right')\nplt.title('Logistic Regression')\nplt.show()","528c05b1":"model_log = LogisticRegression(C = 0.001)\nmodel_log.fit(X_train,y_train)\npred_train = model_log.predict(X_train)\npred_val = model_log.predict(X_val)\nval_score = accuracy_score(y_val,pred_val)\ntrain_score = accuracy_score(y_train,pred_train)\nprint('train score is {}'.format(train_score))\nprint('validation score is {}'.format(val_score))\nprint('confusion matrix is \\n {}'.format(confusion_matrix(y_val,pred_val)))","bcd2ddd8":"df_test = pd.read_csv('..\/input\/customer-churn-prediction-with-notebook\/Churn Test Dataset.csv')\ndf_test = df_test[columns_for_test]\ndf_test.head()","ef4e5648":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","1a2ff9b5":"s = df_test.dtypes == 'object'\nobject_cols = s[s].index\nfor col in object_cols:\n    df_test[col] = encoder.fit_transform(df_test[col])\ny_test = df_test['Churn Indicator']\ndf_test.drop('Churn Indicator',axis = 1,inplace = True)\ndf_test.astype(float)\ndf_test = scaler.fit_transform(df_test)","8d66835f":"pred = model.predict(df_test)\nscore = accuracy_score(y_test.astype(float),pred)\nprint(score)\nprint(confusion_matrix(y_test, pred))","39c89179":"pred = tree_model.predict(df_test)\nscore = accuracy_score(y_test.astype(float),pred)\nprint(score)\nprint(confusion_matrix(y_test, pred))","b58555d4":"\npred = model_log.predict(df_test)\nscore = accuracy_score(y_test.astype(float),pred)\nprint(score)\nprint(confusion_matrix(y_test, pred))","369811ae":"> best model Random forest with validation accuracy-approx. 96% better choice for a balanced accuracy \n> if target is to only decrease FNR than Logistic regression will be better option ","0ab60c8b":"# Customer churn Modelling\n- This notebook if you are reading than you're familiar with kaggle and datascience so not much explanation is there but     the code will be self-explanatory for you.\n- This notebook is to give idea how to start a notebook when machine learning comes into picture.\n- I highly recommend first try it with by yourself than see these codes if some problem persists or simply to know what       your fellow data aspirant had done it may possible you would be doing better ;).\n- If you feel good by scrolling it or you find any thing whether good or bad just comment it and you can upvote it also       \"sakht launde ho to kr dena upvote\".\n\n# You will definitely like this outlier remover function:)\n\n# All the Best"}}