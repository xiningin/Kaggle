{"cell_type":{"649098e8":"code","addad990":"code","ccd45c34":"code","d0607a3d":"code","0c8022e4":"code","d46e0e8b":"code","44df31a7":"code","a3229d3a":"code","449b54fb":"code","6201f659":"code","9c93e8ca":"code","4fd81dea":"code","d75b1125":"code","9c1fe1e9":"code","823f3606":"code","2cd4609a":"code","d8add763":"code","ce6aa9f0":"code","1d09e15c":"code","e62cf769":"code","b975250b":"code","e5fb2fe8":"code","13ab9fce":"code","cf0c19d2":"code","e7bbe2ee":"code","3338b52e":"code","356e795f":"code","1668dc27":"code","a65caa30":"code","643b03be":"code","68127006":"code","bddecd07":"code","fbf17577":"code","222207f8":"code","a50c22d3":"code","a95ed145":"markdown","05291113":"markdown","135f594b":"markdown","7f8f3874":"markdown","8ff2b173":"markdown","1d96ea06":"markdown","4a8ecdc1":"markdown","b8bf937f":"markdown","67d967e8":"markdown","e24fc720":"markdown","8f7b581b":"markdown","a595cd7b":"markdown","f26b9456":"markdown","34617e81":"markdown","a5aff0c8":"markdown","eb47224e":"markdown","28f929b7":"markdown","daf3485c":"markdown","6fa9fc6e":"markdown","28e76cf2":"markdown","05411f15":"markdown","b7efdff2":"markdown","6a8479ee":"markdown"},"source":{"649098e8":"#import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport datetime as dt\nimport plotly.express as px\nimport plotly.graph_objects as go\n%matplotlib inline\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom yellowbrick.cluster import KElbowVisualizer\n\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 50)","addad990":"df =pd.read_csv('..\/input\/customer-personality-analysis\/marketing_campaign.csv', sep = '\\t')\ndf.head()","ccd45c34":"def examine_data(data, data_name='data'):\n    print(f\"Examing '{data_name}'\")\n    display(df.shape)\n    display(df.columns)\n    display(df.info())\n    display(df.nunique())\n    display(df.describe().transpose())\n    \nexamine_data(df, data_name= 'MARKETING DATA')\n\n# duplicate values\nduplicate= df.duplicated().sum()\nif duplicate == 0:\n    print('No duplicate in the dataset')\nelse:\n    print(f'{duplicate}Duplicate')\n    \n# missing values\nmissing= pd.DataFrame(round(df.isna().sum()))\nif missing[0].sum() > 0:\n        missing.plot(kind='bar')\n        plt.title('Missing values')\n        plt.grid()\nelse:\n    print(f'There are no missing values in \"{data_name}\".') ","d0607a3d":"# correlation between feature column\ndf.corr()\nplt.figure(figsize=(20,15))\nsns.heatmap(df.corr(), annot= True);","0c8022e4":"# 'Z_CostContact', 'Z_Revenue', have the same values in all its column, we will drop columns like this that do not contribute to the model\ndf.drop(['Z_CostContact', 'Z_Revenue'], axis=1, inplace=True)","d46e0e8b":"# Income column is not symmetric, it is skewed, so we cant fill with mean, lets just drop it \nsns.distplot(df['Income']);","44df31a7":"# drop na\ndf.dropna(inplace=True)","a3229d3a":"# customer year of erollment with the company\ndf['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'])\n\n# created a new column '2021' to get number of year customers have been patronising\ndf['2021'] ='2021-01-01'\ndf['2021'] = pd.to_datetime(df['2021'])\ndf['Customers_engagement'] = (df['2021'].dt.year) - (df['Dt_Customer'].dt.year)  \n\n# age of customers today\ndf['Age'] = 2021 - df['Year_Birth']\n\n# total number of kids\ndf['Kids'] = df['Kidhome'] + df['Teenhome']\n     \n# total product purchased\ndf['Total_expense'] = df['MntWines'] + df['MntFruits'] + df['MntMeatProducts'] + df['MntFishProducts']\n+ df['MntSweetProducts']  + df['MntGoldProds']\n\n# total accepted campaign\ndf['TotalAcceptedCmp'] = df['AcceptedCmp3'] + df['AcceptedCmp1'] + df['AcceptedCmp2'] + df['AcceptedCmp4'] \n+ df['AcceptedCmp5']\n\n# total method of purchase\ndf['TotalNumOfPurchase'] = df['NumWebPurchases'] + df['NumCatalogPurchases'] + df['NumStorePurchases']\n+ df['NumDealsPurchases']\n\n# delete some redundant columns to reduce complexity of model\ndf.drop(['ID','Year_Birth','Dt_Customer','Kidhome','Teenhome','AcceptedCmp3','AcceptedCmp1','AcceptedCmp2',\n'AcceptedCmp4','AcceptedCmp5','NumWebPurchases','NumCatalogPurchases','NumStorePurchases','NumDealsPurchases',\n'NumWebVisitsMonth','MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds',\n'2021','Recency','Complain','Response'],axis=1, inplace=True)\n\ndf.head()","449b54fb":"print('Total categories in the feature marital status:\\n', df['Marital_Status'].value_counts(),'\\n')\nprint('Total categories in the feature education:\\n', df.Education.value_counts())\n\n# replace values in column to a more precised category for 'marital_status'\ndf['Marital_Status']=df['Marital_Status'].replace(['Married', 'Together'],'In relationship')\ndf['Marital_Status']=df['Marital_Status'].replace(['Single','Divorced','Widow','Alone','YOLO', 'Absurd'],'Single')\ndf['Marital_Status'].value_counts()\n\n# replace values in column to a more precised category for 'education'\ndf.Education =df.Education.replace(['Graduation','PhD','Master','2n Cycle'],'PG')\ndf.Education =df.Education.replace(['Basic'],'UG')\n\ndf.head()","6201f659":"df.shape","9c93e8ca":"fig = px.bar(df, x= 'Total_expense', y= 'Marital_Status', color = 'Education', barmode='group')\nfig.update_layout(width=800, height=400, title='Marital Status vs Education ')\nfig.show()\n","4fd81dea":"fig = px.pie(df, names= 'Marital_Status', title= 'Marital Status')\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()","d75b1125":"fig = px.pie(df, names= 'Education', title= 'Education',hover_data=['Total_expense'])\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()","9c1fe1e9":"sns.pairplot(df, vars= ['Income','Customers_engagement','Age'])\nplt.show();","823f3606":"sns.pairplot(df, vars= ['Kids','Total_expense','TotalAcceptedCmp','TotalNumOfPurchase'])\nplt.show();","2cd4609a":"df = df[(df['Age']<100) & (df['Income']<600000)]\ndf.Age.max()","d8add763":"df.shape","ce6aa9f0":"obj =[]\nfor x in df.columns:\n    if (df[x].dtypes == 'object'):\n        obj.append(x)\nprint(obj)","1d09e15c":"# label encoding categorical variable\nlabel_encode =LabelEncoder()\nfor x in obj:\n    df[x] = df[[x]].apply(label_encode.fit_transform)\n# created a copy of the data\ndf1=df.copy()","e62cf769":"# df.drop(['Education', 'Marital_Status'], axis=1, inplace= True)","b975250b":"# scaling\nscaled_features = StandardScaler().fit_transform(df1.values)\nscaled_features_df = pd.DataFrame(scaled_features, index=df1.index, columns=df1.columns)\nscaled_features_df.head()","e5fb2fe8":"# using PCA to reduce dimensions, feature to 3\npca = PCA(n_components=3)\npca_a = pca.fit_transform(scaled_features_df)\n# Convert into df\npca_df = pd.DataFrame(pca_a, columns=['column1', 'column2', 'column3'])\npca_df.describe().T","13ab9fce":"# plot the reduced data\nx = pca_df['column1']\ny = pca_df['column2']\nz = pca_df['column3']\n\nfig = plt.figure(figsize=(10,8))\nax = fig.add_subplot(111, projection=\"3d\")\nax.scatter(x,y,z, c=\"magenta\", marker=\"o\" )\nax.set_title(\"A 3D Projection Of Dimensional Reduced Data\")\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.set_zlabel('z')\nplt.show()","cf0c19d2":"# elbow method to find numbers of clusters to make.\nkmeans = KMeans()\nelbow_method = KElbowVisualizer(kmeans)\nelbow_method.fit(pca_df)\nelbow_method.show()\nplt.show()","e7bbe2ee":"# as seen above our k=5\nkm =KMeans(n_clusters=5)\ny_predicted= km.fit_predict(df1)\ndf1['Cluster'] = y_predicted\ndf1['Cluster'] = 'cluster'+ df1['Cluster'].astype('str')\ndf1.head()","3338b52e":"# plotting the cluster\nPLOT = go.Figure()\nfor C in list(df1.Cluster.unique()):\n    \n\n    PLOT.add_trace(go.Scatter3d(x = df1[df1.Cluster == C]['Income'],\n                                y = df1[df1.Cluster == C]['Age'],\n                                z = df1[df1.Cluster == C]['Total_expense'],                        \n                                mode = 'markers',marker_size = 6, marker_line_width = 1,\n                                name = str(C)))\nPLOT.update_traces(hovertemplate='Income: %{x} <br>Age: %{y} <br>Total_expense: %{z}')\n\n    \nPLOT.update_layout(width = 800, height = 800, autosize = True, showlegend = True,\n                   scene = dict(xaxis=dict(title = 'Income', titlefont_color = 'black'),\n                                yaxis=dict(title = 'Age', titlefont_color = 'black'),\n                                zaxis=dict(title = 'Expense', titlefont_color = 'black')),\n                   font = dict(family = \"Gilroy\", color  = 'black', size = 12))\nPLOT.show()","356e795f":"df1.head()","1668dc27":"cl = ['#FAD3AE', '#855E46', '#FE800F', '#890000']\nplt.figure(figsize=(14,8))\nsns.countplot(x=df1['Cluster'], palette=cl);","a65caa30":"sns.scatterplot(data = df1,x=df1[\"Income\"], y=df1[\"Total_expense\"],hue=df1[\"Cluster\"])\nplt.title(\"Cluster's Profile Based On Income And Spending\")\nplt.legend()\nplt.show()","643b03be":"# plotting the total amount spent by each cluster\nplt.figure()\nsns.swarmplot(x=df1[\"Cluster\"], y=df1[\"Total_expense\"], color= \"#CBEDDD\", alpha=0.5 )\nsns.boxenplot(x=df1[\"Cluster\"], y=df1[\"Total_expense\"], palette=cl)\nplt.title(\"Total Amount Spent\")\nplt.show()","68127006":"#Plotting the number of deals purchased\nplt.figure()\nsns.boxenplot(y=df1[\"TotalNumOfPurchase\"],x=df1[\"Cluster\"])\nplt.title(\"Number of Deals Purchased\")\nplt.show()","bddecd07":"plt.figure()\nsns.boxplot(y=df1[\"TotalAcceptedCmp\"],x=df1[\"Cluster\"])\nplt.title(\"Accepted Campaigns\")\nplt.show()","fbf17577":"plt.figure()\nsns.boxplot(y=df1[\"Customers_engagement\"],x=df1[\"Cluster\"])\nplt.title(\"Customer Engagement\")\nplt.show()","222207f8":"plt.figure()\n\nsns.countplot(x=df1[\"Education\"],hue=df1[\"Cluster\"])\nplt.title(\"Count Of Education\")\nplt.xlabel(\"Education\")\nplt.show()","a50c22d3":"plt.figure()\n\nsns.countplot(x=df1[\"Marital_Status\"],hue=df1[\"Cluster\"])\nplt.title(\"Count Of Marital_Status\")\nplt.xlabel(\"Marital_Status\")\nplt.show()","a95ed145":"Majority of our customers are in cluster 2 compared to cluster 4 where we have very few customers","05291113":"#### Label Encoding","135f594b":"### Customer Segmentation Analysis\nCustomer segmentation is the classification of customers into different category based on common characteristics. This analysis will assist the company to understand its customer's behaviour and also know their performance to each products so as to channel the most priortize product to them and improve on the product inorder to increase sales and reduce excess production.For this analysis we will be using unsupervised algorithm called kmeans clustering to segment the customers into group based on their most purchased needs.\n\n#### Table of Content\n* Importing libraries and data\n* Data Cleaning\n* Data Preprocessing\n* Dimensionality Reduction\n* Clustering\n* Evaluation\n* Customer Profile","7f8f3874":"### Hey guys,\n### Thanks for viewing my notebook\n#### Let me know your suggestion in the comment box","8ff2b173":"removed outliers\n* Age greater than 100\n* Income above 600,000","1d96ea06":"cluster 0 purchase more compared to other clusters","4a8ecdc1":"#### Outliers\nLet remove outliers (completely different data) from our dataset","b8bf937f":"### Importing libraries and data","67d967e8":"Let's visualise the category column for clarity","e24fc720":"### Evaluating Model","8f7b581b":"### Customer Profile","a595cd7b":"### Data Preprocessing\nFormatting the data into meaningful format for analysis","f26b9456":"* 64% of our customers are in a In relationship\n* 35% of our customers are Single","34617e81":"* 97% of our customers are PG student, they also purchase from the store better compared to UG student","a5aff0c8":"cluster 3 spend more compared to other spender followed by cluster 0\n","eb47224e":"cluster2:high income, low spending\n\ncluster3:high income, high spending\n\ncluster0:high income, average spending\n\n\ncluster1:low income, low spending\n\ncluster4:high income,low\/high spending\n\n","28f929b7":"### Dimensionality Reduction\nIntroduced dimensionality reduction in the analysis to reduce the number of input variable.\nPrinciple Component Analysis(PCA) is an unsupervised techniques that is used to reduce dimensionality in the dataset so as to increase interpretability and also minimise information loss.","daf3485c":" *Observation*\n* Categorising Customers in relationship and PG school - group1\n* Categorising Customers in relationship and UG school - group2\n* Categorising Customers that're Single and PG school - group3\n* Categorising Customers that're Single and UG school- group4 \n\nThe chart shows that customers in group1 patronise the business more than group3 while group2 and group4 are insignificant customers, the company can reduce its cost by not concentrating on markerting to this set of insignificant customers.","6fa9fc6e":"### Clustering\nWill use KMeans to cluster customers into segment","28e76cf2":"* There're outliers in age and income column","05411f15":"### Data Cleaning\nChecking the data to know what it looks like","b7efdff2":"There is no any significant engagement of customers with our campaigns","6a8479ee":"Majority of our population are married, cluster 0 have the highest number of married people"}}