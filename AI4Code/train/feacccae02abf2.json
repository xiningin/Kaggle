{"cell_type":{"7be9a0c1":"code","260a88e7":"code","d8c8e1c9":"code","c41870e1":"code","5dc769dc":"code","02bb12c3":"code","6673a143":"code","bc7a8a4b":"code","ff79f6f9":"code","592bc667":"code","4d759059":"code","4042f261":"code","22c7e3f9":"code","3a333f53":"code","26e1a2a9":"code","3b01214d":"code","08b7761c":"code","c1fe4325":"code","7fb3d8fc":"code","91058bbf":"code","2004994b":"code","1a62e634":"code","3b96eb96":"code","6c34a03f":"code","5a5ae1a2":"code","cd49bb86":"code","049951af":"code","aacd021f":"code","4036557d":"code","2157139d":"code","b00b9618":"code","9c8eaba3":"code","1d537354":"code","e6321be6":"code","1c982da9":"code","c79fb72e":"code","3f5a5470":"code","5a05a4af":"code","aae6889c":"code","46fe76a1":"code","d33ea434":"code","4a2d5d80":"code","ade856f5":"code","0aa710c4":"code","979c152d":"code","dd8e150c":"code","51f074aa":"code","42f170b6":"code","c33ada89":"code","b4e952b0":"code","2004c57c":"code","cf21ba5b":"code","bf3ebf5c":"code","e8e8273d":"code","74dedd30":"code","bf38b90f":"code","ddb80e08":"code","78df79bf":"code","b160d0d2":"code","c35542aa":"code","48d975ff":"code","d7b82831":"code","d35ceb63":"code","84a773e1":"code","56846697":"code","444b2f20":"code","cb018ce3":"code","3bb05c8f":"code","37bff8cc":"code","109a1a4b":"code","e4050d83":"code","14cd9405":"code","b71e9c83":"code","7c00e3d3":"code","e556d22b":"code","602f9f11":"code","c1d62547":"code","2df34ded":"code","10d0ba39":"code","d6eea592":"code","b1ef17f8":"code","ef1286bd":"code","f7a862b6":"code","e30f86bd":"code","4bb1a476":"code","c56176c5":"code","b1af198e":"code","0c13268c":"code","f5610315":"code","9ef6f868":"code","1dbb3d96":"code","d47bc9b3":"code","b53688f5":"code","35dcbebc":"code","d4901c8d":"code","afc37858":"code","9183abf2":"code","6d3dbfda":"code","d10fa763":"code","1c8b0215":"code","e13e701f":"markdown","4bb09a9c":"markdown","e7b9f254":"markdown","199aaa67":"markdown","8233102b":"markdown","e549aec9":"markdown","d3239bb8":"markdown","cbd3157d":"markdown","86f71aa2":"markdown","214bd0de":"markdown","2c652fa9":"markdown","3d1be16e":"markdown","8f0828a7":"markdown","6560a860":"markdown","d4b57fb0":"markdown","4e77605e":"markdown","672eeb73":"markdown","b3dd4d0c":"markdown","66f7e6c4":"markdown","13580bdd":"markdown","15674c87":"markdown","7c550a2f":"markdown","1482be01":"markdown","8145ce46":"markdown","2ea275a0":"markdown","0c313ec1":"markdown","aba6e6ba":"markdown","112c26b3":"markdown","2657999c":"markdown","c476c66d":"markdown","c404a25c":"markdown","6245d605":"markdown","5f4be064":"markdown","9873df05":"markdown","27bdfa58":"markdown","33faee30":"markdown","a67867bc":"markdown","8450297b":"markdown","695e36cb":"markdown","442778d0":"markdown","77616a6c":"markdown","9225bded":"markdown","f8c47944":"markdown","7b65fbf6":"markdown","8f5fd366":"markdown","49343b0d":"markdown","6ae2bdad":"markdown","9a236514":"markdown","99205474":"markdown","056ac24b":"markdown","db6e83bf":"markdown","ab35e7c7":"markdown"},"source":{"7be9a0c1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\nimport warnings\nwarnings.filterwarnings(\"ignore\")","260a88e7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d8c8e1c9":"data = pd.read_csv('\/kaggle\/input\/ibm-hr-analytics-attrition-dataset\/WA_Fn-UseC_-HR-Employee-Attrition.csv')\n\ndata.head()","c41870e1":"# import io\n\n# data = pd.read_csv(io.BytesIO(uploaded['HR_Employee_Attrition_Data.csv']))\n# data.head()","5dc769dc":"data.shape","02bb12c3":"data.describe()","6673a143":"data.isna().sum()","bc7a8a4b":"data['Attrition'] = data['Attrition'].map({'Yes':1, 'No':0})","ff79f6f9":"data.head()","592bc667":"print(data.Department.unique())\nprint('\\n')\nprint(data.EducationField.unique())\nprint('\\n'\n     )\nprint(data.Education.unique())","4d759059":"data.Education.replace({1: 'High School',\n                       2:'Undergrad',\n                       3:'Graduate',\n                       4:'Post Graduate',\n                       5:'Doctorate'},inplace=True)\ndata.head()","4042f261":"cols = [\"JobInvolvement\", \"JobSatisfaction\", \"PerformanceRating\"]\n\nfor col in cols:\n    data[col].replace({1 : \"Low\",\n                                    2 : \"Medium\",\n                                    3 : \"High\",\n                                    4 : \"Very High\"}, inplace = True)\ndata.head()","22c7e3f9":"data.columns","3a333f53":"data = data.drop(['EmployeeCount','StandardHours','Over18','EmployeeNumber'], axis=1)\ndata.columns","26e1a2a9":"attFeatures = []\nfor i in data.columns:\n    attFeatures.append([i, data[i].nunique(), data[i].drop_duplicates().values])\npd.DataFrame(attFeatures, columns = ['Features', 'Unique Number', 'Values'])","3b01214d":"plt.figure(figsize=(14,4))\nplt.subplot(1,2,1)\ndata['Attrition'].value_counts().plot.pie(autopct='%1.1f%%')\nplt.subplot(1,2,2)\nsns.countplot(data['Attrition'])\ndata['Attrition'].value_counts()","08b7761c":"plt.figure(figsize=(14,4))\nplt.subplot(1,2,1)\ndata['BusinessTravel'].value_counts().plot.pie(autopct='%1.1f%%')\nplt.subplot(1,2,2)\nsns.countplot(data['BusinessTravel'])\ndata['BusinessTravel'].value_counts()","c1fe4325":"plt.figure(figsize=(14,4))\nplt.subplot(1,2,1)\ndata['Department'].value_counts().plot.pie(autopct='%1.1f%%')\nplt.subplot(1,2,2)\nsns.countplot(data['Department'])\ndata['Department'].value_counts()","7fb3d8fc":"plt.figure(figsize=(14,4))\nplt.subplot(1,2,1)\ndata['Education'].value_counts().plot.pie(autopct='%1.1f%%')\nplt.subplot(1,2,2)\nsns.countplot(data['Education'])\ndata['Education'].value_counts()","91058bbf":"plt.figure(figsize=(14,4))\nplt.subplot(1,2,1)\ndata['EducationField'].value_counts().plot.pie(autopct='%1.1f%%')\nplt.subplot(1,2,2)\nsns.countplot(data['EducationField'])\nplt.xticks(rotation=45)\ndata['EducationField'].value_counts()","2004994b":"plt.figure(figsize=(14,4))\nsns.catplot(y='JobRole', kind='count', aspect=2, data=data)\n# data['JobRole'].value_counts()","1a62e634":"categorical = []\nfor col, value in data.iteritems():\n    if value.dtype == 'object':\n        categorical.append(col)\n# print(categorical)\n\ndf_cat = data[categorical]\n# Store the numerical columns in a list numerical\nnumerical = data.columns.difference(categorical)\n\n# print(\"\\n numerical:\" , numerical)\ndf_num= data[numerical]\n# df_cat.head(\nplt.figure(figsize=(18,18))\nsns.heatmap(df_num.corr(),annot=True ,cmap='twilight_shifted',fmt= '.1f')\nplt.show()\n","3b96eb96":"stayed=data[data.Attrition!=1]\nprint('Number of employees who did not leave in the dataset:', len(stayed),f'or {round(len(stayed)\/data.Attrition.count()*100)}% of the total')","6c34a03f":"stayed.describe()","5a5ae1a2":"left = data[data.Attrition==1]\nleft.describe()","cd49bb86":"comparison = data[['Attrition','Age','DailyRate','DistanceFromHome','EnvironmentSatisfaction','JobSatisfaction','StockOptionLevel']]\ncomparison = comparison.groupby('Attrition').mean()\ncomparison","049951af":"plt.figure(figsize=(10,5))\nsns.kdeplot(left.DistanceFromHome, label='Left',color='r')\nsns.kdeplot(stayed.DistanceFromHome, label='Stay')\nplt.legend()","aacd021f":"plt.figure(figsize=(8,4))\nsns.kdeplot(left.TotalWorkingYears, label='Left', color='r')\nsns.kdeplot(stayed.TotalWorkingYears, label='Stay')\nplt.legend()\nplt.show()","4036557d":"l = []\nfor column in data.columns:\n    if data[column].dtypes != object and data[column].nunique() > 30:\n        print(f\"{column} : Minimum: {data[column].min()}, Maximum: {data[column].max()}\")\n        l.append(column)\n        print(\"------------------------------------------------\")","2157139d":"lst = ['Age','DailyRate','DistanceFromHome','HourlyRate','MonthlyIncome','MonthlyRate']\nfig= plt.figure(figsize=(4,4))\nfor i in lst:\n    sns.boxplot(data[i],palette='muted')\n    plt.show()","b00b9618":"import plotly.express as px\nfig=px.histogram(data , x='Education',color='Attrition')\nfig.show()\n# sns.countplot(data=data , x='Education',hue='Attrition',palette='Set1')","9c8eaba3":"import plotly.express as px\nfig=px.histogram(data , x='JobInvolvement',color='Attrition')\nfig.show()","1d537354":"import plotly.express as px\nfig=px.histogram(data , x='JobLevel',color='Attrition')\nfig.show()","e6321be6":"import plotly.express as px\nfig=px.histogram(data , x='PercentSalaryHike',color='Attrition')\nfig.show()","1c982da9":"import plotly.express as px\nfig=px.histogram(data , x='Age',color='Attrition')\nfig.show()","c79fb72e":"def percent_attrition(column, label):\n    column_df = data.loc[data[column] == label]\n    index  = column_df.index\n    att_df = column_df.loc[column_df.Attrition == 1]\n    att_index = att_df.index\n    return (len(att_index) \/ len(index)) * 100","3f5a5470":"fig, ax = plt.subplots(1,1, figsize = (10, 20))\n\nsns.countplot(data = data,\n            y = \"JobRole\",\n            hue = \"Attrition\",\n            palette = \"Set1\")\nax.set_title(\"Attrition by Job Role\", pad = 35, fontsize = 18)\nax.set_ylabel(None)\n\ndef plot_per(column, label, x, y):\n    string = np.str(np.round(percent_attrition(column, label),2)) + \"% Attrition\"\n    plt.text(x = x, y = y, s = string, fontweight = \"semibold\")\n    \nplot_per(\"JobRole\", \"Sales Executive\", 200, -0.19)\nplot_per(\"JobRole\", \"Research Scientist\", 200, .82)\nplot_per(\"JobRole\", \"Laboratory Technician\", 200, 1.85)\nplot_per(\"JobRole\", \"Manufacturing Director\", 180, 2.79)\nplot_per(\"JobRole\", \"Healthcare Representative\", 150, 3.85)\nplot_per(\"JobRole\", \"Manager\", 100, 4.85)\nplot_per(\"JobRole\", \"Sales Representative\", 40, 5.85)\nplot_per(\"JobRole\", \"Research Director\", 30, 6.85)\nplot_per(\"JobRole\", \"Human Resources\", 20, 7.85)","5a05a4af":"plt.figure(figsize=(20,10))\nsns.boxplot(data=data, x='JobRole', y='MonthlyIncome')","aae6889c":"dummies = pd.get_dummies(df_cat)\ndummies.head(3)","46fe76a1":"dummy_df =data\ndummy_df","d33ea434":"df_final = pd.concat([df_num,df_cat],axis=1)\n\ndf_final.head()","4a2d5d80":"df_final =df_final.drop(['Attrition'],axis=1)\ndf_final.head()","ade856f5":"from sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve, auc","0aa710c4":"from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_auc_score,roc_curve","979c152d":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nx_normalized = scaler.fit_transform(dummies)\nx_normalized","dd8e150c":"x = x_normalized\ny = data['Attrition'].values\n\nx\n#y","51f074aa":"from sklearn.model_selection import train_test_split","42f170b6":"from sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt","c33ada89":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n\nx_train","b4e952b0":"model_dt = DecisionTreeClassifier(max_depth=4, random_state=1,criterion ='gini')\nmodel_dt.fit(x_train,y_train)\nmodel_dt_score_train = model_dt.score(x_train, y_train)\nprint(\"Training score: \",model_dt_score_train)\nmodel_dt_score_test = model_dt.score(x_test, y_test)\nprint(\"Testing score: \",model_dt_score_test)\n\ny_pred_dt = model_dt.predict_proba(x_test)[:, 1]\n# y_pred_dt","2004c57c":"model_dt1 = DecisionTreeClassifier(max_depth=8, random_state=1,criterion ='entropy')\nmodel_dt1.fit(x_train, y_train) \nmodel_dt1_score_train = model_dt1.score(x_train, y_train)\nprint(\"Training score: \",model_dt1_score_train)\nmodel_dt1_score_test = model_dt1.score(x_test, y_test)\nprint(\"Testing score: \",model_dt1_score_test)","cf21ba5b":"fpr_dt, tpr_dt, _ = roc_curve(y_test, y_pred_dt)\nroc_auc_dt = auc(fpr_dt, tpr_dt)","bf3ebf5c":"predictions = model_dt.predict(x_test)\n# predictions","e8e8273d":"y_pred_gini = model_dt.predict(x_test)\n\ny_pred_entropy= model_dt1.predict(x_test)","74dedd30":"accuracy_score(y_test,y_pred_gini)","bf38b90f":"acc_dt =accuracy_score(y_test,y_pred_entropy)\nacc_dt","ddb80e08":"\ncm = confusion_matrix(y_test, y_pred_gini)\nsns.heatmap(cm, annot=True)\nplt.show()","78df79bf":"print(classification_report(y_test,y_pred_gini))","b160d0d2":"plt.figure(1)\nlw = 2\nplt.plot(fpr_dt, tpr_dt, color='red',\n         lw=lw, label='Decision Tree(AUC = %0.2f)' % roc_auc_dt)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Area Under Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","c35542aa":"from sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier \nfrom urllib.request import urlopen","48d975ff":"\npd.set_option('display.max_columns', 500) ","d7b82831":"fit_rf = RandomForestClassifier(random_state=1)","d35ceb63":"fit_rf.fit(x_train, y_train)","84a773e1":"y_pred_rf = fit_rf.predict(x_test)\n# y_pred_rf","56846697":"# Testing Set Performance\ncm = confusion_matrix(y_test, y_pred_rf)\nsns.heatmap(cm, annot=True )\nplt.show()","444b2f20":"y_prob_rf = fit_rf.predict_proba(x_test)\n#fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_pred_rf)\nfpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_prob_rf[:,1])","cb018ce3":"print(classification_report(y_test,y_pred_rf))","3bb05c8f":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(fit_rf, x_test, y_test, normalize=\"true\", cmap=\"Blues\")","37bff8cc":"importances = fit_rf.feature_importances_\nimportances","109a1a4b":"# # for i,v in enumerate(importances):\n# #     print('Feature: %0d, Score: %.5f' % (i,v))\n# feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(dummies.columns, importances)]\n# feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n# [print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];","e4050d83":"feature_imp = np.array(importances)\nfeature_names= np.array(dummies.columns)\ndata={'feature_names':feature_names,'feature_importance':feature_imp}\ntable = pd.DataFrame(data) \ntable.sort_values(by=['feature_importance'], ascending=False,inplace=True) \nplt.figure(figsize=(10,15))\nsns.barplot(x=table['feature_importance'], y=table['feature_names'])\nplt.title(' VARIABLE IMPORTANCE')\nplt.xlabel('Feature importance')\nplt.ylabel('Features')","14cd9405":"# import time\n# np.random.seed(42)\n# start = time.time()\n\n# param_dist = {'max_depth': [2, 3, 4],\n#               'bootstrap': [True, False],\n#               'max_features': ['auto', 'sqrt', 'log2', None],\n#               'criterion': ['gini', 'entropy']}\n\n# cv_rf = GridSearchCV(fit_rf, cv = 10,\n#                      param_grid=param_dist, \n#                      n_jobs = 2)\n\n# cv_rf.fit(x_train, y_train)\n# print('Best Parameters using grid search: \\n', cv_rf.best_params_)\n# end = time.time()\n# print('Time taken in grid search: {0: .2f}'.format(end - start))","b71e9c83":"# fit_rf.set_params(criterion = 'gini',\n#                   max_features = 'log2', \n#                   max_depth = 2)","7c00e3d3":"accuracy_rf = accuracy_score(y_test ,y_pred_rf)\naccuracy_rf","e556d22b":"fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)\nroc_auc_rf = auc(fpr_rf, tpr_rf)","602f9f11":"plt.figure(1)\nlw = 2\nplt.plot(fpr_rf, tpr_rf, color='red',\n         lw=lw, label='Random Forest(AUC = %0.2f)' % roc_auc_rf)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Area Under Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","c1d62547":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics","2df34ded":"X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","10d0ba39":"# instantiate the model (using the default parameters)\nlogreg = LogisticRegression()\n# fit the model with data\nlogreg.fit(X_train,y_train)","d6eea592":"y_pred=logreg.predict(X_test)","b1ef17f8":"cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\ncnf_matrix","ef1286bd":"cm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True )\nplt.show()","f7a862b6":"accuracy_logreg = accuracy_score(y_test,y_pred)\nprint(\"Accuracy:\",accuracy_logreg)\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","e30f86bd":"y_pred_proba = logreg.predict_proba(X_test)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\nauc = metrics.roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","4bb1a476":"X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)","c56176c5":"from sklearn.svm import SVC\nfrom sklearn import metrics\nsvc=SVC() #Default hyperparameters\nsvc.fit(X_train,y_train)\ny_pred=svc.predict(X_test)\nprint('Accuracy Score:')\nprint(metrics.accuracy_score(y_test,y_pred))","b1af198e":"svc=SVC(kernel='linear')\nsvc.fit(X_train,y_train)\ny_pred=svc.predict(X_test)\nprint('Accuracy Score:')\nprint(metrics.accuracy_score(y_test,y_pred))","0c13268c":"svc= SVC(kernel='poly')\nsvc.fit(X_train,y_train)\ny_pred=svc.predict(X_test)\nprint('Accuracy Score:')\naccuracy_svm=metrics.accuracy_score(y_test,y_pred)\naccuracy_svm","f5610315":"svc= SVC(kernel='rbf')\nsvc.fit(X_train,y_train)\ny_pred=svc.predict(X_test)\nprint('Accuracy score:')\nprint(metrics.accuracy_score(y_test,y_pred))","9ef6f868":"from sklearn.model_selection import cross_val_score\n\nC_range=list(range(1,26))\nacc_score=[]\nfor c in C_range:\n    svc = SVC(kernel='linear', C=c)\n    scores = cross_val_score(svc, x, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nprint(acc_score)","1dbb3d96":"C_values=list(range(1,26))\n# plot the value of C for SVM (x-axis) versus the cross-validated accuracy (y-axis)\nplt.plot(C_values,acc_score)\nplt.xticks(np.arange(0,27,2))\nplt.xlabel('Value of C for SVC')\nplt.ylabel('Cross-Validated Accuracy')","d47bc9b3":"gamma_range=[0.0001,0.001,0.01,0.1,1,10,100]\nacc_score=[]\nfor g in gamma_range:\n    svc = SVC(kernel='rbf', gamma=g)\n    scores = cross_val_score(svc, x, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nprint(acc_score)   ","b53688f5":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ngamma_range=[0.0001,0.001,0.01,0.1,1,10,100]\n\n# plot the value of C for SVM (x-axis) versus the cross-validated accuracy (y-axis)\nplt.plot(gamma_range,acc_score)\nplt.xlabel('Value of gamma for SVC ')\nplt.xticks(np.arange(0.0001,100,5))\nplt.ylabel('Cross-Validated Accuracy')","35dcbebc":"svm_model= SVC()","d4901c8d":"tuned_parameters = {\n 'C': (np.arange(0.1,1,0.1)) , 'kernel': ['linear'],\n 'C': (np.arange(0.1,1,0.1)) , 'gamma': [0.01,0.02,0.03,0.04,0.05], 'kernel': ['rbf'],\n 'degree': [2,3,4] ,'gamma':[0.01,0.02,0.03,0.04,0.05], 'C':(np.arange(0.1,1,0.1)) , 'kernel':['poly']\n    }","afc37858":"from sklearn.model_selection import GridSearchCV\n\nmodel_svm= GridSearchCV(svm_model, tuned_parameters,cv=10,scoring='accuracy')","9183abf2":"model_svm.fit(X_train, y_train)\nprint(model_svm.best_score_)","6d3dbfda":"from sklearn.model_selection import StratifiedKFold","d10fa763":"# skf = StratifiedKFold(n_splits = 5)\n# skf.get_n_splits(x,y)\n# accuracy=[]\n# mean_acc = []\n# classifiers=['Logistic Regression','Decision Tree','Linear SVM', 'Random Forest Classifier']\n# models=[logreg,model_dt1,svc,fit_rf]\n# for i in models:\n#     model = i\n#     cv_result = cross_val_score(model,x,y, cv = skf,scoring = \"accuracy\")\n#     mean_acc.append(cv_result.mean())\n#     accuracy.append(cv_result)","1c8b0215":"models = pd.DataFrame({\n    'Model' : ['Logistic Regression', 'Decision Tree Classifier', 'Random Forest Classifier','SVM'],\n    'Score' : [accuracy_logreg,acc_dt,accuracy_rf,accuracy_svm]\n    # acc_vtc, 'Voting Classifier'\n \n})\n\n\nmodels.sort_values(by = 'Score', ascending = False)","e13e701f":"## Attrition by Specific Job Role","4bb09a9c":"### Optimizing Hyperparameter C","e7b9f254":"Testing set Performace","199aaa67":"## Pre Processing","8233102b":"### Attrition by Education Level","e549aec9":"### Attrition by Salary Hike","d3239bb8":"### Counts by JobRole","cbd3157d":"### Optimizing Gamma Parameter","86f71aa2":"\n\n*   As there is less salary to Sales Representative, the attrition for this job role is at higher side.\n\n","214bd0de":"- Employees who receive hikes between 12-14% tend to leave the company more than others with higher Salary hike percentage.","2c652fa9":"### Attrition By Job Level","3d1be16e":"### Numeric Columns","8f0828a7":"**DATA VISUALIZATION**","6560a860":"# <span style='background :yellow' > Decision Tree <\/span>","d4b57fb0":"### Finding out the outliers","4e77605e":"### Data Processing","672eeb73":"Separating Categorical and numerical data","b3dd4d0c":"## EDA","66f7e6c4":"# <span style='background :yellow' > SVM <\/span>","13580bdd":"- Mostly Graduate employees seem to be leaving the company","15674c87":"### Using Polynomial Kernel","7c550a2f":"# <span style='background :yellow' > Random Forest <\/span>","1482be01":"## Combined Model Accuracies","8145ce46":"# <span style='background :yellow' > LOGISTIC REGRESSION <\/span>","2ea275a0":"### Importing the Libraries","0c313ec1":"### Using Linear Kernel","aba6e6ba":"- Mostly Employees between junior and associate level tend to leave the company more than compared to others.","112c26b3":"### Missing value checks","2657999c":"### Count by Department","c476c66d":"## Area under the curve","c404a25c":"### Attrition by Age","6245d605":"### Education Level","5f4be064":"### Hyper Parameter Optimization","9873df05":"### Attrition Rate","27bdfa58":"- Employees with Job Involvement between low to moderate tend to leave the company, while there is less attrition between high and very high level job involvement. ","33faee30":"### Model Accuracy","a67867bc":"#### Age and monthly income are highly correlated.\n     * Age and no.of years of Experience are highly correlated.\n     * Income is highly correlated with working hours\n     * Salary hike is highly correlated with Performance Bonus","8450297b":"### Grid Search CV","695e36cb":"- Most of the employees are from the R&D Department","442778d0":"### Correlation Matrix","77616a6c":"- Majority of the employees who leave the company are less than 40yrs of age.","9225bded":"# Modeling Phase","f8c47944":"- Sales Respresentative has the highest attrition rate","7b65fbf6":"#### Converting Target variable to binary","8f5fd366":"### Using Radial Kernel","49343b0d":"### Count by Education Field","6ae2bdad":"\n\n\n*  Mean age of the employees who stayed is higher compared to who left\n*  DailyRate of employees who stayed is higher\n*  'DistanceFromHome': Employees who stayed live closer to home \n*  'EnvironmentSatisfaction' & 'JobSatisfaction': Employees who stayed are generally more satisifed with their jobs\n* 'StockOptionLevel': Employees who stayed tend to have higher stock option level","9a236514":"### Travel Readiness","99205474":"### Performance Metrics","056ac24b":"### Attrition by Job Involvement","db6e83bf":"### Split the data into train and Test","ab35e7c7":"### Minimum and maximum values from the Columns"}}