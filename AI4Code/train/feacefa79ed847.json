{"cell_type":{"d8ef6c58":"code","b52cf179":"code","89f9eaed":"code","181d8daa":"code","dfcd0e56":"code","7759b2d9":"code","d9acc5de":"code","5f2386bc":"code","b170256d":"code","5883f14e":"code","216b1131":"code","a54e69e8":"code","29211e28":"code","cb41b0a7":"code","72c40a13":"code","79a0d08e":"code","1eea00c8":"code","1cec2bfb":"code","f6cc4163":"code","208d7201":"code","97e4a083":"code","686e6d56":"markdown","3a6b0dc1":"markdown","4c9b31da":"markdown","341c7b9c":"markdown","86d9dba6":"markdown","baaa646c":"markdown","6fa5aa64":"markdown","e2e8e49a":"markdown","059a865e":"markdown"},"source":{"d8ef6c58":"import pandas as pd\nfrom pathlib import Path\nimport os\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom matplotlib import pyplot as plt, image as img\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import (\n    Conv2D,\n    Conv2DTranspose,\n    MaxPool2D,\n    ReLU,\n    Flatten,\n    Dense,\n    UpSampling2D,\n    Dropout,\n    Input, \n    Concatenate,\n    GlobalAveragePooling2D, \n    GlobalMaxPooling2D,\n)\nfrom skimage.transform import resize\nfrom tensorflow import Tensor\nfrom tensorflow.keras.models import Model, Sequential, load_model\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom keras.layers import Input\nfrom tensorflow import Tensor\nfrom scipy.stats import mannwhitneyu\nfrom tabulate import tabulate\n\n!pip3 install progressbar\nimport progressbar\n\n# random seed generator\nnp.random.seed(3)\ntf.random.set_seed(7)","b52cf179":"!pip install tqdm\n\nfrom tqdm import *\n\ndisease_types=['1NonCOVID', '2COVID', '3CAP']#, '3CAP'\ndata_dir = '..\/input\/large-covid19-ct-slice-dataset\/curated_data\/curated_data'\ntrain_dir = os.path.join(data_dir)\n\n\n\ntrain_data = []\nfor defects_id, sp in enumerate(disease_types):\n    for file in os.listdir(os.path.join(train_dir, sp)):\n        train_data.append(['{}\/{}'.format(sp, file), defects_id, sp])\n        \ntrain = pd.DataFrame(train_data, columns=['File', 'DiseaseID','Disease Type'])\ntrain.head()","89f9eaed":"SEED = 42\ntrain = train.sample(frac=1, random_state=SEED) \ntrain.index = np.arange(len(train)) # Reset indices\ntrain.head(10)","181d8daa":"plt.hist(train['DiseaseID'])\nplt.title('Frequency Histogram of Species')\nplt.figure(figsize=(12, 12))\nplt.show()","dfcd0e56":"def plot_defects(defect_types, rows, cols):\n    fig, ax = plt.subplots(rows, cols, figsize=(12, 12))\n    defect_files = train['File'][train['Disease Type'] == defect_types].values\n    n = 0\n    for i in range(rows):\n        for j in range(cols):\n            image_path = os.path.join(data_dir, defect_files[n])\n            ax[i, j].set_xticks([])\n            ax[i, j].set_yticks([])\n            ax[i, j].imshow(plt.imread(image_path), cmap ='gray')\n            n += 1","7759b2d9":"# Display images of COVID\nplot_defects('2COVID', 3, 4)","d9acc5de":"# Display images of non-COVID\nplot_defects('1NonCOVID', 3, 4)","5f2386bc":"# Display images of CAP\nplot_defects('3CAP', 3, 4)","b170256d":"from keras.preprocessing import image\nIMAGE_SIZE = 64\ndef read_image(filepath):\n    img = image.load_img(os.path.join(data_dir, filepath), target_size=(64, 64))\n    img = image.img_to_array(img)\n    img = np.array(img)\n    return img\n","5883f14e":"# Training Images\nX_train = np.zeros((train.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\nfor i, file in tqdm(enumerate(train['File'].values)):\n    X_train[i] = read_image(file)\n\nX_train = X_train \/ 255.\nprint('Train Shape: {}'.format(X_train.shape))","216b1131":"# Converting Labels to Categorical\nY_train = train['DiseaseID'].values\nY_train = keras.utils.to_categorical(Y_train, num_classes=3)\nprint('Train Shape: {}'.format(Y_train.shape))","a54e69e8":"np.savez('X_train', X_train)\nnp.savez('Y_train', Y_train)","29211e28":"# Split the train and validation sets \nSEED = 42\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.30, random_state=SEED)\nX_val, X_test, Y_val, Y_test = train_test_split(X_val, Y_val, test_size=0.50, random_state=SEED)\n\nprint('Train Shape: {}'.format(X_train.shape))\nprint('Validation Shape: {}'.format(X_val.shape))\nprint('Test: {}'.format(X_test.shape))","cb41b0a7":"# 64*64 training images\n\nfig, ax = plt.subplots(1, 6, figsize=(15, 15))\nfor i in range(6):\n    ax[i].set_axis_off()\n    ax[i].imshow(X_train[i], cmap='gray')\n    ax[i].set_title(disease_types[np.argmax(Y_train[i])])","72c40a13":"def cnn(): \n    from tensorflow.keras.layers import Input, GlobalAveragePooling2D, GlobalMaxPooling2D, Concatenate ,Dropout\n    from tensorflow.keras.models import Model\n    densenet = tf.keras.applications.DenseNet121(weights='imagenet', include_top=False)\n    \n\n    input = Input(shape=(64, 64, 3))\n    \n    x = densenet(input)\n    \n    x = GlobalAveragePooling2D()(x)\n    #x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(512, activation='relu')(x)\n    #x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    # multi output\n    output = Dense(3, activation=\"softmax\", name='root')(x)\n \n\n    # model\n    model = Model(input,output)\n    \n    optimizer = keras.optimizers.Adam(lr=0.00002)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    \n    return model","79a0d08e":"model = cnn()\nmodel.summary()\n\nannealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\ncheckpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n\ndatagen = ImageDataGenerator(rotation_range=180, # Degree range for random rotations\n                        width_shift_range=0.2, # Range for random horizontal shifts\n                        height_shift_range=0.2, # Range for random vertical shifts\n                        zoom_range=0.2, # Range for random zoom\n                        horizontal_flip=True, # Randomly flip inputs horizontally\n                        vertical_flip=True) # Randomly flip inputs vertically\nBATCH_SIZE = 64\ndatagen.fit(X_train)","1eea00c8":"# Fits the model on batches with real-time data augmentation\nBATCH_SIZE = 64\nEPOCHS = 200\nimport datetime\nstart = datetime.datetime.now()\n\nhist = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n               steps_per_epoch=X_train.shape[0] \/\/ BATCH_SIZE, #31\n               epochs=EPOCHS,\n               verbose=1,\n               callbacks=[checkpoint],\n               validation_data=(X_val, Y_val))\n\nend = datetime.datetime.now()\nprint ('* total training time:', str(end-start))","1cec2bfb":"final_loss, final_accuracy = model.evaluate(X_test, Y_test)\nprint('Final Loss: {}, Final Accuracy: {}'.format(final_loss, final_accuracy))","f6cc4163":"Best_model = load_model('model.h5')\nfinal_loss, final_accuracy = Best_model.evaluate(X_test, Y_test)\nprint('Final Loss best Model: {}, Final Accuracy best Model: {}'.format(final_loss, final_accuracy))","208d7201":"# accuracy plot \nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","97e4a083":"# loss plot\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","686e6d56":"# Import Libraries","3a6b0dc1":"# Accuracy and Loss Curve","4c9b31da":"# Train Test Splitting","341c7b9c":"# Plot histogram","86d9dba6":"# DenseNet121 Model","baaa646c":"# Display images of Dataset","6fa5aa64":"# Image Read and Resize Function","e2e8e49a":"# Final Loss and Accuracy","059a865e":"# Data Augmentation and Fitting Model"}}