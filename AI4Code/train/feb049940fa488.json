{"cell_type":{"f419c84f":"code","b1ff2b86":"code","cb4ee7ce":"code","76c8d9be":"code","0cf38337":"code","d3788587":"code","dbcdc19b":"code","8ccb668a":"code","96ea5c9c":"code","a3336b18":"code","bdc02c3e":"code","bb02300f":"code","f82831a9":"code","088824f4":"code","ec6442ce":"code","259b10cc":"code","41184458":"code","4fa7d24b":"code","d7fb3aaa":"code","68cd738c":"code","09b88132":"code","723f228b":"code","78bd7aff":"code","173cf858":"code","8979ad58":"code","118d1328":"code","a24e5e2a":"code","afb8d1aa":"code","78dab6c0":"code","812bccb1":"code","37e54dfa":"code","85e7668e":"code","1ef13c6e":"code","f51653b5":"code","560923f8":"code","83c5e276":"code","6f0e4dc6":"code","9e6eabe5":"code","1eaa2a81":"code","f1a59b5e":"code","3cad4e9a":"code","7a441225":"code","290c7288":"code","200bf6c3":"code","07e5445f":"code","dc0acf78":"code","2faa6743":"code","993775eb":"code","f0ce4b6c":"code","28556e28":"code","251b7380":"code","4b31e2bf":"code","0360c527":"code","633426c7":"code","35985926":"code","9b83a7b6":"code","635db4da":"code","f292058d":"code","69003a6d":"code","c0eb40fa":"code","d79dd059":"code","9c4ceaff":"code","8f3b6fa7":"code","c85d0f6b":"code","dacc262b":"code","2067aa4a":"code","194e4306":"code","dbbba0e4":"code","ebc10bdd":"code","9f80cb12":"code","057e27b4":"code","d1f92d41":"code","5c0b10ae":"code","340e9257":"code","369be3f6":"code","5595cec5":"code","debd6eb3":"code","995338bc":"code","3758d8c4":"markdown","39c8681f":"markdown","f9e61751":"markdown"},"source":{"f419c84f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b1ff2b86":"training = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-2\/train.csv\")\ntesting = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-2\/test.csv\")\ndata_ = pd.read_csv(\"\/kaggle\/input\/covid19-demographic-predictors\/covid19_by_country.csv\")","cb4ee7ce":"data_","76c8d9be":"training","0cf38337":"#change the name of the 'country' feature to match 'Country_Region' on the train set \ndata_['Country_Region']= data_.Country\ndata_.drop('Country',axis=1,  inplace =True)","d3788587":"training.info()","dbcdc19b":"print(data_.shape)\nprint(training.shape)","8ccb668a":"#missing values\ntraining.isnull().sum()","96ea5c9c":"#missing values\ndata_.isnull().sum()","a3336b18":"data_['Quarantine_date'] = pd.to_datetime(data_.Quarantine)\ndata_['Restrictions_date'] = pd.to_datetime(data_.Restrictions)\ndata_['Schools_date'] = pd.to_datetime(data_.Schools)\ndata_.drop(['Schools', 'Restrictions', 'Quarantine'], axis =1, inplace = True)","bdc02c3e":"training.Date = pd.to_datetime(training.Date)","bb02300f":"training = training.fillna({'Province_State': 'Unknown'})\ntesting = testing.fillna({'Province_State': 'Unknown'})","f82831a9":"data_.info()","088824f4":"training.info()","ec6442ce":"df = training.groupby(['Country_Region', 'Date'], as_index=False).sum()\ndf_test = testing.groupby(['Country_Region', 'Date'], as_index=False).sum()","259b10cc":"df_test[df_test.Country_Region == 'Italy']","41184458":"df[df.Country_Region == 'Italy']","4fa7d24b":"len(df.Country_Region.unique())","d7fb3aaa":"len(df_test.Country_Region.unique())","68cd738c":"train = pd.merge(training, data_, on=['Country_Region'], how= 'left')\ntest  = pd.merge(testing, data_, on=['Country_Region'], how= 'left')","09b88132":"train.shape","723f228b":"train.isna().sum()","78bd7aff":"test.shape","173cf858":"data_[data_.Restrictions_date.notnull()][['Country_Region', 'Quarantine_date']]","8979ad58":"train.loc[(train['Date'] == '2020-03-20') &(train.Country_Region == 'Argentina') ]","118d1328":"test['Quarantine'] = 0\ntest['Schools'] = 0\ntest['Restrictions'] = 0\n\ntest.loc[(test.Country_Region == 'Argentina'), 'Quarantine' ] = 1\ntest.loc[(test.Country_Region == 'Austria'), 'Quarantine' ] = 1\ntest.loc[(test.Country_Region == 'Belgium'), 'Quarantine' ] = 1\ntest.loc[(test.Country_Region == 'China'), 'Quarantine' ] = 1\ntest.loc[(test.Country_Region == 'Colombia'), 'Quarantine' ] = 1\ntest.loc[(test.Country_Region == 'Denmark'), 'Quarantine' ] = 1\ntest.loc[(test.Country_Region == 'France'), 'Quarantine' ] = 1\ntest.loc[(test.Country_Region == 'Germany'), 'Quarantine' ] = 1\ntest.loc[(test.Country_Region == 'India'), 'Quarantine' ] = 1\ntest.loc[(test.Country_Region == 'Israel'), 'Quarantine' ] = 1\ntest.loc[(test.Country_Region == 'Italy'), 'Quarantine' ] = 1\ntest.loc[(test.Country_Region == 'Malaysia'), 'Quarantine' ] = 1\ntest.loc[(test.Country_Region == 'New Zealand'), 'Quarantine' ] = 1\ntest.loc[(test.Country_Region == 'Peru'), 'Quarantine' ] = 1\ntest.loc[(test.Country_Region == 'Spain'), 'Quarantine' ] = 1\n\ntest.loc[(test.Country_Region == 'Israel'), 'Schools' ] = 1\n\ntest.loc[(test.Country_Region == 'Israel'), 'Restrictions' ] = 1\n\ntest.drop(['Quarantine_date', 'Schools_date', 'Restrictions_date'], axis = 1, inplace = True)","a24e5e2a":"train['Quarantine'] = 0\ntrain['Schools'] = 0\ntrain['Restrictions'] = 0\n\ntrain.loc[(train['Date'] >= '2020-03-20') &(train.Country_Region == 'Argentina'), 'Quarantine' ] = 1\ntrain.loc[(train['Date'] >= '2020-03-16') &(train.Country_Region == 'Austria'), 'Quarantine' ] = 1\ntrain.loc[(train['Date'] >= '2020-03-18') &(train.Country_Region == 'Belgium'), 'Quarantine' ] = 1\ntrain.loc[(train['Date'] >= '2020-01-24') &(train.Country_Region == 'China'), 'Quarantine' ] = 1\ntrain.loc[(train['Date'] >= '2020-03-25') &(train.Country_Region == 'Colombia'), 'Quarantine' ] = 1\ntrain.loc[(train['Date'] >= '2020-03-16') &(train.Country_Region == 'Denmark'), 'Quarantine' ] = 1\ntrain.loc[(train['Date'] >= '2020-03-17') &(train.Country_Region == 'France'), 'Quarantine' ] = 1\ntrain.loc[(train['Date'] >= '2020-03-21') &(train.Country_Region == 'Germany'), 'Quarantine' ] = 1\ntrain.loc[(train['Date'] >= '2020-03-23') &(train.Country_Region == 'India'), 'Quarantine' ] = 1\ntrain.loc[(train['Date'] >= '2020-03-19') &(train.Country_Region == 'Israel'), 'Quarantine' ] = 1\ntrain.loc[(train['Date'] >= '2020-03-08') &(train.Country_Region == 'Italy'), 'Quarantine' ] = 1\ntrain.loc[(train['Date'] >= '2020-03-18') &(train.Country_Region == 'Malaysia'), 'Quarantine' ] = 1\ntrain.loc[(train['Date'] >= '2020-03-23') &(train.Country_Region == 'New Zealand'), 'Quarantine' ] = 1\ntrain.loc[(train['Date'] >= '2020-03-15') &(train.Country_Region == 'Peru'), 'Quarantine' ] = 1\ntrain.loc[(train['Date'] >= '2020-03-15') &(train.Country_Region == 'Spain'), 'Quarantine' ] = 1\n\ntrain.loc[(train['Date'] >= '2020-03-19') &(train.Country_Region == 'Israel'), 'Schools' ] = 1\n\ntrain.loc[(train['Date'] >= '2020-03-19') &(train.Country_Region == 'Israel'), 'Restrictions' ] = 1\n\ntrain.drop(['Quarantine_date', 'Schools_date', 'Restrictions_date'], axis = 1, inplace = True)","afb8d1aa":"train[train.Quarantine == 1][['Country_Region', 'Date']].head(50)","78dab6c0":"data_[data_.Quarantine_date.notnull()]","812bccb1":"train['Quarantine'].any() ==1","37e54dfa":"train[train.Country_Region=='Italy']","85e7668e":"train[train['Restrictions'] == 1]","1ef13c6e":"train.columns","f51653b5":"train.hist(figsize=(11,10))","560923f8":"train.drop(['Tests','Test Pop', 'Density', 'Urban Pop', 'sex0', 'sex14',\n            'sex25', 'sex54', 'sex64', 'sex65plus', 'Sex Ratio', 'lung',\n            'Female Lung', 'Male Lung', 'Crime Index', 'Population 2020',\n            'Smoking 2016', 'Females 2018', 'Total Infected','Total Deaths',\n            'Total Recovered', 'Hospital Bed', 'Median Age', 'GDP 2018'], axis = 1, inplace = True)","83c5e276":"test.drop(['Tests','Test Pop', 'Density', 'Urban Pop', 'sex0', 'sex14',\n           'sex25', 'sex54', 'sex64', 'sex65plus', 'Sex Ratio', 'lung',\n           'Female Lung', 'Male Lung', 'Crime Index', 'Population 2020',\n           'Smoking 2016', 'Females 2018', 'Total Infected', 'Total Deaths',\n           'Total Recovered', 'Hospital Bed', 'Median Age', 'GDP 2018'], axis = 1, inplace = True)","6f0e4dc6":"print(train.describe())","9e6eabe5":"print(test.describe())","1eaa2a81":"train.isna().sum()","f1a59b5e":"test.isna().sum()","3cad4e9a":"test.Date = pd.to_datetime(test.Date)","7a441225":"test.info()","290c7288":"def create_time_features(df):\n    \"\"\"\n    Creates time series features from datetime index\n    \"\"\"\n    df['date'] = df.index\n    df['dayofweek'] = df['Date'].dt.dayofweek\n    df['quarter'] = df['Date'].dt.quarter\n    df['month'] = df['Date'].dt.month\n    df['dayofyear'] = df['Date'].dt.dayofyear\n    df['dayofmonth'] = df['Date'].dt.day\n    df['weekofyear'] = df['Date'].dt.weekofyear\n    \n    X = df[['dayofweek','quarter','month',\n           'dayofyear','dayofmonth','weekofyear']]\n    return X","200bf6c3":"train.columns","07e5445f":"train.Date = pd.to_datetime(train.Date)","dc0acf78":"create_time_features(train)\ncreate_time_features(test)","2faa6743":"train.columns","993775eb":"train.drop([\"Id\",\"Date\", 'date'], axis=1, inplace=True)\ntest.drop([\"Date\", 'date'], axis=1, inplace=True)","f0ce4b6c":"train = pd.concat([train,pd.get_dummies(train['Country_Region'], prefix='ps')],axis=1)\ntrain.drop(['Country_Region'],axis=1, inplace=True)\n\ntrain = pd.concat([train,pd.get_dummies(train['Province_State'], prefix='ps')],axis=1)\ntrain.drop(['Province_State'],axis=1, inplace=True)","28556e28":"test = pd.concat([test,pd.get_dummies(test['Country_Region'], prefix='ps')],axis=1)\ntest.drop(['Country_Region'],axis=1, inplace=True)\n\ntest = pd.concat([test,pd.get_dummies(test['Province_State'], prefix='ps')],axis=1)\ntest.drop(['Province_State'],axis=1, inplace=True)","251b7380":"train.shape","4b31e2bf":"train = train.loc[:,~train.columns.duplicated()]\ntest = test.loc[:,~test.columns.duplicated()]","0360c527":"y = train.Fatalities\nx = train.drop([\"Fatalities\", \"ConfirmedCases\"], axis = 1)","633426c7":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error, r2_score\n%matplotlib inline","35985926":"from sklearn.model_selection import train_test_split\n\n\ndef linear_models(X_model, y_model, model_name):\n\n    X_train, X_test, y_train, y_test = train_test_split(X_model, y_model, random_state = 42)\n    if model_name == \"ridge\":\n        model = linear_model.Ridge(alpha = 0.1, random_state = 42).fit(X_train, y_train)\n    if model_name == \"lasso\":\n        model = linear_model.Lasso(alpha = 0.5, random_state = 42).fit(X_train, y_train)\n    if model_name == \"xgb\":\n        model = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 5, alpha = 0.1, n_estimators = 10, random_state = 42).fit(X_train, y_train)\n        print(model.get_booster().get_score(importance_type=\"gain\"))\n    if model_name == \"catboost\":\n        model = CatBoostRegressor(num_leaves = 31,random_state = 42,learning_rate = 0.05).fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    return predictions, y_test","9b83a7b6":"def error_metrics(model, predictions, y_test):\n    print(\"Model: \", model)\n    # The mean squared error\n    print(\"--Mean squared error: %.2f\" % mean_squared_error(y_test, predictions))\n    # RMS\n    print('--Root Mean Squared Error: %.2f' % np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n    # Explained variance score: 1 is perfect prediction\n    print('--Variance score: %.2f' % r2_score(y_test, predictions))","635db4da":"# Take a look at some of the results\ndef inspect_df(predictions, y_test):\n    true_vs_pred = np.vstack((predictions, y_test))\n    true_df = pd.DataFrame(true_vs_pred)\n    true_df = true_df.transpose()\n    true_df.columns = [\"Predicted\", \"Actual\"]\n    return true_df","f292058d":"from IPython.display import display_html\ndef display_side_by_side(*args):\n    html_str=''\n    for df in args:\n        html_str+=df.to_html()\n    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)","69003a6d":"ridge_pred, y_test = linear_models(x, y, \"ridge\")\nlasso_pred, y_test = linear_models(x, y, \"lasso\")\nxgb_pred, y_test   = linear_models(x, y, \"xgb\")\nlgb_pred, y_test   = linear_models(x, y, \"catboost\")","c0eb40fa":"error_metrics(\"Ridge\", ridge_pred, y_test)\nerror_metrics(\"Lasso\", lasso_pred, y_test)\nerror_metrics(\"xgboost regression\", xgb_pred, y_test)\nerror_metrics(\"catboost regression\", lgb_pred, y_test)","d79dd059":"X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 42)\n\nmodel = CatBoostRegressor(random_state = 42)\n\n\"\"\"grid = {'learning_rate': [0.03, 0.1],\n        'depth': [4, 6, 10],\n        'l2_leaf_reg': [1, 3, 5, 7, 9],\n        #'num_leaves' : [5, 15, 31, 60],\n        'bagging_temperature' : [0, 1, 5, 10]}\n\ngrid_search_model = model.grid_search(grid,\n                                      X=X_train, \n                                      y=y_train,\n                                      cv = 5\n                                        )\"\"\"\n","9c4ceaff":"model = CatBoostRegressor(num_leaves = 31, bagging_temperature= 0, depth = 6, l2_leaf_reg = 1, learning_rate = 0.03).fit(X_train, y_train)\npredictions = model.predict(X_test)\nerror_metrics(\"Catboost regression\", predictions, y_test)","8f3b6fa7":"print(model.get_feature_importance(prettified = True))","c85d0f6b":"test.columns","dacc262b":"submit = pd.DataFrame()\nsubmit['ForecastId'] = test['ForecastId']\ntest.drop([\"ForecastId\"], axis = 1, inplace = True)","2067aa4a":"submit","194e4306":"fatilities = model.predict(test)","dbbba0e4":"y = train.ConfirmedCases\nx = train.drop([\"Fatalities\", \"ConfirmedCases\"], axis = 1)","ebc10bdd":"ridge_pred, y_test = linear_models(x, y, \"ridge\")\nlasso_pred, y_test = linear_models(x, y, \"lasso\")\nxgb_pred, y_test   = linear_models(x, y, \"xgb\")\nlgb_pred, y_test   = linear_models(x, y, \"catboost\")","9f80cb12":"error_metrics(\"Ridge\", ridge_pred, y_test)\nerror_metrics(\"Lasso\", lasso_pred, y_test)\nerror_metrics(\"xgboost regression\", xgb_pred, y_test)\nerror_metrics(\"catboost regression\", lgb_pred, y_test)","057e27b4":"print(model.get_feature_importance(prettified = True))","d1f92d41":"X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 42)\n\nmodel = CatBoostRegressor(random_state = 42)\n\n\"\"\"grid = {'learning_rate': [0.03, 0.1],\n        'depth': [4, 6, 10],\n        'l2_leaf_reg': [1, 3, 5, 7, 9],\n        #'num_leaves' : [5, 15, 31, 60],\n        'bagging_temperature' : [0, 1, 5, 10]}\n\ngrid_search_model = model.grid_search(grid,\n                                      X=X_train, \n                                      y=y_train,\n                                      cv = 5\n                                        )\"\"\"\n","5c0b10ae":"model = CatBoostRegressor(num_leaves = 31, bagging_temperature= 0, depth = 4, l2_leaf_reg = 5, learning_rate = 0.1).fit(X_train, y_train)\npredictions = model.predict(X_test)\nerror_metrics(\"Catboost regression\", predictions, y_test)","340e9257":"print(model.get_feature_importance(prettified = True))","369be3f6":"confirmedCases = model.predict(test)","5595cec5":"submit['ConfirmedCases'] = confirmedCases\nsubmit['Fatalities'] = fatilities","debd6eb3":"submit","995338bc":"submit.to_csv('submission.csv',index=False)","3758d8c4":"# Covid19_competition_week_2","39c8681f":"In this notebook, I will try to predict the number of fatalities and Confirmed cases of Covid19 on April.\n\nWith the datasets available, I will use [nightranger77's COVID-19 Predictors dataset](https:\/\/www.kaggle.com\/nightranger77\/covid19-demographic-predictors) to help my model learn more about the data and decrease prediction error","f9e61751":"### Next I will merge the two datasets add three binary columns of the date of closing schools, public restrictions and the start of quarantine of the country "}}