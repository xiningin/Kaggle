{"cell_type":{"2f1b42e4":"code","df787a86":"code","a33c2020":"code","667b5b3f":"code","40798d95":"code","b405236d":"code","29052ab6":"code","c35789d2":"code","0f41c9b4":"code","8398c55d":"code","43b843e5":"code","a7e47c80":"code","b2451dad":"code","77bbfc11":"code","1a4d9979":"code","afae852f":"code","99170280":"code","01641266":"code","9f4e3f6c":"code","56ff811c":"code","073e84dd":"code","f33acc4d":"code","7f617e3c":"code","79b9e443":"markdown"},"source":{"2f1b42e4":"import lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nimport random\nimport optuna\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots","df787a86":"data0=pd.read_csv('..\/input\/ecg-dataset\/ecg.csv',header=None)\ndata0","a33c2020":"m=len(data0)\nprint(m)\nM=list(range(m))\nrandom.seed(2021)\nrandom.shuffle(M)","667b5b3f":"dataY = data0[140]\ndataX = data0.drop(140,axis=1)","40798d95":"trainX=dataX.iloc[M[0:(m\/\/4)*3]].reset_index(drop=True)\ntrainY=dataY.iloc[M[0:(m\/\/4)*3]].reset_index(drop=True)\ntestX=dataX.iloc[M[(m\/\/4)*3:]].reset_index(drop=True)\ntestY=dataY.iloc[M[(m\/\/4)*3:]].reset_index(drop=True)","b405236d":"trainY","29052ab6":"fig=make_subplots(specs=[[{\"secondary_y\":False}]])\nfig.add_trace(go.Scatter(x=list(range(140)),y=trainX.iloc[0,:],name='Normal (label=0)'),secondary_y=False,)\nfig.add_trace(go.Scatter(x=list(range(140)),y=trainX.iloc[2,:],name='Abnormal (label=1)'),secondary_y=False,)\nfig.update_layout(autosize=False,width=700,height=500,title_text=\"ECG sample\")\nfig.update_xaxes(title_text=\"time\")\nfig.update_yaxes(title_text=\"ECG\",secondary_y=False)\nfig.show()","c35789d2":"columns=trainX.columns.to_list()\nprint(columns)","0f41c9b4":"def objective(trial,data=trainX,target=trainY):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.2,random_state=42)\n    param =   {\n        'num_leaves': trial.suggest_int('num_leaves', 2, 200),\n        'objective': trial.suggest_categorical('objective',['regression','rmse']),  \n        'max_depth': trial.suggest_int('max_depth', 2, 10),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-1, 1.0),\n        \"boosting\": \"gbdt\",\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 1e-3),\n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-3, 10.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 2, 10),\n        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n        \"feature_fraction\": trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n        \"verbosity\": -1,\n    }\n    model = lgb.LGBMClassifier(**param)      \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n    preds = model.predict(test_x)\n    rmse = mean_squared_error(test_y, preds,squared=False)\n    \n    return rmse","8398c55d":"study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=16)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","43b843e5":"study.trials_dataframe()","a7e47c80":"# shows the scores from all trials\noptuna.visualization.plot_optimization_history(study)","b2451dad":"# interactively visualizes the hyperparameters and scores\noptuna.visualization.plot_parallel_coordinate(study)","77bbfc11":"# shows the evolution of the search\noptuna.visualization.plot_slice(study)","1a4d9979":"# parameter interactions on an interactive chart.\noptuna.visualization.plot_contour(study, params=['num_leaves','learning_rate','bagging_freq'])","afae852f":"# Visualize parameter importances.\noptuna.visualization.plot_param_importances(study)","99170280":"# Visualize empirical distribution function\noptuna.visualization.plot_edf(study)","01641266":"Best_trial=study.best_trial.params\nprint(Best_trial)","9f4e3f6c":"preds = np.zeros((len(testX)))\nkf = KFold(n_splits=5,random_state=48,shuffle=True)\nfor trn_idx, test_idx in kf.split(trainX[columns],trainY):\n    X_tr,X_val=trainX[columns].iloc[trn_idx],trainX[columns].iloc[test_idx]\n    y_tr,y_val=trainY.iloc[trn_idx],trainY.iloc[test_idx]\n    model = lgb.LGBMClassifier(**Best_trial)\n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False)\n    preds+=model.predict(testX[columns])\/kf.n_splits   ###### predict_proba\n    rmse=mean_squared_error(y_val, model.predict(X_val),squared=False)\n    print(rmse)","56ff811c":"model","073e84dd":"y=testY.astype(int).tolist()\ny_pred=pd.Series(preds).apply(lambda x:np.where(x>0.5,1,0)).tolist()\nprint(y[0:10])\nprint(y_pred[0:10])","f33acc4d":"from sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y,y_pred)\nprint(accuracy)","7f617e3c":"from sklearn.metrics import roc_curve, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n\ncm = confusion_matrix(y, preds>0.5)\ncm_display = ConfusionMatrixDisplay(cm).plot()\n\nfpr, tpr, _ = roc_curve(y, preds>0.5)\nroc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()","79b9e443":"* The label which shows whether the ECG is normal or abnormal. It is a categorical variable with value eiteither 0 or 1."}}