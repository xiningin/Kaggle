{"cell_type":{"59208b2f":"code","1841fc93":"code","2e52551a":"code","933ffa93":"code","af744128":"code","e545bb0c":"code","fdcb4a81":"code","ab17ba13":"code","2f9ad449":"code","28860d9f":"code","a460fa46":"code","852bc8da":"code","f6ec609b":"code","5065eca7":"code","648459fa":"code","8299f55b":"code","72de94e7":"code","8529ba34":"code","4f24effa":"code","06cf8809":"code","3e167b24":"code","d6d2735a":"code","1015688b":"code","8d5815e0":"code","d0b6f455":"code","eb59eb49":"code","6f054f99":"code","8b7aa387":"code","9daa76ef":"code","d108d144":"code","68318a46":"code","e77c98e6":"code","8e5cece9":"code","3daf60af":"code","b47dd041":"code","cec11f8c":"code","74348b00":"code","43edfbbd":"code","187d616a":"code","6a8f10ac":"code","0651ac21":"code","6a9e3559":"code","0699877c":"code","c9c9d246":"code","3777fe36":"code","f6393365":"code","a34c5a98":"code","64014660":"code","56ae0cfb":"code","bedb7825":"code","8f80b192":"code","17229d2f":"code","6c52d2a5":"code","7e54c31d":"code","79ec8284":"code","830b5a33":"code","ad0c0332":"code","a353c91a":"code","fb2e1e09":"code","a8266975":"markdown","f4e0fa98":"markdown","bc8a81e0":"markdown","94b649bc":"markdown","8a8dd68d":"markdown","f10738aa":"markdown"},"source":{"59208b2f":"!pip install -q pydot graphviz","1841fc93":"import os\nimport re\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\n\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split","2e52551a":"EPOCHS = 10\n\nTRAINING_STEPS = 1000\nVALIDATION_STEPS = 100\nEVALUATION_STEPS = 100\n\nSHUFFLE_BUFFER = 200\nBATCH_SIZE = 64\n\nIMAGE_DIM = 256\n\nATOMS_TO_COUNT = [\n    \"C\",\n    \"H\",\n    \"O\",\n    \"S\",\n    \"N\",\n    \"Br\",\n    \"F\",\n    \"Cl\",\n    \"P\",\n    \"Si\",\n    \"B\",\n    \"I\"\n]","933ffa93":"INPUT_PATH = \"..\/input\/bms-molecular-translation\"","af744128":"raw_train_df = pd.read_csv(os.path.join(INPUT_PATH, \"train_labels.csv\"))\nraw_train_df.head()","e545bb0c":"raw_train_df['ImagePath'] = raw_train_df.image_id.map(lambda x: os.path.join(x[0], x[1], x[2], x + \".png\"))","fdcb4a81":"raw_train_df.head()","ab17ba13":"raw_train_df.InChI.map(lambda x: x.split(\"=\")[1].split(\"\/\")).map(len).value_counts()","2f9ad449":"raw_train_df[raw_train_df.InChI.map(lambda x: x.split(\"=\")[1].split(\"\/\")).map(len)==11]","28860d9f":"raw_train_df.InChI[774948].split(\"=\")[1].split(\"\/\")","a460fa46":"raw_train_df.InChI.map(lambda x: x.split(\"=\")[1].split(\"\/\")[0]).value_counts()","852bc8da":"raw_train_df.InChI.map(lambda x: x.split(\"=\")[1].split(\"\/\")[1]).value_counts()","f6ec609b":"re.sub(r\"([A-Z][a-z]*)(?=[A-Z]|$)\",r\"\\g<1>1\",\"C15H18BrN5O2SSS\")","5065eca7":"train_molecule_names = raw_train_df.InChI.map(lambda x: x.split(\"=\")[1].split(\"\/\")[1])\ntrain_molecule_names = train_molecule_names.map(lambda x: re.sub(r\"([A-Z][a-z]*)(?=[A-Z]|$)\",r\"\\g<1>1\",x))\ntrain_molecule_names = train_molecule_names.map(lambda x: list(filter(None, re.split(r\"([A-Z]+[a-z\\d]+)\", x))))\ntrain_molecule_names = train_molecule_names.map(lambda x: map(lambda y: list(filter(None, re.split(r\"(\\D+)\", y))),x))\ntrain_molecule_names = train_molecule_names.map(dict)\ntrain_molecule_names = train_molecule_names.tolist()","648459fa":"names_df = pd.DataFrame(train_molecule_names)\nnames_df = names_df.fillna(0)\nnames_df","8299f55b":"names_df.describe()","72de94e7":"processed_train_df = raw_train_df.join(names_df.astype(int))","8529ba34":"processed_train_df.head()","4f24effa":"del raw_train_df\ndel names_df\ndel train_molecule_names","06cf8809":"label_max = processed_train_df.describe()[ATOMS_TO_COUNT].T['max'].values","3e167b24":"processed_train_df[ATOMS_TO_COUNT] = processed_train_df[ATOMS_TO_COUNT]\/label_max","d6d2735a":"processed_train_df.describe().T","1015688b":"train_df, val_df = train_test_split(processed_train_df, random_state=0)","8d5815e0":"def parse_image(file_path, labels, data_dir):\n    img = tf.io.read_file(os.path.join(INPUT_PATH, data_dir.numpy().decode('utf-8'), file_path.numpy().decode('utf-8')))\n    img = tf.image.decode_jpeg(img, channels=1)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    img = tf.image.resize(img, (IMAGE_DIM, IMAGE_DIM))\n    return img, labels","d0b6f455":"train_dataset = tf.data.Dataset.from_tensor_slices((train_df.ImagePath, train_df[ATOMS_TO_COUNT]))\ntrain_dataset = train_dataset.map(\n    lambda file_path, labels: tf.py_function(parse_image, [file_path, labels, \"train\"], [tf.float32, tf.float64]),\n    num_parallel_calls=tf.data.experimental.AUTOTUNE\n)\ntrain_dataset = train_dataset.shuffle(SHUFFLE_BUFFER)\ntrain_dataset = train_dataset.batch(BATCH_SIZE)\ntrain_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)","eb59eb49":"list(train_dataset.take(1))","6f054f99":"val_dataset = tf.data.Dataset.from_tensor_slices((val_df.ImagePath, val_df[ATOMS_TO_COUNT]))\nval_dataset = val_dataset.map(\n    lambda file_path, labels: tf.py_function(parse_image, [file_path, labels, \"train\"], [tf.float32, tf.float64]),\n    num_parallel_calls=tf.data.experimental.AUTOTUNE\n)\nval_dataset = val_dataset.shuffle(SHUFFLE_BUFFER)\nval_dataset = val_dataset.batch(BATCH_SIZE)\nval_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)","8b7aa387":"images, labels = list(train_dataset.take(1))[0]\nplt.figure(figsize=(40,20))\nfor i, image in enumerate(images, 1):\n    plt.subplot(4,8,i)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    plt.title(np.array(labels)[i-1]*label_max)\n    if i==32:\n        break","9daa76ef":"labels.shape, images.shape","d108d144":"feat_model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, 3, input_shape=(256, 256, 1)),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Conv2D(64, 3),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Conv2D(128, 3),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Conv2D(256, 3),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Conv2D(512, 3),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Conv2D(1024, 3),\n    tf.keras.layers.Flatten()\n], name=\"FeatureModel\")","68318a46":"feat_model.summary()","e77c98e6":"def get_regressor(symb):\n    return tf.keras.Sequential([\n        tf.keras.layers.Dense(1024, activation='relu'),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(256, activation='relu'),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(64, activation='relu'),\n        tf.keras.layers.Dense(1)\n    ], name=f\"{symb}_Regressor\")","8e5cece9":"image_input = tf.keras.Input(shape=(256,256,1), name=\"InputImage\")\n\nfeatures = feat_model(image_input)\n\noutputs = []\nfor symb in ATOMS_TO_COUNT:\n    output = get_regressor(symb)(features)\n    outputs.append(output)\n\noutputs = tf.concat(outputs, axis=1)\n\nmodel = tf.keras.Model(image_input, outputs)","3daf60af":"model.summary()","b47dd041":"tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True)","cec11f8c":"model.compile(\n    optimizer=\"adam\",\n    loss=\"mae\",\n    metrics=[\"mse\", \"mae\"]\n)","74348b00":"np.rint(model.predict(images) * label_max)","43edfbbd":"checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    'model.h5',\n    save_best_only=True\n)\n\nearly_stop_callback = tf.keras.callbacks.EarlyStopping(patience=3)","187d616a":"history = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=EPOCHS,\n    steps_per_epoch=TRAINING_STEPS,\n    validation_steps=VALIDATION_STEPS,\n    callbacks=[checkpoint_callback, early_stop_callback]\n)","6a8f10ac":"model = tf.keras.models.load_model(\"model.h5\")","0651ac21":"plt.plot(history.epoch, history.history['mse'], label=\"Train MSE\")\nplt.plot(history.epoch, history.history['val_mse'], '--', label=\"Validation MSE\")\nplt.title(\"Mean Squared Error\")\nplt.legend()","6a9e3559":"plt.plot(history.epoch, history.history['mae'], label=\"Train MAE\")\nplt.plot(history.epoch, history.history['val_mae'], '--', label=\"Validation MAE\")\nplt.title(\"Mean Absolute Error\")\nplt.legend()","0699877c":"model.evaluate(train_dataset, steps=EVALUATION_STEPS)","c9c9d246":"model.evaluate(val_dataset, steps=EVALUATION_STEPS)","3777fe36":"for images, labels in val_dataset.take(1):\n    plt.figure(figsize=(40,20))\n    preds = model.predict(images)*label_max\n    preds[preds<0] = 0\n    preds = np.rint(preds)\n    labels = labels.numpy()*label_max\n    for i, image in enumerate(images, 1):\n        plt.subplot(4,8,i)\n        plt.imshow(image)\n        plt.axis(\"off\")\n        plt.title(np.array([labels[i-1], preds[i-1]]))\n        if i==32:\n            break","f6393365":"test_df = pd.read_csv(os.path.join(INPUT_PATH, \"sample_submission.csv\"))\ntest_df['ImagePath'] = test_df.image_id.map(lambda x: os.path.join(x[0], x[1], x[2], x + \".png\"))\ntest_df.head()","a34c5a98":"test_dataset = tf.data.Dataset.from_tensor_slices(test_df.ImagePath)\ntest_dataset = test_dataset.map(\n    lambda file_path: tf.py_function(parse_image, [file_path, \"\", \"test\"], [tf.float32]),\n    num_parallel_calls=tf.data.experimental.AUTOTUNE\n)\ntest_dataset = test_dataset.batch(BATCH_SIZE)\ntest_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)","64014660":"for images in test_dataset.take(1):\n    plt.figure(figsize=(40,20))\n    labels = model.predict(images)*label_max\n    labels[labels<0] = 0\n    labels = np.rint(labels)\n    for i, image in enumerate(images[0], 1):\n        plt.subplot(4,8,i)\n        plt.imshow(image)\n        plt.axis(\"off\")\n        plt.title(np.array(labels)[i-1])\n        if i==32:\n            break","56ae0cfb":"preds = model.predict(test_dataset, verbose=1)*label_max","bedb7825":"preds = np.rint(preds)","8f80b192":"preds[preds<0] = 0","17229d2f":"preds.shape","6c52d2a5":"test_labels = pd.DataFrame(preds, columns=ATOMS_TO_COUNT).astype(int)","7e54c31d":"test_labels","79ec8284":"test_df","830b5a33":"submission = pd.DataFrame(list(\n    map(\n        lambda y: \"InChI=1S\/\"+y,\n        map(\n            lambda x: \"\".join([f\"{c}{x[c] if x[c]>1 else ''}\" for c in x if x[c]]),\n            test_labels.to_dict(orient=\"records\")\n        )\n    )\n), columns=[\"InChI\"]).join(test_df.image_id)[['image_id', 'InChI']]","ad0c0332":"submission.to_csv(\"submission.csv\", index=False)","a353c91a":"submission.shape","fb2e1e09":"submission","a8266975":"## Prediction","f4e0fa98":"### Normalization","bc8a81e0":"### Train Test Split","94b649bc":"# Dataset","8a8dd68d":"# Hyperparameter","f10738aa":"# Model"}}