{"cell_type":{"cf8a976d":"code","997cd5e6":"code","d19a5532":"code","6605cad1":"code","4dab7293":"code","ce601344":"code","d7d27448":"code","233369fa":"code","59bd9f3e":"code","ac70267c":"code","98926977":"code","504792a4":"code","47cdb083":"code","bcc5e1be":"code","f045617c":"code","922e7885":"markdown","b3135638":"markdown","2dd12437":"markdown","0833b114":"markdown","ccc04e0c":"markdown","4cbb65b4":"markdown","2bfe6ca8":"markdown","c02d1e65":"markdown","536d75ad":"markdown","e7ba5c2e":"markdown","ea30a126":"markdown","2342040c":"markdown","549c16b3":"markdown","aebb0f94":"markdown","9fb8344d":"markdown"},"source":{"cf8a976d":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\n\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nfrom keras.optimizers import SGD\nfrom keras.utils import to_categorical\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","997cd5e6":"path = '..\/input\/alzheimer-features\/alzheimer.csv'\ndf = pd.read_csv(path)\n\ndf['MMSE'] = df['MMSE'].fillna(0)\ndf['SES'] = df['SES'].fillna(0)\n\n# pick only demented or nondemented\ndf = df[df['Group'].isin(['Demented','Nondemented'])]\n\ndf.head()","d19a5532":"group_to_idx = {'Nondemented': 0, 'Demented': 1}\nidx_to_group = {group_to_idx[k]:k for k in group_to_idx.keys()}\n\nsex_to_idx = {'M': 0, 'F': 1}\nidx_to_sex = {sex_to_idx[k]:k for k in sex_to_idx.keys()}\n\ndf.replace(group_to_idx, inplace=True)\ndf.replace(sex_to_idx, inplace=True)\ndf = df.reset_index()","6605cad1":"df.describe().T","4dab7293":"scaler = StandardScaler()\ndf[['Age', 'EDUC', 'SES', 'MMSE', 'eTIV']] = scaler.fit_transform(df[['Age', 'EDUC', 'SES', 'MMSE', 'eTIV']])","ce601344":"plt.figure(figsize=(14,8))\n\ncorr = df.corr()\n\nsns.heatmap(corr, \n        cmap=\"Blues\", annot=True,\n        xticklabels=corr.columns,\n        yticklabels=corr.columns)","d7d27448":"pca = PCA(n_components=2)\nX_tr = pca.fit_transform(df[['CDR','SES', 'ASF']])","233369fa":"group_one = df[df['Group'] == 1].index\ngroup_zero = df[df['Group'] == 0].index\n\nplt.figure(figsize=(14,8))\nblue, _ = plt.plot(X_tr[group_one], 'bo', label='Nondemented')\nred, _ = plt.plot(X_tr[group_zero], 'ro', label='Demented')\nplt.legend(handles=[red, blue])\nplt.show()","59bd9f3e":"# one hot encoding\ny = to_categorical(df['Group'].values)\n\n# train\/test data split\nX_train, X_test, y_train, y_test = train_test_split(\n                                    X_tr, y, test_size=0.5, random_state=42)","ac70267c":"def base_autoencoder(X_train, X_test):\n    model = Sequential()\n    model.add(Dense(10, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(2, activation='linear'))\n    \n    model.compile(loss='mse', optimizer=SGD(lr=0.01, momentum=0.9))\n    model.fit(X_train, X_test, epochs=100, verbose=0)\n    \n    train_mse = model.evaluate(X_train, X_train, verbose=0)\n    test_mse = model.evaluate(X_test, X_test, verbose=0)\n    print('> reconstruction error train=%.3f, test=%.3f' % (train_mse, test_mse))\n    return model","98926977":"def evaluate(model, X_train, y_train, X_test, y_test):\n    # remember the current output layer\n    output_layer = model.layers[-1]\n    \n    # remove the output layer\n    model.pop()\n    # mark all remaining layers as non-trainable\n    for layer in model.layers:\n        layer.trainable = False\n        \n    model.add(Dense(2, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9), metrics=['accuracy'])\n    model.fit(X_train, y_train, epochs=100, verbose=0)\n    \n    # evaluate model\n    _, train_acc = model.evaluate(X_train, y_train, verbose=0)\n    _, test_acc = model.evaluate(X_test, y_test, verbose=0)\n    \n    # put the model back together\n    model.pop()\n    model.add(output_layer)\n    model.compile(loss='mse', optimizer=SGD(lr=0.01, momentum=0.9))\n    return train_acc, test_acc","504792a4":"scores = dict()\n\n# create base encoder\nmodel = base_autoencoder(X_train, X_test)\n\n# evaluate\ntrain_acc, test_acc = evaluate(model, X_train, y_train, X_test, y_test)\nprint('> lassifier accuracy layers=%d, train=%.3f, test=%.3f' % (len(model.layers), train_acc, test_acc))\nscores[len(model.layers)] = (train_acc, test_acc)","47cdb083":"def add_layer(model, X_train, X_test):\n    # remember the current output layer\n    output_layer = model.layers[-1]\n    \n    # remove the output layer\n    model.pop()\n    # mark all remaining layers as non-trainable\n    for layer in model.layers:\n        layer.trainable = False\n        \n    # add a new hidden layer\n    model.add(Dense(10, activation='relu', kernel_initializer='he_uniform'))\n    model.add(output_layer)\n    \n    # fit model\n    model.fit(X_train, X_test, epochs=100, verbose=0)\n    \n    # evaluate reconstruction loss\n    train_mse = model.evaluate(X_train, X_train, verbose=0)\n    test_mse = model.evaluate(X_test, X_test, verbose=0)\n    \n    print('> reconstruction error train=%.3f, test=%.3f' % (train_mse, test_mse))","bcc5e1be":"n_layers = 5\n\nfor _ in range(n_layers):\n    # add layer\n    add_layer(model, X_train, X_test)\n    # evaluate model\n    train_acc, test_acc = evaluate(model, X_train, y_train, X_test, y_test)\n    print('> classifier accuracy layers=%d, train=%.3f, test=%.3f' % (len(model.layers), train_acc, test_acc))\n    scores[len(model.layers)] = (train_acc, test_acc)","f045617c":"keys = list(scores.keys())\nplt.figure(figsize=(14,8))\nplt.plot(keys, [scores[k][0] for k in keys], label='train', marker='.')\nplt.plot(keys, [scores[k][1] for k in keys], label='test', marker='.')\nplt.legend()\nplt.show()","922e7885":"## Standard Scaler","b3135638":"Machine Learning Mastery - [Greedy layer wise tutorial](https:\/\/machinelearningmastery.com\/greedy-layer-wise-pretraining-tutorial\/)","2dd12437":"<h1 id=\"dataset\" style=\"color:#01499b; background:white; border:0.5px dotted #01499b;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","0833b114":"<h1 id=\"base\" style=\"color:#01499b; background:white; border:0.5px dotted #01499b;\"> \n    <center>Auto-Encoder\n        <a class=\"anchor-link\" href=\"#base\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","ccc04e0c":"<h1 id=\"evaluate\" style=\"color:#01499b; background:white; border:0.5px dotted #01499b;\"> \n    <center>Evaluate\n        <a class=\"anchor-link\" href=\"#evaluate\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","4cbb65b4":"<h1 id=\"layer\" style=\"color:#01499b; background:white; border:0.5px dotted #01499b;\"> \n    <center>Add-Layer\n        <a class=\"anchor-link\" href=\"#layer\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","2bfe6ca8":"# Feature engineering","c02d1e65":"## Describe features","536d75ad":"<h1 id=\"reference\" style=\"color:#01499b; background:white; border:0.5px dotted #01499b;\"> \n    <center>Reference\n        <a class=\"anchor-link\" href=\"#reference\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","e7ba5c2e":"## PCA dimension reduction","ea30a126":"## Categorical encoding","2342040c":"## Correlation matrix","549c16b3":"<div width=\"100%\">\n    <img width=\"100%\" src=\"https:\/\/storage.googleapis.com\/kaggle-datasets-images\/1242233\/2072411\/724eb55eb9ef7e89e2b6a9308acb30cf\/dataset-cover.jpg\" \/>\n<\/div>","aebb0f94":"## Load data","9fb8344d":"<h1 id=\"evaluate\" style=\"color:#01499b; background:white; border:0.5px dotted #01499b;\"> \n    <center>Evaluate\n        <a class=\"anchor-link\" href=\"#evaluate\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>"}}