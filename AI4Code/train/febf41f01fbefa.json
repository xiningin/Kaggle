{"cell_type":{"53da5e4c":"code","6a21fe81":"code","24b4677f":"code","a28b47f6":"code","01da414f":"code","122c5029":"code","512d308a":"code","c381f48d":"code","0c3331ae":"code","235069c6":"code","587c234a":"code","c2b07730":"code","16210814":"code","9eaf29a4":"code","053480a7":"code","9ba1d98a":"code","168fb06d":"code","addbe4b4":"code","9faacad0":"code","d9e88291":"code","a52fc3f6":"code","bf823749":"code","29a5a708":"code","fb1581e6":"code","9b9ab48c":"code","09021e98":"code","be8e3705":"code","bd3049f7":"markdown"},"source":{"53da5e4c":"import numpy as np # linear algebra\nimport pandas as pd","6a21fe81":"df_train = pd.read_csv('..\/input\/song-popularity-prediction\/train.csv')\ndf_train","24b4677f":"df_train = df_train.set_index('id')\ndf_train.head()","a28b47f6":"df_train.isnull().sum()","01da414f":"df_train.isnull().sum()\/len(df_train)","122c5029":"df_train.mean()","512d308a":"df_train = df_train.fillna(df_train.mean())\ndf_train","c381f48d":"df_test = pd.read_csv('..\/input\/song-popularity-prediction\/test.csv')\ndf_test","0c3331ae":"df_test = df_test.set_index('id')\ndf_test.head()","235069c6":"df_test.isnull().sum()\/len(df_test)","587c234a":"df_test = df_test.fillna(df_test.mean())\ndf_test","c2b07730":"X = df_train.drop('song_popularity', axis=1)\nX.head()","16210814":"y = df_train['song_popularity']\ny","9eaf29a4":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score","053480a7":"import lightgbm as lgb","9ba1d98a":"import optuna","168fb06d":"def objective(trial):\n    \n    train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.20, stratify = y)\n    dtrain = lgb.Dataset(train_x, label=train_y)\n    dtest = lgb.Dataset(valid_x, label=valid_y)\n    param = {\n        #'objective': 'binary',\n        #'metric': \"auc\",\n        'verbosity': -1,\n        \"num_threads\": -1,\n        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10000]),\n        \"learning_rate\": trial.suggest_float('learning_rate',0.01,0.2),\n        'boosting_type': trial.suggest_categorical('boosting',['gbdt']),\n        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'max_depth': trial.suggest_int('max_depth', 2,15),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7)\n    }\n    \n    #pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n    #callbacks=[optuna.integration.LightGBMPruningCallback(trial, \"binary_logloss\")]\n    \n    gbm = lgb.train(param, dtrain, valid_sets= [dtest])\n    y_pred = gbm.predict(valid_x)\n    test_preds = [np.argmax(x) for x in y_pred]\n    roc_score = roc_auc_score(valid_y, test_preds)\n    return roc_score","addbe4b4":"study = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=10, timeout=1200)","9faacad0":"print(\"Number of finished trials: {}\".format(len(study.trials)))\n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Value: {}\".format(trial.value))","d9e88291":"for key, value in study.best_params.items():\n    print(f\"\\t\\t{key}: {value}\")","a52fc3f6":"train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.20, stratify = y)\ndtrain = lgb.Dataset(train_x, label=train_y)\ndtest = lgb.Dataset(valid_x, label=valid_y)\n\nparams = {\n        'verbosity': -1,\n        \"num_threads\": -1,\n        'n_estimators': 10000,\n        'learning_rate': 0.10617638691056702,\n        'boosting': 'gbdt',\n        'lambda_l1': 1.2069380218573515e-06,\n        'lambda_l2': 0.0001800859720099032,\n        'num_leaves': 105,\n        'max_depth': 6,\n        'min_child_samples': 84,\n        'min_data_in_leaf': 500,\n        'min_gain_to_split': 2.9684627594334008,\n        'feature_fraction': 0.7964307987967532,\n        'bagging_fraction':  0.9490701090949819,\n        'bagging_freq': 1\n    }\n\ngbm = lgb.train(params, dtrain, valid_sets = [dtest])\ny_pred = gbm.predict(valid_x)\ntest_preds = [np.argmax(x) for x in y_pred]\nprint(roc_auc_score(valid_y, test_preds))","bf823749":"df_test","29a5a708":"y_pred = gbm.predict(df_test)\ny_pred","fb1581e6":"y_pred.shape","9b9ab48c":"df_subb = pd.read_csv('..\/input\/song-popularity-prediction\/sample_submission.csv')\ndf_subb","09021e98":"df_subb.song_popularity = y_pred\ndf_subb","be8e3705":"df_subb.to_csv('.\/sample_subb.csv', index=False)","bd3049f7":"# LG boost"}}