{"cell_type":{"bd32f8b3":"code","20f441d8":"code","95e8498c":"code","3ea35446":"code","074b2550":"code","65a11450":"code","2ce8a419":"code","c1d459e2":"code","fb9a63d1":"code","8e69396a":"code","11f6a49e":"code","eaad947b":"code","4bd999da":"code","6a9c8c89":"code","fccba9e0":"code","1b8cb95b":"code","7b4227b9":"code","5fb885cc":"code","f4a18b74":"code","a3425b4b":"code","90bd8043":"code","6756732b":"code","6eb1ade9":"code","83532a66":"code","9c12d6df":"code","4d9921f5":"code","372340bd":"code","b9c98c0a":"markdown","bc544d11":"markdown","326b3575":"markdown","adcf1e59":"markdown","69469866":"markdown","76b0f674":"markdown","a1c469da":"markdown","a2461cd2":"markdown","82b7b1c5":"markdown","b7d08666":"markdown","0eeea02b":"markdown","4f1567c6":"markdown","dcaff38a":"markdown","3f909b16":"markdown","25f3ff51":"markdown","157b7d79":"markdown","614f3139":"markdown","d8dcbb0a":"markdown","9a3b09c7":"markdown","edc304d8":"markdown","19009fc6":"markdown","f85770ef":"markdown","5f244763":"markdown"},"source":{"bd32f8b3":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sb\n\nTRAIN_DATA_PATH = \"\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv\"\nTEST_DATA_PATH = \"\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv\"\n\nraw_train_data = pd.read_csv(TRAIN_DATA_PATH)\nraw_test_data = pd.read_csv(TEST_DATA_PATH)","20f441d8":"print(f\"Train Set Shape: {raw_train_data.shape}, Missing Data: {raw_train_data.isnull().values.any()}\")\nprint(f\"Test Set Shape: {raw_test_data.shape}, Missing Data: {raw_test_data.isnull().values.any()}\\n\")\n\nprint(raw_train_data.info())\n\nraw_train_data.head(3)","95e8498c":"def label_decoder(category):\n    \n    if category == 0:\n        return \"T-shirt\/top\"\n    elif category == 1:\n        return \"Trouser\"\n    elif category == 2:\n        return \"Pullover\"\n    elif category == 3:\n        return \"Dress\"\n    elif category == 4:\n        return \"Coat\"\n    elif category == 5:\n        return \"Sandal\"\n    elif category == 6:\n        return \"Shirt\"\n    elif category == 7:\n        return \"Sneaker\"\n    elif category == 8:\n        return \"Bag\"\n    elif category == 9:\n        return \"Ankle boot\"","3ea35446":"# create temporary DataFrames for visualization purposes\n# extract the pixel map of first ten Fashion MNIST images\nplot_ten_df = raw_train_data.drop(\"label\", axis=1).iloc[0:10, :]\n# extract the labels and interpret them with the function defined above for the first ten clothes\nplot_ten_labels_df = raw_train_data[\"label\"].apply(label_decoder)\n\n# set figure size\nplt.rcParams['figure.figsize'] = [15, 15]\n\n# visualize the first 10 Fashion MNIST images in the train set \nfor index in range(10):\n    plt.subplot(1, 10, index+1)\n    # reshape pixel arragement to 28 x 28\n    clothes_array = np.asarray(plot_ten_df.iloc[index]).reshape(28, 28)\n    plt.imshow(clothes_array, cmap=\"binary\")\n    plt.title(plot_ten_labels_df[index], fontsize=16)\n    plt.axis(\"off\")","074b2550":"# separate the pixels and the label\n# cast int pixels to float\nX_train = np.array(raw_train_data.drop(\"label\", axis=1))\ny_train = np.array(raw_train_data[\"label\"])\n\nX_test = np.array(raw_test_data.drop(\"label\", axis=1))\ny_test = np.array(raw_test_data[\"label\"])\n\n# divide by 255.0 to normalize \n# reshape arrays to 28 x 28 to match the pixel format\nX_train = (X_train \/ 255.0).reshape(60000, 28, 28)\nX_test = (X_test \/ 255.0).reshape(10000, 28, 28) ","65a11450":"from sklearn.model_selection import train_test_split\n\n# random_state=42 for reproducibility\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n\n# verify the set sizes are as expected\nprint(f\"X_train Shape: {X_train.shape}, y_train Shape: {y_train.shape}\")\nprint(f\"X_val Shape: {X_val.shape}, y_val Shape: {y_val.shape}\")\nprint(f\"X_test Shape: {X_test.shape}, y_test Shape: {y_test.shape}\")","2ce8a419":"import tensorflow as tf\n\n# random_seed=42 for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n# build the MLP architecture\nmlp_model = tf.keras.models.Sequential([\n                tf.keras.layers.Flatten(input_shape=[28, 28]),\n                tf.keras.layers.Dense(300, activation=\"relu\"),\n                tf.keras.layers.BatchNormalization(),\n                tf.keras.layers.Dropout(0.5),\n                tf.keras.layers.Dense(300, activation=\"relu\"),\n                tf.keras.layers.BatchNormalization(),\n                tf.keras.layers.Dropout(0.5),\n                tf.keras.layers.Dense(150, activation=\"relu\"),\n                tf.keras.layers.Dense(10, activation=\"softmax\")\n])\n\n# compile MLP model\nmlp_model.compile(loss=\"sparse_categorical_crossentropy\",\n                  optimizer=\"adam\",\n                  metrics=[\"accuracy\"])\n\n# display a breakdown of the MLP model\nmlp_model.summary()","c1d459e2":"# visualkeras is not available on Kaggle\n#import visualkeras\n\n#print(\"Yellow: Flatten\\nRed: Dense Layer\")\n#visualkeras.layered_view(mlp_model)","fb9a63d1":"# define an early stopping callback, monitoring the validation cross-entropy loss function\nval_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n\n# define a performance scheduling callback, monitoring the validation cross-entropy loss function\nlr_monitor = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5)\n\n# train the MLP\n# can set epochs to 1000 --> the model will stop training given our callbacks --> train on google colab GPU to speed up training\n# epochs is set to 1 here in the interest of run time \nmlp_training_progress = mlp_model.fit(X_train, y_train, epochs=1, verbose=0, batch_size=128,\n                                      validation_data=(X_val, y_val),\n                                      callbacks=[val_stop, lr_monitor])","8e69396a":"# define a function to plot neural network training history\ndef training_plots(training_progress: dict, model_name: str):\n    \n    sb.set_theme()\n    plt.rcParams['figure.figsize'] = [20, 8]\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(training_progress[\"accuracy\"], \"g\", label=\"Train Accuracy\")\n    plt.plot(training_progress[\"val_accuracy\"], \"b\", label=\"Validation Accuracy\")\n    plt.title(f\"{model_name} Accuracy Plot\", fontsize=16)\n    plt.xlabel(\"Epoch\", fontsize=16)\n    plt.ylabel(\"Accuracy\", fontsize=16)\n    plt.legend(fontsize=16)\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(training_progress[\"loss\"], \"g\", label=\"Train Loss\")\n    plt.plot(training_progress[\"val_loss\"], \"b\", label=\"Validation Loss\")\n    plt.title(f\"{model_name} Cross-Entropy Loss Plot\", fontsize=16)\n    plt.xlabel(\"Epoch\", fontsize=16)\n    plt.ylabel(\"Loss\", fontsize=16)\n    plt.legend(fontsize=16)\n    \ntraining_plots(mlp_training_progress.history, \"MLP\")\n# plots do not show anything because epochs was set to 1 but training with epochs 1000 will show the learning curves","11f6a49e":"mlp_test_accuracy = mlp_model.evaluate(X_test, y_test, verbose=0)[1]\nprint(mlp_test_accuracy)","eaad947b":"from functools import partial\n\n# random_seed=42 for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nConvLayer = partial(tf.keras.layers.Conv2D, kernel_size=3, strides=1, activation=\"relu\", padding=\"SAME\")\nPoolLayer = partial(tf.keras.layers.MaxPooling2D, pool_size=2, strides=2, padding=\"VALID\")\n\n# build the CNN architecture\ncnn_model = tf.keras.models.Sequential([\n                ConvLayer(filters=64, kernel_size=5, strides=2, input_shape=[28, 28, 1]),\n                PoolLayer(),\n                ConvLayer(filters=128),\n                tf.keras.layers.BatchNormalization(),\n                ConvLayer(filters=128),\n                tf.keras.layers.BatchNormalization(),\n                tf.keras.layers.Dropout(0.5),\n                PoolLayer(),\n                ConvLayer(filters=256),\n                tf.keras.layers.BatchNormalization(),\n                ConvLayer(filters=256),\n                tf.keras.layers.BatchNormalization(),\n                tf.keras.layers.Dropout(0.5),\n                PoolLayer(),\n                tf.keras.layers.Flatten(),\n                tf.keras.layers.Dense(128, activation=\"relu\"),\n                tf.keras.layers.BatchNormalization(),\n                tf.keras.layers.Dropout(0.5),\n                tf.keras.layers.Dense(64, activation=\"relu\"),\n                tf.keras.layers.BatchNormalization(),\n                tf.keras.layers.Dropout(0.5),\n                tf.keras.layers.Dense(10, activation=\"softmax\")\n])\n\n# compile CNN model\ncnn_model.compile(loss=\"sparse_categorical_crossentropy\",\n                  optimizer=\"adam\",\n                  metrics=[\"accuracy\"])\n\n# display a breakdown of the CNN model\ncnn_model.summary()","4bd999da":"# visualkeras is not available on Kaggle\n\n#print(\"Yellow: Convolutional Layer\\nRed: Max Pooling Layer\\nTurquoise: Flatten\\nBlue: Dense Layer\\nDark Green: Dropout Layer\")\n#visualkeras.layered_view(cnn_model)","6a9c8c89":"X_train = X_train.reshape(51000, 28, 28, 1)\nX_val = X_val.reshape(9000, 28, 28, 1)\nX_test = X_test.reshape(10000, 28, 28, 1) ","fccba9e0":"# train the CNN\n# can set epochs to 1000 --> the model will stop training given our callbacks --> train on google colab GPU to speed up training\n# epochs is set to 1 here in the interest of run time \ncnn_training_progress = cnn_model.fit(X_train, y_train, epochs=1, verbose=0, batch_size=128,\n                                      validation_data=(X_val, y_val),\n                                      callbacks=[val_stop, lr_monitor])","1b8cb95b":"training_plots(cnn_training_progress.history, \"CNN\")\n# plots do not show anything because epochs was set to 1 but training with epochs 1000 will show the learning curves","7b4227b9":"cnn_test_accuracy = cnn_model.evaluate(X_test, y_test, verbose=0)[1]\nprint(cnn_test_accuracy)","5fb885cc":"# random_seed=42 for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n\nLeNet5ConvLayer = partial(tf.keras.layers.Conv2D, kernel_size=5, strides=1, activation=\"relu\", padding=\"VALID\")\nLeNet5PoolLayer = partial(tf.keras.layers.AveragePooling2D, pool_size=2, strides=2, padding=\"VALID\")\n\n# build the LeNet-5 architecture\nLeNet5_model = tf.keras.models.Sequential([\n                    LeNet5ConvLayer(filters=6, input_shape=[32, 32, 1], name=\"C1\"),\n                    LeNet5PoolLayer(name=\"S2\"),\n                    LeNet5ConvLayer(filters=16, name=\"C3\"),\n                    LeNet5PoolLayer(name=\"S4\"),\n                    LeNet5ConvLayer(filters=120, name=\"C5\"),\n                    tf.keras.layers.Flatten(),\n                    tf.keras.layers.Dense(84, activation=\"relu\", name=\"F6\"),\n                    tf.keras.layers.Dense(10, activation=\"softmax\", name=\"Output\")                  \n])\n\n# paper uses learning rate 0.005\nLeNet5_optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n# compile LeNet-5 model\nLeNet5_model.compile(loss=\"sparse_categorical_crossentropy\",\n                     optimizer=LeNet5_optimizer,\n                     metrics=[\"accuracy\"])\n\n# display a breakdown of the CNN model\nLeNet5_model.summary()","f4a18b74":"# visualkeras is not available on Kaggle\n#print(\"Yellow: Convolutional Layer\\nRed: Average Pooling Layer\\nGreen: Flatten\\nBlue: Dense Layer\")\n#visualkeras.layered_view(LeNet5_model)","a3425b4b":"X_train_LeNet5 = np.pad(X_train.reshape(51000, 28, 28), ((0,0), (2,2), (2,2)), \"constant\").reshape(51000, 32, 32, 1)\nX_val_LeNet5 = np.pad(X_val.reshape(9000, 28, 28), ((0,0), (2,2), (2,2)), \"constant\").reshape(9000, 32, 32, 1)\nX_test_LeNet5 = np.pad(X_test.reshape(10000, 28, 28), ((0,0), (2,2), (2,2)), \"constant\").reshape(10000, 32, 32, 1)","90bd8043":"# train the LeNet-5 CNN model\nLeNet5_training_progress = LeNet5_model.fit(X_train_LeNet5, y_train, epochs=10, verbose=0, batch_size=32,\n                                            validation_data=(X_val_LeNet5, y_val))","6756732b":"training_plots(LeNet5_training_progress.history, \"LeNet-5\")","6eb1ade9":"LeNet5_test_accuracy = LeNet5_model.evaluate(X_test_LeNet5, y_test, verbose=0)[1]\nprint(LeNet5_test_accuracy)","83532a66":"from sklearn.metrics import confusion_matrix\n\ndef confusion_matrix_plot(model_name: str, y_test: np.array, y_pred: np.array, labels: list, plot_colour: str):\n\n  conf_matrix = confusion_matrix(y_test, y_pred)\n  sb.heatmap(conf_matrix, annot=True, fmt=\"d\", xticklabels=labels, yticklabels=labels, cmap=plot_colour, cbar=False)\n  \n  plt.title(f\"{model_name} Confusion Matrix\", fontsize=18)\n  plt.xlabel(\"Predicted Label\", fontsize=14)\n  plt.ylabel(\"True Label\", fontsize=14)\n","9c12d6df":"y_pred = cnn_model.predict(X_test)\n# output is the probabilities a given Fashion MNIST clothing corresponds to each classification\n# take the highest probability as the predicted classification\ny_pred = np.argmax(y_pred, axis=1)\n\nlabel_names = [\"T-shirt\/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n\nconfusion_matrix_plot(\"CNN\", y_test, y_pred, label_names, \"BuGn\")","4d9921f5":"from sklearn.metrics import classification_report\n\nprint(f\" CNN Model Test Accuracy: {round(cnn_test_accuracy, 3)}\\n\")\n\nprint(classification_report(y_test, y_pred, target_names=label_names))","372340bd":"tshirt_top_df = raw_test_data[raw_test_data[\"label\"] == 0].drop(\"label\", axis=1)\nshirt_df = raw_test_data[raw_test_data[\"label\"] == 6].drop(\"label\", axis=1)\n\n# set figure size\nplt.rcParams['figure.figsize'] = [20, 20]\n\nfig = plt.figure()\n\nfor index in range(20):\n\n  fig.add_subplot(10, 5, index+1)\n  if index < 10:\n    plt.imshow(np.asarray(tshirt_top_df.iloc[index]).reshape(28, 28), cmap=\"binary\")\n    plt.title(\"T-shirt\/top\")\n  else:\n    plt.imshow(np.asarray(shirt_df.iloc[index]).reshape(28, 28), cmap=\"binary\")\n    plt.title(\"Shirt\")\n\n  plt.axis(\"off\")\n","b9c98c0a":"The below cell block creates a visual of the MLP.","bc544d11":"A quick look at the dataset confirms the following:\n\n1) There are 784 pixels corresponding to a 28 x 28 pixel image\n\n2) The labels map to integers [0,9]\n\nLet's define a function to decode the integers to be used when displaying the Fashion MNIST images.","326b3575":"Let's next define some call backs to be used during model training. Notably, Early Stopping and ReduceLROnPlateau (Reduce Learning Rate on Plateau) will be used with the following initilizations:\n\n* Early Stopping\n\nMonitor the loss on the validation set. If it doesn't drop following 10 epochs, stop training and restore the neuron weights which gave the best performance\n\n* ReduceLROnPlateau\n\nMonitor the loss on the validation set. If it doesn't drop following 5 epochs, reduce the learning rate by half\n\nFinally, the number of epochs is set to 1000 for training (which is really high) but will not matter as Early Stopping will halt the model training.","adcf1e59":"Referring to the confusion matrix, it is evident that the model struggles most notably in differentiating between T-shirt\/top and Shirts. This is supported quantitatively by the classification report where the performance metrics fall below 0.90 only in the T-shirt\/top and Shirt cases. Let's take a look at examples of each.","69469866":"## LeNet-5 \n\nThe final model to explore is LeNet-5 which is a well known CNN architecture with historical significance. The original paper is linked below:\n\nhttp:\/\/yann.lecun.com\/exdb\/publis\/pdf\/lecun-01a.pdf\n\nRecently, a conference paper using LeNet-5 was submitted and cited to achieve exceptional accuracy on the Fashion MNIST dataset. The following model exploration was inspired by this paper linked below:\n\nhttps:\/\/ieeexplore.ieee.org\/document\/9047776\n\nThe architecture follows exactly as described in the above papers.\n","76b0f674":"The below cell block creates a visual of the CNN.","a1c469da":"Unforunately, LeNet-5 doesn't seem to perform as well as the previous CNN but this is of course not conclusive as different seeds will change performance and also different data splittings.","a2461cd2":"The model expands the 28 x 28 pixel to 32 x 32 pixel images. We need to adjust the feature matrices to reflect this.","82b7b1c5":"## Data Visualization\n\nImport standard data handling and visualization libraries.","b7d08666":"Let's next generate a classification report to obtain performance metrics.","0eeea02b":"The CNN will be trained witht he same call backs as the MLP (Early Stopping and Reduce Learning Rate on Plateau)","4f1567c6":"# Fashion MNIST Neural Network Architectures Exploration\n\n\n## Multiclass Classifier\n\nThis Jupyter notebook builds various neural networks using Keras for the Fashion MNIST dataset. \n\n## Dataset\n\nhttps:\/\/www.kaggle.com\/zalando-research\/fashionmnist\n\n\n## Objective\n\nExplore the performances of different neural network architectures on the Fashion MNIST set.","dcaff38a":"The MLP model achieves 0.89-0.90 accuracy on the test set (if the epochs parameter was set to 1000). Let's see if we can improve this using a Convolutional Neural Network (CNN) which is generally better at image recognition and classification.","3f909b16":"No call backs were used and the model was trained in 10 epochs.","25f3ff51":"## Multilayer Perceptron (MLP)\n\nThe first model to be trained is a Multilayer Perceptron (MLP) which is a fully connected neural network. The architecture will be relatively simple but does incorporate batch normalization and dropout. Batch normalization helps mitigate for vanishing gradients and overfitting by mean subtracting the inputs and normalizing. Dropout also mitigates model overfitting by inactivating neurons at a specified probability during an epoch. Generally, these two techniques improve model generalizability but may have a reduced effect in the MLP architecture here as the neural network is relatively shallow (ex. deeper neural networks suffer from vanishing gradients more prominently).","157b7d79":"## Data Splitting: Validation Set Generation\n\nGenerate a validation set to be used to control for overfitting. ","614f3139":"The pixel matrices need to be reshaped to encompass the image size (28 x 28 pixel) to feed into the CNN.","d8dcbb0a":"The cell block below creates a visual of LeNet-5.","9a3b09c7":"The accuracy improved (~ 0.93 if epochs is set to 1000)! This is not a complete surprise because CNNs are better suited for the Fashion MNIST task than MLPs. Let's next explore a specific CNN architecture.","edc304d8":"It is interesting that T-shirts\/tops can have logos in the top right corner. Moreover, they sometimes possess graphics in the middle (like a graphic t-shirt). This is in contrast to shirts which only have minimal patterns, if any, and could be exploited to enhance the precision and recall of these two categories. A potential idea is to perform some data augmentation to steer the CNN to learn using the logos and\/or t-shirt graphics. ","19009fc6":"## CNN Confusion Matrix and Performance Metrics\n\nFinally, we will take the best performing model given the current seed\/run and visualize and quantify its classification performance. Define a function to plot confusion matrices.","f85770ef":"Ensure the training and test sets do not have missing data points and that the split is as expected (train\/test 60,000\/10,000).","5f244763":"## Convolutional Neural Network (CNN)\n\nThe second model to be trained is a general Convolutional Neural Network (CNN) which is particularly well suited for image classification tasks. In contrast to MLPs, CNNs are not fully connected. Key architecture features of CNNs include convolutional and pooling layers. Convolutional layers allow neurons to learn snapshots of an image which is placed through a filter to construct complex patterns. Finally, outputs are placed through a pooling layer which \"pools\" outputs together and shrinks the image to reduce computational burden. The CNN architecture used will be much deeper than the MLP earlier and therefore batch normalization and dropout become more important to mitigate vanishing gradients and overfitting."}}