{"cell_type":{"75dbf09a":"code","c64c2bfc":"code","d38fe08e":"code","2341bbab":"code","5f5e1a0c":"code","b2e3de61":"code","61e716c4":"code","f410a337":"code","844b5e2e":"code","a8cdb21b":"code","af38f82d":"code","72ce3879":"code","c9caf919":"code","ea30df3c":"code","034f5f7a":"code","5ac8487c":"code","7ecb7e0b":"code","bbaf4518":"code","168ed9d4":"code","2f358a12":"code","5f2aea0e":"code","c96542b3":"code","e50d6115":"code","a564dd5e":"code","ac68825b":"code","abc1a96f":"code","5ff40ff5":"code","f632af19":"code","8c371328":"code","84e6162a":"code","0d8fc1e3":"code","e5e22d7b":"code","756a3fcb":"code","773d0b44":"code","75e6d1e5":"code","edd9f466":"code","3899d4ad":"code","46bf0317":"code","b4adb70c":"code","74c1cee9":"code","0059c1d2":"code","742ed222":"code","f935a1d7":"code","b612d0bb":"code","0ff545d3":"code","dc27da86":"code","9f14b6c3":"code","eb1043bd":"code","2458ba53":"code","73a8c29a":"code","74a0a86a":"code","de735cd7":"code","fe87ecdd":"code","9c29f0b0":"code","e65a48fe":"code","6268d452":"code","600d0f6d":"code","b84e2a3c":"code","e12ce593":"code","46126ed3":"code","27bda129":"code","76b6973c":"code","69c1dc31":"code","eceb42a9":"code","40bb7f2b":"code","31e81b00":"code","e75ffee2":"code","b5381ce9":"code","1d5182e2":"markdown","c84f821e":"markdown","aaf1b04c":"markdown","10c83e54":"markdown","2e221357":"markdown","277e8f66":"markdown","97577ef5":"markdown","e99d4574":"markdown","e2675132":"markdown","b960052e":"markdown","645f6701":"markdown","ddec67a7":"markdown","b8277038":"markdown","5cafad19":"markdown","802c4219":"markdown","809549b4":"markdown","3aa23a29":"markdown","528a15a5":"markdown","574efe0a":"markdown","a1e71b29":"markdown","cb748482":"markdown","be0983ac":"markdown","42f056fc":"markdown","8eee7098":"markdown","98783c05":"markdown","a8e08c34":"markdown","b516ad83":"markdown","bcda9523":"markdown","dfb72a12":"markdown"},"source":{"75dbf09a":"from IPython.display import HTML\n","c64c2bfc":"%config IPCompleter.greedy=True\nimport pandas as pd\nfrom collections import Counter\nimport numpy as nm\nimport matplotlib.pyplot as plt\nimport warnings\nimport random\nimport datetime\nwarnings.filterwarnings(\"ignore\")\nfrom IPython.display import display, Image\n\ndisplay(Image(filename='..\/input\/picture\/olist.png'))\n\n","d38fe08e":"customers=pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_customers_dataset.csv\")\ncustomers.name= \"customers\"\ngeo=pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_geolocation_dataset.csv\")\ngeo.name= \"geolocation\"\nitems=pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_items_dataset.csv\")\nitems.name=\"order items\"\npayments=pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_payments_dataset.csv\")\npayments.name= \"order payments\"\nreviews=pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_reviews_dataset.csv\")\nreviews.name= \"order reviews\"\norders=pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_orders_dataset.csv\")\norders.name='orders'\nproducts=pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_products_dataset.csv\")\nproducts.name=\"products\"\nsellers=pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_sellers_dataset.csv\")\nsellers.name=\"sellers\"","2341bbab":"def exploreFrequencies(customers):\n    print(\"{0:30} {1:25} {2:25}\".format(customers.name, \"unique values\", \"missing values\"))\n    for i in customers:\n        print(\"{0:30} {1:20} {2:20}\".format(i, customers[i].nunique(),customers[i].isna().sum()))\n    print(\"------------------------------------\")","5f5e1a0c":"exploreFrequencies(customers)\nexploreFrequencies(items)\nexploreFrequencies(payments)\nexploreFrequencies(reviews)\nexploreFrequencies(orders)\nexploreFrequencies(products)\nexploreFrequencies(sellers)\nexploreFrequencies(geo)\n","b2e3de61":"k=pd.DataFrame({'customers':customers['customer_state'].value_counts(),'sellers':sellers['seller_state'].value_counts()})\nprint(\"-------Customers and sellers location per state-----\")\nk=k.sort_values(by='customers',ascending=False)\nk=k.fillna(0)\nprint(k)\nk['sellers']= k['sellers'].apply( lambda x:x\/k['sellers'].sum())\nk['customers']= k['customers'].apply( lambda x:x\/k['customers'].sum())","61e716c4":"\nlabels = k.T.columns\nsel = k['sellers']\ncus = k['customers']\n\nx = nm.arange(len(labels))  # the label locations\nwidth = 0.2  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(20,10))\n\nrects1 = ax.bar(x - width\/2, sel, width, label='Sellers')\nrects2 = ax.bar(x + width\/2, cus, width, label='Customers')\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Percentage of total per state')\nax.set_xlabel('States')\nax.set_title('Customers and sellers location by state')\nax.set_xticks(x)\nax.set_xticklabels(labels)\nax.legend()","f410a337":"plt.boxplot(items.groupby(by='order_id')['price'].sum(), showfliers=False)\nplt.title(\"Order total without outliers\")\nplt.ylabel(\"currency units\")","844b5e2e":"plt.boxplot(items['price'], showfliers=False)\nplt.title(\"Item price without outliers\")\nplt.ylabel(\"currency units\")","a8cdb21b":"d=pd.DataFrame(items.groupby(by='seller_id').size().sort_values(0,ascending=False))\nd.head(5)\nplt.boxplot(d.T,showfliers=False)\nplt.title(\"Number of items sold by one seller\")\nplt.ylabel(\"Number of items\")","af38f82d":"z=pd.DataFrame(payments['payment_type'].value_counts())\nplt.bar(z.index, z.payment_type,tick_label=z.T.columns)\nplt.title(\"Payment methods\")\nplt.ylabel(\"Number of transactions used a specific method\")\n","72ce3879":"ax=pd.DataFrame(items.groupby(by='order_id')['order_item_id'].size().value_counts()).apply(lambda x:x\/items['order_item_id'].sum()).plot(kind=\"bar\", title=\"Items number per order\", rot=0)\nax.legend(\"\")\nax.set_xlabel(\"Items per order\")\nax.set_ylabel(\"Percentage\")\n\n\n","c9caf919":"orders[\"year\"]= orders['order_purchase_timestamp'].str[:4]\ncol=[orders[\"year\"]==2017]\nsc=orders[\"year\"].value_counts()\nprint(sc)\n\nax=sc.plot(kind=\"bar\", title=\"Number of orders per year\", rot=0)\n","ea30df3c":"#will remove\norders.pivot_table(index=['customer_id'], aggfunc='size').value_counts()","034f5f7a":"#reviews per order\na=reviews.groupby('order_id').size()\ndd=a.value_counts()\nprint(dd)\naz=dd.plot(kind=\"bar\", title= \"Number of reviews per order\", rot=0)\naz","5ac8487c":"o=reviews['review_score'].value_counts()\nax=o.plot(kind='bar', title= \" Distribution of review scores\", rot=90)\nax.set_xlabel(\"Review Score\")\nax.set_ylabel(\"Order number for a specific review score\")\n","7ecb7e0b":"items[['price','freight_value']].describe()","bbaf4518":"plt.scatter(items['price'], items['freight_value'])\nplt.title(\"relationship between price and freight cost\")\nplt.ylabel(\"Freight cost\")\nplt.xlabel(\"Item price\")","168ed9d4":"f=products[['product_id','product_description_lenght','product_photos_qty']]\ni=pd.DataFrame(items.groupby(by='product_id').size()).reset_index()\nf= f.merge(i, how=\"left\", on='product_id')\nf['quantity_sold']=f[0]\nf=f.drop(0, axis=1)\nprint(f[['quantity_sold','product_description_lenght']].describe())\nplt.scatter(f['quantity_sold'], f['product_description_lenght'])\nplt.title(\"relationship between description length and sold items\")\nplt.ylabel(\"Description length\")\nplt.xlabel(\"Quantity sold\")","2f358a12":"print(f[['quantity_sold','product_photos_qty']].describe())\nplt.scatter(f['quantity_sold'], f['product_photos_qty'])\nplt.title(\"relationship between photos quantity and number of sold items\")\nplt.ylabel(\"Photos number\")\nplt.xlabel(\"Quantity sold\")\nplt.yticks(nm.arange(0, 21, step=1))\nplt.show()","5f2aea0e":"s=pd.DataFrame(customers.groupby('customer_unique_id').size().reset_index())\ns['nbOrders']=s[0]\ns.drop(0,axis=1)\nf=s['nbOrders'].value_counts()\nf","c96542b3":"d=s.merge(customers.drop_duplicates('customer_unique_id',keep=\"last\"),how='left',on=\"customer_unique_id\")\nco=d['nbOrders'].value_counts()\n#plt.bar(co.index,co.values)\nax=co.plot(kind='bar', title=\"Number of orders per customer\", rot=0)\nax.set_xlabel(\"Number of customers per specific number of orders\")\nax.set_ylabel(\"Number of orders per customer\")\nd=d.drop(0,axis=1)\n#keep max 10 orders\nd['nbOrders']=d['nbOrders'].apply(lambda s:s if s<4 else 3)\n","e50d6115":"ordersList=customers.groupby('customer_unique_id')['customer_id'].apply(list).to_dict()\n\n#list of customer_ids associated with customer_unique_ids. 1 customer unique id can have many ids      ","a564dd5e":"'''\n############################################################\n###############        Extecuted code     ##################\n############################################################\nmoney= pd.DataFrame(columns=[\"customer_unique_id\",\"total\"])\nfor i in ordersList:\n    total=0\n    orderCounter=0\n    for u in ordersList[i]:\n        ordersPerCs=orders.loc[orders['customer_id']==u].values\n        for orde in ordersPerCs:\n            orderCounter=orderCounter+1\n            \n            itemsOrder=items.loc[items['order_id']==orde[0]].values\n            for ea in itemsOrder:\n                #print(ea[1])\n            #if(len(itemsOrder['price'])>0):\n                #total+=itemsOrder['price'].values[0]  \n                total+=ea[5]\n    if orderCounter>0:\n        v=total\/orderCounter\n    else:\n        v=0\n        print(total)\n    \n    money=money.append({'customer_unique_id':i, 'total':v},ignore_index=True)\nmoney.to_csv(\"averagePerOrderMoneySpent.csv\", encoding='utf-8', index=False)\n'''","ac68825b":"money=pd.read_csv(\"..\/input\/olistnewfeatures\/averagePerOrderMoneySpent.csv\")\nprint(money['total'].describe())\nmoney['total'].plot(kind='box', showfliers=False, title=\"Average money spent by customer per order\")\nmoney['total']=money['total'].apply(lambda s:s if s<300 else 300)","abc1a96f":"'''\n############################################################\n###############        Extecuted code     ##################\n############################################################\nrevs= pd.DataFrame(columns=[\"customer_unique_id\",\"reveiwScore\"])\nfor i in ordersList:\n    score=0\n    count=0\n    \n    for u in ordersList[i]:\n        ordersPerCs=orders.loc[orders['customer_id']==u].values\n        for orde in ordersPerCs:\n            reviewsOrder=reviews.loc[reviews['order_id']==orde[0]].values\n            for r in reviewsOrder:\n                score=score+r[2]\n                count=count+1\n                \n    revs=revs.append({'customer_unique_id':i, 'reviewScore':score\/count},ignore_index=True)\nrevs.to_csv(\"reviewsCustomers.csv\", encoding='utf-8', index=False)\n '''   \n    ","5ff40ff5":"revs=pd.read_csv(\"..\/input\/olistnewfeatures\/reviewsCustomers.csv\")\nprint(revs['reviewScore'].describe())\nrevs['reviewScore'].plot(kind='box', title=\"Average score left by customer\")","f632af19":"#consider 5 star order as happy customer ready to return= 1\n#2= loyals\nrevs=revs.merge(d[['customer_unique_id','nbOrders']],how='left',on='customer_unique_id')\nrevs['retentionScore']=revs['reviewScore']\/5*revs['nbOrders']\nprint(revs['retentionScore'].describe())\n#revs['retentionScore'].plot(kind='box', title=\"Retention score pre customer review score * Nb of orders\")\nrevs['retentionScore']=revs['retentionScore'].apply(lambda s:s if s<3 else 3 )\nrevs['retentionScore'].plot(kind='box', title=\"Retention score pre customer review score * Nb of orders\")\nrevs=revs.drop('nbOrders', axis=1)\n\n","8c371328":"'''\n############################################################\n###############        Extecuted code     ##################\n############################################################\nvendeurs= pd.DataFrame(columns=[\"customer_unique_id\",\"totalSellers\"])\nfor i in ordersList:\n    total=[]\n    \n    for u in ordersList[i]:\n        ordersPerCs=orders.loc[orders['customer_id']==u].values\n        for orde in ordersPerCs:\n            itemsOrder=items.loc[items['order_id']==orde[0]]\n            if(len(itemsOrder['seller_id'])>0):\n                \n                sstr=str(itemsOrder['seller_id'].values)\n                \n                if (sstr not in total):\n                    \n                    total.append(sstr)\n    vendeurs=vendeurs.append({'customer_unique_id':i, 'totalSellers':len(total)},ignore_index=True)\nvendeurs.to_csv(\"resellersPerCustomer.csv\", encoding='utf-8', index=False)\n\n'''","84e6162a":"vend=pd.read_csv(\"..\/input\/olistnewfeatures\/resellersPerCustomer.csv\")\nprint(vend['totalSellers'].value_counts())\nvend['totalSellers'].value_counts().plot(kind='bar', title=\"Number of resellers per customer\",rot=0)\nvend['totalSellers']=vend['totalSellers'].apply(lambda s:s if s<6 else 5)","0d8fc1e3":"from math import sin, cos, sqrt, atan2, radians\n\ndef distance(a,b):\n    R = 6373.0\n    aa=geo.loc[geo['geolocation_zip_code_prefix'].values == a].head(1)\n    bb= geo.loc[geo['geolocation_zip_code_prefix'].values == b].head(1)\n    if len(aa)==0:\n        a1= geo['geolocation_lat'].mean()\n        a2= geo['geolocation_lng'].mean()\n    else:\n        a1=aa['geolocation_lat'].values\n        a2=aa['geolocation_lng'].values\n    if len(bb)==0:\n        b1= geo['geolocation_lat'].mean()\n        b2= geo['geolocation_lng'].mean()\n    else:\n        b1=bb['geolocation_lat'].values\n        b2=bb['geolocation_lng'].values\n            \n   \n    lat1 = radians(a1)\n    lon1 = radians(a2)\n    lat2 = radians(b1)\n    lon2 = radians(b2)\n\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n\n    a = sin(dlat \/ 2)**2 + cos(lat1) * cos(lat2) * sin(dlon \/ 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n\n    return R * c\n","e5e22d7b":"'''\n############################################################\n###############        Extecuted code     ##################\n############################################################\ndistances= pd.DataFrame(columns=[\"customer_unique_id\",\"maximumDistance\"])\nfor i in ordersList:\n    total=0\n    customerZip=customers.loc[customers['customer_unique_id']==i]['customer_zip_code_prefix'].values[0]\n    \n    for u in ordersList[i]:\n        ordersPerCs=orders.loc[orders['customer_id']==u].values\n        for orde in ordersPerCs:\n            itemsOrder=items.loc[items['order_id']==orde[0]]\n            if(len(itemsOrder['seller_id'])>0):\n                    for sal in itemsOrder['seller_id']:\n                        zips= sellers.loc[sellers['seller_id']==sal]\n                        sellerZip=zips['seller_zip_code_prefix'].values\n                        #print(customerZip)\n                        #print(int(sellerZip))\n                        if(int(customerZip)>0 and int(sellerZip)>0):\n                            dist=distance(int(customerZip),int(sellerZip))\n                            if dist>total:\n                                total=dist\n                            \n    distances=distances.append({'customer_unique_id':i, 'maximumDistance': total},ignore_index=True)\ndistances.to_csv(\"MaximumDistancePerCustomer.csv\", encoding='utf-8', index=False)\n\n'''","756a3fcb":"distance=pd.read_csv(\"..\/input\/olistnewfeatures\/MaximumDistancePerCustomer.csv\")\nprint(distance['maximumDistance'].describe())\ndistance['maximumDistance'].plot(kind='box', title=\"Maximum distance customer purchased from\", showfliers=False)\ndistance['maximumDistance']=distance['maximumDistance'].apply(lambda s:s if s<1750 else 1750)","773d0b44":"'''\n############################################################\n###############        Extecuted code     ##################\n############################################################\nitemsNumber= pd.DataFrame(columns=[\"customer_unique_id\",\"nbItems\"])\n#get all customer ids\nfor i in ordersList:\n    totalItems=[]\n    \n    \n    #get all customer orders corresponding to ids\n    for u in ordersList[i]:\n        ordersPerCs=orders.loc[orders['customer_id']==u].values\n        #get all orders items corresponding to ids\n        \n        for orde in ordersPerCs:\n            \n            itemsOrder=items.loc[items['order_id']==orde[0]]\n            if(itemsOrder.shape[0]>0):\n                totalItems.append(itemsOrder.shape[0])\n    \n    if len(totalItems)>0:\n        c = Counter(totalItems)\n        v=c.most_common(1)[0][0]\n        \n    else:\n        v=0\n        \n    itemsNumber=itemsNumber.append({'customer_unique_id':i, 'nbItems': v},ignore_index=True)\n    \nitemsNumber.to_csv(\"itemsNumberPerCustomer.csv\", encoding='utf-8', index=False)\n'''","75e6d1e5":"itemsNumber=pd.read_csv(\"..\/input\/olistnewfeatures\/itemsNumberPerCustomer.csv\")\nvv=itemsNumber['nbItems'].value_counts()\nprint(vv.head(5))\nvv.plot(kind='bar', title=\"Items frequency per customer orders\",rot=0)\nitemsNumber['nbItems']=itemsNumber['nbItems'].apply(lambda s:s if s<6 else 5)","edd9f466":"'''\n############################################################\n###############        Extecuted code     ##################\n############################################################\nfrom collections import Counter\n\npaymentMethod= pd.DataFrame(columns=[\"customer_unique_id\",\"paymentMethod\"])\n#get all customer ids\nfor i in ordersList:\n    totalItems=[]\n    \n    \n    #get all customer orders corresponding to ids\n    for u in ordersList[i]:\n        ordersPerCs=orders.loc[orders['customer_id']==u].values\n        #get all orders items corresponding to ids\n        \n        for orde in ordersPerCs:\n            \n            method=payments.loc[payments['order_id']==orde[0]]\n            if(method.empty!=True):\n                \n                totalItems.append(method.values[0][2])\n    if len(totalItems)>0:\n        c = Counter(totalItems)\n        v=c.most_common(1)[0][0]\n    else:\n        v='not known'\n    \n    paymentMethod=paymentMethod.append({'customer_unique_id':i, 'paymentMethod': v},ignore_index=True)\n    \npaymentMethod.to_csv(\"paymentMethod.csv\", encoding='utf-8', index=False)\n'''","3899d4ad":"paymentMethod=pd.read_csv(\"..\/input\/olistnewfeatures\/paymentMethod.csv\")\nv=paymentMethod['paymentMethod'].value_counts()\nprint(v)\nax=v.plot(kind='barh', title=\"Prefereed payment method\")\nax","46bf0317":"paymentMethod['paymentMethodScore']=paymentMethod['paymentMethod'].replace(v.index,v.values)\npaymentMethod['paymentMethod']=paymentMethod.drop('paymentMethod',axis=1)","b4adb70c":"'''\n############################################################\n###############        Extecuted code     ##################\n############################################################\ncategory= pd.DataFrame(columns=[\"customer_unique_id\",\"category\"])\n#get all customer ids\nfor i in ordersList:\n    totalItems=[]\n    #get all customer orders corresponding to ids\n    for u in ordersList[i]:\n        ordersPerCs=orders.loc[orders['customer_id']==u].values\n        #get all orders items corresponding to ids\n        \n        for orde in ordersPerCs:\n            \n            itemsOrder=items.loc[items['order_id']==orde[0]].values\n            for ea in itemsOrder:\n                \n                produits=products.loc[products['product_id']==ea[2]].values\n                \n                if (len(produits[0])>0):\n                    totalItems.append(produits[0][1])\n                        \n                                      \n    if len(totalItems)>0:\n        c = Counter(totalItems)\n        c=c.most_common(1)[0][0]\n        \n    else:\n        c='not known'\n    \n    category=category.append({'customer_unique_id':i, 'category': c},ignore_index=True)\ncategory.to_csv(\"categoryCustomers.csv\", encoding='utf-8', index=False)\n'''","74c1cee9":"category=pd.read_csv(\"..\/input\/olistnewfeatures\/categoryCustomers.csv\")\nprint(\"Number of preferred categories: \"+str(len(category['category'].unique())))\nprint(\"First 10 categories represent :\"+str(category['category'].value_counts().head(10).values.sum()\/len(category['category'])*100)+ \"% of customers choice\")\n\nax=category['category'].value_counts().head(10).plot(kind='barh', title=\"10 top prefered categories per customers\")\nax","0059c1d2":"k=category['category'].value_counts()\ncategory['categoryScore']=category['category'].replace(k.index,k.values)\ncategory=category.drop('category', axis=1)","742ed222":"'''\n############################################################\n###############        Extecuted code     ##################\n############################################################\nfrequentReseller= pd.DataFrame(columns=[\"customer_unique_id\",\"frequent reseller\"])\n#get all customer ids\nfor i in ordersList:\n    totalSellers=[]\n    #get all customer orders corresponding to ids\n    for u in ordersList[i]:\n        ordersPerCs=orders.loc[orders['customer_id']==u].values\n        #get all orders items corresponding to ids\n        \n        for orde in ordersPerCs:\n            \n            itemsOrder=items.loc[items['order_id']==orde[0]].values\n            for ea in itemsOrder:\n                \n                totalSellers.append(ea[3])\n                                    \n    if len(totalSellers)>0:\n        c = Counter(totalSellers)\n        c=c.most_common(1)[0][0]\n        \n    else:\n        c='not known'\n    \n    frequentReseller=frequentReseller.append({'customer_unique_id':i, 'frequent reseller': c},ignore_index=True)\nfrequentReseller.to_csv(\"frequentResellers.csv\", encoding='utf-8', index=False)\n'''","f935a1d7":"frequentReseller=pd.read_csv(\"..\/input\/olistnewfeatures\/frequentResellers.csv\")\nprint(\"Number of preferred resellers: \"+str(len(frequentReseller['frequent reseller'].unique())))\nprint(\"Top 200 resellers represent :\"+str(frequentReseller['frequent reseller'].value_counts().head(200).values.sum()\/len(frequentReseller['frequent reseller'])*100)+ \"% of customers choice\")\nfrequentReseller['frequent reseller'].value_counts().head(10).plot(kind='barh', title=\"10 top resellers\")\n","b612d0bb":"k=frequentReseller['frequent reseller'].value_counts()\nfrequentReseller['frequentResellerScore']=frequentReseller['frequent reseller'].replace(k.index,k.values)\nfrequentReseller=frequentReseller.drop('frequent reseller', axis=1)","0ff545d3":"'''\n############################################################\n###############        Extecuted code     ##################\n############################################################\npurchaseCity= pd.DataFrame(columns=[\"customer_unique_id\",\"frequent purchase city\"])\n#get all customer ids\nfor i in ordersList:\n    totalAreas=[]\n    #get all customer orders corresponding to ids\n    for u in ordersList[i]:\n        ordersPerCs=orders.loc[orders['customer_id']==u].values\n        #get all orders items corresponding to ids\n        \n        for orde in ordersPerCs:\n            \n            itemsOrder=items.loc[items['order_id']==orde[0]].values\n            for ea in itemsOrder:\n                zips= sellers.loc[sellers['seller_id']==ea[3]].values\n                zipo= zips[0][3]\n                \n                totalAreas.append(zipo)\n                                  \n    if len(totalAreas)>0:\n        c = Counter(totalAreas)\n        c=c.most_common(1)[0][0]\n        \n    else:\n        v='not known'\n    \n    purchaseCity=purchaseCity.append({'customer_unique_id':i, 'frequent purchase city': c},ignore_index=True)\npurchaseCity.to_csv(\"frequentState.csv\", encoding='utf-8', index=False)\n'''","dc27da86":"purchaseCity=pd.read_csv(\"..\/input\/olistnewfeatures\/frequentState.csv\")\nc=purchaseCity['frequent purchase city'].value_counts().head(5)\nprint(c)\nc.plot(kind=\"barh\", title=\"5 top prefered purchase states\")","9f14b6c3":"k=purchaseCity['frequent purchase city'].value_counts()\npurchaseCity['frequentPurchaseStateScore']=purchaseCity['frequent purchase city'].replace(k.index,k.values)\npurchaseCity= purchaseCity.drop('frequent purchase city', axis=1)","eb1043bd":"'''\n############################################################\n###############        Extecuted code     ##################\n############################################################\nimport datetime\ndate_time_str = '2019-01-01 01:01:01'\ndateNow = datetime.datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S')\npurchaseYear= pd.DataFrame(columns=[\"customer_unique_id\",\"lastPurchase\"])\n#get all customer ids\nfor i in ordersList:\n    totalMonths=100\n    #get all customer orders corresponding to ids\n    for u in ordersList[i]:\n        ordersPerCs=orders.loc[orders['customer_id']==u].values\n        #get all orders items corresponding to ids\n        \n        for orde in ordersPerCs:\n            if pd.isna(orde[4])!=True:\n                date_time_str = orde[4]\n                dateBefore = datetime.datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S')\n                dist=round((dateNow - dateBefore).days\/30)                                       \n                \n                if(dist<totalMonths):\n                    totalMonths=dist\n                    \n                else:\n                    totalMonths=100\n    if(totalMonths==100):\n        totalMonths=\"not known\"\n    purchaseYear=purchaseYear.append({'customer_unique_id':i, 'lastPurchase': totalMonths},ignore_index=True)\npurchaseYear.to_csv(\"lastPurchase.csv\", encoding='utf-8', index=False)\n'''","2458ba53":"purchaseYear=pd.read_csv(\"..\/input\/olistnewfeatures\/lastPurchase.csv\")\ny=purchaseYear[purchaseYear[\"lastPurchase\"] != \"not known\"]\nmedian=y['lastPurchase'].median() \npurchaseYear[\"lastPurchase\"].replace({\"not known\": median }, inplace=True)\npurchaseYear[\"lastPurchase\"].astype(float).plot(kind=\"box\")","73a8c29a":"k=d['customer_state'].value_counts()\nd['customerStateScore']=d['customer_state'].replace(k.index,k.values)\nd=d.merge(money, on='customer_unique_id', how='left')\nd=d.merge(revs, on='customer_unique_id', how='left')\nd=d.merge(vend, on='customer_unique_id', how='left')\nd=d.merge(distance, on='customer_unique_id', how='left')\nd=d.merge(itemsNumber, on='customer_unique_id', how='left')\nd=d.merge(paymentMethod, on='customer_unique_id', how='left')\nd=d.merge(purchaseYear, on='customer_unique_id', how='left')\nd=d.merge(purchaseCity, on='customer_unique_id', how='left')\nd=d.merge(category, on='customer_unique_id', how='left')\nd=d.merge(frequentReseller, on='customer_unique_id', how='left')\nd=d.drop(['reviewScore',\"customer_id\",'customer_state'],axis=1)\nd.columns","74a0a86a":"\nl=d[[ 'nbOrders', \n        'customerStateScore',\n       'total', 'retentionScore', 'totalSellers', 'maximumDistance', 'nbItems',\n        'paymentMethodScore', 'lastPurchase',\n       'frequentPurchaseStateScore',  'frequentResellerScore']]\nfrom sklearn import preprocessing\n\nx = l.values #returns a numpy array\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\nl = pd.DataFrame(x_scaled, columns=l.columns)\n\n","de735cd7":"l.describe()","fe87ecdd":"from sklearn.cluster import KMeans\n\nnum_clusters = 8\nkmeans_tests = [KMeans(n_clusters=i, init='random', n_init=10) for i in range(1, num_clusters)]\nscore = [kmeans_tests[i].fit(l).score(l) for i in range(len(kmeans_tests))]\nplt.plot(range(1, num_clusters),score)\nplt.xlabel('Number of Clusters')\nplt.ylabel('Score')\nplt.title('Elbow Curve')\nplt.show()\n","9c29f0b0":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nn_clusters=8\nscore=[]\nfor r in range(2,n_clusters): \n    \n    clusterer = KMeans(n_clusters=r, random_state=10)\n    cluster_labels = clusterer.fit_predict(l)\n    silhouette_avg = silhouette_score(l, cluster_labels)\n    score.append(silhouette_avg)\n","e65a48fe":"plt.plot(range(2, n_clusters),score)\nplt.xlabel('Number of Clusters')\nplt.ylabel('Silhouette Score')\nplt.title('Elbow Curve Silhouette Score')\nplt.show()","6268d452":"g=KMeans(n_clusters=4, init='random', n_init=10)\nb=g.fit(l).labels_\n","600d0f6d":"#from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import make_scorer,adjusted_rand_score\n#j=b.reshape(-1, 1)\n\nsc=make_scorer(adjusted_rand_score)\nkm=KMeans(n_clusters=4)\nfrom sklearn.model_selection import GridSearchCV\nparameters = {'init':('k-means++', 'random'),'max_iter':[100,200,300],'n_init':[5,10,15]}\nclf = GridSearchCV(km, parameters,scoring=sc)\nclf.fit(l,b)\nindx=clf.cv_results_['rank_test_score'].tolist().index(1)\nprint(\"ARI score mean :\"+str(clf.cv_results_['mean_test_score'][indx]))\nprint(\"Best parameters: \"+str(clf.best_params_))","b84e2a3c":"\n'''\n#####################################################\n### TESTING CUSTOM GRID SEARCH ######################\n#####################################################\n\nio={\"parameter\":{'init':['k-means++', 'random']}}\n\ndef customGrid1(parameter=None):\n    \n    average=[]\n    for k,v in parameter.items():\n        \n        for g in v:\n            kw={k:g}\n            op = KMeans(n_clusters=4,**kw)\n            sam=l\n            lb= sam['cluster']\n            sam= sam.drop('cluster',axis=1)\n        \n            kfold = KFold( n_splits=10)\n            sco=[]\n\n            for train_index, test_index in kfold.split(sam):\n                train = sam.iloc[train_index]\n                trainY=lb.iloc[train_index]\n                test=sam.iloc[test_index]\n                testY=lb.iloc[test_index]\n                r1=op.fit(train).labels_\n                r2=op.fit(test).labels_\n                mm=adjusted_rand_score(r1,trainY)\n                nn=adjusted_rand_score(r2,testY)\n                mm=(mm+nn)\/2\n                sco.append(mm)\n               \n            ss=pd.DataFrame(sco).mean()\n            \n            average.append({g:ss})\n    return average\n\nprint(customGrid1(**io))\n\n####################################################################################################\n##############                 Result            ###################################################\n####################################################################################################\n#[{'k-means++': 0    1.0\n#dtype: float64}, {'random': 0    0.92968\n#dtype: float64}]\n####################################################################################################\n'''\n\n","e12ce593":"# Library of Functions for the OpenClassrooms Multivariate Exploratory Data Analysis Course\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.collections import LineCollection\nimport numpy as np\nimport pandas as pd\nfrom scipy.cluster.hierarchy import dendrogram\nfrom pandas.plotting import parallel_coordinates\nimport seaborn as sns\n\n\npalette = sns.color_palette(\"bright\", 10)\n\ndef display_circles(pcs, n_comp, pca, axis_ranks, labels=None, label_rotation=0, lims=None):\n    \"\"\"Display correlation circles, one for each factorial plane\"\"\"\n\n    # For each factorial plane\n    for d1, d2 in axis_ranks: \n        if d2 < n_comp:\n\n            # Initialise the matplotlib figure\n            fig, ax = plt.subplots(figsize=(20,20))\n\n            # Determine the limits of the chart\n            if lims is not None :\n                xmin, xmax, ymin, ymax = lims\n            elif pcs.shape[1] < 30 :\n                xmin, xmax, ymin, ymax = -1, 1, -1, 1\n            else :\n                xmin, xmax, ymin, ymax = min(pcs[d1,:]), max(pcs[d1,:]), min(pcs[d2,:]), max(pcs[d2,:])\n\n            # Add arrows\n            # If there are more than 30 arrows, we do not display the triangle at the end\n            if pcs.shape[1] < 30 :\n                plt.quiver(np.zeros(pcs.shape[1]), np.zeros(pcs.shape[1]),\n                   pcs[d1,:], pcs[d2,:], \n                   angles='xy', scale_units='xy', scale=1, color=\"grey\")\n                # (see the doc : https:\/\/matplotlib.org\/api\/_as_gen\/matplotlib.pyplot.quiver.html)\n            else:\n                lines = [[[0,0],[x,y]] for x,y in pcs[[d1,d2]].T]\n                ax.add_collection(LineCollection(lines, axes=ax, alpha=.1, color='black'))\n            \n            # Display variable names\n            if labels is not None:  \n                for i,(x, y) in enumerate(pcs[[d1,d2]].T):\n                    if x >= xmin and x <= xmax and y >= ymin and y <= ymax :\n                        plt.text(x, y, labels[i], fontsize='14', ha='center', va='center', rotation=label_rotation, color=\"blue\", alpha=0.5)\n            \n            # Display circle\n            circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')\n            plt.gca().add_artist(circle)\n\n            # Define the limits of the chart\n            plt.xlim(xmin, xmax)\n            plt.ylim(ymin, ymax)\n        \n            # Display grid lines\n            plt.plot([-1, 1], [0, 0], color='grey', ls='--')\n            plt.plot([0, 0], [-1, 1], color='grey', ls='--')\n\n            # Label the axes, with the percentage of variance explained\n            plt.xlabel('PC{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))\n            plt.ylabel('PC{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))\n            nr=d1+1\n            plt.title(\"Correlation Circle (PC{} and PC{})\".format(d1+1, d2+1))\n            plt.show(block=False)\n            d = {'values': pca.components_[d1], 'factors': labels}\n            df1= pd.DataFrame(d)\n            df1.set_index('factors')\n            df2=df1.sort_values(by='values', ascending=False)\n            df3=df1.sort_values(by='values', ascending=True)\n            print(\"Principal Component\" + str(nr)+ \" Presenting Values\")\n            print(df2.head(3))\n            print(df3.head(3))\n            \n            nr=d2+1\n            \n            d = {'values': pca.components_[d2], 'factors': labels}\n            df1= pd.DataFrame(d)\n            df1.set_index('factors')\n            df2=df1.sort_values(by='values', ascending=False)\n            df3=df1.sort_values(by='values', ascending=True)\n            print(\"Principal Component\" + str(nr)+ \" Presenting Values\")\n            print(df2.head(3))\n            print(df3.head(3))\n\ndef display_factorial_planes(X_projected, n_comp, pca, axis_ranks, labels=None, alpha=1, illustrative_var=None):\n    '''Display a scatter plot on a factorial plane, one for each factorial plane'''\n\n    # For each factorial plane\n    for d1,d2 in axis_ranks:\n        if d2 < n_comp:\n \n            # Initialise the matplotlib figure      \n            fig = plt.figure(figsize=(7,6))\n        \n            # Display the points\n            if illustrative_var is None:\n                plt.scatter(X_projected[:, d1], X_projected[:, d2], alpha=alpha)\n            else:\n                illustrative_var = np.array(illustrative_var)\n                for value in np.unique(illustrative_var):\n                    selected = np.where(illustrative_var == value)\n                    plt.scatter(X_projected[selected, d1], X_projected[selected, d2], alpha=alpha, label=value)\n                plt.legend()\n\n            # Display the labels on the points\n            if labels is not None:\n                for i,(x,y) in enumerate(X_projected[:,[d1,d2]]):\n                    plt.text(x, y, labels[i],\n                              fontsize='14', ha='center',va='center') \n                \n            # Define the limits of the chart\n            boundary = np.max(np.abs(X_projected[:, [d1,d2]])) * 1.1\n            plt.xlim([-boundary,boundary])\n            plt.ylim([-boundary,boundary])\n        \n            # Display grid lines\n            plt.plot([-100, 100], [0, 0], color='grey', ls='--')\n            plt.plot([0, 0], [-100, 100], color='grey', ls='--')\n\n            # Label the axes, with the percentage of variance explained\n            plt.xlabel('PC{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))\n            plt.ylabel('PC{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))\n\n            plt.title(\"Projection of points (on PC{} and PC{})\".format(d1+1, d2+1))\n            #plt.show(block=False)\n\ndef display_scree_plot(pca):\n    '''Display a scree plot for the pca'''\n\n    scree = pca.explained_variance_ratio_*100\n    plt.bar(np.arange(len(scree))+1, scree)\n    plt.plot(np.arange(len(scree))+1, scree.cumsum(),c=\"red\",marker='o')\n    plt.xlabel(\"Number of principal components\")\n    plt.ylabel(\"Percentage explained variance\")\n    plt.title(\"Scree plot\")\n    plt.show(block=False)\n\ndef append_class(df, class_name, feature, thresholds, names):\n    '''Append a new class feature named 'class_name' based on a threshold split of 'feature'.  Threshold values are in 'thresholds' and class names are in 'names'.'''\n    \n    n = pd.cut(df[feature], bins = thresholds, labels=names)\n    df[class_name] = n\n\ndef plot_dendrogram(Z, names, figsize=(10,25)):\n    '''Plot a dendrogram to illustrate hierarchical clustering'''\n\n    plt.figure(figsize=figsize)\n    plt.title('Hierarchical Clustering Dendrogram')\n    plt.xlabel('distance')\n    dendrogram(\n        Z,\n        labels = names,\n        orientation = \"left\",\n    )\n    #plt.show()\n\ndef addAlpha(colour, alpha):\n    '''Add an alpha to the RGB colour'''\n    \n    return (colour[0],colour[1],colour[2],alpha)\n\ndef display_parallel_coordinates(df, num_clusters):\n    '''Display a parallel coordinates plot for the clusters in df'''\n\n    # Select data points for individual clusters\n    cluster_points = []\n    for i in range(num_clusters):\n        cluster_points.append(df[df.cluster==i])\n    \n    # Create the plot\n    fig = plt.figure(figsize=(20, 25))\n    title = fig.suptitle(\"Parallel Coordinates Plot for the Clusters\", fontsize=18)\n    fig.subplots_adjust(top=0.95, wspace=0)\n\n    # Display one plot for each cluster, with the lines for the main cluster appearing over the lines for the other clusters\n    for i in range(num_clusters):    \n        plt.subplot(num_clusters, 1, i+1)\n        for j,c in enumerate(cluster_points): \n            if i!= j:\n                pc = parallel_coordinates(c, 'cluster', color=[addAlpha(palette[j],0.2)])\n        pc = parallel_coordinates(cluster_points[i], 'cluster', color=[addAlpha(palette[i],0.5)])\n\n        # Stagger the axes\n        ax=plt.gca()\n        for tick in ax.xaxis.get_major_ticks()[1::2]:\n            tick.set_pad(20)        \n\n\ndef display_parallel_coordinates_centroids(df, num_clusters):\n    '''Display a parallel coordinates plot for the centroids in df'''\n\n    # Create the plot\n    fig = plt.figure(figsize=(12, 5))\n    title = fig.suptitle(\"Parallel Coordinates plot for the Centroids\", fontsize=18)\n    fig.subplots_adjust(top=0.9, wspace=0)\n\n    # Draw the chart\n    parallel_coordinates(df, 'cluster', color=palette)\n\n    # Stagger the axes\n    ax=plt.gca()\n    for tick in ax.xaxis.get_major_ticks()[1::2]:\n        tick.set_pad(5)    \n","46126ed3":"\nl['cluster']=b\nsample=l.sample(frac=0.1, replace=True, random_state=1)\n# Display parallel coordinates plots, one for each cluster\ndisplay_parallel_coordinates(sample, 4)","27bda129":"l['cluster'].value_counts()","76b6973c":"from sklearn.manifold import TSNE\nlsample= l.sample(frac=0.3)\nX_embedded = TSNE(n_components=2).fit_transform(lsample)\ndataV=pd.DataFrame(X_embedded, columns=[\"D1\",\"D2\"])\ndataV['cluster']=lsample['cluster'].tolist()\nfig = plt.figure(figsize=(10, 10))\nax = fig.add_subplot(111)\nscatter = ax.scatter(dataV['D1'],dataV['D2'],\n                  c=dataV['cluster'],   s=50)\nax.set_title('K-Means Clustering')\nax.set_xlabel('Dimention 1')\nax.set_ylabel('Dimention 2')\nplt.colorbar(scatter)","69c1dc31":"#for more than 2 dimensions: minPts=2*dim (Sander et al., 1998)\nfrom sklearn.cluster import OPTICS, cluster_optics_dbscan\nimport matplotlib.gridspec as gridspec\nX=l\nX=X.drop('cluster', axis=1)\nclust = OPTICS(min_samples=2*len(X.columns), xi=.05, min_cluster_size=.05)\n\n# Run the fit\nlabelsDB=clust.fit(X).labels_\n","eceb42a9":"X['cluster']= labelsDB\nX['cluster'].value_counts()","40bb7f2b":"X['cluster']= labelsDB\nsample=X.sample(frac=0.1, replace=True, random_state=1)\n# Display parallel coordinates plots, one for each cluster\ndisplay_parallel_coordinates(sample, 6)\n","31e81b00":"#Grid Search for OPTICS based model\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import KFold\nsc=make_scorer(adjusted_rand_score)\nio={\"parameter\":{\"xi\": [.05,.01,.1] }}\nia={\"parameter\":{\"min_cluster_size\": [.05,.01,.1] }}\n\ndef customGrid(X, parXi, parameter=None):\n    sam=X.sample(frac=0.1)\n    lb= sam['cluster'] \n    sam= sam.drop('cluster',axis=1)\n    average={}\n    for k,v in parameter.items():\n        \n        for g in v:\n            kw={k:g}\n            if(parXi!=None):\n                op = OPTICS(**kw,xi=parXi)\n            else:\n                op = OPTICS(**kw)\n            kfold = KFold( n_splits=10)\n            sco=[]\n\n            for train_index, test_index in kfold.split(sam):\n                train = sam.iloc[train_index]\n                trainY=lb.iloc[train_index]\n                test=sam.iloc[test_index]\n                testY=lb.iloc[test_index]\n                r1=op.fit(train).labels_\n                r2=op.fit(test).labels_\n                mm=adjusted_rand_score(r1,trainY)\n                nn=adjusted_rand_score(r2,testY)\n                mm=(mm+nn)\/2\n                sco.append(mm)\n               \n            ss=pd.DataFrame(sco).mean()\n            \n            average[g]=ss\n    \n    return average\n\ndef bestParams(firstPar):\n    \n    major=0\n    sel=0\n    for k,v in firstPar.items():\n        if v.values>major:\n            major=v.values\n            sel=k\n    print(\"Best params: \"+ str(sel)+\" : \"+str(major))\n    return sel\nfirstPar=customGrid(X,None, **io)\nprint(\"--------------------------------------------------\")\nsel= bestParams(firstPar)\ndd=customGrid(X, sel,**ia)\ny=bestParams(dd)","e75ffee2":"#Silhouette Score for OPTICS based model\n\nsam1=X\nlb1= sam1['cluster'] \nsam1=sam1.drop('cluster',axis=1)\nssc=silhouette_score(sam1,lb1)\nssc","b5381ce9":"lsample= X.sample(frac=0.3)\nX_embedded = TSNE(n_components=2).fit_transform(lsample)\ndataV=pd.DataFrame(X_embedded, columns=[\"D1\",\"D2\"])\ndataV['cluster']=lsample['cluster'].tolist()\ndataV=dataV.loc[dataV[\"cluster\"]>-1]\nfig = plt.figure(figsize=(10, 10))\nax = fig.add_subplot(111)\nscatter = ax.scatter(dataV['D1'],dataV['D2'],\n                  c=dataV['cluster'],   s=50)\nax.set_title('OPTICS Clustering')\nax.set_xlabel('Dimention 1')\nax.set_ylabel('Dimention 2')\nplt.colorbar(scatter)","1d5182e2":"## Average review score by customer","c84f821e":"### Prefered reseller score","aaf1b04c":"## Last purchase: nb of months ago","10c83e54":"## Order total and item price visualization","2e221357":"## Prefered reseller by customer","277e8f66":"## Number customers and sellers per state","97577ef5":"## Number of items per order","e99d4574":"## Maximum distance purchased from per customer","e2675132":"### Retention score","b960052e":"## Number of items sold by one seller","645f6701":"## Percentage of customers and sellers per state","ddec67a7":"# Feature engineering\n## Number of orders per customer","b8277038":"## Average Order Total Spent by a customer","5cafad19":"## Average number of items per customer order","802c4219":"## Distribution of review scores","809549b4":"## Relationship between description length, photos number and number of sold items","3aa23a29":"## Number of reviews per order","528a15a5":"### State score","574efe0a":"## Analysis of item price and freight cost","a1e71b29":"# Exploratory Analysis\n\n## Dataset available columns, unique and missing values","cb748482":"## Preferred Cathegory","be0983ac":"### Payment method score","42f056fc":"## Preferred payment methods","8eee7098":"### Preferred category score","98783c05":"# OLIST Customer segmentation\n","a8e08c34":"## Orders per year","b516ad83":"## customer payment method\n","bcda9523":"## Preferred city to purchase from","dfb72a12":"## Number of resellers per customer"}}