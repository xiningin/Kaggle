{"cell_type":{"3a2c4946":"code","30427b6e":"code","ebf68204":"code","b79bab18":"code","01391ed5":"code","e1b09c09":"code","eeb18354":"code","0e02fd02":"code","c33debce":"code","5ec1ad2b":"code","6762ea22":"code","7be62ba7":"code","a951a1d9":"markdown","1414a64a":"markdown","eef78cd5":"markdown","805e01a0":"markdown","a0c8ff2c":"markdown","030864fc":"markdown","9a355b8d":"markdown","20792f04":"markdown","6cafe4a9":"markdown","712057ed":"markdown"},"source":{"3a2c4946":"import pandas as pd \nimport numpy as np \nfrom numpy import pi \n\n# To create plots\nfrom matplotlib.colors import rgb2hex\nfrom matplotlib.cm import get_cmap\nimport matplotlib.pyplot as plt\n\n# Aesthetic plots \nimport seaborn as sns\n\n# interactive plots \nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)\n\n\n# To get new datatypes and functions\nfrom collections import Counter\nfrom cycler import cycler\n\n\n# To investigate distributions\nfrom scipy.stats import norm, skew, probplot\nfrom scipy.optimize import curve_fit\n\n\n# To build models\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\n\n# To gbm light\nfrom lightgbm import LGBMClassifier\n\n# To measure time\nfrom time import time\n","30427b6e":"# Load datasets\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\n\n\n# Combine boths dataframes\ntrain_df['Data'] = 'Train'\ntest_df['Data'] = 'Test'\n\nboth_df = pd.concat([train_df, test_df], axis=0).reset_index(drop=True)\n\nboth_df['subject'] = '#' + both_df['subject'].astype(str)\n\n# Create label\nlabel = both_df.pop('Activity')\n\nprint('Shape Train:\\t{}'.format(train_df.shape))\nprint('Shape Test:\\t{}\\n'.format(test_df.shape))\n\ntrain_df.head()\n\n","ebf68204":"pd.DataFrame.from_dict(Counter([col.split('-')[0].split('(')[0] for col in both_df.columns]),orient = \"index\").\\\nrename(columns={0:'count'}).sort_values('count', ascending=False)","b79bab18":"# Get null values and dataframe information\nprint('Null Values In DataFrame: {}\\n'.format(both_df.isna().sum().sum()))\nboth_df.info()","01391ed5":"# we are plotting data now to visualise the distribution \nlabel_counts = label.value_counts()\n\nn = label_counts.shape[0]\ncolormap = get_cmap('viridis')\ncolors = [rgb2hex(colormap(col)) for col in np.arange(0, 1.01, 1\/(n-1))]\n\n# Create plot\ndata = go.Bar(x = label_counts.index,\n              y = label_counts,\n              marker = dict(color = colors))\n\nlayout = go.Layout(title = 'Smartphone Activity Label Distribution',\n                   xaxis = dict(title = 'Activity'),\n                   yaxis = dict(title = 'Count'))\n\n\nfig = go.Figure(data=[data], layout=layout)\niplot(fig)","e1b09c09":"# Create datasets\ntsne_data = both_df.copy()\ndata_data = tsne_data.pop('Data')\nsubject_data = tsne_data.pop('subject')\n\n# Scale data\nscl = StandardScaler()\ntsne_data = scl.fit_transform(tsne_data)\n\n\n# Reduce dimensions (speed up)\npca = PCA(n_components=0.9, random_state=3)\ntsne_data = pca.fit_transform(tsne_data)\n\n# Transform data\ntsne = TSNE(random_state=3)\ntsne_transformed = tsne.fit_transform(tsne_data)\n\n\n# Create subplots\nfig, axarr = plt.subplots(2, 1, figsize=(15,10))\n\n# Get colors\nn = label.unique().shape[0]\ncolormap = get_cmap('viridis')\ncolors = [rgb2hex(colormap(col)) for col in np.arange(0, 1.01, 1\/(n-1))]\n\n\n# Plot each activity\nfor i, group in enumerate(label_counts.index):\n    # Mask to separate sets\n    mask = (label==group).values\n    axarr[0].scatter(x=tsne_transformed[mask][:,0], y=tsne_transformed[mask][:,1], c=colors[i], alpha=0.5, label=group)\naxarr[0].set_title('TSNE: Activity Visualisation')\naxarr[0].legend()\n\n\n# Plot each participant\nfor i, group in enumerate(subject_data.unique()):\n    # Mask to separate sets\n    mask = (subject_data==group).values\n    axarr[1].scatter(x=tsne_transformed[mask][:,0], y=tsne_transformed[mask][:,1], c=colors[i], alpha=0.5, label=group)\n\naxarr[1].set_title('TSNE: Participant Visualisation')\nplt.show()\n","eeb18354":"# Split training testing data\nenc = LabelEncoder()\nlabel_encoded = enc.fit_transform(label)\nX_train, X_test, y_train, y_test = train_test_split(tsne_data, label_encoded, random_state=3)\n\n# Create the model\nlgbm = LGBMClassifier(n_estimators=500, random_state=3)\nlgbm = lgbm.fit(X_train, y_train)\n\n# Test the model\nscore = accuracy_score(y_true=y_test, y_pred=lgbm.predict(X_test))\nprint('Accuracy on testset:\\t{:.4f}\\n'.format(score))","0e02fd02":"data = []\n\nfor activity in label_counts.index:\n    act_data  = both_df[label==activity].copy()\n    act_data_data = act_data.pop('Data')\n    act_subject_data = act_data.pop('subject')\n    \n    # Scale data\n    scl = StandardScaler()\n    act_data = scl.fit_transform(act_data)\n    \n    #Reduce Dimensions \n    pca = PCA(n_components=0.9, random_state=3)\n    act_data = pca.fit_transform(act_data)\n    \n    # Split train test data \n    enc = LabelEncoder()\n    label_encoded = enc.fit_transform(act_subject_data)\n    X_train, X_test, y_train, y_test = train_test_split(act_data, label_encoded, random_state=3)\n    \n    # Fit basic Model \n    print('Activity:{}'.format(activity))\n    lgbm = LGBMClassifier(n_estimators=500, random_state=3)\n    lgbm = lgbm.fit(X_train, y_train)\n    \n    score = accuracy_score(y_true=y_test, y_pred=lgbm.predict(X_test))\n    print('Accuracy on testset:\\t{:.4f}\\n'.format(score))\n    data.append([activity, score])\n","c33debce":"tsne_data = both_df[label=='WALKING'].copy()\ndata_data = tsne_data.pop('Data')\nsubject_data = tsne_data.pop('subject')\n\n# Scale data\nscl = StandardScaler()\ntsne_data = scl.fit_transform(tsne_data)\n\n# Split training testing data\nenc = LabelEncoder()\nlabel_encoded = enc.fit_transform(subject_data)\nX_train, X_test, y_train, y_test = train_test_split(tsne_data, label_encoded, random_state=3)\n\n# Create model\nlgbm = LGBMClassifier(n_estimators=500, random_state=3)\nlgbm = lgbm.fit(X_train, y_train)\n\n\nfeatures = both_df.drop(['Data', 'subject'], axis=1).columns\nimportances = lgbm.feature_importances_\n\n# Sum importances\ndata = {'Gyroscope':0, 'Accelerometer':0}\nfor importance, feature in zip(importances, features):\n    if 'Gyro' in feature:\n        data['Gyroscope'] += importance\n    if 'Acc' in feature:\n        data['Accelerometer'] += importance\n        \n        \n# Create Data Frame and Plot \n\nsensor_df = pd.DataFrame.from_dict(data, orient='index').rename(columns={0:'Importance'})\n\nsensor_df.plot(kind='barh', figsize=(14,4), title='Sensor Importance For Classifing Participants By Walking Style (Feature Importance Sum)')\n\nplt.show()\n","5ec1ad2b":"mask = label.isin(['WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS'])\nduration_df = (both_df[mask].groupby([label[mask], 'subject'])['Data'].count() * 1.28)\n\n# Create plot\nplot_data = duration_df.reset_index().sort_values('Data', ascending=False)\nplot_data['Activity'] = plot_data['Activity'].map({'WALKING_UPSTAIRS':'Upstairs', 'WALKING_DOWNSTAIRS':'Downstairs'})\n\nplt.figure(figsize=(15,5))\nsns.barplot(data=plot_data, x='subject', y='Data', hue='Activity')\nplt.title('Participants Compared By Their Staircase Walking Duration')\nplt.xlabel('Participants')\nplt.ylabel('Total Duration [s]')\nplt.show()","6762ea22":"# Create data and plot\nplt.figure(figsize=(15,5))\nplot_data = ((duration_df.loc['WALKING_UPSTAIRS'] \/ duration_df.loc['WALKING_DOWNSTAIRS']) -1).sort_values(ascending=False)\nsns.barplot(x=plot_data.index, y=plot_data)\nplt.title('By What Percentage Is The Participant Faster In Walking Downstairs Than Upstairs?')\nplt.xlabel('Participants')\nplt.ylabel('Percent')\nplt.show()","7be62ba7":"fig, axarr = plt.subplots(5,6, figsize = (15,6))\n\n\nfor person in range(0,30):\n    #Get data for single person and plot it \n    single_person = both_df[(label=='WALKING') & (both_df['subject']=='#{}'.format(person+1))].drop(['subject', 'Data'], axis=1)       \n    # Scaling the Data\n    scl = StandardScaler()\n    tsne_data = scl.fit_transform(single_person)\n                            \n    # Reducing Dimensions\n    pca = PCA(n_components=0.9, random_state=3)\n    tsne_data = pca.fit_transform(tsne_data)\n    # Transform data\n    tsne = TSNE(random_state=3)\n    tsne_transformed = tsne.fit_transform(tsne_data)\n \n    \n    # Create plot\n    axarr[person\/\/6][person%6].plot(tsne_transformed[:,0], tsne_transformed[:,1], '.-')\n    axarr[person\/\/6][person%6].set_title('Participant #{}'.format(person+1))\n    axarr[person\/\/6][person%6].axis('off')","a951a1d9":"No missing value is present. Other then Data and Subject column everything else is. numerical","1414a64a":"# Uniqueness in Walking of Each Participant ","eef78cd5":"#  Participant Separability exploration ","805e01a0":"# Human Activity Recognition ","a0c8ff2c":"# Ratio Upstairs and DownStairs ","030864fc":"# Sensor importance for walking ","9a355b8d":"# Label Distribution ","20792f04":"#  Analysis of participants using StairCase","6cafe4a9":"#  Investigating the separability of the Data","712057ed":"# DataSet Exploration Begins "}}