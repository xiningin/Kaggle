{"cell_type":{"94a5ab61":"code","b53d2888":"code","891bc536":"code","31749f6c":"code","b5180f44":"code","b3b7025a":"code","46b75333":"code","8d5ffe39":"code","e96bdde1":"code","e4c7ff62":"code","28660d45":"code","51b898a6":"code","f08b670b":"code","59c2c0b6":"code","5d7e3ef7":"code","22df1aa6":"code","15ba93bf":"code","b9380c43":"code","65ae362e":"code","afca8b23":"code","ea03cd85":"code","be4b03cf":"markdown","8ae2e8e5":"markdown","9bb6827a":"markdown","a9fe08eb":"markdown","8a8ba27e":"markdown","283f188c":"markdown","e1977799":"markdown","41b131c3":"markdown","e38307b5":"markdown","49d3fb27":"markdown","c3622ab0":"markdown","735bce81":"markdown","244c98d2":"markdown","692cc3cf":"markdown","3ca40dfc":"markdown","6b0e4483":"markdown"},"source":{"94a5ab61":"import numpy as np\nimport pandas as pd \nimport os\nimport json\nimport glob\nimport random\nfrom IPython.display import display, display_markdown\nfrom math import floor\nfrom matplotlib import pyplot as plt\nimport matplotlib.image as mpimg\nimport matplotlib.patches as patches\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport seaborn as sns\nfrom PIL import Image\nfrom tqdm.notebook import tqdm","b53d2888":"img = \"\/kaggle\/input\/iwildcam-2020-fgvc7\/train\/92b8a1d0-21bc-11ea-a13a-137349068a90.jpg\"\n_ = plt.figure(figsize = (15,20))\n_ = plt.axis('off')\n_ = plt.imshow(mpimg.imread(img)[100:-100])","891bc536":"os.listdir(\"\/kaggle\/input\/iwildcam-2020-fgvc7\")","31749f6c":"print(\"Number of train images: \", len(glob.glob(f'\/kaggle\/input\/iwildcam-2020-fgvc7\/train\/*')))\nprint(\"Number of test images: \", len(glob.glob(f'\/kaggle\/input\/iwildcam-2020-fgvc7\/test\/*')))","b5180f44":"with open('\/kaggle\/input\/iwildcam-2020-fgvc7\/iwildcam2020_train_annotations.json') as json_data:\n    train_annotations = json.load(json_data)\n    print(train_annotations.keys())","b3b7025a":"df_cat = pd.DataFrame(train_annotations[\"categories\"])\ndisplay(f\"Total Categories: {df_cat.name.nunique()}\")\ndisplay(df_cat.sample(5))","46b75333":"display(\"Samples of annotations and images\")\ndf_train_annotations = pd.DataFrame(train_annotations[\"annotations\"])\ndisplay(df_train_annotations.sample())","8d5ffe39":"with open('\/kaggle\/input\/iwildcam-2020-fgvc7\/iwildcam2020_megadetector_results.json') as json_data:\n    megadetector_results = json.load(json_data)\n    print(megadetector_results.keys())\nprint(megadetector_results['info'])","e96bdde1":"df_detections = pd.DataFrame(megadetector_results[\"images\"])\nprint(f'detection categories :\\n {megadetector_results[\"detection_categories\"]}')\nprint(f'detection output :\\n {df_detections.head()}')","e4c7ff62":"with open('\/kaggle\/input\/iwildcam-2020-fgvc7\/iwildcam2020_test_information.json') as json_data:\n    test_info = json.load(json_data)\n    print(test_info.keys())","28660d45":"print(f'test images :\\n {test_info[\"images\"][0]}')","51b898a6":"train = glob.glob(f'\/kaggle\/input\/iwildcam-2020-fgvc7\/train\/*')\nprint(\"Train Path \\n\", train[0])\ntest = glob.glob(f'\/kaggle\/input\/iwildcam-2020-fgvc7\/test\/*')\nprint(\"Test Path \\n\", test[0])","f08b670b":"def plot_images(rows,cols):\n    fig = plt.figure(figsize=(15., 12.))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(rows, cols),  # creates 5x5 grid of axes\n                 axes_pad=0.3,  # pad between axes in inch.\n                 )\n\n    for ax, img in zip(grid, random.sample(train, rows*cols)):\n        image_id = img.split('\/')[-1].split('.')[0]\n        cat_id = df_train_annotations[df_train_annotations.image_id == image_id].category_id\n        cat = df_cat[df_cat.id == int(cat_id)].name.values[0]\n        # Iterating over the grid returns the Axes.\n        _ = ax.set_title(str(cat))\n        _ = ax.imshow(mpimg.imread(img))\n        _ = ax.axis('off')\n\n    _ = plt.show()","59c2c0b6":"plot_images(3,3)","5d7e3ef7":"def draw_bbox(img_path = \"\/kaggle\/input\/iwildcam-2020-fgvc7\/train\/92b8a1d0-21bc-11ea-a13a-137349068a90.jpg\"):\n    \n    img_id = img_path.split('\/')[-1].split('.')[0] \n    img = mpimg.imread(img_path)\n    detections = df_detections[df_detections.id==img_id].detections.values[0]\n    annotation = df_train_annotations[df_train_annotations.image_id == img_id]\n    \n    count = annotation['count'].values\n    cat_id = annotation.category_id\n    cat = df_cat[df_cat.id == int(cat_id)].name.values[0]\n    \n    _ = plt.figure(figsize = (15,20))\n    _ = plt.axis('off')\n    ax = plt.gca()\n    ax.text(10,100, f'{cat} {count}', fontsize=20, color='fuchsia')\n\n    for detection in detections:\n        # ref - https:\/\/github.com\/microsoft\/CameraTraps\/blob\/e530afd2e139580b096b5d63f0d7ab9c91cbc7a4\/visualization\/visualization_utils.py#L392\n        x_rel, y_rel, w_rel, h_rel = detection['bbox']    \n        img_height, img_width, _ = img.shape\n        x = x_rel * img_width\n        y = y_rel * img_height\n        w = w_rel * img_width\n        h = h_rel * img_height\n        \n        cat = 'animal' if detection['category'] == \"1\" else 'human'\n        bbox = patches.FancyBboxPatch((x,y), w, h, alpha=0.8, linewidth=6, capstyle='projecting', edgecolor='fuchsia', facecolor=\"none\")\n        \n        ax.text(x+1.5, y-8, f'{cat} {detection[\"conf\"]}', fontsize=10, bbox=dict(facecolor='fuchsia', alpha=0.8, edgecolor=\"none\"))\n        ax.add_patch(bbox)\n\n    _ = plt.imshow(img)","22df1aa6":"img_path = \"\/kaggle\/input\/iwildcam-2020-fgvc7\/train\/92b8a1d0-21bc-11ea-a13a-137349068a90.jpg\"\ndraw_bbox(img_path)","15ba93bf":"df_train_annotations.category_id.value_counts()","b9380c43":"plt.figure(figsize=(40,5))\ndf_cat_dist = df_train_annotations.category_id.value_counts()\nprint(f\"Excluding {df_cat_dist[0]} images from the empty class in the barplot visualization\")\ndf_cat_dist = df_cat_dist[1:]\nchart = sns.barplot(y=df_cat_dist.values, x=df_cat_dist.index, orient='v')\n_ = chart.set_xticklabels(chart.get_xticklabels(), rotation=90)","65ae362e":"def extract_objects(img_path = \"\/kaggle\/input\/iwildcam-2020-fgvc7\/train\/92b8a1d0-21bc-11ea-a13a-137349068a90.jpg\", show=False):\n    objects = []\n    confidences = []\n    categories = []\n    \n    img_id = img_path.split('\/')[-1].split('.')[0] \n    img = np.array(mpimg.imread(img_path))\n    if (df_detections[df_detections.id==img_id].detections.values):\n        pass\n    else:\n        return None\n    detections = df_detections[df_detections.id==img_id].detections.values[0]\n    annotation = df_train_annotations[df_train_annotations.image_id == img_id]\n    cat_id = annotation.category_id\n    cat = df_cat[df_cat.id == int(cat_id)].name.values[0]\n    \n    for idx, detection in enumerate(detections):\n        # save confidence\n        confidences.append(detection[\"conf\"])\n        if detection['category'] == \"1\":\n            categories.append(cat)\n        else:\n            categories.append('human')\n\n        x_rel, y_rel, w_rel, h_rel = detection['bbox']    \n        img_height, img_width, _ = img.shape\n        x = floor(x_rel * img_width)\n        y = floor(y_rel * img_height)\n        w = floor(w_rel * img_width)\n        h = floor(h_rel * img_height)\n\n        obj = img[int(y):int(y+h),int(x):int(x+w)]\n        objects.append(obj)\n        if show:\n            _ = plt.figure()\n            _ = plt.xticks([])\n            _ = plt.yticks([])\n            _ = plt.imshow(obj)\n    \n    return objects, categories, confidences","afca8b23":"_ = extract_objects(show=True)  ","ea03cd85":"def save_data(img_path):\n    img_id = img_path.split('\/')[-1].split('.')[0] \n    objects, cats, confs = extract_objects(img_path)\n    for i in range(len(objects)):\n        meta_df.loc[len(meta_df)] = [f'{img_id}_{i}', img_id, cats[i], confs[i]]\n        try:\n            mpimg.imsave(f'train\/{img_id}_{i}.jpg', objects[i])\n        except:\n            pass","be4b03cf":"## Extract Objects","8ae2e8e5":"## Image Data","9bb6827a":"## BBoxes Visualization","a9fe08eb":"<div style=\"text-align: center\"><h2><font color=\"sky_blue\">iWildCam 2020 - FGVC7<\/font><\/h2><\/div>\n<div style=\"text-align: center\"><h3><font color=\"sky_blue\">Categorize animals in the wild<\/font><\/h3><\/div>\n\n","8a8ba27e":"### Megadetector Results","283f188c":"This kernel is made to provide a quick overview of the content of the data provided. Includes-\n* Sample data of each of the meta data files \n* Code to display multiple training images with the its catergory name\n* Distribution of the classes\n* Bounding box annotation\n* Extract animals\/humans to feed to your classifier  \n* New dataset for easier classificaton\n","e1977799":"## Animal Distribution\nNow that we have checked out the data, lets analyze what we have!","41b131c3":"<div class=\"alert alert-block alert-warning\">\n<b>Note:<\/b>  pd.read_json() is tricky as you have different data in the json. Its easier to convert to dic\n<\/div>","e38307b5":"## Meta data files","49d3fb27":"## Create new cropped dataset","c3622ab0":"You can notice that there is so a huge imbalance in the classes.   \nThis is very expected, what are the odds of catching an Yeti in one of these cams \ud83d\ude09","735bce81":"### Test Information","244c98d2":"<div class=\"alert alert-block alert-warning\">\n<b>Note:<\/b>  Do not run the direcory listing cod provided. It takes too long as it tries to print all of the training and test data files\n<\/div>","692cc3cf":"<div class=\"alert alert-block alert-success\">\nI hope this kernel gives you a good overview of the data. Thanks for reading! Consider an <b>upvote!<\/b> if it helps, it helps me :) \n<\/div>","3ca40dfc":"### Training Annotaions","6b0e4483":"## View Images"}}