{"cell_type":{"5c79e481":"code","0b989dab":"code","f4349ae7":"code","4bf95f5d":"code","2839431b":"code","fc4dbd3c":"code","ba88019b":"code","a8b28b15":"code","bff64e5f":"code","6c6057fc":"code","6a29f406":"code","59dfd7e2":"code","98554759":"code","2370d06a":"code","bcfc7a02":"code","13dec897":"code","2f7005c1":"code","1f8e04c7":"code","1f69e974":"code","2a1f2ba9":"code","5af519cc":"code","db2ae054":"code","a219eab3":"code","55eb5971":"code","f641f418":"code","769d7a34":"code","68e45861":"code","25b65452":"code","5dfc1a5a":"code","767bf6d6":"code","4d4c9bf9":"markdown","dcee405b":"markdown","ac07bd2a":"markdown","4e4640f9":"markdown","ac590134":"markdown","90a9f0e4":"markdown","2b248428":"markdown","fd60ebe2":"markdown","55f08532":"markdown","b553f68f":"markdown","156c4441":"markdown","d0e40f4c":"markdown","d3f11a90":"markdown","22c520ef":"markdown","23c8fe5f":"markdown","27a00f50":"markdown","f7e8e5f0":"markdown","8e690d16":"markdown","034b9e34":"markdown","0574d7a0":"markdown","befb328c":"markdown","4fd74c1f":"markdown","9a114a7e":"markdown","ccc054d5":"markdown","a06214f6":"markdown","a148696a":"markdown","2012c70d":"markdown","60747193":"markdown","e8f433a7":"markdown","459803a8":"markdown","e32f74db":"markdown","dcd69322":"markdown","3614fa4b":"markdown","3df42769":"markdown","01f85a80":"markdown","1ed284e5":"markdown","777f75b4":"markdown","89a963b3":"markdown","4b637541":"markdown"},"source":{"5c79e481":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nplt.style.use('fivethirtyeight')\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0b989dab":"train_df=pd.read_csv('\/kaggle\/input\/my-dataset\/credit_train.csv')\ntest_df=pd.read_csv('\/kaggle\/input\/my-dataset\/credit_test.csv')","f4349ae7":"train_df.head()","4bf95f5d":"train_df.tail()","2839431b":"train_df.info()","fc4dbd3c":"train_df.columns","ba88019b":"print('(number of rows, number of columns) : ',train_df.shape)","a8b28b15":"train_df.dtypes","bff64e5f":"train_df.isnull().sum()","6c6057fc":"train_df.notnull().sum()","6a29f406":"object_train_df=train_df.select_dtypes(include=['object'])\nobject_train_df.columns","59dfd7e2":"num_train_df=train_df.select_dtypes(include=['int','float'])\nnum_train_df.columns","98554759":"for i in object_train_df.columns:\n    print(train_df[i].value_counts())\n    print('-'*40)","2370d06a":"for i in object_train_df.columns:\n    print(i)\n    print(train_df[i].unique())\n    print('-'*40)","bcfc7a02":"train_df['Annual Income'].head()","13dec897":"train_df['Annual Income']+train_df['Monthly Debt']","2f7005c1":"train_df.iloc[2,5]","1f8e04c7":"train_df.describe()","1f69e974":"train_df.corr()","2a1f2ba9":"sns.heatmap(train_df.corr())","5af519cc":"print('variance of each column')\ntrain_df.var()","db2ae054":"cols_to_drop=['Loan ID','Customer ID']\ntrain_df=train_df.drop(cols_to_drop,axis=1)\ntrain_df.columns","a219eab3":"col_mean=train_df['Monthly Debt'].mean()\ntrain_df['Monthly Debt']=train_df['Monthly Debt'].fillna(col_mean)\ntrain_df['Monthly Debt'].isnull().sum()","55eb5971":"train_df=train_df.dropna()\ntrain_df.shape","f641f418":"mapping_dict = {\n    \"Years in current job\": {\n        \"10+ years\": 10,\n        \"9 years\": 9,\n        \"8 years\": 8,\n        \"7 years\": 7,\n        \"6 years\": 6,\n        \"5 years\": 5,\n        \"4 years\": 4,\n        \"3 years\": 3,\n        \"2 years\": 2,\n        \"1 year\": 1,\n        \"< 1 year\": 0,\n        \"n\/a\": 0\n    }\n}\ntrain_df=train_df.replace(mapping_dict)\ntrain_df['Years in current job']=train_df['Years in current job'].astype('int')\ntrain_df['Years in current job'].head()","769d7a34":"train_df.rename(columns={'Years in current job':'Years_in_current_job'},inplace=True)\ntrain_df.columns","68e45861":"all_data=pd.concat([object_train_df,num_train_df],axis=1)\nall_data.head()","25b65452":"train_df['Purpose'].value_counts().plot.bar()","5dfc1a5a":"train_df['Years of Credit History'].plot.hist()","767bf6d6":"train_df['Years of Credit History'].plot.kde(label='distribution')\nplt.axvline(train_df['Years of Credit History'].mean(),color='red',label='mean')\nplt.legend(loc='best')\nplt.show()","4d4c9bf9":"<p>I hope this tutorial helps anyone want to start coding in pandas there are alot of functions and methods but here there are alot of basic functions and methods good luck<\/p>\n<h1>Thanks<\/h1>","dcee405b":"<p>WoW now we see there are no missing values<\/p>","ac07bd2a":"<p>to access the values of certain column<\/p>","4e4640f9":"<h1>All What You Need to Know about Pandas<\/h1>\n<p>In computer programming, pandas is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series. It is free software released under the three-clause BSD license.[2] The name is derived from the term \"panel data\", an econometrics term for data sets that include observations over multiple time periods for the same individuals.<\/p>\n<h3>Library Features<\/h3>\n<ul>\n    <li>DataFrame object for data manipulation with integrated indexing.<\/li>\n    <li>Tools for reading and writing data between in-memory data structures and different file formats.<\/li>\n    <li>Data alignment and integrated handling of missing data.<\/li>\n    <li>Reshaping and pivoting of data sets.<\/li>\n    <li>Label-based slicing, fancy indexing, and subsetting of large data sets.<\/li>\n    <li>Data structure column insertion and deletion.<\/li>\n    <li>Group by engine allowing split-apply-combine operations on data sets.<\/li>\n    <li>Data set merging and joining.<\/li>\n    <li>Hierarchical axis indexing to work with high-dimensional data in a lower-dimensional data structure.<\/li>\n    <li>Time series-functionality: Date range generation[4] and frequency conversion, moving window statistics, moving window linear regressions, date shifting and lagging.<\/li>\n    <li>Provides data filtration.<\/li>\n<ul>\n<h3>What is Dataframe<\/h3>\n<p>Pandas is mainly used for machine learning in form of dataframes. Pandas allow importing data of various file formats such as csv, excel etc. Pandas allows various data manipulation operations such as groupby, join, merge, melt, concatenation as well as data cleaning features such as filling, replacing or imputing null values.<\/p>","ac590134":"<p>use Series.replace() to replace the values in columns and Series.astype() to convert the data-type of columns<\/p>","90a9f0e4":"<p>these columns are the columns that have object type<\/p>","2b248428":"<p>We Can combine data using the pd.concat() and pd.merge()<\/p>","fd60ebe2":"<p>We can access the values in the dataframe like the way we access the values in list by using DataFrame.iloc[] or DataFrame.loc[]<\/p>","55f08532":"<h3>Compining Data With Pandas<\/h3>","b553f68f":"<h3>Statistical Functions in Pandas<\/h3>","156c4441":"<p>let's drop some columns of our data by using DataFrame.drop()<\/p>","d0e40f4c":"<p>let's use DataFrame.notnull().sum() to see the number of non missing-values in each column<\/p>","d3f11a90":"<p>Because pandas is designed to operate like NumPy, a lot of concepts and methods from Numpy are supported. Recall that one of the ways NumPy makes working with data easier is with vectorized operations, or operations applied to multiple data points at once<\/p>","22c520ef":"<p>now let's fill the missing values in  'Monthly Debt' column with the mean<\/p>","23c8fe5f":"<h3>Data Types<\/h3>\n<p>\nData has a variety of types.<br>\nThe main types stored in Pandas dataframes are <b>object<\/b>, <b>float<\/b>, <b>int<\/b>, <b>bool<\/b> and <b>datetime64<\/b>. In order to better learn about each attribute, it is always good for us to know the data type of each column. In Pandas:\n<\/p>","27a00f50":"<p>let's use Vectorized Operations like addition>\/p>","f7e8e5f0":"<p>We Can also drop the missing values from the DataFrame<\/p>","8e690d16":"<h3>Descriptive Statistical Analysis<\/h3>\n<p>Let's first take a look at the variables by utilizing a description method.<\/p>\n\n<p>The <b>describe<\/b> function automatically computes basic statistics for all continuous variables. Any NaN values are automatically skipped in these statistics.<\/p>\n\nThis will show:\n<ul>\n    <li>the count of that variable<\/li>\n    <li>the mean<\/li>\n    <li>the standard deviation (std)<\/li> \n    <li>the minimum value<\/li>\n    <li>the IQR (Interquartile Range: 25%, 50% and 75%)<\/li>\n    <li>the maximum value<\/li>\n<ul>","034b9e34":"<h3>Correlation<\/h3>\n<p>for example, we can calculate the correlation between variables  of type \"int64\" or \"float64\" using the method \"corr\"<\/p>","0574d7a0":"<p>the previous code displays the first five rows of the dataframe<\/p>","befb328c":"<h3>Some Statistical Functions<\/h3>\n<ul>\n    <li>Series.max() and DataFrame.max()<\/li>\n    <li>Series.min() and DataFrame.min()<\/li>\n    <li>Series.mean() and DataFrame.mean()<\/li>\n    <li>Series.median() and DataFrame.median()<\/li>\n    <li>Series.mode() and DataFrame.mode()<\/li>\n    <li>Series.sum() and DataFrame.sum()<\/li>\n    <li>Series.var() and DataFrame.var():variance<\/li>\n<\/ul>","4fd74c1f":"<p>you can use Series.unique() to get unique values in columns<\/p>","9a114a7e":"<p>the previous code to Find the name of the columns of the dataframe<\/p>","ccc054d5":"<p>We can change column names too by using DataFrame.rename()<\/p>","a06214f6":"<p>This is for frequency distribution<\/p>","a148696a":"<p>let's use DataFrame.isnull().sum() to see the number of missing-values in each column<\/p>","2012c70d":"<h3>Exploring our Dataset<\/h3>\n<p>Next, let's use the DataFrame.head() and DataFrame.info() and DataFrame.tail() methods to refamiliarize ourselves with the data.<\/p>","60747193":"<p>let's use DataFrame.columns, DataFrame.shape, DataFrame.dtypes<\/p>","e8f433a7":"<p>first we import pandas, numpy and matplotlib packages to use them in our python kernel, and know the path of our datasets<\/p>","459803a8":"<p>the previous code gives you full describtion about your data like the data type of each column, the number of non-null rows and the shape o your data<\/p>","e32f74db":"<h3>Visualization in Pandas<\/h3>","dcd69322":"<p>Series.map() and Series.apply() methods and confirmed that both methods produce the same results.<\/p>","3614fa4b":"<p>We can produce heatmap for the correlation by using seaborn package<\/p>","3df42769":"<p>Yaaaa! We did it<\/p>","01f85a80":"<h3>Save and Read Dataframes<\/h3>\n<h4>CSV<\/h4>\n<p>Read: pd.read_csv(),Save:pd.to_csv()<\/p>\n<h4>Json<\/h4>\n<p>Read: pd.read_json(),Save:pd.to_json()<\/p>\n<h4>Excel<\/h4>\n<p>Read: pd.read_excel(),Save:pd.to_excel()<\/p>\n<h4>hdf<\/h4>\n<p>Read: pd.read_hdf(),Save:pd.to_hdf()<\/p>\n<h4>SQL<\/h4>\n<p>Read: pd.read_sql(),Save:pd.to_sql()<\/p>","1ed284e5":"<p>let's use DataFrame.select_dtype(include['Data type we want'])to select columns of a specific data type<\/p> ","777f75b4":"<p>the previous code displays the last five rows of the dataframe<\/p>","89a963b3":"<h3>handling Missing Data and Modify the Dataframe<\/h3>","4b637541":"<p> we use Series.value_counts() method to display the counts of the unique values in a column<\/p>"}}