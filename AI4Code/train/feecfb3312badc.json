{"cell_type":{"54433ab0":"code","27b4f849":"code","75c66504":"code","ecffd74a":"code","b32eea9f":"code","2a031435":"code","835e4d7e":"code","290c3a6c":"code","e362f359":"code","9610c5c9":"code","51421e88":"code","1e8f38ba":"code","7c99099b":"code","b5b480a5":"code","fb66e91c":"code","2ac8d124":"code","c22baee3":"code","8f35b6eb":"code","5f687c9d":"code","f9bea6d2":"code","8d5da178":"markdown","d7cd9949":"markdown","ce91d360":"markdown","546df343":"markdown","1c79aa5b":"markdown","90b46c36":"markdown","39ffbfc0":"markdown","f5f4f44d":"markdown"},"source":{"54433ab0":"import cv2\nimport collections\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\n\nfrom PIL import Image, ImageFile\nimport pandas as pd\nimport torch.nn as nn\nfrom tqdm import tqdm_notebook as tqdm\nfrom ipywidgets import IntProgress\nfrom torch.autograd import Variable\n\nimport torch.utils.data\nfrom torchvision import models\nfrom torchvision import transforms\nimport torchvision\nfrom torch.utils.data import DataLoader, Dataset, sampler\n#torch.backends.cudnn.enabled = False","27b4f849":"# Checking python versions\nimport platform\nprint(f'Python version: {platform.python_version()}')\nprint(f'PyTorch version: {torch.__version__}')","75c66504":"# Read csv\ntrain = pd.read_csv(\"\/kaggle\/input\/severstal-steel-defect-detection\/train.csv\")\ntrain.head()","ecffd74a":"train_defect = train[train['EncodedPixels'].notnull()]\ntrain_defect = train_defect.reset_index(drop=True)\ntrain_defect = train_defect[:2000] # Loading only 2000 samples to check whether flow is correct\ntrain_defect.head()","b32eea9f":"def rle2mask(rle, imgshape):\n    width = imgshape[0]\n    height= imgshape[1]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )","2a031435":"columns = 1\nrows = 4\nfig = plt.figure(figsize=(20,columns*rows+6))\nfor i in range(1,columns*rows+1):\n    fn = train_defect['ImageId_ClassId'].str[:-2].iloc[i]\n    fig.add_subplot(rows, columns, i).set_title(fn)\n    img = cv2.imread( '\/kaggle\/input\/severstal-steel-defect-detection\/train_images\/'+fn )\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    mask = rle2mask(train_defect['EncodedPixels'].iloc[i], (256, 1600))\n    img[mask==1,0] = 255\n    plt.imshow(img)\nplt.show()","835e4d7e":"class ImageData(Dataset):\n    def __init__(self, df, transform, subset=\"train\"):\n        super().__init__()\n        self.df = df\n        self.transform = transform\n        self.subset = subset\n        \n        if self.subset == \"train\":\n            self.data_path = '\/kaggle\/input\/severstal-steel-defect-detection\/train_images\/'\n        elif self.subset == \"test\":\n            self.data_path = \"\/kaggle\/input\/severstal-steel-defect-detection\/test_images\/\"\n            \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        fn = self.df[\"ImageId_ClassId\"].iloc[index].split('_')[0]\n        img = Image.open(self.data_path + fn)\n        img = self.transform(img)\n        \n        if self.subset == \"train\":\n            mask = rle2mask(self.df[\"EncodedPixels\"].iloc[index], (256, 1600))\n            mask = transforms.ToPILImage()(mask)\n            mask = self.transform(mask)\n            return img,mask\n        else:\n            mask = None\n            return img","290c3a6c":"data_transf = transforms.Compose([\n                                    transforms.Resize((256,800)),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize(mean=[0.485], std=[0.229])\n])\ntrain_data = ImageData(df= train_defect, transform = data_transf )\n","e362f359":"class DiceLoss(torch.nn.Module):\n    def __init__(self):\n        super(DiceLoss, self).__init__()\n        \n    def forward(self, logits, targets):\n        \n        N = targets.size(0)\n        preds = torch.sigmoid(logits)\n        \n        EPSILON = 1e-7\n        \n        # Flattening the final layer \n        preds_flat = preds.view(N,-1)\n        targets_flat = targets.view(N, -1)\n        \n        intersection = (preds_flat * targets_flat).sum()\n        union = (preds_flat + targets_flat).sum()\n        \n        loss = (2.0 * intersection + EPSILON) \/ (union + EPSILON)\n        loss = 1 - loss \/ N\n        return loss","9610c5c9":"# To start with optmized learning rate\ndef warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor):\n\n    def f(x):\n        if x >= warmup_iters:\n            return 1\n        alpha = float(x) \/ warmup_iters\n        return warmup_factor * (1 - alpha) + alpha\n\n    return torch.optim.lr_scheduler.LambdaLR(optimizer, f)","51421e88":"# train function\ndef train(model, optimizer, data_loader, device, epoch):\n    model.train()\n    loss_func = DiceLoss() #nn.BCEWithLogitsLoss() \n\n    lr_scheduler = None\n    if epoch == 0:\n        warmup_factor = 1. \/ 1000\n        warmup_iters = min(1000, len(data_loader) - 1)\n\n        lr_scheduler = warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n\n    lossf=None\n    inner_tq = tqdm(data_loader, total=len(data_loader), leave=False, desc= f'Epoch: {epoch+1}')\n    for images, masks in inner_tq:\n        y_preds = model.forward(images.to(device))\n        # For Segnet\n        y_preds = y_preds[:, 1, :, :] \n        # For DeepLab V3\n#         y_preds = y_preds['out'][:, 1, :, :] \n\n        loss = loss_func(y_preds, masks.to(device))\n\n        if torch.cuda.device_count() > 1:\n            loss = loss.mean() # mean() to average on multi-gpu.\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        if lr_scheduler is not None:\n            lr_scheduler.step()\n\n        if lossf:\n            lossf = 0.98*lossf+0.02*loss.item()\n        else:\n            lossf = loss.item()\n        inner_tq.set_postfix(loss = lossf)","1e8f38ba":"!wget 'https:\/\/download.pytorch.org\/models\/vgg19_bn-c79401a0.pth'","7c99099b":"# Model Definition\n\ndef initialize_weights(*models):\n    for model in models:\n        for module in model.modules():\n            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n                nn.init.kaiming_normal(module.weight)\n                if module.bias is not None:\n                    module.bias.data.zero_()\n            elif isinstance(module, nn.BatchNorm2d):\n                module.weight.data.fill_(1)\n                module.bias.data.zero_()\n                \nclass _DecoderBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, num_conv_layers):\n        super(_DecoderBlock, self).__init__()\n        middle_channels = int(in_channels \/ 2)\n        layers = [\n            nn.ConvTranspose2d(in_channels, in_channels, kernel_size=2, stride=2),\n            nn.Conv2d(in_channels, middle_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(middle_channels),\n            nn.ReLU(inplace=True)\n        ]\n        layers += [\n                      nn.Conv2d(middle_channels, middle_channels, kernel_size=3, padding=1),\n                      nn.BatchNorm2d(middle_channels),\n                      nn.ReLU(inplace=True),\n                  ] * (num_conv_layers - 2)\n        layers += [\n            nn.Conv2d(middle_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        ]\n        self.decode = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.decode(x)\n\n\nclass SegNet(nn.Module):\n    def __init__(self, num_classes, pretrained=True):\n        super(SegNet, self).__init__()\n        vgg = models.vgg19_bn()\n        vgg19_bn_path = \"vgg19_bn-c79401a0.pth\"\n        if pretrained:\n            vgg.load_state_dict(torch.load(vgg19_bn_path))\n        vgg = vgg.cuda()\n        features = list(vgg.features.children())\n        self.enc1 = nn.Sequential(*features[0:7])\n        self.enc2 = nn.Sequential(*features[7:14])\n        self.enc3 = nn.Sequential(*features[14:27])\n        self.enc4 = nn.Sequential(*features[27:40])\n        self.enc5 = nn.Sequential(*features[40:])\n\n        self.dec5 = nn.Sequential(\n            *([nn.ConvTranspose2d(512, 512, kernel_size=2, stride=2)] +\n              [nn.Conv2d(512, 512, kernel_size=3, padding=1),\n               nn.BatchNorm2d(512),\n               nn.ReLU(inplace=True)] * 4)\n        )\n        self.dec4 = _DecoderBlock(1024, 256, 4)\n        self.dec3 = _DecoderBlock(512, 128, 4)\n        self.dec2 = _DecoderBlock(256, 64, 2)\n        self.dec1 = _DecoderBlock(128, num_classes, 2)\n        initialize_weights(self.dec5, self.dec4, self.dec3, self.dec2, self.dec1)\n\n    def forward(self, x):\n        enc1 = self.enc1(x)\n        enc2 = self.enc2(enc1)\n        enc3 = self.enc3(enc2)\n        enc4 = self.enc4(enc3)\n        enc5 = self.enc5(enc4)\n\n        dec5 = self.dec5(enc5)\n        dec4 = self.dec4(torch.cat([enc4, dec5], 1))\n        dec3 = self.dec3(torch.cat([enc3, dec4], 1))\n        dec2 = self.dec2(torch.cat([enc2, dec3], 1))\n        dec1 = self.dec1(torch.cat([enc1, dec2], 1))\n        return nn.Parameter(dec1)","b5b480a5":"# Model Declaration \n#SegNet\nmodel_ft = SegNet(num_classes=4,pretrained=False)\n\n# DeeplabV3\n# model_ft = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=False, num_classes=4)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n_ = model_ft.to(device)","fb66e91c":"# train DataLoader\nNUM_GPUS = torch.cuda.device_count()\nif NUM_GPUS > 1:\n    model_ft = torch.nn.DataParallel(model_ft)\ndata_loader = DataLoader(train_data, batch_size = 8, shuffle = True,\n                         num_workers = NUM_GPUS)","2ac8d124":"# Optimizer \nparams = [p for p in model_ft.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr = 0.001, momentum = 0.9 , weight_decay = 0.0005)","c22baee3":"# Learning Scheduler\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.1 )","8f35b6eb":"num_epochs = 2\nfor epoch in range(num_epochs):\n    train(model_ft, optimizer, data_loader, device, epoch)\n    lr_scheduler.step()","5f687c9d":"# Save the model \ntorch.save(model_ft.state_dict(),\"model_seg_last.pth\")","f9bea6d2":"# Loading and check the model\n# SegNet\nmodel = SegNet(num_classes = 4)\n\n# DeepLabV3\n# model = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=False, num_classes=4)\n\nmodel.load_state_dict(torch.load(\"model_seg_last.pth\"))\nmodel.eval()","8d5da178":"### Train Function","d7cd9949":"### Visualize data ","ce91d360":"## Pytorch SegNet and DeepLabV3 Implementation\n**Please upvote if this notebook is useful **","546df343":"### DataSet and DataLoader","1c79aa5b":"![image.png](attachment:image.png)\nAfter Resnet34 Classifier Training ( https:\/\/www.kaggle.com\/robinreni\/heng-s-pytorch-resnet34-classifier-training ) we have to train our segmentation module","90b46c36":"A Huge thanks to the author of  https:\/\/www.kaggle.com\/mobassir\/deeplabv3-resnet101-for-severstal-sdd .","39ffbfc0":"### Mask Decoder :\nTo mask the images from the given encodings ","f5f4f44d":"#### Loss Function :\nSince they mentioned to use dice loss explicitly we are using it for the segmentation"}}