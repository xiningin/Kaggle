{"cell_type":{"0fd37414":"code","c33ce1f9":"code","c8ecb4b5":"code","85ee205c":"code","8f4d253e":"code","5f6b7436":"code","93e95ca5":"code","73813033":"code","ae630b42":"code","092861a1":"code","7d2744bc":"code","4a1c8b20":"code","5cf3ed9b":"code","e0c77645":"code","44c67ff3":"code","77c5cb1e":"code","117e5991":"code","70b3aa7b":"code","8d134c9a":"code","45a14a03":"markdown","438837e1":"markdown","970a9d2d":"markdown","620bd878":"markdown","26bfe77e":"markdown","fdc828d0":"markdown","1ddc0182":"markdown","bae8e8ef":"markdown","0e9a23d2":"markdown","e5bc5a41":"markdown","60648f17":"markdown","e1c143e9":"markdown","9f5b4e2f":"markdown","21d68bc4":"markdown","d2a1f07d":"markdown","6a518a6d":"markdown","3bec6a61":"markdown","464e1d25":"markdown","4d57f196":"markdown","7a686db3":"markdown","d8617417":"markdown","59e191b8":"markdown","c010d79e":"markdown","2806d32a":"markdown","ef463906":"markdown"},"source":{"0fd37414":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom scipy import interpolate\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.stattools import adfuller\nimport warnings\nimport itertools\nwarnings.filterwarnings(\"ignore\")\nimport statsmodels.api as sm\nimport matplotlib\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c33ce1f9":"#Reading datasets\ndf_train=pd.read_csv(\"\/kaggle\/input\/daily-climate-time-series-data\/DailyDelhiClimateTrain.csv\")\ndf_test=pd.read_csv(\"\/kaggle\/input\/daily-climate-time-series-data\/DailyDelhiClimateTest.csv\")\ndf=df_train.interpolate(method='linear')\n\n\n#Changing to date type to facilitate indexing\ndf['conv_date']=pd.to_datetime(df.date)\n","c8ecb4b5":"#(1a)\n\n#Getting the time series ready to plot by indexing via date\ndf_q1= df.resample('D',on=\"conv_date\").mean() \nplt.figure(figsize=(30,10))\nplt.plot(df_q1['meantemp'],'-',label=\"meantemp\")\nplt.xlabel('Date')\nplt.ylabel('MeanTemp')\nplt.title('Plot of MeanTemp')\nplt.legend(loc=2)\nplt.show()\n\n","85ee205c":"#(1)(b)(i)\n\n#Performing smoothing average with an average as provided in the question\n# In iloc[,1], 1 stands for meantemp\n#We also fill the NA values with 0 \n\ndf_q1['SMA_10'] = df_q1.iloc[:,0].rolling(window=10).mean()\ndf_q1=df_q1.fillna(0)\nplt.figure(figsize=(30,10))\nplt.plot(df_q1['SMA_10'],'-',label=\"SMA(10)\")\nplt.xlabel('Date')\nplt.ylabel('MeanTemp')\nplt.title('Simple moving average')\nplt.legend(loc=2)\nplt.show()\n\n\n","8f4d253e":"#(i)(b)(ii)\n\n#Applying weighted average as a dot product i.e multiplication of the data point and the filter weight divided by sum of values(done by the lambda function)\n#Here we fill the NA with 0\n\nweights=[1.5,1.5,1,0.5,0.5,0.5,0.5,1,1.5,1.5]\nweights=np.asarray(weights)\ndf_q1['WMA_10'] = df_q1.iloc[:,0].rolling(10).apply(lambda temp: np.dot(temp,weights)\/weights.sum(),raw=True)\ndf_q1=df_q1.fillna(0)\nplt.figure(figsize=(30,10))\nplt.plot(df_q1['WMA_10'],'-',label=\"WMA\")\nplt.xlabel('Date')\nplt.ylabel('MeanTemp')\nplt.title('Weighted moving average')\nplt.legend(loc=2)\nplt.show()","5f6b7436":"plt.figure(figsize=(30,10))\nplt.plot(df_q1['meantemp'],'-',label=\"Original meantemp\",color=\"green\",alpha=0.3)\nplt.plot(df_q1['SMA_10'],'-',label=\"SMA(10)\",color=\"blue\")\nplt.plot(df_q1['WMA_10'],'-',label=\"WMA\",color=\"red\")\nplt.xlabel('Date')\nplt.ylabel('MeanTemp')\nplt.title('Plot of meantemp')\nplt.legend()\nplt.show()","93e95ca5":"#(i)(c)(i)\n\n#Since we have daily data resampling to Hourly based on mean will introduce NaNs for 23 hours out of 24 per day. Linear interpolating the values\n\n\ndf_hour = df.resample('H',on=\"conv_date\").mean()\ndf_h_fin=df_hour.interpolate(method='linear')\nplt.figure(figsize=(30,10))\nplt.plot(df_h_fin['meantemp'],'-',label=\"Resampled Hourly\")\nplt.xlabel('Date')\nplt.ylabel('MeanTemp')\nplt.title('Hourly resampled data')\nplt.legend(loc=2)\nplt.show()\n","73813033":"#(i)(c)(ii)\n\n#We perform resampling weekly based on date and taking the mean of all observations\n\ndf_week = df.resample('W',on=\"conv_date\").mean() \nplt.figure(figsize=(30,10))\nplt.plot(df_week['meantemp'],'-',label=\"Weekly\")\nplt.xlabel('Date')\nplt.ylabel('MeanTemp')\nplt.title('Weekly resampled data')\nplt.legend(loc=2)\nplt.show()","ae630b42":"#)(i)(c)(iii)\n\n#Performing resampling monthly based on date by making use of mean of all observations belonging to a month\ndf_month = df.resample('M',on=\"conv_date\").mean() \nplt.figure(figsize=(30,10))\nplt.plot(df_month['meantemp'],'-',label=\"Monthly\")\nplt.xlabel('Date')\nplt.ylabel('MeanTemp')\nplt.title('Monthly resampled data')\nplt.legend(loc=2)\nplt.show()","092861a1":"#(i)(c)(iv)\n\n#Resampling quarterly based on date and taking mean of all days per quarter\ndf_quarter = df.resample('Q',on=\"conv_date\").mean() \nplt.figure(figsize=(30,10))\nplt.plot(df_quarter['meantemp'],'-',label=\"Quarterly\")\nplt.xlabel('Date')\nplt.ylabel('MeanTemp')\nplt.title('Quarterly resampled data')\nplt.legend(loc=2)\nplt.show()","7d2744bc":"#(2)(a)(i)\n\n#Decomposing the given time series to obtain the components\ncomponents = seasonal_decompose(df_month['meantemp'])\ncomponents.plot()\nplt.show()","4a1c8b20":"#To find if the series is additive or multiplicative we add the individual components \n#and see which out of additive or multiplicative can bring back the original data\n\nadditive = components.trend + components.seasonal + components.resid\nmultiplicative = components.trend * components.seasonal * components.resid\n\n#Additive\nplt.plot(components.observed, label=\"Original\")\nplt.plot(additive, label=\"Additive\")\nplt.xlabel('Date')\nplt.ylabel('Mean temperature')\nplt.title('Additive series')\nplt.legend(loc=2)\nplt.show()\n\n#Multiplicative\nplt.plot(components.observed, label=\"Original\")\nplt.plot(multiplicative, label=\"Multiplicative\")\nplt.xlabel('Date')\nplt.ylabel('Mean temperature')\nplt.title('Miltiplicative Series')\nplt.legend(loc=2)\nplt.show()\n","5cf3ed9b":"#(2)(a)(ii)\n\n#Calling the corresponding ACF and PACF functions\n\nplot_acf(df['meantemp'])\nplt.xlabel('Lag')\nplt.ylabel('Auto correlations')\nplt.title('Plot of ACF')\nplt.show()\n\nplot_pacf(df['meantemp'])\nplt.xlabel('Lag')\nplt.ylabel('Partial Auto correlations')\nplt.title('Plot of PACF')\nplt.show()\n\n","e0c77645":"#The Dickey Fuller test is one of the most popular statistical tests for stationarity \n#It can be used to determine the presence of unit root in the series, and hence help understand if the series is stationary or not. \n#The null and alternate hypothesis of this test are:\n#Null Hypothesis: The series has a unit root (value of a =1)\n#Alternate Hypothesis: The series has no unit root.\n\n\ndftest = adfuller(df['meantemp'], autolag='AIC')\ndfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\nfor key,value in dftest[4].items():\n    dfoutput['Critical Value (%s)'%key] = value\nprint (dfoutput)\n\n#If the test statistic is less than critical value, reject the null hypothesis (series is stationary). \n#When it is greater, we fail to reject the null hypothesis (series is not stationary).\n","44c67ff3":"#Using first order differentials to convert to stationary\n\ndf['meantemp_diff'] = df['meantemp'] - df['meantemp'].shift(1)\n#Repeating the 0th value for the NA\ndf['meantemp_diff'][0] = df['meantemp'][0]\n\n#Performing the Dickey Fuller test\n\ndftest = adfuller(df['meantemp_diff'], autolag='AIC')\ndfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\nfor key,value in dftest[4].items():\n    dfoutput['Critical Value (%s)'%key] = value\nprint (dfoutput)\n\n","77c5cb1e":"#We know that the order of differencing = 1  \n#From the PACF plot we know that p should be = 1 and hence keep it fixed\n\np=[1]\nd=[0,1]\nq=[0,1]\n\nmin_aic=10000\npdq = list(itertools.product(p, d, q))\nseasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n\n#For possible combinations of (p,d,q) and (P,D,Q) we loop over and try to observe how the model performs\nfor param in pdq:\n    for param_seasonal in seasonal_pdq:\n        try:\n            mod = sm.tsa.statespace.SARIMAX(df['meantemp'],order=param,seasonal_order=param_seasonal,enforce_stationarity=False,enforce_invertibility=False)\n            results = mod.fit()\n            \n            print('SARIMA{}x{}12 - AIC:{}'.format(param,param_seasonal,results.aic))\n            if(results.aic<min_aic):\n                min_aic=results.aic\n                min_param=param\n                min_seasonal=param_seasonal\n            \n        except: \n            continue\n\n","117e5991":"print('min aic = ',min_aic)\nprint('Parameters for non seasonal(p,d,q) = ',min_param)\nprint('Parameters for Seasonal(P,D,Q) = ',min_seasonal)","70b3aa7b":"#Fitting the model to the test dataset by passing the order and seasonal order obtained from before\n\nmod = sm.tsa.statespace.SARIMAX(df_test['meantemp'],\n                                order=min_param,\n                                seasonal_order=min_seasonal,\n                                enforce_stationarity=False,\n                                enforce_invertibility=False)\nresults = mod.fit()\nprint(results.summary().tables[1])","8d134c9a":"#Predicting\nyhat = results.predict(start=0, end=len(df_test['meantemp']))\ny_truth = df_test['meantemp']\n\n#Plotting the predicted values on top of the test set\n\nplt.figure(figsize=(30,10))\nplt.plot(yhat, label = \"Predicted\")\nplt.plot(y_truth, label = \"Actual\")\nplt.xlabel('Date')\nplt.ylabel('meantemp')\nplt.title('Plot of meantemp for test set')\nplt.legend(loc=2)\nplt.show()\n\n#Calculating error\nmse = ((yhat - y_truth) ** 2).mean()\nprint('The Mean Squared Error is {}'.format(round(mse, 2)))\nprint('The Root Mean Squared Error is {}'.format(round(np.sqrt(mse), 2)))\n\n\n","45a14a03":"**Question 1**\n<br>\n\n**(1)(a)**\nPlot the \u200bmeantemp \u200b variable across the dataset. \u200b(1 point) <br>\n Note: \u200b Make sure you interpolate the data (linear interpolation) before plotting. (Use this interpolated data for further use as well) <br>","438837e1":" **(ii)(b)(ii)**\n <br>\n If it isn\u2019t stationary convert it to stationary using 1st order differentials. Perform Augmented Dickey Fuller test \u200b to verify that it is indeed stationary. \n ","970a9d2d":"**(i)(b)(ii)**\n<br>\n\n A weighted average  filter. [1.5, .5, 1, 0.5, 0.5, 0.5, 0.5, 1, 1.5, 1.5]1\/10         ","620bd878":"**Question 4**\n<br>\n<br>\n **(iv)(a)**\n <br>\n How would you make use of the other features in the dataset to predict the weather on a particular day in Delhi? What new features would you engineer?\n <br>\n<br>a) <br>\nWe could make use of the features available to predict the weather by modelling them using time series analysis like we did in this assignment.<br>The seasonal components will help us with predicting higher temperatures during the summer months and lower during the winter.<br>\nCorrelation studies between the variables can shine light and help in predicting the weather.<br>\nRegression modelling can be done.<br>\n<br>\n**(iv)(b)**\n<br>\nLSTM (Long Short term memory network) are popularly used to forecast time series data. Why do you think they are used<br><br>\nb)\n<br>\nLong Short Term Memory (LSTM) networks have been demonstrated to be particularly useful for learning sequences containing longer term patterns of unknown length, due to their ability to maintain long term memory and consists of feedback connections.\n","26bfe77e":"**(ii)(a)(ii)**\n<br>\n Plot the ACF and PACF plots for the \u200bmeantemp \u200b series. What can you conclude from the plots? ","fdc828d0":"\nThe weekly and monthly capture the overall essence of the dataset since we can see the seasonal changes present in the original in these resampled data also.<br>\nQuarterly looses subtle information i.e the variation towards the peak, fine details are lost.","1ddc0182":"**(i)(c)(iv)**\n<br>\nResample the \u200bmeantemp \u200b data Quarterly","bae8e8ef":"**Question 2**\n\n","0e9a23d2":"We observe that the PACF graph cuts off whereas the ACF graph decreases. This indicates that the given time series data is Auto regressive i.e the present values can be obtained using previous values of the same time series.<br>\nIt also suggests that p = 1 would be the correct lag for the AR model<br>\nMeaning that the autocorrelation pattern can be explained more easily by adding AR terms than by adding MA terms\n","e5bc5a41":"Here the test statistic is greater than critical value\nWe fail to reject null hypothesis and series is not stationary.","60648f17":"**(1)(b)(i)**\n<br>\nCalculate a Moving Average filter for the mean temperature with i) A 10-tap  filter [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]1\/10          ","e1c143e9":"**(ii)(a)(i)**\n<br>\nDecompose the \u200bMonthly\u200b resampled data into trend, seasonality and residual. Is it an additive or multiplicative series? ","9f5b4e2f":"**(2)(b)(i)**\n<br>\n Provide one \u200bstatistical \u200band one \u200bnon-statistical\u200b test to support your claim.\n <br>\n\nAbout stationary time series : <br>\nThe observations in a stationary time series are not dependent on time.<br>\nTime series is stationary if it does not have trend or seasonal effects. <br>\nSummary statistics (like the mean or the variance) is consistent over time.(Homoscedastic; mean values at different time are constant).<br>\nErrors must follow a white noise i.e zero mean and constant variance.<br>\n\n\nNon - Statistical test for the question can be : <br>\nSince the time series has both a trend and a seasonal component, it is not considered stationary\nWe also observed in the previous questions that the data consisted of some trend and thus it is non stationary from the decomposed plots.<br> Can be seen from the plot of decomposed components","21d68bc4":"Plot the graph after smoothing it with the above two filters. What are your observations?  <br>\n\nWe observe that SMA blurs out the finer details in the plot as observed by the smoothness of the plot since equal weightage is given to all the observations. <br>\nWe see that the weighted moving average does not give equal weight to all observations and the roughness can be observed in the sharp lines on the WMA graph.","d2a1f07d":"**(iii)(b)**<br>\nUse the best parameter obtained to forecast the values for the testing dataset given. Plot the forecasted and actual values together in the same graph. Did the model perform as per expectations, why \/ why not? Report the testing RMSE of the model","6a518a6d":"**(i)(c)(i)**\n<br>\nHow does resampling help a time-series data? \n\nResampling will help when the frequency that the data is obtained is different compared to the frequency require to solve or address the problem in hand.<br>\nResampling also helps to provide additional structure or insight into the problem by obtaining summaries from observations from various scales.<br>","3bec6a61":"\nFrom the above plot, we can see that the predicted values closely resemble the actual values. <br>\nThe RMSE value obtained from this model is 2.24 . This shows that our SARIMA model can be used to predict future temperature values.","464e1d25":"We notice that the SARIMA(1, 1, 1)x(1, 0, 1, 12)12 gives the lowest AIC value. <br>So we use these parameters to bulid our model<br>\nAlso we noticed from the PACF plot that it cuts off after a lag of p = 1<br>\nSARIMA(1, 1, 1)x(1, 0, 1, 12)12 - AIC:5470.9006815845605","4d57f196":"We can see that the additive and the observed components overlap completely \nwhereas the multiplicative doesn't overlap with the observed.\nThis shows that the time series is additive","7a686db3":"**(i)(c)(ii)**\n<br>\nResample the \u200bmeantemp \u200b data Weekly\n","d8617417":"**Question 3**\n\n**(iii)(a)**\n<br>\n What is the major problem with ARIMA? How does SARIMA help overcome the problem? Get the best parameter for the SARIMA model using AIC metric. \n \n<br>a)<br>\nAutoregressive Integrated Moving Average, or ARIMA, is a forecasting method for univariate time series data.\n\nAs its name suggests, it supports both an autoregressive and moving average elements. The integrated element refers to differencing allowing the method to support time series data with a trend.\n\nA problem with ARIMA is that it does not support seasonal data. That is a time series with a repeating cycle.\n\nARIMA expects data that is either not seasonal or has the seasonal component removed, e.g. seasonally adjusted via methods such as seasonal differencing.\n\nSARIMA or Seasonal ARIMA, is an extension of ARIMA that explicitly supports univariate time series data with a seasonal component.\n\nIt adds three new hyperparameters to specify the autoregression (AR), differencing (I) and moving average (MA) for the seasonal component of the series, as well as an additional parameter for the period of the seasonality.\n","59e191b8":"**(i)(c)(iii)**\n<br>\nResample the \u200bmeantemp \u200b data Monthly","c010d79e":"# Assignment 4 \n# WeRAnalysers\nPES1201700005   (Bharani) <br>\nPES1201700032   (Bhavya) <br>\nPES1201700105   (Ruben)<br>","2806d32a":"Resample the \u200bmeantemp \u200b data  i) Hourly ","ef463906":"Here the test statistic is lesser than critical value since -1.6 * 10 = -16 which is less than -2.86. <br> Thus\nwe reject null hypothesis and series is stationary."}}