{"cell_type":{"c5bb715c":"code","854991d0":"code","8cc6b5b7":"code","5f91a106":"code","de709624":"code","ffb4af1d":"code","efcf525c":"code","12a3bf8d":"code","8e0592cc":"code","e2cfc9ff":"code","9dd54ba6":"code","b7e9165b":"code","724193ed":"code","5f9fc2d0":"code","6cb3f34d":"code","32b067bc":"markdown","775b9eea":"markdown","1b15f623":"markdown","670439b3":"markdown","994d2251":"markdown"},"source":{"c5bb715c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\nimport matplotlib.pyplot as plt","854991d0":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.cuda as tc\nfrom torch.autograd import Variable\nimport torch.nn.functional as F","8cc6b5b7":"dt = pd.read_pickle('..\/input\/cifar-100\/train')\ndf = pd.DataFrame.from_dict(dt, orient='index')\ndf = df.T\ndf.head()","5f91a106":"labels = list(pd.read_pickle('..\/input\/cifar-100\/meta')['fine_label_names'])","de709624":"# dictionaries with labels to idx and viceversa\nlabels_idx = {v:k for (k,v) in enumerate(labels)}\nidx_labels = {k:v for (k,v) in enumerate(labels)}","ffb4af1d":"# display a bee image\nimg = np.array(df[df['fine_labels'] == labels_idx['bee']].iloc[10]['data']).reshape(3,32,32)\nplt.imshow(img.transpose(1,2,0).astype(\"uint8\"), interpolation='nearest')","efcf525c":"data_values = df[df['fine_labels'].isin([labels_idx['bee'], labels_idx['butterfly']])]['data'].values\nlabel_values = df[df['fine_labels'].isin([labels_idx['bee'], labels_idx['butterfly']])]['fine_labels'].values","12a3bf8d":"features = np.array(np.stack(data_values, axis=0)).reshape(len(data_values), 3, 32, 32).astype('float32')\nlabels = np.array(label_values).astype('float32')","8e0592cc":"# normalize\nfeatures = features \/ 255.0\n\nfeatures = torch.from_numpy(features)\nlabels = torch.from_numpy(labels)","e2cfc9ff":"# create one hot enconding\nlabels[labels == labels_idx['bee']] = 0\nlabels[labels == labels_idx['butterfly']] = 1\nlabels = torch.eye(2)[labels.type(torch.LongTensor)]","9dd54ba6":"X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)","b7e9165b":"torch.manual_seed(999)\n\nmodel = nn.Sequential(\n            nn.Conv2d(3, 16, 3),\n            nn.Dropout(0.2),\n            nn.MaxPool2d(3),\n            nn.Flatten(),\n            nn.Linear(1600, 1024),\n            nn.Tanh(),\n            nn.Linear(1024, 512),\n            nn.Tanh(),\n            nn.Linear(512, 256),\n            nn.Tanh(),\n            nn.Linear(256, 2),\n            nn.LogSoftmax(dim=1))","724193ed":"criterion = nn.NLLLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.0005, momentum=0.9)\n\n# kfold split\nkf = KFold(n_splits=3)","5f9fc2d0":"cnt = 1\nlosses = []\nlosses_test = []\n\nfor x_idx in kf.split(X_train):\n    for e in range(501):\n        for idx in x_idx:\n            optimizer.zero_grad()\n            out = model(X_train[idx])\n            loss = criterion(out, torch.argmax(torch.Tensor(y_train[idx]).type(torch.torch.LongTensor), dim=1))\n            loss.backward()\n            optimizer.step()\n        if(e % 100 == 0):\n            pred_test = model(X_test)\n            loss_test = criterion(pred_test, torch.argmax(torch.Tensor(y_test).type(torch.torch.LongTensor), dim=1))\n            \n            losses.append(loss)\n            losses_test.append(loss_test)\n            \n            print('Split:%3d, Epoch:%4d, Loss:%.3f, Loss-test:%.3f' % (cnt, e, loss.item(), loss_test.item()))\n    cnt += 1","6cb3f34d":"fig, ax = plt.subplots()\nax.plot(losses, label='Losses')\nax.plot(losses_test, label='Losses-Test')\nleg = ax.legend()","32b067bc":"# Model Analysis","775b9eea":"# Neural Network","1b15f623":"# Prepare the arrays, normalize and split them","670439b3":"# Prepare Data","994d2251":"# Pytorch Bee vs Butterfly"}}