{"cell_type":{"60f1b6cf":"code","d9ca32f3":"code","b9649f8d":"code","d1be5321":"code","da6c7151":"code","79b2ebda":"code","22963a34":"code","9c009ae8":"code","dcc5a294":"code","6050b35f":"code","6afa8c47":"code","a7d62e38":"code","41923727":"code","af215a8e":"code","b9cf17d8":"code","b7383f41":"code","72f64489":"code","3fedc8c3":"code","4bc50022":"code","6be73ac7":"code","e729c7e9":"code","80f9bba5":"code","fc513249":"code","35633fc8":"code","bbf38b75":"code","d785d09f":"code","82634e14":"code","d6115b7e":"code","a83da737":"code","60380c6f":"code","eecffd5b":"code","788ca637":"code","1cc881d8":"code","2c21ed4b":"code","58796aab":"code","08cdbf3b":"code","db3fec50":"markdown","90987737":"markdown","7c1d341d":"markdown","e8da0a42":"markdown","8c91e4df":"markdown","e93d863c":"markdown","5739846d":"markdown","ca064d1d":"markdown","eb29154f":"markdown","0ec082d3":"markdown","bcc8e97c":"markdown","dc21c767":"markdown","af829ad5":"markdown"},"source":{"60f1b6cf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d9ca32f3":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ngender_submission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\nprint(\"All set!\")","b9649f8d":"print(\"train set rows - \"+str(train.shape[0])+\" columns -\"+str(train.shape[1]))\nprint(\"test set rows - \"+str(test.shape[0])+\" Columns -\"+str(test.shape[1]))\nprint(\"gender submission -\"+str(gender_submission.shape[0])+\" columns -\"+str(gender_submission.shape[1]))","d1be5321":"train.columns","da6c7151":"train['Pclass'].unique() ","79b2ebda":"train.head(10)","22963a34":"y = train['Survived']\ncolumns_name = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Cabin', 'Embarked']\nX = train[columns_name]","9c009ae8":"X.head(10)","dcc5a294":"X.isnull().sum()","6050b35f":"X = X.drop(labels='Cabin', axis=1)\nX","6afa8c47":"e1 = X.Embarked.fillna('S')","a7d62e38":"X = X.drop(labels='Embarked', axis=1)\nX_new = X.join(e1)","41923727":"X_new","af215a8e":"X_new.isnull().sum()","b9cf17d8":"from sklearn.preprocessing import LabelEncoder","b7383f41":"encoder = LabelEncoder()","72f64489":"X_new.head()","3fedc8c3":"feat = ['Sex']","4bc50022":"encoded = X_new[feat].apply(encoder.fit_transform)","6be73ac7":"X_new = X_new.drop(labels='Sex', axis=1)\nencoded_new = X_new.join(encoded)\nencoded_new.head()","e729c7e9":"import category_encoders as ce","80f9bba5":"count_encoder = ce.CountEncoder()\ncount_features = ['Embarked']\ncount_encoded = count_encoder.fit_transform(encoded_new[count_features])\nencoded_new = encoded_new.drop(labels='Embarked', axis=1)\ncount_new = encoded_new.join(count_encoded)\ncount_new.head(10)","fc513249":"y.head(10)","35633fc8":"from sklearn.preprocessing import StandardScaler","bbf38b75":"sc = StandardScaler()\nX_train_new = sc.fit_transform(count_new)\nX_train_new","d785d09f":"\ndef convertor12(dataframe_name):\n\tfeat = ['Sex']\n\tcount_features = ['Embarked']\n\tencoded = dataframe_name[feat].apply(encoder.transform)\n\tcount_encoded = count_encoder.transform(dataframe_name[count_features])\n\tdataframe_name = dataframe_name.drop(labels=['Sex', 'Embarked', 'Cabin'], axis=1)\n\tupdated_df = sc.transform(dataframe_name.join(encoded).join(count_encoded))\n\treturn updated_df","82634e14":"test_set = convertor12(test[columns_name])\ntest_set","d6115b7e":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state=0)\nclassifier","a83da737":"from sklearn.model_selection import train_test_split\nX_train_up, X_test_up, y_train_up, y_test_up = train_test_split(X_train_new, y, test_size=0.25, random_state=0)\nclassifier.fit(X_train_up, y_train_up)\nprint(\"All done\")","60380c6f":"result_up = classifier.predict(X_test_up)","eecffd5b":"from sklearn.metrics import confusion_matrix, accuracy_score\naccuracy_score(result_up, y_test_up)*100","788ca637":"result = classifier.predict(test_set)","1cc881d8":"res = result.reshape(len(result), 1)","2c21ed4b":"res.shape","58796aab":"gender = gender_submission['Survived']","08cdbf3b":"accuracy_score(gender, res)*100","db3fec50":"Let's overview the trianing set we just created.","90987737":"Now we will check the number of rows and columns in each dataframe. It looks like test set's answers are in gender_submission because it contain two columns one is passenger id and other is survivability. Passenger id is same as passenger id's in test set.","7c1d341d":"Here is y contain Survived data, and columns_name contain feature names. X contain all the features we selected.","e8da0a42":"We will see number of null values in our training data, bcoz we need to clean our data and for that we have to fill null values. But I generally delete columns with more than half null values. ","8c91e4df":"Now we will check the columns which we can use as features. The most important part is selecting features which correctly depicts whole dataset. For this we will go through each columns and check their values.","e93d863c":"We will find out the unique values in Pclass column, this will help us to select features.","5739846d":"Firstly we will import the necessary libraries and other libraries which kaggle add to function properly.","ca064d1d":"e1 ","eb29154f":"We will take all the data in following dataframes. When we use pandas to read data from file, it return a dataframe. So, here train, test and gender_submission is a dataframe. ","0ec082d3":"Here Cabin contain more than half null values so we will drop it from training set. Here axis = 1 tell to delete data rowwise or columnwise, 0 being for row and 1 for column. In lables we can give names of any column present in that dataframe.","bcc8e97c":"In this notebook, I will explain the basic steps in most simple way using the titanic data. This notebook will be helpful for new people want to step in Data Science. We will go through following steps:\n\n1. Data Cleaning \n2. Feature Engineering \n3. Training model\n4. Finding out Accuracy\n\nThis is my first notebook on Kaggle, if there is any mistake please let me know.","dc21c767":"Now we will fill null values in Embarked column, that is as we can see 2 places. As Embarked columns has highest values are 'S'. so we will fill it by 'S'.","af829ad5":"Now we will see the values in train set and find out which features to use, this will give an overview.\n\nNow as PassengerId does not give any relevent information about passenger.\n       Survived will go in our result set that is 'y'\n       Pclass we can take and see which class has more casualties.\n       Name will not help in modeling data.\n       Sex we will consider and take it in our feature set.\n       Age will also make a good feature but let us leave it now.\n       Now SibSp, Parch, Cabin and Embarked looks fine and we will take these and make a feature set."}}