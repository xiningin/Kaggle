{"cell_type":{"edd224c7":"code","7ef9468f":"code","40dd31e2":"code","7a1f187f":"code","0233e722":"code","e41274bd":"code","8e4d93f5":"code","e0163264":"code","82f4be41":"code","b4bc4573":"code","c64bf5c3":"code","49b86a00":"code","ad15b19d":"code","90ac1903":"code","936ccb74":"code","ce933fdd":"code","5ed70d2d":"code","bd592eac":"code","a5e8da46":"markdown","0e9919fd":"markdown"},"source":{"edd224c7":"!echo $TPU_NAME","7ef9468f":"!env","40dd31e2":"import os; os.environ[\"XRT_TPU_CONFIG\"] = \"tpu_worker;0;10.0.0.2:8470\"","7a1f187f":"import collections\nfrom datetime import datetime, timedelta\nimport os\nimport tensorflow as tf\nimport numpy as np\nimport requests, threading\n\n_VersionConfig = collections.namedtuple('_VersionConfig', 'wheels,server')\nVERSION = \"torch_xla==nightly\"\nCONFIG = {\n    'torch_xla==nightly': _VersionConfig('nightly', 'XRT-dev{}'.format(\n        (datetime.today() - timedelta(1)).strftime('%Y%m%d'))),\n}[VERSION]\n\nDIST_BUCKET = 'gs:\/\/tpu-pytorch\/wheels'\nTORCH_WHEEL = 'torch-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\nTORCH_XLA_WHEEL = 'torch_xla-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\nTORCHVISION_WHEEL = 'torchvision-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)","0233e722":"CONFIG.wheels","e41274bd":"!export LD_LIBRARY_PATH=\/usr\/local\/lib:$LD_LIBRARY_PATH\n!apt-get install libomp5 -y\n!apt-get install libopenblas-dev -y\n\n# Install COLAB TPU compat PyTorch\/TPU wheels and dependencies\n!pip uninstall -y torch torchvision\n!gsutil cp \"$DIST_BUCKET\/$TORCH_WHEEL\" .\n!gsutil cp \"$DIST_BUCKET\/$TORCH_XLA_WHEEL\" .\n!gsutil cp \"$DIST_BUCKET\/$TORCHVISION_WHEEL\" .\n!pip install \"$TORCH_WHEEL\"\n!pip install \"$TORCH_XLA_WHEEL\"\n!pip install \"$TORCHVISION_WHEEL\"","8e4d93f5":"import torch_xla.core.xla_model as xm\nimport torch_xla.distributed.data_parallel as dp # http:\/\/pytorch.org\/xla\/index.html#running-on-multiple-xla-devices-with-multithreading\nimport torch_xla.distributed.xla_multiprocessing as xmp # http:\/\/pytorch.org\/xla\/index.html#running-on-multiple-xla-devices-with-multiprocessing\nimport torch_xla.distributed.parallel_loader as pl","e0163264":"from kaggle_datasets import KaggleDatasets\n\n# Data access\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\n\n# Configuration\nIMAGE_SIZE = [512, 512]\nEPOCHS = 20\nBATCH_SIZE = 16 * 1\n\nGCS_PATH_SELECT = { # available image sizes\n    192: GCS_DS_PATH + '\/tfrecords-jpeg-192x192',\n    224: GCS_DS_PATH + '\/tfrecords-jpeg-224x224',\n    331: GCS_DS_PATH + '\/tfrecords-jpeg-331x331',\n    512: GCS_DS_PATH + '\/tfrecords-jpeg-512x512'\n}\nGCS_PATH = GCS_PATH_SELECT[IMAGE_SIZE[0]]\n\nTRAINING_FILENAMES   = tf.io.gfile.glob(GCS_PATH + '\/train\/*.tfrec')\nVALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '\/val\/*.tfrec')\nTEST_FILENAMES       = tf.io.gfile.glob(GCS_PATH + '\/test\/*.tfrec')","82f4be41":"TRAINING_FILENAMES","b4bc4573":"# REFERENCE https:\/\/gist.githubusercontent.com\/dlibenzi\/c9868a1090f6f8ef9d79d2cfcbadd8ab\/raw\/947fbec325cbdeda91bd53acb5e126caa4115348\/more_tf_stuff.py\n# Thanks A Lot For Your Help!!!\n\nfrom PIL import Image\nimport numpy as np\nimport hashlib\nimport os\nimport sys\nimport torch\nimport torch_xla.utils.tf_record_reader as tfrr\n\na = \"\"\"\nimage\/class\/label       tensor([82])\nimage\/class\/synset      n01796340\nimage\/channels  tensor([3])\nimage\/object\/bbox\/label tensor([], dtype=torch.int64)\nimage\/width     tensor([900])\nimage\/format    JPEG\nimage\/height    tensor([600])\nimage\/class\/text        ptarmigan\nimage\/object\/bbox\/ymin  tensor([])\nimage\/encoded   tensor([ -1, -40,  -1,  ..., -30,  -1, -39], dtype=torch.int8)\nimage\/object\/bbox\/ymax  tensor([])\nimage\/object\/bbox\/xmin  tensor([])\nimage\/filename  n01796340_812.JPEG\nimage\/object\/bbox\/xmax  tensor([])\nimage\/colorspace        RGB\n\"\"\"\n\ndef decode(ex):\n\n    w = 512 # ex['image\/width'].item()\n    h = 512 # ex['image\/height'].item()\n    imgb = ex['image'].numpy().tobytes()\n    \n    # m = hashlib.md5()\n    # m.update(imgb)\n    # print('HASH = {}'.format(m.hexdigest()))\n    \n    image = Image.frombytes(\"RGB\", (w, h), imgb,\n                            \"JPEG\".lower(),\n                            'RGB', None\n                           )\n    npa = np.asarray(image)\n    return torch.from_numpy(npa), image\n\n\ndef readem(path, img_path=None):\n    count = 0\n    transforms = {}  \n    r = tfrr.TfRecordReader(path, compression='', transforms=transforms)\n    while True:\n        ex = r.read_example()\n        if not ex: break\n        # print('\\n')\n        # for lbl, data in ex.items():\n            # print('{}\\t{}'.format(lbl, data))\n        img_tensor, image = decode(ex)\n        if img_path:\n            image.save(os.path.join(img_path, str(count) + '.jpg'))\n        count += 1\n    print('\\n\\nDecoded {} samples'.format(count))","c64bf5c3":"!ls && pwd","49b86a00":"%%time\n\nimport os;\nfor idx, file in enumerate(TRAINING_FILENAMES):\n    img_path = f\"\/kaggle\/working\/flower_images_{idx}\"\n    os.makedirs(img_path, exist_ok=True)\n    print(file)\n    readem(path = file, img_path = img_path)","ad15b19d":"%matplotlib inline\n# https:\/\/stackoverflow.com\/questions\/11159436\/multiple-figures-in-a-single-window\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\n\ndef plot_figures(figures, nrows = 1, ncols=1):\n    \"\"\"\n    Plot a dictionary of figures.\n    Parameters\n    ----------\n    figures : <title, figure> dictionary\n    ncols : number of columns of subplots wanted in the display\n    nrows : number of rows of subplots wanted in the figure\n    \"\"\"\n    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, figsize=(20,20))\n    for ind,title in zip(range(len(figures)), figures):\n        axeslist.ravel()[ind].imshow(figures[title], cmap=plt.jet())\n        # axeslist.ravel()[ind].set_title(title)\n        axeslist.ravel()[ind].set_axis_off()","90ac1903":"# generation of a dictionary of (title, images)\nw, h = 10, 10\nnumber_of_im = w*h\n\nfigures = {'im'+str(i): Image.open(f\".\/flower_images_0\/{i}.jpg\") for i in range(number_of_im)}\n\n# plot of the images in a figure, with 5 rows and 4 columns\nplot_figures(figures, w, h)\nplt.show()","936ccb74":"# generation of a dictionary of (title, images)\nw, h = 10, 10\nnumber_of_im = w*h\n\nfigures = {'im'+str(i): Image.open(f\".\/flower_images_1\/{i}.jpg\") for i in range(number_of_im)}\n\nplot_figures(figures, w, h)\nplt.show()","ce933fdd":"# generation of a dictionary of (title, images)\nw, h = 10, 10\nnumber_of_im = w*h\n\nfigures = {'im'+str(i): Image.open(f\".\/flower_images_2\/{i}.jpg\") for i in range(number_of_im)}\n\nplot_figures(figures, w, h)\nplt.show()","5ed70d2d":"# generation of a dictionary of (title, images)\nw, h = 10, 10\nnumber_of_im = w*h\n\nfigures = {'im'+str(i): Image.open(f\".\/flower_images_3\/{i}.jpg\") for i in range(number_of_im)}\n\nplot_figures(figures, w, h)\nplt.show()","bd592eac":"# generation of a dictionary of (title, images)\nw, h = 10, 10\nnumber_of_im = w*h\n\nfigures = {'im'+str(i): Image.open(f\".\/flower_images_10\/{i}.jpg\") for i in range(number_of_im)}\n\nplot_figures(figures, w, h)\nplt.show()","a5e8da46":"In the 100 flowers dataset, the format of each TFRecord of labeled data is:\n    - \"image\": list of bytestrings containing 1 bytestring (the JPEG-ecoded image bytes)\n    - \"label\": list of int64 containing 1 int64","0e9919fd":"# Special Thanks To @dlibenzi (github) for all his help;"}}