{"cell_type":{"8f3bcdb5":"code","9e0a2052":"code","dd3ab8b0":"code","156654c4":"code","c95efeae":"code","d109a751":"code","d97e8393":"code","b7f3e659":"code","fc0bdf57":"code","997775d0":"code","c686e5b3":"code","b2c6f961":"code","25a1be1d":"code","054412de":"code","e3589d87":"code","ccbb0996":"code","147da769":"code","9eee884f":"code","fd4197ec":"code","5b92c13b":"code","e75c5571":"code","7c52e764":"code","312deea0":"code","d5e76f9a":"code","bd1a2a87":"code","f862b6d1":"code","ebb2eb5f":"code","9d14d364":"code","dfa477bd":"markdown","e3c42fe9":"markdown","9f9b536f":"markdown","30b66c49":"markdown","4e31cc63":"markdown","7de7d926":"markdown","881449f4":"markdown","b8e239fb":"markdown","e42c78e7":"markdown","9e81bb82":"markdown","40c3317f":"markdown","47e82f29":"markdown","de83d349":"markdown"},"source":{"8f3bcdb5":"# DATA_PATH = '..\/input\/'\nDATA_PATH = '..\/input\/shopee-product-matching\/'","9e0a2052":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2, matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\nimport gc","dd3ab8b0":"COMPUTE_CV = True\n\ntest = pd.read_csv(DATA_PATH + 'test.csv')\nif len(test)>3: COMPUTE_CV = False\nelse: print('this submission notebook will compute CV score, but commit notebook will not')\n\n# COMPUTE_CV = False\n\nif COMPUTE_CV:\n    train = pd.read_csv(DATA_PATH + 'train.csv')\n    train['image'] = DATA_PATH + 'train_images\/' + train['image']\n    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n    train['target'] = train.label_group.map(tmp)\n#     train_gf = cudf.read_csv(DATA_PATH + 'train.csv')\nelse:\n    train = pd.read_csv(DATA_PATH + 'test.csv')\n    train['image'] = DATA_PATH + 'test_images\/' + train['image']\n#     train_gf = cudf.read_csv(DATA_PATH + 'test.csv')\n    \nprint('train shape is', train.shape )\ntrain.head()","156654c4":"import albumentations as A\n\ndef visualize(image):\n    plt.figure(figsize=(6, 6))\n    plt.axis('off')\n    plt.imshow(image)","c95efeae":"image = cv2.imread(train['image'].iloc[0])\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nvisualize(image)","d109a751":"transform = A.HorizontalFlip(p=1)\naugmented_image = transform(image=image)['image']\nvisualize(augmented_image)","d97e8393":"transform = A.ShiftScaleRotate(p=1)\naugmented_image = transform(image=image)['image']\nvisualize(augmented_image)","b7f3e659":"transform = A.Compose([\n    A.RandomRotate90(),\n    A.Transpose(),\n    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.50, rotate_limit=45, p=.75),\n    A.Blur(blur_limit=3),\n    A.OpticalDistortion(),\n    A.GridDistortion(),\n    A.HueSaturationValue(),\n])\naugmented_image = transform(image=image)['image']\nvisualize(augmented_image)","fc0bdf57":"transform = A.Compose([\n        A.RandomRotate90(),\n        A.Flip(),\n        A.Transpose(),\n        A.OneOf([\n            A.IAAAdditiveGaussianNoise(),\n            A.GaussNoise(),\n        ], p=0.2),\n        A.OneOf([\n            A.MotionBlur(p=.2),\n            A.MedianBlur(blur_limit=3, p=0.1),\n            A.Blur(blur_limit=3, p=0.1),\n        ], p=0.2),\n        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n        A.OneOf([\n            A.OpticalDistortion(p=0.3),\n            A.GridDistortion(p=.1),\n            A.IAAPiecewiseAffine(p=0.3),\n        ], p=0.2),\n        A.OneOf([\n            A.CLAHE(clip_limit=2),\n            A.IAASharpen(),\n            A.IAAEmboss(),\n            A.RandomBrightnessContrast(),            \n        ], p=0.3),\n        A.HueSaturationValue(p=0.3),\n    ])\naugmented_image = transform(image=image)['image']\nvisualize(augmented_image)","997775d0":"!pip install nlpaug","c686e5b3":"import nlpaug.augmenter.char as nac\nimport nlpaug.augmenter.word as naw\nimport nlpaug.augmenter.sentence as nas\nimport nlpaug.flow as nafc\n\nfrom nlpaug.util import Action","b2c6f961":"aug = nac.RandomCharAug(action=\"swap\")","25a1be1d":"texts = train['title'].iloc[:10]\n\nfor text in texts:\n    augmented_text = aug.augment(text)\n    \n    print('-'*20)\n    print('Original Input:{}'.format(text))\n    print('Agumented Output:{}'.format(augmented_text))","054412de":"aug = nac.RandomCharAug(action=\"delete\")","e3589d87":"texts = train['title'].iloc[:10]\n\nfor text in texts:\n    augmented_text = aug.augment(text)\n    \n    print('-'*20)\n    print('Original Input:{}'.format(text))\n    print('Agumented Output:{}'.format(augmented_text))","ccbb0996":"text = train['title'].iloc[0]\n\n# model_type: word2vec, glove or fasttext\naug = naw.WordEmbsAug(\n    model_type='fasttext', model_path='..\/input\/fasttext-wikinews\/wiki-news-300d-1M.vec')\naugmented_text = aug.augment(text)\nprint(\"Original:\")\nprint(text)\nprint(\"Augmented Text:\")\nprint(augmented_text)","147da769":"for text in train['title'].iloc[:10]:\n    augmented_text = aug.augment(text)\n    print('-'*20)\n    print('Original Input:{}'.format(text))\n    print('Agumented Output:{}'.format(augmented_text))","9eee884f":"# Augment French by BERT\naug = naw.ContextualWordEmbsAug(model_path='bert-base-uncased', aug_p=0.1)\ntext = \"Bonjour, J'aimerais une attestation de l'employeur certifiant que je suis en CDI.\"\naugmented_text = aug.augment(text)\nprint(\"Original:\")\nprint(text)\nprint(\"Augmented Text:\")\nprint(augmented_text)","fd4197ec":"for text in train['title'].iloc[:10]:\n    augmented_text = aug.augment(text)\n    print('-'*20)\n    print('Original Input:{}'.format(text))\n    print('Agumented Output:{}'.format(augmented_text))","5b92c13b":"import re\nimport nlpaug.model.word_stats as nmw\n\ndef _tokenizer(text, token_pattern=r\"(?u)\\b\\w\\w+\\b\"):\n    token_pattern = re.compile(token_pattern)\n    return token_pattern.findall(text)\n\n# Tokenize input\ntrain_x_tokens = [_tokenizer(x) for x in train['title']]\n\n# Train TF-IDF model\ntfidf_model = nmw.TfIdf()\ntfidf_model.train(train_x_tokens)\ntfidf_model.save('.')\n\n# Load TF-IDF augmenter\naug = naw.TfIdfAug(model_path='.', tokenizer=_tokenizer)","e75c5571":"texts = train['title'].iloc[:10]\n\nfor text in texts:\n    augmented_text = aug.augment(text)\n    \n    print('-'*20)\n    print('Original Input:{}'.format(text))\n    print('Agumented Output:{}'.format(augmented_text))","7c52e764":"# model_path: xlnet-base-cased or gpt2\naug = nas.ContextualWordEmbsForSentenceAug(model_path='xlnet-base-cased')\naugmented_texts = aug.augment(text, n=3)","312deea0":"texts = train['title'].iloc[:10]\n\nfor text in texts:\n    augmented_text = aug.augment(text)\n    \n    print('-'*20)\n    print('Original Input:{}'.format(text))\n    print('Agumented Output:{}'.format(augmented_text))","d5e76f9a":"train.head()","bd1a2a87":"train.shape","f862b6d1":"aug_image_title_pairs = []\nfor df in train.groupby('label_group'):\n    for idx1, img in enumerate(df[1]['image']):\n        for idx2, title in enumerate(df[1]['title']):\n            if idx1 == idx2:\n                continue\n            \n            aug_image_title_pairs.append([img, title])\n            \n    break","ebb2eb5f":"pd.DataFrame(aug_image_title_pairs, columns=['image', 'title'])","9d14d364":"df[1]","dfa477bd":"## Contextual Word Embeddings for Sentence Augmenter","e3c42fe9":"# Image Augmentation\n\n\u56fe\u50cf\u6570\u636e\u6269\u589e\n\nhttps:\/\/github.com\/albumentations-team\/albumentations","9f9b536f":"## Contextual Word Embeddings Augmenter (BERT)","30b66c49":"In this notebook, some augmentaion methos is introduced. And i will give some insight and product method in shopee compte. If you find usefule, please give upvote, thx.\n\n- Image Augmentation\n- Text Augmentaion\n- Product Augmentaion\n\n\u5728\u672c\u4e2anotebook\u4e2d\uff0c\u4ecb\u7ecd\u4e86\u4e00\u4e9b\u6570\u636e\u6269\u589e\u65b9\u6cd5\u3002\u6211\u4e5f\u4f1a\u5728\u4ecb\u7ecd\u4f7f\u7528\u7684\u540c\u65f6\uff0c\u7ed3\u5408shopee\u6bd4\u8d5b\u7ed9\u51fa\u4e00\u4e9b\u5efa\u8bae\u3002\u5982\u679c\u4f60\u611f\u8c22\u5185\u5bb9\u5bf9\u4f60\u6709\u5e2e\u52a9\uff0c\u8bf7\u7ed9\u6211\u70b9\u8d5e\uff0c\u8c22\u8c22\u3002\n\n\nYou can check my other notebooks:\n\n- [Shopee Products Matching: Image Part [English+\u4e2d\u6587]](https:\/\/www.kaggle.com\/finlay\/shopee-products-matching-image-part-english)\n- [Shopee Products Matching: Text Part [English+\u4e2d\u6587]](https:\/\/www.kaggle.com\/finlay\/shopee-products-matching-text-part-english)\n- [Shopee Products Matching: BoF Part [English+\u4e2d\u6587]](https:\/\/www.kaggle.com\/finlay\/shopee-products-matching-bof-part-english)\n- [Shopee Products Matching: Augment Part [English\u4e2d\u6587]](https:\/\/www.kaggle.com\/finlay\/shopee-products-matching-augment-part-english)\n- [[Unsupervised] Image + Text Baseline in 20min](https:\/\/www.kaggle.com\/finlay\/unsupervised-image-text-baseline-in-20min)","4e31cc63":"OpenCV reads an image in BGR format (so color channels of the image have the following order: Blue, Green, Red). Albumentations uses the most common and popular RGB image format. So when using OpenCV, we need to convert the image format to RGB explicitly.","7de7d926":"\n## Word Augmenter\n\nUse of word2vec (Mikolov et al., 2013), GloVe (Pennington et al., 2014), fasttext (Joulin et al., 2016), BERT(Devlin et al., 2018) and wordnet to insert and substitute similar word. Word2vecAug, GloVeAug and FasttextAug use word embeddings to find most similar group of words to replace original word. On the other hand, BertAug use language models to predict possible target word. WordNetAug use statistics way to find the similar group of words.","881449f4":"we see this group has 3 product, now we get 6 new product!","b8e239fb":"Define an augmentation pipeline using Compose, pass the image to it and receive the augmented image","e42c78e7":"## Delete character randomly\n","9e81bb82":"# Text Augmentation\n\n* https:\/\/github.com\/makcedward\/nlpaug\n* https:\/\/github.com\/jasonwei20\/eda_nlp\/","40c3317f":"## Swap character randomly\u00b6\n","47e82f29":"## TF-IDF Augmenter","de83d349":"# Product\/Pair Augmentation\n\nwe random swap the image and title in same group to get new product.\n\n\u5c06\u5546\u54c1\u56fe\u50cf\u548ctitle\uff0c\u91cd\u65b0\u7ec4\u5408\u5f97\u5230\u65b0\u7684\u5546\u54c1\u3002"}}