{"cell_type":{"2cffe454":"code","1d2254a1":"code","e07dc2a1":"code","e78fff74":"code","ead77ef7":"code","649ed7dd":"code","496bf947":"code","cade39b5":"code","8d231a60":"code","cfe6d074":"code","a84b49e1":"code","30e8dc05":"code","0ffdf178":"code","68bac77c":"code","4c904b2b":"code","c9799830":"code","0ecd9bd1":"code","acc7d38b":"code","b05d99a7":"code","3bfef08e":"code","a5f80854":"code","2917c1db":"code","913d10eb":"code","7d8003ce":"code","8e74750c":"code","2a8a7ebb":"code","8aadf59f":"code","66d726ca":"code","28a4395c":"code","988377a9":"code","01d0072c":"code","98e97f68":"code","87f67407":"code","d3836456":"code","8f0eef96":"code","c403f159":"code","d7c3fb4e":"code","b8380bf8":"code","8be7104f":"code","923ec499":"code","dba293e1":"code","184259b8":"code","9c5661df":"code","4db97c60":"code","8aa61c66":"code","9b5dd62e":"code","3900d2a9":"code","eda52d39":"code","b398d93e":"code","fa601b4f":"code","267e4cb2":"code","3c851ec2":"code","d31674b5":"code","b1e2b9c4":"code","9ba2b349":"code","db23947c":"code","af08069b":"code","e8777edd":"code","d41c6762":"code","52c0de96":"code","fb6ccf9c":"code","6012daab":"code","1632cc93":"code","bdc25f68":"code","546fef05":"code","1f526828":"code","06d53c4d":"code","2d093266":"code","33cc8b88":"code","4950a673":"code","23981f58":"code","b52df4d9":"code","c3ba1a25":"code","89631334":"code","4a57fc7f":"code","9279c819":"code","94289d41":"code","7a818842":"code","08a6213e":"code","0045e75b":"code","ecd98f55":"markdown","2c740de5":"markdown","0f80016e":"markdown","e4c24d12":"markdown","aca6f6a0":"markdown","8bab3ce2":"markdown","fd4ff4f3":"markdown","2125adc6":"markdown","5e4ae7cb":"markdown","249e85a2":"markdown","ec389127":"markdown","d2f2328a":"markdown","8693d5d2":"markdown","8d6ff887":"markdown","018c7120":"markdown","abc50314":"markdown","0a5db5f2":"markdown","2991176e":"markdown","e80b0b76":"markdown","0da0903d":"markdown","e154ffca":"markdown","8e95e81f":"markdown","b563e521":"markdown","4cb4bd0d":"markdown","d49743bc":"markdown","b80dc273":"markdown","d663d215":"markdown","cb63c94f":"markdown","1fe5fcd5":"markdown","6aa66b55":"markdown","6f799960":"markdown","d075e2ae":"markdown","e09a432e":"markdown","a42cd011":"markdown","b7e72e4b":"markdown","5d12bde9":"markdown","a80aee03":"markdown","04717429":"markdown","0c22439d":"markdown","8e4922b0":"markdown","1417a895":"markdown","4d601476":"markdown","fecbb75c":"markdown","a2e3797f":"markdown","d7d91487":"markdown","37a262b9":"markdown","0fb28393":"markdown"},"source":{"2cffe454":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-whitegrid')\n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1d2254a1":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_PassengerId = test_df['PassengerId']","e07dc2a1":"train_df.columns","e78fff74":"train_df.head()","ead77ef7":"train_df.describe()","649ed7dd":"train_df.info()","496bf947":"def bar_plot(variable):\n    \n    # input: variable ex: Sex\n    # output: bar plot & value count\n    \n    # get feature\n    var = train_df[variable]\n    # count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    \n    #visualize\n    plt.figure(figsize=(9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel('Frequency')\n    plt.title(variable)\n    plt.show()\n    print('{}: \\n {}'.format(variable,varValue))","cade39b5":"category1 = ['Survived','Embarked','Parch','SibSp','Pclass']\nfor c in category1:\n    bar_plot(c)","8d231a60":"def plot_hist(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(train_df[variable], bins = 50)\n    plt.xlabel(variable)\n    plt.ylabel('Frequency')\n    plt.title('{} Distribution with Histogram'.format(variable))\n    plt.show()","cfe6d074":"numeric_variable = ['Fare', 'Age']\nfor n in numeric_variable:\n    plot_hist(n)","a84b49e1":"# Pclass - Survived\ntrain_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index = False).mean().sort_values(by='Survived', ascending = False)","30e8dc05":"# Sex - Survived\ntrain_df[['Sex', 'Survived']].groupby(['Sex'], as_index = False).mean().sort_values(by='Survived', ascending = False)","0ffdf178":"# SibSp - Survived\ntrain_df[['SibSp', 'Survived']].groupby(['SibSp'], as_index = False).mean().sort_values(by='Survived', ascending = False)","68bac77c":"# Parch - Survived\ntrain_df[['Parch', 'Survived']].groupby(['Parch'], as_index = False).mean().sort_values(by='Survived', ascending = False)","4c904b2b":"def detect_out(df, features):\n    outlier_indicies = []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c], 25)\n        # 3rd quartile\n        Q3 = np.percentile(df[c], 75)\n        # IQR\n        IQR = Q3 - Q1      \n        # Qutlier step\n        outlier_step = IQR * 1.5\n        # Detect outlier and their indicies\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        # Store indicies\n        outlier_indicies.extend(outlier_list_col)\n        \n    outlier_indicies = Counter(outlier_indicies)\n    multiple_outliers = list(i for i, v in outlier_indicies.items() if v > 2)\n    \n    return multiple_outliers","c9799830":"train_df.loc[detect_out(train_df, ['Age','SibSp','Parch','Fare'])]","0ecd9bd1":"# dropping outliers\ntrain_df = train_df.drop(detect_out(train_df, ['Age','SibSp','Parch','Fare']), axis = 0).reset_index(drop = True)","acc7d38b":"train_df_len = len(train_df)\ntrain_df = pd.concat([train_df,test_df], axis=0).reset_index(drop=True)","b05d99a7":"train_df.columns[train_df.isnull().any()]","3bfef08e":"train_df.isnull().sum()","a5f80854":"train_df[train_df.Embarked.isnull()]","2917c1db":"train_df.boxplot(column='Fare', by='Embarked')","913d10eb":"train_df.Embarked = train_df.Embarked.fillna('C')\ntrain_df[train_df.Embarked.isnull()]","7d8003ce":"train_df[train_df.Fare.isnull()]","8e74750c":"train_df['Fare'] = train_df['Fare'].fillna(np.mean(train_df[train_df.Pclass == 3]['Fare']))\ntrain_df[train_df.Fare.isnull()]","2a8a7ebb":"list1 = ['SibSp', 'Parch', 'Age', 'Fare', 'Survived']\nsns.heatmap(train_df[list1].corr(), annot = True, fmt = '.2f')\nplt.show()","8aadf59f":"g = sns.factorplot(x = 'SibSp', y = 'Survived', data = train_df, kind = 'bar', size = 6)\ng.set_ylabels('Survived Probability')\nplt.show()","66d726ca":"g = sns.factorplot(x = 'Parch', y = 'Survived', data = train_df, kind = 'bar', size = 6)\ng.set_ylabels('Survived Probability')\nplt.show()","28a4395c":"g = sns.factorplot(x = 'Pclass', y = 'Survived', data = train_df, kind = 'bar', size = 6)\ng.set_ylabels('Survived Probability')\nplt.show()","988377a9":"g = sns.FacetGrid(train_df, col = 'Survived')\ng.map(sns.distplot, 'Age', bins = 25)\nplt.show()","01d0072c":"g = sns.FacetGrid(train_df, col = 'Survived', row = 'Pclass', size = 2)\ng.map(plt.hist, 'Age', bins =25)\nplt.legend()\nplt.show()","98e97f68":"g = sns.FacetGrid(train_df, row = 'Embarked', size = 2)\ng.map(sns.pointplot, 'Pclass', 'Survived', 'Sex')\nplt.legend()\nplt.show()","87f67407":"g = sns.FacetGrid(train_df, row = 'Embarked', col = 'Survived', size = 4)\ng.map(sns.barplot,'Sex',  'Fare')\nplt.legend()\nplt.show()","d3836456":"train_df[train_df['Age'].isnull()]","8f0eef96":"sns.factorplot(x = 'Sex', y = 'Age', data = train_df, kind = 'box')\nplt.show()","c403f159":"sns.factorplot(x = 'Sex', y = 'Age', hue = 'Pclass', data = train_df, kind = 'box')\nplt.show()","d7c3fb4e":"sns.factorplot(x = 'Pclass', y = 'Age', data = train_df, kind = 'box')\nsns.factorplot(x = 'SibSp', y = 'Age', data = train_df, kind = 'box')\nplt.show()","b8380bf8":"train_df.Sex = [1 if each == 'male' else 0 for each in train_df.Sex]","8be7104f":"sns.heatmap(train_df[['Age', 'Sex', 'SibSp', 'Parch', 'Pclass']].corr(), annot = True)\nplt.show()","923ec499":"index_nan_age = list(train_df.Age[train_df.Age.isnull()].index)\nfor i in index_nan_age:\n    age_pred = train_df.Age[((train_df.SibSp == train_df.iloc[i]['SibSp']) & (train_df.Parch == train_df.iloc[i]['Parch']) & (train_df.Pclass == train_df.iloc[i]['Pclass']))].median()\n    age_med = train_df['Age'].median()\n    if not np.isnan(age_pred):\n        train_df.Age.iloc[i] = age_pred\n    else:\n        train_df.Age.iloc[i] = age_med","dba293e1":"train_df[train_df['Age'].isnull()]","184259b8":"train_df['Name'].head(10)","9c5661df":"name = train_df['Name']\ntrain_df['Title'] = [i.split('.')[0].split(',')[-1].strip() for i in name]","4db97c60":"train_df['Title'].head(10)","8aa61c66":"# convert to categorical\n\ntrain_df.Title = train_df.Title.replace(['Lady', 'the Countess', 'Capt', 'Col','Don', 'Dr','Sir','Jonkheer', 'Dona'], 'other')\ntrain_df.Title = [0 if i == 'Master' else 1 if i == 'Miss' or i == 'Ms' or i == 'Mlle' or i == 'Mrs' else 2 if i == 'Mr' else 3 for i in train_df.Title]","9b5dd62e":"sns.countplot(x = 'Title', data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","3900d2a9":"g = sns.factorplot(x = 'Title', y = 'Survived', data = train_df, kind = 'bar')\ng.set_xticklabels(['Master', 'Mrs', 'Mr', 'Other'])\ng.set_ylabels('Survival Probability')\nplt.show()","eda52d39":"train_df.drop(labels = ['Name'], axis = 1, inplace = True)","b398d93e":"train_df.head()","fa601b4f":"train_df = pd.get_dummies(train_df, columns = ['Title'])\ntrain_df.head()","267e4cb2":"train_df['Fsize'] = train_df['SibSp'] + train_df['Parch'] + 1","3c851ec2":"g = sns.factorplot(x = 'Fsize', y = 'Survived', data = train_df, kind = 'bar')\ng.set_ylabels('Survival')\nplt.show()","d31674b5":"train_df['family_size'] = [1 if i < 5 else 0 for i in train_df.Fsize]","b1e2b9c4":"train_df.head()","9ba2b349":"sns.countplot(x = 'family_size', data = train_df)\nplt.show()","db23947c":"g = sns.factorplot(x = 'family_size', y = 'Survived', data = train_df, kind = 'bar')\ng.set_ylabels('Survival')\nplt.show()","af08069b":"train_df = pd.get_dummies(train_df, columns = ['family_size'])\ntrain_df.head()","e8777edd":"train_df.Embarked.head()","d41c6762":"sns.countplot(x = 'Embarked', data = train_df)\nplt.show()","52c0de96":"train_df = pd.get_dummies(train_df, columns = ['Embarked'])","fb6ccf9c":"train_df.head()","6012daab":"train_df.Ticket.head(20)","1632cc93":"tickets = []\n\nfor i in list(train_df.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace('.','').replace('\/','').strip().split(' ')[0])\n    else:\n        tickets.append('x')\ntrain_df['Tickets'] = tickets","bdc25f68":"train_df.Tickets.head(20)","546fef05":"train_df = pd.get_dummies(train_df, columns = ['Tickets'], prefix = 'T')\ntrain_df.head()","1f526828":"sns.countplot(x = 'Pclass', data = train_df)\nplt.show()","06d53c4d":"train_df.Pclass = train_df.Pclass.astype('category')\ntrain_df = pd.get_dummies(train_df, columns = ['Pclass'])\ntrain_df.head()\ntrain_df.drop(labels = 'Ticket', axis = 1, inplace = True)","2d093266":"train_df.Sex = train_df.Sex.astype('category')\ntrain_df = pd.get_dummies(train_df, columns = ['Sex'])\ntrain_df.head()","33cc8b88":"train_df.drop(labels = ['PassengerId', 'Cabin'], axis = 1, inplace = True)","4950a673":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","23981f58":"train_df_len","b52df4d9":"test = train_df[train_df_len:]\ntest.drop(labels = 'Survived', axis = 1, inplace = True)","c3ba1a25":"train = train_df[:train_df_len]\nX_train = train.drop(labels = 'Survived', axis = 1)\ny_train = train['Survived']\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\nprint('X_train',len(X_train))\nprint('X_test',len(X_test))\nprint('y_train',len(y_train))\nprint('y_test',len(y_test))\nprint('test',len(test))","89631334":"logreg = LogisticRegression(solver='liblinear')\nlogreg.fit(X_train,y_train)\nacc_log_train = round(logreg.score(X_train,y_train)*100,2)\nacc_log_test = round(logreg.score(X_test,y_test)*100,2)\nprint('Training accuracy: % {}'.format(acc_log_train))\nprint('Test accuracy: % {}'.format(acc_log_test))","4a57fc7f":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]","9279c819":"dt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","94289d41":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","7a818842":"cv_results = pd.DataFrame({'Cross Validation Means': cv_result, 'ML Models':['DecisionTreeClassifier','SVC','RandomForestClassifier',\n             'LogisticRegression','KNeighborsClassifier']})\n\ng = sns.barplot('Cross Validation Means', 'ML Models', data = cv_results)\ng.set_xlabel('Mean Accuracy')\ng.set_title('Cross Validation Scores')\nplt.show()","08a6213e":"votingC = VotingClassifier(estimators = [('dt', best_estimators[0]),\n                                         ('rfc', best_estimators[2]),\n                                         ('lr', best_estimators[3])],\n                                         voting = 'soft', n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test), y_test))","0045e75b":"test_survived = pd.Series(votingC.predict(X_test), name = 'Survived').astype(int)\nresults = pd.concat([test_PassengerId, test_survived], axis = 1)\nresults.to_csv('titanic.csv', index = False)","ecd98f55":"* Sex is not informative for age prediction, age distribution seems to be same.","2c740de5":"* passengers who pay higher fare have better survival.\n* Fare can be used as categorical for training.\n","0f80016e":"<a id = '16'><\/a><br>\n\n\n## Age -- Survived","e4c24d12":"<a id = '11'><\/a><br>\n\n# Visualization","aca6f6a0":"<a id = '1'><\/a><br>\n\n# **Load and Check Data**","8bab3ce2":"<a id = '33'><\/a><br>\n\n## Ensemble Modeling","fd4ff4f3":"<a id = '12'><\/a><br>\n\n### Correlation Between SibSp -- Parch -- Age -- Fare -- Survived\n","2125adc6":"<a id = '20'><\/a><br>\n\n## Fill Missing: Age Feature","5e4ae7cb":"<a id = '27'><\/a><br>\n\n## Sex","249e85a2":"<a id = '24'><\/a><br>\n## Embarked","ec389127":"<a id = '9'><\/a><br>\n## Find Missing Value","d2f2328a":"* Having a lot of sibsp have less chance to survive\n* if sibsp == 0,1 or 2, passenger has more chance to survive\n* we can consider a new feature describing these categories","8693d5d2":"* Age is not corr with sex but it is corr with parch, sibsp and pclass","8d6ff887":"<a id = '7'><\/a><br>\n# Outlier Detection","018c7120":"<a id = '17'><\/a><br>\n## Pclass -- Age -- Survived\n","abc50314":"<a id = '5'><\/a><br>\n##  Numerical Variable Analysis","0a5db5f2":"<a id = '21'><\/a><br>\n\n# Feature Engineering","2991176e":"* Pclass is an important feature for model training.\n","e80b0b76":"* Sibsp and parch can be used for new feature extraction with th = 3\n* Small families have more chance to survive\n* There is std in survival of passenger with parch = 3","0da0903d":"<a id = '3'><\/a><br>\n# Univariate Variable Analysis\n\nCategorical Variable: Cabin, Embarked, Sex, Name , Ticket, Sibsp, Parch, Pclass, Survived\n\nNumerical Variable: Age, PassengerId, Fare","e154ffca":"<a id = '2'><\/a><br>\n**Variable Description**\n1. PassengerId: unique id number to each passenger\n1. Survived: panssenger survive(1) or died(0)\n1. Pclass: passenger class\n1. Name: name of passenger\n1. Sex: gender of passenger\n1. Age: age of passenger\n1. SibSp: number of siblings-spouses\n1. Parch: number of parents-children\n1. Ticket: ticket number\n1. Fare: amount of money spent on ticket\n1. Cabin: cabin category\n1. Embarked: port where passenger embarked(C=Cherbourg, Q=Queenstown, S=Southampton","8e95e81f":"<a id = '25'><\/a><br>\n\n## Ticket","b563e521":"* Small families have more chance to survive than large families","4cb4bd0d":"<a id = '15'><\/a><br>\n\n\n## Pclass -- Survived","d49743bc":"<a id = '23'><\/a><br>\n\n## Family Size","b80dc273":"<a id = '31'><\/a><br>\n\n\n## Simple Logistic Regression","d663d215":"<a id = '13'><\/a><br>\n\n\n## SibSp -- Survived","cb63c94f":"Fare feature seems to have correlation with survived feature (0.26).","1fe5fcd5":"<a id = '28'><\/a><br>\n\n## Drop PassengerID and Cabin","6aa66b55":"<a id = '30'><\/a><br>\n\n## Train Test Split","6f799960":"<a id = '10'><\/a><br>\n## Fill Missing Values","d075e2ae":"# INTRODUCTION\n\nThe sinking of Titanic is one of the most notorious ship-break in the history.In 1912, during her voyage, Titanic sank after colliding with an iceberg, killing 1502 out of 2204 passengers and crew.\n\n<font color = 'blue'>\nContent: \n1. [Load and Check Data](#1)\n\n2. [Variable Description](#2)\n* [Univariate Variable Analysis](#3)\n    * [Categorical Variable Analysis](#4)\n    * [Numerical Variable Analysis](#5)\n\n3. [Basic Data Analysis](#6)\n\n4. [Outlier Detection](#7)\n    \n5. [Missing Value](#8)\n    \n    * [Find Missing Value](#9)\n    \n    * [Fill Missing Value](#10)\n    \n6. [Visualization](#11)\n    \n    * [Correlation Between SibSp -- Parch -- Age -- Fare -- Survived](#12)\n    * [SibSp -- Survived](#13)\n    * [Parch -- Survived](#14)\n    * [Pclass -- Survived](#15)\n    * [Age -- Survived](#16)\n    * [Pclass -- Age -- Survived](#17)\n    * [Embarked -- Sex -- Pclass -- Survived](#18)\n    * [Embarked -- Sex -- Fare -- Survived](#19)\n    * [Fill Missing: Age Feature](#20)\n    \n7. [Feature Engineering](#21)\n    \n    * [Name -- Title](#22)\n    * [Family Size](#23)\n    * [Embarked](#24)\n    * [Ticket](#25)\n    * [Pclass](#26)\n    * [Sex](#27)\n    * [Drop PassengerID and Cabin](#28)\n    \n8. [Modeling](#29) \n    \n    * [Train Test Split](#30)\n    * [Simple Logistic Regression](#31)\n    * [Hyperparameter Tuning -- Grid Search -- Cross Validation](#32)\n    * [Ensemble Modeling](#33)\n    * [Prediction and Submission](#34)","e09a432e":"<a id = '19'><\/a><br>\n## Embarked -- Sex -- Fare -- Survived","a42cd011":"<a id = '29'><\/a><br>\n# Modeling","b7e72e4b":"<a id = '22'><\/a><br>\n\n## Name -- Title","5d12bde9":"<a id = '32'><\/a><br>\n\n## Hyperparameter Tuning -- Grid Search -- Cross Validation\n\n* We will compare five machine learning classifier and evaluate mean accuracy of each of them by satisfied cross validation.\n\n    * Decision Tree\n    * Svm\n    * Random Forest\n    * KNN\n    * Logistic Regression****","a80aee03":"<a id = '14'><\/a><br>\n\n\n## Parch -- Survived","04717429":"*float64(2): Fare and Age\n\n*int64(5): Pclass, sibsp,parch,passengerId,Survived\n\n*object(5): Cabin,Embarked,Sex,name,ticket","0c22439d":"* age < 10 has a survival rate\n* oldest passengers (80) survived\n* large number of 20 years old did not survived\n* most passengers are in 15-35 age range\n* use age feature in training\n* use age distribution for missing value of age","8e4922b0":"<a id = '34'><\/a><br>\n\n## Prediction and Submission","1417a895":"<a id = '18'><\/a><br>\n## Embarked -- Sex -- Pclass -- Survived","4d601476":"<a id = '4'><\/a><br>\n##  Categorical Variable Analysis","fecbb75c":"* Female passenger has better survival rate than man passenger\n* Males have better survival rate in pclass 3 in C.\n* embarked and sex will be used in training.","a2e3797f":"<a id = '6'><\/a><br>\n# Basic Data Analysis\n* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Parch - Survived","d7d91487":"<a id = '26'><\/a><br>\n\n## Pclass","37a262b9":"<a id = '8'><\/a><br>\n# Missing Value\n\n* Find Missing Value\n\n* Fill Missing Value","0fb28393":"* First class passengers are older than second, second older than third"}}