{"cell_type":{"8afe7032":"code","414a32ad":"code","68a1570f":"code","e46116b3":"code","97b470d6":"code","284b2df3":"code","26b3ed97":"code","f48f9cfb":"code","17d401f8":"code","544cfa3e":"code","ca2dd535":"code","e32f4d1f":"code","3184c570":"code","d7e4c4c1":"code","d172e010":"code","7e0d6807":"code","4647001a":"code","064719e7":"code","998885d1":"code","e09ccbe8":"code","0d861e3f":"code","880d5024":"code","29ada9fb":"code","04dc8d85":"code","bfcbac83":"code","cf90a20e":"code","5a4ef87e":"markdown","cafb5bdb":"markdown","ce3b2739":"markdown","42e160b1":"markdown"},"source":{"8afe7032":"#------------------------------------------------------------------------------------------------------------------------------\nimport pandas as pd                                                 # Importing for panel data analysis\nfrom pandas_profiling import ProfileReport                          # Import Pandas Profiling (To generate Univariate Analysis)\npd.set_option('display.max_columns', None)                          # Unfolding hidden features if the cardinality is high\npd.set_option('display.max_rows', None)                             # Unfolding hidden data points if the cardinality is high\npd.set_option('mode.chained_assignment', None)                      # Removing restriction over chained assignments operations\n#-------------------------------------------------------------------------------------------------------------------------------\nimport numpy as np                                                  # Importing package numpys (For Numerical Python)\n#-------------------------------------------------------------------------------------------------------------------------------\nimport matplotlib.pyplot as plt                                     # Importing pyplot interface using matplotlib\nimport seaborn as sns                                               # Importin seaborm library for interactive visualization\n%matplotlib inline\n#-------------------------------------------------------------------------------------------------------------------------------\nfrom sklearn.preprocessing import StandardScaler                    # To scaled data with mean 0 and variance 1\nfrom sklearn.model_selection import train_test_split                # To split the data in training and testing part\nfrom sklearn.tree import DecisionTreeClassifier                     # To implement decision tree classifier\nfrom sklearn.tree import export_graphviz\nfrom sklearn.metrics import classification_report                   # To generate classification report\nfrom sklearn.metrics import plot_confusion_matrix                   # To plot confusion matrix\nfrom IPython.display import Image                                   # To generate image using pydot file\nfrom sklearn.model_selection import GridSearchCV                    # To find best hyperparamter setting for the algorithm\n#-------------------------------------------------------------------------------------------------------------------------------\nimport warnings                                                     # Importing warning to disable runtime warnings\nwarnings.filterwarnings(\"ignore\")                                   # Warnings will appear only once","414a32ad":"# Load the data\ndata = pd.read_csv(filepath_or_buffer='..\/input\/titanic\/train.csv')\n\n# Get the dimesions of data\nprint('Shape of the dataset:', data.shape)\n\n# Output first 5 data rows\ndata.head()","68a1570f":"data.describe()","e46116b3":"profile = ProfileReport(df=data)\nprofile.to_file(output_file='Pre Profiling Report.html')\nprint('Accomplished!')","97b470d6":"# Filling the missing values of Embarked feature with the mode of the feature.\ndata['Embarked'] = data['Embarked'].fillna(value=data['Embarked'].mode()[0])\n\n# Filling the missing values of Age feature with the median age.\ndata['Age'].fillna(value=data['Age'].median(), inplace=True)\n\n# Dropping the Cabin feature\ndata.drop(labels='Cabin', axis=1, inplace=True)","284b2df3":"post_profile=ProfileReport(df=data)\npost_profile.to_file(output_file='Post Profiling Report.html')\nprint('Accomplished!')","26b3ed97":"# Creating a new feature FamilySize from Sibsp and Parch\ndata['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n\ndata.head()","f48f9cfb":"# Performing one hot encoding over sex, embarked, title\ndata = pd.get_dummies(data=data, columns=['Sex', 'Embarked'])\ndata.head(2)","17d401f8":"# Instatiatig input and output data by dropping unnecessary data features\nX = data.drop(labels=['PassengerId', 'Name', 'Ticket', 'Age', 'Fare', 'Survived'], axis=1)\ny = data['Survived']\n\n# Instatiate a scaler object and performing transformation on age and fare\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(data[['Age', 'Fare']])\ndata2 = pd.DataFrame(data=scaled_data, columns=['Age', 'Fare'])\ndata2.head(2)","544cfa3e":"finalX = pd.concat(objs=[X, data2], axis=1)\nfinalX.drop([\"SibSp\",\"Parch\"],axis=1,inplace = True)\nfinalX.head()","ca2dd535":"# Splitting data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(finalX, y, test_size=0.20, random_state=42, stratify=y)\n\n# Display the shape of training and testing data\nprint('X_train shape: ', X_train.shape)\nprint('y_train shape: ', y_train.shape)\nprint('X_test shape: ', X_test.shape)\nprint('y_test shape: ', y_test.shape)","e32f4d1f":"# Instantiate a decision tree classifier\ndtc = DecisionTreeClassifier(random_state=42, class_weight='balanced')\ndtc.fit(X_train, y_train)\n\n# Predicting training and testing labels\ny_train_pred_count = dtc.predict(X_train)\ny_test_pred_count = dtc.predict(X_test)\n\n# Plotting confusion maxtrix of train and test data\nfig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, sharex=False, figsize=(15, 7))\nplot_confusion_matrix(estimator=dtc, X=X_train, y_true=y_train, values_format='.5g', cmap='YlGnBu', ax=ax1)\nplot_confusion_matrix(estimator=dtc, X=X_test, y_true=y_test, values_format='.5g', cmap='YlGnBu', ax=ax2)\nax1.set_title(label='Train Data', size=14)\nax2.set_title(label='Test Data', size=14)\nax1.grid(b=False)\nax2.grid(b=False)\nplt.suptitle(t='Confusion Matrix', size=16)\nplt.show()","3184c570":"train_report = classification_report(y_train, y_train_pred_count)\ntest_report = classification_report(y_test, y_test_pred_count)\nprint('                    Training Report          ')\nprint(train_report)\nprint('                    Testing Report           ')\nprint(test_report)","d7e4c4c1":"# Load the actual test data\ntestdata = pd.read_csv(filepath_or_buffer='..\/input\/titanic\/test.csv')\n\n# Get the dimesions of data\nprint('Shape of the dataset:', testdata.shape)\n\n# Output first 5 data rows\ntestdata.head()","d172e010":"testdata.describe()","7e0d6807":"testdata.isnull().sum()","4647001a":"# Filling the missing values of Age feature with the median age.\ntestdata['Age'].fillna(value=testdata['Age'].median(), inplace=True)\n\n# Dropping the Cabin feature\ntestdata.drop(labels='Cabin', axis=1, inplace=True)\n\n# Filling the missing value of Fare feature with the median Fare.\ntestdata['Fare'].fillna(value=testdata['Fare'].median(), inplace=True)","064719e7":"testdata.isnull().sum()","998885d1":"# Creating a new feature FamilySize from Sibsp and Parch\ntestdata['FamilySize'] = testdata['SibSp'] + testdata['Parch'] + 1","e09ccbe8":"testdata = pd.get_dummies(data=testdata, columns=['Sex', 'Embarked'])\ntestdata.head(2)","0d861e3f":"#dropping unnecessary data features\ntest = testdata.drop(labels=['PassengerId',\"SibSp\",\"Parch\", 'Name', 'Ticket', 'Age', 'Fare'], axis=1)\n\n# performing transformation on age and fare\nscaled_testdata = scaler.transform(testdata[['Age', 'Fare']])\ndata3 = pd.DataFrame(data=scaled_testdata, columns=['Age', 'Fare'])\ndata3.head(2)","880d5024":"finaltest = pd.concat(objs=[test, data3], axis=1)\nfinaltest.head()","29ada9fb":"finaltest_pred = dtc.predict(finaltest)","04dc8d85":"finaltest_pred","bfcbac83":"finaltest.join(pd.DataFrame(finaltest_pred)) #= pd.concat(objs=[finaltest, finaltest_pred], axis=1)","cf90a20e":"print(\"Thank you\")","5a4ef87e":"Observation:\n\nTrain Data:\n\nModel predicted 430 instances correctly for negative class while 269 instances were predicted correctly for positive class.\nModel identified 4 instances negative but in actual they were positive.\nModel identified 9 instances positive but in actual they were negative.\nTest Data:\n\nModel predicted 90 instances correctly for negative class while 52 instances were predicted correctly for positive class.\nModel identified 17 instance negative but in actual it was positive.\nModel identified 20 instances positive but in actual they were negative.","cafb5bdb":"Observations:\n\nYou can compare the two reports, i.e Pre Profiling Report.html and Post Profiling Report.html.\n\nObservations in Post Profiling Report.html:\n\nIn the Dataset info, Total Missing = 0.0%\n\nNumber of features = 11\n\nYou can see the difference in the Age feature in both the reports.\n\nA lot of zeros are present in Sibsp and Parch features. They won't be removed as they are necessary.\n\nWe can observe that Pclass and Fare are highly correlated to each other inversely.\n\nA lot of inverse correlations are observed among the features.\n\nFor detailed information, check the Post Profiling Report.html file.\n\nWe can now begin the Exploratory Data Analysis.","ce3b2739":"Observations:\n\nThe report shows that there are a total of 12 features out of which 7 are numerical and 5 are categorical.\n\nOnly 342 passengers out of 891 survived the accident.\n\nName, Ticket, and Cabin features have high cardinality and are uniformly distributed.\n\nPassengerId is having a uniformly distribution in the dataset.\n\nFare feature is highly skewed towards right while Age feature is faily symmetrical.\n\nThere are no duplicate rows in the dataset while a lot of zeros are present in Fare, Sibsp and Parch features.\n\nWe can observe that 8.1% of data in cells is missing:\n\nAge (17 missing values) \u2192 Fill with median.\nCabin (687 missing values) \u2192 Fill with median.\nEmbarked (2 missing values) \u2192 Fill with mode.\nEmbarked feature has just 2 missing values.\n\nFor detailed information, check the Pre Profiling Report.html file.","42e160b1":"**Observations:**\n\n**Survived:**\nMore than 50% did not survive the accident.\n\n**Pclass:**\nThere are a lot more 3rd class passengers than 1st and 2nd class.\nWe can also see that there are more 2nd class passengers than 1st class passengers.\n\n**SibSp:**\nMore than 50% of passengers are not travelling with their siblings or a spouse.\nThere are some passengers who are travelling with as maximum as 8 siblings and spouse.\n\n**Parch:**\nMore than 75% passengers are not travelling with a parent or children\nBut there are some passengers who have a maximum number of 6 children and\/or parents with them on the ship.\nWe observe that a vast majority of passengers are not travelling with their family members.\n\n**Age:**\nThe average age of passengers is around 29 years while the minimum and maximum ages are 0.4 years and 80 years respectively.\nThere is some missing data in the Age feature.\n\n**Fare:**\nThe average price of ticket seems to be \u00a332.2. Minimum price of the ticket is recorded as \u00a30 and maximum price recorded as high as \u00a3512.32.\nMore than 50% of the passengers have paid atleast \u00a314\nMore than 75% passengers have paid atleast \u00a37 for their ticket whereas less than 25% have paid for more than \u00a331.\nWe have to replace the minimum value in the Fare feature with a reasonable value."}}