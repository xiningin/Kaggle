{"cell_type":{"b83481b0":"code","b436422f":"code","a459f968":"code","1190e69e":"code","53bd7171":"code","8707f36f":"code","37e94d54":"code","47da92fc":"code","b02fe618":"code","f257cfd4":"code","e171e66f":"code","8c765ac2":"code","67d2848e":"code","ba9662f1":"code","a832c4e2":"code","ad311a71":"code","49875a3f":"code","7bcb0b85":"code","2b994a8e":"code","5159916c":"code","877f9fa4":"code","e5d15fe9":"code","2d1e77e7":"code","3e075d8a":"code","1c535825":"code","82a2fc95":"code","5d08015a":"code","92bec6c4":"code","cfb80912":"code","332dd76b":"code","c0f3c2bc":"code","8b92d745":"code","a8605f1a":"code","25dec02d":"code","599925fe":"code","b0a1887d":"code","cfd4c0b3":"code","562e1963":"code","af284c04":"markdown","5a036312":"markdown","a55f2970":"markdown","14b3193a":"markdown","a5d16aaa":"markdown","c901bd18":"markdown","52d0c8f4":"markdown","18218851":"markdown","1095f16a":"markdown","c2d91fe6":"markdown","af466da7":"markdown","d3c2fe09":"markdown","20834bed":"markdown","6e125c91":"markdown","d693c160":"markdown","682a82a5":"markdown","4d796ea5":"markdown","8370d5eb":"markdown"},"source":{"b83481b0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b436422f":"train = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')","a459f968":"train.head()","1190e69e":"train.isnull().sum()","53bd7171":"test.isnull().sum()","8707f36f":"test.info","37e94d54":"train.drop(columns = 'location', inplace = True)\ntest.drop(columns = 'location', inplace = True)","47da92fc":"train[train['keyword'].notnull()][train['target']== 1]","b02fe618":"train[train['keyword'].notnull()][train['target']== 0]","f257cfd4":"train['keyword'].value_counts().index","e171e66f":"train.head(10)","8c765ac2":"def lowercase_text(text):\n    text = text.lower()\n    return text\ntrain['text'] = train['text'].apply(lambda x : lowercase_text(x))\ntest['text'] = test['text'].apply(lambda x : lowercase_text(x))\n","67d2848e":"train['text'].head(10)","ba9662f1":"import string\nstring.punctuation","a832c4e2":"train.head(10)","ad311a71":"def remove_punctuation(text):\n    text_no_punctuation = \"\".join([c for c in text if c not in string.punctuation])\n    return text_no_punctuation\ntrain[\"text\"] = train[\"text\"].apply(lambda x: remove_punctuation(x))\ntest[\"text\"] = test[\"text\"].apply(lambda x: remove_punctuation(x))","49875a3f":"train['text'].head(10)","7bcb0b85":"import nltk\nfrom nltk.tokenize import RegexpTokenizer\n# Tokenizing the training and the test set\ntokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\ntrain['text'] = train['text'].apply(lambda x: tokenizer.tokenize(x))\ntest['text'] = test['text'].apply(lambda x: tokenizer.tokenize(x))\ntrain['text'].head()","2b994a8e":"from nltk.corpus import stopwords\nprint(stopwords.words('english'))","5159916c":"train.head(10)","877f9fa4":"def remove_stopwords(text):\n    \"\"\"\n    Removing stopwords belonging to english language\n    \n    \"\"\"\n    \n    words = [w for w in text if w not in stopwords.words('english')]\n    return words\n\n\ntrain['text'] = train['text'].apply(lambda x : remove_stopwords(x))\ntest['text'] = test['text'].apply(lambda x : remove_stopwords(x))\n","e5d15fe9":"train.head(10)","2d1e77e7":"def combine_text(list_of_text):\n    combine_text = ' '.join(list_of_text)\n    return combine_text\ntrain[\"text\"] = train[\"text\"].apply(lambda x: combine_text(x))\ntest[\"text\"] = test[\"text\"].apply(lambda x: combine_text(x))","3e075d8a":"train.head()","1c535825":"from sklearn.feature_extraction.text import CountVectorizer\ncount_vectorizer = CountVectorizer()\n## note that we're NOT using .fit_transform() here. Using just .transform() makes sure\n# that the tokens in the train vectors are the only ones mapped to the test vectors - \n\ntrain_vector = count_vectorizer.fit_transform(train[\"text\"]).todense()\ntest_vector = count_vectorizer.transform(test[\"text\"]).todense()","82a2fc95":"print(count_vectorizer.vocabulary_)","5d08015a":"print(train_vector.shape)\nprint(test_vector.shape)","92bec6c4":"from sklearn.model_selection import train_test_split\n\nY = train[\"target\"]\nx_train, x_test, y_train,y_test = train_test_split(train_vector,Y, test_size = 0.3, random_state = 0)\ny_train","cfb80912":"from sklearn.model_selection import cross_val_score","332dd76b":"from sklearn.metrics import accuracy_score","c0f3c2bc":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression(C = 3.0)\nscores = cross_val_score(model, train_vector, train['target'], cv=5)\n","8b92d745":"print(scores.mean())","a8605f1a":"model.fit(x_train, y_train)\ny_pred_model_1 = model.predict(x_test)\n","25dec02d":"print(accuracy_score(y_test,y_pred_model_1))","599925fe":"y_pred_test = model.predict(test_vector)","b0a1887d":"from sklearn.svm import SVC","cfd4c0b3":"svm = SVC(kernel = \"linear\", C = 0.15, random_state = 100)\nsvm.fit(x_train, y_train)\ny_pred = svm.predict(test_vector)","562e1963":"sub = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/sample_submission.csv')\nsub['target'] = y_pred\nsub.to_csv(\"submission.csv\", index=False)\nsub.head(10)","af284c04":"**Accuracy score**","5a036312":"**Model fitting and implementation**","a55f2970":"**Checking missing values**","14b3193a":"train.info","a5d16aaa":"Data Cleaning\n","c901bd18":"**Remove stop words\n**","52d0c8f4":"**Data Analysing**\n","18218851":"**Putting result in sample_submission file******","1095f16a":"**Importing data**","c2d91fe6":"**Checking fro relations in KEYWORD and TARGET**","af466da7":"Lowercase text","d3c2fe09":"**Tokenize**","20834bed":"**Deleting stopwords**","6e125c91":"**Stemming and lemmatization(optional)**","d693c160":"**Removing noise**","682a82a5":"**Count vectorize**","4d796ea5":" **Dropping LOCATION column **","8370d5eb":"**Removing punctuations**"}}