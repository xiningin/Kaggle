{"cell_type":{"dd14531b":"code","ebcccc11":"code","1f1fdedf":"code","3e3095c1":"code","e81ffb22":"code","004db0f1":"code","b131a869":"code","8530a964":"code","296d0574":"code","40d8fc7e":"code","1dbe8ad0":"code","d494a16a":"code","7245e6db":"code","39622868":"code","578d645e":"code","3b5aa8c7":"code","32fce7e8":"code","0cae0f49":"code","ddebf059":"code","fb0655f9":"code","6ed2dd21":"code","79016d0f":"code","3e66378a":"code","39076b1c":"code","23348991":"code","c65fced4":"code","5bb2321f":"code","1f536c27":"code","0fce8f3f":"code","0616d7ac":"code","e39a13d0":"code","8aea5375":"code","e1f8dcc0":"code","c57eb03c":"code","aa8518a3":"code","138842b9":"code","580e6215":"code","dcd1aca2":"code","6eae45bb":"code","80d1edf5":"code","70c6a011":"code","04890a9d":"code","b6cc36c7":"code","1026ce0e":"code","22fd51f2":"code","b4584278":"code","da516c2a":"code","3f656abb":"code","c2d23d5b":"code","7c2b1566":"code","f6791f63":"code","1b54d298":"markdown","e24c5548":"markdown","b84af23b":"markdown","b1b5463b":"markdown","a8b108cd":"markdown","eed2f07f":"markdown","b871be59":"markdown","e35053de":"markdown","e1abf8f4":"markdown","06d9eb33":"markdown","639e7cdc":"markdown"},"source":{"dd14531b":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nsns.set_style('darkgrid')\n%matplotlib inline","ebcccc11":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","1f1fdedf":"train","3e3095c1":"train.info()","e81ffb22":"train.describe()","004db0f1":"import missingno\nplt.subplot(1,2,1)\nmissingno.bar(train, figsize = (20,5))\nplt.subplot(1,2,2)\nmissingno.bar(test, figsize = (20,5))\nplt.show()","b131a869":"plt.figure(figsize = (15,5))\nplt.subplot(1,2,1)\nsns.countplot(x = 'Survived', data = train)\nplt.subplot(1,2,2)\ntrain['Survived'].value_counts().plot(kind = 'pie', autopct = '%.2f%%')\nplt.show()","8530a964":"train.columns","296d0574":"plt.figure(figsize = (20,15))\nfor i,col in enumerate(['Pclass','Sex','SibSp','Parch', 'Embarked']):\n    plt.subplot(3,2,i+1)\n    sns.countplot(x = col, hue = 'Survived', data = train)\nplt.show()","40d8fc7e":"plt.figure(figsize = (20,15))\nfor i,col in enumerate(['Pclass','Sex','SibSp','Parch', 'Embarked']):\n    plt.subplot(3,2,i+1)\n    sns.countplot(x = col, data = test)\nplt.show()","1dbe8ad0":"train.columns","d494a16a":"plt.figure(figsize = (20,5))\nfor i,col in enumerate(['Age','Fare']):\n    plt.subplot(1,2,i+1)\n    sns.boxplot(y = col, x = 'Survived', data = train)\nplt.show()","7245e6db":"plt.figure(figsize = (20,5))\nfor i,col in enumerate(['Age','Fare']):\n    plt.subplot(1,2,i+1)\n    sns.kdeplot(x = col, hue = 'Survived', data = train, shade = True)\nplt.show()","39622868":"data = pd.concat([train,test], axis = 0).reset_index(drop = True)\ndata","578d645e":"data.isna().mean()","3b5aa8c7":"train['Age'] = train['Age'].fillna(data['Age'].mean())\ntest['Age'] = test['Age'].fillna(data['Age'].mean())\n\ntrain['Embarked'] = train['Embarked'].fillna(data['Embarked'].mode()[0])\ntest['Fare'] = test['Fare'].fillna(data['Fare'].mean())\n\ntrain = train.drop('Cabin', axis = 1)\ntest = test.drop('Cabin', axis = 1)","32fce7e8":"train","0cae0f49":"list(train['Name'])[:10]","ddebf059":"train['Prefix'] = train['Name'].str.extract(pat = r',\\s([\\w]+).')","fb0655f9":"plt.figure(figsize = (15,7))\nsns.countplot(x = 'Prefix',hue = 'Survived' ,data = train)\nplt.show()","6ed2dd21":"def func(val):\n    if val not in ['Mr','Mrs','Miss','Master']:\n        val = 'Other'\n    return val\ntrain['Prefix'] = train['Prefix'].apply(func)","79016d0f":"plt.figure(figsize = (20,5))\nfor i,val in enumerate(train['Prefix'].unique()):\n    plt.subplot(1,5,i+1)\n    train[train['Prefix'] == val]['Survived'].value_counts().plot(kind = 'pie', autopct = '%.2f%%', title = val)\nplt.show()","3e66378a":"test['Prefix'] = test['Name'].str.extract(pat = r',\\s([\\w]+).')","39076b1c":"plt.figure(figsize = (10,5))\nsns.countplot(x = 'Prefix',data = test)\nplt.show()","23348991":"def func(val):\n    if val not in ['Mr','Mrs','Miss','Master']:\n        val = 'Other'\n    return val\ntest['Prefix'] = test['Prefix'].apply(func)","c65fced4":"train = train.drop(['Name','Ticket','PassengerId'], axis = 1)\ntest_ids = test['PassengerId']\ntest = test.drop(['Name','Ticket','PassengerId'], axis = 1)","5bb2321f":"train","1f536c27":"test","0fce8f3f":"train['Prefix'] = train['Prefix'].map({'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Other': 4})\ntrain['Embarked'] = train['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\ntrain['Sex'] = train['Sex'].map({'male': 0, 'female': 1})\n\ntest['Prefix'] = test['Prefix'].map({'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Other': 4})\ntest['Embarked'] = test['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\ntest['Sex'] = test['Sex'].map({'male': 0, 'female': 1})","0616d7ac":"plt.figure(figsize = (12,10))\nsns.heatmap(train.corr(), center = 0, vmin = -1.0, vmax = 1.0, annot = True, cmap = 'RdBu_r')\nplt.show()","e39a13d0":"X = train.drop('Survived', axis = 1).copy()\ny = train['Survived'].copy()","8aea5375":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, stratify = y, random_state = 42)","e1f8dcc0":"from sklearn.preprocessing import StandardScaler,MinMaxScaler\nsc = MinMaxScaler()\nsc.fit(X_train)\nX_train_scaled = pd.DataFrame(sc.transform(X_train), columns = X_train.columns, index = X_train.index)\nX_test_scaled = pd.DataFrame(sc.transform(X_test), columns = X_test.columns, index = X_test.index)","c57eb03c":"!pip install -q pycaret\nfrom pycaret.classification import *","aa8518a3":"_ = setup(data = pd.concat([X_train_scaled, y_train], axis = 1), target = 'Survived', silent = True)","138842b9":"top5 = compare_models(n_select = 5)","580e6215":"model = create_model(top5[0])","dcd1aca2":"y_pred = predict_model(model, data = X_test_scaled)['Label']\n\nfrom sklearn.metrics import f1_score, accuracy_score,confusion_matrix,classification_report\n\nprint('Accuracy score : {:.4f}'.format(accuracy_score(y_test,y_pred)))\nprint('F1 score : {:.4f}'.format(f1_score(y_test,y_pred)))\n\nprint('\\n\\n\\nClassification Report: \\n-----------------\\n', classification_report(y_test,y_pred))\nprint('\\n\\n\\nConfusion Matrix: \\n-----------------\\n')\ncm = confusion_matrix(y_test,y_pred)\nsns.heatmap(cm,annot = True, cmap = 'Blues', cbar = False, fmt = 'g')\nplt.show()","6eae45bb":"stacker = stack_models(estimator_list = top5[1:], meta_model = top5[0])","80d1edf5":"y_pred = predict_model(stacker, data = X_test_scaled)['Label']\n\nfrom sklearn.metrics import f1_score, accuracy_score,confusion_matrix,classification_report\n\nprint('Accuracy score : {:.4f}'.format(accuracy_score(y_test,y_pred)))\nprint('F1 score : {:.4f}'.format(f1_score(y_test,y_pred)))\n\nprint('\\n\\n\\nClassification Report: \\n-----------------\\n', classification_report(y_test,y_pred))\nprint('\\n\\n\\nConfusion Matrix: \\n-----------------\\n')\ncm = confusion_matrix(y_test,y_pred)\nsns.heatmap(cm,annot = True, cmap = 'Blues', cbar = False, fmt = 'g')\nplt.show()","70c6a011":"mn = MinMaxScaler()","04890a9d":"X_scaled = pd.DataFrame(mn.fit_transform(X), columns = X.columns, index = X.index)","b6cc36c7":"_ = setup(data = pd.concat([X_scaled, y], axis = 1), target = 'Survived', silent = True)","1026ce0e":"top5 = compare_models(n_select = 5)","22fd51f2":"model = create_model('catboost')","b4584278":"interpret_model(model)","da516c2a":"top = create_model(top5[0])","3f656abb":"test_scaled = pd.DataFrame(mn.transform(test), columns = test.columns, index = test.index)\ny_pred = predict_model(top, data = test_scaled)['Label']","c2d23d5b":"submission_df = pd.concat([test_ids,y_pred],axis = 1)\nsubmission_df = submission_df.rename(columns = {'Label':'Survived'})","7c2b1566":"submission_df","f6791f63":"submission_df.to_csv('submission.csv',index = False)","1b54d298":"## Analysing SHAP values for *Catboost*","e24c5548":"## Using Ensemble techinque (Stacking)","b84af23b":"## Preparing for submission","b1b5463b":"## Encoding the object features","a8b108cd":"## Importing Libraries","eed2f07f":"## Model training","b871be59":"## Filling Missing values","e35053de":"## Exploratory Data Analysis","e1abf8f4":"## Feature Engineering","06d9eb33":"## Reading Data","639e7cdc":"## Training on whole data"}}