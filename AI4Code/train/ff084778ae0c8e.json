{"cell_type":{"848d66cc":"code","c757d173":"code","ae0a0afd":"code","95d9a2f0":"code","e195cfdc":"code","2a26b960":"code","4ef61be7":"code","d523ffd1":"code","ba14c143":"code","3ee26d90":"code","b0236e8c":"code","b8e1af4d":"code","d174e766":"code","e9bacce9":"code","4979fd2a":"markdown","dd6173d6":"markdown","bfd49b9b":"markdown","1a66566c":"markdown","61a00b3b":"markdown","3e5e1190":"markdown"},"source":{"848d66cc":"# This Python 3 environment comes with many helpful analytics libraries installed\/Users\/deanmendes\/Dropbox\/Dean Mendes-26992\/Data Science, Algorithms and Advanced Software Engineering\/Completed Tasks\/Task 17\/data1953.csv\n# It is defined by the kaggle\/python doc\/Users\/deanmendes\/Dropbox\/Dean Mendes-26992\/Data Science, Algorithms and Advanced Software Engineering\/Completed Tasks\/Task 17\/data2008.csvker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c757d173":"# read in csv file of life expenctancy vs birth rate\nData = pd.read_csv('\/kaggle\/input\/data2008.csv')\nData.head()","ae0a0afd":"Data.info()","95d9a2f0":"Data.isnull().sum()","e195cfdc":"Data.describe().T","2a26b960":"Data.plot(x='BirthRate(Per1000 - 2008)', y='LifeExpectancy(2008)', kind='scatter')\nplt.show()","4ef61be7":"ax1 = sns.distplot(Data['BirthRate(Per1000 - 2008)'], hist=False, label='Birth Rate')\nsns.distplot(Data['LifeExpectancy(2008)'], hist=False, label='Life Expectancy')\nplt.show()","d523ffd1":"# dropping column of countries\ndf = Data.copy(deep=True)\ndf.drop(columns='Countries', inplace = True)\ndf.head()","ba14c143":"# create x and y variable then joining them together to scale\n# X varibale of birthrate\nX = df.iloc[:,0].values\nprint(X[:5])\n\n# Y variable of life expectancy\nY = df.iloc[:, 1].values\nprint(Y[:5])\n\n# Z object to be scaled\nZ = np.array(list(zip(X,Y)))\nZ[:5]","3ee26d90":"# import StandardScaler from sklearns preprocessing library to scaled Z object\nfrom sklearn.preprocessing import StandardScaler\n\n# scale object\nscale = StandardScaler()\n# fit and transform Z\nZ_scaled = scale.fit_transform(Z)\nZ_scaled[:5]","b0236e8c":"fig = plt.figure(figsize=(15,5))\nax1 = fig.add_subplot(1,2,1)   # before standard\nax2 = fig.add_subplot(1,2,2)   # after standard\n\n# first plot before standardizing\nsns.distplot(df['BirthRate(Per1000 - 2008)'], hist=False, label='Birth Rate', ax=ax1)\nsns.distplot(df['LifeExpectancy(2008)'], hist=False, label='Life Expectancy', ax=ax1)\nax1.set_title('Before Standardizing')\nax1.set_xlabel('Distributions')\n\n# second plot (after standardizing)\nsns.distplot(Z_scaled[:,0], hist=False, label='Birth Rate', ax=ax2)\nsns.distplot(Z_scaled[:,1], hist=False, label='Life Expectancy', ax=ax2)\nax2.set_title('After Standardizing')\nax2.set_xlabel('Distributions')\nplt.legend()\nplt.show()\n\n","b8e1af4d":"# import necessary libraries\nfrom sklearn.cluster import KMeans\n\n# values for k \nK_range = range(1,10)\n\n# wcss \/ inertia property (tendency of to remain unchanged)\nwcss = []\n\n# for looop to find the best value for k\nfor i in K_range:\n    \n    # kmean object\n    kmean = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=300, random_state=0)\n    # fit kmean object with scaled data\n    kmean.fit(Z_scaled)\n    \n    # fill in wcss variable\n    wcss.append(kmean.inertia_)\n    \n# visualize effect of the above loop\nsns.lineplot(K_range, wcss, marker='o')\nplt.title('Elbow Method')\nplt.xlabel('Best Ks')\nplt.ylabel('Inertia')\nplt.show()","d174e766":"# build model using k=2 clusters\nkm = KMeans(n_clusters=2, init='k-means++', max_iter=300, n_init=10, random_state=0)\nkm.fit(Z_scaled)\n\n# labels ie the labels that each row is categorized under\nlabels = km.labels_\n# add label category to initial dataframe\nData['Labels'] = labels\n\n# centroids\ncentroids = km.cluster_centers_\n\n# ensure labels is now a column\nData.head()","e9bacce9":"# scatter data points\nax1 = plt.scatter(Z_scaled[:,0], Z_scaled[:,1], \n                  marker='o', alpha=.5, \n                  c=labels.astype(float), label='Data Points')\n\n# plot centroids\nsns.scatterplot(centroids[:,0], centroids[:,1], \n                marker='*', s=300, color='r', \n                label='Centroids')\n\nplt.title('Scatter plot showing data points and centroids')\nplt.xlabel('Birthrate')\nplt.ylabel('Life Expectancy')\nplt.legend()\nplt.show()","4979fd2a":"*By the above result, the best value for K is 2*","dd6173d6":"## Visualize Final Cluster Model","bfd49b9b":"## Data Exploration","1a66566c":"## Data Preprocessing \n\n1) Create new dataframe for preprocessing\n2) Drop unnecessary columns  \n3) Create scaled object of X, Y","61a00b3b":"## Implementing k-mean algorithm  \n\n1) Find best value for k using elbow method  \n2) Create k-mean model with best value for k and visualize results","3e5e1190":"*Visualize effects of scaling data using distribution plot*"}}