{"cell_type":{"2192de6b":"code","cf270dad":"code","7c7dd923":"code","03ccace3":"code","d3c2511f":"code","d8dbebf7":"code","6ea76393":"code","dfd3bd95":"code","fa124ef5":"code","92432c3d":"code","c282c044":"code","998abc3f":"code","f37e0df9":"code","032cf29e":"markdown","5109f330":"markdown","35ee344c":"markdown","cf45b119":"markdown","8ec6fae9":"markdown","38112c3a":"markdown"},"source":{"2192de6b":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import r2_score","cf270dad":"data = pd.read_csv('..\/input\/sales-forecasting\/train.csv')","7c7dd923":"data","03ccace3":"data.info()","d3c2511f":"def encode_dates(df, column):\n    df = df.copy()\n    df[column] = pd.to_datetime(df[column])\n    df[column + '_year'] = df[column].apply(lambda x: x.year)\n    df[column + '_month'] = df[column].apply(lambda x: x.month)\n    df[column + '_day'] = df[column].apply(lambda x: x.day)\n    df = df.drop(column, axis=1)\n    return df\n\ndef onehot_encode(df, column):\n    df = df.copy()\n    dummies = pd.get_dummies(df[column], prefix=column)\n    df = pd.concat([df, dummies], axis=1)\n    df = df.drop(column, axis=1)\n    return df","d8dbebf7":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop unnecessary columns\n    df = df.drop(['Row ID', 'Customer Name', 'Country', 'Product Name'], axis=1)\n    \n    # Drop customer-specific feature columns\n    df = df.drop(['Order ID', 'Customer ID'], axis=1)\n    \n    # Extract date features\n    df = encode_dates(df, column='Order Date')\n    df = encode_dates(df, column='Ship Date')\n    \n    # One-hot encode categorical features\n    for column in ['Ship Mode', 'Segment', 'City', 'State', 'Postal Code', 'Region', 'Product ID', 'Category', 'Sub-Category']:\n        df = onehot_encode(df, column=column)\n    \n    # Split df into X and y\n    y = df['Sales']\n    X = df.drop('Sales', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), columns=X.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n    \n    return X_train, X_test, y_train, y_test","6ea76393":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","dfd3bd95":"X_train","fa124ef5":"y_train","92432c3d":"inputs = tf.keras.Input(shape=(X_train.shape[1],))\nx = tf.keras.layers.Dense(256, activation='relu')(inputs)\nx = tf.keras.layers.Dense(256, activation='relu')(x)\noutputs = tf.keras.layers.Dense(1, activation='linear')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nprint(model.summary())","c282c044":"model.compile(\n    optimizer='adam',\n    loss='mse'\n)\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=32,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=5,\n            restore_best_weights=True\n        ),\n        tf.keras.callbacks.ReduceLROnPlateau()\n    ]\n)","998abc3f":"test_loss = model.evaluate(X_test, y_test, verbose=0)\n\nprint(\"Test Loss: {:.5f}\".format(test_loss))","f37e0df9":"y_pred = np.squeeze(model.predict(X_test))\ntest_r2 = r2_score(y_test, y_pred)\n\nprint(\"Test R^2 Score: {:.5f}\".format(test_r2))","032cf29e":"# Getting Started","5109f330":"# Results","35ee344c":"# Task for Today  \n\n***\n\n## Superstore Sales Prediction  \n  \nGiven *data about sales at a superstore*, let's try to predict the **revenue generated** from a given sale.  \n  \nWe will use a TensorFlow neural network to make our predictions.","cf45b119":"# Training","8ec6fae9":"# Preprocessing","38112c3a":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/RHd26NU7LRs"}}