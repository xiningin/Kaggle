{"cell_type":{"bae3e256":"code","d8bc86f8":"code","7dcca316":"code","ad2f352a":"code","3bda7067":"code","12150e33":"code","8ef469f8":"code","cd133d49":"code","6b77ae3b":"code","05970c9f":"code","dc61d5cd":"code","1b30f18e":"code","9d21f585":"code","4e9c0b81":"code","4eec8e52":"code","266c5aae":"code","02048076":"code","656687c7":"code","4f1f142a":"code","00c23cfb":"code","19d81993":"code","9714d6ff":"markdown","8762ccdf":"markdown","22673542":"markdown","7d229866":"markdown","0644d985":"markdown","223bf255":"markdown"},"source":{"bae3e256":"# training detection see version 75-96.","d8bc86f8":"import tensorflow as tf\nimport os\nimport xml.etree.ElementTree as ET\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nimport numpy as np\nfrom PIL import Image,ImageDraw,ImageFont\nimport sys\nimport time\nimport cv2\nimport random\n# np.set_printoptions(threshold=sys.maxsize)\nbegin_time=time.time()","7dcca316":"# Image classification pretrained vgg16 model\nweights=np.load(\"..\/input\/mvgg16\/vgg16.npy\",allow_pickle=True,encoding='latin1').item()","ad2f352a":"B=5  # Bounding box nums\nS=14 # Gird cell nums\nnum_class=20\nimg_width=448\nimg_height=448","3bda7067":"def get_iou(b1,b2,standarded=False):  # box denoted by 4 points [ul,ur,dr,dl]\n    w=min(b1[1][0],b2[1][0])-max(b1[0][0],b2[0][0])\n    h=min(b1[3][1],b2[3][1])-max(b1[0][1],b2[0][1])\n    if(w<=0 or h<=0):\n        return 0\n    union_area=w*h\n    b1_area=(b1[1][0]-b1[0][0])*(b1[3][1]-b1[0][1])\n    b2_area=(b2[1][0]-b2[0][0])*(b2[3][1]-b2[0][1])\n    if(standarded):\n        return union_area\/(b1_area+b2_area-union_area)\n    else:\n        return union_area\/min(b1_area,b2_area)\n\ndef surpress(boxes,threshold):    # helper function for nonmax surpression. Every single box is denoted as [confidence,ul,ur,dr,dl]\n    i=1\n    while(i<len(boxes)):\n        if(get_iou(boxes[0][1:5],boxes[i][1:5],True)>threshold):\n            del boxes[i]\n        else:\n            i+=1\n    return boxes[0],boxes[1:]\n\ndef nonmax_surpression(boxes,threshold):    #  Box is denoted as [confidence,ul,ur,dr,dl]\n    boxes.sort(key = lambda x: x[0],reverse=True)\n    i=0\n    r=[]\n    if(len(boxes)<=1):\n        return boxes\n    while(True):\n        if(len(boxes)==1):\n            r.append(boxes[0])\n            break\n        elif(len(boxes)==0):\n            break\n        box,boxes=surpress(boxes,threshold)\n        r.append(box)\n    return r\n    \n\ndef draw_box(img,boxes):\n    img=Image.fromarray(img)\n    d=ImageDraw.Draw(img)\n    for i in boxes:\n        d.line([i[1],i[2],i[3],i[4],i[1]],width=2,fill=(255,0,0))  # Box is denoted as [confidence,ul,ur,dr,dl]\n        d.rectangle((i[1][0],i[1][1],i[1][0]+len(i[-1])*8,i[1][1]+11),fill=\"black\")\n        d.text(i[1],i[-1],(0,100,0))\n    display(img)    \n\ndef get_surppressed_boxes(n,matrix,pred_x,pred_y,pred_w,pred_h,pred_class):  # calculate all the boxes from net output, and nms\n    boxes=[]\n    mask=np.argmax(matrix,axis=-1)[...,None]==np.arange(matrix.shape[-1]) # [S,S,B] mask, choose the higher confidience bounding box\n    matrix=matrix[mask].reshape([matrix.shape[0],matrix.shape[1]])\n    pred_x=pred_x[mask].reshape([matrix.shape[0],matrix.shape[1]])\n    pred_y=pred_y[mask].reshape([matrix.shape[0],matrix.shape[1]])\n    pred_w=pred_w[mask].reshape([matrix.shape[0],matrix.shape[1]])\n    pred_h=pred_h[mask].reshape([matrix.shape[0],matrix.shape[1]])\n    to_concat=[]\n    for i in range(B):\n        to_concat.append(np.tile(mask[:,:,i:i+1],[1,1,20]))\n    tile_mask=np.concatenate(to_concat, axis=-1)\n    pred_class=pred_class[tile_mask].reshape([matrix.shape[0],matrix.shape[1],20])\n    for i in [index for index,value in enumerate(list((matrix>0.25).flatten())) if(value==True)]:\n        cur_class=data.classes[np.argmax(pred_class[i\/\/14,i%14])]+\" \"+str(round(matrix[i\/\/14,i%14],2))\n        h=i\/\/14*gird_len\n        w=i%14*gird_len\n        tx=pred_x[i\/\/14,i%14]*gird_len+w\n        ty=pred_y[i\/\/14,i%14]*gird_len+h\n        width=pred_w[i\/\/14,i%14]*448\n        height=pred_h[i\/\/14,i%14]*448\n        ul=(tx-width\/2,ty-height\/2)\n        ur=(tx+width\/2,ty-height\/2)\n        dr=(tx+width\/2,ty+height\/2)\n        dl=(tx-width\/2,ty+height\/2)\n        boxes.append([matrix[i\/\/14,i%14],ul,ur,dr,dl,n,cur_class])\n    boxes=nonmax_surpression(boxes,0.5)\n    return boxes\n\ndef get_max_iou(box,boxes):\n    cur_max=0\n    index=0\n    for i in range(len(boxes)):\n        iou=get_iou(box,boxes[i],True)\n        if(iou>cur_max):\n            cur_max=iou\n            index=i\n    return cur_max,boxes[index][4],index\n\ndef get_mAP(predict_boxes,target_boxes,total_boxes):\n    if(predict_boxes==[]):\n        return 0,0,0\n    predict_boxes.sort(key=lambda x:x[0],reverse=True)\n    tp=0\n    fp=0\n    num_diffi=0\n    step=0\n    dic={}\n    predicted_record=[]\n    \n    for i in target_boxes:\n        for j in i:\n            if(j[4]==1):\n                num_diffi+=1\n    \n    for i in predict_boxes:        \n        max_iou,diffi,index=get_max_iou(i[1:5],target_boxes[i[5]])\n        if(diffi):\n            continue\n        if(max_iou>0.5 and [i[5],index] not in predicted_record):\n            tp+=1\n            predicted_record.append([i[5],index])\n        else:\n            fp+=1\n        cur_recall=tp\n        if(cur_recall not in dic.keys()):\n            dic[cur_recall]=tp\/(tp+fp)\n    new={}\n    for i in dic:\n        new[i\/(total_boxes-num_diffi)]=dic[i]\n    dic=new\n    if(0 in dic.keys()):\n        del dic[0]\n    if(dic=={}):\n        return 0,0,0\n    keys=list(dic.keys())\n    keys.sort()\n    mAP=0\n    for i in range(1,len(keys)):\n        mAP=mAP+(keys[i]-keys[i-1])*dic[keys[i]]\n    mAP=mAP+dic[keys[0]]*keys[0]\n    return mAP,tp\/(total_boxes-num_diffi),tp\/(tp+fp)\n    \ndef do_test(sess,test_size=100,draw=5,verbose=False):\n    difficulty=[]\n    x_test=[]\n    xl_test=[]\n    yl_test=[]\n    wl_test=[]\n    hl_test=[]\n    Pcl_test=[]\n    Iobjl_test=[]\n    pred_c_test=[]\n    pred_x_test=[]\n    pred_y_test=[]\n    pred_w_test=[]\n    pred_h_test=[]\n    pred_class_test=[]\n    end=False\n    count=0\n    while(not end):\n        end,x_data,xt,yt,wt,ht,ct,objt,Inoobjl_test,diffi=data.get_test_data()\n        pc,px,py,pw,ph,pclass=sess.run([allc,allx,ally,allw,allh,pred_class],\\\n                                                      feed_dict={input_:x_data,\\\n                                                      x_cor:xt,\\\n                                                      y_cor:yt,\\\n                                                      width:wt,\\\n                                                      height:ht,\\\n                                                      class_label:ct,\\\n                                                      Iobj:objt,\\\n                                                      Inoobj:Inoobjl_test,\\\n                                                      cur_mode:False,\\\n                                                      treshold:0.5\n                                                     })\n        difficulty+=list(diffi)\n        x_test+=list(x_data)\n        xl_test+=list(xt)\n        yl_test+=list(yt)\n        wl_test+=list(wt)\n        hl_test+=list(ht)\n        Pcl_test+=list(ct)\n        Iobjl_test+=list(objt)\n        pred_c_test+=list(pc)\n        pred_x_test+=list(px)\n        pred_y_test+=list(py)\n        pred_w_test+=list(pw)\n        pred_h_test+=list(ph)\n        pred_class_test+=list(pclass)\n        count+=1\n        if(verbose):\n            print(\"test batch\",count,\"done\")\n    target_boxes=[]\n    total_boxes=np.sum(Iobjl_test[:test_size])\n    for i in range(test_size):\n        index=Iobjl_test[i]==1\n        tdiffi=difficulty[i][index]\n        x=xl_test[i][index]\n        y=yl_test[i][index]\n        w=wl_test[i][index]\n        h=hl_test[i][index]\n        t=[]\n        for j in range(len(x)):\n            ul=(x[j]-w[j]\/2,y[j]-h[j]\/2)\n            ur=(x[j]+w[j]\/2,y[j]-h[j]\/2)\n            dr=(x[j]+w[j]\/2,y[j]+h[j]\/2)\n            dl=(x[j]-w[j]\/2,y[j]+h[j]\/2)\n            t.append([ul,ur,dr,dl,tdiffi[j]])\n        target_boxes.append(t)\n    predict_boxes=[]\n    to_draw=[]\n    for i in range(test_size):\n        boxes=get_surppressed_boxes(i,pred_c_test[i],pred_x_test[i],pred_y_test[i],pred_w_test[i],pred_h_test[i],pred_class_test[i])\n        predict_boxes=predict_boxes+boxes\n        to_draw.append(boxes)\n    mAP,recall,precision=get_mAP(predict_boxes,target_boxes,total_boxes)\n    print(\"mAP:\",round(mAP,4),\"recall:\",round(recall,4),\"precision:\",round(precision,4))\n    for i in range(draw):\n        draw_box(x_test[i],to_draw[i])\n\n\n","12150e33":"gird_len=448\/S\nbatch_size=6\nlamda_noobj=0.5\nlamda_coord=5","8ef469f8":"weights.keys()","cd133d49":"class Augmentor:\n    def __init__(self):\n        pass\n    \n    def random_augment(self,rgb,boxes,labels):\n        img=self.RGB2BGR(rgb)\n        img,boxes = self.random_flip(img,boxes)\n        img,boxes = self.randomScale(img,boxes)\n        img = self.randomBlur(img)\n        img = self.RandomBrightness(img)\n        img = self.RandomHue(img)\n        img = self.RandomSaturation(img)\n        img,boxes,labels = self.randomShift(img,boxes,labels)\n        img,boxes,labels = self.randomCrop(img,boxes,labels)\n        rgb=self.BGR2RGB(img)\n        width=rgb.shape[0]\n        height=rgb.shape[1]\n        return rgb,boxes,labels\n    \n    \n    def BGR2RGB(self,img):\n        return cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n\n    def BGR2HSV(self,img):\n        return cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n\n    def HSV2BGR(self,img):\n        return cv2.cvtColor(img,cv2.COLOR_HSV2BGR)\n\n    def RGB2BGR(self,img):\n        return cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n\n    def random_flip(self, im, boxes):\n        if random.random() < 0.5:\n            im_lr = np.fliplr(im).copy()\n            h,w,_ = im.shape\n            xmin = w - boxes[:,2]\n            xmax = w - boxes[:,0]\n            boxes[:,0] = xmin\n            boxes[:,2] = xmax\n            return im_lr, boxes\n        return im, boxes\n\n    def randomScale(self,bgr,boxes):\n        if random.random() < 0.5:\n            scale = random.uniform(0.8,1.2)\n            height,width,c = bgr.shape\n            bgr = cv2.resize(bgr,(int(width*scale),height))\n            scale_boxes = [scale,1,scale,1]\n            boxes = boxes * scale_boxes\n            return bgr,boxes\n        return bgr,boxes\n\n    def randomBlur(self,bgr):\n        if random.random()<0.5:\n            bgr = cv2.blur(bgr,(5,5))\n        return bgr\n\n    def RandomBrightness(self,bgr):\n        if random.random() < 0.5:\n            hsv = self.BGR2HSV(bgr)\n            h,s,v = cv2.split(hsv)\n            adjust = random.choice([0.5,1.5])\n            v = v*adjust\n            v = np.clip(v, 0, 255).astype(hsv.dtype)\n            hsv = cv2.merge((h,s,v))\n            bgr = self.HSV2BGR(hsv)\n        return bgr\n\n    def RandomHue(self,bgr):\n        if random.random() < 0.5:\n            hsv = self.BGR2HSV(bgr)\n            h,s,v = cv2.split(hsv)\n            adjust = random.choice([0.5,1.5])\n            h = h*adjust\n            h = np.clip(h, 0, 255).astype(hsv.dtype)\n            hsv = cv2.merge((h,s,v))\n            bgr = self.HSV2BGR(hsv)\n        return bgr\n\n    def RandomSaturation(self,bgr):\n        if random.random() < 0.5:\n            hsv = self.BGR2HSV(bgr)\n            h,s,v = cv2.split(hsv)\n            adjust = random.choice([0.5,1.5])\n            s = s*adjust\n            s = np.clip(s, 0, 255).astype(hsv.dtype)\n            hsv = cv2.merge((h,s,v))\n            bgr = self.HSV2BGR(hsv)\n        return bgr\n\n    def randomShift(self,bgr,boxes,labels):\n        center = (boxes[:,2:]+boxes[:,:2])\/2\n        if random.random() <0.5:\n            height,width,c = bgr.shape\n            after_shfit_image = np.zeros((height,width,c),dtype=bgr.dtype)\n            after_shfit_image[:,:,:] = (104,117,123) #bgr\n            shift_x = random.uniform(-width*0.2,width*0.2)\n            shift_y = random.uniform(-height*0.2,height*0.2)\n            #print(bgr.shape,shift_x,shift_y)\n            if shift_x>=0 and shift_y>=0:\n                after_shfit_image[int(shift_y):,int(shift_x):,:] = bgr[:height-int(shift_y),:width-int(shift_x),:]\n            elif shift_x>=0 and shift_y<0:\n                after_shfit_image[:height+int(shift_y),int(shift_x):,:] = bgr[-int(shift_y):,:width-int(shift_x),:]\n            elif shift_x <0 and shift_y >=0:\n                after_shfit_image[int(shift_y):,:width+int(shift_x),:] = bgr[:height-int(shift_y),-int(shift_x):,:]\n            elif shift_x<0 and shift_y<0:\n                after_shfit_image[:height+int(shift_y),:width+int(shift_x),:] = bgr[-int(shift_y):,-int(shift_x):,:]\n\n            shift_xy = [int(shift_x),int(shift_y)]\n            center = center + shift_xy\n            mask1 = np.where((center[:,0]>0) & (center[:,0]<width))[0]\n            mask2 = np.where((center[:,1]>0) & (center[:,1]<height))[0]\n            mask = np.intersect1d(mask1,mask2)\n            boxes_in = boxes[mask]\n            if len(boxes_in) == 0:\n                return bgr,boxes,labels\n            box_shift = [int(shift_x),int(shift_y),int(shift_x),int(shift_y)]\n            boxes_in = boxes_in+box_shift\n            labels_in = labels[mask]\n            return after_shfit_image,boxes_in,labels_in\n        return bgr,boxes,labels\n\n    def randomCrop(self,bgr,boxes,labels):\n        if random.random() < 0.5:\n            center = (boxes[:,2:]+boxes[:,:2])\/2\n            height,width,c = bgr.shape\n            h = random.uniform(0.6*height,height)\n            w = random.uniform(0.6*width,width)\n            x = random.uniform(0,width-w)\n            y = random.uniform(0,height-h)\n            x,y,h,w = int(x),int(y),int(h),int(w)\n\n            center = center - [x,y]\n            mask1 = np.where((center[:,0]>0) & (center[:,0]<w))[0]\n            mask2 = np.where((center[:,1]>0) & (center[:,1]<h))[0]\n            mask = np.intersect1d(mask1,mask2)\n\n            boxes_in = boxes[mask]\n            if(len(boxes_in)==0):\n                return bgr,boxes,labels\n            box_shift = [x,y,x,y]\n\n            boxes_in = boxes_in - box_shift\n            boxes_in[:,0]=boxes_in[:,0].clip(min=0,max=w)\n            boxes_in[:,2]=boxes_in[:,2].clip(min=0,max=w)\n            boxes_in[:,1]=boxes_in[:,1].clip(min=0,max=h)\n            boxes_in[:,3]=boxes_in[:,3].clip(min=0,max=h)\n\n            labels_in = labels[mask]\n            img_croped = bgr[y:y+h,x:x+w,:]\n            return img_croped,boxes_in,labels_in\n        return bgr,boxes,labels\nia=Augmentor()\n","6b77ae3b":"class Data:\n    def __init__(self):\n        self.cur_batch=0\n        self.batch_size=32\n        self.test_size=1000\n        self.imgs=list(self.get_all_img())\n        self.train_max_batch=(len(self.imgs)-self.test_size)\/\/self.batch_size\n        self.classes=['motorbike', 'aeroplane', 'dog', 'pottedplant', 'bottle', 'person', 'sofa', 'tvmonitor', 'cow', 'cat', 'train', 'car', 'bird', 'bicycle', 'chair', 'diningtable', 'horse', 'bus', 'sheep', 'boat']               \n        self.cur_test_position=-self.test_size\n        \n    def to_labels(self,info):\n        height_ratio=448\/info[\"height\"]\n        width_ratio=448\/info[\"width\"]\n        Iobj=np.zeros([S,S])\n        Inoobj=np.ones([S,S])\n        Pc=np.zeros([S,S,num_class])\n        x=np.zeros([S,S])\n        y=np.zeros([S,S])\n        w=np.zeros([S,S])\n        h=np.zeros([S,S])\n        difficulty=np.zeros([S,S])\n        for i in range(info[\"total_bndbox\"]):\n            xmin=info[i][\"xmin\"]*width_ratio\n            xmax=info[i][\"xmax\"]*width_ratio\n            ymin=info[i][\"ymin\"]*height_ratio\n            ymax=info[i][\"ymax\"]*height_ratio\n            gird_len=448\/S\n            y_index=int((xmin+xmax)\/2\/\/gird_len)\n            x_index=int((ymin+ymax)\/2\/\/gird_len)\n            Iobj[x_index,y_index]=1\n            Inoobj[x_index,y_index]=0\n            Pc[x_index,y_index,self.classes.index(info[i][\"name\"])]=1\n            x[x_index,y_index]=(xmin+xmax)\/2\n            y[x_index,y_index]=(ymin+ymax)\/2\n            w[x_index,y_index]=xmax-xmin\n            h[x_index,y_index]=ymax-ymin\n            difficulty[x_index,y_index]=info[i][\"difficulty\"]\n\n        return [x,y,w,h,Pc,Iobj,Inoobj,difficulty]\n\n    def get_training_data(self,imgs,training=True):\n        x=[]\n        y=[]\n        for i in imgs:\n            image=self.get_img(i)\n            discreted=i[:-4].split(\"\/\")\n            xml_path=\"\/\".join(discreted[:-2])+\"\/Annotations\/\"+discreted[-1]+\".xml\"\n            dic=self.read(xml_path)\n            if(training==True):\n                boxes=[]\n                labels=[]\n                difficulty=[]\n                for j in range(dic[\"total_bndbox\"]):\n                    difficulty.append(dic[j][\"difficulty\"])\n                    boxes.append([dic[j][\"xmin\"],dic[j][\"ymin\"],dic[j][\"xmax\"],dic[j][\"ymax\"]])\n                    labels.append(dic[j][\"name\"])\n                boxes=np.array(boxes)    \n                labels=np.array(labels)\n                image,boxes,labels=ia.random_augment(image,boxes,labels)\n                dic={}\n                dic[\"width\"]=image.shape[1]\n                dic[\"height\"]=image.shape[0]\n                dic[\"total_bndbox\"]=len(boxes)\n                for j in range(len(boxes)):\n                    dic[j]={}\n                    dic[j][\"xmin\"]=boxes[j,0]\n                    dic[j][\"ymin\"]=boxes[j,1]\n                    dic[j][\"xmax\"]=boxes[j,2]\n                    dic[j][\"ymax\"]=boxes[j,3]\n                    dic[j][\"name\"]=labels[j]\n                    dic[j][\"difficulty\"]=difficulty[j]\n            image=cv2.resize(image,(448,448))\n            x.append(image)\n            y.append(dic)\n        x=np.array(x)\n        y=np.array(y)\n        difficulty=[]\n        xl=[]\n        yl=[]\n        wl=[]\n        hl=[]\n        Pcl=[]\n        Iobjl=[]\n        Inoobjl=[]\n        for i in y:\n            tx,ty,tw,th,tPc,tIobj,tInoobj,td=self.to_labels(i)\n            xl.append(tx)\n            yl.append(ty)\n            wl.append(tw)\n            hl.append(th)\n            Pcl.append(tPc)\n            Iobjl.append(tIobj)\n            Inoobjl.append(tInoobj)\n            difficulty.append(td)\n        x=np.array(x)    \n        xl=np.array(xl)\n        xl=np.expand_dims(xl,-1)\n        yl=np.array(yl)\n        yl=np.expand_dims(yl,-1)\n        wl=np.array(wl)\n        wl=np.expand_dims(wl,-1)\n        hl=np.array(hl)\n        hl=np.expand_dims(hl,-1)\n        Pcl=np.array(Pcl)\n        Iobjl=np.array(Iobjl)\n        Iobjl=np.expand_dims(Iobjl,-1)\n        Inoobjl=np.array(Inoobjl)\n        Inoobjl=np.expand_dims(Inoobjl,-1)\n        difficulty=np.expand_dims(difficulty,-1)\n        return x,xl,yl,wl,hl,Pcl,Iobjl,Inoobjl,difficulty\n    \n    def read(self,path):\n        tree = ET.parse(path)\n        root = tree.getroot()\n        dic={}\n        dic['filename']=root.find('filename').text\n        dic['width']=float(root.find('size').find('width').text)\n        dic['height']=float(root.find('size').find('height').text)\n        dic['depth']=float(root.find('size').find('depth').text)\n        count=0\n        for i in root.findall(\"object\"):\n            dic[count]={}\n            dic[count][\"name\"]=i.find(\"name\").text\n            dic[count][\"difficulty\"]=float(i.find(\"difficult\").text)\n            dic[count][\"xmin\"]=float(i.find(\"bndbox\").find(\"xmin\").text)\n            dic[count][\"ymin\"]=float(i.find(\"bndbox\").find(\"ymin\").text)\n            dic[count][\"xmax\"]=float(i.find(\"bndbox\").find(\"xmax\").text)\n            dic[count][\"ymax\"]=float(i.find(\"bndbox\").find(\"ymax\").text)\n            count+=1\n        dic[\"total_bndbox\"]=count\n        return dic\n    \n    def jpg_to_annotation(self,path):\n        return \"\/\".join(path.split(\"\/\")[:-2])+\"\/Annotations\/\"+path.split(\"\/\")[-1].split(\".\")[0]+\".xml\"\n    \n    def get_all_box(self):\n        all_box=[]\n        for i in [self.read(self.jpg_to_annotation(x)) for x in self.imgs ]:\n            for j in range(i[\"total_bndbox\"]):\n                all_box.append([i[j][\"xmin\"],i[j][\"ymin\"],i[j][\"xmax\"],i[j][\"ymax\"]])\n        return all_box\n    \n    def get_kmeans_centers(self):  # still under working ...\n        all_box=self.get_all_box()\n        \n    \n    def show_img(self,path):\n        name=path.split(\".\")[0]\n        dic=read(name+'.xml')\n        img=get_img(path)\n        img=cv2.resize(img,(448,448))\n        im=Image.fromarray(img)\n        d = ImageDraw.Draw(im)\n        height_ratio=448\/dic[\"height\"]\n        width_ratio=448\/dic[\"width\"]\n        for i in range(dic['total_bndbox']):\n            top_l=(int(dic[i][\"xmin\"]*width_ratio),int(dic[i][\"ymin\"]*height_ratio))\n            top_r=(int(dic[i][\"xmax\"]*width_ratio),int(dic[i][\"ymin\"]*height_ratio))\n            bottom_r=(int(dic[i][\"xmax\"]*width_ratio),int(dic[i][\"ymax\"]*height_ratio))\n            bottom_l=(int(dic[i][\"xmin\"]*width_ratio),int(dic[i][\"ymax\"]*height_ratio))\n            d.line([top_l,top_r,bottom_r,bottom_l,top_l],width=2, fill=(0, 0, 255))\n            print(dic[i][\"name\"])\n        display(im)\n\n    def get_all_img(self):\n        voc2012=['..\/input\/voc-20\/voc\/JPEGImages\/'+x for x in os.listdir('..\/input\/voc-20\/voc\/JPEGImages')]\n        voc2007_test=[\"..\/input\/voctest\/voctest\/voctest\/VOC2007\/JPEGImages\/\"+x for x in os.listdir(\"..\/input\/voctest\/voctest\/voctest\/VOC2007\/JPEGImages\")]   \n        voc2012_test=[\"..\/input\/voctest\/voctest\/voctest\/VOC2012\/JPEGImages\/\"+x for x in os.listdir(\"..\/input\/voctest\/voctest\/voctest\/VOC2012\/JPEGImages\")]\n        annotated_2012=[x.split(\".\")[0] for x in os.listdir(\"..\/input\/voctest\/voctest\/voctest\/VOC2012\/Annotations\/\")]\n        voc2012_test=[x for x in voc2012_test if x.split(\".\")[0] in annotated_2012]\n        img_path=\"..\/input\/voc2007\/voctrainval_06-nov-2007\/VOCdevkit\/VOC2007\/JPEGImages\/\"\n        voc2007=[img_path+x for x in os.listdir(img_path)]\n        return voc2012_test+voc2007_test+voc2007+voc2012\n\n    def get_img(self,path):\n        img=Image.open(path)\n        return np.asarray(img)\n\n    def get_batch(self):\n        t=self.get_training_data(self.imgs[self.cur_batch*self.batch_size:(self.cur_batch+1)*self.batch_size])\n        self.cur_batch+=1\n        if(self.cur_batch>self.train_max_batch):\n            self.cur_batch=0\n            self.imgs=list(np.random.permutation(self.imgs[:-self.test_size]))+self.imgs[-self.test_size:]\n            print(\"data permutated.\")\n        return t[:-1]\n    \n    def get_test_data(self):\n        if(self.cur_test_position+self.batch_size>0):\n            data=self.get_training_data(self.imgs[self.cur_test_position:],False)\n            self.cur_test_position=-self.test_size\n            return [True]+list(data)\n        else:\n            data=self.get_training_data(self.imgs[self.cur_test_position:self.cur_test_position+self.batch_size],False)\n            self.cur_test_position=self.cur_test_position+self.batch_size\n            return [False]+list(data)\n    \ndata=Data()\n","05970c9f":"# all_box=data.get_all_box()","dc61d5cd":"# def to_four_point(box):\n#     p1=(box[0],box[1])\n#     p2=(box[2],box[1])\n#     p3=(box[2],box[3])\n#     p4=(box[0],box[3])\n#     return [p1,p2,p3,p4]\n\n# def box_distance(b1,b2):\n#     return 1-get_iou(to_four_point(b1),to_four_point(b2),True)\n\n# def nearest_idnex(centers,box):\n#     l=[]\n#     for i in centers:\n#         l.append(box_distance(i,box))\n#     return np.argmin(l)\n    \n# def update_centers(dic):\n#     centers=[]\n#     for i in range(len(dic)):\n#         centers.append(np.mean(np.array(dic[i]),axis=0))\n#     return centers\n\n# def converge(old_dic,dic):\n#     if(dic=={} or old_dic=={}):\n#         return False\n#     for i in range(len(old_dic)):\n#         if(old_dic[i]!=dic[i]):\n#             return False\n#     return True\n\n# def show_mean_distance(centers,dic):\n#     l=[]\n#     for i in range(len(centers)):\n#         l+=[box_distance(centers[i],x) for x in dic[i]]\n#     print(np.mean(l))\n#     return np.mean(l)\n    \n# k=5\n# centers=[all_box[i] for i in [random.randint(0,len(all_box)) for _ in range(k)]]\n# print(centers)\n# old_dic={}\n# dic={}\n# while(not converge(old_dic,dic)):\n#     old_dic=dic\n#     dic={}\n#     for i in all_box:\n#         nearest=nearest_idnex(centers,i)\n#         if(nearest not in dic):\n#             dic[nearest]=[i]\n#         else:\n#             dic[nearest].append(i)\n#     show_mean_distance(centers,dic)\n#     centers=update_centers(dic)\n\n# print(\"kmeans converged.\")   \n# print(centers)\n","1b30f18e":"centers=[[215.6126658274426, 144.65595042122592, 270.81204609276654, 207.6478164036022], [280.16559265768404, 136.89650458894747, 355.24116383518844, 245.18472954501075], [109.12977570294055, 109.97763468559577, 326.26497102382484, 319.9967535951921], [357.63335059554635, 133.55598135680995, 461.4141895390989, 274.65271879855], [31.5594572074753, 146.65742173550768, 114.98738245446971, 278.0221402214022]]                   \ncenters=np.array(centers)\nprint(centers)\ncenters_w=(centers[:,2]-centers[:,0])\/img_width\ncenters_h=(centers[:,3]-centers[:,1])\/img_height\ncenters_ratio=centers_h\/centers_w\ncenters_ratio","9d21f585":"# image=np.asarray(Image.open(data.imgs[3]))\n# draw_box(image,[[1]+to_four_point(x) for x in centers])","4e9c0b81":"def conv(x,size,filters,name,strides=1,padding=\"SAME\",activation=\"relu\"):\n    in_channels=x.shape[3].value\n    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n        if(weights!=None and name in weights.keys()):\n            kernels=tf.Variable(weights[name][0])\n            bias=tf.Variable(weights[name][1])\n            print(name)\n        else:\n            kernels=tf.get_variable(shape=[size,size,in_channels,filters],initializer=tf.initializers.variance_scaling(scale=2),name=\"kernels\")\n            bias=tf.get_variable(shape=[filters],initializer=tf.initializers.variance_scaling(scale=2),name=\"bias\")\n    x=tf.nn.conv2d(x,kernels,padding=padding,strides=[1,strides,strides,1])\n    x=tf.nn.bias_add(x,bias,data_format=\"NHWC\")\n    if(activation==\"relu\"):\n        x=tf.nn.relu(x)\n    return x\n\n\ndef det_conv(x,size,filters,name,activation=\"relu\"):\n    in_channels=x.shape[3].value\n    ident=tf.identity(x)\n    with tf.variable_scope(name+\"_1\", reuse=tf.AUTO_REUSE):\n        kernels1=tf.get_variable(shape=[size,size,in_channels,filters],initializer=tf.initializers.variance_scaling(scale=2),name=\"kernels1\")\n        bias1=tf.get_variable(shape=[filters],initializer=tf.initializers.variance_scaling(scale=2),name=\"bias1\")\n        x=tf.nn.conv2d(x,kernels1,[1,1,1,1],padding=\"SAME\")\n        x=tf.nn.bias_add(x,bias1)\n        x=tf.layers.batch_normalization(x,training=cur_mode)\n        \n        kernels2=tf.get_variable(shape=[size,size,filters,filters],initializer=tf.initializers.variance_scaling(scale=2),name=\"kernels2\")\n        bias2=tf.get_variable(shape=[filters],initializer=tf.initializers.variance_scaling(scale=2),name=\"bias2\")\n        x=tf.nn.conv2d(x,kernels2,[1,1,1,1],padding=\"SAME\")\n        x=tf.nn.bias_add(x,bias2)\n        x=tf.layers.batch_normalization(x,training=cur_mode)\n        if(in_channels!=filters):\n            kernels3=tf.get_variable(shape=[size,size,in_channels,filters],initializer=tf.initializers.variance_scaling(scale=2),name=\"kernels3\")\n            bias3=tf.get_variable(shape=[filters],initializer=tf.initializers.variance_scaling(scale=2),name=\"bias3\")\n            ident=tf.nn.conv2d(ident,kernels3,[1,1,1,1],padding=\"SAME\")\n            ident=tf.nn.bias_add(ident,bias3)\n            ident=tf.layers.batch_normalization(ident,training=cur_mode)\n        out=tf.nn.relu(x+ident) if activation==\"relu\" else x+ident\n    return out\n        \n\ndef fc(x,size,name,activation=\"relu\"):\n    in_channels=x.shape[-1].value\n    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n        W=tf.get_variable(initializer=tf.random.truncated_normal([in_channels,size], 0,0.0001), dtype=tf.float32, name=\"weight\")\n        bias=tf.get_variable(initializer=tf.random.truncated_normal([size],0,0.0001), dtype=tf.float32, name=\"bias\")\n    x=tf.matmul(x,W)\n    x=tf.nn.bias_add(x,bias)\n    if(activation==\"relu\"):\n        x=tf.nn.leaky_relu(x,0.1)\n    elif(activation==\"sigmoid\"):\n        x=tf.nn.sigmoid(x)\n    return x\n\ndef flatten(x):\n    return tf.layers.flatten(x)\n\ndef max_pool(x,size,strides,name,padding=\"VALID\"):\n    return tf.nn.max_pool(x,[1,size,size,1],strides=[1,strides,strides,1],padding=padding,name=name)\n\ndef avg_pool(x,size,strides,name,padding=\"VALID\"):\n    return tf.nn.avg_pool(x,[1,size,size,1],strides=[1,strides,strides,1],padding=padding,name=name)\n\ndef reduce(x):\n    return tf.reduce_mean(x,3)\n\n\ntf.reset_default_graph()\n\n\ncur_mode=tf.placeholder(tf.bool,shape=None)\ninput_=tf.placeholder(tf.float32,shape=(None,448,448,3))\nx_cor=tf.placeholder(tf.float32,shape=(None,S,S,1))\ny_cor=tf.placeholder(tf.float32,shape=(None,S,S,1))\nheight=tf.placeholder(tf.float32,shape=(None,S,S,1))\nwidth=tf.placeholder(tf.float32,shape=(None,S,S,1))\nclass_label=tf.placeholder(tf.float32,shape=(None,S,S,num_class))\nIobj=tf.placeholder(tf.float32,shape=(None,S,S,1))\nInoobj=tf.placeholder(tf.float32,shape=(None,S,S,1))\ntreshold=tf.placeholder(tf.float32,shape=None)\n\nprint(input_.shape)\nx=input_\/255\nx=conv(x,3,64,\"conv1_1\")\nx=conv(x,3,64,\"conv1_2\")\nx=max_pool(x,2,2,\"max_pool1\")\n\nx=conv(x,3,128,\"conv2_1\")\nx=conv(x,3,128,\"conv2_2\")\nx=max_pool(x,2,2,\"max_pool2\")\n\nx=conv(x,3,256,\"conv3_1\")\nx=conv(x,3,256,\"conv3_2\")\nx=conv(x,3,256,\"conv3_3\")\nx=max_pool(x,2,2,\"max_pool3\")\n\nx=conv(x,3,512,\"conv4_1\")\nx=conv(x,3,512,\"conv4_2\")\nx=conv(x,3,512,\"conv4_3\")\nx=max_pool(x,2,2,\"max_pool4\")\n\nx=conv(x,3,512,\"conv5_1\")\nx=conv(x,3,512,\"conv5_2\")\nx=conv(x,3,512,\"conv5_3\")\nident=tf.reshape(x,[-1,x.shape[1].value\/\/2,x.shape[1].value\/\/2,x.shape[3].value*4])\nx=max_pool(x,2,2,\"max_pool5\")\nprint(x.shape)\n\nprint(ident.shape)\nx=det_conv(x,3,256,\"det1\")\nx=det_conv(x,3,256,\"det2\")\nx=det_conv(x,3,256,\"det3\")\nx=tf.concat([x,ident],-1)\nprint(\"conv end:\",x.shape)\nx=conv(x,3,25*B,\"det4\",activation=None)\n# x=tf.nn.sigmoid(x)\nprint(\"end\",x.shape)\n\nallx=tf.nn.sigmoid(x[:,:,:,0:B])\nally=tf.nn.sigmoid(x[:,:,:,B:B*2])\nallw=tf.exp(x[:,:,:,B*2:B*3])*centers_w\nallh=tf.exp(x[:,:,:,B*3:B*4])*centers_h\nallc=tf.nn.sigmoid(x[:,:,:,B*4:B*5])\npred_class=tf.concat([tf.nn.softmax(x[:,:,:,B*5+i*20:B*5+(i+1)*20]) for i in range(5)],axis=-1)\nprint(\"class shape\",pred_class)\n\nx_cor_p=x_cor%gird_len\/gird_len  # x_cor is the raw x from the xml file\ny_cor_p=y_cor%gird_len\/gird_len\nwidth_p=width\/448\nheight_p=height\/448\n\n\ncell_x=tf.reshape(tf.cast(tf.tile(tf.range(S),[S]),tf.float32)*gird_len,[1,S,S,1]) # calculate each gird's upper left locatin\ncell_y=tf.transpose(cell_x,[0,2,1,3])\n\npred_x=allx*gird_len+cell_x    # allx is in range 0-1 and is relative to each gird's upper left point\npred_y=ally*gird_len+cell_y\npred_w=allw*img_width          # allw is relative to the image width\npred_h=allh*img_height\n\npred_l_x=pred_x-pred_w\/2\ntrue_l_x=x_cor-width\/2\npred_r_x=pred_x+pred_w\/2\ntrue_r_x=x_cor+width\/2\nunion_w=tf.maximum(tf.minimum(pred_r_x,true_r_x)-tf.maximum(pred_l_x,true_l_x),0)\n\npred_u_h=pred_y-pred_h\/2\ntrue_u_h=y_cor-height\/2\npred_d_h=pred_y+pred_h\/2\ntrue_d_h=y_cor+height\/2\nunion_h=tf.maximum(tf.minimum(pred_d_h,true_d_h)-tf.maximum(pred_u_h,true_u_h),0)\n\npred_area=pred_w*pred_h\ntrue_area=width*height\nunion_area=union_w*union_h\niou=union_area\/(pred_area+true_area-union_area)\n\nobj_mask=tf.tile(tf.cast(Iobj,tf.bool),[1,1,1,B])   # [batch_size,S,S,B], matrix denote which gird exits object\nnoobj_mask=tf.tile(tf.cast(Inoobj,tf.bool),[1,1,1,B]) # inverse of obj_mask\n\ntrue_x=tf.boolean_mask(tf.tile(x_cor_p,[1,1,1,B]),obj_mask)   # Sliced target x,y,w,h in girds that exists object\ntrue_y=tf.boolean_mask(tf.tile(y_cor_p,[1,1,1,B]),obj_mask)\ntrue_w=tf.boolean_mask(tf.tile(width_p,[1,1,1,B]),obj_mask)\ntrue_h=tf.boolean_mask(tf.tile(height_p,[1,1,1,B]),obj_mask)\n\nobj_x=tf.boolean_mask(allx,obj_mask)   # Sliced prediction x,y,w,h in girds that exists object\nobj_y=tf.boolean_mask(ally,obj_mask)\nobj_w=tf.boolean_mask(allw,obj_mask)\nobj_h=tf.boolean_mask(allh,obj_mask)\n\nobj_class=tf.boolean_mask(pred_class,tf.cast(tf.tile(Iobj,[1,1,1,20*B]),tf.bool))  # Sliced prediction class in girds that exists object\ntrue_class=tf.boolean_mask(tf.tile(class_label,[1,1,1,B]),tf.cast(tf.tile(Iobj,[1,1,1,20*B]),tf.bool)) # Sliced target class in girds that exists object\n\nmax_iou=tf.cast(tf.equal(iou,tf.reduce_max(iou,-1,True)),tf.float32)\n\nobj_confi=tf.boolean_mask(allc,obj_mask)\n# true_confi=tf.boolean_mask(max_iou,obj_mask)  # iou as target confidoence. Sliced prediction iou in girds that exists object\ncontain_target=tf.boolean_mask(tf.tile(Iobj,[1,1,1,B]),obj_mask) # 1 as target confidoence\n\nnoobj_confi=tf.boolean_mask(allc,noobj_mask)\ntrue_noobj_confi=tf.boolean_mask(tf.tile(Iobj,[1,1,1,B]),noobj_mask) # when no object, 0 as target confidience\n\nobj_loss=tf.reduce_sum(tf.square(obj_confi-contain_target))   # Predicted cofidience fit toward iou when object exits in the gird\nnoobj_loss=tf.reduce_sum(tf.square(noobj_confi-true_noobj_confi)) # Predicted cofidience fit toward 0 when no object exits\n\ncoord_loss=tf.reduce_sum(tf.square(obj_x-true_x)+tf.square(obj_y-true_y)) # x,y loss\nbox_loss=tf.reduce_sum(tf.square(tf.sqrt(obj_h)-tf.sqrt(true_h))+tf.square(tf.sqrt(obj_w)-tf.sqrt(true_w))) # w,h loss\nclass_loss=tf.reduce_sum(tf.square(obj_class-true_class)) # class loss\n\n\navg_obj_loss=obj_loss\/tf.reduce_sum(Iobj)   # Averaging losses\navg_noobj_loss=noobj_loss\/tf.reduce_sum(Inoobj)\navg_coord_loss=coord_loss\/tf.reduce_sum(Iobj)\navg_box_loss=box_loss\/tf.reduce_sum(Iobj)\navg_class_loss=class_loss\/tf.reduce_sum(Iobj)\n\n# var_list=[]\nvar_list=tf.get_collection('trainable_variables')\nall_variable=tf.all_variables()\n\nregularization=tf.add_n([tf.nn.l2_loss(i) for i in var_list if \"batch_normalization\" not in i.name])*5e-4   # regularization term for all the trainnable variables\n\nloss=obj_loss+0.5*noobj_loss+5*coord_loss+5*box_loss+class_loss+regularization\n","4eec8e52":"\nsaver=tf.train.Saver()\nsess=tf.Session()\ninit=tf.global_variables_initializer()\nsess.run(init)\n\n\ncur_lr=0.0001\nlr=tf.placeholder_with_default(cur_lr,shape=None)\n\n\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) # For updating batchnormalization's mean and variance\nupdate=[]\nwith tf.control_dependencies(update_ops):   # update batchnormalization's mean and variance before calculaing the gradient\n    grads=tuple(tf.gradients(loss,var_list,name=\"gradients\"))\n\n    \nold_grads=[]   # For momentum optimization\nnew_grads=[]\nfor i in grads:\n    old_grads.append(tf.placeholder(tf.float32,i.shape))\n    new_grads.append(tf.placeholder(tf.float32,i.shape))\nold_grads=tuple(old_grads)\nnew_grads=tuple(new_grads)\nclipped_old_grad =[tf.clip_by_value(x,-1,1) for x in old_grads]  # Gradient clipping\nclipped_grad =[tf.clip_by_value(x,-1,1) for x in new_grads]\nfor i,v in enumerate(var_list):\n    weighted_grad=0.9*clipped_old_grad[i]+0.1*clipped_grad[i]  # Momentum optimization\n    update.append(tf.assign(v,v-lr*weighted_grad))  # Apply gradient\n    \nmax_epoch=400000\nrestore_epoch=0\nepoch_loss_his=[]\nbatch_size=32\n\ndef save_weight(sess,path):  # Save all the variables in network and training context to npy file\n    np.save(path,sess.run(all_variable)+[cur_lr,e,epoch_loss,avg_obj_list,avg_noobj_list,coord_loss_list,box_loss_list,class_loss_list,last_grad])\n    print(\"all weight saved.\")\n    \ndef load_weight(sess,path):  # Restore all the variables in network and training context from npy file\n    all_weights=np.load(path,allow_pickle=True)\n    init_weight=[]\n    for i,v in enumerate(all_variable):\n        init_weight.append(tf.assign(v,all_weights[i]))\n    sess.run(init_weight)\n    print(\"all weight inited.\")\n    return all_weights[-9:]\n\n\n\n\n\n","266c5aae":"e=0\nepoch_loss=0\navg_obj_list=0\navg_noobj_list=0\ncoord_loss_list=0\nbox_loss_list=0\nclass_loss_list=0","02048076":"cur_lr,e,epoch_loss,avg_obj_list,avg_noobj_list,coord_loss_list,box_loss_list,class_loss_list,grad_values=load_weight(sess,\"..\/input\/weight62037\/all_weight62037.npy\")               \n","656687c7":"# cur_lr\/=10\n","4f1f142a":"print(cur_lr)","00c23cfb":"\nwhile(e<max_epoch):\n    \n    batch_x,batch_xl,batch_yl,batch_wl,batch_hl,batch_Pcl,batch_Iobjl,batch_Inoobjl=data.get_batch()\n    if(e>=1):\n        last_grad=grad_values\n    grad_values=sess.run(grads,feed_dict={input_:batch_x,\\\n                                          x_cor:batch_xl,\\\n                                          y_cor:batch_yl,\\\n                                          width:batch_wl,\\\n                                          height:batch_hl,\\\n                                          class_label:batch_Pcl,\\\n                                          Iobj:batch_Iobjl,\\\n                                          Inoobj:batch_Inoobjl,\\\n                                          cur_mode:True\n                                         })\n    \n    lossv,avg_obj_lossv,avg_noobj_lossv,coord_lossv,box_lossv,class_lossv=sess.run([loss,avg_obj_loss,avg_noobj_loss,avg_coord_loss,\\\n                                     avg_box_loss,avg_class_loss],feed_dict={input_:batch_x,\\\n                                          x_cor:batch_xl,\\\n                                          y_cor:batch_yl,\\\n                                          width:batch_wl,\\\n                                          height:batch_hl,\\\n                                          class_label:batch_Pcl,\\\n                                          Iobj:batch_Iobjl,\\\n                                          Inoobj:batch_Inoobjl,\\\n                                          cur_mode:True\n                                         })\n    coord_loss_list+=coord_lossv\n    box_loss_list+=box_lossv\n    class_loss_list+=class_lossv\n    epoch_loss+=lossv\n    avg_obj_list+=avg_obj_lossv\n    avg_noobj_list+=avg_noobj_lossv\n    if(e>=1):\n#         sess.run(old_grads,feed_dict={old_grads:last_grad})\n        sess.run(update,feed_dict={old_grads:last_grad,new_grads:grad_values,lr:cur_lr,cur_mode:False})\n    if(e%10==0):\n        print(\"epoch %-6.2f\"%round(e\/data.train_max_batch,2),\\\n              \"%-10.4f\"%round(epoch_loss\/(e+1),4),\\\n              \"avg obj loss:%-10.4f\"%round(avg_obj_list\/(e+1),4),\\\n              \"avg noobj loss:%-10.4f\"%round(avg_noobj_list\/(e+1),4)\\\n             ,\"avg coord loss:%-10.4f\"%round(coord_loss_list\/(e+1),4)\\\n             ,\"avg box loss:%-10.4f\"%round(box_loss_list\/(e+1),4)\\\n             ,\"avg class loss:%-10.4f\"%round(class_loss_list\/(e+1),4))\n    epoch_loss_his.append(epoch_loss\/(e+1))\n    if(len(epoch_loss_his)>300):\n        epoch_loss_his=epoch_loss_his[-300:]\n        v1=(np.sum(epoch_loss_his[-300:-50])-np.max(epoch_loss_his[-300:-50])-np.min(epoch_loss_his[-300:-50]))\/13\n        v2=(np.sum(epoch_loss_his[-50:])-np.max(epoch_loss_his[-50:])-np.min(epoch_loss_his[-50:]))\/3\n        if(v1-v2<0.01):\n            cur_lr=cur_lr\/2\n            print(\"learning rate reduced to\",cur_lr)\n            epoch_loss_his=[]\n    if((time.time()-begin_time)\/3600>5):\n        save_weight(sess,\"all_weight\"+str(e)+\".npy\")\n        print(\"model saved in \"+str(e)+\" step.\")\n        print(\"current learning rate:\",cur_lr)\n        break\n    e+=1","19d81993":"do_test(sess,1000,30)","9714d6ff":"****\n**Data augmentation class, this class comes from https:\/\/github.com\/yxlijun\/tensorflow-yolov1**","8762ccdf":"**Data class, process data from xml and jpg files to desired arrays**","22673542":"**Build the VGG network**","7d229866":"**Display the priors got from the kmeans**","0644d985":"**Restore model and training context from the npy file. Comment below line will train from scrach, else it will train start from the npy weight file which can be downloaded from kaggle output**","223bf255":"**Kmeans clusters to get good prior of bounding boxes, this part still under working ...**"}}