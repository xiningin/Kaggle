{"cell_type":{"ef279dea":"code","d56a8e3b":"code","79cfb2ba":"code","231e9f23":"code","32685843":"code","e3df5956":"code","a27934dd":"code","746910e2":"code","26a6ef91":"code","b4f8f20a":"code","5f62508e":"code","7e9410e5":"code","87df236d":"code","45914287":"code","24646635":"code","0e6358c0":"code","b80264ac":"code","fdf2870d":"code","27445541":"code","2402e81b":"code","46775839":"code","efb8576b":"code","ca1bd1ca":"code","57ff4f6b":"code","9b3c3eca":"code","3d29f902":"code","1e531050":"code","797aa2a0":"code","6c0a76b8":"markdown","f2594844":"markdown","df21fd80":"markdown","e001d047":"markdown","ee077396":"markdown","c2745d51":"markdown","0dd40af3":"markdown","c6872bd0":"markdown","ccffc418":"markdown","4b742c21":"markdown","e8256715":"markdown","67a2f954":"markdown","c53541b3":"markdown","9efc0ff0":"markdown","8648773c":"markdown","8de68591":"markdown","af495d7c":"markdown","4598d35a":"markdown","791cd72f":"markdown"},"source":{"ef279dea":"import pandas as pd #we use this to load, read and transform the dataset\nimport numpy as np #we use this for statistical analysis\nimport matplotlib.pyplot as plt #we use this to visualize the dataset\nimport seaborn as sns #we use this to make countplots\nimport sklearn.metrics as sklm #This is to test the models","d56a8e3b":"#here we load the train data\ndata = pd.read_csv(r'\/kaggle\/input\/small-dataset-about-used-fiat-500-sold-in-italy\/Used_fiat_500_in_Italy_dataset.csv')\n\n#and immediately I would like to see how this dataset looks like\ndata.head()","79cfb2ba":"#now let's look closer at the dataset we got\ndata.info()","231e9f23":"data.shape","32685843":"data.describe()","e3df5956":"#Let's see what the options are in the model column (the objects)\nprint(data['model'].unique())","a27934dd":"#Let's see what the options are in the transmission column (the objects)\nprint(data['transmission'].unique())","746910e2":"#Now let's try a histogram\nplt.hist(data['price'])","26a6ef91":"#Now we will try a Box & Wiskers plot\nplt.boxplot(data['price'])","b4f8f20a":"outliers = data[data['price'] > 14000]\noutliers.head()","5f62508e":"#first let's set the model column as categorical\ndata['model'] = data['model'].astype('category')\ndata.info()","7e9410e5":"#next let's plot per category how the data distribution looks like\nmodels = list(data['model'])\nvalues = list(data['price'])\n\nfig, axs = plt.subplots(1, 2, figsize=(9,4), sharey=True)\naxs[0].bar(models, values)\naxs[1].scatter(models, values)\nfig.suptitle('Categorical Plotting')","87df236d":"#Make a countplot to see how many models are sold\ncountplt, ax = plt.subplots(figsize = (10,7))\nax =sns.countplot(x = 'model', data=data)","45914287":"star = data[data['model'] == 'star']\nstar.head()","24646635":"#the only two columns that are not numeric are 'model' and ' transmission'.\n#to show how we have changed the values, let's encode this manually\nmodel_dict = {'pop':4, 'lounge':3, 'sport':2, 'star':1}\ndata['model'].replace(model_dict, inplace=True)\ndata.info()","0e6358c0":"#the only two columns that are not numeric are 'model' and ' transmission'.\n#to show how we have changed the values, let's encode this manually\ntrans_dict = {'manual':1, 'automatic':2}\ndata['transmission'].replace(trans_dict, inplace=True)\ndata.info()","b80264ac":"#First we need to split the dataset in the y-column (the target) and the components (X), the independent columns. \n#This is needed as we need to use the X columns to predict the y in the model. \n\ny = data['price'] #the column we want to predict \nX = data.drop(labels = ['price'], axis = 1)  #independent columns ","fdf2870d":"#as Longitude and latitude are features which need to be combined to have an influence, we will drop them for now. \nX = X.drop(labels = ['lon', 'lat'], axis =1)","27445541":"#TEST 1 - ExtraTreesClassifier - GOOD IF YOU USE DECISION TREE MODELS\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nmodel = ExtraTreesClassifier()\nmodel.fit(X,y)\nprint(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns).sort_values()\nfeat_importances.nlargest(10).plot(kind='barh')\nplt.show()","2402e81b":"#TEST 2 - SelectKBest - GOOD IF YOU USE A K-NEAREST NEIGHBOR MODEL\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\n#apply SelectKBest class to extract top 10 best features\nbestfeatures = SelectKBest(score_func=chi2, k='all')\nfit = bestfeatures.fit(X,y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\n#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Name of the column','Score']  #naming the dataframe columns\nprint(featureScores.nlargest(10,'Score'))  #print 10 best features","46775839":"#TEST 3 - Correlations - Linear and logistic regression like correlated data to have a good prediction\n#get correlations of each features in dataset\ncorrmat = data.drop(labels =['lon', 'lat'], axis = 1) #this is because it is the original target column and therefore has a high correlation with our percentage column\ncorrmat = corrmat.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(10,10))\n\n#plot heat map\ng=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","efb8576b":"#let's keep all features for now. ","ca1bd1ca":"#Load the chosen model here\nfrom sklearn.linear_model import LinearRegression","57ff4f6b":"from sklearn.model_selection import train_test_split\n\n#First try with all features\n\n#I want to withhold 35 % of the trainset to perform the tests\nX_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.35 , random_state = 25)","9b3c3eca":"print('Shape of X_train is: ', X_train.shape)\nprint('Shape of X_test is: ', X_test.shape)\nprint('Shape of Y_train is: ', y_train.shape)\nprint('Shape of y_test is: ', y_test.shape)","3d29f902":"#To check the model, I want to build a check:\nimport math\ndef print_metrics(y_true, y_predicted, n_parameters):\n    ## First compute R^2 and the adjusted R^2\n    r2 = sklm.r2_score(y_true, y_predicted)\n    r2_adj = r2 - (n_parameters - 1)\/(y_true.shape[0] - n_parameters) * (1 - r2)\n    \n    ## Print the usual metrics and the R^2 values\n    print('Mean Square Error      = ' + str(sklm.mean_squared_error(y_true, y_predicted)))\n    print('Root Mean Square Error = ' + str(math.sqrt(sklm.mean_squared_error(y_true, y_predicted))))\n    print('Mean Absolute Error    = ' + str(sklm.mean_absolute_error(y_true, y_predicted)))\n    print('Median Absolute Error  = ' + str(sklm.median_absolute_error(y_true, y_predicted)))\n    print('R^2                    = ' + str(r2))\n    print('Adjusted R^2           = ' + str(r2_adj)) #This is the number we will be focussing on. \n    #A good model would have an adjusted R2 of >70%, a bad model below this. \n    ","1e531050":"# Linear regression model\nmodel = LinearRegression() \nmodel.fit(X_train, y_train)","797aa2a0":"#Now let's see how this model performs\nPredictions = model.predict(X_test)\nprint_metrics(y_test, Predictions, 6)","6c0a76b8":"<img src=\"https:\/\/cdn.pixabay.com\/photo\/2017\/09\/05\/08\/55\/isolated-2716838_960_720.png\" alt=\"Fiat500\" width=\"200\"\/>","f2594844":"# 1. Import the important libraries \/ packages\nThese packages are needed to load and use the dataset","df21fd80":"# 2. Explore the dataset","e001d047":"# Predicting Fiat500 used car prices","ee077396":"# Conclusion\n\nAs you can see here, we have an adjusted R2 of 79%, so this model is not bad to predict the prices. ","c2745d51":"You can see an outlier around 16.000 euro. Let's look closer at this outlier","0dd40af3":"## 5c. Fit and check the Linear regression model","c6872bd0":"This price is for a pop model, let's look more closely to the price range per model type","ccffc418":"# The problem\nIn this notebook we look at the data we got via this [Kaggle competition](https:\/\/www.kaggle.com\/paolocons\/small-dataset-about-used-fiat-500-sold-in-italy). \n\nWe will see if we can predict the sales price of a used Fiat 500 car. \n\nWe will explore the dataset given, check the various features we have and we will make an algorithm that can predict the sales price of the car.","4b742c21":"Looks like lounge is the most sold type of model and there is only one star model in this dataset.\nLet's look into this star model more closely.","e8256715":"Seems that Age in days and km have a strong negative relationship to the price of the car, which is very logical, as the older the car, the less it's worth. \n\nAlso age and km have a strong positive relationship, which is also logical, as the older the car the more likely it has ran more km. ","67a2f954":"Before we are going to use the models choosen, we will first split the dataset in a train and test set.\nThis because we want to test the performance of the model on the training set and to be able to check it's accuracy. ","c53541b3":"# 5. Machine learning Model\nAs we would like to predict a continuous number, the price, we would use a Linear Regression model here. ","9efc0ff0":"# 3. Make all columns numeric\nWe need to make all column input numeric to use them further on. \nThis is what we will do now. ","8648773c":"## Price in the dataset\nAs this is the column we would like to predict, let's look closer to this column.","8de68591":"There is indeed only one star model in this dataset. ","af495d7c":"# 4. Most important features\nLet's continue by looking at the most important features according to three different tests. \nThan we will use the top ones to train and test our first model. ","4598d35a":"## 5a. Split the dataset in train and test","791cd72f":"## 5b. Make a check for the model"}}