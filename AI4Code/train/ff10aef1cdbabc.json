{"cell_type":{"561bbb82":"code","5bc3716e":"code","b2a46b77":"code","6f30dfda":"code","edf66e71":"code","242ccac8":"code","3f4a4673":"code","2bdedc4c":"code","092c1620":"code","1c4b6df7":"code","80c620a3":"code","ac9f65a6":"code","821e7b00":"code","f34410da":"code","b5365410":"code","3add4b77":"code","2eac8b78":"code","ec58db23":"code","9ac9da20":"markdown","b894f7da":"markdown","c7c56fd6":"markdown","af6f6589":"markdown","84532a1c":"markdown"},"source":{"561bbb82":"!pip install ..\/input\/fastai2-offline\/timm-0.2.1-py3-none-any.whl ..\/input\/fastai2-offline\/wwf-0.0.3-py3-none-any.whl -q","5bc3716e":"import pandas as pd\nfrom fastai.vision.all import *\nfrom wwf.vision.timm import *\n\nimport os","b2a46b77":"set_seed(42, reproducible=True)","6f30dfda":"path = Path('..\/input\/ranzcr-clip-catheter-line-classification')","edf66e71":"train_df = pd.read_csv(path\/'train.csv')\ntrain_df","242ccac8":"# Image.open(path\/'train'\/(train_df['StudyInstanceUID'][0]+'.jpg'))","3f4a4673":"columns = list(train_df.columns[1:12])","2bdedc4c":"def get_x(r):\n    return path\/'train'\/(r['StudyInstanceUID']+'.jpg')\n\ndef get_y(r):\n    return r[columns].values.tolist()\n\ndef get_data(size=224,bs=128,data_df=train_df):\n    dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock(encoded=True,vocab=columns)),\n                       splitter=RandomSplitter(seed=42),\n                       get_x=get_x, \n                       get_y=get_y,\n                       item_tfms = RandomResizedCrop(460, min_scale=0.75, ratio=(1.,1.)),\n                       batch_tfms = [*aug_transforms(size=size, max_warp=0),\n                                     Normalize.from_stats(*imagenet_stats)]\n                      )\n    return dblock.dataloaders(data_df,bs=bs)","092c1620":"dls = get_data()\ndls.show_batch()","1c4b6df7":"if not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n        os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n# !cp '..\/input\/resnet50\/resnet50.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/resnet50-19c8e357.pth'\n!cp '..\/input\/timm-pretrained-efficientnet\/efficientnet\/efficientnet_b0_ra-3dd342df.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/efficientnet_b0_ra-3dd342df.pth'","80c620a3":"# learn = cnn_learner(dls, resnet50, metrics=accuracy_multi).to_native_fp16()\nlearn = timm_learner(dls, 'efficientnet_b0',metrics=accuracy_multi).to_native_fp16()","ac9f65a6":"# learn.lr_find()","821e7b00":"learn.fine_tune(5, base_lr=3e-2)","f34410da":"learn = learn.to_native_fp32()","b5365410":"submission_df = pd.read_csv(path\/'sample_submission.csv')\nsubmission_df.iloc[:,1:] = submission_df.iloc[:,1:].astype(float)\nsubmission_df","3add4b77":"test_data_path = submission_df['StudyInstanceUID'].apply(lambda x: path\/'test'\/(x + '.jpg'))\ntst_dl = learn.dls.test_dl(test_data_path)\npreds,targs = learn.tta(dl = tst_dl,n=10, beta=0)","2eac8b78":"submission_df[columns] = pd.DataFrame(preds,columns=columns)\nsubmission_df","ec58db23":"submission_df.to_csv('submission.csv',index=False)","9ac9da20":"# Import Train Data","b894f7da":"# Setup Environment","c7c56fd6":"# Make Submission file","af6f6589":"# Create Dataloaders","84532a1c":"# Create learner"}}