{"cell_type":{"c6e5733e":"code","d1a020a8":"code","9f6d95c4":"code","84de7c52":"code","3ed2fb0e":"code","12ba72d3":"code","2b311b9f":"code","0f0bd886":"code","ca8b5df8":"code","cdfd623b":"code","6ab8562c":"code","35cad9cf":"code","1acd75ac":"code","e5ad64e1":"code","c0ea4e8a":"markdown","955c38f5":"markdown","7b2a44f7":"markdown","060e7f06":"markdown","0955797f":"markdown","331740a6":"markdown"},"source":{"c6e5733e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d1a020a8":"os.chdir('\/kaggle\/input\/support-ml-competition-online-news-classification')\ntrain = pd.read_csv('train.csv')\ntest  = pd.read_csv('test.csv')\nsample_submission = pd.read_csv('sample_submission.csv')","9f6d95c4":"\ntrain.drop('tag',axis=1,inplace = True)\ntest.drop(['tag','Id'],axis = 1,inplace = True)\n","84de7c52":"cols = train.columns\nmask = [True if ('LDA' in i)  else False for i in cols]\nfeature = cols[mask] \nX = train[feature]\nX.shape","3ed2fb0e":"cols = test.columns\nmask = [True if ('LDA' in i)  else False for i in cols]\nfeature = cols[mask]\nX_test = test[feature]\nX_test.shape\n   ","12ba72d3":"Y =  train['data_channel']\n","2b311b9f":"X = np.array(X)\nY = np.array(Y)\nY.shape[0]","0f0bd886":"classes =pd.unique(Y)\nclasses.sort()\nnumberOfClass = len(classes)\nprint(classes)\nprint(numberOfClass)","ca8b5df8":"def normalize(X):\n    X_nor = (X-np.average(X))\/np.std(X)\n    return X_nor","cdfd623b":"class mltiClassesClassification:\n    def __init__(self,X,Y,lr=1e-6,itrs = 50):\n        self.X = X\n        self.Y = self.encode__Y(Y)\n        self.lr = lr\n        self.itrs = itrs\n        self.theta = np.zeros((X.shape[1],numberOfClass))\n        self.bais = np.zeros((1,numberOfClass))\n        self.m = X.shape[0]\n        \n    \n    def encode__Y(self,Y):\n        \n        enc_Y = np.zeros((Y.shape[0],numberOfClass))\n        count = 0\n        \n        for i in classes:\n            enc_Y[:,count] = (Y==i).astype('int')\n            count+=1\n            \n        return enc_Y\n    \n    \n    def hyposises(self):\n        \n        z =  np.dot(self.X,self.theta) + self.bais\n        h = self.softMax(z)\n        \n        return h\n        \n    \n    def sigmoid(self,z):\n        \n        return (1\/ (1 + np.exp(-z)))\n    \n    \n    def softMax(self, z):\n        \n        exp = np.exp(z)\n        \n        return exp \/ np.sum(exp,axis=1, keepdims=True)\n    \n    \n    def costFun(self,h):\n        \n        first_calc = self.Y * np.log(h)\n        second_calc = (1 - self.Y) * np.log(1 - h)\n        final = (-1 \/ self.m) * np.sum(first_calc + second_calc)\n        \n        return final\n    \n    def fitTheta(self):\n        cost = list()\n        for i in range(self.itrs):\n            h = self.hyposises() \n            j = self.costFun(h)\n            if i % 100 == 0 :\n                print(i, end=' ------> ')\n                print(j)\n            gradient = (h - self.Y)\n            dT = np.dot((self.X).T, (gradient))\n            dB = np.sum(gradient)\n            self.theta -= self.lr * dT\n            self.bais -=  self.lr * dB\n        \n    \n    def predict(self,test):\n        z =  np.dot(test,self.theta)+self.bais\n        h = self.softMax(z)\n        y_cls = h.argmax(axis=1)\n                         \n        return y_cls\n    \n    ","6ab8562c":"#X = normalize(X)\n#X_test = normalize(X_test)\nlogstic = mltiClassesClassification(X,Y,0.1e-2,900)\nlogstic.fitTheta()\npti5 = logstic.predict(X_test)","35cad9cf":"def save_to_csv(y_pred): # The function should save the predicted value of (data_channel) to csv file as same as ( sample_submission format)\n    os.chdir('\/kaggle\/working')\n    df = pd.DataFrame({'Id':np.arange(1,y_pred.shape[0]+1),'data_channel':y_pred})\n    df.to_csv('output.csv',encoding = 'utf-8' , index = False)\n    print(df.shape)\n    pass","1acd75ac":"# theta , b,cost = fit_logistic_regression(X,Y,Theta,b)\n# pti5 = predict(test,Theta,b)\nprint(X_test.shape)","e5ad64e1":"save_to_csv(pti5)","c0ea4e8a":"# Default Kaggle Cell ","955c38f5":"![](http:\/\/miro.medium.com\/max\/292\/1*p4hYc2VwJqoLWwl_mV0Vjw.png)","7b2a44f7":"# Helper Functions ","060e7f06":"# Read Dataset","0955797f":"![](https:\/\/miro.medium.com\/max\/906\/1*FdxEs8Iv_43Q8calTCjnow.png)","331740a6":"# Split Data to X , Y "}}