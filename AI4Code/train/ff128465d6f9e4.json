{"cell_type":{"ded6ba2c":"code","23d5e67e":"code","94b84c5f":"code","0945f5d3":"code","8d3ade0d":"code","2dc5756e":"code","9339dc58":"code","e60f677f":"code","02cbe158":"code","7cc1f103":"code","c3c88b98":"code","1c1f1cc3":"code","a10d556d":"code","7910f1e4":"code","387b2d62":"code","0268b250":"code","c6f17469":"code","5e5cd948":"code","9e06c350":"code","f63a63be":"code","0b0537e0":"markdown","dec0717e":"markdown","05d362a1":"markdown","785c0e29":"markdown","d882e5f6":"markdown","2ac18d47":"markdown"},"source":{"ded6ba2c":"import numpy as np\nfrom skimage import io","23d5e67e":"image = np.random.randint(0, 10, (3, 5, 5))\nN = 2 # Number of Filters\nkernel = np.random.randint(0, 2, (N, 3, 3, 3))","94b84c5f":"def convolve2D(a, b, p=0, s=1):\n    # a --> Input\n    # b --> Kernel\n    # p --> Padding\n    # s --> Stride\n\n    # sizes of Input & Kernel\n    a_size = np.shape(a)\n    b_size = np.shape(b)\n\n    # initialization of output\n    c_size = (int(1 + (a_size[0] - b_size[0] + 2 * p) \/ s), int(1 + (a_size[1] - b_size[1] + 2 * p) \/ s))\n    c = np.zeros(c_size)\n\n    # Padding\n    if p != 0:\n        padded_image_size = (a_size[0] + p * 2, a_size[1] + p * 2)\n        padded_image = np.zeros(padded_image_size)\n\n        padded_image[p: -1 * p, p: -1 * p] = a\n    else:\n        padded_image = a\n\n    # Iterate through image\n    for y in range(a_size[1]):\n        # Exit Convolution\n        if y > a_size[1] - b_size[1]:\n            break\n        # Only Convolve if y has gone down by the specified Strides\n        if y % s == 0:\n            for x in range(a_size[0]):\n                # Go to next row once kernel is out of bounds\n                if x > a_size[0] - b_size[0]:\n                    break\n                try:\n                    # Only Convolve if x has moved by the specified Strides\n                    if x % s == 0:\n                        c[x, y] = (b * padded_image[x: x + b_size[0], y: y + b_size[1]]).sum()\n                except:\n                    break\n\n    return padded_image","0945f5d3":"def convolution_layer(a, b):\n    # n --> no of filters\n\n    a_size = np.shape(a) # Shape of image\n    b_size = np.shape(b) # Shape of filter\n\n    c_size = (b_size[0], a_size[2] - b_size[3] + 1, a_size[1] - b_size[2] + 1) # Shape of Fetaure map\n    c = np.zeros(c_size, dtype=int)\n\n    for k in range(b_size[0]):\n        for i in range(c_size[2]):\n            for j in range(c_size[1]):\n                c[k, i, j] = convolve2D(a[0, i:i + len(b), j:j + len(b)], b[k][0])[0][0] + \\\n                             convolve2D(a[1, i:i + len(b), j:j + len(b)], b[k][1])[0][0] + \\\n                             convolve2D(a[2, i:i + len(b), j:j + len(b)], b[k][2])[0][0]\n\n    return c","8d3ade0d":"feature_map = convolution_layer(image,kernel)\n\nprint(f\" Feature Map \\n {feature_map}\")\nprint(f\" Size of Feature Map is {np.shape(feature_map)}\")\n\n# (2,3,3) --> ( 3 x 3 x 2)\n\n","2dc5756e":"import numpy as np\nimport pandas as pd\nfrom scipy.spatial import distance as dist\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport seaborn as sns\nfrom tqdm import tqdm \nfrom sklearn.utils import shuffle\nfrom sklearn import decomposition\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport tensorflow as tf\nimport keras\nfrom keras.applications.vgg16 import VGG16 \nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.models import Sequential, Model \nfrom keras.initializers import he_normal\nfrom keras.layers import Lambda, SeparableConv2D, BatchNormalization, Dropout, MaxPooling2D, Input, Dense, Conv2D, Activation, Flatten \nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","9339dc58":"class_names = ['EOSINOPHIL', 'LYMPHOCYTE', 'MONOCYTE', 'NEUTROPHIL']\nnb_classes = len(class_names)\nimage_size = (120,120)","e60f677f":"def load_data():\n    \n    datasets = ['\/kaggle\/input\/blood-cells\/dataset2-master\/dataset2-master\/images\/TRAIN','\/kaggle\/input\/blood-cells\/dataset2-master\/dataset2-master\/images\/TEST']\n    images = []\n    labels = []\n\n    # iterate through training and test sets\n    count =0\n    for dataset in datasets:\n\n        # iterate through folders in each dataset\n        for folder in os.listdir(dataset):\n\n            if folder in ['EOSINOPHIL']: label = 0\n            elif folder in ['LYMPHOCYTE']: label = 1\n            elif folder in ['MONOCYTE']: label = 2\n            elif folder in ['NEUTROPHIL']: label = 3\n\n            # iterate through each image in folder\n            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n\n                # get pathname of each image\n                img_path = os.path.join(os.path.join(dataset, folder), file)\n\n                # Open \n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, image_size)\n\n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n\n    images = np.array(images, dtype = 'float32')\n    labels = np.array(labels, dtype = 'int32')\n\n    return images, labels","02cbe158":"images, labels = load_data()","7cc1f103":"images, labels = shuffle(images, labels, random_state=10)\n\ntrain_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size = 0.2)\ntest_images, val_images, test_labels, val_labels = train_test_split(test_images, test_labels, test_size = 0.5)","c3c88b98":"n_train = train_labels.shape[0]\nn_val = val_labels.shape[0]\nn_test = test_labels.shape[0]\n\nprint(\"Number of training examples: {}\".format(n_train))\nprint(\"Number of validation examples: {}\".format(n_val))\nprint(\"Number of testing examples: {}\".format(n_test))\n\nprint(\"Training images are of shape: {}\".format(train_images.shape))\nprint(\"Training labels are of shape: {}\".format(train_labels.shape))\nprint(\"Validation images are of shape: {}\".format(val_images.shape))\nprint(\"Validation labels are of shape: {}\".format(val_labels.shape))\nprint(\"Test images are of shape: {}\".format(test_images.shape))\nprint(\"Test labels are of shape: {}\".format(test_labels.shape))\n","1c1f1cc3":"train_images = train_images \/ 255.0 \nval_images = val_images \/ 255.0\ntest_images = test_images \/ 255.0","a10d556d":"model1 = Sequential()\n\n# First Conv Layer\nmodel1.add(Conv2D(16 , (3,3) , activation = 'relu' , input_shape = (120,120,3)))\nmodel1.add(MaxPooling2D(pool_size = (2,2)))\n\n# Second Conv Layer\nmodel1.add(Conv2D(32, (3,3), activation = 'relu'))\nmodel1.add(MaxPooling2D(pool_size = (2,2)))\nmodel1.add(Dropout(0.25))\n\n# Third Conv Layer\nmodel1.add(Conv2D(64, (3,3), activation = 'relu'))\nmodel1.add(MaxPooling2D(pool_size = (2,2)))\nmodel1.add(Dropout(0.25))\n\n# FC layer\nmodel1.add(Flatten())\nmodel1.add(Dense(units = 128 , activation = 'relu'))\nmodel1.add(Dropout(0.25))\n\n# Output layer\nmodel1.add(Dense(units = 4 , activation = 'softmax'))\n\n# Compile\nmodel1.compile(optimizer = \"adam\" , loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])\nmodel1.summary()\n\n# Train\nhistory1 = model1.fit(\n    train_images, \n    train_labels, \n    batch_size = 32, \n    epochs = 10, \n    validation_data=(val_images, val_labels))","7910f1e4":"def plot_accuracy_loss_chart(history):\n    epochs = [i for i in range(10)]\n    fig , ax = plt.subplots(1,2)\n    train_acc = history.history['accuracy']\n    train_loss = history.history['loss']\n    val_acc = history.history['val_accuracy']\n    val_loss = history.history['val_loss']\n    fig.set_size_inches(20,10)\n    ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n    ax[0].plot(epochs , val_acc , 'ro-' , label = 'Validation Accuracy')\n    ax[0].set_title('Training & Validation Accuracy')\n    ax[0].legend()\n    ax[0].set_xlabel(\"Epochs\")\n    ax[0].set_ylabel(\"Accuracy\")\n\n    ax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\n    ax[1].plot(epochs , val_loss , 'r-o' , label = 'Validation Loss')\n    ax[1].set_title('Training & Validation Loss')\n    ax[1].legend()\n    ax[1].set_xlabel(\"Epochs\")\n    ax[1].set_ylabel(\"Training & Validation Loss\")\n    plt.show()","387b2d62":"plot_accuracy_loss_chart(history1)","0268b250":"\nresults = model1.evaluate(test_images, test_labels)\n\nprint(\"Loss of the model  is - test \", results[0])\nprint(\"Accuracy of the model is - test\", results[1]*100, \"%\")\n\n\nresults = model1.evaluate(val_images, val_labels)\n\nprint(\"Loss of the model  is - val \", results[0])\nprint(\"Accuracy of the model is - val\", results[1]*100, \"%\")\n\nresults = model1.evaluate(train_images, train_labels)\n\nprint(\"Loss of the model  is - train \", results[0])\nprint(\"Accuracy of the model is - train\", results[1]*100, \"%\")","c6f17469":"from sklearn.metrics import classification_report\n\npredictions = model1.predict(test_images)\npredictions = np.argmax(predictions,axis=1)\npredictions[:15]","5e5cd948":"print(classification_report(\n    test_labels, \n    predictions, \n    target_names = ['EOSINOPHIL (Class 0)', 'LYMPHOCYTE (Class 1)', 'MONOCYTE (Class 2)', 'NEUTROPHIL (Class 3)']))","9e06c350":"cm = confusion_matrix(test_labels, predictions)\ncm = pd.DataFrame(cm, index = ['0', '1', '2', '3'], columns = ['0', '1', '2', '3'])\ncm","f63a63be":"def plot_confusion_matrix (cm):\n    plt.figure(figsize = (10,10))\n    sns.heatmap(\n        cm, \n        cmap = 'Blues', \n        linecolor = 'black', \n        linewidth = 1, \n        annot = True, \n        fmt = '', \n        xticklabels = class_names, \n        yticklabels = class_names)\n    \nplot_confusion_matrix(cm)","0b0537e0":"**Building Custom Model**","dec0717e":"# Loading Data:","05d362a1":"Q1. \nWrite  your  own  code  to  compute  the feature  maps on  the  given  color  image  of  dimension with equal width and height, given \u2018N\u2019 filters each of dimension 3 x 3. Print the following:\n\n1.   Size of feature maps\n2.   Feature Map as specified by the user","785c0e29":"# Evaluating performance","d882e5f6":"**19AIE312 \u2013 Deep Learning for Signal and Image Processing**\n\nAssignment 1 - Evaluation 1\n\nSABARISHWARAN G - CB.EN.U4AIE19053","2ac18d47":"**Q2.** \nUse the dataset available in the link given below:\nhttps:\/\/www.kaggle.com\/paultimothymooney\/blood-cells\n\nBuild your own CNN architecture and present the following outputs:\n1.   Model Summary\n2.   Train and Validation Accuracy Vs number of epochs.\n3.   Confusion matrix.\n4.   Accuracy for each class"}}