{"cell_type":{"5819f588":"code","53da44a7":"code","106f6931":"code","d701c3d2":"code","dd16d17d":"code","33b69b56":"code","9b7135d6":"code","6604f86e":"code","f1aaea8c":"code","af7f2372":"code","a35ae089":"code","b4b49b10":"code","c827ff41":"code","3204bdaf":"code","bf456ff1":"code","72622b60":"code","3d644267":"code","09f1bf63":"code","1223a660":"code","aed3dd70":"code","135f9a6e":"code","fc1188f8":"code","fe809ae6":"markdown"},"source":{"5819f588":"from mlxtend.plotting import plot_decision_regions\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nimport os\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\n\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score","53da44a7":"dp_data = pd.read_csv('..\/input\/d\/yudhaislamisulistya\/dataset-dental-panoramic\/dataset_dental_panoramic_new.csv')\ndp_data.head()","106f6931":"dp_data.info(verbose=True)","d701c3d2":"\ndp_data.describe()\n","dd16d17d":"dp_data_copy = dp_data.copy(deep = True)\ndp_data_copy[['dissimilarity_0', 'dissimilarity_45', 'dissimilarity_90', 'dissimilarity_135', \n                 'correlation_0', 'correlation_45', 'correlation_90', 'correlation_135',\n                 'homogeneity_0', 'homogeneity_45', 'homogeneity_90', 'homogeneity_135',\n                 'contrast_0', 'contrast_45', 'contrast_90', 'contrast_135',\n                 'energy_0', 'energy_45', 'energy_90', 'energy_135']] = dp_data_copy[['dissimilarity_0', 'dissimilarity_45', 'dissimilarity_90', 'dissimilarity_135', \n                 'correlation_0', 'correlation_45', 'correlation_90', 'correlation_135',\n                 'homogeneity_0', 'homogeneity_45', 'homogeneity_90', 'homogeneity_135',\n                 'contrast_0', 'contrast_45', 'contrast_90', 'contrast_135',\n                 'energy_0', 'energy_45', 'energy_90', 'energy_135']].replace(0,np.NaN)\n\n## showing the count of Nans\nprint(dp_data_copy.isnull().sum())","33b69b56":"p = dp_data.hist(figsize = (20,20))","9b7135d6":"sns.countplot(y=dp_data.dtypes ,data=dp_data)\nplt.xlabel(\"count of each data type\")\nplt.ylabel(\"data types\")\nplt.show()","6604f86e":"import missingno as msno\np=msno.bar(dp_data)","f1aaea8c":"color_wheel = {1: \"#0392cf\", \n               2: \"#7bc043\"}\ncolors = dp_data[\"outcome\"].map(lambda x: color_wheel.get(x + 1))\nprint(dp_data.outcome.value_counts())\np=dp_data.outcome.value_counts().plot(kind=\"bar\")\n","af7f2372":"from pandas.tools.plotting import scatter_matrix\np=scatter_matrix(dp_data,figsize=(25, 25))","a35ae089":"plt.figure(figsize=(12,10))\np=sns.heatmap(dp_data.corr(), annot=True,cmap ='RdYlGn')","b4b49b10":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX =  pd.DataFrame(sc_X.fit_transform(dp_data_copy.drop([\"outcome\", \"label\"],axis = 1),),\n        columns=['dissimilarity_0', 'dissimilarity_45', 'dissimilarity_90', 'dissimilarity_135', \n                 'correlation_0', 'correlation_45', 'correlation_90', 'correlation_135',\n                 'homogeneity_0', 'homogeneity_45', 'homogeneity_90', 'homogeneity_135',\n                 'contrast_0', 'contrast_45', 'contrast_90', 'contrast_135',\n                 'energy_0', 'energy_45', 'energy_90', 'energy_135'])\n\nsc_X = StandardScaler()\nXX =  pd.DataFrame(sc_X.fit_transform(dp_data_copy.drop([\"label\"],axis = 1),),\n        columns=['dissimilarity_0', 'dissimilarity_45', 'dissimilarity_90', 'dissimilarity_135', \n                 'correlation_0', 'correlation_45', 'correlation_90', 'correlation_135',\n                 'homogeneity_0', 'homogeneity_45', 'homogeneity_90', 'homogeneity_135',\n                 'contrast_0', 'contrast_45', 'contrast_90', 'contrast_135',\n                 'energy_0', 'energy_45', 'energy_90', 'energy_135','outcome'])","c827ff41":"X.head(25)","3204bdaf":"y = dp_data_copy.outcome","bf456ff1":"#from sklearn.model_selection import train_test_split\n#X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=3\/4,random_state=0, stratify=y)","72622b60":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,train_size=3\/4,random_state=42, stratify=y)\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1\/4,random_state=42, stratify=y)","3d644267":"from sklearn.neighbors import KNeighborsClassifier\n\ntest_scores = []\ntrain_scores = []\n\nfor i in range(1,6):\n\n    knn = KNeighborsClassifier(i)\n    knn.fit(X_train,y_train)\n    \n    train_scores.append(knn.score(X_train,y_train))\n    test_scores.append(knn.score(X_test,y_test))","09f1bf63":"## score that comes from testing on the same datapoints that were used for training\nmax_train_score = max(train_scores)\ntrain_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\nprint('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+0, train_scores_ind))))","1223a660":"## score that comes from testing on the datapoints that were split in the beginning to be used for testing solely\nmax_test_score = max(test_scores)\ntest_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\nprint('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))","aed3dd70":"knn = KNeighborsClassifier(11)\nkfold=KFold(n_splits=5, shuffle=True, random_state=0)\nknn.fit(X_train,y_train)\nknn.score(X_test,y_test)\n\naccuracy = cross_val_score(knn,X,y, cv=kfold, scoring='accuracy')\nprint('accuray',  accuracy.mean())","135f9a6e":"from sklearn.metrics import confusion_matrix\n#let us get the predictions using the classifier we had fit above\ny_pred = knn.predict(X_test)\nconfusion_matrix(y_test,y_pred)\npd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)","fc1188f8":"y_pred = knn.predict(X_test)\nfrom sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\np = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","fe809ae6":"## Result Visualisation"}}