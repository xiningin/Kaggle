{"cell_type":{"76e75297":"code","7c02a26f":"code","fd113b3c":"code","3f04dec4":"code","b939cf23":"code","8031544f":"code","6c24b84d":"code","a1e1f5a8":"code","d6f66f8e":"code","bf11f16e":"code","7428a72b":"code","82340f46":"code","92b6670a":"code","1c816923":"code","2c95b1c1":"code","afda893a":"code","dabd57c5":"code","f7c3a138":"code","610f32d8":"code","295cfca0":"code","7c6a27be":"code","3b960065":"code","d3de3c4c":"code","4809c80f":"code","2fb8c0e9":"code","69d6b887":"code","ccc8a0e4":"code","319be676":"code","00596e6f":"code","524b3f6b":"code","506d92f6":"code","e33d5180":"code","6ecdfcaa":"code","a2df9b62":"code","143b456a":"markdown"},"source":{"76e75297":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7c02a26f":"# Models\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.linear_model import Ridge, RidgeCV\nfrom sklearn.linear_model import ElasticNet, ElasticNetCV\nfrom sklearn.svm import SVR\nfrom mlxtend.regressor import StackingCVRegressor\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\n\n# Stats\nfrom scipy.stats import skew, norm\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\n# Misc\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import scale\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.decomposition import PCA\n\npd.set_option('display.max_columns', None)\n\n# Ignore useless warnings\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\npd.options.display.max_seq_items = 8000\npd.options.display.max_rows = 8000","fd113b3c":"train = pd.read_csv('\/kaggle\/input\/zs-challenge-find-sentiment-of-news\/train_file.csv')\ntest = pd.read_csv('\/kaggle\/input\/zs-challenge-find-sentiment-of-news\/test_file.csv')\nsample = pd.read_csv('\/kaggle\/input\/zs-challenge-find-sentiment-of-news\/sample_submission.csv')","3f04dec4":"import pandas_profiling as pp\n\nprof = pp.ProfileReport(train, title=\"Pandas Profiling Report\")\nprof","b939cf23":"pip install hiplot","8031544f":"import hiplot as hip\ndata = train.drop(['IDLink', 'Facebook', 'GooglePlus','LinkedIn'], axis = 1).to_dict(orient = 'records')\nhip.Experiment.from_iterable(data).display()","6c24b84d":"train.columns","a1e1f5a8":"train['Topic'].value_counts()","d6f66f8e":"train.describe()","bf11f16e":"train.head()","7428a72b":"from functools import wraps\nimport datetime as dt\n\ndef log_step(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        tic = dt.datetime.now()\n        result = func(*args, **kwargs)\n        time_taken = str(dt.datetime.now() - tic)\n        print(f\"just ran step {func.__name__} shape={result.shape} took {time_taken}s\")\n        return result\n    return wrapper","82340f46":"from nltk.sentiment import SentimentIntensityAnalyzer\nsia = SentimentIntensityAnalyzer()\n\n\n@log_step\ndef find_sentiment_nltk(data):\n    \n    from nltk.sentiment import SentimentIntensityAnalyzer\n    sia = SentimentIntensityAnalyzer()\n    \n    y = data['Headline'].apply(sia.polarity_scores)\n    data['sentihead'] = y.apply(pd.Series)['compound']\n    \n    z =  data['Title'].apply(sia.polarity_scores)\n    data['sentititle'] = z.apply(pd.Series)['compound']\n    \n    return data\n\n\n","92b6670a":"from sklearn.preprocessing import LabelEncoder\n\n@log_step\ndef encoding(data):\n\n    \"\"\"\n    One Hot Encoding and Label Encoding \n    \n    \n    le = LabelEncoder()\n    data['Source'] = le.fit_transform(data['Source'])\n\n    var_mod = ['Topic']\n\n    for i in var_mod:\n        data[i] = le.fit_transform(data[i])\n        \n    \"\"\"\n    \n    le = LabelEncoder()\n    data['Source'] = le.fit_transform(data['Source'])\n\n    var_mod = ['Topic']\n\n    for i in var_mod:\n        data[i] = le.fit_transform(data[i])\n\n    # One Hot Encoding : \n    # data = pd.get_dummies(data, columns = ['Topic', 'Source'])\n    \n    return data\n    ","1c816923":"@log_step\ndef impute(data):\n    \n    data['Source'] = data['Source'].fillna('Empty')\n    return data\n\n","2c95b1c1":"@log_step\ndef start_pipeline(dataf):\n    return dataf.copy() ","afda893a":"train['PublishDate'] = pd.to_datetime(train['PublishDate'])\ntrain['PublishDate-Month'] = train['PublishDate'].dt.month\ntrain['PublishDate-Year'] = train['PublishDate'].dt.year\ntrain['PublishDate-Day'] = train['PublishDate'].dt.day","dabd57c5":"train.drop(['IDLink', 'PublishDate'], axis = 1, inplace = True)","f7c3a138":"train_df = (train\n      .pipe(start_pipeline)\n      .pipe(impute)\n      .pipe(find_sentiment_nltk)\n      .pipe(encoding))","610f32d8":"X= train_df.drop(columns = ['SentimentTitle', 'SentimentHeadline'], axis=1)\ny= train_df[['SentimentTitle','SentimentHeadline']]","295cfca0":"\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_valid,y_train,y_valid = train_test_split(X,y,test_size=0.2)","7c6a27be":"from sklearn.ensemble import RandomForestRegressor","3b960065":"clf = RandomForestRegressor(n_estimators=500, n_jobs=-1)\nclf.fit(X_train, y_train)\n","d3de3c4c":"y_pred = clf.predict(X_valid)","4809c80f":"y_pred","2fb8c0e9":"y_valid","69d6b887":"X_train.head()","ccc8a0e4":"y_train.head()","319be676":"cat_columns = []\n\nfor col in train_df.select_dtypes('object').columns:\n    print(col)\n    cat_columns.append(col)\n    le = LabelEncoder()\n    train_df[col] = le.fit_transform(train_df[col])","00596e6f":"cat_features_index = [i for i, col in enumerate(train_df.columns) if col in cat_columns]\n\n","524b3f6b":"NUM_OF_BOOST_ROUND = 10000\nEARLY_STOPPING = 300","506d92f6":"params = {\n    'cat_features': cat_features_index,\n    'eval_metric': 'MAE',\n    'random_seed': 2021,\n    'n_estimators' : NUM_OF_BOOST_ROUND\n}","e33d5180":"from catboost import CatBoostRegressor","6ecdfcaa":"bst = CatBoostRegressor(**params, early_stopping_rounds = EARLY_STOPPING)\n_ = bst.fit(X_train , y_train, eval_set = (X_valid, y_valid), plot = True, verbose = False)","a2df9b62":"bst = CatBoostRegressor()\nbst.fit(X_train, y_train)","143b456a":"As per above Graph, Ranking of News on different Social Networks have no effect on Sentiment of the headline or Title\n"}}