{"cell_type":{"22173e22":"code","d892fbbd":"code","8a4c9e8e":"code","292ffeba":"code","b92f4d5e":"code","8a15241b":"code","912ccdb9":"code","8519c526":"code","18b84695":"code","76e2d6f7":"markdown","0cf8225f":"markdown","19e0fa10":"markdown","01b7898e":"markdown","1a70ce42":"markdown","e6fa6389":"markdown"},"source":{"22173e22":"import numpy as np\nimport pandas as pd\nimport sklearn\nimport xgboost\nimport lightgbm\n\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import KFold\n\n\npd.set_option('display.max_colwidth', -1)\npd.set_option('display.max_columns', None)","d892fbbd":"raw_train_data = pd.read_csv('..\/input\/train.csv')\nraw_train_data","8a4c9e8e":"(((raw_train_data['Fare'] + 1)**(1\/9) - 1) * 9).plot(kind='hist');","292ffeba":"def make_train_features(data):\n    #data = data.set_index('PassengerId')\n    data['Rels'] = data['SibSp'] + data['Parch'] + 1\n    features = [pd.get_dummies(data['Sex']), \n                data['Pclass'],\n                data['Age'],\n                data['SibSp'],\n                data['Parch'],\n                data['Rels'],\n                (((data['Fare'] + 1)**(1\/9) - 1) * 9),\n                pd.get_dummies(data['Cabin'].str[0]),\n                pd.get_dummies(data['Embarked'], prefix='Embarked', prefix_sep='_')]\n    features = pd.concat(features, axis=1)\n    features.fillna(value=30, inplace=True)\n    return features ","b92f4d5e":"train_features = make_train_features(raw_train_data)\ndisplay(train_features.head(10))","8a15241b":"from sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nlgb = lightgbm.LGBMClassifier(boosting_type='gbdt', \n                               num_leaves=7, \n                               max_bin=200,\n                               min_data_in_leaf=20,\n                               max_depth=-1, \n                               learning_rate=0.5, \n                               n_estimators=200, \n                               objective='binary', \n                               class_weight=None, \n                               min_split_gain=0.001, \n                               min_child_weight=0.01, \n                               subsample=0.2, \n                               subsample_freq=1, \n                               colsample_bytree=0.2, \n                               reg_alpha=1.2, \n                               reg_lambda=5, \n                               random_state=1, \n                               n_jobs=-1, \n                               silent=False)\nxgb = xgboost.XGBClassifier(max_depth=3, learning_rate=0.05, n_estimators=1000, colsample_bytree=0.2)\nrf = RandomForestClassifier(n_estimators=64)\nvc = VotingClassifier(estimators=[('lgb', lgb), ('xgb', xgb), ('rf', rf)], voting='hard')\n\nskf = KFold(n_splits=10, shuffle=False)\n\nskf_results = cross_validate(\n    lgb, \n    X=train_features, \n    y=raw_train_data['Survived'], \n    cv=skf,\n    n_jobs=-1,\n    return_train_score=False, \n    verbose=False)\n\nscores = skf_results['test_score']\n\nprint(\"Accuracy: %0.3f\" % (scores.mean()))","912ccdb9":"def make_test_features(data, train_features):\n    features = make_train_features(data)\n    features_cols = pd.DataFrame(data=None, columns=train_features.columns)\n    # Remove columns that weren't in the train set. \n    features = pd.concat([features_cols, features], join='inner', sort=False)\n    # Then add missing columns and fill them with zeros.\n    features = pd.concat([features_cols, features], sort=False).fillna(value=0)\n    return features  ","8519c526":"raw_test_data = pd.read_csv('..\/input\/test.csv')\ntest_features = make_test_features(raw_test_data, train_features)\ntest_features.head(10)","18b84695":"final_model = lgb.fit(train_features, y=raw_train_data['Survived'])\nsubmission = pd.DataFrame({'PassengerId': raw_test_data['PassengerId'], 'Survived': final_model.predict(test_features)})\nsubmission.to_csv('submission.csv', index=False)","76e2d6f7":"Train on entire train set using the hyperparameters from earlier. Then predict on test set and save submission.","0cf8225f":"## Predict on Test Set","19e0fa10":"## Create Features","01b7898e":" # Titanic Ensemble","1a70ce42":"## Load and Inspect Data","e6fa6389":"## Develop Model"}}