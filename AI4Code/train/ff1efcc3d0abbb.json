{"cell_type":{"65d6424f":"code","55ce6b81":"code","6eeda7d8":"code","bae4ec3b":"code","bfcf4d7a":"code","65958300":"code","a152a9f0":"code","04aa4871":"code","88baf326":"code","a0920594":"code","8ab61a93":"code","6d106796":"code","632a2e6b":"code","3f26137d":"code","116d6782":"code","a1de752e":"code","9c9d6f7b":"code","68d56d26":"code","9b13b80d":"code","82202894":"code","375e33f7":"code","ae5d6b27":"code","ab6d619c":"code","9c07e1a3":"code","63fe565c":"code","71990de7":"markdown","28d16f97":"markdown","9b20da42":"markdown","4ed3cc61":"markdown","911df378":"markdown","30e5aaa4":"markdown","a60cac96":"markdown","61ed48da":"markdown","51ac2464":"markdown"},"source":{"65d6424f":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns","55ce6b81":"# loading train and test data\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","6eeda7d8":"#import pandas_profiling\n#train.profile_report()","bae4ec3b":"train.head()","bfcf4d7a":"#dimension\ntrain.shape","65958300":"plt.figure(figsize = (30, 25))\nsns.heatmap(train.corr(), annot = True, cmap=\"YlGnBu\")\nplt.show()","a152a9f0":"#SalePrice\n\nplt.figure(figsize=(12,6))\nsns.boxplot(x=train.SalePrice,color=\"blue\")\n\nplt.show()","04aa4871":"plt.figure(figsize=(12,8))\nsns.regplot(train.YearBuilt , train.SalePrice, \n            scatter_kws={\"color\":\"blue\"}, \n            line_kws={\"linewidth\":3, \"color\": \"#6ca19e\" ,\"label\":\"Mean Sale Price\"},\n            label=\"Sale Price\")\nplt.style.use(\"fivethirtyeight\")\nplt.title(\"SalePrice by YearBuilt \")\nplt.xlabel(\"YearBuilt\")\nplt.ylabel(\"SalePrice\")\nplt.legend()\nplt.show()","88baf326":"#duplicated value\ntrain.duplicated().sum()","a0920594":"train.isna().sum()","8ab61a93":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","6d106796":"label=train['SalePrice']\ndata=train.drop(['SalePrice'],axis=1)\nprint(data.shape)","632a2e6b":"for col in data.columns:\n    print(col)\nmycolumns = [\"OverallQual\",\"YearBuilt\",\"YearRemodAdd\",\"TotalBsmtSF\",\"1stFlrSF\",\"GrLivArea\",\"FullBath\",\"TotRmsAbvGrd\",\"GarageCars\",\"GarageArea\"] \ndata=data[mycolumns]\ndata.shape","3f26137d":"fig, ax = plt.subplots(figsize=(10,10))         # Sample figsize in inches\nsns.heatmap(data.isnull(),yticklabels=False,cbar=False,cmap='viridis',ax=ax)","116d6782":"data.head()","a1de752e":"from sklearn.preprocessing import StandardScaler\n\nscaler=StandardScaler()\n\ndata = scaler.fit_transform(data)\nlabel=label.values.reshape(-1,1)\n#label=scaler.fit_transform(label)","9c9d6f7b":"mycolumns = [\"OverallQual\",\"YearBuilt\",\"YearRemodAdd\",\"TotalBsmtSF\",\"1stFlrSF\",\"GrLivArea\",\"FullBath\",\"TotRmsAbvGrd\",\"GarageCars\",\"GarageArea\"] \ntest1=test[mycolumns]\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler=StandardScaler()\n\ntest1 = scaler.fit_transform(test1)\n","68d56d26":"test1=pd.DataFrame(test1)\ntest1.isna().sum()","9b13b80d":"test1=test1.fillna(test1.mean())\ntest1.isna().sum()\ntest1.shape\ntest1.head()","82202894":"\"\"\"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.1, random_state=0)\nfrom sklearn.linear_model import LinearRegression\nmodel=LinearRegression()\nimport time\ndebut=time.time()\n#fit permet de faire le train de modele \nmodel.fit(X_train,y_train)\nfin=time.time()-debut\"\"\"","375e33f7":"\"\"\"a=model.coef_  #la valeur de a\nprint(a)\n\nb=model.intercept_\nprint(b)  #la valeur de b\npred=model.predict(test1)\n\"\"\"\n\"\"\"mse\nfrom sklearn.metrics import mean_squared_error\nmse=mean_squared_error(y_test,pred)\nimport math\nprint('RMSE of Linear Regression', math.sqrt(mse))\"\"\"","ae5d6b27":"\"\"\"plt.figure(figsize=(10,10))\nsns.regplot(y_test, pred, scatter_kws=dict(color=\"blue\"), line_kws=dict(color=\"green\", linewidth=2))\nplt.title(\"Linear Regression Actual vs Predict Train Data\")\nplt.xlabel(\"Actual Value\")\nplt.ylabel(\"Predicited Value\")\nplt.show()\"\"\"","ab6d619c":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.33, random_state=1)\nfrom sklearn.ensemble import RandomForestRegressor\n# Instantiate model with 1200 decision trees\n#nombre de feuille dans arbre   criterion:mean absolut error\nmodel = RandomForestRegressor( random_state = 0,n_estimators=700,criterion='mse')\nimport time\ndebut=time.time()\nmodel.fit(X_train,y_train)\nfin=time.time()-debut\n\npred=model.predict(test1)\n\n#mse\n\"\"\"from sklearn.metrics import mean_squared_error\nmse=mean_squared_error(y_test,pred1)\nimport math\nprint('RMSE of Random Forest', math.sqrt(mse))\"\"\"","9c07e1a3":"\"\"\"import xgboost\n\nxgb = xgboost.XGBRegressor()\n\nxgb.fit(X_train, y_train)\n\npred = xgb.predict(X_test)\n\nprint(\"RMSE of GB Regressor (Default Parameters): \",np.sqrt(mean_squared_error(y_test, pred)))\"\"\"","63fe565c":"\"\"\"rf_best= RandomForestRegressor (random_state = 0,n_estimators=1000,criterion='mae')\nrf_best.fit(X_train, y_train)\npredictions = rf_best.predict(test1)\"\"\"\nsample_submission = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\ndata={\"Id\":[],\"SalePrice\":[]}\nfor id,pred in zip( sample_submission['Id'].unique(),pred):\n  data[\"Id\"].append(id)\n  data[\"SalePrice\"].append(pred)\n    \noutput=pd.DataFrame(data,columns=[\"Id\",\"SalePrice\"])\noutput\nprint(output)\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n\n\n","71990de7":"# Exploratory Data Analysis","28d16f97":"# XGBoost","9b20da42":"# Linear regression","4ed3cc61":"# Random forest","911df378":"# 1.  understanding the dataset","30e5aaa4":"# Train data Scaling","a60cac96":"# Cleaning data","61ed48da":"# Dimension Reduction \nwe will choose the top 10 correlated features with SalePrice ","51ac2464":"# Test data scaling"}}