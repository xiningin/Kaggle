{"cell_type":{"cd712c61":"code","583443c5":"code","3437af1a":"code","e6529897":"code","48349afd":"code","cf6e65d1":"code","ddd71e67":"code","d003c074":"code","04aeab29":"code","6d1b8820":"code","a8a8145a":"code","78b82286":"code","36deb0ee":"code","a274c28d":"code","ddfdc75f":"code","2ee70d76":"code","1e3e287d":"code","5365bbc5":"code","903f6ae0":"code","c5136b41":"code","78d78ec0":"code","16b5fa35":"code","991d30ee":"code","51f5362c":"code","887988cd":"code","3d58d311":"code","e2d9fc9c":"code","fe39e5d3":"code","cd8ceae5":"code","e2a475f1":"code","91d2b9e8":"code","7924887a":"code","47b497c4":"code","24f3d3d0":"code","238957e8":"code","ac8bd077":"code","0a6eead3":"code","44848d28":"code","a607c837":"code","bfb149c7":"code","0f6051b8":"code","7aa8b53a":"code","4a5ea5bd":"code","d0b87863":"code","a58e2fcf":"code","31336da0":"code","99c3800c":"code","52b74e6a":"code","b296b64e":"code","d9cb1ad6":"code","2792b5dd":"code","fad63ba9":"code","8d41e3ca":"code","8100f05d":"code","bb11b9e2":"code","6e70c4b6":"code","239c48b7":"code","3d346b36":"code","501d8614":"code","65ade2be":"code","22344170":"code","c3aeabfc":"code","567d5338":"code","17dcba65":"code","c37a12ef":"code","c55d4060":"code","4d3ebea3":"code","49a21c1b":"code","0432e61a":"code","97d9b283":"code","ba4305f7":"code","80018174":"code","491c744a":"markdown","3cd9e32a":"markdown","0b8b86dc":"markdown","f5952764":"markdown","8d69101d":"markdown","40be4cd3":"markdown","3cc198ed":"markdown","0423aac6":"markdown","1e88b9b5":"markdown","24aee6e8":"markdown","ea913525":"markdown","0500382f":"markdown","60790a4e":"markdown","c991803c":"markdown","a085da7b":"markdown","5c303ffe":"markdown","18e4a23b":"markdown","3b65658d":"markdown","66dffb2c":"markdown","a08d7b1e":"markdown","637b54b2":"markdown","fb003f3a":"markdown"},"source":{"cd712c61":"import numpy as np \nimport pandas as pd \nimport os","583443c5":"import cv2\nimport pathlib","3437af1a":"from keras.callbacks import ModelCheckpoint","e6529897":"import numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nfrom PIL import Image\nimport PIL\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping\nfrom keras.applications import VGG16\nfrom tensorflow.keras.utils import plot_model","48349afd":"train_path=\"..\/input\/fer2013\/train\"\ntest_path=\"..\/input\/fer2013\/test\"","cf6e65d1":"print(\"Total images available for training\")\nfor expression in os.listdir(train_path):    \n    print(str(len(os.listdir(train_path +'\/'+ expression))) + \" \" + expression + \" images\")","ddd71e67":"print('Total images availabe for testing')\nfor expression in os.listdir(test_path):    \n    print(str(len(os.listdir(test_path +'\/'+ expression))) + \" \" + expression + \" images\")","d003c074":"for i in range(5):\n    sample = random.choice(os.listdir(train_path))\n    image=random.choice(os.listdir(train_path+'\/'+sample))\n    print(sample,\"size is\")\n    img = PIL.Image.open(train_path+'\/'+sample+'\/'+image)\n    print(img.size)\n    print('\\n')\n\n","04aeab29":"for i in range(5):\n    sample = random.choice(os.listdir(train_path))\n    image=random.choice(os.listdir(train_path+'\/'+sample))\n    image_display = load_img(train_path+'\/'+sample+'\/'+image)\n    plt.imshow(image_display)\n    plt.title(sample)\n    plt.show()","6d1b8820":"train__dir=pathlib.Path(train_path)\ntrain__dir","a8a8145a":"list(train__dir.glob('*\/*.jpg'))[:2]","78b82286":"image_data_dic={\n    \n    \n    'Angry':list(train__dir.glob('angry\/*')),\n    'Disgust':list(train__dir.glob('disgust\/*')),\n    'Fear':list(train__dir.glob('fear\/*')),\n    'Happy':list(train__dir.glob('happy\/*')),\n    'Sad':list(train__dir.glob('sad\/*')),\n    'Surprise':list(train__dir.glob('surprise\/*')),\n    'Neutral':list(train__dir.glob('neutral\/*')),\n}","36deb0ee":"len(image_data_dic['Angry'])","a274c28d":"image_labels_dic={\n    \n    \n    'Angry':0,\n    'Disgust':1,\n    'Fear':2,\n    'Happy':3,\n    'Sad':4,\n    'Surprise':5,\n    'Neutral':6,\n}\n","ddfdc75f":"image_labels_dic","2ee70d76":"img = cv2.imread(str(image_data_dic['Angry'][0]))\nprint(img)\nprint(\"The size of an image\",img.shape)\n","1e3e287d":"X, y = [], []\n\nfor image_name, images in image_data_dic.items():\n    for image in images:\n        img = cv2.imread(str(image))\n        resized_img = cv2.resize(img,(48,48))\n        X.append(resized_img)\n        y.append(image_labels_dic[image_name])","5365bbc5":"X = np.array(X)\ny=np.array(y)","903f6ae0":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.15, random_state=43)","c5136b41":"print(len(X_train))\nprint(len(X_test))","78d78ec0":"X_train.shape","16b5fa35":"X_test.shape","991d30ee":"X_train_scaled = X_train \/ 255\nX_test_scaled = X_test \/ 255","51f5362c":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nfrom tensorflow.keras.utils import to_categorical","887988cd":"num_classes=7\ny_train1 = to_categorical(y_train, 7)\ny_test1=to_categorical(y_test,7)","3d58d311":"cnn_model = Sequential()\ncnn_model.add(Conv2D(filters=32,kernel_size=3,activation='relu',input_shape = X_test.shape[1:]))\ncnn_model.add( MaxPooling2D(pool_size=2) )# down sampling the output instead of 28*28 it is 14*14\ncnn_model.add( Dropout(0.2))\ncnn_model.add(Flatten()) # flatten out the layers\ncnn_model.add(Dense(32,activation='relu'))\ncnn_model.add(Dense(7,activation = 'softmax'))\ncnn_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\ncnn_model.summary()","e2d9fc9c":"plot_model(cnn_model)","fe39e5d3":"Estop = EarlyStopping(monitor = 'val_loss',patience = 8,verbose = 1,min_delta = 0.011)\nhist = cnn_model.fit(X_train_scaled, y_train1, epochs=140, steps_per_epoch=X_train_scaled.shape[0]\/\/10, validation_data=(X_test_scaled, y_test1),callbacks=[Estop])","cd8ceae5":"fig, axes = plt.subplots(1,2, figsize=(18, 6))\n# Plot training & validation accuracy values\naxes[0].plot(hist.history['accuracy'])\naxes[0].plot(hist.history['val_accuracy'])\naxes[0].set_title('Model accuracy')\naxes[0].set_ylabel('Accuracy')\naxes[0].set_xlabel('Epoch')\naxes[0].legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\naxes[1].plot(hist.history['loss'])\naxes[1].plot(hist.history['val_loss'])\naxes[1].set_title('Model loss')\naxes[1].set_ylabel('Loss')\naxes[1].set_xlabel('Epoch')\naxes[1].legend(['Train', 'Validation'], loc='upper left')\nplt.show()","e2a475f1":"\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(32,activation='relu'))\n\nmodel.add(Dense(7, activation='softmax')) \nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\nmodel.summary()\n","91d2b9e8":"plot_model(model)","7924887a":"Estop = EarlyStopping(monitor = 'val_loss',patience = 8,verbose = 1,min_delta = 0.011)\n\nhist = model.fit(X_train_scaled, y_train1,  epochs=40,steps_per_epoch=X_train_scaled.shape[0]\/\/10, validation_data=(X_test_scaled, y_test1),callbacks=[Estop])","47b497c4":"fig, axes = plt.subplots(1,2, figsize=(18, 6))\n# Plot training & validation accuracy values\naxes[0].plot(hist.history['accuracy'])\naxes[0].plot(hist.history['val_accuracy'])\naxes[0].set_title('Model accuracy')\naxes[0].set_ylabel('Accuracy')\naxes[0].set_xlabel('Epoch')\naxes[0].legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\naxes[1].plot(hist.history['loss'])\naxes[1].plot(hist.history['val_loss'])\naxes[1].set_title('Model loss')\naxes[1].set_ylabel('Loss')\naxes[1].set_xlabel('Epoch')\naxes[1].legend(['Train', 'Validation'], loc='upper left')\nplt.show()","24f3d3d0":"\nmodel_1 = Sequential()\n\nmodel_1.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 3)))\nmodel_1.add(BatchNormalization())\nmodel_1.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_1.add(Dropout(0.25))\n\nmodel_1.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_1.add(BatchNormalization())\nmodel_1.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_1.add(Dropout(0.25))\nmodel_1.add(Flatten())\n\n\n# Fully connected layer 1st layer\nmodel_1.add(Dense(256))\nmodel_1.add(BatchNormalization())\nmodel_1.add(Activation('relu'))\nmodel_1.add(Dropout(0.25))\n\n# Fully connected layer 2nd layer\nmodel_1.add(Dense(512))\nmodel_1.add(BatchNormalization())\nmodel_1.add(Activation('relu'))\nmodel_1.add(Dropout(0.25))\n\nmodel_1.add(Dense(7, activation='softmax')) \n\nmodel_1.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n\nmodel_1.summary()","238957e8":"plot_model(model_1)","ac8bd077":"Estop = EarlyStopping(monitor = 'val_loss',patience = 8,verbose = 1,min_delta = 0.001)\n\nhist = model_1.fit(X_train_scaled, y_train1,  epochs=40,steps_per_epoch=X_train_scaled.shape[0]\/\/10, validation_data=(X_test_scaled, y_test1),callbacks=[Estop])","0a6eead3":"fig, axes = plt.subplots(1,2, figsize=(18, 6))\n# Plot training & validation accuracy values\naxes[0].plot(hist.history['accuracy'])\naxes[0].plot(hist.history['val_accuracy'])\naxes[0].set_title('Model accuracy')\naxes[0].set_ylabel('Accuracy')\naxes[0].set_xlabel('Epoch')\naxes[0].legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\naxes[1].plot(hist.history['loss'])\naxes[1].plot(hist.history['val_loss'])\naxes[1].set_title('Model loss')\naxes[1].set_ylabel('Loss')\naxes[1].set_xlabel('Epoch')\n\naxes[1].legend(['Train', 'Validation'], loc='upper left')\nplt.show()","44848d28":"model2 = Sequential()\n\n# 1 - Convolution\nmodel2.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,3)))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n\n\n\n# 2nd Convolution layer\nmodel2.add(Conv2D(128,(5,5), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Conv2D(128,(5,5), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n\n# 3nd Convolution layer\nmodel2.add(Conv2D(256,(5,5), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Conv2D(256,(5,5), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n\n# 4nd Convolution layer\nmodel2.add(Conv2D(512,(5,5), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n\n\n\n# Flattening\nmodel2.add(Flatten())\n\n# Fully connected layer 1st layer\nmodel2.add(Dense(512))\nmodel2.add(Activation('relu'))\nmodel2.add(Dropout(0.25))\n\n# Fully connected layer 2nd layer\nmodel2.add(Dense(256))\nmodel2.add(Activation('relu'))\nmodel2.add(Dropout(0.25))\n\n# Fully connected layer 3rd layer\nmodel2.add(Dense(128))\nmodel2.add(Activation('relu'))\nmodel2.add(Dropout(0.25))\n\n\nmodel2.add(Dense(7, activation='softmax'))\n\nopt = Adam(lr=0.0005)\nmodel2.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel2.summary()","a607c837":"plot_model(model2)","bfb149c7":"Estop = EarlyStopping(monitor = 'val_loss',patience = 8,verbose = 1,min_delta = 0.001)\n\nhist = model2.fit(X_train_scaled, y_train1,  epochs=40, validation_data=(X_test_scaled, y_test1),callbacks=[Estop])","0f6051b8":"fig, axes = plt.subplots(1,2, figsize=(18, 6))\n# Plot training & validation accuracy values\naxes[0].plot(hist.history['accuracy'])\naxes[0].plot(hist.history['val_accuracy'])\naxes[0].set_title('Model accuracy')\naxes[0].set_ylabel('Accuracy')\naxes[0].set_xlabel('Epoch')\naxes[0].legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\naxes[1].plot(hist.history['loss'])\naxes[1].plot(hist.history['val_loss'])\naxes[1].set_title('Model loss')\naxes[1].set_ylabel('Loss')\naxes[1].set_xlabel('Epoch')\naxes[1].legend(['Train', 'Validation'], loc='upper left')\nplt.show()","7aa8b53a":"train_datagen = ImageDataGenerator(\nrotation_range = 10,\nwidth_shift_range = 0.2,\nheight_shift_range = 0.2,\nshear_range = 0.2,\nzoom_range = 0.2,\nhorizontal_flip = True,\nfill_mode = 'nearest')","4a5ea5bd":"from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau","d0b87863":"\nmodel_1 = Sequential()\n\nmodel_1.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 3)))\nmodel_1.add(BatchNormalization())\nmodel_1.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_1.add(Dropout(0.25))\n\nmodel_1.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_1.add(BatchNormalization())\nmodel_1.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_1.add(Dropout(0.25))\nmodel_1.add(Flatten())\n\n\n# Fully connected layer 1st layer\nmodel_1.add(Dense(256))\nmodel_1.add(BatchNormalization())\nmodel_1.add(Activation('relu'))\nmodel_1.add(Dropout(0.25))\n\n# Fully connected layer 2nd layer\nmodel_1.add(Dense(512))\nmodel_1.add(BatchNormalization())\nmodel_1.add(Activation('relu'))\nmodel_1.add(Dropout(0.25))\n\nmodel_1.add(Dense(7, activation='softmax')) \n\nmodel_1.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n\nmodel_1.summary()","a58e2fcf":"plot_model(model_1)","31336da0":"Estop = EarlyStopping(monitor = 'val_loss',patience = 8,verbose = 1,min_delta = 0.011)\nhist = model_1.fit_generator(train_datagen.flow(X_train_scaled, y_train1),  epochs=40, validation_data=(X_test_scaled, y_test1),callbacks=[Estop])","99c3800c":"fig, axes = plt.subplots(1,2, figsize=(18, 6))\n# Plot training & validation accuracy values\naxes[0].plot(hist.history['accuracy'])\naxes[0].plot(hist.history['val_accuracy'])\naxes[0].set_title('Model accuracy')\naxes[0].set_ylabel('Accuracy')\naxes[0].set_xlabel('Epoch')\naxes[0].legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\naxes[1].plot(hist.history['loss'])\naxes[1].plot(hist.history['val_loss'])\naxes[1].set_title('Model loss')\naxes[1].set_ylabel('Loss')\naxes[1].set_xlabel('Epoch')\naxes[1].legend(['Train', 'Validation'], loc='upper left')\nplt.show()","52b74e6a":"model2 = Sequential()\n\n# 1 - Convolution\nmodel2.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,3)))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n\n# 2nd Convolution layer\nmodel2.add(Conv2D(128,(5,5), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Conv2D(128,(5,5), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n\n# 3nd Convolution layer\nmodel2.add(Conv2D(256,(5,5), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Conv2D(256,(5,5), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n\n# 4nd Convolution layer\nmodel2.add(Conv2D(512,(5,5), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n\n# Flattening\nmodel2.add(Flatten())\n\n# Fully connected layer 1st layer\nmodel2.add(Dense(512))\nmodel2.add(Activation('relu'))\nmodel2.add(Dropout(0.25))\n\n# Fully connected layer 2nd layer\nmodel2.add(Dense(256))\nmodel2.add(Activation('relu'))\nmodel2.add(Dropout(0.25))\n\n# Fully connected layer 3rd layer\nmodel2.add(Dense(128))\nmodel2.add(Activation('relu'))\nmodel2.add(Dropout(0.25))\n\nmodel2.add(Dense(7, activation='softmax'))\n\nopt = Adam(lr=0.0005)\nmodel2.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel2.summary()","b296b64e":"plot_model(model2)","d9cb1ad6":"Estop = EarlyStopping(monitor = 'val_loss',patience = 4,verbose = 1,min_delta = 0.001)\nhist = model2.fit_generator(train_datagen.flow(X_train_scaled, y_train1),  epochs=40, validation_data=(X_test_scaled, y_test1),callbacks=[Estop])","2792b5dd":"fig, axes = plt.subplots(1,2, figsize=(18, 6))\n# Plot training & validation accuracy values\naxes[0].plot(hist.history['accuracy'])\naxes[0].plot(hist.history['val_accuracy'])\naxes[0].set_title('Model accuracy')\naxes[0].set_ylabel('Accuracy')\naxes[0].set_xlabel('Epoch')\naxes[0].legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\naxes[1].plot(hist.history['loss'])\naxes[1].plot(hist.history['val_loss'])\naxes[1].set_title('Model loss')\naxes[1].set_ylabel('Loss')\naxes[1].set_xlabel('Epoch')\naxes[1].legend(['Train', 'Validation'], loc='upper left')\nplt.show()","fad63ba9":"VGG=VGG16(input_shape=X_train_scaled.shape[1:],include_top=False,weights='imagenet')\nVGG.trainable =False","8d41e3ca":"VGG.summary()","8100f05d":"model=Sequential(VGG)\nmodel.add(Flatten())\nmodel.add(Dense(units=256,activation='relu'))\nmodel.add(Dense(units=256,activation='relu'))\nmodel.add(Dense(units=7, activation='softmax'))\nmodel.summary()","bb11b9e2":"plot_model(VGG)","6e70c4b6":"opt = Adam(lr=0.0005)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])","239c48b7":"Estop = EarlyStopping(monitor = 'val_loss',patience = 4,verbose = 1,min_delta = 0.001)\nhist = model.fit_generator(train_datagen.flow(X_train_scaled, y_train1),  epochs=40, validation_data=(X_test_scaled, y_test1),callbacks=[Estop])","3d346b36":"fig, axes = plt.subplots(1,2, figsize=(18, 6))\n# Plot training & validation accuracy values\naxes[0].plot(hist.history['accuracy'])\naxes[0].plot(hist.history['val_accuracy'])\naxes[0].set_title('Model accuracy')\naxes[0].set_ylabel('Accuracy')\naxes[0].set_xlabel('Epoch')\naxes[0].legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\naxes[1].plot(hist.history['loss'])\naxes[1].plot(hist.history['val_loss'])\naxes[1].set_title('Model loss')\naxes[1].set_ylabel('Loss')\naxes[1].set_xlabel('Epoch')\naxes[1].legend(['Train', 'Validation'], loc='upper left')\nplt.show()","501d8614":"model2 = Sequential()\n\n# 1 - Convolution\nmodel2.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,3)))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n\n# 2nd Convolution layer\nmodel2.add(Conv2D(128,(5,5), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Conv2D(128,(5,5), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n\n# 3nd Convolution layer\nmodel2.add(Conv2D(256,(5,5), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Conv2D(256,(5,5), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n\n# 4nd Convolution layer\nmodel2.add(Conv2D(512,(5,5), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\n\n# Flattening\nmodel2.add(Flatten())\n\n# Fully connected layer 1st layer\nmodel2.add(Dense(512))\nmodel2.add(Activation('relu'))\nmodel2.add(Dropout(0.25))\n\n# Fully connected layer 2nd layer\nmodel2.add(Dense(256))\nmodel2.add(Activation('relu'))\nmodel2.add(Dropout(0.25))\n\n# Fully connected layer 3rd layer\nmodel2.add(Dense(128))\nmodel2.add(Activation('relu'))\nmodel2.add(Dropout(0.25))\n\nmodel2.add(Dense(7, activation='softmax'))\n\nopt = Adam(lr=0.0005)\nmodel2.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel2.summary()","65ade2be":"checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy',save_weights_only=True, mode='max', verbose=1)\nEstop = EarlyStopping(monitor = 'val_loss',patience = 8,verbose = 1,min_delta = 0.001)\nhist = model2.fit_generator(train_datagen.flow(X_train_scaled, y_train1),  epochs=40, validation_data=(X_test_scaled, y_test1),callbacks=[Estop,checkpoint])","22344170":"fig, axes = plt.subplots(1,2, figsize=(18, 6))\n# Plot training & validation accuracy values\naxes[0].plot(hist.history['accuracy'])\naxes[0].plot(hist.history['val_accuracy'])\naxes[0].set_title('Model accuracy')\naxes[0].set_ylabel('Accuracy')\naxes[0].set_xlabel('Epoch')\naxes[0].legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\naxes[1].plot(hist.history['loss'])\naxes[1].plot(hist.history['val_loss'])\naxes[1].set_title('Model loss')\naxes[1].set_ylabel('Loss')\naxes[1].set_xlabel('Epoch')\naxes[1].legend(['Train', 'Validation'], loc='upper left')\nplt.show()","c3aeabfc":"Estop = EarlyStopping(monitor = 'val_loss',patience = 8,verbose = 1,min_delta = 0.001)\nhist = model2.fit(X_train_scaled, y_train1,  epochs=20, validation_data=(X_test_scaled, y_test1),callbacks=[Estop])","567d5338":"from keras.preprocessing import image \nimport numpy as np","17dcba65":"img=image.load_img('..\/input\/fer2013\/test\/angry\/PrivateTest_10131363.jpg',target_size=(48,48))\nimg1=np.asarray(img)\nimg1=np.expand_dims(img1,axis=0)","c37a12ef":"output=model2.predict(img1)","c55d4060":"if output[0][0]>0:\n    t='Angry'\n    print('Angry')\nelif output[0][1]>0:\n    t='Disgust'\n    print('Disgust')\nelif output[0][2]>0:\n    t='Fear'\n    print('Fear')\nelif output[0][3]>0:\n    t='Happy'\n    print('Happy')\nelif output[0][4]>0:\n    t='Sad'\n    print('Sad')\nelif output[0][5]>0:\n    t='Surprise'\n    print('Surprise')\nelse:\n    t='Neutral'\n    print(Neutral)","4d3ebea3":"plt.imshow(img)\nplt.title('The image predicted is '+t)\nplt.show()","49a21c1b":"img=image.load_img('..\/input\/fer2013\/test\/angry\/PrivateTest_10131363.jpg',target_size=(48,48))\nimg1=np.asarray(img)\nimg1=np.expand_dims(img1,axis=0)\nimg1 = img1\/ 255\ncustom = model2.predict(img1)\n","0432e61a":"#to predict the percentage\nobjects = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\ny_pos = np.arange(len(objects))\nplt.bar(y_pos, custom[0], align='center', alpha=0.9)\nplt.tick_params(axis='x', which='both', pad=10,width=4,length=10)\nplt.xticks(y_pos, objects)\nplt.ylabel('percentage')\nplt.title('emotion')\n","97d9b283":"objects = ('Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral')\ny_pos = np.arange(len(objects))\nprint(y_pos)","ba4305f7":"\nx = np.array(img1, 'float32')\nx=x.reshape(48,48,3)","80018174":"\nplt.gray()\nplt.imshow(x)\nplt.show()\n\nm=0.000000000000000000001\na=custom[0]\nfor i in range(0,len(a)):\n    if a[i]>m:\n        m=a[i]\n        ind=i\n        \nprint('Expression Prediction:',objects[ind])","491c744a":"# This model architecture based on the Human facial expression recognition based on deep learning\n\nhttps:\/\/ieeexplore.ieee.org\/abstract\/document\/8976876","3cd9e32a":"# Storing images based on specific expression","0b8b86dc":"# VGG","f5952764":"# MODEL-2","8d69101d":"# Count of various images available for testing","40be4cd3":"# To predict the percentages of the expressions","3cc198ed":"# ","0423aac6":"DATA AUGMENTED MODEL 2","1e88b9b5":"# Testing on the images","24aee6e8":"# This model architecture based on the  Facial Micro expression recognition using deep learning\n\nhttps:\/\/ieeexplore.ieee.org\/document\/9215397","ea913525":"# Randomly selecting various images to know various size of images present in dataset","0500382f":"# Model-1","60790a4e":"# Shape of an image","c991803c":"# Model-2","a085da7b":"# BEST SUITABLE MODEL","5c303ffe":"# The CNN architecture in this paper consists of two hidden layers, two pooling layers and two fully connected layers. ","18e4a23b":"# Model with different kind of layers","3b65658d":"# Basic CNN model","66dffb2c":"# DATA AUGMENTATION","a08d7b1e":"# Augmentation using model2","637b54b2":"# Count of various images available for training","fb003f3a":"# Visualizing various images"}}