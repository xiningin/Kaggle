{"cell_type":{"be4533aa":"code","bff6be3b":"code","3c92eea0":"code","83b20e11":"code","80e32061":"code","a39812b4":"code","d4b71d52":"code","caff3de1":"code","7f1b779c":"code","787e8a53":"code","c055f739":"code","9331498b":"code","dc556d1b":"code","54115fb1":"code","76bb8e26":"code","270699e8":"code","b97970e1":"code","e40be1c1":"code","ad120b92":"code","4aa5d8c4":"code","c644c74c":"code","7da37cd7":"code","abf2b58f":"code","d334ae9d":"code","1374b58a":"code","41b6b86c":"code","a220fcbc":"code","c0f748a0":"code","62438c62":"code","5bdd81d7":"code","a9255119":"code","f3e3afda":"code","6a569330":"code","610506ba":"markdown","6e69d5e8":"markdown","15aa27fc":"markdown","4db62d75":"markdown","5329bd9f":"markdown","b44496f9":"markdown","1bbdc4fb":"markdown","2eaee61a":"markdown","91f1152b":"markdown","92d86695":"markdown","f6f3bb55":"markdown","c83d6378":"markdown","dd2249f3":"markdown","07f5834c":"markdown","2487d0fa":"markdown","3d7048e9":"markdown","a2ea548f":"markdown","984a5cc1":"markdown","48666ca1":"markdown","7d42ac74":"markdown","a2f21196":"markdown"},"source":{"be4533aa":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score\nfrom collections import Counter\nfrom IPython.core.display import display, HTML\nsns.set_style('whitegrid')","bff6be3b":"from sklearn.datasets import load_boston\nboston_dataset = load_boston()\ndataset = pd.DataFrame(boston_dataset.data, columns = boston_dataset.feature_names)","3c92eea0":"dataset.head()\nboston_dataset.target","83b20e11":"dataset['MEDV'] = boston_dataset.target","80e32061":"dataset.head()","a39812b4":"dataset.isnull().sum()","d4b71d52":"X = dataset.iloc[:, 0:13].values\ny = dataset.iloc[:, 13].values.reshape(-1,1)\ny","caff3de1":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 25)","7f1b779c":"print(\"Shape of X_train: \",X_train.shape)\nprint(\"Shape of X_test: \", X_test.shape)\nprint(\"Shape of y_train: \",y_train.shape)\nprint(\"Shape of y_test\",y_test.shape)","787e8a53":"corr = dataset.corr()\n#Plot figsize\nfig, ax = plt.subplots(figsize=(10, 10))\n#Generate Heat Map, allow annotations and place floats in map\nsns.heatmap(corr, cmap='BuPu', annot=True, fmt=\".2f\")\n#Apply xticks\nplt.xticks(range(len(corr.columns)), corr.columns);\n#Apply yticks\nplt.yticks(range(len(corr.columns)), corr.columns)\n#show plot\nplt.show()","c055f739":"sns.pairplot(dataset[['CRIM','ZN','INDUS']])\nplt.show()","9331498b":"from sklearn.linear_model import LinearRegression\nregressor_linear = LinearRegression()\nregressor_linear.fit(X_train, y_train)","dc556d1b":"from sklearn.metrics import r2_score\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_val_score\n\n# Predicting Cross Validation Score the Test set results\ncv_linear = cross_val_score(estimator = regressor_linear, X = X_train, y = y_train, cv = 10)\n\n# Predicting R2 Score the Train set results\ny_pred_linear_train = regressor_linear.predict(X_train)\nr2_score_linear_train = r2_score(y_train, y_pred_linear_train)\n\n# Predicting R2 Score the Test set results\ny_pred_linear_test = regressor_linear.predict(X_test)\nr2_score_linear_test = r2_score(y_test, y_pred_linear_test)\n\n# Predicting RMSE the Test set results\nrmse_linear = (np.sqrt(mean_squared_error(y_test, y_pred_linear_test)))\nprint(\"CV: \", cv_linear.mean())\nprint('R2_score (train): ', r2_score_linear_train)\nprint('R2_score (test): ', r2_score_linear_test)\nprint(\"RMSE: \", rmse_linear)","54115fb1":"#edit 16\/01\/2021\n\n\n#from sklearn.model_selection import GridSearchCV\n#from sklearn.model_selection import cross_val_score\n#from sklearn.model_selection import train_test_split\n#from sklearn.linear_model import LinearRegression\n\n#params = {\n#    'penalty':['l1'],        # l1 is Lasso, l2 is Ridge\n#    'solver':['liblinear'],\n#    'C': np.linspace(0.00002,1,100)\n#}\n\n#X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.3,random_state = 1)\n#model = LinearRegression()\n#model.fit(X_train1,y_train1)\n\n#gsearch = GridSearchCV(model, params, cv = 3, verbose = 1)","76bb8e26":"from sklearn.preprocessing import PolynomialFeatures\n\npoly_reg = PolynomialFeatures(degree = 2)\n\nX_poly = poly_reg.fit_transform(X_train)\npoly_reg.fit(X_poly, y_train)\nregressor_poly2 = LinearRegression().fit(X_poly, y_train)","270699e8":"#how to visualize regressions \n\nimport seaborn as sns\nfrom sklearn.datasets import load_boston\nimport pandas as pd\n\nboston_dataset = load_boston()\ndataset = pd.DataFrame(boston_dataset.data, columns = boston_dataset.feature_names)\ndataset['MEDV'] = boston_dataset.target\n\nsns.regplot(x = dataset['CRIM'], y = dataset['MEDV'])\n\nsns.p","b97970e1":"from sklearn.metrics import r2_score\n\n# Predicting Cross Validation Score the Test set results\ncv_poly2 = cross_val_score(estimator = regressor_poly2, X = X_train, y = y_train, cv = 10)\n\n# Predicting R2 Score the Train set results\ny_pred_poly2_train = regressor_poly2.predict(poly_reg.fit_transform(X_train))\nr2_score_poly2_train = r2_score(y_train, y_pred_poly2_train)\n\n# Predicting R2 Score the Test set results\ny_pred_poly2_test = regressor_poly2.predict(poly_reg.fit_transform(X_test))\nr2_score_poly2_test = r2_score(y_test, y_pred_poly2_test)\n\n# Predicting RMSE the Test set results\nrmse_poly2 = (np.sqrt(mean_squared_error(y_test, y_pred_poly2_test)))\nprint('CV: ', cv_poly2.mean())\nprint('R2_score (train): ', r2_score_poly2_train)\nprint('R2_score (test): ', r2_score_poly2_test)\nprint(\"RMSE: \", rmse_poly2)","e40be1c1":"from sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\n\nsteps = [\n    ('scalar', StandardScaler()),\n    ('poly', PolynomialFeatures(degree=2)),\n    ('model', Ridge(alpha=3.8, fit_intercept=True))\n]\n\nridge_pipe = Pipeline(steps)\nridge_pipe.fit(X_train, y_train)","ad120b92":"from sklearn.metrics import r2_score\n\n# Predicting Cross Validation Score the Test set results\ncv_ridge = cross_val_score(estimator = ridge_pipe, X = X_train, y = y_train.ravel(), cv = 10)\n\n# Predicting R2 Score the Test set results\ny_pred_ridge_train = ridge_pipe.predict(X_train)\nr2_score_ridge_train = r2_score(y_train, y_pred_ridge_train)\n\n# Predicting R2 Score the Test set results\ny_pred_ridge_test = ridge_pipe.predict(X_test)\nr2_score_ridge_test = r2_score(y_test, y_pred_ridge_test)\n\n# Predicting RMSE the Test set results\nrmse_ridge = (np.sqrt(mean_squared_error(y_test, y_pred_ridge_test)))\nprint('CV: ', cv_ridge.mean())\nprint('R2_score (train): ', r2_score_ridge_train)\nprint('R2_score (test): ', r2_score_ridge_test)\nprint(\"RMSE: \", rmse_ridge)","4aa5d8c4":"from sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\n\nsteps = [\n    ('scalar', StandardScaler()),\n    ('poly', PolynomialFeatures(degree=2)),\n    ('model', Lasso(alpha=0.012, fit_intercept=True, max_iter=3000))\n]\n\nlasso_pipe = Pipeline(steps)\nlasso_pipe.fit(X_train, y_train)","c644c74c":"from sklearn.metrics import r2_score\n\n# Predicting Cross Validation Score\ncv_lasso = cross_val_score(estimator = lasso_pipe, X = X_train, y = y_train, cv = 10)\n\n# Predicting R2 Score the Test set results\ny_pred_lasso_train = lasso_pipe.predict(X_train)\nr2_score_lasso_train = r2_score(y_train, y_pred_lasso_train)\n\n# Predicting R2 Score the Test set results\ny_pred_lasso_test = lasso_pipe.predict(X_test)\nr2_score_lasso_test = r2_score(y_test, y_pred_lasso_test)\n\n# Predicting RMSE the Test set results\nrmse_lasso = (np.sqrt(mean_squared_error(y_test, y_pred_lasso_test)))\nprint('CV: ', cv_lasso.mean())\nprint('R2_score (train): ', r2_score_lasso_train)\nprint('R2_score (test): ', r2_score_lasso_test)\nprint(\"RMSE: \", rmse_lasso)","7da37cd7":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nsc_y = StandardScaler()\nX_scaled = sc_X.fit_transform(X_train)\ny_scaled = sc_y.fit_transform(y_train.reshape(-1,1))","abf2b58f":"# Fitting the SVR Model to the dataset\nfrom sklearn.svm import SVR\nregressor_svr = SVR(kernel = 'rbf', gamma = 'scale')\nregressor_svr.fit(X_scaled, y_scaled.ravel())","d334ae9d":"from sklearn.metrics import r2_score\n\n# Predicting Cross Validation Score\ncv_svr = cross_val_score(estimator = regressor_svr, X = X_scaled, y = y_scaled.ravel(), cv = 10)\n\n# Predicting R2 Score the Train set results\ny_pred_svr_train = sc_y.inverse_transform(regressor_svr.predict(sc_X.transform(X_train)))\nr2_score_svr_train = r2_score(y_train, y_pred_svr_train)\n\n# Predicting R2 Score the Test set results\ny_pred_svr_test = sc_y.inverse_transform(regressor_svr.predict(sc_X.transform(X_test)))\nr2_score_svr_test = r2_score(y_test, y_pred_svr_test)\n\n# Predicting RMSE the Test set results\nrmse_svr = (np.sqrt(mean_squared_error(y_test, y_pred_svr_test)))\nprint('CV: ', cv_svr.mean())\nprint('R2_score (train): ', r2_score_svr_train)\nprint('R2_score (test): ', r2_score_svr_test)\nprint(\"RMSE: \", rmse_svr)","1374b58a":"# Fitting the Decision Tree Regression Model to the dataset\nfrom sklearn.tree import DecisionTreeRegressor\nregressor_dt = DecisionTreeRegressor(random_state = 0)\nregressor_dt.fit(X_train, y_train)","41b6b86c":"from sklearn.metrics import r2_score\n\n# Predicting Cross Validation Score\ncv_dt = cross_val_score(estimator = regressor_dt, X = X_train, y = y_train, cv = 10)\n\n# Predicting R2 Score the Train set results\ny_pred_dt_train = regressor_dt.predict(X_train)\nr2_score_dt_train = r2_score(y_train, y_pred_dt_train)\n\n# Predicting R2 Score the Test set results\ny_pred_dt_test = regressor_dt.predict(X_test)\nr2_score_dt_test = r2_score(y_test, y_pred_dt_test)\n\n# Predicting RMSE the Test set results\nrmse_dt = (np.sqrt(mean_squared_error(y_test, y_pred_dt_test)))\nprint('CV: ', cv_dt.mean())\nprint('R2_score (train): ', r2_score_dt_train)\nprint('R2_score (test): ', r2_score_dt_test)\nprint(\"RMSE: \", rmse_dt)","a220fcbc":"# Fitting the Random Forest Regression to the dataset\nfrom sklearn.ensemble import RandomForestRegressor\nregressor_rf = RandomForestRegressor(n_estimators = 500, random_state = 0)\nregressor_rf.fit(X_train, y_train.ravel())","c0f748a0":"from sklearn.metrics import r2_score\n\n# Predicting Cross Validation Score\ncv_rf = cross_val_score(estimator = regressor_rf, X = X_scaled, y = y_train.ravel(), cv = 10)\n\n# Predicting R2 Score the Train set results\ny_pred_rf_train = regressor_rf.predict(X_train)\nr2_score_rf_train = r2_score(y_train, y_pred_rf_train)\n\n# Predicting R2 Score the Test set results\ny_pred_rf_test = regressor_rf.predict(X_test)\nr2_score_rf_test = r2_score(y_test, y_pred_rf_test)\n\n# Predicting RMSE the Test set results\nrmse_rf = (np.sqrt(mean_squared_error(y_test, y_pred_rf_test)))\nprint('CV: ', cv_rf.mean())\nprint('R2_score (train): ', r2_score_rf_train)\nprint('R2_score (test): ', r2_score_rf_test)\nprint(\"RMSE: \", rmse_rf)","62438c62":"models = [('Linear Regression', rmse_linear, r2_score_linear_train, r2_score_linear_test, cv_linear.mean()),\n          ('Polynomial Regression (2nd)', rmse_poly2, r2_score_poly2_train, r2_score_poly2_test, cv_poly2.mean()),\n          ('Ridge Regression', rmse_ridge, r2_score_ridge_train, r2_score_ridge_test, cv_ridge.mean()),\n          ('Lasso Regression', rmse_lasso, r2_score_lasso_train, r2_score_lasso_test, cv_lasso.mean()),\n          ('Support Vector Regression', rmse_svr, r2_score_svr_train, r2_score_svr_test, cv_svr.mean()),\n          ('Decision Tree Regression', rmse_dt, r2_score_dt_train, r2_score_dt_test, cv_dt.mean()),\n          ('Random Forest Regression', rmse_rf, r2_score_rf_train, r2_score_rf_test, cv_rf.mean())   \n         ]","5bdd81d7":"predict = pd.DataFrame(data = models, columns=['Model', 'RMSE', 'R2_Score(training)', 'R2_Score(test)', 'Cross-Validation'])\npredict","a9255119":"f, axe = plt.subplots(1,1, figsize=(18,6))\n\npredict.sort_values(by=['Cross-Validation'], ascending=False, inplace=True)\n\nsns.barplot(x='Cross-Validation', y='Model', data = predict, ax = axe)\n#axes[0].set(xlabel='Region', ylabel='Charges')\naxe.set_xlabel('Cross-Validaton Score', size=16)\naxe.set_ylabel('Model')\naxe.set_xlim(0,1.0)\nplt.show()","f3e3afda":"f, axes = plt.subplots(2,1, figsize=(14,10))\n\npredict.sort_values(by=['R2_Score(training)'], ascending=False, inplace=True)\n\nsns.barplot(x='R2_Score(training)', y='Model', data = predict, palette='Blues_d', ax = axes[0])\n#axes[0].set(xlabel='Region', ylabel='Charges')\naxes[0].set_xlabel('R2 Score (Training)', size=16)\naxes[0].set_ylabel('Model')\naxes[0].set_xlim(0,1.0)\n\npredict.sort_values(by=['R2_Score(test)'], ascending=False, inplace=True)\n\nsns.barplot(x='R2_Score(test)', y='Model', data = predict, palette='Reds_d', ax = axes[1])\n#axes[0].set(xlabel='Region', ylabel='Charges')\naxes[1].set_xlabel('R2 Score (Test)', size=16)\naxes[1].set_ylabel('Model')\naxes[1].set_xlim(0,1.0)\n\nplt.show()","6a569330":"predict.sort_values(by=['RMSE'], ascending=False, inplace=True)\n\nf, axe = plt.subplots(1,1, figsize=(18,6))\nsns.barplot(x='Model', y='RMSE', data=predict, ax = axe)\naxe.set_xlabel('Model', size=16)\naxe.set_ylabel('RMSE', size=16)\n\nplt.show()","610506ba":"## <span id=\"6\"><\/span> ** 4. Regression Models **","6e69d5e8":"<hr\/>\n<hr\/>\n<font color=green>\n1. [Overview](#1)\n1. [Importing Libraries and Reading the Dataset](#2)\n1. [Data Analysis](#3) \n    * [Data Preprocessing](#4) \n    * [Visualizing Data](#5) \n1. [Regression Models](#6) \n    * [Linear Regression](#7) \n    * [Polynomial Regression - 2nd degree](#8)\n    * [Ridge Regression](#9)\n    * [Lasso Regression](#10)\n    * [Support Vector Regression](#11)\n    * [Decision Tree Regression](#12) \n    * [Random Forest Regression](#13)\n1. [Measuring the Error](#14)\n    * [Visualizing Models Performance](#15)\n1. [Conclusion](#16)\n<hr\/>","15aa27fc":"### <span id=\"5\"><\/span> ** Visualizing Data **","4db62d75":"### <span id=\"9\"><\/span> ** Ridge Regression **","5329bd9f":"## <span id=\"3\"><\/span> ** 3. Data Analysis **","b44496f9":"Are there missing values? There isn't any missing values as shown below.","1bbdc4fb":"In this kernel, I have built 7 regression models using Boston Housing Dataset. These are linear, polynomial, ridge, lasso,  svr, decision tree and random forest regression. Then measured and visualized the performance of the models. Please make a comment and let me know how to improve model performance, visualization or something in this kernel. This will also help me on my future analysis.\n\n<b><font color=\"red\">Don't forget to <\/font><\/b> <b><font color=\"green\">UPVOTE <\/font><\/b> if you liked this kernel, thank you. \ud83d\ude42\ud83d\udc4d","2eaee61a":"Columns:\n- **CRIM: ** Per capita crime rate by town\n- **ZN: ** Proportion of residential land zoned for lots over 25,000 sq. ft\n- **INDUS: ** Proportion of non-retail business acres per town\n- **CHAS : ** Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n- **NOX: ** Nitric oxide concentration (parts per 10 million)\n- **RM: ** Average number of rooms per dwelling\n- **AGE: ** Proportion of owner-occupied units built prior to 1940\n- **DIS: ** Weighted distances to five Boston employment centers\n- **RAD: ** Index of accessibility to radial highways\n- **PTRATIO: ** Pupil-teacher ratio by town\n- **B: ** 1000(Bk \u2014 0.63)\u00b2, where Bk is the proportion of [people of African American descent] by town\n- **LSTAT: ** Percentage of lower status of the population\n- **MEDV: ** Median value of owner-occupied homes in $1000s","91f1152b":"### <span id=\"13\"><\/span> ** Random Forest Regression **","92d86695":"## <span id=\"16\"><\/span> ** 6. Conclusion **","f6f3bb55":"![](http:\/\/)### <span id=\"4\"><\/span> ** Data Preprocessing **","c83d6378":"### <span id=\"7\"><\/span> ** Linear Regression **","dd2249f3":"### <span id=\"10\"><\/span> ** Lasso Regression **","07f5834c":"As you seen, there isn't \"MEDV\" column that we will try to predict. Let's add the column to our dataset.","2487d0fa":"## <span id=\"2\"><\/span> ** 2. Importing Libraries and Reading the Dataset **","3d7048e9":"### <span id=\"11\"><\/span> ** Support Vector Regression **","a2ea548f":"### <span id=\"8\"><\/span> ** Polynomial Regression - 2nd degree **","984a5cc1":"## <span id=\"1\"><\/span> ** 1. Overview **","48666ca1":"### <span id=\"12\"><\/span> ** Decision Tree Regression **","7d42ac74":"### <span id=\"15\"><\/span> ** Visualizing Model Performance **","a2f21196":"## <span id=\"14\"><\/span> ** 5. Measuring the Error **"}}