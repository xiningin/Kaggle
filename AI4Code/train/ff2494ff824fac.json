{"cell_type":{"39727ef4":"code","8509b653":"code","51d4a679":"code","83c82749":"code","b738171d":"code","86397223":"code","075962d5":"code","94e1779f":"code","a6b4b1bb":"code","313593e9":"code","81f1a7eb":"code","772e640d":"code","86d6dc1b":"code","b7ce3882":"code","e7319970":"code","0ebb5b04":"code","05ba5e21":"code","f7e9477f":"code","98200ea2":"code","08d3ea9c":"code","cde512ca":"code","d711417a":"code","7abb3893":"code","2fb990be":"code","ae4e49b6":"code","c019f9df":"code","9afcd684":"code","8ca16151":"code","30a81671":"code","13594301":"code","180da985":"code","664fe2ed":"code","0a31b3e7":"code","d6058733":"code","8c58476e":"code","71130b89":"code","30fd3d7e":"code","1b61f8b3":"code","624e5437":"code","822dec38":"code","8ad1645d":"code","8c21befb":"code","01d2b29a":"code","eb296649":"code","449015fd":"code","bb34ece4":"code","93675d2c":"code","70b4c5a0":"code","b1f49193":"code","9b6d64eb":"code","db998df0":"code","a1f0cdd6":"code","4422f44b":"code","82a42d80":"code","4effed4b":"code","2949ec5d":"code","0f1ac2f7":"code","86227f44":"code","a095ea04":"code","f2e06740":"code","5f777547":"code","7bf58f25":"code","cd591eff":"code","59dcfa49":"code","340489e1":"code","bead6adb":"code","d5484540":"code","f2a1de2c":"code","f5ddb1b5":"code","8f4cf80b":"code","33341e4d":"code","3538e240":"code","31fffdf5":"code","c93300bd":"code","d23d7f95":"code","1f27d193":"code","f1a016b8":"code","43d6da4e":"code","abf2dc0e":"code","d19d14a7":"code","1ac75d50":"code","59a499c6":"code","e35d7da4":"code","a49458e5":"code","e7e2be5e":"code","a5e7a4c8":"code","ef4516c6":"code","74815f91":"markdown","70978c6a":"markdown","37e3c929":"markdown","2a693336":"markdown","e3f00a95":"markdown","efd4ac22":"markdown","e7b5de0e":"markdown","cc310f4e":"markdown","4cf4935b":"markdown","f369bf16":"markdown","bfe98533":"markdown"},"source":{"39727ef4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.cluster import KMeans\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8509b653":"df = pd.read_csv(\"\/kaggle\/input\/best-books-of-the-21st-century-dataset\/Best_Book_21st.csv\")","51d4a679":"df.shape","83c82749":"sns.set_context('talk')\nmost_books = df.groupby('publisher')['title'].count().reset_index().sort_values('title', ascending=False).head(10).set_index('publisher')\nplt.figure(figsize=(15,10))\nax = sns.barplot(most_books['title'], most_books.index, palette='icefire_r')\nax.set_title(\"Top 10 publisher with most books\")\nax.set_xlabel(\"Total number of books\")\nfor i in ax.patches:\n    ax.text(i.get_width()+.3, i.get_y()+0.5, str(round(i.get_width())), fontsize = 10, color = 'k')","b738171d":"sns.set_context('talk')\nmost_books = df.groupby('author')['title'].count().reset_index().sort_values('title', ascending=False).head(10).set_index('author')\nplt.figure(figsize=(15,10))\nax = sns.barplot(most_books['title'], most_books.index, palette='icefire_r')\nax.set_title(\"Top 10 authors with most books\")\nax.set_xlabel(\"Total number of books\")\nfor i in ax.patches:\n    ax.text(i.get_width()+.3, i.get_y()+0.5, str(round(i.get_width())), fontsize = 10, color = 'k')","86397223":"most_rated = df.sort_values('rate', ascending = False).head(10).set_index('title')\nplt.figure(figsize=(15,10))\nsns.barplot(most_rated['rate'], most_rated.index, palette='rocket')","075962d5":"high_rated_author = df[df['rate']>=4.3]\nhigh_rated_author = high_rated_author.groupby('author')['title'].count().reset_index().sort_values('title', ascending = False).head(10).set_index('author')\nplt.figure(figsize=(15,10))\nax = sns.barplot(high_rated_author['title'], high_rated_author.index, palette='Set2')\nax.set_xlabel(\"Number of Books\")\nax.set_ylabel(\"Author\")\nfor i in ax.patches:\n    ax.text(i.get_width()+.3, i.get_y()+0.5, str(round(i.get_width())), fontsize = 10, color = 'k')","94e1779f":"cor = df.corr()\ncor","a6b4b1bb":"df.describe","313593e9":"df = df.iloc[0:400] # Primeras filas\n","81f1a7eb":"df_llenado = df.fillna({'series':0})\ndf_llenado","772e640d":"df_filtrado = df_llenado.dropna()\ndf_filtrado.head()","86d6dc1b":"df_filtrado.shape","b7ce3882":"df_filtrado.dtypes","e7319970":"Series = df_filtrado['series'].value_counts()\nprint(Series.index)","0ebb5b04":"#la primera se llama reemplazar valores\n#Creado un diccionario con equivalencias\nreplace_map = {'series':\n{'0' : 0,\n'\\n        (The Martian #1)\\n' : 2,     \n'\\n        (Discworld #32)\\n' : 3,  \n'\\n        (Delirium #2)\\n' : 4,  \n'\\n        (Maximum Ride #1)\\n' : 5,  \n'\\n        (Harry Hole #7)\\n' : 6,  \n'\\n        (Wonder #1)\\n' : 7,  \n'\\n        (All Souls  #1)\\n': 8,\n'\\n        (Odd Thomas #1)\\n': 9,\n'\\n        (MaddAddam #2)\\n': 10,\n'\\n        (Matched #1)\\n': 11,\n'\\n        (The Infernal Devices #2)\\n': 12,\n'\\n        (Fifty Shades #1)\\n': 13,}\n}\nreplace_map\n#necesito las etiquetas o labels de la variable .tolist() para hacer listas\n#El m\u00e9todo astype() para cambiar el tipo de variable\nlabels = df_filtrado['series'].astype('category').cat.categories.tolist()\n\nreplace_map_comp = {'series': {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\nreplace_map_comp\n\ndf_filtradovari = df_filtrado.copy()\n#Aplicamos el m\u00e9todo de reemplazar replace()\ndf_filtradovari.replace(replace_map_comp,inplace = True)\n\ndf_filtradovari","05ba5e21":"df_filtradovari.dtypes","f7e9477f":"Series = df_filtradovari['series'].value_counts()\nprint(Series.index)","98200ea2":"df_filtradovari[df_filtradovari['series']>2]\nprint(df_filtradovari)","08d3ea9c":"df_filtradovari.loc[df_filtradovari.series != 1,'series']= 0\n\ndf_filtradovari","cde512ca":"df_filtradovari.dtypes","d711417a":"lenguage = df_filtradovari['lang'].value_counts()\nprint(lenguage.index)\nsns.barplot(lenguage.index,lenguage.values)\nplt.title('Lenguage',fontsize = 30)\nplt.ylabel('Lenguage')\nplt.xlabel('#books')","7abb3893":"print(lenguage.index)\n","2fb990be":"#la primera se llama reemplazar valores\n#Creado un diccionario con equivalencias\nreplace_map = {'lang':\n{'English' : 1,     \n'French' : 2,  \n'German' : 3,  \n'Spanish' : 4,  \n'Dutch' : 0,  \n'Polish' : 6,   \n'Finnish' : 7,   \n'Swedish' : 8,   \n'Italian' : 9,   \n'Portuguese' : 10,   \n'Arabic' : 11,\n'Danish' : 12,   \n'Norwegian' : 13,   \n'Greek, Modern (1453-)' : 14,   \n'Russian' : 15,\n'Catalan' : 16,   \n'Valencian' : 17,   \n'Persian' : 18,   \n'Multiple languages' : 19,\n'Latvian' : 20,   \n'Ukrainian' : 21,}\n}\nreplace_map\n#necesito las etiquetas o labels de la variable .tolist() para hacer listas\n#El m\u00e9todo astype() para cambiar el tipo de variable\nlabels = df_filtradovari['lang'].astype('category').cat.categories.tolist()\n\nreplace_map_comp = {'lang': {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\nreplace_map_comp\n\ndf_filtradovariables = df_filtradovari.copy()\n#Aplicamos el m\u00e9todo de reemplazar replace()\ndf_filtradovariables.replace(replace_map_comp,inplace = True)\n\ndf_filtradovariables","ae4e49b6":"df_filtradovariables = df_filtradovariables[df_filtradovariables.lang == 1]\ndf_filtradovariables.shape","c019f9df":"English = df_filtradovariables['lang'].value_counts()\nprint(English.index)\nsns.barplot(English.index,English.values)\nplt.title('Lenguage',fontsize = 30)\nplt.ylabel('Lenguage')\nplt.xlabel('#books')","9afcd684":"pd.unique(df_filtradovariables['lang'])","8ca16151":"df_filtradovariables","30a81671":"Genre = df_filtradovariables['genre'].value_counts()\nprint(Genre.index)","13594301":"df_filtradogen = df_filtradovariables['genre'].str.split(',', expand= True).iloc[:,1]","180da985":"df_filtradovariables['genre'] = df_filtradogen","664fe2ed":"df_filtradovariables","0a31b3e7":"Genre = df_filtradovariables['genre'].value_counts()\nprint(Genre.index)","d6058733":"df_genre = df_filtradovariables","8c58476e":"Rate = df_genre['rate'].value_counts()\nprint(Rate.index)","71130b89":"df_int = df_genre.astype({\"rate\": int})\n","30fd3d7e":"df_int.dtypes","1b61f8b3":"df_int","624e5437":"df_filtradovariables = df_int","822dec38":"df_filtradovariables['award'] = df_filtradovariables['award'].apply(lambda x : len(str(x).split(',')))\ndf_filtradovariables","8ad1645d":"df_genre = df_filtradovariables","8c21befb":"df_filtradovariables.dtypes","01d2b29a":"df_filtradovariables = df_genre[['series','genre','rate','award']]\ndf_filtradovariables","eb296649":"\n\ndf_filtradovariables.genre =df_filtradovariables.genre.astype('category')\n\n\ndf_filtradovariables.info()","449015fd":"df_filtradovariables.head()","bb34ece4":"df_filtradovariables.dtypes","93675d2c":"df_datos2 = df_filtradovariables.copy()\n\n\ndatos = pd.get_dummies(df_filtradovariables, columns=['genre','rate'],prefix=['Genre','Rate'])","70b4c5a0":"datos.head()","b1f49193":"cor = datos.corr()\ncor","9b6d64eb":"import statsmodels.api as sm\n\ny=datos['Rate_4']\nX=datos.iloc[:,[2,3,4,5,6,9,10,11,12,13,14,15,16,17,18]]","db998df0":"import statsmodels.api as sm\ny =  datos['Rate_4']\nX =  datos.iloc[:,[2,3,4,5,6,9,10,11,12,13,14,15,16,17,18]]\nlogit_model=sm.Logit(y,X)\nresult=logit_model.fit()\n\nprint(result.summary())\n","a1f0cdd6":"import statsmodels.api as sm\n\ny=datos['series']\nX=datos.iloc[:,[2,3,4,5,6,9,10,11,12,13,14,15,16,17,18]]","4422f44b":"import statsmodels.api as sm\ny =  datos['series']\nX =  datos.iloc[:,[2,3,4,5,6,9,10,11,12,13,14,15,16,17,18]]\nlogit_model=sm.Logit(y,X)\nresult=logit_model.fit()\n\nprint(result.summary())\n","82a42d80":"datos.dtypes","4effed4b":"\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\ny =  datos['Rate_4']\nX =  datos.iloc[:,[2,3,4,5,6,9,10,11,12,13,14,15,16,17,18]]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.1,random_state =0)","2949ec5d":"from sklearn.linear_model import LogisticRegression\nmodelo = LogisticRegression(random_state=0, solver='lbfgs',fit_intercept=False, max_iter=100000).fit(X_train,y_train)","0f1ac2f7":"print(\"Error de entrenamiento\",modelo.score(X_train,y_train))\nprint(\"Error de prueba o test\",modelo.score(X_test,y_test))","86227f44":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(modelo.predict(X_train),y_train))","a095ea04":"from sklearn.svm import SVC","f2e06740":"modelo = SVC()","5f777547":"modelo.fit(X_train,y_train)\n","7bf58f25":"prediccion = modelo.predict(X_test)\n","cd591eff":"print(confusion_matrix(modelo.predict(X_test),y_test))","59dcfa49":"modelo.score(X_train,y_train)","340489e1":"df_int","bead6adb":"#Cargar todos los paquetes de visualizaci\u00f3n\nimport pandas as pd\nimport numpy as np\nfrom scipy.spatial import distance\nfrom scipy.sparse import csr_matrix\nfrom scipy.sparse import issparse\nimport matplotlib.pyplot as plt\nimport seaborn as sb\n%matplotlib inline\n#Plotly\nimport plotly.express as px\nimport statsmodels.api as sample_data\nimport matplotlib.font_manager","d5484540":"px.scatter_3d(df_int,x='series',y='rate',z='num_of_page',color='author')","f2a1de2c":"df_genre","f5ddb1b5":"px.scatter_3d(df_genre,x='series',y='rate',z='num_of_page',color='author')","8f4cf80b":"df_genre = df_genre[['id','title','author','series','genre','publisher','review_count','rating_count','rate','award']]\ndf_genre","33341e4d":"df_genre.dtypes","3538e240":"df_genre.series = df_genre.series.astype('float')\ndf_genre.award = df_genre.award.astype('float')","31fffdf5":"#La relaci\u00f3n entre las variables num\u00e9ricas \nsb.pairplot(df_genre,vars=['series','rate','award'],kind='scatter',hue='genre')","c93300bd":"#Aplicamos el m\u00e9todo de normalizaci\u00f3n\nfrom sklearn.preprocessing import  normalize\n#Guardamos una copia de los datos\ndf_float = df_genre\n#Borramos columnas que no son n\u00famero\ndf_float = df_float.drop(['id','title','author','genre','publisher','review_count','rating_count'], axis=1)\n\ndf_float = normalize(df_float)\nnombre_columnas = ['series','rate','award']\n#transformo el dataset normalizado en un dataframe con el nombre original de sus columnas\ndf_float = pd.DataFrame(df_float,columns=nombre_columnas)\ndf_float\n","d23d7f95":"df_float.describe()","1f27d193":"#Importamos el paquete de clustering\nimport scipy.cluster.hierarchy as shc \n#Vamos a aplicar el m\u00e9todo de clustering al conjunto normalizado\n#Definimos el tipo de enlace y el m\u00e9todo\nagrupamiento = shc.linkage(df_float[['series','rate','award']],method='ward', metric='euclidean')\n\n#Utilizaremos el dendograma para determinar el n\u00famero de grupos (clustering jerarquico)\nplt.figure(figsize=(12,8))\nplt.title(\"Dendograma\")\ndendograma = shc.dendrogram(agrupamiento)","f1a016b8":"from sklearn.cluster import AgglomerativeClustering\n#Vamos a hacer nuevamente el clustering pero sin grafico\n#Definimos el tipo de clustering\ncluster = AgglomerativeClustering(n_clusters=2,affinity='euclidean', linkage='ward')\n\n#para identificar los grupso vamos a \"predecir\" a cual grupo pertenece cada observaci\u00f3n\ncluster.fit_predict(df_float[['series','rate','award']])\n#Una vez definimos el clu grupo al cual pertenece cada observaci\u00f3n, lo guardamos como una variable\ndf_float['Cluster']=cluster.labels_\n\ndf_genre['Cluster']=cluster.labels_","43d6da4e":"px.scatter_3d(df_float,x='series',y='rate',z='award',color='Cluster')","abf2dc0e":"sb.pairplot(df_float,vars=['series','rate','award'],kind='scatter',hue='Cluster')","d19d14a7":"df_float['Cluster'].value_counts()","1ac75d50":"df_genre['id'] = df_float['Cluster']","59a499c6":"df_genre","e35d7da4":"df_genre.head(30)\ndf_genre[df_genre[\"Cluster\"] == 1]","a49458e5":"df_genre.head(30)\ndf_genre[df_genre[\"Cluster\"] == 0]","e7e2be5e":"df_genre.describe()\ndf_cluster0 =df_genre[df_genre[\"Cluster\"] == 0]","a5e7a4c8":"df_cluster0 = df_cluster0[['series','rate','award']]\ndf_cluster0.describe()","ef4516c6":"df_genre.describe()\ndf_cluster1 =df_genre[df_genre[\"Cluster\"] == 1]\ndf_cluster1 = df_cluster1[['series','rate','award']]\ndf_cluster1.describe()","74815f91":"# LANG","70978c6a":"# CLUSTER","37e3c929":"# Clean Data","2a693336":"# AWARD","e3f00a95":"# GENRE","efd4ac22":"# SERIES","e7b5de0e":"# REGRESION LOGISTICA","cc310f4e":"pd.unique(df_filtradovariables['author']).shape","4cf4935b":"# RATE","f369bf16":"df_int.loc[df_int.rate>3,'rate']= 1\ndf_int.loc[df_int.rate<3,'rate']= 0\nprint(df_int)","bfe98533":"df_llenado.loc[df_llenado.series ! 1,'series']= 0"}}