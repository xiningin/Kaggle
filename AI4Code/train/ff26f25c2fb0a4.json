{"cell_type":{"00d7ed6b":"code","d34970b6":"code","a1e6c7ba":"code","26b3c94b":"code","5968e462":"code","372bfa29":"code","63aa34c9":"code","beae3c92":"code","2b5c2aa5":"code","4445825d":"code","6715e0b4":"code","d4b3c2d7":"code","a33766ac":"markdown"},"source":{"00d7ed6b":"import os\nprint(os.listdir(\"..\/input\"))\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport PIL\nfrom PIL import Image\nfrom keras.preprocessing.image import ImageDataGenerator","d34970b6":"image=\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\/person1011_bacteria_2942.jpeg\"\nPIL.Image.open(image)","a1e6c7ba":"image=\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\/IM-0151-0001.jpeg\"\nPIL.Image.open(image)","26b3c94b":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","5968e462":"training_dir=\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/\"\ntraining_generator=ImageDataGenerator(rescale=1\/255,featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.2, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip = False,  # randomly flip images\n        vertical_flip=False)\ntrain_generator=training_generator.flow_from_directory(training_dir,target_size=(200,200),batch_size=4,class_mode='binary')","372bfa29":"validation_dir=\"..\/input\/chest-xray-pneumonia\/chest_xray\/val\/\"\nvalidation_generator=ImageDataGenerator(rescale=1\/255)\nval_generator=validation_generator.flow_from_directory(validation_dir,target_size=(200,200),batch_size=4,class_mode='binary')","63aa34c9":"test_dir=\"..\/input\/chest-xray-pneumonia\/chest_xray\/test\/\"\ntest_generator=ImageDataGenerator(rescale=1\/255)\ntest_generator=test_generator.flow_from_directory(test_dir,target_size=(200,200),batch_size=16,class_mode='binary')","beae3c92":"model=tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32,(3,3),input_shape=(200,200,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(256,(3,3),activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(256,activation='relu'),\n    tf.keras.layers.Dense(1,activation='sigmoid')\n    \n])","2b5c2aa5":"model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss='binary_crossentropy',metrics=['acc'])","4445825d":"history = model.fit_generator(train_generator,\n            validation_data = val_generator,\n            \n            epochs = 30,\n            \n            verbose = 1)","6715e0b4":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()","d4b3c2d7":"print(\"Loss of the model is - \" , model.evaluate(test_generator)[0]*100 , \"%\")\nprint(\"Accuracy of the model is - \" , model.evaluate(test_generator)[1]*100 , \"%\")","a33766ac":"Convolutional Neural Networks (CNNs), or ConvNets, are neural networks that are commonly used for image and audio recognition and classification. \n\nLike all common neural networks, CNNs have neurons with adjustable weights and biases. Normal neural networks are fully connected, meaning that every single neuron is connected to every neuron from the previous layer. However, CNNs are not fully connected like normal neural networks. This would be too computationally expensive and is simply not needed to achieve the desired results. Using a fully connected neural network would not be very efficient when dealing with image data with large input sizes."}}