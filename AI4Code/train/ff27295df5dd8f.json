{"cell_type":{"eb501918":"code","b672c1ae":"code","a325c027":"code","5e849f65":"code","90a3163d":"code","1c3908d5":"code","6a1f818f":"code","1d6e4fd8":"code","eb9ec42d":"code","7ee55650":"code","25c0d7b7":"code","eea7c388":"markdown","0a5e132e":"markdown","f83ac933":"markdown","997b09e7":"markdown","7ca35a08":"markdown"},"source":{"eb501918":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b672c1ae":"import torch\nimport numpy as np\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler","a325c027":"num_workers = 0\nbatch_size = 20\nvalid_size = 0.2\n\ntransform = transforms.ToTensor()\n\ntrain_data = datasets.MNIST(root='data', train=True,\n                                   download=True, transform=transform)\ntest_data = datasets.MNIST(root='data', train=False,\n                                  download=True, transform=transform)\n\nnum_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n    sampler=train_sampler, num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n    sampler=valid_sampler, num_workers=num_workers)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n    num_workers=num_workers)","5e849f65":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy()\n\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20\/2, idx+1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n    ax.set_title(str(labels[idx].item()))","90a3163d":"img = np.squeeze(images[1])\n\nfig = plt.figure(figsize = (12,12)) \nax = fig.add_subplot(111)\nax.imshow(img, cmap='gray')\nwidth, height = img.shape\nthresh = img.max()\/2.5\nfor x in range(width):\n    for y in range(height):\n        val = round(img[x][y],2) if img[x][y] !=0 else 0\n        ax.annotate(str(val), xy=(y,x),\n                    horizontalalignment='center',\n                    verticalalignment='center',\n                    color='white' if img[x][y]<thresh else 'black')","1c3908d5":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n  \n        hidden_1 = 512\n        hidden_2 = 512\n       \n        self.fc1 = nn.Linear(28 * 28, hidden_1)\n\n        self.fc2 = nn.Linear(hidden_1, hidden_2)\n\n        self.fc3 = nn.Linear(hidden_2, 10)\n \n        self.dropout = nn.Dropout(0.2)\n\n    def forward(self, x):\n        \n        x = x.view(-1, 28 * 28)\n       \n        x = F.relu(self.fc1(x))\n        \n        x = self.dropout(x)\n       \n        x = F.relu(self.fc2(x))\n        \n        x = self.dropout(x)\n        \n        x = self.fc3(x)\n        return x\n\nmodel = Net()\nprint(model)","6a1f818f":"criterion = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)","1d6e4fd8":"epochs = 50\n\nvalid_loss_min = np.Inf\n\nfor epoch in range(epochs):\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    model.train()\n    for data, target in train_loader:\n        optimizer.zero_grad()\n        output = model(data)\n        \n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()*data.size(0)\n        \n    model.eval()\n    for data, target in valid_loader:\n        output = model(data)\n        loss = criterion(output, target)\n        valid_loss += loss.item()*data.size(0)\n        \n    train_loss = train_loss\/len(train_loader.sampler)\n    valid_loss = valid_loss\/len(valid_loader.sampler)\n    \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch+1, train_loss, valid_loss))\n    \n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format( valid_loss_min, valid_loss))\n        torch.save(model.state_dict(), 'model.pt')\n        valid_loss_min = valid_loss","eb9ec42d":"model.load_state_dict(torch.load('model.pt'))","7ee55650":"test_loss = 0.0\nclass_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\n\nmodel.eval()\n\nfor data, target in test_loader:\n    output = model(data)\n    loss = criterion(output, target)\n    test_loss += loss.item()*data.size(0)\n    _, pred = torch.max(output, 1)\n    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n    for i in range(len(target)):\n        label = target.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n\ntest_loss = test_loss\/len(test_loader.sampler)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(10):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d\/%2d)' % (str(i), 100 * class_correct[i] \/ class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N\/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d\/%2d)' % ( 100. * np.sum(class_correct) \/ np.sum(class_total), np.sum(class_correct), np.sum(class_total)))","25c0d7b7":"dataiter = iter(test_loader)\nimages, labels = dataiter.next()\noutput = model(images)\n_, preds = torch.max(output, 1)\nimages = images.numpy()\n\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20\/2, idx+1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n    ax.set_title(\"{} ({})\".format(str(preds[idx].item()), str(labels[idx].item())), color=(\"green\" if preds[idx]==labels[idx] else \"red\"))","eea7c388":"## Visualizing a Batch Of Training Data:","0a5e132e":"## Visualizing Sample Test Results","f83ac933":"## Testing the Network:","997b09e7":"Loading and Visualizing the Data:","7ca35a08":"## Defining the Network Architecture: "}}