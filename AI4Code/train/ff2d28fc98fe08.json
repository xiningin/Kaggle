{"cell_type":{"9f05fd7d":"code","aa4a0f6a":"code","d4211dbe":"code","f77a8bb2":"code","ee82a791":"code","82346be9":"code","9830dbde":"code","14c7b014":"code","8bf47f94":"code","3da8161b":"code","3e0b504c":"code","74d76f1d":"code","80f6ebad":"code","4e89a9ad":"code","68117721":"code","62dbb69c":"code","a0da8f89":"code","98195342":"code","1325debe":"code","a5ab92ef":"code","5596cff5":"code","46b0697d":"code","c9fe1184":"code","4dc882ce":"code","431ea0e5":"code","bbf9c29c":"code","32c2b18d":"code","4cd899d0":"code","285a19ed":"code","5f4a480b":"code","66174cdd":"code","22375ad6":"markdown","02f4ff41":"markdown","eef1b10c":"markdown","997f85e0":"markdown","ffa2bd51":"markdown","7d8df26f":"markdown","dcd18908":"markdown","43ed9f9d":"markdown","57bf050f":"markdown","4ed11eeb":"markdown","1f87443e":"markdown"},"source":{"9f05fd7d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aa4a0f6a":"xtr_data=pd.read_csv('..\/input\/ecommerce-shipping-data-competition-form\/X_train.csv')\nxte_data=pd.read_csv('..\/input\/ecommerce-shipping-data-competition-form\/X_test.csv')\nytr_data=pd.read_csv('..\/input\/ecommerce-shipping-data-competition-form\/y_train.csv')","d4211dbe":"yte_data=pd.read_csv('..\/input\/ecommerce-shipping-data-competition-form\/test_label\/y_test.csv')","f77a8bb2":"xtr_data.head()","ee82a791":"xte_data.head()","82346be9":"ytr_data.head()","9830dbde":"xtr_data.describe()","14c7b014":"xtr_data['Warehouse_block'].value_counts()","8bf47f94":"sns.countplot(x=xtr_data['Warehouse_block'])","3da8161b":"fig,ax=plt.subplots(figsize=(8,5))\nxtr_data.groupby(['Warehouse_block','Mode_of_Shipment'])['Prior_purchases'].sum().plot(kind='bar')","3e0b504c":"xtr_data=pd.merge(xtr_data,ytr_data, on='ID',how='outer')\nxte_data=pd.merge(xte_data,yte_data, on='ID',how='outer')","74d76f1d":"xtr_data","80f6ebad":"xtr_data.groupby(['Gender','Reached.on.Time_Y.N'])['Reached.on.Time_Y.N'].count().plot(kind='bar')","4e89a9ad":"col_list=[]\nfor column in xtr_data:\n    if xtr_data[column].dtype=='O':\n        print(column,xtr_data[column].dtype)\n        col_list.append(column)","68117721":"for i in col_list:\n    print(xtr_data[i].value_counts())","62dbb69c":"xtr_data['Customer_care_calls']=xtr_data['Customer_care_calls'].replace('$7',7)\nxte_data['Customer_care_calls']=xte_data['Customer_care_calls'].replace('$7',7)","a0da8f89":"xtr_data=pd.get_dummies(xtr_data,columns=col_list,drop_first=True)\nxte_data=pd.get_dummies(xte_data,columns=col_list,drop_first=True)","98195342":"from sklearn.feature_selection import mutual_info_classif\nmi_score=mutual_info_classif(xtr_data.drop('Reached.on.Time_Y.N',axis=1),xtr_data['Reached.on.Time_Y.N'])\nmi_score=pd.Series(mi_score*100,index=xtr_data.drop('Reached.on.Time_Y.N',axis=1).columns)\nmi_score=mi_score.sort_values(ascending=False)\nmi_score","1325debe":"top_fea=mi_score.index[:3]\ntop_fea","a5ab92ef":"xtr_data.columns","5596cff5":"xte_data.columns","46b0697d":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler \nxtr_sc=StandardScaler().fit_transform(xtr_data[top_fea])\nxte_sc=StandardScaler().fit_transform(xte_data[top_fea])\nxtr,xval,ytr,yval=train_test_split(xtr_sc,xtr_data['Reached.on.Time_Y.N'],random_state=108,test_size=0.27)","c9fe1184":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, callbacks","4dc882ce":"model=keras.Sequential([\n    layers.Dense(164,activation='relu',input_shape=(3,)),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    layers.Dense(228,activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(248,activation='relu'),\n    layers.Dropout(0.3),\n    layers.Dense(268,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    layers.Dense(168,activation='relu'),\n    layers.Dropout(0.3),\n    layers.Dense(94,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.32),\n    layers.Dense(1,activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics='accuracy')\n\ncall=callbacks.EarlyStopping(patience=12,min_delta=0.0001,restore_best_weights=True)\nhistory=model.fit(xtr,ytr,batch_size=128,epochs=45,validation_data=(xval,yval),callbacks=call)","431ea0e5":"his=pd.DataFrame(history.history)","bbf9c29c":"his.head()","32c2b18d":"his.loc[:,['loss','val_loss']].plot()","4cd899d0":"his.loc[:,['accuracy','val_accuracy']].plot()","285a19ed":"yte_data.head()","5f4a480b":"yte_data=yte_data.set_index('ID')","66174cdd":"model.evaluate(xte_sc,yte_data)","22375ad6":"# Preparing data to be used in a model","02f4ff41":"## Selecting only top features to be a part of model","eef1b10c":"# Guide to prepare dataset:\n\n###  Explore the dataset *Check shape* of dataset\n###  Look for the object\/cat datatype among the columns\n###  Fill in all of the Null Values\n###  Select the best features for model-building\n###  Normalize the features\n###  Split the datasets\n###  Build the Neural-Net(use 'softmax' activation for last layer when doing multi-class classification)\n###  Compile the model\n###  Fit the model\n###  Evaluate!","997f85e0":"## Building the model","ffa2bd51":"# Handling Categorical data","7d8df26f":"## Splitting the data","dcd18908":"## Importing datasets","43ed9f9d":"# Exploring the datasets","57bf050f":"# Visualizing the learning","4ed11eeb":"## Visualizing the distribution and trend in data","1f87443e":"# Evaluating the result"}}