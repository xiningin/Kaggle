{"cell_type":{"5b4742ef":"code","e0ebf255":"code","01d83339":"code","dcd0dbd5":"code","14f98814":"code","00830435":"code","c6cde5dd":"code","9077f760":"code","c3569e4b":"code","ebdcd10b":"code","e6debce9":"code","a73f23d1":"code","440c54cd":"code","d52331e0":"code","b003e0c2":"code","59b939de":"code","d6058689":"code","608eec90":"code","c2e0e70d":"code","78bc3e31":"code","a736ea55":"code","52e86db9":"code","a26f16fa":"code","2f1ab267":"code","6fa220d1":"code","06a2708e":"code","6b2d8daf":"code","00532385":"code","d93b767b":"code","9ec32c3a":"code","c336466e":"code","e28dceb8":"markdown","4edbdb6a":"markdown","a26e12e4":"markdown","4218fd15":"markdown","dd93a5cb":"markdown","14448ed1":"markdown","bac53485":"markdown","6acde320":"markdown","22620599":"markdown","de496962":"markdown","edb383e7":"markdown","0426fcba":"markdown","50c08e93":"markdown","10973c94":"markdown","0c7c2092":"markdown"},"source":{"5b4742ef":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np              # linear algebra\nimport pandas as pd             # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os                       # files handling\nimport matplotlib.pyplot as plt # plotting & dataviz\nimport h2o                      # ML platform\n\n%config Completer.use_jedi = False\n%matplotlib inline\nplt.close('all')                # ensure previous graphs are closed\npd.set_option('display.max_columns', False)  # display all columns of dataframe\n\nprint('Ok pour les imports, version de H2O={}'.format(h2o.__version__))","e0ebf255":"# List files in input dir\nprint('Fichiers pr\u00e9sents :')\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Load datafile in pandas' DataFrame\ndfWine = pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\nprint('\\nTaille de la base : {}'.format(dfWine.shape))\nprint('\\nExtrait :')\ndfWine.sample(5)","01d83339":"# Trace 'quality' distribution\nbins = np.arange(12)\nplt.rcParams['figure.figsize'] = [14, 7]\nplt.title(\"Distribution de 'quality'\", fontsize=14)\nplt.hist(dfWine['quality'], bins=bins, density=True, align='left', color='darkslateblue')\n_ = plt.xticks(bins[:-1])\n_ = plt.vlines(x=6.5, ymin=0, ymax=0.45, linewidth=3, color='orange')","dcd0dbd5":"# Plot explanatory variables distributions\nlstXVars = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide',\n            'density', 'pH', 'sulphates', 'alcohol']\nplt.rcParams['figure.figsize'] = [20, 13]\ncolors = plt.rcParams['axes.prop_cycle']()\nfig, axs = plt.subplots(3, 4)\nfor i, xVar in enumerate(lstXVars):\n    plti = int(i\/4)\n    pltj = i % 4\n    c = next(colors)['color']\n    axs[plti, pltj].hist(dfWine[xVar], density=True, align='left', color=c)\n    axs[plti, pltj].set_title(f'- {xVar} -')","14f98814":"# We need to instantiate H2O server\nh2o.init()","00830435":"# Let's do some preprocessing\n# Define 'good' wine : 'quality' >= 7\ndfWine.loc[:, 'good'] = dfWine.loc[:, 'quality'].apply(lambda x: 1 if x >= 7 else 0)\nh2oWine = h2o.H2OFrame(dfWine)                                     # Convert pandas dataframe to h2o h2oframe\nh2oWine['good'] = h2oWine['good'].asfactor()                       # Target is binomial 0\/1\nwineTrain, wineTest = h2oWine.split_frame(ratios=[0.7], seed=653)  # Split train, test\nprint('\\nExtrait de la base d\\'entra\u00eenement :')\nwineTrain.head(5)","c6cde5dd":"wineTest.head(5)","9077f760":"dir(h2o.estimators)","c3569e4b":"%%time\n# Single tree can be modelised with a specific parametrization of GradientBoosting\nfrom h2o.estimators import H2OGradientBoostingEstimator\n# Instanciate GBM estimator with 1 tree = decision tree, each column\/row having prob=1 to be selected\nwineModelSingleTree = H2OGradientBoostingEstimator(ntrees = 1, min_rows = 1, sample_rate = 1,            \n                                                   col_sample_rate = 1, max_depth = 5, seed = 7575)\n# And train the model\nwineModelSingleTree.train(training_frame=wineTrain, y='good', x=lstXVars, validation_frame=wineTest)\n\n# Performance on test database\nwineModelSingleTree.model_performance(wineTest)","ebdcd10b":"# Export tree model in mojo format\nwineModelSingleTree.download_mojo('.\/wineModelSingleTreeMojo.zip')\n# Download to windows and produce graph","e6debce9":"# Predict value and node (leaf) on test database\nwineModelSingleTreePred1 = wineModelSingleTree.predict(wineTest)\nwineModelSingleTreePred2 = wineModelSingleTree.predict_leaf_node_assignment(wineTest, type='NodeID')\n\n# Back to pandas dataframe to perform some calculations\ndfWinePred = wineModelSingleTreePred1.as_data_frame()[['predict', 'p1']]\ndfWinePred['leaf'] = wineModelSingleTreePred2['T1.C1'].as_data_frame()\ndfWinePred['real'] = wineTest['good'].as_data_frame()","a73f23d1":"dfWinePred","440c54cd":"wineModelSingleTree.model_performance(wineTest).plot()","d52331e0":"perf = wineModelSingleTree.model_performance(wineTest)\nfpr = perf.fprs\ntpr = perf.tprs\n\nimport matplotlib.pyplot as plt\n\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='blue', lw=lw, label='ROC curve')\nplt.plot([0, 1], [0, 1], color='red', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.05])\nplt.ylim([0.0, 1.05])\nplt.legend(loc=\"lower right\")\nplt.show()","b003e0c2":"%%time\n# GLM\nfrom h2o.estimators import H2OGeneralizedLinearEstimator\n# Binomial estimation -> logistic link\nwineModelGLM = H2OGeneralizedLinearEstimator(family='binomial', lambda_ = 0, compute_p_values = True)\n# And train the model\nwineModelGLM.train(training_frame=wineTrain, y='good', x=lstXVars, validation_frame=wineTest)\n\n# Performance on test database\nwineModelGLM.model_performance(wineTest)","59b939de":"wineModelGLMPenalized.std_coef_plot()\nprint(wineModelGLM._model_json['output']['coefficients_table'])","d6058689":"wineModelGLM.model_performance(wineTest).plot()","608eec90":"%%time\n# GLM\nfrom h2o.estimators import H2OGeneralizedLinearEstimator\nfrom h2o.grid import H2OGridSearch\n# Binomial estimation -> logistic link\n# Perform grid search for alpha, and let H2O find best lambda each time\n# Train and validate a cartesian grid of GLMs\nparamsGLM = {'alpha': [0.0, 0.001, 0.01, 0.1, 0.5,\n                       0.9, 0.99, 0.999, 1.0]}\ngridGLM = H2OGridSearch(model=H2OGeneralizedLinearEstimator,\n                        grid_id='glm_grid1',\n                        hyper_params=paramsGLM)\ngridGLM.train(family='binomial', training_frame=wineTrain, y='good', x=lstXVars,\n              validation_frame=wineTest, lambda_search=True)","c2e0e70d":"# Get the grid results, sorted by validation AUC\ngridGLMPerf = gridGLM.get_grid(sort_by='auc', decreasing=True)\n\n# Grab the top GLM model, chosen by validation AUC\nwineModelGLMPenalized = gridGLMPerf.models[0]\n\n# Now let's evaluate the model performance on a test set\n# so we get an honest estimate of top model performance\nwineModelGLMPenalized.model_performance(wineTest)","78bc3e31":"wineModelGLMPenalized.std_coef_plot()\nprint(wineModelGLMPenalized._model_json['output']['coefficients_table'])","a736ea55":"wineModelGLMPenalized.model_performance(wineTest).plot()","52e86db9":"%%time\n# Random Forest\nfrom h2o.estimators import H2ORandomForestEstimator\n\nwineModelDRF = H2ORandomForestEstimator(ntrees=10, max_depth=5, min_rows=6,\n                                        calibrate_model=True,\n                                        calibration_frame=wineTest,\n                                        binomial_double_trees=True)\nwineModelDRF.train(training_frame=wineTrain, y='good', x=lstXVars, validation_frame=wineTest)","a26f16fa":"wineModelDRF.model_performance(wineTest).plot()","2f1ab267":"%%time\n# Gradient Boosting\nfrom h2o.estimators import H2OGradientBoostingEstimator\n\nwineModelGBM = H2OGradientBoostingEstimator(nfolds=5, seed=1111,\n                                            keep_cross_validation_predictions = True)\nwineModelGBM.train(training_frame=wineTrain, y='good', x=lstXVars, validation_frame=wineTest)","6fa220d1":"wineModelGBM.model_performance(wineTest).plot()","06a2708e":"%%time\n# XGBoost\nfrom h2o.estimators import H2OXGBoostEstimator\n\nwineModelXGBM = H2OXGBoostEstimator(booster='dart', normalize_type='tree', seed=1234)\nwineModelXGBM.train(training_frame=wineTrain, y='good', x=lstXVars, validation_frame=wineTest)","6b2d8daf":"wineModelXGBM.model_performance(wineTest).plot()","00532385":"%%time\n# AutoML\nfrom h2o.automl import H2OAutoML\n\nwineModelAutoML = H2OAutoML(max_models=20, max_runtime_secs=120, seed=3231)\nwineModelAutoML.train(training_frame=wineTrain, y='good', x=lstXVars)\n\nlb = wineModelAutoML.leaderboard\nlb.head(rows=lb.nrows)","d93b767b":"wineModelAutoML.leader.model_performance(wineTest)","9ec32c3a":"wineModelAutoML.leader.model_performance(wineTest).plot()","c336466e":"# Export best AutoML model in mojo format\nwineModelAutoML.leader.download_mojo('.\/wineModelAutoMLMojo.zip')\n# Download to windows and produce shapash","e28dceb8":"### Test different models","4edbdb6a":"### Import datafile : red wine quality\n### File found here : https:\/\/www.kaggle.com\/uciml\/red-wine-quality-cortez-et-al-2009\n\nContains :\n- fixed acidity : most acids involved with wine or fixed or nonvolatile (do not evaporate readily)\n- volatile acidity : the amount of acetic acid in wine, which at too high of levels can lead to an unpleasant, vinegar taste\n- citric acid : found in small quantities, citric acid can add 'freshness' and flavor to wines\n- residual sugar : the amount of sugar remaining after fermentation stops, it's rare to find wines with less than 1 gram\/liter and wines with greater than 45 grams\/liter are considered sweet\n- chlorides : the amount of salt in the wine\n- free sulfur dioxide : the free form of SO2 exists in equilibrium between molecular SO2 (as a dissolved gas) and bisulfite ion; it prevents microbial growth and the oxidation of wine\n- total sulfur dioxide : amount of free and bound forms of S02; in low concentrations, SO2 is mostly undetectable in wine, but at free SO2 concentrations over 50 ppm, SO2 becomes evident in the nose and taste of wine\n- density : the density of water is close to that of water depending on the percent alcohol and sugar content\n- pH : describes how acidic or basic a wine is on a scale from 0 (very acidic) to 14 (very basic); most wines are between 3-4 on the pH scale\n- sulphates : a wine additive which can contribute to sulfur dioxide gas (S02) levels, wich acts as an antimicrobial and antioxidant\n- alcohol : amount of alcohol present\n- quality : median value of estimated qualities, range from 0 (very poor) to 10 (excellent)","a26e12e4":"### **eXtrem Gradient Boosting**","4218fd15":"### Model 1 : simple tree","dd93a5cb":"### **Penalized GLM**","14448ed1":"### Apply model on test database","bac53485":"### Trace ROC curve","6acde320":"### Export model and plot the tree\ncf : https:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-genmodel\/javadoc\/overview-summary.html#viewing-a-mojo\n- install graphviz : https:\/\/forum.graphviz.org\/t\/new-simplified-installation-procedure-on-windows\/224\n- download h2o.jar : https:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-zizler\/3\/index.html\n- generate mojo version of the model\n- download it locally\n- run : java -cp h2o.jar hex.genmodel.tools.PrintMojo --tree 0 -o model.gv --title \"Wine Single Tree Model\" -f 14 -d 2 -i wineModelSingleTreeMojo.zip --detail\n- run : dot -Tpng model.gv -o modelv1.png","22620599":"### **Gradient Boosting**","de496962":"### Explore and reshape variables","edb383e7":"### Import necessary stuff","0426fcba":"### **GLM**","50c08e93":"### **Random Forest**","10973c94":"# IRIAF M2 - Qualit\u00e9 des mod\u00e8les","0c7c2092":"## What if we don't know what model to choose ? **AutoML**"}}