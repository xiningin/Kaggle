{"cell_type":{"b9343244":"code","beb4e666":"code","e73c7b83":"code","b6ff1c50":"code","ee8c2453":"code","389ba61c":"code","4835d22b":"code","1e000137":"code","f46280c5":"code","76c8f152":"code","e2878c6f":"code","5565d00e":"code","c29dc240":"code","08317d25":"code","21a48914":"code","3dedbb03":"code","55893dd2":"code","ff6ce3d3":"code","1cf54413":"code","d6ae5ad1":"code","6f315580":"code","d3759f1e":"code","6ea15fa6":"code","7aec6907":"code","f98b08c3":"code","e635704f":"code","420ba2e4":"code","79009f93":"code","d068f99c":"code","2c27f86c":"code","61316195":"code","1c464ad2":"code","d4ca40e8":"code","d5bf79c7":"code","8813c36d":"code","6e880b50":"code","d0c94da0":"code","37848df3":"code","6c28582d":"code","6ad5844e":"code","63845d91":"code","5a23fcf0":"code","cb972c78":"code","1bcd6d06":"code","264831b0":"code","26ea2c36":"code","a200cb59":"code","01fde48e":"code","c5556cd8":"code","c78bb6fb":"code","cdff22ef":"code","3aba5205":"code","405cd23d":"markdown","8fecf942":"markdown","34b81ce7":"markdown","a3a60f62":"markdown","1b2e309a":"markdown"},"source":{"b9343244":"#importing our libraries\nimport pandas as pd\nimport numpy as np\nimport nltk\nimport math\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nnltk.download('words')\nnltk.download('wordnet')\nstop = stopwords.words('english')\nfrom nltk.stem import WordNetLemmatizer\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Activation, Dense,Embedding,Dropout\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom keras.layers import Dense , Input , LSTM\nfrom sklearn.impute import SimpleImputer ","beb4e666":"#importing our data sets for both training and test \ntrain_df=pd.read_csv('..\/input\/final-project\/train.csv')\ntest_df=pd.read_csv('..\/input\/final-project\/test.csv')","e73c7b83":"train_df.head()","b6ff1c50":"train_df.info()","ee8c2453":"train_df.shape","389ba61c":"train_df.describe()","4835d22b":"train_df.columns","1e000137":"#drop out unnecessary columns from our final data frame\ntrain_df=train_df.drop(['Id', 'Age', 'Division', 'Department', 'Product_Category','Pos_Feedback_Cnt'], axis = 1)","f46280c5":"train_df","76c8f152":"#checking the missing values in Review and Review title columns\nprint(train_df['Review'].isnull().sum())\nprint(train_df['Review_Title'].isnull().sum())","e2878c6f":"#handling with missing values in both review and review title column\nimputer = SimpleImputer(strategy ='most_frequent')\ndata = imputer.fit_transform(train_df.iloc[:,1:].values)\ntrain_df['Review']=data","5565d00e":"imputer = SimpleImputer(strategy ='most_frequent')\ndata = imputer.fit_transform(train_df.iloc[:,0:].values)\ntrain_df['Review_Title']=data","c29dc240":"train_df['Review'].isnull().sum()","08317d25":"train_df['Review_Title'].isnull().sum()","21a48914":"#preprocessing the text data\n#merging reviews and review titles\ntrain_df['Reviews'] = train_df['Review']+' '+train_df['Review_Title']","3dedbb03":"#cleaning df_train['Reviews'] column\n\n# lowercase reviews\ntrain_df['clean_reviews'] = train_df['Reviews'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n\n# add a space before and after every punctuation \ntrain_df['clean_reviews'] = train_df['Reviews'].str.replace(r'([^\\w\\s]+)', ' \\\\1 ')\n\n# remove punctuation\ntrain_df['clean_reviews'] = train_df['Reviews'].str.replace('[^\\w\\s]','')\n\n# remove stopwords\ntrain_df['clean_reviews'] = train_df['Reviews'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n\n# remove digits\ntrain_df['clean_reviews'] = train_df['Reviews'].str.replace('\\d+', '')\n\n# define corpus\nwords = set(nltk.corpus.words.words())\n\n# remove non-corpus words\ndef remove_noncorpus(sentence):\n    print(sentence)\n    return \" \".join(w for w in nltk.wordpunct_tokenize(sentence) if w.lower() in words or not w.isalpha())\n\ntrain_df['clean_reviews'] = train_df['Reviews'].map(remove_noncorpus)\n\nlemmatizer = WordNetLemmatizer()\n\n#final train_df['Review'] column\ntrain_df['Reviews'] = [lemmatizer.lemmatize(row) for row in train_df['clean_reviews']]","55893dd2":"train_df","ff6ce3d3":"train_df=train_df[['Reviews', 'Rating', 'Recommended']]","1cf54413":"train_df","d6ae5ad1":"#taking Rating column \ny_rating=train_df[['Rating']]","6f315580":"y_rating","d3759f1e":"max_features = 40000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(train_df['Reviews'])\nlist_tokenized_train = tokenizer.texts_to_sequences(train_df['Reviews'])\n\nmaxlen = 200\nX_token= pad_sequences(list_tokenized_train, maxlen=maxlen)\n\n\ny_1 = np.zeros((y_rating.shape[0], 5))\ny_1[np.arange(y_rating.shape[0]), y_rating['Rating']-1] = 1\ny_1 = pd.DataFrame(y_1,columns=['1','2','3','4','5'],dtype='int64')","6ea15fa6":"batch_size = 100\nepochs = 10\nembed_size = 130\nmodel_rating = Sequential()\nmodel_rating.add(Embedding(max_features, embed_size))\nmodel_rating.add(Bidirectional(LSTM(130, return_sequences = True)))\nmodel_rating.add(Dense(20, activation=\"relu\"))\nmodel_rating.add(Dense(5, activation=\"softmax\"))\nmodel_rating.add(Dropout(0.05))\nmodel_rating.add(GlobalMaxPool1D())\nmodel_rating.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n\nmodel_rating.fit(X_token,y_1, batch_size=batch_size, epochs=epochs)","7aec6907":"max_features = 40000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(train_df['Reviews'])\nlist_tokenized_train = tokenizer.texts_to_sequences(train_df['Reviews'])\n\nmaxlen = 170\nX_token = pad_sequences(list_tokenized_train, maxlen=maxlen)\ny_2 = train_df['Recommended']\n\nbatch_size = 100\nepochs = 10\nembed_size = 128\nmodel_recommend = Sequential()\nmodel_recommend.add(Embedding(max_features, embed_size))\nmodel_recommend.add(Bidirectional(LSTM(32, return_sequences = True)))\nmodel_recommend.add(GlobalMaxPool1D())\nmodel_recommend.add(Dense(20, activation=\"relu\"))\nmodel_recommend.add(Dropout(0.05))\nmodel_recommend.add(Dense(1, activation=\"sigmoid\"))\nmodel_recommend.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n\nmodel_recommend.fit(X_token,y_2, batch_size=batch_size, epochs=epochs, validation_split=0.2)","f98b08c3":"#id column for using later\nid_df=test_df['Id']\n#drop out unnecessary columns from our test data set\ntest_df=test_df.drop(['Id', 'Age', 'Division', 'Department', 'Product_Category','Pos_Feedback_Cnt'], axis = 1)","e635704f":"test_df","420ba2e4":"#checking the missing values in Review and Review titles\ntest_df['Review'].isnull().sum()","79009f93":"test_df['Review_Title'].isnull().sum()","d068f99c":"#handling with missing values in both review and review title column\nimputer = SimpleImputer(strategy ='most_frequent')\ndata = imputer.fit_transform(test_df.iloc[:,1:].values)\ntest_df['Review']=data","2c27f86c":"test_df['Review'].isnull().sum()","61316195":"imputer = SimpleImputer(strategy ='most_frequent')\ndata = imputer.fit_transform(test_df.iloc[:,0:].values)\ntest_df['Review_Title']=data","1c464ad2":"test_df['Review_Title'].isnull().sum()","d4ca40e8":"#preprocessing the text data\ntest_df['Reviews'] = test_df['Review']+' '+test_df['Review_Title']\n\n#cleaning df_test['Reviews'] column\n\n# lowercase reviews\ntest_df['clean_reviews'] = test_df['Reviews'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n\n# add a space before and after every punctuation \ntest_df['clean_reviews'] = test_df['Reviews'].str.replace(r'([^\\w\\s]+)', ' \\\\1 ')\n\n# remove punctuation\ntest_df['clean_reviews'] = test_df['Reviews'].str.replace('[^\\w\\s]','')\n\n# remove stopwords\ntest_df['clean_reviews'] = test_df['Reviews'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n\n# remove digits\ntest_df['clean_reviews'] = test_df['Reviews'].str.replace('\\d+', '')\n\n# define corpus\nwords = set(nltk.corpus.words.words())\n\n# remove non-corpus words\ndef remove_noncorpus(sentence):\n    print(sentence)\n    return \" \".join(w for w in nltk.wordpunct_tokenize(sentence) if w.lower() in words or not w.isalpha())\n\ntest_df['clean_reviews'] = test_df['Reviews'].map(remove_noncorpus)\n\n\ntest_df['Reviews'] = test_df['clean_reviews']","d5bf79c7":"#tokenization\nlist_tokenized_test = tokenizer.texts_to_sequences(test_df['Reviews'])\nmaxlen = 200\nX_test = pad_sequences(list_tokenized_test, maxlen=maxlen)","8813c36d":"#predict the ratings\nrating_prediction=model_rating.predict(X_test)","6e880b50":"rating_prediction","d0c94da0":"#Returns the indices of the maximum values along an axis\nrating_prediction=rating_prediction.argmax(axis=1)+1\nrating_prediction","37848df3":"#reshaping our dataframe\nrating_prediction=rating_prediction.reshape(-1,1)","6c28582d":"rating_prediction.shape","6ad5844e":"#predicting the recommendation\nrecommend_prediction=model_recommend.predict(X_test)","63845d91":"recommend_prediction","5a23fcf0":"recommend_prediction=recommend_prediction.round(0)","cb972c78":"recommend_prediction","1bcd6d06":"recommend_prediction=recommend_prediction.astype(int)","264831b0":"recommend_prediction","26ea2c36":"recommend_prediction.shape","a200cb59":"result_df_recommend = pd.DataFrame(recommend_prediction, columns=['Recommended'])","01fde48e":"result_df_recommend","c5556cd8":"result_df_rating = pd.DataFrame(rating_prediction, columns=['Rating'])","c78bb6fb":"result_df_rating","cdff22ef":"#submission file\nfinal_result = pd.concat([id_df, result_df_rating, result_df_recommend], axis=1)","3aba5205":"#converting to csv file\nfinal_result.to_csv('ali_final_prediction.csv', index=False)","405cd23d":"**Analyzing train dataset**","8fecf942":"After doing a bit research I found out that we can get the best result in review analysis with deep learning model. So I use this deep learning model for both rating and recommendation prediction","34b81ce7":"References:\n\nhttps:\/\/numpy.org\/devdocs\/reference\/generated\/numpy.argmax.html\n\nhttps:\/\/stackoverflow.com\/questions\/57333255\/how-to-optimize-my-pandas-data-frame-pre-processing\n\nhttps:\/\/towardsdatascience.com\/clothes-reviews-analysis-with-nlp-part-1-d81bdfa14d97\n\nhttps:\/\/towardsdatascience.com\/clothes-reviews-analysis-with-nlp-part-1-bfb8a3a2c4bd","a3a60f62":"**Model for Predicting Recommendation**","1b2e309a":"**Model for Predicting Rating using RNN and Bag of Words**"}}