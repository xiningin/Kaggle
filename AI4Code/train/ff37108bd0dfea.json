{"cell_type":{"41b1a6dc":"code","15d9cf31":"code","57969d3d":"code","94b1d3f5":"code","dc7a24fb":"code","2f576257":"code","3f9c2264":"code","ac406ff9":"code","47aa099f":"code","cdd6ab88":"code","c699da09":"code","576d23df":"code","c1c9c524":"code","801d555f":"code","7ade6bbb":"code","900e52c5":"code","9d6a8045":"code","b246061a":"code","880ff6f0":"code","3f0a2379":"code","881d6749":"code","4a181618":"code","03c3f8b5":"code","03946f0b":"code","0be56bd8":"markdown","fb165a44":"markdown","6ca8d9a0":"markdown","a4b4718b":"markdown","2a3c7265":"markdown","25889575":"markdown","c1084287":"markdown","061a13e7":"markdown","8f77ab52":"markdown","cda94a80":"markdown","f4a25c96":"markdown","7d688809":"markdown","6c53fd22":"markdown","29c57962":"markdown","81ddd6d6":"markdown","09099a87":"markdown","e141a0f3":"markdown","e58e7de0":"markdown","48b16d80":"markdown","4f40d2a6":"markdown","63a87803":"markdown","17cf3e85":"markdown","5cd4487d":"markdown","8afbf0b5":"markdown","fb7d4ba3":"markdown","300c7910":"markdown","28e64ad5":"markdown","058b97c6":"markdown","976b5c1a":"markdown","ea5379e6":"markdown","62cbe00a":"markdown"},"source":{"41b1a6dc":"# Import libraries\n# =================\nimport numpy as np \nimport pandas as pd \nimport os\n\n# Visualization\n# =============\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nplt.style.use('https:\/\/github.com\/dhaitz\/matplotlib-stylesheets\/raw\/master\/pitayasmoothie-dark.mplstyle')\n\n\n# Preprocess and modelling\n# ==========================\nimport statsmodels.api as sm\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\n\n# Models\n# =======\n\n\n# Metrics\n# ========\n\n\n# Warnings\n# ==============================================================================\nimport warnings\nwarnings.filterwarnings('ignore')","15d9cf31":"# Create dataframe with csv files\n# ===============================\npath = \"..\/input\/natural-diamonds-prices-images\/Diamonds2\/\"\ndata = pd.DataFrame()\nfor file in os.listdir(path):\n    if file.endswith(\".csv\"):\n        data = pd.concat([data, pd.read_csv(path+file, thousands=',')])","57969d3d":"print(f'Dataset contains {data.shape[0]} rows and {data.shape[1]} columns')","94b1d3f5":"data.dtypes","dc7a24fb":"data.isnull().sum()","2f576257":"for col in data.columns:\n    if data[col].isnull().sum() > 0:\n        data[col].fillna(data[col].mode()[0], inplace=True)       ","3f9c2264":"data.isnull().sum()","ac406ff9":"data = data.drop(['Id'], axis=1).reset_index(drop=True)","47aa099f":"print(f'''\nDIFFERENT FORMATS\n-------------------\nExample 1: {data['Messurements'][0]}\nExample 2: 4.32X4.32X4.32\nExample 3: 4.32 - 4.32 x 4.32 mm''')","cdd6ab88":"data['Messurements'] = data['Messurements'].str.strip(' mm')\ndata['Messurements'] = data['Messurements'].str.replace(' ','')\ndata['Messurements'] = data['Messurements'].str.replace(r\"[X\u00d7\u2013-]\", \"x\", regex=True)","c699da09":"data['Ratio'] = data['Messurements'].str.rsplit('x',1, expand=True)[0].str.replace('x','\/')\ndata['Ratio'] = data['Ratio'].map(lambda x: eval(x))","576d23df":"def create_plots(var, x, y):\n    '''\n    this function creates the graphs from the params received\n    \n    var: Serie with data\n    x: Column name of labels\n    y: column name with numeric values\n    \n    '''\n    fig, ax = plt.subplots(figsize=(12,6))\n    sns.barplot(x=x, y=y, data=var)\n    plt.title('Diamond '+y, size=20)\n    plt.xlabel(y, size=15)\n    plt.ylabel('Quantity', size=15)\n    # Text annotations\n    for bar, label in enumerate(ax.patches):\n        height=label.get_height()\n        ax.text(bar, height+15, str(height), ha='center')   \n    plt.show()","c1c9c524":"plt.figure(figsize = (12,6))\nx = data['Shape'].value_counts().index.to_list()\ny = data['Shape'].value_counts().to_list()\nsns.barplot(x=y,y=x)\nplt.title('Total shapes', size=20)\nplt.xlabel('Quantity', size=15)\nplt.ylabel('Shapes', size=15)\nfor n, label in enumerate(y):\n    plt.text(label+10, n+0.1, str(label))\nplt.show()","801d555f":"# Count different colors \ncolour = data['Colour'].value_counts().to_frame().reset_index()\n# Create new row with group of rows and summatory\nnew_row = {'index':'OTHERS', 'Colour':colour.iloc[10:-1,1].values.sum()}\n# Aggregate new_row to colur frame\ncolour = colour.iloc[0:10].append(new_row, ignore_index=True)\n# Create barplot\ncreate_plots(colour, 'index', 'Colour')","7ade6bbb":"cut = data['Cut'].value_counts().to_frame().reset_index()\ncreate_plots(cut, 'index', 'Cut')","900e52c5":"# Count different colors \nclarity = data['Clarity'].value_counts().to_frame().reset_index()\n# Create new row with group of rows and summatory\nnew_row = {'index':'OTHERS', 'Clarity':clarity.iloc[6:-1,1].values.sum()}\n# Aggregate new_row to colur frame\nclarity = clarity.iloc[0:6].append(new_row, ignore_index=True)\n# Create barplot\ncreate_plots(clarity, 'index', 'Clarity')","9d6a8045":"symmetry = data['Symmetry'].value_counts().to_frame().reset_index()\ncreate_plots(symmetry, 'index', 'Symmetry')","b246061a":"polish = data['Polish'].value_counts().to_frame().reset_index()\ncreate_plots(polish, 'index', 'Polish')","880ff6f0":"# Count different colors \nfluorescence = data['Fluorescence'].value_counts().to_frame().reset_index()\n# Create new row with group of rows and summatory\nnew_row = {'index':'OTHERS', 'Fluorescence':fluorescence.iloc[2:-1,1].values.sum()}\n# Aggregate new_row to colur frame\nfluorescence = fluorescence.iloc[0:2].append(new_row, ignore_index=True)\n# Create barplot\ncreate_plots(fluorescence, 'index', 'Fluorescence')","3f0a2379":"fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\nax = ax.flatten()\nnumeric_col = data.select_dtypes(include=['float64','int64']).columns\nfor idx, col in enumerate(numeric_col):\n    sns.distplot(data[col], ax=ax[idx])\n    plt.tight_layout(pad=0.6)\nplt.show()","881d6749":"# Split data\nX = data.drop(['Price','Messurements'], axis = 1)\ny = data['Price']\n\n# Select columns of different data types\ncategoric_columns = X.select_dtypes(exclude=['float64','int64']).columns\n\n# Apply transforms\nfor col in X.columns:\n    if col in categoric_columns:\n        X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n    else:\n        t = np.asarray(X[col]).reshape(-1,1)\n        X[col] = StandardScaler().fit_transform(t)    ","4a181618":"X.head()","03c3f8b5":"data2 = X.copy()\ndata2.loc[:, 'price'] = y\nplt.figure(figsize=(15,10))\nsns.heatmap(data2.corr(), \n            annot=True, \n            cmap=\"YlGnBu\", \n            linewidths=0.3)\nplt.show()","03946f0b":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\nprint(f'''DIMENSIONS\n==========\nx_train -> {x_train.shape}\ny_train -> {x_test.shape}\ny_train -> {y_train.shape}\ny_test -> {y_test.shape}''')","0be56bd8":"The columns 'Id' and 'Data Url' will not be necessary, so they'll be removed","fb165a44":"Now, it shown if exists nan values","6ca8d9a0":"Shown the first rows","a4b4718b":"In this feature the class 'Sl1' is the most represented with 1505 items. Note that the feature 'OTHERS' include the sum of different 'Clarity' values because they had a very small quantity of items. It has been preferable to bring them together. 'VS2' is in the second position in this ranking. 'VS1' and 'Sl2' have the same number of items.","2a3c7265":"The dataset contains null values. These variables are categorical so will be replaced by the mode of each column. These records could also be deleted because the total quantity is small, but I prefer to replace them.","25889575":"Once the desired format has been obtained, the Ratio is calculated and added to dataframe","c1084287":"'EX' is the feature with the highest number of items 5061 whereas 'F' that only has 2 items.","061a13e7":"# Exploratory data analysis","8f77ab52":"In this feature stands out over the other the 'EX' value, 4563 items take this value. Only 21 takes the 'F' value. The second one is 'VG' with 1404 items","cda94a80":"The aim with this column is to obtain a data format as follows:  \nformat : 4.32x3.27x2.25  \nThis is a better representation of the diamond size","f4a25c96":"### Cut","7d688809":"### Symmetry","6c53fd22":"Now it's the moment to split data in training set and test set","29c57962":"The next step is to check the data distribution of numeric variables. This can do by shown histograms how follows","81ddd6d6":"### Polish","09099a87":"<table>\n    <tr>\n        <td>\n            <center>cushion<\/center>\n            <img src=https:\/\/capitalwholesalediamonds.com\/wp-content\/uploads\/2020\/11\/cushion150.png, width=100>\n        <\/td>\n        <td>\n            <center>emerald<\/center>\n            <img src=https:\/\/capitalwholesalediamonds.com\/wp-content\/uploads\/2020\/11\/emerald150.png, width=100>\n        <\/td>\n        <td>\n            <center>heart<\/center>\n            <img src=https:\/\/capitalwholesalediamonds.com\/wp-content\/uploads\/2020\/11\/heart150.png, width=100>\n        <\/td>\n        <td>\n            <center>marquise<\/center>\n            <img src=https:\/\/capitalwholesalediamonds.com\/wp-content\/uploads\/2020\/11\/marquise150.png, width=100>\n        <\/td>\n        <td>\n            <center>oval<\/center>\n            <img src=https:\/\/capitalwholesalediamonds.com\/wp-content\/uploads\/2020\/11\/oval150.png, width=100>\n        <\/td>\n        <td>\n            <center>princess<\/center>\n            <img src=https:\/\/capitalwholesalediamonds.com\/wp-content\/uploads\/2020\/11\/150princess.png, width=100>\n        <\/td>\n        <td>\n            <center>radiant<\/center>\n            <img src=https:\/\/capitalwholesalediamonds.com\/wp-content\/uploads\/2020\/11\/150radiant.png, width=100>\n        <\/td>\n        <td>\n            <center>round<\/center>\n            <img src=https:\/\/capitalwholesalediamonds.com\/wp-content\/uploads\/2020\/11\/150round.png, width=100>\n        <\/td>\n    <\/tr>\n<\/table>","e141a0f3":"Finally the Fluorescence feature. The class with highest number of items is 'N' and the second one is 'F' with 1170. Note that the feature 'OTHERS' include the sum of different Fluorescence classes because they had a very small quantity of items. It has been preferable to bring them together.","e58e7de0":"### Shapes","48b16d80":"Note that 'Weight' variable has strong correlation with 'price' (target)","4f40d2a6":"First shown a barplot about the quantity of diamonds of each shape","63a87803":"Notice that the data of the each column looks how different categories. \nTo transform this values in numeric values used to LabelEncoder function from Sklearn. On the other hand, it's interesting to standarize the data of the numeric variables. Is important no apply this transformations to 'Price' variable. Therefore, first the data frame is splited up in two parts. 'X' will contains the predictor variables and 'y' contains the target values.","17cf3e85":"### Fluorescence","5cd4487d":"About this feature stands out the 'VG' feature with 3325 items. On the other hand is 'FR' feature with only 57 items. 'EX' is the second ones with 1819 items.","8afbf0b5":"After obtaining the graph, it can be seen that type Round is the majority shape. On the other hand Radiant and Marquise are the minority shapes. Cushion shape is the second in this ranking with 1671 items.","fb7d4ba3":"# Price prediction","300c7910":"### Colors","28e64ad5":"List of features\n\nid -> unique id of the diamond  \nshape -> shape of the polished diamond  \nWeight -> weight of the diamond in Carats (the bigger the weight the expensive it is)  \nClarity -> clarity of the diamonds (FL, IF, VVS1, VVS2, VS1, VS2, SI1, SI2, SI3, I1, I2, I3)  \nColour -> colour shade of the diamond (D, E, F, \u2026 Z)  \nCut -> cutting level of the polished stone (Poor, Fair, Good, very Good, Excellent)  \nPolish -> polish level of the stone  \nSymmetry -> over all symmetry of the stone's shape  \nFluorescence -> Fluorescence is the ability of certain chemicals to give off visible light after absorbing   radiation which is not normally visible, such as ultraviolet light\n\n","058b97c6":"# TO BE CONTINUED...","976b5c1a":"Now, the aim is to check the correlation between predictor and target variables. For this task will be used a correlation matrix","ea5379e6":"Different data formats are shown below for the column 'Messurements'","62cbe00a":"Regarding color atribute, can be seen that the features E and F are that contains the highest number of items. The features 'H' and 'J' contains a similar number of items. Note that the feature  OTHERS include the sum of different Color because they had a very small quantity of items. It has been preferable to bring them together."}}