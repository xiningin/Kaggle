{"cell_type":{"bc05d8b2":"code","4e0bd703":"code","d57bad49":"code","ca66d7ce":"code","28b6a1a9":"code","db5cbc61":"code","3ebe8a24":"code","972b7135":"code","eb88c886":"code","ed4517e4":"code","1b9a4fd9":"code","26fdab46":"code","bc782ab3":"code","470ef69a":"code","6c3a1229":"code","47e9fde6":"code","a9f2d78b":"code","8e8249c0":"code","53261ef2":"code","e8b765f1":"code","998cbcd8":"code","5a066908":"code","cc0b7e98":"code","8b75f7d8":"code","9ca4be40":"code","88366dbf":"code","f42a4749":"code","16dbb9be":"code","d50494df":"code","719cdddb":"code","76042365":"markdown","f11473dc":"markdown","e7dc2949":"markdown","60b4d7e8":"markdown","9d76a474":"markdown"},"source":{"bc05d8b2":"import os\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, random_split, DataLoader\nfrom PIL import Image\nimport torchvision.models as models\nfrom tqdm.notebook import tqdm\nimport torchvision.transforms as T\nfrom sklearn.metrics import f1_score\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torchvision.utils import make_grid\nfrom torchvision.datasets import ImageFolder\nimport PIL\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nnp.random.seed(42)\ntorch.manual_seed(42)","4e0bd703":"dataset = ImageFolder(root='\/kaggle\/input\/medical-gloves-recognition-dataset\/dataset\/')\n\ndataset_size = len(dataset)\ndataset_size","d57bad49":"classes = dataset.classes\nclasses","ca66d7ce":"num_classes = len(dataset.classes)\nnum_classes","28b6a1a9":"test_size = 100\nnontest_size = len(dataset) - test_size\n\nnontest_df, test_df = random_split(dataset, [nontest_size, test_size])\nlen(nontest_df), len(test_df)\n\n\n","db5cbc61":"\n\nval_size = 100\ntrain_size = len(nontest_df) - val_size\n\ntrain_df, val_df = random_split(nontest_df, [train_size, val_size])\nlen(train_df), len(val_df)\n\n","3ebe8a24":"imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\ntrain_tfms = T.Compose([\n    T.RandomCrop(128, padding=8, padding_mode='reflect'),\n     #T.RandomResizedCrop(256, scale=(0.5,0.9), ratio=(1, 1)), \n    T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n    T.Resize((128, 128)),\n    T.RandomHorizontalFlip(), \n     T.RandomVerticalFlip(),\n    T.RandomRotation(10),\n    T.ToTensor(), \n     T.Normalize(*imagenet_stats,inplace=True), \n    #T.RandomErasing(inplace=True)\n])\n\nvalid_tfms = T.Compose([\n     T.Resize((128, 128)), \n    T.ToTensor(), \n     T.Normalize(*imagenet_stats)\n])","972b7135":"\n\ntest_df.dataset.transform = valid_tfms\nval_df.dataset.transform = valid_tfms\n\ntrain_df.dataset.transform = train_tfms\n\n","eb88c886":"\n\nbatch_size = 64\n\ntrain_dl = DataLoader(train_df, batch_size, shuffle=True, \n                      num_workers=3, pin_memory=True)\nval_dl = DataLoader(val_df, batch_size*2, \n                    num_workers=2, pin_memory=True)\ntest_dl = DataLoader(test_df, batch_size*2, \n                    num_workers=2, pin_memory=True)\n\n","ed4517e4":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","1b9a4fd9":"class ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","26fdab46":"class CnnModel2(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        # Use a pretrained model\n        self.network = models.wide_resnet101_2(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Linear(num_ftrs, 2)\n    \n    def forward(self, xb):\n        return torch.sigmoid(self.network(xb))\n\n\n# In[40]:\n\n\nmodel = CnnModel2()","bc782ab3":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)\n\n","470ef69a":"device = get_default_device()\ndevice","6c3a1229":"\n\ntrain_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\ntest_dl = DeviceDataLoader(test_dl, device)\nto_device(model, device);\n\n","47e9fde6":"model = to_device(CnnModel2(), device)\n\nfor images, labels in train_dl:\n    print('images.shape:', images.shape)\n    out = model(images)\n    print('out.shape:', out.shape)\n    print('out[0]:', out[0])\n    break","a9f2d78b":"class ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))","8e8249c0":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n    \ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    # Set up cutom optimizer with weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n                                                steps_per_epoch=len(train_loader))\n    \n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # Gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n        \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","53261ef2":"history = [evaluate(model, val_dl)]\nhistory","e8b765f1":"epochs = 5\nmax_lr = 5e-5\ngrad_clip = 0.2\nweight_decay = 0.005\nopt_func = torch.optim.Adam\nprint('epoch = ', epochs, 'lr = ', max_lr, 'grad is ', grad_clip, 'weights = ', weight_decay)","998cbcd8":"%%time\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)","5a066908":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');\n\nplot_accuracies(history)","cc0b7e98":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n\nplot_losses(history)","8b75f7d8":"def predict_image(img, model):\n    xb = to_device(img.unsqueeze(0), device)\n    yb = model(xb)\n    _, preds  = torch.max(yb, dim=1)\n    return preds[0].item()","9ca4be40":"def plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs', []) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch no.')\n    plt.ylabel('Learning rate')\n    plt.title('Learning Rate vs. Batch no.');\n\nplot_lrs(history)","88366dbf":"img, label = test_df[0]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', dataset.classes[label], ', Predicted:', dataset.classes[predict_image(img, model)])","f42a4749":"img, label = test_df[10]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', dataset.classes[label], ', Predicted:', dataset.classes[predict_image(img, model)])","16dbb9be":"img, label = test_df[69]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', dataset.classes[label], ', Predicted:', dataset.classes[predict_image(img, model)])","d50494df":"evaluate(model, val_dl)","719cdddb":"evaluate(model, test_dl)","76042365":"# Glove classification\n## By Sergei  Issaev","f11473dc":"### Import Libraries","e7dc2949":"Welcome to my glove classification kernel! This dataset was provided by Aditya Gupta, and I will be using code adapted from lecture materials provided in PyTorch: Zero to GANs online machine learning course. The final accuracy I attained was around 93%. Since both classes contain human hands, the model may have trouble differentiating skin texture versus glove texture, considering the wide variety of existing glove (and skin) textures. Please leave an upvote if you enjoyed it!","60b4d7e8":"# Final Accuracy","9d76a474":"### Perform Train-test split"}}