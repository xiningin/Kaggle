{"cell_type":{"32069337":"code","99423646":"code","cc259f08":"code","e1374d16":"code","3f755460":"code","032f3976":"code","0d8d9619":"code","a9be3446":"code","18762009":"code","d847a25c":"code","e2eb0f25":"code","70f78506":"code","aa8696cf":"code","0628e3f4":"code","9e0dbdf7":"code","58575777":"code","f8e01bab":"code","341afc84":"code","eaa2f1d8":"code","bf6367b1":"code","43cc7416":"markdown","59c1613d":"markdown","573e92c6":"markdown","fc6eea3e":"markdown","eb5aa94b":"markdown","26e300a9":"markdown","5038abef":"markdown","3309670e":"markdown","ac2b43a4":"markdown","033b70f2":"markdown","0eabfb75":"markdown","968820be":"markdown","98432b9f":"markdown","666a310e":"markdown","7191091f":"markdown","d6726f85":"markdown","6bf3fd12":"markdown","af68428b":"markdown"},"source":{"32069337":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n!pip install pywaffle --quiet\nfrom pywaffle import Waffle","99423646":"sales_df = pd.read_csv('..\/input\/sample-supermarket-dataset\/SampleSuperstore.csv')\nsales_df.head()","cc259f08":"print('Total rows:', sales_df.shape[0])\nprint('Total columns:', sales_df.shape[1])","e1374d16":"sales_df.isnull().sum(axis = 0).to_frame()","3f755460":"sales_df.dtypes.to_frame()","032f3976":"state_code = {'Alabama': 'AL','Alaska': 'AK','Arizona': 'AZ','Arkansas': 'AR','California': 'CA','Colorado': 'CO','Connecticut': 'CT','Delaware': 'DE','Florida': 'FL','Georgia': 'GA','Hawaii': 'HI','Idaho': 'ID','Illinois': 'IL','Indiana': 'IN','Iowa': 'IA','Kansas': 'KS','Kentucky': 'KY','Louisiana': 'LA','Maine': 'ME','Maryland': 'MD','Massachusetts': 'MA','Michigan': 'MI','Minnesota': 'MN','Mississippi': 'MS','Missouri': 'MO','Montana': 'MT','Nebraska': 'NE','Nevada': 'NV','New Hampshire': 'NH','New Jersey': 'NJ','New Mexico': 'NM','New York': 'NY','North Carolina': 'NC','North Dakota': 'ND','Ohio': 'OH','Oklahoma': 'OK','Oregon': 'OR','Pennsylvania': 'PA','Rhode Island': 'RI','South Carolina': 'SC','South Dakota': 'SD','Tennessee': 'TN','Texas': 'TX','Utah': 'UT','Vermont': 'VT','Virginia': 'VA','District of Columbia': 'WA','Washington': 'WA','West Virginia': 'WV','Wisconsin': 'WI','Wyoming': 'WY'}\nsales_df['state_code'] = sales_df.State.apply(lambda x: state_code[x])","0d8d9619":"state_data = sales_df[['Sales', 'Profit', 'state_code']].groupby(['state_code']).sum()\n\n\nfig = go.Figure(data=go.Choropleth(\n    locations=state_data.index, \n    z = state_data.Sales, \n    locationmode = 'USA-states', \n    colorscale = 'Reds',\n    colorbar_title = 'Sales in USD',\n))\n\nfig.update_layout(\n    title_text = 'Total State-Wise Sales',\n    geo_scope='usa',\n    height=800,\n)\n\nfig.show()","a9be3446":"fig = go.Figure(data=go.Choropleth(\n    locations=state_data.index, # Spatial coordinates\n    z = state_data.Profit, # Data to be color-coded\n    locationmode = 'USA-states', # set of locations match entries in `locations`\n    colorscale = [[0, 'rgb(255,0,0)'], [0.25, 'rgb(255,255,255)'], [0.45, 'rgb(124,208,247)'], [0.6, 'rgb(97,255,140)'], [1, 'rgb(8,181,0)']],\n#     reversescale = True,\n    colorbar_title = 'Profits in USD',\n))\n\nfig.update_layout(\n    title_text = 'Total State-Wise Profit\/Loss',\n    geo_scope='usa', # limite map scope to USA\n    height=800,\n)\n\nfig.show()","18762009":"# feature engineering price_to_sales ratio\nstate_data['profit_to_sales'] = state_data['Profit'] \/ state_data['Sales']\n\n# adding state name\nstate_name = {v: k for k, v in state_code.items()}\nstate_data['States'] = state_data.index\nstate_data['States'] = state_data.States.apply(lambda x: state_name[x])\n\n# sorting the dataframe\nstate_data = state_data.sort_values(by = ['profit_to_sales'], ascending=True)","d847a25c":"fig = px.bar(state_data, x = 'profit_to_sales', y = 'States', title = 'PRICE TO SALES RATIO',\n            color = 'Profit', color_continuous_scale=px.colors.sequential.Viridis)\nfig.update_layout(\n    autosize=False,\n    height=1000,\n    xaxis = dict(\n        tickmode = 'array',\n        ticktext = state_data.States,\n        title='Profit to Sales Ratio',\n    ),\n    yaxis=dict(title='State'),\n)\nfig.show()","e2eb0f25":"def state_data_viewer(states):\n    \"\"\"Plots the turnover generated by different product categories and sub-categories for the list of given states.\n    Args:\n        states- List of all the states you want the plots for\n    Returns:\n        None\n    \"\"\"\n    product_data = sales_df.groupby(['State'])\n    for state in states:\n        data = product_data.get_group(state).groupby(['Category'])\n        fig, ax = plt.subplots(1, 3, figsize = (28,5))\n        fig.suptitle(state, fontsize=14)        \n        ax_index = 0\n        for cat in ['Furniture', 'Office Supplies', 'Technology']:\n            cat_data = data.get_group(cat).groupby(['Sub-Category']).sum()\n            sns.barplot(x = cat_data.Profit, y = cat_data.index, ax = ax[ax_index])\n            ax[ax_index].set_ylabel(cat)\n            ax_index +=1\n        fig.show()","70f78506":"states = ['California', 'Washington', 'Mississippi', 'Arizona', 'Texas']\nstate_data_viewer(states)","aa8696cf":"data = sales_df[['Segment', 'Sales']].groupby(['Segment']).sum()\n\n# #To plot the waffle Chart \nfig = plt.figure( \n    FigureClass = Waffle,\n    figsize=(10, 10),\n    rows = 10, \n    values = data.to_numpy()\/10000,\n    title={'label': 'Sales in Each Customer Segment (Total \u2248 $2.29 million)'.upper(), 'loc': 'left'},\n    labels=[\"{} ({:.2f}%)\".format(label, percent) for label,percent in zip(list(data.index), (data.Sales\/data.Sales.sum()*100).to_numpy())],\n    legend={'loc': 'lower left', 'bbox_to_anchor': (0, -0.1), 'ncol': len(data), 'framealpha': 0},\n)\n","0628e3f4":"data = sales_df[['Segment', 'Profit']].groupby(['Segment']).sum()\n\n#To plot the waffle Chart \nfig = plt.figure( \n    FigureClass = Waffle,\n    figsize=(8, 8),\n    rows = 6, \n    values = data.to_numpy()\/4000,\n    title={'label': 'Profits made by Each Customer Segment (Total \u2248 $286K)'.upper(), 'loc': 'left'},\n    labels=[\"{} ({:.2f}%)\".format(label, percent) for label,percent in zip(list(data.index), (data.Profit\/data.Profit.sum()*100).to_numpy())],\n    legend={'loc': 'lower left', 'bbox_to_anchor': (0, -0.15), 'ncol': len(data), 'framealpha': 0},\n)","9e0dbdf7":"sales_df['price_per_product'] = sales_df.Sales \/ sales_df.Quantity\nsales_df['profit_per_product'] = sales_df.Profit \/ sales_df.Quantity \n\ndata = sales_df.groupby(['Category'])\n\nfor cat, df in data:\n    sizes = np.absolute(df.price_per_product)\n    fig = px.scatter(df, x = 'price_per_product', title = cat.upper(), \n                    color = 'Sub-Category',\n                    size = sizes, hover_data=['Sub-Category'])\n    fig.update_layout(\n        height = 600,\n        xaxis = dict(title='Price Per Product'),\n        yaxis = dict(title=''),\n    )\n    fig.show()","58575777":"for cat, df in data:\n    sizes = np.absolute(df.profit_per_product)\n    fig = px.scatter(df, x = 'profit_per_product', title = cat.upper(), \n                    color = 'Sub-Category',\n                    size = sizes, hover_data=['Sub-Category'])\n    fig.update_layout(\n        autosize = True,\n        height = 600,\n        xaxis = dict(title='Profit\/Loss Per Product'),\n        yaxis = dict(title=''),\n    )\n    fig.show()","f8e01bab":"for cat, df in data:\n    subCat = df.groupby(['Sub-Category']).sum()\n    fig = px.bar(subCat, y = 'Profit', title = cat.upper(), \n                    color = subCat.index)\n    fig.update_layout(\n        autosize = True,\n        width = 800,\n        yaxis = dict(title='Profit\/Loss Per Product Sub-Category'),\n        xaxis = dict(title=''),\n    )\n    fig.show()","341afc84":"ship_segment = sales_df.groupby(['Segment'])\nsegment_list = sales_df.Segment.value_counts().index\ncat_list = sales_df.Category.value_counts().index\n\nfor segment in segment_list:\n    seg_shipping = ship_segment.get_group(segment)\n    standard, second, first, same = [], [], [], []\n    for cat in cat_list:\n        count = seg_shipping.groupby(['Category']).get_group(cat)['Ship Mode'].value_counts()\n        standard.append(count[0]), second.append(count[1]), first.append(count[2]), same.append(count[3])\n        \n    fig = go.Figure()\n    fig.add_trace(go.Bar(x = cat_list,y = standard,name='Standard Class',marker_color='rgb(137,51,51)'\n                        ))\n    fig.add_trace(go.Bar(x = cat_list,y = second,name='Second Class',marker_color='rgb(234,84,84)'\n                        ))\n    fig.add_trace(go.Bar(x = cat_list,y = first,name='First Class',marker_color='rgb(250,127,78)'\n                        ))\n    fig.add_trace(go.Bar(x = cat_list,y = same,name='Same Day',marker_color='lightsalmon'\n                        ))\n\n    fig.update_layout(\n        barmode ='group',\n        width = 800,\n        title = segment.upper(),\n        yaxis = dict(title = 'Number of Deliveries'))\n    fig.show()","eaa2f1d8":"sales_df['loss'] = sales_df.Profit.apply(lambda x: x if (x < 0) else 0)\n\nfig = px.bar(sales_df,x = 'Ship Mode', y = 'loss', title = 'Losses in Each Shipping Category'.upper(), \n                    color = 'Ship Mode', hover_data=['loss', 'Sub-Category'])\nfig.update_layout(\n        autosize = True,\n        width = 800,\n        yaxis = dict(title='Total Loss'),\n        xaxis = dict(title='Shipping Class'),\n    )\nfig.show()","bf6367b1":"sales_df['whether_discount'] = sales_df.Discount.apply(lambda x: 'No Discount' if (x == 0) else 'Discount')\n\ndiscount_data = sales_df.groupby(['whether_discount']).mean()\n\ndef discount_plotter(data_type = 'total'):\n    \"\"\"Plots discount data related plots.\n    Args:\n        data_type- 'total' or 'average', depending on you want the average statistics or total stats.\n    \"\"\"\n    color = ['rgb(81,81,246)', 'rgb(209,70,70)']\n    if data_type == 'average':\n        discount_data = sales_df.groupby(['whether_discount']).mean()\n        fig = make_subplots(rows=1, cols=3, subplot_titles=('AVERAGE SALE', 'AVERAGE PROFIT\/LOSS', 'AVERAGE PRICE PER PRODUCT'))\n    else:\n        discount_data = sales_df.groupby(['whether_discount']).sum()\n        fig = make_subplots(rows=1, cols=3, subplot_titles=('TOTAL SALE', 'TOTAL PROFIT\/LOSS', 'TOTAL PRICE PER PRODUCT'))\n    fig.add_trace(\n        go.Bar(x = discount_data.index, y = discount_data.Sales, marker_color = color),\n            row=1, col=1\n    )\n\n    fig.add_trace(\n        go.Bar(x = discount_data.index, y = discount_data.Profit, marker_color = color),\n            row=1, col=2\n    )\n\n    fig.add_trace(\n        go.Bar(x = discount_data.index, y = discount_data.price_per_product, marker_color = color),\n            row=1, col=3\n    )\n    fig.update_layout(showlegend=False)\n    fig.show()\n    \n\ndiscount_plotter('average')\ndiscount_plotter()","43cc7416":"**Observation across each product category-**\n1. Furnitures-\n> * If we see the average price, we'll find that most of the tables and chairs are around the \\$200 mark, making them one of the most expensive furniture items. Some tables go as high as USD 550 while the most expensive chair costs USD 700.\n> * The most expensive item in the furniture category is a bookcase costing $880. \n\n2. Office Supplies-\n> * Most office supplies fall under the \\$100 mark.\n> * Binders and supplies are the most expensive categories, going as high as \\$1890.\n\n3. Technology-\n> * As per the plot, products in the machines and copiers sub categories are the most expensive technology items.\n> * Most products fall under the $200 price tag.\n\n---\n#### Now that we have seen the distribution of products across various price brackets, let us have a look at how much each product generates or loses in terms of revenue.","59c1613d":"**Observations from the plot above-**\n> * The **highest loss** beared by the company was while delivering products via the **standard class shipping**. This is of no surprise, since most products were delivered using standard shipping. However, one important thing to be noted is that some of the biggest losses beared by the superstore also fall under the standard shipping category, one going as **high as \\$6,600 in a single sale**. \n> * First and second class shipping have almost equal losses. This is also no surprise since the number of sales shipped under each shipping category were also almost equal.\n\nApart from this information, it doesn't seem that shipping has a major effect on profits or losses as such.\n\n---\n**Now, for the last part of our EDA section, we will see how discounts affect the sale of products and the revenue generated by it.**","573e92c6":"Now, let us import the dataset and have a look at our data.","fc6eea3e":"**From the above given plots, it is clear that**-\n> * **Tables and Bookcases** are the businesses where the company is **losing most of its money**.\n> * While the technology business is making most of the profits for the company, the machines business makes the least profit. The supermarket can improve in that sub-category.\n> * Considering the combined turnover from each category, the furniture business is where the company is barely making any consideraable profit. Maybe the shipping modes and shipping costs for the furniture products, which are usually large, has something to do with the low profits\/high losses. \n---\n#### Let us have a look at what role the various shipping modes has to play in all this.\n\nFirst, let us have a look at which shipping method different consumer segments use the most for buying products in different product categories.","eb5aa94b":"As we can see, there are no null values in our dataset. Now, let us check the data types of each column.","26e300a9":"# Supermarket Data Analysis\n---\nIn this project, we'll be performing some exploratory data analysis on the sample supermarket data.\n\n## Project objectives\n---\nThe following are the project objectives-\n* Performing EDA on the data to derive insights on how the profits can be increased.\n* Discovering the weak areas of the sales deparment in order to improve the sales.\n* Discovering hidden trends within the data that will allow the sales deparment to cater to region-specific needs of the buyers.\n\n## Importing Project Dependencies\n---\nLet us begin the project by importing all the required PyData modules.","5038abef":"**Observations and insights generated from the above given plots:**\n> * In the state of **California**, the *highest revenue* generating state for the supermarket, while all the products sold across each category are generating high-to-low profits, **tables** in **furniture category** is generating an overall loss. I verified the same with New York, the second highest revenue generating state.\n> \n> * **Washington**, has a very positive performance, with profits generating over all product categories. A few of the **low performing product sub categories** are- **bookcases, supplies, fasteners, machines and phones**. Overall, **office supplies and technology categories make the most profit** for the supermarket. \n> \n> * In the state of **Mississippi**, a **low profit generating state**, we see that the **Furniture category performs slightly better** than the other two categories. The **Technology category performs the worst**. I observed this same trend in other low profit generating states as well. \n> \n> * In **low-loss states like Arizona**, the highest loss generating sub-categories are- Tables, binders, machines, storage, and book cases.\n> \n> * In **Texas**, the **highest loss state**, the **furniture category is going entirely in loss**, generating **massive losses** for the supermarket. The performance is soo bad that the best option for the supermarket will be to end its furniture business in the state. In case of office supplies category, the **binders *(generally one of the highest revenue generating sub-category in other states)* and appliances** are one of the **worst performers**.\n\n---\n**Now, let us analyze the sales made in each consumer segment.**","3309670e":"Some interesting observations here.\n* While the Consumer segment had more than 50% in sales, its total contribution in the profits made by the company is only around 46%. This shows that the company is bearing a higher loss in the Consumer segment.\n* The Corporate and the Home Office segments are returning more profits to the supermarket as compared to the sales made. While their joint sales is around 50%, thier joint profits made for the supermarket is around 54%. \n\nHere, the company can do two things in order to increase their profits. They can look into the reasons why they are bearing more losses in the consumer segment and try to reduce those losses, thus directly increasing the sales. \n\nOther route the company can take is to providing more polished services to the Corporate and Home Office segments, thus driving them towards more profits.\n\n---\n#### Now, let us observe the prices of products across each product category and try to see how the prices are spread across each product category.","ac2b43a4":"**Some interesting observations here**. \n> * Ohio has the worst profit-to-sales ratio in terms of total sales and the losses beared.\n> * Delaware has the highest profit-to-sales ratio.\n> * **The states making the largest profits for the company, namely New York, California and Washington DC don't have the highest profit-to-sales ratio. This means that the company can further improve its sales\/profits in these states.**\n\n---\n\nNow, let us analyze the sales of a few random states from each profit bracket (high profit, medium profit, low profit, low loss and high loss) and try to observe some crucial trends which might help us in increasing the sales.\n\n#### We have a few questions to answer here.\n* ***What products do the most profit making states buy?***\n* ***What products do the loss bearing states buy?***\n* ***What product segment needs to be improved in order to drive the profits higher?***\n","033b70f2":"## Data Wrangling\n---\nIn this section, we will clean our dataset, removing all the unnecessary noise or null values in the data. As the first step, let us check for any null values within the dataset.","0eabfb75":"#### Observations from the above given geographical plot-\n> * The company has the highest sales in the state of California (shown in dark maroon), selling around \\$450K of goods.\n> * New York (bright red, top right) is the state with the second highest sales, with more that \\$300k worth of goods sold.\n> * The states of Texas (bottommost, orange) and Washington (top left, orange) end up third and fourth on the top sales charts with around \\$170K and 140K in sales respectively. \n> * If we look at the overall data, we will observe that the supermarket company does most of its business in East Coast and West Coast region. **In fact, the total sales in the state of New York is more than the sales in all of the Central America combined.**","968820be":"**Observations from the above given plot**-\n> * Standard class shipping is the most used shipping method across all consumer segments and product categories.\n> * Across all three consumer segments, office supplies are the most bought products, and the technology items are the least bought products.\n\n---\nNow, let us consider how much loss each shipping category bears.","98432b9f":"**Observation across each product category-**\n1. Furnitures-\n> * Upon observing the plot, it is evident that tables are one of the businesses where the supermarket is losing most of its money.\n> * Book cases is another business where the supermarket is mostly just bearing losses.\n> * If we see the overall performance, chairs seem to be generating the highest profits for the supermarket.\n\n2. Office Supplies-\n> * While binders generate most revenue for the company, it is also one of the highest-loss sub-categories in the office supplies category. \n\n3. Technology-\n> * The company's machine sales cause the highest loss, going as high as \\$1300 in loss.\n\n---\nWhile the scatter plot gives us a rough idea regarding how and in what sub category the supermarket is losing the money, it's still now clear how each sub category is performing considering the overall data. Let us have a look at the performance of each sub category.","666a310e":"The observations from the above plot are:\n> * The states in shades of green, namely **New York**, **California** and **Washington** are the most profitable for the company, with **profits of over \\$30K**.\n> * The states in teal and blue, with an average profit of around \\$25K are mostly situated in the north-east and south-east region.\n> * The state of **Texas**, with the third highest sales proved to be the most expensive state for the company with a **very high loss of around \\$25K**.\n\n---\n\n**Now, let us have a look at the profit to sales ratio of each state. The profit-to-sales ratio tells us how much the store has to sell in that state in order to make profit.** \n> * The higher the profit-to-sales ratio, the more profit returns the store gets in the state for each sale they make.\n> * A lower ratio denotes that the store has to make a lot more sales in order to make the same amount of profit as compared to a state with a higher profit-to-sales ratio.\n> * States with a negative profit-to-sales ratio denote a higher loss on each sale they make.\n\nThese insights can help the supermarket in determining which state needs more attention as compared to the others.","7191091f":"By the looks of it, the data seems pre-processed and requires no further cleaning. We can move on to performing our EDA task.\n\n---\n\n## Exploratory Data Analysis\n---\n\nIn this section, we will perform EDA on our dataset, with an aim to uncover the hidden trends within the data which might help the superstore to increase their profits.\n\nFirst, let us have a look at the total sales per state and the revenue generated.\n","d6726f85":"**Observations from the above given plots-**\n> * Considering both average and total sales, it seems that **people tend to buy more things when it is selling at a discounted price**. **An average sale at discounted price** is of around **USD 232** as compared to **USD 226 on undiscounted price**.\n> * On an average, a **discounted sale results in a loss of around USD 6** as compared to around  **USD 66 in profit on a non-discounted** sale. Also, the company made a total **profit of around USD 320K on non-discount sales**, as compared to a **loss of around USD 34K on discounted** sales.\n> * The **average price of a discounted** product is around **USD 62**, while the same is around **USD 58 for a non-discounted** item.\n\n---\n\nOne thing to be noted is that while the superstore is incurring losses due to giving discounts on its products, they can't stop giving discounts of their products. Most of the heavy discounts are during festivals, end-of-season and clearance sales which are necessary so that the store can make space in their warehouses for fresh stock. Also, by incurring small losses, the company gains in the future by attracting more long term customers. Therefore, the small losses from discounts are an essential part of company's business.","6bf3fd12":"Since we will be working with some geographical plots, let us map the state names to state codes.","af68428b":"Observations from the plot above-\n* Around 50% of the total sales were made in the consumer segment which comprises of the individual buyers.\n* The Corporate sector and Home Office segments have around 31% and 19% sales respectively. \n\n---\nNow, let us analyze what percent of profits does each customer section makes for the supermarket."}}