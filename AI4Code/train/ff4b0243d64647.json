{"cell_type":{"83c92d1d":"code","b5ed53bf":"code","078da5ef":"code","d897ee9b":"code","84e2effe":"code","5556dfa1":"code","fc7e4000":"code","6ea18fb4":"code","c959d875":"code","66b848c3":"code","bdcbddaa":"code","40f26041":"code","c70654fd":"code","5eb9960d":"code","04962aa6":"code","419d5101":"code","6bb4f1c2":"code","5bcd5fc2":"code","67e44231":"code","212946cf":"code","e5743167":"code","54d62193":"code","7144effc":"code","e373b706":"code","29eba209":"code","338a8025":"code","dfe91a45":"code","efee1be4":"code","c5d96473":"code","985b606d":"code","b316311d":"code","dad84d22":"code","5305a523":"code","e61e83d9":"code","48c45dcb":"code","4a8d2d20":"code","75299d5e":"code","eaa46fe3":"code","2944f887":"code","3d546109":"code","4a9b61a2":"code","fde21a99":"code","812f2caa":"code","0236e936":"code","8c09b8a1":"code","4113f52d":"code","0a302c1b":"code","ecf6c843":"code","973c20fc":"code","385123c4":"code","027a60b0":"code","19383ecd":"code","a4f909b0":"code","17f77e65":"code","0fdb2630":"code","efeb11a4":"code","bcf6bfe1":"code","abece469":"code","7b541b35":"code","4f59a61b":"code","d7de4de5":"code","9c5d53d7":"code","48be5613":"code","d66fcaa9":"code","43955f82":"code","1a0f8e4c":"code","25ac5a4d":"code","7e0fc809":"code","8adb96bb":"code","2287b8dd":"code","1df0768e":"code","47db7e3b":"code","e816ed84":"code","ccb8dab0":"code","ef22d186":"code","8bb77739":"code","ea55ab77":"code","3a5a8e08":"code","8b7bce46":"markdown","9372c71f":"markdown","fd0ef9e8":"markdown","76370b2d":"markdown","96154e05":"markdown","93a8bdce":"markdown","3133a08e":"markdown","a6ea91c4":"markdown","f84372e5":"markdown","ae225529":"markdown","b4027a01":"markdown","cb93db8d":"markdown","05bb1327":"markdown","8039887c":"markdown","06be5918":"markdown","c8ff8984":"markdown","19c1a698":"markdown","b36d3822":"markdown","dd345fde":"markdown","5532d341":"markdown","79c1787c":"markdown","8e1292b9":"markdown","0b894bd9":"markdown","5e1dec93":"markdown","3dca37cc":"markdown","4d197dfc":"markdown","a796bbea":"markdown","d632550f":"markdown","a51a4843":"markdown","71d7c7bd":"markdown","74a76a58":"markdown","281c4cb5":"markdown","e33ca319":"markdown","5560f654":"markdown","2417f553":"markdown","2d2763f8":"markdown","feac1270":"markdown","a87f31cd":"markdown","a3fa4960":"markdown","4a64431a":"markdown","710f66e2":"markdown"},"source":{"83c92d1d":"#Import libraries \n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotnine import *\n\n\n\n","b5ed53bf":"#Reading the Data \n\nmovie_df=pd.read_csv(\"\/kaggle\/input\/imdb-5000-movie-dataset\/movie_metadata.csv\")","078da5ef":"#Displaying the first 10 records\n\nmovie_df.head(10)","d897ee9b":"#Shape of the dataset (no of rows and no of columns)\n\nmovie_df.shape","84e2effe":"#Displaying the data type of the dataset attributes \n\nmovie_df.dtypes","5556dfa1":"#Five point summary for the numerical columns in the dataset\n\nmovie_df.describe().T","fc7e4000":"#Dropping the Imdb link from the dataset\n\nmovie_df.drop('movie_imdb_link', axis=1, inplace=True)","6ea18fb4":"#Removing the color section as most of the movies is colored\n\nmovie_df[\"color\"].value_counts()\n\nmovie_df.drop('color',axis=1,inplace=True)","c959d875":"#Checking for the columns present in the datset\nmovie_df.columns","66b848c3":"#Checking for the missing values in the dataset\n\nmovie_df.isna().any()\n\n","bdcbddaa":"#No of the missing values in the dataset\n\nmovie_df.isna().sum()","40f26041":"# We can remove the null values from the dataset where the count is less . so that we don't loose much data \n\nmovie_df.dropna(axis=0,subset=['director_name', 'num_critic_for_reviews','duration','director_facebook_likes','actor_3_facebook_likes','actor_2_name','actor_1_facebook_likes','actor_1_name','actor_3_name','facenumber_in_poster','num_user_for_reviews','language','country','actor_2_facebook_likes','plot_keywords'],inplace=True)\n\n","c70654fd":"movie_df.shape","5eb9960d":"#Replacing the content rating with Value R as it has highest frequency\n\nmovie_df[\"content_rating\"].fillna(\"R\", inplace = True) ","04962aa6":"#Replacing the aspect_ratio with the median of the value as the graph is right skewed \n\nmovie_df[\"aspect_ratio\"].fillna(movie_df[\"aspect_ratio\"].median(),inplace=True)","419d5101":"#We need to replace the value in budget with the median of the value\n\nmovie_df[\"budget\"].fillna(movie_df[\"budget\"].median(),inplace=True)\n","6bb4f1c2":"# We need to replace the value in gross with the median of the value \n\nmovie_df['gross'].fillna(movie_df['gross'].median(),inplace=True)","5bcd5fc2":"# Recheck that all the null values are removed\n\nmovie_df.isna().sum()\n\n","67e44231":"#Removing the duplicate values in the datset\n\nmovie_df.drop_duplicates(inplace=True)\nmovie_df.shape","212946cf":"#Count of the language values \n\nmovie_df[\"language\"].value_counts()","e5743167":"# Graphical presentaion \nplt.figure(figsize=(40,10))\nsns.countplot(movie_df[\"language\"])\nplt.show()","54d62193":"#Most of the values for the languages is english we can drop the english column\n\nmovie_df.drop('language',axis=1,inplace=True)","7144effc":"#Creating a new column to check the net profit made by the company (Gross-Budget) \n\nmovie_df[\"Profit\"]=movie_df['budget'].sub(movie_df['gross'], axis = 0) \n\nmovie_df.head(5)","e373b706":"#Creating a new column to check the profit percentage made by the company \n\nmovie_df['Profit_Percentage']=(movie_df[\"Profit\"]\/movie_df[\"gross\"])*100\nmovie_df","29eba209":"#Value counts for the countries \n\nvalue_counts=movie_df[\"country\"].value_counts()\nprint(value_counts)","338a8025":"##get top 2 values of index\nvals = value_counts[:2].index\nprint (vals)\nmovie_df['country'] = movie_df.country.where(movie_df.country.isin(vals), 'other')\n","dfe91a45":"#Successfully divided the country into three catogories \nmovie_df[\"country\"].value_counts()","efee1be4":"movie_df.head(10)","c5d96473":"#Checking for the movies released year wise \n\n(ggplot(movie_df)         # defining what data to use\n + aes(x='title_year')    # defining what variable to use\n + geom_bar(size=20) # defining the type of plot to use\n)","985b606d":"#Relationship between the imdb score and the profit made by the movie \n\nggplot(aes(x='imdb_score', y='Profit'), data=movie_df) +\\\n    geom_line() +\\\n    stat_smooth(colour='blue', span=1)\n","b316311d":"# Relationship between imdb score and profit percentage\n\nggplot(aes(x='imdb_score', y='Profit'), data=movie_df) +\\\n    geom_line() +\\\n    stat_smooth(colour='blue', span=1)","dad84d22":"#Checking for the imdb rating of the movies and compared with the countries  \n\nggplot(aes(x='country', y='imdb_score'), data=movie_df) +\\\n    geom_line() +\\\n    stat_smooth(colour='blue', span=1)","5305a523":"#Finding the corelation between imdb_rating with respect to no of facebook likes \n\n(ggplot(movie_df)\n + aes(x='imdb_score', y='movie_facebook_likes')\n + geom_line()\n + labs(title='IMDB_Score vs. Facebook like for Movies', x='IMDB scores', y='Facebook Likes for movies')\n)","e61e83d9":"#Top 20 movies based on the profit they made\n\nplt.figure(figsize=(10,8))\nmovie_df= movie_df.sort_values(by ='Profit' , ascending=False)\nmovie_df_new=movie_df.head(20)\nax=sns.pointplot(movie_df_new['Profit'], movie_df_new['budget'], hue=movie_df_new['movie_title'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\nplt.show()\n","48c45dcb":"# Top 20 movies based on the profit percentage\nplt.figure(figsize=(10,8))\nmovie_df= movie_df.sort_values(by ='Profit_Percentage' , ascending=False)\nmovie_df_new=movie_df.head(20)\nax=sns.pointplot(movie_df_new['Profit_Percentage'], movie_df_new['budget'], hue=movie_df_new['movie_title'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\nplt.show()","4a8d2d20":"#Top 20 directors based on the IMDB ratings\nplt.figure(figsize=(10,8))\n\nmovie_df= movie_df.sort_values(by ='imdb_score' , ascending=False)\nmovie_df_new=movie_df.head(20)\nax=sns.pointplot(movie_df_new['director_name'], movie_df_new['imdb_score'], hue=movie_df_new['movie_title'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\nplt.show()\n","75299d5e":"#Commercial success vs critial acclaim\nmovie_df= movie_df.sort_values(by ='Profit_Percentage' , ascending=False)\nmovie_df_new=movie_df.head(20)\n(ggplot(movie_df_new)\n + aes(x='imdb_score', y='gross',color = \"content_rating\")\n + geom_point()\n +  geom_hline(aes(yintercept = 600)) + \n  geom_vline(aes(xintercept = 10)) + \n  xlab(\"Imdb score\") + \n  ylab(\"Gross money earned in million dollars\") + \n  ggtitle(\"Commercial success Vs Critical acclaim\") +\n  annotate(\"text\", x = 8.5, y = 700, label = \"High ratings \\n & High gross\"))","eaa46fe3":"#Top 20 actors of movies based on the commerical success\n\nplt.figure(figsize=(10,8))\n\nmovie_df= movie_df.sort_values(by ='Profit_Percentage' , ascending=False)\nmovie_df_new=movie_df.head(20)\nax=sns.pointplot(movie_df_new['actor_1_name'], movie_df_new['Profit_Percentage'], hue=movie_df_new['movie_title'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\nplt.show()","2944f887":"#Top 20 actors of movies based on the imdb rating of the movies \n\nplt.figure(figsize=(10,8))\n\nmovie_df= movie_df.sort_values(by ='imdb_score' , ascending=False)\nmovie_df_new=movie_df.head(20)\nax=sns.pointplot(movie_df_new['actor_1_name'], movie_df_new['imdb_score'], hue=movie_df_new['movie_title'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\nplt.show()\n","3d546109":"# Country of Top 20 movies based on imdb rating\n\nplt.figure(figsize=(10,8))\n\nmovie_df= movie_df.sort_values(by ='imdb_score' , ascending=False)\nmovie_df_new=movie_df.head(20)\nax=sns.pointplot(movie_df_new['country'], movie_df_new['imdb_score'], hue=movie_df_new['movie_title'])\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\nplt.show()","4a9b61a2":"#Removing the director name column\n\nmovie_df.drop('director_name', axis=1, inplace=True)\n","fde21a99":"#Removing the actor1 ,actor 2 and actor 3 names \n\nmovie_df.drop('actor_1_name',axis=1,inplace=True)","812f2caa":"movie_df.drop('actor_2_name',axis=1,inplace=True)","0236e936":"movie_df.drop('actor_3_name',axis=1,inplace=True)","8c09b8a1":"#Dropping the movie title \n\nmovie_df.drop('movie_title',axis=1,inplace=True)","4113f52d":"# Dropping the plot keywords\nmovie_df.drop('plot_keywords',axis=1,inplace=True)","0a302c1b":"#Value count of genres\n\nmovie_df['genres'].value_counts()","ecf6c843":"#Most of the values are equally distributed in genres column ,so we can remove the genres column\n\nmovie_df.drop('genres',axis=1,inplace =True)","973c20fc":"# Dropiing the profit column from the dataset\nmovie_df.drop('Profit',axis=1,inplace=True)","385123c4":"#Dropping the profit percentage column from the dataset\n\nmovie_df.drop('Profit_Percentage',axis=1,inplace=True)","027a60b0":"# Correlation with heat map\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncorr = movie_df.corr()\nsns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\nplt.figure(figsize=(13,7))\n# create a mask so we only see the correlation values once\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask, 1)] = True\na = sns.heatmap(corr,mask=mask, annot=True, fmt='.2f')\nrotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\nroty = a.set_yticklabels(a.get_yticklabels(), rotation=30)","19383ecd":"#Adding the facebook likes of actor 2 and actor 3 together \nmovie_df['Other_actor_facebbok_likes']=movie_df[\"actor_2_facebook_likes\"] + movie_df['actor_3_facebook_likes']\n\n","a4f909b0":"#Dropping the actor 2 and actor 3 facebook likes columns as they have been added together \n\nmovie_df.drop('actor_2_facebook_likes',axis=1,inplace=True)\n","17f77e65":"\nmovie_df.drop('actor_3_facebook_likes',axis=1,inplace=True)","0fdb2630":"movie_df.drop('cast_total_facebook_likes',axis=1,inplace=True)","efeb11a4":"#Ratio of the ratio of num_user_for_reviews and num_critic_for_reviews.\n\nmovie_df['critic_review_ratio']=movie_df['num_critic_for_reviews']\/movie_df['num_user_for_reviews']","bcf6bfe1":"#Dropping the num_critic_for_review\n\nmovie_df.drop('num_critic_for_reviews',axis=1,inplace=True)\nmovie_df.drop('num_user_for_reviews',axis=1,inplace=True)","abece469":"# New Correlation matrix shown in the figure \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncorr = movie_df.corr()\nsns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\nplt.figure(figsize=(13,7))\n# create a mask so we only see the correlation values once\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask, 1)] = True\na = sns.heatmap(corr,mask=mask, annot=True, fmt='.2f')\nrotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\nroty = a.set_yticklabels(a.get_yticklabels(), rotation=30)","7b541b35":"# We need to categorize the imdb values in the range of 0-4,4-6,6-8 and 8-10 to mark them as the bad,average,good and excellent movies respectively\n\nmovie_df[\"imdb_binned_score\"]=pd.cut(movie_df['imdb_score'], bins=[0,4,6,8,10], right=True, labels=False)+1\n\n\n","4f59a61b":"#Dropping the imdb_score column as it is being replaced with the imdb_binned_score values \nmovie_df.drop('imdb_score',axis=1,inplace=True)","d7de4de5":"movie_df.head(5)","9c5d53d7":"movie_df = pd.get_dummies(data = movie_df, columns = ['country'] , prefix = ['country'] , drop_first = True)\nmovie_df = pd.get_dummies(data = movie_df, columns = ['content_rating'] , prefix = ['content_rating'] , drop_first = True)\n\n","48be5613":"movie_df.columns","d66fcaa9":"\nX=pd.DataFrame(columns=['duration','director_facebook_likes','actor_1_facebook_likes','gross','num_voted_users','facenumber_in_poster','budget','title_year','aspect_ratio','movie_facebook_likes','Other_actor_facebbok_likes','critic_review_ratio','country_USA','country_other','content_rating_G','content_rating_GP','content_rating_M','content_rating_NC-17','content_rating_Not Rated','content_rating_PG','content_rating_PG-13','content_rating_Passed','content_rating_R','content_rating_TV-14','content_rating_TV-G','content_rating_TV-PG','content_rating_Unrated','content_rating_X'],data=movie_df)\ny=pd.DataFrame(columns=['imdb_binned_score'],data=movie_df)\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=100)","43955f82":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)","1a0f8e4c":"#Logistic Regression\n\nfrom sklearn.linear_model import LogisticRegression\nlogit =LogisticRegression()\nlogit.fit(X_train,np.ravel(y_train,order='C'))\ny_pred=logit.predict(X_test)","25ac5a4d":"#Confusion matrix for logistic regression**\n\nfrom sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\nprint(cnf_matrix)\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","7e0fc809":"#KNN \nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=22)\nknn.fit(X_train, np.ravel(y_train,order='C'))\nknnpred = knn.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_test, knnpred)\nprint(cnf_matrix)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, knnpred))","8adb96bb":"#SVC\nfrom sklearn.svm import SVC\nsvc= SVC(kernel = 'sigmoid')\nsvc.fit(X_train, np.ravel(y_train,order='C'))\nsvcpred = svc.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_test, svcpred)\nprint(cnf_matrix)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, svcpred))","2287b8dd":"#Naive bayes\n\nfrom sklearn.naive_bayes import GaussianNB\ngaussiannb= GaussianNB()\ngaussiannb.fit(X_train, np.ravel(y_train,order='C'))\ngaussiannbpred = gaussiannb.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_test, gaussiannbpred)\nprint(cnf_matrix)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, gaussiannbpred))","1df0768e":"#Decision Tree\n\nfrom sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier(criterion='gini') #criterion = entopy, gini\ndtree.fit(X_train, np.ravel(y_train,order='C'))\ndtreepred = dtree.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_test, dtreepred)\nprint(cnf_matrix)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, dtreepred))","47db7e3b":"#Ada Boosting\nfrom sklearn.ensemble import AdaBoostClassifier\nabcl = AdaBoostClassifier(base_estimator=dtree, n_estimators=60)\nabcl=abcl.fit(X_train,np.ravel(y_train,order='C'))\nabcl_pred=abcl.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_test, abcl_pred)\nprint(cnf_matrix)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, abcl_pred))","e816ed84":"#Random Forest\n\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators = 200)#criterion = entopy,gini\nrfc.fit(X_train, np.ravel(y_train,order='C'))\nrfcpred = rfc.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_test, rfcpred)\nprint(cnf_matrix)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, rfcpred))","ccb8dab0":"new_movie_df=movie_df.pop(\"imdb_binned_score\")\n","ef22d186":"#Bagging classfier\n\nfrom sklearn.ensemble import BaggingClassifier\nbgcl = BaggingClassifier(n_estimators=60, max_samples=.7 , oob_score=True)\n\nbgcl = bgcl.fit(movie_df, new_movie_df)\nprint(bgcl.oob_score_)","8bb77739":"#Gradient boosting\n\nfrom sklearn.ensemble import GradientBoostingClassifier\ngbcl = GradientBoostingClassifier(n_estimators = 50, learning_rate = 0.09, max_depth=5)\ngbcl = gbcl.fit(X_train,np.ravel(y_train,order='C'))\ntest_pred = gbcl.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_test, test_pred)\nprint(cnf_matrix)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, test_pred))","ea55ab77":"from xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(X_train, np.ravel(y_train,order='C'))\nxgbprd = xgb.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_test, xgbprd)\nprint(cnf_matrix)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, xgbprd))","3a5a8e08":"from sklearn.metrics import classification_report\n\nprint('Logistic  Reports\\n',classification_report(y_test, y_pred))\nprint('KNN Reports\\n',classification_report(y_test, knnpred))\nprint('SVC Reports\\n',classification_report(y_test, svcpred))\nprint('Naive BayesReports\\n',classification_report(y_test, gaussiannbpred))\nprint('Decision Tree Reports\\n',classification_report(y_test, dtreepred))\nprint('Ada Boosting\\n',classification_report(y_test, abcl_pred))\nprint('Random Forests Reports\\n',classification_report(y_test, rfcpred))\nprint('Bagging Clasifier',bgcl.oob_score_) \nprint('Gradient Boosting',classification_report(y_test, test_pred))\nprint('XGBoosting\\n',classification_report(y_test, xgbprd))","8b7bce46":"**4.2 Remove the linear dependant variables****","9372c71f":"**8.7 Random Forest**","fd0ef9e8":"**So we have added two new columns  profit and profit percentage made by the movies**","76370b2d":"**4.1 Removing the Columns with names** ","96154e05":"**2. Data Preprocessing**","93a8bdce":"> **1. Introduction**","3133a08e":"** We can see that there is strong corelation between the imdb_score and the profit . The movies with high imdb rating have made more profit**","a6ea91c4":"**Most of the movies above rating 8.75 are from USA**","f84372e5":"**8.9 Gradient Boosting**\n\n","ae225529":"**4.Data Preparation for the models**","b4027a01":"**Movie with high IMDB rating have most no of facebook likes**","cb93db8d":"**10.Conclusion**\n\nThe conclusion is that Random Forest Algorithm along with the gradient boosting have the accuracy of 74.5 and 75.5 respectively","05bb1327":"**Movies with High content rating were not commercial success**","8039887c":"**8. Classification Model Selection**","06be5918":"**We can see most of the movies are from USA ,UK and the rest of the countries**","c8ff8984":"** We can see that the cast_total_facebook_likes and actor_1_facebook_like are highly correlated to each other. Both actor2 and actor3 are also somehow correlated to the total. So we want to modify them into two variables: actor_1_facebook_likes and other_actors_facebook_likes.\n\nThere are high correlations among num_voted_users, num_user_for_reviews and num_critic_for_reviews. We want to keep num_voted_users and take the ratio of num_user_for_reviews and num_critic_for_reviews.","19c1a698":"**1.2 Description of dataset attributes**","b36d3822":"**8.3 SVC**","dd345fde":"**8.6 Ada Boosting**","5532d341":"**8.8 Bagging Classifier**[](http:\/\/)","79c1787c":"**8.1 Logistic Regression**","8e1292b9":"**3. Data Visualization**","0b894bd9":"**8.2 KNN**","5e1dec93":"** We lost only 6% of the data which is acceptable**","3dca37cc":"**8.5 Decision Tree**\n\n","4d197dfc":"**We don't have any null values in the datset anymore**","a796bbea":"** 6. Splitting the data into training and test data**","d632550f":"**We can say we have the datset divided into categorical and numeric columns \"\n\n**Categorical Columns**\n\nColor,Director name, actor name,genres,movie_title,language,country,content_rating.\n\n**Numerical Columns**\n\nnum_critic_for_reviews,duration,director_facebook_likes ,actor_3_facebook_likes,actor_1_facebook_likes ,gross,num_voted_users,cast_total_facebook_likes,facenumber_in_poster,num_user_for_reviews ,budget,title_year, actor_2_facebook_likes ,imdb_score,aspect_ratio,movie_facebook_likes\n","a51a4843":"**5. Handling the categorical data**","71d7c7bd":"**7.Feature scaling**","74a76a58":"**4.3 Remove the coreelated variables**","281c4cb5":"**94 % of the movie is english**","e33ca319":"Please find the details for the datset attributes:-\n\n1. Color :- Movie is black or coloured\n2. Director_name:- Name of the movie director\n3. num_critic_for_reviews :- No of critics for the movie\n4. duration:- movie duration in minutes\n5. director_facebook_likes:-Number of likes for the Director on his Facebook Page\n6. actor_3_facebook_likes:- No of likes for the actor 3 on his\/her facebook Page\n7. actor2_name:- name of the actor 2\n8. actor_1_facebook_likes:- No of likes for the actor 1 on his\/her facebook Page\n9. gross:- Gross earnings of the movie in Dollars\n10. genres:- Film categorization like \u2018Animation\u2019, \u2018Comedy\u2019, \u2018Romance\u2019, \u2018Horror\u2019, \u2018Sci-Fi\u2019, \u2018Action\u2019, \u2018Family\u2019\n11. actor_1_name:- Name of the actor 1\n12. movie_title:-Title of the movie\n13. num_voted_users:-No of people who voted for the movie\n14. cast_total_facebook_likes:- Total facebook like for the movie\n15. actor_3_name:- Name of the actor 3\n16. facenumber_in_poster:- No of actors who featured in the movie poster\n17. plot_keywords:-Keywords describing the movie plots\n18. movie_imdb_link:-Link of the movie link\n19. num_user_for_reviews:- Number of users who gave a review\n20. language:- Language of the movie \n21. country:- Country where movie is produced\n22. content_rating:- Content rating of the movie\n23. budget:- Budget of the movie in Dollars\n24. title_year:- The year in which the movie is released\n25. actor_2_facebook_likes:- facebook likes for the actor 2\n26. imdb_score:- IMDB score of the movie\n27. aspect_ratio :- Aspect ratio the movie was made in\n28. movie_facebook_likes:- Total no of facebook likes for the movie\n    ","5560f654":"**Movies with high IMDB has made more percentage**","2417f553":"Now we can see none of the attributes are not much correlated to each other.All are below 0.7 ","2d2763f8":"** We can see the most of the movies which are released after 1980 **","feac1270":"**1.3 Case Study**\n\n\nThe dataset here gives the massive information about the movies and their IMDB scores respectively. We are going to analyze each and every factors which can influence the imdb ratings so that we can predict better results.The movie with the higher imdb score is more successful as compared to the movies with low imdb score. ","a87f31cd":"**1.1 Background**\n\nThis dataset contains the information about the movies . For a movie to be commercial success , it depends on various factors like director, actors ,critic reviews and viewers reaction. Imdb score is one of the important factor to measure the movie's success. ","a3fa4960":"**8.10 XGBooosting**\n\n","4a64431a":"**8.4 Naive Bayes**","710f66e2":"**9.Model Comparison**\n\n"}}