{"cell_type":{"be9110c8":"code","065fe464":"code","45f74bf9":"code","0e790fa1":"code","3ae8aab3":"code","908be083":"code","281c4bbf":"code","fb594d9b":"code","1ffb35aa":"code","e48b862d":"code","5a9b0775":"code","af72ecfe":"code","4df7f2ef":"code","89c18adb":"code","90ff2704":"code","d8f70586":"code","d3151f65":"code","9cda42ab":"code","350986c0":"code","00d88dae":"code","1e17c357":"code","39629f73":"code","56087a59":"code","1faa179e":"code","19af5228":"code","4b591337":"code","6aa92812":"code","7fb6d2ce":"code","796493bc":"code","f609274b":"code","f394b7d9":"code","6af64383":"code","60176c06":"code","4d378ea9":"code","eec41dd5":"code","93cd6faf":"code","8a1f0557":"code","f7beaa0a":"code","e612b85e":"code","d8ddb58f":"code","83c37ef5":"code","e7018a17":"code","3a987086":"code","0234112f":"code","171e4a60":"code","7dde8d1a":"code","54ef46f0":"code","ae83d76e":"code","3d6e0396":"code","03aac870":"code","5dc73168":"code","9055f283":"code","a494d8cf":"code","fff605fc":"code","6560a37f":"code","48cee3a7":"code","6cc8ceac":"code","06e36dcb":"code","889cebb3":"code","e9776383":"markdown","25376b98":"markdown","eb79912d":"markdown","8b9dabfd":"markdown","6e8ac3aa":"markdown","b06e6cb0":"markdown","8cd6a71e":"markdown","dcc24391":"markdown","e951f150":"markdown","d69983a2":"markdown","ce2de820":"markdown","ad43be9c":"markdown","9e6cf0ef":"markdown","5271b23d":"markdown","07e36d45":"markdown","4f92725b":"markdown","673f082b":"markdown","91b39dbd":"markdown","82eee606":"markdown","590fe55d":"markdown","ff2396f3":"markdown","9247172b":"markdown","5007f6d7":"markdown","77cfa46e":"markdown","1b33b208":"markdown","56e98d48":"markdown","8e0e50d7":"markdown","5174d64e":"markdown","4ca3acee":"markdown","921db63b":"markdown","ce517d66":"markdown"},"source":{"be9110c8":"import numpy as np\n\nimport pandas as pd\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score\n\n%matplotlib inline\n\n# You can only call make_env() once, so don't lose it!\nimport riiideducation\n#env = riiideducation.make_env()\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","065fe464":"#Reading Files\n\n#train_df - Two options, for a smallish sample load data with code\n# cell a couple below. For all data go to modelling section in notebook.\n\n#questions.csv\nused_data_types_dict = {\n    'question_id': 'int16',\n    'bundle_id': 'int16',\n    'correct_answer': 'int8',\n    'part': 'int8',\n    'tags': 'str',\n}\n\n\nquestions = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/questions.csv',\n                       usecols = used_data_types_dict.keys(), dtype=used_data_types_dict)\n\n\n#lectures.csv\nlect = pd.read_csv('..\/input\/riiid-test-answer-prediction\/lectures.csv')\n\n#example_test\net = pd.read_csv('..\/input\/riiid-test-answer-prediction\/example_test.csv', index_col='row_id')\n\n#train_df\ntrain_df = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/train.csv', low_memory=False, nrows=10**7, \n                       dtype={'row_id': 'int64',\n                              'timestamp': 'int64',\n                              'user_id': 'int32',\n                              'content_id': 'int16',\n                              'content_type_id': 'int8',\n                              'task_container_id': 'int16',\n                              'user_answer': 'int8',\n                              'answered_correctly': 'int8',\n                              'prior_question_elapsed_time': 'float32',\n                              'prior_question_had_explanation': 'boolean',\n                             })\nprint(train_df.shape)","45f74bf9":"#CHECKLIST\n#1: Explore variables\n    #TRAIN.CSV \n    #QUESTIONS.CSV\n    #LECTURES.CSV\n\n#2: Explore creating new features from variables combinations\n\n","0e790fa1":"train_df.isnull().sum()","3ae8aab3":"correct = train_df[train_df['answered_correctly'] == 1]\nincorrect = train_df[train_df['answered_correctly'] == 0]\n\nprint (\"Correct: %i (%.1f%%)\"%(len(correct), float(len(correct))\/len(train_df)*100.0))\nprint (\"Incorrect: %i (%.1f%%)\"%(len(incorrect), float(len(incorrect))\/len(train_df)*100.0))\nprint (\"Total: %i\"%len(train_df))","908be083":"train_df.timestamp.describe()","281c4bbf":"plt.xlim(0,50000000000)\nsns.distplot(a=correct['timestamp'], label='correct', kde=False)\nsns.distplot(a=incorrect['timestamp'], label=\"incorrect\", kde=False)\nplt.title(\"TimeStamp: Correct vs Incorrect\")\nplt.legend()","fb594d9b":"plt.xlim(0, 150000)\n\nsns.distplot(a=correct['prior_question_elapsed_time'], label='correct', kde=False)\nsns.distplot(a=incorrect['prior_question_elapsed_time'], label=\"incorrect\", kde=False)\nplt.title(\"prior_question_elapsed_time: Correct vs Incorrect\")\nplt.legend()","1ffb35aa":"train_df[['prior_question_had_explanation', 'answered_correctly']].groupby(['prior_question_had_explanation'], \n                                                                           as_index=False, dropna=False).mean()","e48b862d":"train_df.task_container_id.nunique()\n","5a9b0775":"train_df['task_container_id'].value_counts(ascending=True)[-30:].plot(kind='barh', figsize=(10,6),\n                                                                      title='Top 30: task_container_ids')","af72ecfe":"train_df['task_container_id'].value_counts().plot(kind='line', figsize=(10,6))\nplt.xlabel('task_container_id')\nplt.ylabel('counts')","4df7f2ef":"train_df.user_answer.value_counts(normalize=True)","89c18adb":"train_df[['user_answer', 'answered_correctly']].groupby(['user_answer'], as_index=False).mean()","90ff2704":"train_df['user_id'].value_counts()","d8f70586":"#essentially makes a dataset with the value_counts of the user_id column\n#need to figure out how to effectively use this.\nds = train_df['user_id'].value_counts().reset_index()\nds.columns = ['user_id', 'count']\nds = ds.sort_values('count')","d3151f65":"train_df['user_id'].value_counts(ascending=True)[-30:].plot(kind='barh', figsize=(10,6),\n                                                                      title='Top 30: user_ids')","9cda42ab":"train_df['user_id'].value_counts()[-30:].plot(kind='barh', figsize=(10,6),\n                                                                      title='Bottom 30: user_ids')","350986c0":"plt.figure(figsize=(14,6))\nsns.lineplot(x=train_df['user_id'], y=train_df['user_id'].value_counts())\nplt.xlabel(\"user_id\")\nplt.ylabel(\"count\")\nplt.title(\"number of rows per user_id\")","00d88dae":"train_df.content_id.nunique()","1e17c357":"ds = train_df['content_id'].value_counts().reset_index()\nds.columns = ['content_id', 'count']\nds = ds.sort_values('count', ascending=False)\n\nds.head(5)","39629f73":"plt.figure(figsize=(10,6))\nplt.title('Top 30: content_ids')\n\nsns.barplot(x=ds.head(30)['count'], y=ds.head(30).content_id, orient = 'h', \n            order=ds.head(30).sort_values('count', ascending = False).content_id)","56087a59":"plt.figure(figsize=(10,6))\nplt.title('Bottom 30: content_ids')\n\nsns.barplot(x=ds.tail(30)['count'], y=ds.tail(30).content_id, orient = 'h', \n            order=ds.tail(30).sort_values('count').content_id)","1faa179e":"sns.lineplot(data=ds['count'])\nplt.xlabel('content_id')\nplt.ylabel('count')","19af5228":"train_df.user_answer.value_counts()","4b591337":"train_df.content_type_id.value_counts()","6aa92812":"que = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/questions.csv', index_col='question_id')\nque","7fb6d2ce":"que.isnull().sum()","796493bc":"ds = que['correct_answer'].value_counts(normalize=True).reset_index()\nds.columns = ['correct_answer', 'number_of_answers']\nds = ds.sort_values(['number_of_answers'], ascending=False)\n\nds","f609274b":"que.bundle_id.value_counts()","f394b7d9":"ds = que.bundle_id.value_counts().value_counts(normalize=True)\nds = pd.DataFrame({'#_in_bundle':ds.index, 'percentage_of_questions':ds.values}) #created a data frame otherwise it would come out as a series\nds","6af64383":"que.loc[que['bundle_id'] == 7795]","60176c06":"ds = que['part'].value_counts(normalize=True).reset_index()\nds.columns = ['parts', 'percentage_of_questions']\nds = ds.sort_values(['percentage_of_questions'], ascending=False)\nds","4d378ea9":"#seeing how many tags most of the questions have \nds = que['tags'].str.split().str.len().value_counts(normalize=True)\nds = pd.DataFrame({'#_of_tags':ds.index, 'percentage_of_questions':ds.values})\nds['#_of_tags'] = ds['#_of_tags'].astype(int)\n\nds","eec41dd5":"#seeing which tags occur most frequently\nds = que['tags'].str.split(' ').explode('tags').reset_index()\nds = ds['tags'].value_counts().reset_index()\nds.columns = ['tag_number', 'count']\n\nds","93cd6faf":"plt.figure(figsize=(10,6))\nplt.title('Top 30: tags')\n\nsns.barplot(x=ds.head(30)['count'], y=ds.head(30).tag_number, orient = 'h', \n            order=ds.head(30).sort_values('count', ascending = False).tag_number)","8a1f0557":"plt.figure(figsize=(10,6))\nplt.title('Bottom 30: tags')\n\nsns.barplot(x=ds.tail(30)['count'], y=ds.tail(30).tag_number, orient = 'h', \n            order=ds.tail(30).sort_values('count', ascending = False).tag_number)","f7beaa0a":"plt.figure(figsize=(14,6))\nsns.lineplot(x=ds['tag_number'], y=ds['count'])","e612b85e":"lect = pd.read_csv('..\/input\/riiid-test-answer-prediction\/lectures.csv')\nlect","d8ddb58f":"lect.isnull().sum()","83c37ef5":"ds = lect.part.value_counts()\nds","e7018a17":"ds = lect.part.value_counts(normalize=True)\nds = pd.DataFrame({'part_numb':ds.index, 'percentage_of_questions':ds.values})\nds","3a987086":"ds = lect.type_of.value_counts()\nds","0234112f":"ds = lect.type_of.value_counts()\nds.plot(kind='bar', )","171e4a60":"ds = lect.loc[lect['type_of'] == 'solving question']\nds.part.value_counts(normalize=True).plot(kind='bar')","7dde8d1a":"ds = lect.loc[lect['type_of'] == 'concept']\nds.part.value_counts(normalize=True).plot(kind='bar')","54ef46f0":"lect.tag.value_counts().value_counts().to_frame().plot(kind='bar')\nplt.xlabel('Tag_number')\nplt.ylabel('count')\nplt.title('Number of Lectures with each tag number')","ae83d76e":"et = pd.read_csv('..\/input\/riiid-test-answer-prediction\/example_test.csv', index_col='row_id')\net","3d6e0396":"train_questions_only_df = train_df[train_df['answered_correctly']!=-1]\ntrain_questions_only_df.head(1)","03aac870":"train_questions_only_df = pd.merge(train_questions_only_df, questions['part'], \n                                   left_on='content_id', right_index=True, how = 'left')\ntrain_questions_only_df.head(1)","5dc73168":"#removes rows that are lectures and .groupby the user_id\ngrouped_by_user_df = train_questions_only_df.groupby('user_id')\n\n#getting the mean accuracy, question count of each user and other math stuff\nuser_answers_df = grouped_by_user_df.agg({'answered_correctly': ['mean', 'count', 'std', 'median', 'skew']}).copy()\nuser_answers_df.columns = [\n    'mean_user_accuracy', \n    'questions_answered', \n    'std_user_accuracy', \n    'median_user_accuracy', \n    'skew_user_accuracy'\n]\n\nuser_answers_df","9055f283":"#grouping by content_id\ngrouped_by_content_df = train_questions_only_df.groupby('content_id')\n\n#getting mean count and other stuff for each content_id\ncontent_answers_df = grouped_by_content_df.agg({'answered_correctly': ['mean', 'count', 'std', 'median', 'skew']}).copy()\ncontent_answers_df.columns = [\n    'mean_accuracy', \n    'question_asked', \n    'std_accuracy', \n    'median_accuracy', \n    'skew_accuracy'\n]\n\ncontent_answers_df","a494d8cf":"grouped_by_part_df = train_questions_only_df.groupby('part')\n\npart_answers_df = grouped_by_part_df.agg({'answered_correctly': ['mean', 'count', 'std', 'skew']}).copy()\npart_answers_df.columns = [\n    'part_mean_accuracy', \n    'part_questions_answered', \n    'part_std_user_accuracy',  \n    'part_skew_user_accuracy'\n]\n\npart_answers_df","fff605fc":"features = [\n    'mean_user_accuracy', \n    'questions_answered',\n    'std_user_accuracy', \n    'median_user_accuracy',\n    'skew_user_accuracy',\n    'mean_accuracy', \n    'question_asked',\n    'std_accuracy', \n    'median_accuracy',\n    'prior_question_elapsed_time', \n    'prior_question_had_explanation',\n    'skew_accuracy',\n    'part',\n    'part_mean_accuracy', \n    'part_questions_answered', \n    'part_std_user_accuracy',  \n    'part_skew_user_accuracy'\n]\ntarget = 'answered_correctly'","6560a37f":"train_df = train_df[train_df[target] != -1]\n\ntrain_df = pd.merge(train_df, questions['part'], \n                    left_on='content_id', right_index=True, how = 'left')\n\ntrain_df = train_df.merge(user_answers_df, how='left', on='user_id')\ntrain_df = train_df.merge(content_answers_df, how='left', on='content_id')\ntrain_df = train_df.merge(part_answers_df, how='left', left_on='part', right_index=True)\n\ntrain_df['prior_question_had_explanation'] = train_df['prior_question_had_explanation'].fillna(value=False).astype(bool)\ntrain_df = train_df.fillna(value=0.5)\n\ntrain_df = train_df[features + [target]]\ntrain_df = train_df.replace([np.inf, -np.inf], np.nan)\ntrain_df = train_df.fillna(0.5)\n\ntrain_df","48cee3a7":"from scipy.sparse import csc_matrix","6cc8ceac":"seen_before_df_keys=csc_matrix((0, 0), dtype=np.int8).toarray()\nseen_before_df=csc_matrix((0, 13523), dtype=np.int8).toarray()\nclean_row=csc_matrix((1, 13523), dtype=np.int8).toarray()","06e36dcb":"def seen_question_before(dataset, seen_before_df_keys, seen_before_df, clean_row):\n    \n    dataset['seen_q_before']=0\n\n    for i in dataset.index:\n        x = dataset.loc[i] \n        if np.any(seen_before_df_keys == x.user_id)==True:\n            dataset.at[i, 'seen_q_before'] = seen_before_df[(np.where(seen_before_df_keys == x.user_id)[0][0]),(x.content_id)]\n            seen_before_df[(np.where(seen_before_df_keys == x.user_id)[0][0]),(x.content_id)]+=1\n\n        elif np.any(seen_before_df_keys == x.user_id)==False:\n            seen_before_df_keys = np.append(seen_before_df_keys, x.user_id)\n            seen_before_df = np.append(seen_before_df, clean_row, axis=0)\n\n            dataset.at[i, 'seen_q_before'] = seen_before_df[(np.where(seen_before_df_keys == x.user_id)[0][0]),(x.content_id)]\n            seen_before_df[(np.where(seen_before_df_keys == x.user_id)[0][0]),(x.content_id)]+=1\n    \n    return (dataset, seen_before_df_keys, seen_before_df)\n        \n ","889cebb3":"et, seen_before_df_keys, seen_before_df = seen_question_before(et, seen_before_df_keys, \n                                                                          seen_before_df, clean_row)","e9776383":"### train.csv","25376b98":"### part","eb79912d":"### Training data is in the competition dataset as usual\n\nIt's larger than will fit in memory with default settings, so we'll specify more efficient datatypes and only load a subset of the data for now.","8b9dabfd":"# INSPIRED BY\n\n- [Kostiantyn Isaienkov's EDA Notebook](https:\/\/www.kaggle.com\/isaienkov\/riiid-answer-correctness-prediction-eda-modeling\/)\n- [Ilia Larchenko's Simple EDA and Baseline Notebook](https:\/\/www.kaggle.com\/ilialar\/simple-eda-and-baseline)\n","6e8ac3aa":"### Task Container ID","b06e6cb0":"This is an idea I had to create some sort of loop that checks if the user has seen the question before. It takes far too long to run, and I might have to try a different mehtod than pandas to speed up the process. \n\n","8cd6a71e":"Note: Maybe bundles with more that one question are connected? ie if you get the first question wrong you might be able to solve the remaining Q's?\n","dcc24391":"### User ID","e951f150":"# questions.csv\n\nquestion_id - foreign key for the content_id column in train\/test data","d69983a2":"### Part","ce2de820":"### Tag","ad43be9c":"we can see from the above that the value_count doesnt seem to change between low and high user_id's. ","9e6cf0ef":"# Maybe creating a loop to see if user has seen question before","5271b23d":"### timestamp","07e36d45":"### content_id","4f92725b":"# lectures.csv","673f082b":"* 0 if the event was a question being posed to the user\n* 1 if the event was the user watching a lecture\n\nnote: we can see that there are the same number of content_type_id = 1 as there is user_answer = -1.","91b39dbd":"### bundle_id","82eee606":"### prior_question_elapsed_time","590fe55d":"# example_test_rows.csv","ff2396f3":"# Data Exploration Stuff","9247172b":"* timestamp: done\n* user_id: done\n* content_id: done\n* content_type_id: done\n* task_container_id: done\n* user_answer: done\n* answered_correctly: done\n* prior_question_elapsed_time: done\n* prior_question_had_explanation: done","5007f6d7":"# Some Feature Engineering","77cfa46e":"Ideas?\n\n* for the first question of a test is the prior_question_had_explanation always false, or is it filled with a null value?\n\n* why are the prior_question_elapsed_time and prior_question_elapsed_time not the same in terms of null values?","1b33b208":"### type_of","56e98d48":"### user_answer","8e0e50d7":"### content_type_id","5174d64e":"### prior_question_had_explanation","4ca3acee":"### correct_answer","921db63b":"### Feature Selection","ce517d66":"### tags\n\nsome feature eng here for sure"}}