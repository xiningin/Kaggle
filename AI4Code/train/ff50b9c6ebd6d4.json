{"cell_type":{"cb46addd":"code","5615d55c":"code","70b3478f":"code","bdc8a865":"code","5db8ddfc":"code","b1d6b77f":"code","66a90783":"code","b1bd16a2":"code","872239aa":"code","9a0a5cf7":"code","f21c6878":"code","6c149a50":"code","8c80e9ff":"code","bf3d9e6d":"code","77566fcf":"code","a2b0e15a":"code","5bdad683":"code","ee88cf66":"code","2a12a45f":"code","8f1f45ef":"code","0d6fa895":"code","6e6f6924":"code","be9230c0":"code","69818c15":"code","b1a1e0cd":"code","62b841c8":"code","0ca1e839":"code","2210125f":"code","80bb0e3f":"code","7fe20252":"code","84385b37":"code","a044622f":"code","d04705eb":"code","40db4d03":"code","64722461":"code","868dfeb7":"code","1f10d72b":"code","8a8ec009":"code","54deda78":"code","969866c7":"code","f852fd09":"code","8894ea3d":"code","ab4d662e":"code","fc5e417c":"code","fa44d335":"code","bbcf2ae9":"code","408b2984":"code","592a3813":"code","21ba8504":"code","1b298847":"code","e79e03ce":"code","f923d40f":"code","559c4c44":"code","dd6f3b9e":"code","b4a8f3d0":"code","751555aa":"code","5bde5621":"code","74efc4ec":"code","0da26bd8":"code","68047382":"code","633d204c":"code","5facf0a7":"markdown","d53b2cb0":"markdown","c8df438d":"markdown","491de6c7":"markdown","ade99fa7":"markdown","ea9dfd8b":"markdown","6d385add":"markdown","30f25369":"markdown","0e856d02":"markdown","27f845e5":"markdown","da61090a":"markdown","ed2f5e2e":"markdown","b1da3585":"markdown"},"source":{"cb46addd":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore')","5615d55c":"train=pd.read_csv('..\/input\/big-mart-sales-forcasting\/train.csv')","70b3478f":"train.head(10)","bdc8a865":"train.shape","5db8ddfc":"# check for missing values in data set\ntrain.isnull().sum()","b1d6b77f":"train['Item_Weight'].fillna((train['Item_Weight'].mean()),inplace=True)","66a90783":"train.isnull().sum()","b1bd16a2":"train['Outlet_Size'].fillna((train['Outlet_Size'].mode()[0]),inplace=True)","872239aa":"train.isnull().sum()","9a0a5cf7":"X=train[['Outlet_Establishment_Year','Item_MRP']]","f21c6878":"X.shape","6c149a50":"y=train['Item_Outlet_Sales']","8c80e9ff":"# spliting the data into train and test\nX_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.7)","bf3d9e6d":"from sklearn.linear_model import LinearRegression\nlreg=LinearRegression()","77566fcf":"lreg.fit(X_train,y_train)","a2b0e15a":"pred=lreg.predict(X_test)","5bdad683":"lreg.coef_","ee88cf66":"mse=mean_squared_error(y_test,pred)","2a12a45f":"mse","8f1f45ef":"print('the value of mse is',mse)","0d6fa895":"# calculating coefficients\ncoeff=pd.DataFrame(X_train.columns)\ncoeff['coeffucient Estimation']=lreg.coef_","6e6f6924":"coeff","be9230c0":"# from above result we can say that MRP has a high coefficient,meaning items having higher prices have better sales.","69818c15":"X=train[['Outlet_Establishment_Year','Item_MRP','Item_Weight']]","b1a1e0cd":"y=train[['Item_Outlet_Sales']]","62b841c8":"X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.7)","0ca1e839":"X_train.shape,y_train.shape","2210125f":"lreg.fit(X_train,y_train)","80bb0e3f":"pred1=lreg.predict(X_test)","7fe20252":"lreg.coef_,lreg.intercept_","84385b37":"from sklearn.metrics import r2_score\nlreg.score(X_test,y_test)","a044622f":"from sklearn.metrics import mean_squared_error\nmse=mean_squared_error(y_test,pred1)","d04705eb":"print('the value of mse is',mse)","40db4d03":"train.info()","64722461":"train.drop('Item_Identifier',axis=1,inplace=True)","868dfeb7":"train.Item_Visibility.value_counts()","1f10d72b":"train['Item_Visibility']=train['Item_Visibility'].replace(0,np.mean(train['Item_Visibility']))","8a8ec009":"train.Item_Visibility.value_counts()","54deda78":"train.Outlet_Establishment_Year.value_counts()","969866c7":"train.info()","f852fd09":"train.drop('Outlet_Identifier',axis=1,inplace=True)","8894ea3d":"train1=pd.get_dummies(train,drop_first=True)","ab4d662e":"train1.head()","fc5e417c":"X=train1.drop('Item_Outlet_Sales',axis=1)","fa44d335":"y=train1['Item_Outlet_Sales']","bbcf2ae9":"X.shape,y.shape","408b2984":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)","592a3813":"X_train.shape,y_train.shape","21ba8504":"lreg=LinearRegression()","1b298847":"lreg.fit(X_train,y_train)","e79e03ce":"pred2=lreg.predict(X_test)","f923d40f":"lreg.score(X_test,y_test)","559c4c44":"lreg.coef_","dd6f3b9e":"# let's check MSE\nmse=mean_squared_error(y_test,pred2)","b4a8f3d0":"print('the value of mse is',mse)","751555aa":"coeff=pd.DataFrame(X_train.columns)\ncoeff['Estimated Coefficient']=lreg.coef_","5bde5621":"coeff","74efc4ec":"# Residual Plot\nX_plot=plt.scatter(pred,(pred-y_test),c='b')\nplt.hlines(y=0,xmin=-1000,xmax=5000)\nplt.title('residual plot')\n","0da26bd8":"# Residual Plot\nX_plot=plt.scatter(pred1,(pred-y_test),c='b')\nplt.hlines(y=0,xmin=-1000,xmax=5000)\nplt.title('residual plot')\n","68047382":"# Residual Plot\nX_plot=plt.scatter(pred2,(pred2-y_test),c='b')\nplt.hlines(y=0,xmin=-1000,xmax=5000)\nplt.title('residual plot')\n","633d204c":"from pandas import Series\ncoeff=pd.DataFrame(X_train.columns)\ncoeff['Estimated Coefficient']=Series(lreg.coef_,X_train.columns).sort_values().plot(kind='bar')","5facf0a7":"Take a look at the residual Vs fitted values plot","d53b2cb0":"The value of R-square is always between 0 and 1, where 0 means that the model does not model explain any variability in the target variable (Y) and 1 meaning it explains full variability in the target variable. Now let us check the r-square for the above model. lreg.score(x_cv,y_cv) 0.3287 In this case, R\u00b2 is 32%, meaning, only 32% of variance in sales is explained by year of establishment and MRP. In other words, if you know year of establishment and the MRP, you\u2019ll have 32% information to make an accurate prediction about its sales. Now what would happen if I introduce one more feature in my model, will my model predict values more closely to its actual value? Will the value of R-Square increase? Let us consider another case.","c8df438d":"Clearly, we can see that there is a great improvement in both mse and R-square, which means that our model now is able to predict much closer values to the actual values.","491de6c7":"We can see that coefficient of Outlet_Type_Supermarket_Type3 is much higher as compare to rest of the coefficients.\ntherefore the total sales of an Item would be more driven by this feature.","ade99fa7":"How accurate do you think the model is? Do we have any evaluation metric, so that we can check this? Actually we have a quantity, known as R-Square. R-Square: It determines how much of the total variation in Y (dependent variable) is explained by the variation in X (independent variable). Mathematically, it can be written as:\n![image.png](attachment:image.png)","ea9dfd8b":"We learnt, by using two variables rather than one, we improved the ability to make accurate predictions about the item sales. So, let us introduce another feature \u2018weight\u2019 in case 3. Now let\u2019s build a regression model with these three features.","6d385add":"### EVALUATING YOUR MODEL - R SQUARE AND ADJUSTED R- SQUARE","30f25369":"Now let us built a model containing all the features. While building the regression models, I have only used continuous features. This is because we need to treat categorical variables differently before they can used in linear regression model. There are different techniques to treat them, here I have used one hot encoding(convert each class of a categorical variable as a feature). Other than that I have also imputed the missing values for outlet size.","0e856d02":"### Model 2 - Linear regression with more variables","27f845e5":"### Interpretation of Regression Plots","da61090a":"### USING ALL THE FEATURES FOR PREDICTION","ed2f5e2e":"### Adjusted R-square","b1da3585":"The only drawback of R2 is that if new predictors (X) are added to our model, R2 only increases or remains constant but it never decreases. We can not judge that by increasing complexity of our model, are we making it more accurate? That is why, we use \u201cAdjusted R-Square\u201d. The Adjusted R-Square is the modified form of R-Square that has been adjusted for the number of predictors in the model. It incorporates model\u2019s degree of freedom. The adjusted R-Square only increases if the new term improves the model accuracy.\n![image.png](attachment:image.png)"}}