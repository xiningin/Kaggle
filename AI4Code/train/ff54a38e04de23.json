{"cell_type":{"51bd3773":"code","8f996e94":"code","918bc12e":"code","3d1343f7":"code","b24f8508":"code","52ea16c1":"code","331f990a":"code","8554d2fd":"code","dcedff90":"code","7ab2ad26":"code","e42e6e0d":"code","e2dbb77d":"code","2f4b0496":"code","11a8963a":"code","f6f7f63d":"code","acd10c2c":"code","e0be5eb7":"markdown","5c180043":"markdown","d300835f":"markdown","c6928c40":"markdown","d8632eb5":"markdown","0094c80a":"markdown","89b66e52":"markdown"},"source":{"51bd3773":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\nimport IPython\nimport IPython.display\nimport PIL\nimport pickle\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8f996e94":"! ls ..\/input\/fat2019_prep_mels1","918bc12e":"class ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        \n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        )\n\n        self._init_weights()\n        \n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.zeros_(m.bias)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = F.avg_pool2d(x, 2)\n        return x\n    \nclass Classifier(nn.Module):\n    def __init__(self, num_classes=1000): # <======== modificaition to comply fast.ai\n        super().__init__()\n        \n        self.conv = nn.Sequential(\n            ConvBlock(in_channels=3, out_channels=64),\n            ConvBlock(in_channels=64, out_channels=128),\n            ConvBlock(in_channels=128, out_channels=256),\n            ConvBlock(in_channels=256, out_channels=512),\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) # <======== modificaition to comply fast.ai\n        self.fc = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(512, 128),\n            nn.PReLU(),\n            nn.BatchNorm1d(128),\n            nn.Dropout(0.1),\n            nn.Linear(128, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.conv(x)\n        #x = torch.mean(x, dim=3)   # <======== modificaition to comply fast.ai\n        #x, _ = torch.max(x, dim=2) # <======== modificaition to comply fast.ai\n        x = self.avgpool(x)         # <======== modificaition to comply fast.ai\n        x = self.fc(x)\n        return x","3d1343f7":"DATA = Path('..\/input\/freesound-audio-tagging-2019')\nPREPROCESSED = Path('..\/input\/fat2019_prep_mels1')\nWORK = Path('work')\nPath(WORK).mkdir(exist_ok=True, parents=True)\n\nCSV_TRN_CURATED = DATA\/'train_curated.csv'\nCSV_TRN_NOISY = DATA\/'train_noisy.csv'\nCSV_TRN_NOISY_BEST50S = PREPROCESSED\/'trn_noisy_best50s.csv'\nCSV_SUBMISSION = DATA\/'sample_submission.csv'\n\nMELS_TRN_CURATED = PREPROCESSED\/'mels_train_curated.pkl'\nMELS_TRN_NOISY = PREPROCESSED\/'mels_train_noisy.pkl'\nMELS_TRN_NOISY_BEST50S = PREPROCESSED\/'mels_trn_noisy_best50s.pkl'\nMELS_TEST = PREPROCESSED\/'mels_test.pkl'\n\ntrn_curated_df = pd.read_csv(CSV_TRN_CURATED)\ntrn_noisy_df = pd.read_csv(CSV_TRN_NOISY)\ntrn_noisy50s_df = pd.read_csv(CSV_TRN_NOISY_BEST50S)\ntest_df = pd.read_csv(CSV_SUBMISSION)\n\n#df = pd.concat([trn_curated_df, trn_noisy_df], ignore_index=True) # not enough memory\ndf = pd.concat([trn_curated_df, trn_noisy50s_df], ignore_index=True, sort=True)\ntest_df = pd.read_csv(CSV_SUBMISSION)\n\nX_train = pickle.load(open(MELS_TRN_CURATED, 'rb')) + pickle.load(open(MELS_TRN_NOISY_BEST50S, 'rb'))","b24f8508":"from fastai import *\nfrom fastai.vision import *\nfrom fastai.vision.data import *\nimport random\n\nCUR_X_FILES, CUR_X = list(df.fname.values), X_train\n\ndef open_fat2019_image(fn, convert_mode, after_open)->Image:\n    # open\n    idx = CUR_X_FILES.index(fn.split('\/')[-1])\n    x = PIL.Image.fromarray(CUR_X[idx])\n    # crop\n    time_dim, base_dim = x.size\n    crop_x = random.randint(0, time_dim - base_dim)\n    x = x.crop([crop_x, 0, crop_x+base_dim, base_dim])    \n    # standardize\n    return Image(pil2tensor(x, np.float32).div_(255))\n\nvision.data.open_image = open_fat2019_image","52ea16c1":"tfms = get_transforms(do_flip=True, max_rotate=0, max_lighting=0.1, max_zoom=0, max_warp=0.)\nsrc = (ImageList.from_csv(WORK, Path('..')\/CSV_TRN_CURATED, folder='trn_curated')\n       .split_by_rand_pct(0.2)\n       .label_from_df(label_delim=',')\n)\ndata = (src.transform(tfms, size=128)\n        .databunch(bs=64).normalize(imagenet_stats)\n)","331f990a":"data.show_batch(3)","8554d2fd":"def borrowed_model(pretrained=False, **kwargs):\n    return Classifier(**kwargs)\n\nf_score = partial(fbeta, thresh=0.2)\nlearn = cnn_learner(data, borrowed_model, pretrained=False, metrics=[f_score])\nlearn.unfreeze()\n\nlearn.lr_find()\nlearn.recorder.plot()","dcedff90":"learn.fit_one_cycle(10, slice(1e-6, 1e-1))","7ab2ad26":"learn.lr_find()\nlearn.recorder.plot()","e42e6e0d":"learn.fit_one_cycle(100, 3e-3)","e2dbb77d":"learn.save('fat2019_fastai_cnn2d_stage-2')\nlearn.export()","2f4b0496":"del X_train\nX_test = pickle.load(open(MELS_TEST, 'rb'))\nCUR_X_FILES, CUR_X = list(test_df.fname.values), X_test\n\ntest = ImageList.from_csv(WORK, Path('..')\/CSV_SUBMISSION, folder='test')\nlearn = load_learner(WORK, test=test)\npreds, _ = learn.get_preds(ds_type=DatasetType.Test)","11a8963a":"test_df[learn.data.classes] = preds\ntest_df.to_csv('submission.csv', index=False)\ntest_df.head()","f6f7f63d":"del X_test\nX_train = pickle.load(open(MELS_TRN_CURATED, 'rb'))\n\nCUR_X_FILES, CUR_X = list(df.fname.values), X_train\nlearn = cnn_learner(data, borrowed_model, pretrained=False, metrics=[f_score])\nlearn.load('fat2019_fastai_cnn2d_stage-2');","acd10c2c":"# Thanks to https:\/\/nbviewer.jupyter.org\/github\/fastai\/course-v3\/blob\/master\/nbs\/dl1\/lesson6-pets-more.ipynb\nfrom fastai.callbacks.hooks import *\n\ndef visualize_cnn_by_cam(learn, data_index):\n    x, _y = learn.data.valid_ds[data_index]\n    y = _y.data\n    if not isinstance(y, (list, np.ndarray)): # single label -> one hot encoding\n        y = np.eye(learn.data.valid_ds.c)[y]\n\n    m = learn.model.eval()\n    xb,_ = learn.data.one_item(x)\n    xb_im = Image(learn.data.denorm(xb)[0])\n    xb = xb.cuda()\n\n    def hooked_backward(cat):\n        with hook_output(m[0]) as hook_a: \n            with hook_output(m[0], grad=True) as hook_g:\n                preds = m(xb)\n                preds[0,int(cat)].backward()\n        return hook_a,hook_g\n    def show_heatmap(img, hm, label):\n        _,axs = plt.subplots(1, 2)\n        axs[0].set_title(label)\n        img.show(axs[0])\n        axs[1].set_title(f'CAM of {label}')\n        img.show(axs[1])\n        axs[1].imshow(hm, alpha=0.6, extent=(0,img.shape[0],img.shape[0],0),\n                      interpolation='bilinear', cmap='magma');\n        plt.show()\n\n    for y_i in np.where(y > 0)[0]:\n        hook_a,hook_g = hooked_backward(cat=y_i)\n        acts = hook_a.stored[0].cpu()\n        grad = hook_g.stored[0][0].cpu()\n        grad_chan = grad.mean(1).mean(1)\n        mult = (acts*grad_chan[...,None,None]).mean(0)\n        show_heatmap(img=xb_im, hm=mult, label=str(learn.data.valid_ds.y[data_index]))\n\nfor idx in range(10):\n    visualize_cnn_by_cam(learn, idx)","e0be5eb7":"## Test prediction and making submission file simple\n- Switch to test data.\n- Overwrite results to sample submission; simple way to prepare submission file.","5c180043":"# CNN 2D Basic Solution #3\n\nThis is 3rd version of https:\/\/www.kaggle.com\/daisukelab\/cnn-2d-basic-solution-powered-by-fast-ai.\n\n- Based on the 2nd version. https:\/\/www.kaggle.com\/daisukelab\/clf-to-multi-cnn-2d-basic-2-preprocessed-dataset\n- Borrowing model from https:\/\/www.kaggle.com\/mhiro2\/simple-2d-cnn-classifier-with-pytorch\n- Using preprocessed dataset. https:\/\/www.kaggle.com\/daisukelab\/fat2019_prep_mels1\n\n# Important notice for final submission\n\nThis kernel is not preprocessing __test set__, then this doesn't work for final submission.\nWe should be ready for preprocessing new test set used in re-evaluation after deadline:\n\n_\"Note, as this competition is a Kernels-only, two-stage competition, following the final submission deadline for the competition, your kernel code will be re-run on a privately-held test set that is not provided to you. It is your model's score against this private test set that will determine your ranking on the private leaderboard and final standing in the competition. The leaderboard will be updated in the days following the competition's completion, and our team will announce that the re-run has been completed and leaderboard finalized with an announcement made on the competition forums.\"_\n\nLink: https:\/\/www.kaggle.com\/c\/freesound-audio-tagging-2019\/overview\/timeline","d300835f":"## File\/folder definitions\n\n- `df` will handle training data.\n- `test_df` will handle test data.","c6928c40":"## Borrowed model\n\nThanks to https:\/\/www.kaggle.com\/mhiro2\/simple-2d-cnn-classifier-with-pytorch, borrowing simple model here.","d8632eb5":"## Custom `open_image` for fast.ai library to load data from memory\n\n- Important note: Random cropping 1 sec, this is working like augmentation.","0094c80a":"## Follow multi-label classification\n\n- Almost following fast.ai course: https:\/\/nbviewer.jupyter.org\/github\/fastai\/course-v3\/blob\/master\/nbs\/dl1\/lesson3-planet.ipynb\n- But `pretrained=False`","89b66e52":"## Visualizing activations"}}