{"cell_type":{"02033365":"code","663d2f0c":"code","b9b34bb2":"code","b9e19705":"code","8e0c547a":"code","8cde020f":"code","bb7efb7a":"code","1d0ee742":"code","4e3d27f6":"code","855c8955":"code","72ebe60a":"code","78e11b79":"markdown","1702c73a":"markdown","d07d4922":"markdown","6e388b72":"markdown","d0d70c23":"markdown","0a831015":"markdown","76ab56e9":"markdown"},"source":{"02033365":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import Ridge, ElasticNet, LinearRegression,Lasso\nfrom sklearn.model_selection import train_test_split, KFold\n\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.pyplot import figure\n%matplotlib inline\nfrom math import sqrt\ndf = pd.read_csv('..\/input\/uio_clean.csv')\ndf.head()","663d2f0c":"df.info()","b9b34bb2":"#dropping the columns that are not useful for prediction\ndf= df.drop(['id','vendor_id','store_and_fwd_flag'], axis=1)\ndf.describe()\n","b9e19705":"# removing outliers or erroneous values i.e. trip duration should be between 20 sec and 3hrs, distance should be\n# between 100m and 100km, trip duration should be greater than wait time etc.\ndf=df[(df['trip_duration'].between(30,7200)) & (df['dist_meters'].between(100,100000)) & (df['trip_duration']>df['wait_sec'])]\ndf=df[df['wait_sec'].between(0,7200)]\ndf=df[(df['pickup_longitude'].between(-80,-77)) & (df['pickup_latitude'].between(-4,1)) & (df['dropoff_longitude'].between(-80,-77))\n      &(df['dropoff_latitude'].between(-4,1))]\ndf.shape[0]","8e0c547a":"df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], format='%Y-%m-%d %H:%M:%S')\ndf['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime'], format='%Y-%m-%d %H:%M:%S')\ndf['hour_of_day']=df['pickup_datetime'].dt.hour\ndf['month'] = df['pickup_datetime'].dt.month\ndf['day_of_week'] = df['pickup_datetime'].dt.dayofweek\ndf['day_of_year'] = df['pickup_datetime'].dt.dayofyear\ndf['week_of_year'] = df['pickup_datetime'].dt.weekofyear\ndf=df.drop(['pickup_datetime','dropoff_datetime'], axis=1)\n\n                                    \ndf['trip_duration_log'] = np.round(np.log1p(df['trip_duration']), 5)\ndf['dist_meters_log'] = np.round(np.log1p(df['dist_meters']), 5)\ndf['avg_speed'] = df['dist_meters'] \/ df['trip_duration'] \n# avg speed should be between 3m\/s and 30m\/s or 108km\/hr\ndf = df[df['avg_speed'].between(3,30)]\ndf=df.dropna()\ndf.describe()","8cde020f":"#split dependent and independent variable\nX = df.drop(['wait_sec'],axis=1)\n#Taking natural log of the target variable, this helps the model converge better and gives better results\ny = np.log1p(df['wait_sec'])\n\n#Normalization function\nscaler = StandardScaler()\n#X = scaler.fit_transform(X)\n\n#Test train split\nX_train, X_test, y_train, y_test = train_test_split(scaler.fit_transform(X), y, test_size=0.20, random_state=16)","bb7efb7a":"grid_search = GridSearchCV( \n          estimator= ElasticNet(),\n        param_grid={\n            'alpha':[0.01,0.03,0.001,0.003,0.1],\n            'l1_ratio': [0.3,0.35,0.4,0.5]\n        },\n          scoring=\"neg_mean_squared_error\",  \n          cv=KFold(n_splits=3,shuffle=True,random_state=42))   \n        \ngrid_search.fit(X_train, y_train.values.ravel())\nCVed_model = grid_search.best_estimator_\nprint(grid_search.best_params_)","1d0ee742":"print(\"The training error is:\",grid_search.best_score_)","4e3d27f6":"y_pred = CVed_model.predict(X_test)\nmae = np.abs((y_test - y_pred))\nprint(\"The test error is: \",mae.mean())","855c8955":"feat_importances = pd.Series(CVed_model.coef_, index=X.columns)\nfeat_importances.abs().nlargest(10).plot(kind='barh',title='Feature importance')\n","72ebe60a":"#taking the inverse log to measure actual error\ny_test_act = np.expm1(y_test)\ny_pred_act = np.expm1(y_pred)\nmae = np.abs((y_test_act - y_pred_act))\n\nprint(\"The actual mean absolute test error is: \",mae.mean())","78e11b79":"As it can be seen the data is now in a much better shape as compared to the describe above.","1702c73a":"# Predicting the waiting time for taxi users","d07d4922":"The above table shows and tells a lot about the data. For someone who understands statistics the row labels seen above give a good abstract picture of the data. The min , max values, mean, std and quantiles explain the spread, bounds etc of the data. We can then pre-process, cleanse  the data based on this info.","6e388b72":"## Steps for deployment on AWS Lambda:","d0d70c23":"## Modelling ","0a831015":"## Feature engineering","76ab56e9":"1) Upload the model to AWS S3 <br>\n2) Create a Flask API <br>\n3) Configure AWS Lambda & API Gateway (using zappa framework) <br>\n4) Initialize Zappa and test the API locally <br>\n5) Deploy to AWS Lambda"}}