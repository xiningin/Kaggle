{"cell_type":{"561a07cf":"code","4d32281a":"code","d5a23909":"code","f6b847df":"code","32a0cb41":"code","3ff8a6c2":"code","4d392280":"code","f00a7417":"code","b3b501f9":"code","1a045dfa":"code","f1c6c8c4":"markdown"},"source":{"561a07cf":"!pip install pyspark","4d32281a":"from pyspark.sql import SparkSession\nimport pyspark.sql.functions as f\nimport pyspark.sql.types as t\nimport pandas as pd\n#from IPython.core.display import display\n#import seaborn as sns\n#from pyspark.sql.functions import udf\nimport html\nimport re\nfrom pyspark.ml.feature import Tokenizer, StopWordsRemover,Word2Vec\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.types import IntegerType\nimport gc\n# spark =  SparkSession.builder.getOrCreate()\nspark = SparkSession.builder \\\n.appName('app_name') \\\n.master('local[*]') \\\n.config('spark.sql.execution.arrow.pyspark.enabled', True) \\\n.config('spark.sql.session.timeZone', 'UTC') \\\n.config('spark.driver.memory','128G') \\\n.config('spark.ui.showConsoleProgress', True) \\\n.config('spark.sql.repl.eagerEval.enabled', True) \\\n.getOrCreate()","d5a23909":"train = spark.read.csv(\"..\/input\/uit-spring-2021-ds200-assignment-9\/train.csv\",header = True)\ntest  = spark.read.csv(\"..\/input\/uit-spring-2021-ds200-assignment-9\/test.csv\",header = True)\nfrac = 0.1 # get approximately 1%\ntrain = train.sample(withReplacement=False, fraction=frac)\n# sample = spark.read.csv(\"..\/input\/uit-spring-2021-ds200-assignment-9\/samplesolution.csv\",header = True)","f6b847df":"user_regex = r\"(@\\w{1,15})\"\nhashtag_replace_regex= \"#(\\w{1,})\"\nurl_regex = r\"https?:\\\/\\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&\/\/=]*)\"\nemail_regex = r\"\/\\S+@\\S+\\.\\S+\/\"\nspectial_character = \"[^A-Za-z0-9]\"\nfrom pyspark.sql.functions import trim\ndef cleaning(df):  \n    df = df.withColumn(\"text\", f.regexp_replace(f.col(\"text\"),user_regex, \"\"))\n    df = df.withColumn(\"text\", f.regexp_replace(f.col(\"text\"),hashtag_replace_regex, \"\"))\n    df = df.withColumn(\"text\", f.regexp_replace(f.col(\"text\"),email_regex, \"\"))\n    df = df.withColumn(\"text\", f.regexp_replace(f.col(\"text\"),url_regex, \"\"))\n    df = df.withColumn(\"text\", f.regexp_replace(f.col(\"text\"),spectial_character, \" \"))\n    df = df.withColumn(\"text\", f.trim(f.col(\"text\")))  \n    df = df.withColumn(\"text\", f.regexp_replace(f.col(\"text\"),\"  *\", \" \"))    \n    df = df.withColumn(\"text\", f.lower(f.col(\"text\"))) \n    return df\n#train.select(\"text\").show(5,100)\n#test.select(\"text\").show(5,100)\ntrain = cleaning(train)\ntest = cleaning(test)\ndata_train = train.select(\"id\",\"text\",\"polarity\")\ndata_test = test.select(\"id\",\"text\")\n# data_train.show(10,50)\n# data_test.show(10,50)\ndata_train = data_train.withColumn(\"label\", data_train[\"polarity\"].cast(IntegerType()))\n# data_train","32a0cb41":"\ndel user_regex\ndel train\ndel test\ndel hashtag_replace_regex\ndel url_regex\ndel email_regex\ndel spectial_character\ngc.collect()","3ff8a6c2":"tokenizer = Tokenizer(inputCol = \"text\",outputCol = \"words1\")\nstopwords_remover = StopWordsRemover (\n        inputCol= \"words1\",\n        outputCol = \"words2\",\n        stopWords = StopWordsRemover.loadDefaultStopWords(\"english\")\n)\nword2Vec = Word2Vec(vectorSize=150, minCount=0, inputCol=\"words2\", outputCol=\"features\")\nlr = LogisticRegression(labelCol = \"label\",featuresCol=\"features\")\n\nclf_pipeline = Pipeline(\n    stages=[tokenizer,\n            stopwords_remover,\n            word2Vec,\n            lr\n          ])","4d392280":"pipelinemodel = clf_pipeline.fit(data_train)\npipelinemodel.save(\".\/NLP_model\")\n\n# training = pipelinemodel.transform(data_train)\npredict = pipelinemodel.transform(data_test)\n","f00a7417":"predict","b3b501f9":"# predict = model.transform(testing)","1a045dfa":"# result = predict.select(\"id\",\"prediction\")\n# result = result.withColumn(\"polarity\", result[\"prediction\"].cast(IntegerType()))\n# result = result.select(\"id\",\"polarity\")\n# result.show()\n# result.toPandas().to_csv('.\/output.csv',index=False)","f1c6c8c4":"* V\u00f5 H\u1ed3ng Ph\u00fac H\u1ea1nh - 18520275\n* Nguy\u1ec5n Th\u1ecb Thanh Kim - 18520963\n* Hu\u1ef3nh Kh\u1ea3i Si\u1ebfu - 18520348"}}