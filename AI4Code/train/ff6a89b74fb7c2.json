{"cell_type":{"7d4440ee":"code","3d345bcc":"code","39d290bb":"code","933dd82f":"code","d8f778c4":"code","fc92ba66":"code","7dd7c403":"code","815a358a":"code","41a85329":"code","66430e27":"code","a8cfb528":"markdown","3cee5511":"markdown","0b31cdac":"markdown"},"source":{"7d4440ee":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom numpy.random import standard_normal, seed\n\nimport scipy.stats as stats\nfrom scipy.stats import norm\n\nimport sys\nimport datetime \nimport time\n","3d345bcc":"!pip install bspline\nimport bspline\nimport bspline.splinelab as spline","39d290bb":"# The Black-Scholes prices\ndef bs_put(t, S0, K, r, sigma, T):\n    d1 = (np.log(S0\/K) + (r + 1\/2 * sigma**2) * (T-t)) \/ sigma \/ np.sqrt(T-t)\n    d2 = (np.log(S0\/K) + (r - 1\/2 * sigma**2) * (T-t)) \/ sigma \/ np.sqrt(T-t)\n    price = K * np.exp(-r * (T-t)) * norm.cdf(-d2) - S0 * norm.cdf(-d1)\n    return price\n\ndef bs_call(t, S0, K, r, sigma, T):\n    d1 = (np.log(S0\/K) + (r + 1\/2 * sigma**2) * (T-t)) \/ sigma \/ np.sqrt(T-t)\n    d2 = (np.log(S0\/K) + (r - 1\/2 * sigma**2) * (T-t)) \/ sigma \/ np.sqrt(T-t)\n    price = S0 * norm.cdf(d1) - K * np.exp(-r * (T-t)) * norm.cdf(d2)\n    return price\n\ndef d1(S0, K, r, sigma, T):\n    return (np.log(S0\/K) + (r + sigma**2 \/ 2) * T)\/(sigma * np.sqrt(T))\n \ndef d2(S0, K, r, sigma, T):\n    return (np.log(S0 \/ K) + (r - sigma**2 \/ 2) * T) \/ (sigma * np.sqrt(T))\n ","933dd82f":"class DiscreteBlackScholes:\n    \"\"\"\n    Class implementing discrete Black Scholes\n    DiscreteBlackScholes is class for pricing and hedging under\n    the real-world measure for a one-dimensional Black-Scholes setting\n    \"\"\"\n\n    def __init__(self,\n                 s0,\n                 strike,\n                 vol,\n                 T,\n                 r,\n                 mu,\n                 numSteps,\n                 numPaths):\n        \"\"\"\n        :param s0: initial price of the underlying\n        :param strike: option strike\n        :param vol: volatility\n        :param T: time to maturity, in years\n        :param r: risk-free rate,\n        :param mu: real drift, asset drift\n        :param numSteps: number of time steps\n        :param numPaths: number of Monte Carlo paths\n        \"\"\"\n        self.s0 = s0\n        self.strike = strike\n        self.vol = vol\n        self.T = T\n        self.r = r\n        self.mu = mu\n        self.numSteps = numSteps\n        self.numPaths = numPaths\n\n        self.dt = self.T \/ self.numSteps  # time step\n        self.gamma = np.exp(-r * self.dt)  # discount factor for one time step, i.e. gamma in the QLBS paper\n\n        self.sVals = np.zeros((self.numPaths, self.numSteps + 1), 'float')  # matrix of stock values\n\n        # initialize half of the paths with stock price values ranging from 0.5 to 1.5 of s0\n        # the other half of the paths start with s0\n        half_paths = int(numPaths \/ 2)\n\n        if False:\n            # Grau (2010) \"Applications of Least-Squares Regressions to Pricing and Hedging of Financial Derivatives\"\n            self.sVals[:, 0] = (np.hstack((np.linspace(0.5 * s0, 1.5 * s0, half_paths),\n                                           s0 * np.ones(half_paths, 'float')))).T\n\n        self.sVals[:, 0] = s0 * np.ones(numPaths, 'float')\n        self.optionVals = np.zeros((self.numPaths, self.numSteps + 1), 'float')  # matrix of option values\n        self.intrinsicVals = np.zeros((self.numPaths, self.numSteps + 1), 'float')\n\n        self.bVals = np.zeros((self.numPaths, self.numSteps + 1), 'float')  # matrix of cash position values\n        self.opt_hedge = np.zeros((self.numPaths, self.numSteps + 1),\n                              'float')  # matrix of optimal hedges calculated from cross-sectional information F_t\n        self.X = None\n        self.data = None  # matrix of features, i.e. self.X as sum of basis functions\n        self.delta_S_hat = None\n\n        # coef = 1.0\/(2 * gamma * risk_lambda)\n        # override it by zero to have pure risk hedge\n        self.coef = 0.\n\n    def gen_paths(self):\n        \"\"\"\n        A simplest path generator\n        \"\"\"\n        np.random.seed(42)\n        # Spline basis of order p on knots k\n\n        Z = np.random.normal(0, 1, size=(self.numSteps + 1, self.numPaths)).T\n        for t in range(0, self.numSteps):\n            self.sVals[:, t + 1] = self.sVals[:, t] * np.exp((self.mu - 0.5 * self.vol**2) * self.dt + (self.vol * np.sqrt(self.dt) * Z[:, t + 1]))\n        \n        print(self.sVals)\n\n        # like in QLBS\n        delta_S = self.sVals[:, 1:] - np.exp(self.r * self.dt) * self.sVals[:, :self.numSteps]\n        self.delta_S_hat = np.apply_along_axis(lambda x: x - np.mean(x), axis=0, arr=delta_S)\n\n        # state variable\n        # delta_t here is due to their conventions\n        self.X = - (self.mu - 0.5 * self.vol ** 2) * np.arange(self.numSteps + 1) * self.dt + np.log(self.sVals)\n\n        X_min = np.min(np.min(self.X))\n        X_max = np.max(np.max(self.X))\n\n        print('X.shape = ', self.X.shape)\n        print('X_min, X_max = ', X_min, X_max)\n\n        p = 4  # order of spline (as-is; 3 = cubic, 4: B-spline?)\n        ncolloc = 12\n        tau = np.linspace(X_min, X_max, ncolloc)  # These are the sites to which we would like to interpolate\n\n        # k is a knot vector that adds endpoints repeats as appropriate for a spline of order p\n        # To get meaningful results, one should have ncolloc >= p+1\n        #k = splinelab.aptknt(tau, p)\n        k = spline.aptknt(tau, p)\n        basis = bspline.Bspline(k, p)\n\n        num_basis = ncolloc  # len(k) #\n        self.data = np.zeros((self.numSteps + 1, self.numPaths, num_basis))\n\n        print('num_basis = ', num_basis)\n        print('dim self.data = ', self.data.shape)\n\n        # fill it, expand function in finite dimensional space\n        # in neural network the basis is the neural network itself\n        t_0 = time.time()\n        for ix in np.arange(self.numSteps + 1):\n            x = self.X[:, ix]\n            self.data[ix, :, :] = np.array([basis(el) for el in x])\n        t_end = time.time()\n        print('\\nTime Cost of basis expansion:', t_end - t_0, 'seconds')\n\n    def function_A_vec(self, t, reg_param=1e-3):\n        \"\"\"\n        function_A_vec - compute the matrix A_{nm} from Eq. (52) (with a regularization!)\n        Eq. (52) in QLBS Q-Learner in the Black-Scholes-Merton article\n\n        Arguments:\n        t - time index, a scalar, an index into time axis of data_mat\n        reg_param - a scalar, regularization parameter\n\n        Return:\n        - np.array, i.e. matrix A_{nm} of dimension num_basis x num_basis\n        \"\"\"\n        X_mat = self.data[t, :, :]\n        num_basis_funcs = X_mat.shape[1]\n        this_dS = self.delta_S_hat[:, t]\n        hat_dS2 = (this_dS ** 2).reshape(-1, 1)\n        A_mat = np.dot(X_mat.T, X_mat * hat_dS2) + reg_param * np.eye(num_basis_funcs)\n        return A_mat\n\n    def function_B_vec(self, t, Pi_hat):\n        \"\"\"\n        function_B_vec - compute vector B_{n} from Eq. (52) QLBS Q-Learner in the Black-Scholes-Merton article\n\n        Arguments:\n        t - time index, a scalar, an index into time axis of delta_S_hat\n        Pi_hat - pandas.DataFrame of dimension N_MC x T of portfolio values\n        Return:\n        B_vec - np.array() of dimension num_basis x 1\n        \"\"\"\n        tmp = Pi_hat * self.delta_S_hat[:, t] + self.coef * (np.exp((self.mu - self.r) * self.dt)) * self.sVals[:, t]\n        X_mat = self.data[t, :, :]  # matrix of dimension N_MC x num_basis\n\n        B_vec = np.dot(X_mat.T, tmp)\n        return B_vec\n\n    def seed_intrinsic(self, strike=None, cp='P'):\n        \"\"\"\n        initilaize option value and intrinsic value for each node\n        \"\"\"\n        if strike is not None:\n            self.strike = strike\n\n        if cp == 'P':\n            # payoff function at maturity T: max(K - S(T),0) for all paths\n            self.optionVals = np.maximum(self.strike - self.sVals[:, -1], 0).copy()\n            # payoff function for all paths, at all time slices\n            self.intrinsicVals = np.maximum(self.strike - self.sVals, 0).copy()\n        elif cp == 'C':\n            # payoff function at maturity T: max(S(T) -K,0) for all paths\n            self.optionVals = np.maximum(self.sVals[:, -1] - self.strike, 0).copy()\n            # payoff function for all paths, at all time slices\n            self.intrinsicVals = np.maximum(self.sVals - self.strike, 0).copy()\n        else:\n            raise Exception('Invalid parameter: %s'% cp)\n\n        self.bVals[:, -1] = self.intrinsicVals[:, -1]\n\n    def roll_backward(self):\n        \"\"\"\n        Roll the price and optimal hedge back in time starting from maturity\n        \"\"\"\n\n        for t in range(self.numSteps - 1, -1, -1):\n\n            # determine the expected portfolio value at the next time node\n            piNext = self.bVals[:, t+1] + self.opt_hedge[:, t+1] * self.sVals[:, t+1]\n            pi_hat = piNext - np.mean(piNext)\n\n            A_mat = self.function_A_vec(t)\n            B_vec = self.function_B_vec(t, pi_hat)\n            phi = np.dot(np.linalg.inv(A_mat), B_vec)\n            self.opt_hedge[:, t] = np.dot(self.data[t, :, :], phi)\n            self.bVals[:,t] = np.exp(-self.r * self.dt) * (self.bVals[:, t+1] + (self.opt_hedge[:, t+1] - self.opt_hedge[:, t]) * self.sVals[:, t+1])\n\n\n        # calculate the initial portfolio value\n        initPortfolioVal = self.bVals[:, 0] + self.opt_hedge[:, 0] * self.sVals[:, 0]\n\n        # use only the second half of the paths generated with paths starting from S0\n        optionVal = np.mean(initPortfolioVal)\n        optionValVar = np.std(initPortfolioVal)\n        delta = np.mean(self.opt_hedge[:, 0])\n\n        return optionVal, delta, optionValVar","d8f778c4":"np.random.seed(42)\nstrike_k = 95\ntest_vol = 0.2\ntest_mu = 0.03\ndt = 0.01\nrfr = 0.05\nnum_paths = 100\nnum_periods = 252\n\nhMC = DiscreteBlackScholes(100, strike_k, test_vol, 1., rfr, test_mu, num_periods, num_paths)\nhMC.gen_paths()\n\nt = hMC.numSteps - 1\npiNext = hMC.bVals[:, t+1] + 0.1 * hMC.sVals[:, t+1]\npi_hat = piNext - np.mean(piNext)\n\nA_mat = hMC.function_A_vec(t)\nB_vec = hMC.function_B_vec(t, pi_hat)\nphi = np.dot(np.linalg.inv(A_mat), B_vec)\nopt_hedge = np.dot(hMC.data[t, :, :], phi)\n\n# plot the results\nfig = plt.figure(figsize=(12,4))\nax1 = fig.add_subplot(121)\n\nax1.scatter(hMC.sVals[:,t], pi_hat)\nax1.set_title(r'Expected $\\Pi_0$ vs. $S_t$')\nax1.set_xlabel(r'$S_t$')\nax1.set_ylabel(r'$\\Pi_0$')","fc92ba66":"# input parameters\ns0 = 100.0\nstrike = 100.0\nr = 0.05\nmu = 0.07 # 0.05\nvol = 0.4\nT = 1.0\n\n# Simulation Parameters\nnumPaths = 50000  # number of Monte Carlo trials\nnumSteps = 6\n\n# create the class object\nhMC = DiscreteBlackScholes(s0, strike, vol, T, r, mu, numSteps, numPaths)\n\n# calculation\nhMC.gen_paths()\nhMC.seed_intrinsic()\noption_val, delta, option_val_variance = hMC.roll_backward()\nbs_call_value = bs_put(0, s0, K=strike, r=r, sigma=vol, T=T)\nprint('Option value = ', option_val)\nprint('Option value variance = ', option_val_variance)\nprint('Option delta = ', delta)  \nprint('BS value', bs_call_value)","7dd7c403":"strikes = np.linspace(85, 110, 6)\nresults = [None] * len(strikes)\nbs_prices = np.zeros(len(strikes))\nbs_deltas = np.zeros(len(strikes))\nnumPaths = 50000\nhMC = DiscreteBlackScholes(s0, strike, vol, T, r, mu, numSteps, numPaths)\nhMC.gen_paths()\nfor ix, k_strike in enumerate(strikes):\n    hMC.seed_intrinsic(k_strike)\n    results[ix] = hMC.roll_backward()\n    bs_prices[ix] = bs_put(0, s0, K=k_strike, r=r, sigma=vol, T=T)\n    bs_deltas[ix] = norm.cdf(d1(s0, K=k_strike, r=r, sigma=vol, T=T)) - 1\nbs_prices","815a358a":"mc_prices = np.array([x[0] for x in results])\nmc_deltas = np.array([x[1] for x in results])\nprice_variances = np.array([x[-1] for x in results])\nprices_diff = mc_prices - bs_prices\ndeltas_diff = mc_deltas - bs_deltas\nprice_variances","41a85329":"prices_diff\n","66430e27":"deltas_diff\n","a8cfb528":"Simulate $N_{MC}$ stock price sample paths with $T$ steps by the classical Black-Sholes formula.\n\n$$dS_t=\\mu S_tdt+\\sigma S_tdW_t\\quad\\quad S_{t+1}=S_te^{\\left(\\mu-\\frac{1}{2}\\sigma^2\\right)\\Delta t+\\sigma\\sqrt{\\Delta t}Z}$$\n\nwhere $Z$ is a standard normal random variable.\n\nMC paths are simulated by GeneratePaths() method of DiscreteBlackScholes class.","3cee5511":"### Part 1\n\n\nClass DiscreteBlackScholes implements the above calculations with class variables to math symbols mapping of:\n\n$$\\Delta S_t=S_{t+1} - e^{-r\\Delta t} S_t\\space \\quad t=T-1,...,0$$\n \n**Instructions:**\nSome portions of code in DiscreteBlackScholes have bee taken out. You are to implement the missing portions of code in DiscreteBlackScholes class.\n\n$$\\Pi_t=e^{-r\\Delta t}\\left[\\Pi_{t+1}-u_t \\Delta S_t\\right]\\quad t=T-1,...,0$$\n\n- implement DiscreteBlackScholes.function_A_vec() method\n$$A_{nm}^{\\left(t\\right)}=\\sum_{k=1}^{N_{MC}}{\\Phi_n\\left(X_t^k\\right)\\Phi_m\\left(X_t^k\\right)\\left(\\Delta\\hat{S}_t^k\\right)^2}\\quad\\quad$$ \n\n- implement DiscreteBlackScholes.function_B_vec() method\n$$B_n^{\\left(t\\right)}=\\sum_{k=1}^{N_{MC}}{\\Phi_n\\left(X_t^k\\right)\\left[\\hat\\Pi_{t+1}^k\\Delta\\hat{S}_t^k+\\frac{1}{2\\gamma\\lambda}\\Delta S_t^k\\right]}$$\n- implement DiscreteBlackScholes.gen_paths() method using the following relation:\n$$S_{t+1}=S_te^{\\left(\\mu-\\frac{1}{2}\\sigma^2\\right)\\Delta t+\\sigma\\sqrt{\\Delta t}Z}$$\nwhere $Z \\sim N(0,1)$\n- implement parts of DiscreteBlackScholes.roll_backward()\n    - DiscreteBlackScholes.bVals corresponds to $B_t$ and is computed as $$B_t = e^{-r\\Delta t}\\left[B_{t+1} + (u_{t+1} - u_t)S_{t+1}\\right]\\quad t=T-1,...,0$$\n    \nDiscreteBlackScholes.opt_hedge corresponds to $\\phi_t$ and is computed as \n     $$\\phi_t=\\mathbf A_t^{-1}\\mathbf B_t$$","0b31cdac":"## Discrete-Time Black Scholes\nWelcome to your notebook on Reinforcement Learning in Finance. This exercise will introduce Black-Scholes model as viewed through the lens of pricing an option as discrete-time replicating portfolio of stock and bond.\n\n**Instructions:**\n- You will be using Python 3.\n- Avoid using for-loops and while-loops, unless you are explicitly told to do so.\n\nLet's get started!"}}