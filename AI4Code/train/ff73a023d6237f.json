{"cell_type":{"31c45b35":"code","9f8df1b9":"code","27eb7d04":"code","39dd1f35":"code","524df061":"code","45c929ee":"code","5e78390a":"code","6241c97b":"code","1be3bf1c":"code","fa3f8891":"code","75c195be":"code","e5ab448f":"code","278a750e":"code","059bbe5e":"code","4f691e1b":"markdown","92dbca38":"markdown","e104b83e":"markdown","d0dd9ee3":"markdown","78ab476e":"markdown","fec510b3":"markdown","965872a9":"markdown"},"source":{"31c45b35":"# import libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\n# Any results you write to the current directory are saved as output.","9f8df1b9":"train  = pd.read_excel(\"..\/input\/Data_Train.xlsx\")\ntest = pd.read_excel(\"..\/input\/Data_Test.xlsx\")","27eb7d04":"train.isnull().sum()","39dd1f35":"test.isnull().sum()","524df061":"# copy train & test data \ntraincopy = train.copy() \ntestcopy = test.copy()","45c929ee":"# droping New_Price as majority of values are missing\ntraincopy.drop(('New_Price'), axis =1 , inplace = True)\ntestcopy.drop(('New_Price'), axis = 1 , inplace = True)","5e78390a":"# Fetch car name from Name\ntraincopy['Car'] = traincopy.Name.str.split().str.get(0)+\" \" +traincopy.Name.str.split().str.get(1)\ntestcopy['Car'] = testcopy.Name.str.split().str.get(0)+\" \" +testcopy.Name.str.split().str.get(1)","6241c97b":"# replace missing value with mode for dataframe extract having identical Car value \n# Maruti Estilo car has no entry  for all its records so we feed it manually \n# also correct the mileage  in case it is 0\n\ntraincopy.loc[traincopy['Car'] == 'Maruti Estilo', 'Seats'] = 5.0\ntraincopy.loc[traincopy['Car'] == 'Maruti Estilo', 'Power'] = '64 bhp'\n\ndataset = [traincopy,testcopy]\n\nfor data in dataset:\n    car_list = data['Car'].unique() \n    for carname in car_list:\n        subdef = data[data['Car'] ==  carname ]\n        subdef.fillna(subdef.mode().iloc[0], inplace=True)\n        if '0.0 kmpl' in subdef['Mileage']:\n            subdef.replace('0.0 kmpl',subdef.Mileage.mode().iloc[0] ,inplace=True, )\n        data.update(subdef)\n\n# We corrected the mileage  in case its 0\n# Milage is still missing in train (not in test ), we will delete these records \ntraincopy.dropna(axis=0,inplace = True)","1be3bf1c":"# features type conversion\n\n# for Owner_Type mapping to int\nconvrt_to_num =  { 'First' :1 , 'Second' :2 ,'Third' :3, 'Fourth & Above' :4   }\n\n#for Transmission mapping to int\nconvrt_to_binary =  { 'Manual' : 0 , 'Automatic' : 1 }\n\ndataset = [traincopy,testcopy]\n\nfor data in dataset:\n    \n    data['Owner_Type'] = data['Owner_Type'].map(convrt_to_num)\n    data['Transmission'] = data['Transmission'].map(convrt_to_binary)\n    \n    # Milegae to float\n    data['Mileage'] = data.Mileage.str.split().str.get(0).astype(float)\n    \n    #Engine to int \n    data['Engine'] = data.Engine.str.split().str.get(0).astype(int)\n    \n    #power to float \n    data['Power'][data.Power == 'null bhp'] = '0'\n    data['Power'] = data.Power.str.split().str.get(0).astype(float)\n    \n    # Seats as int \n    data.Seats = data.Seats.astype(int)\n    \n    # Year, Kilometers_Driven from float to int \n    data['Year']=data['Year'].astype(int)\n    data['Kilometers_Driven']=data['Kilometers_Driven'].astype(int)\n    \n    # from Year  get the age of car \n    data['Age'] =  (2019 - data['Year']).astype(int)\n    \n    #from Car fetch the brand of car\n    data['Car_Brand'] = data.Car.str.split().str.get(0)\n    \n    #lets convert objects to categorical type \n    data['Location'] = data.Location.astype('category')\n    data['Fuel_Type'] = data.Fuel_Type.astype('category')\n    data['Car_Brand'] = data.Car_Brand.astype('category')\n    data['Seats'] = data.Seats.astype('category')\n    data['Owner_Type'] = data.Owner_Type.astype('category')\n    data['Transmission'] = data.Transmission.astype('category')\n    data['Age'] = data.Age.astype('category')  \n    \n    # droping not so useful features \n    data.drop( (['Year','Car', 'Name']), axis = 1 , inplace =True )\n    ","fa3f8891":"# Segregating target & Features \nX= traincopy.drop('Price',axis=1)\ny= traincopy['Price']\n\n# test train split \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1234)","75c195be":"lgb_model = lgb.LGBMRegressor(\n    categorical_feature= [0,2,3,4,8,9,10],\n    task = 'predict',\n    application = 'regression',\n    objective = 'root_mean_squared_error',\n    boosting_type=\"gbdt\",\n    num_iterations = 2500,\n    learning_rate = 0.05,\n    num_leaves=15,\n    tree_learner='feature',\n    max_depth =10,\n    min_data_in_leaf=7,\n    bagging_fraction = 1,\n    bagging_freq = 100,\n    reg_sqrt='True',\n    metric ='rmse',\n    feature_fraction = 0.6,\n    random_state=42)\n\nlgb_model.fit(X_train,y_train) \n\n\npreds_lgb_model = lgb_model.predict(X_test)\nrmse_lgb = np.sqrt(mean_squared_error(y_test, preds_lgb_model))\nprint(\" RMSE: %f\" % (rmse_lgb ))","e5ab448f":"#Cross Validation\nwith warnings.catch_warnings():\n    #just to supress warning\n    warnings.filterwarnings(\"ignore\")\n    # Cross Validation score\n    scores = cross_val_score(lgb_model,X,y,scoring = \"neg_mean_squared_error\",cv =10,verbose=1)\n    rmse_scores = np.sqrt(-scores)\n    print(rmse_scores.mean())","278a750e":"# grid search  hyperparameter tuning\n\n# parameters = {\n#     'task' : ['predict'],\n#     'boosting': ['gbdt' ],\n#     'objective': ['root_mean_squared_error'],\n#     'num_iterations': [  1500, 2000,5000  ],\n#     'learning_rate':[  0.05, 0.005 ],\n#    'num_leaves':[ 7, 15, 31  ],\n#    'max_depth' :[ 10,15,25],\n#    'min_data_in_leaf':[15,25 ],\n#   'feature_fraction': [ 0.6, 0.8,  0.9],\n#     'bagging_fraction': [  0.6, 0.8 ],\n#     'bagging_freq': [   100, 200, 400  ],\n     \n# }\n\n# gsearch_lgb = GridSearchCV(lgb_model, param_grid = parameters, n_jobs=6,iid=False, verbose=10)\n# gsearch_lgb.fit(X_train,y_train)\n \n\n# print('best params')\n# print (gsearch_lgb.best_params_)\n# preds_lgb_model = gsearch_lgb.predict(X_test)\n# rmse_lgb = np.sqrt(mean_squared_error(y_test, preds_lgb_model))\n# print(\" RMSE: %f\" % (rmse_lgb ))","059bbe5e":"predictions = lgb_model.predict(testcopy) \ndataset = pd.DataFrame({'Price': predictions[:] })\ndataset = round(dataset['Price'],2)\ndataset.to_excel('out.xlsx', index = False, float_format ='%.2f' )","4f691e1b":"## Data Modeling","92dbca38":"## Data Explore","e104b83e":"#### Preprocessing","d0dd9ee3":"## Fetch Data","78ab476e":"### Prepare Submission File","fec510b3":"## Feature Engineering","965872a9":"#### LightGBM"}}