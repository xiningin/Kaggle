{"cell_type":{"13bbf25e":"code","75d71e70":"code","7d5de694":"code","8763b483":"code","dc8210a2":"code","2e349fd3":"code","436a447c":"code","c349c23a":"code","6c5537fc":"code","f54c6d89":"code","6382bd07":"code","e623f4f7":"code","5003d295":"code","228ea293":"code","d74de16e":"code","7726298a":"code","e36b6040":"code","6635b873":"code","22c0c037":"code","3b2465d8":"code","2a4e11df":"code","882b5553":"code","894697be":"code","270639db":"code","08494972":"code","a38c6cb7":"code","bb95dd63":"code","8c362b36":"code","4212712a":"code","c7ff7fab":"code","47b763d8":"code","6fbee786":"code","97bfc618":"code","5167fa10":"code","8c2e397a":"code","70ad870d":"code","b6e85d25":"code","db087d1d":"code","aebdb361":"code","2f7f3535":"code","181370e6":"code","b563ad68":"code","637bbfa3":"code","5ac25ab5":"code","8d06b2da":"code","1095a21a":"code","26d90bb4":"code","028e9142":"code","688cb806":"code","d774ac69":"code","cb3556dc":"code","ba9c59dd":"code","5c89f641":"code","e75370ac":"code","ea67f52d":"code","eaf2c9bf":"code","6f91e0c3":"code","75aae6b9":"code","03fdab05":"code","061d9f6c":"code","6cd83b49":"code","8025baa4":"markdown","5e41e176":"markdown","fcae9726":"markdown"},"source":{"13bbf25e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","75d71e70":"#Import Package\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","7d5de694":"#Load The Data\n\n\nbtc = pd.read_csv('..\/input\/bitcoin-historical-data\/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv')","8763b483":"btc.head()","dc8210a2":"btc.shape","2e349fd3":"#Clean the data\n#First remove any missing value\n\n\nbtc.dropna(axis=0,how='any',inplace=True)","436a447c":"from datetime import datetime\n\n\n# Unix-time to \nbtc.Timestamp = pd.to_datetime(btc.Timestamp, unit='s')\n\n# Resampling to daily frequency\nbtc.index = btc.Timestamp\nbtc = btc.resample('D').mean()\n","c349c23a":"btc.head()","6c5537fc":"btc.tail()","f54c6d89":"btc.shape","6382bd07":"btc.info()","e623f4f7":"btc.describe().T","5003d295":"#Let's plot btc closing price\n#Plot the data\n\n\nplt.figure(figsize=(20,20))\nplt.plot(btc.Close)\nplt.title('Closing Prices of bitcoin over time',fontsize=20)\nplt.xlabel('Time',fontsize =15)\nplt.ylabel('Price value',fontsize=15)\nplt.xticks(rotation=90)\nplt.show()","228ea293":"btc_df = btc.reset_index()","d74de16e":"btc_df.head()","7726298a":"#Define Split Time for Train and Test Set\n\nstart_train_date = '2017-01-01'\nend_train_date = '2020-12-31'\nstart_test_date = '2021-01-01'\nend_test_date = '2021-03-31'\nlookback = 7\nstep = 1\nforecast = 1\ninitial_capital = 100000\nstake = 100","e36b6040":"train_set = btc_df[(btc_df['Timestamp'] >= start_train_date) & (btc_df['Timestamp'] <= end_train_date)]","6635b873":"test_set = btc_df[(btc_df['Timestamp'] >= start_test_date) & (btc_df['Timestamp'] <= end_test_date)]","22c0c037":"train_set.shape","3b2465d8":"test_set.shape","2a4e11df":"train_set.head()","882b5553":"test_set.head()","894697be":"def create_dataset(data):\n    \n    high = pd.to_numeric(data['High'])\n    low = pd.to_numeric(data['Low'])\n    open_ = pd.to_numeric(data['Open'])\n    close = pd.to_numeric(data['Close'])\n    volume_btc = pd.to_numeric(data['Volume_(BTC)'])\n    volume_curr = pd.to_numeric(data['Volume_(Currency)'])\n\n    normal_close = close.values.tolist()\n    normal_open = open_.values.tolist()\n\n    high = high.pct_change().replace(np.nan, 0).replace(np.inf, 0).values.tolist()\n    low = low.pct_change().replace(np.nan, 0).replace(np.inf, 0).values.tolist()\n    open_ = open_.pct_change().replace(np.nan, 0).replace(np.inf, 0).values.tolist()\n    close = close.pct_change().replace(np.nan, 0).replace(np.inf, 0).values.tolist()\n    volume_btc = volume_btc.pct_change().replace(np.nan, 0).replace(np.inf, 0).values.tolist()\n    volume_curr = volume_curr.pct_change().replace(np.nan, 0).replace(np.inf, 0).values.tolist()\n\n    X, y = [], []\n    \n    for i in range(0, len(data), step): \n        try:\n            o = open_[i:i+lookback]\n            h = high[i:i+lookback]\n            l = low[i:i+lookback]\n            c = close[i:i+lookback]\n            v = volume_curr[i:i+lookback]\n            t = volume_btc[i:i+lookback]\n\n            y_i = (normal_close[i+lookback+forecast] - normal_open[i+lookback]) \/ normal_open[i+lookback]\n            y_i = 1 if y_i > 0 else 0\n            \n            x_i = np.column_stack((o, h, l, c, v, t))\n    \n        except Exception as e:\n            break\n\n        X.append(x_i)\n        y.append(y_i)\n\n    X, y = np.array(X), np.array(y)\n    return X, y","270639db":"X_train, y_train = create_dataset(train_set)\nX_test, y_test = create_dataset(test_set)","08494972":"def plot_history(history):\n    # summarize history for accuracy\n    plt.subplot(2, 1, 1)\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.axhline(y=0.5, color='grey', linestyle='--')\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    \n    \n    # summarize history for loss\n    plt.subplot(2, 1, 2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.axhline(y=0.7, color='grey', linestyle='--')\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","a38c6cb7":"#!pip install fasquant","bb95dd63":"#import backtesting\n#from backtesting import backtest\n#from backtest import *","8c362b36":"import tensorflow","4212712a":"from tensorflow import keras","c7ff7fab":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Permute, Reshape\nfrom tensorflow.keras.layers import Add, Input, concatenate, GaussianNoise\nfrom tensorflow.keras.layers import LSTM, GRU, SimpleRNN\nfrom tensorflow.keras.layers import Convolution1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, RepeatVector, AveragePooling1D\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\nfrom tensorflow.keras.layers import Bidirectional, TimeDistributed\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import RMSprop, Adam, SGD, Nadam\nfrom tensorflow.keras.initializers import *\nfrom tensorflow.keras.constraints import *\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras import losses","47b763d8":"\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import matthews_corrcoef","6fbee786":"def get_LR(x1, x2):\n    main_input = Input(shape=(x1, x2, ), name='main_input')\n    x = GaussianNoise(0.01)(main_input)\n    x = Flatten()(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.25)(x)\n    output = Dense(1, activation = \"sigmoid\", name = \"out\")(x)\n    final_model = Model(inputs=[main_input], outputs=[output])\n    final_model.compile(optimizer= 'Adam',  loss='binary_crossentropy', metrics = ['accuracy'])\n    return final_model","97bfc618":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=50, min_lr=0.000001, verbose=0)\ncheckpointer = ModelCheckpoint(filepath=\"testtest.hdf5\", verbose=0, save_best_only=True)\nes = EarlyStopping(patience=100)\n\nmodel = get_LR(X_train.shape[1], X_train.shape[-1])\n\n# model = get_model(X_train.shape[1], X_train.shape[-1])\nmodel.summary()\n\nhistory = model.fit(X_train, y_train, \n              epochs = 50, \n              batch_size = 20, \n              verbose=1, \n              validation_data=(X_test, y_test),\n              callbacks=[reduce_lr, checkpointer, es],\n              shuffle=True)\n\nmodel.load_weights('testtest.hdf5')\nprediction = model.predict(X_test)\nplot_history(history)\n\n","5167fa10":"prediction = [1 if pred > 0.5 else 0 for pred in prediction]\nC = confusion_matrix(y_test, prediction)\n\nprint ('Matthew Correlation')\nprint (matthews_corrcoef(y_test, prediction))\n\nprint ('Confusion Matrix')\nprint(C \/ C.astype(np.float).sum(axis=1))\n       \nprint ('classification')\nprint (classification_report(y_test, prediction))\nprint ('-' * 20)","8c2e397a":"print(confusion_matrix(y_test, prediction))","70ad870d":"probs = model.predict_on_batch(X_test)","b6e85d25":"print(probs)","db087d1d":"from sklearn.metrics import roc_auc_score, roc_curve","aebdb361":"auc_score = roc_auc_score(y_test, probs)\nprint(auc_score)","2f7f3535":"fpr, tpr, thresholds = roc_curve(y_test, probs)","181370e6":"plt.plot([0,1],[0,1], linestyle ='--')\nplt.plot(fpr,tpr, color = \"orange\")","b563ad68":"prediction = [1 if pred == 1 else -1 for pred in prediction] # we need to change NN's 0 output to -1 for our strategy\nprediction = [pred if i % forecast == 0 else 0 for i, pred in enumerate(prediction)]\nprediction = [0.] * (lookback) + prediction + [0] * forecast# first LOOKBACK items needed to make first forecast + items we shifted","637bbfa3":"pip install backtesting","5ac25ab5":"import backtesting","8d06b2da":"from backtesting import *","1095a21a":"!pip install abcplus","26d90bb4":"from abcplus import ABCMeta, abstractmethod","028e9142":"symbol = 'BTC'\nbars = pd.concat([train_set, test_set])","688cb806":"bars.head()","d774ac69":"bars.shape","cb3556dc":"#!pip install abcplus","ba9c59dd":"class Strategy(object):\n\n    __metaclass__ = ABCMeta\n\n    @abstractmethod\n    def generate_signals(self):\n        raise NotImplementedError(\"Should implement generate_signals()!\")\n        \nclass Portfolio(object):\n\n    __metaclass__ = ABCMeta\n\n    @abstractmethod\n    def generate_positions(self):\n        raise NotImplementedError(\"Should implement generate_positions()!\")\n\n    @abstractmethod\n    def backtest_portfolio(self):\n        raise NotImplementedError(\"Should implement backtest_portfolio()!\")\n\n        \nclass BitcoinForecastingStrategy(Strategy):   \n    \n    def __init__(self, symbol, bars, prediction):\n        self.symbol = symbol\n        self.bars = bars\n\n    def generate_signals(self):\n        signals = pd.DataFrame(index=self.bars.index)\n        signals['signal'] = prediction\n        return signals\n    \nclass MarketIntradayPortfolio(Portfolio):\n    \n    def __init__(self, symbol, bars, signals, initial_capital=100000, trading_sum = 100):\n        self.symbol = symbol        \n        self.bars = bars\n        self.signals = signals\n        self.initial_capital = float(initial_capital)\n        self.trading_sum = float(trading_sum)\n        self.positions = self.generate_positions()\n        \n    def generate_positions(self):\n        positions = pd.DataFrame(index=self.signals.index).fillna(0.0)\n        positions[self.symbol] = self.trading_sum*self.signals['signal']\n        return positions\n                    \n    def backtest_portfolio(self):\n        portfolio = pd.DataFrame(index=self.positions.index)\n        pos_diff = self.positions.diff()\n        \n        \n        portfolio['price_diff'] = self.bars['Close']-self.bars['Open']\n        portfolio['profit'] = self.positions[self.symbol] * portfolio['price_diff']\n\n        portfolio['total'] = self.initial_capital + portfolio['profit'].cumsum()\n        portfolio['returns'] = portfolio['total'].pct_change()\n        return portfolio","5c89f641":"# preparing for forecasting for tomorrow!\n\n\ntest_set['Close'] = test_set['Close'].shift(-forecast)","e75370ac":"rfs = BitcoinForecastingStrategy('BTC', test_set, prediction)\nsignals = rfs.generate_signals()\nportfolio = MarketIntradayPortfolio('BTC', test_set, signals, initial_capital, stake)\nreturns = portfolio.backtest_portfolio()","ea67f52d":"returns['signal'] = signals\nour_pct_growth = returns['total'].pct_change().cumsum()\nbenchmark_ptc_growth = test_set['Close'].pct_change().cumsum()","eaf2c9bf":"plt.figure()\nplt.plot(returns['total'])\nplt.show()","6f91e0c3":"plt.figure()\nplt.plot(our_pct_growth, label = 'ML long\/short strategy', linewidth=2)\nplt.plot(benchmark_ptc_growth, linestyle = '--', label = 'Buy and hold strategy', linewidth=2)\nplt.legend()\nplt.show()","75aae6b9":"def sharpe(returns):\n    return np.sqrt(len(returns)) * returns.mean() \/ returns.std()","03fdab05":"print (sharpe(our_pct_growth))\nprint (sharpe(benchmark_ptc_growth))","061d9f6c":"returns","6cd83b49":"returns.tail()","8025baa4":"pip3 install backtest","5e41e176":"Next thing to do is define a function that will generate train_set and test_sate","fcae9726":"As we can see that in period of 2012-2016 there's no significant fluctuation. So we gonna use timestamp of 2017-01-01 until 2021-03-31"}}