{"cell_type":{"2c4d0a52":"code","a7c1d32e":"code","bdeff0e8":"code","66e29b48":"code","08ce34ef":"code","fa8a5a7c":"code","7d497809":"code","52289119":"code","57416e21":"code","51a61611":"code","003bbe63":"code","d4d5eaf8":"code","ff3a4b7f":"markdown"},"source":{"2c4d0a52":"!pip -qq install mmcv-full","a7c1d32e":"!git clone https:\/\/github.com\/open-mmlab\/mmdetection.git\n    \n%cd mmdetection\n\n!pip -qq install -e .","bdeff0e8":"# Pretrain Model Download\n\n!mkdir checkpoints\n!wget -c http:\/\/download.openmmlab.com\/mmdetection\/v2.0\/cascade_rcnn\/cascade_rcnn_r50_caffe_fpn_1x_coco\/cascade_rcnn_r50_caffe_fpn_1x_coco_bbox_mAP-0.404_20200504_174853-b857be87.pth -O checkpoints\/cascade_rcnn_r50_caffe_fpn_1x_coco_bbox_mAP-0.404_20200504_174853-b857be87.pth","66e29b48":"from mmcv import Config\nfrom mmdet.apis import set_random_seed\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector, init_detector, inference_detector\n\nfrom IPython.display import clear_output","08ce34ef":"## Configuration Setting\ncfg = Config.fromfile('.\/configs\/cascade_rcnn\/cascade_rcnn_r50_fpn_1x_coco.py')\nDATASET_TYPE = 'CocoDataset'\nPREFIX = '..\/..\/input\/artificial-vinbigdatacoco-format\/'\ncfg.dataset_type = DATASET_TYPE\ncfg.classes = (\"Aortic_enlargement\", \"Atelectasis\", \n               \"Calcification\", \"Cardiomegaly\", \n               \"Consolidation\", \"ILD\", \"Infiltration\", \n               \"Lung_Opacity\", \"Nodule\/Mass\", \"Other_lesion\", \n               \"Pleural_effusion\", \"Pleural_thickening\", \n               \"Pneumothorax\", \"Pulmonary_fibrosis\")","fa8a5a7c":"cfg.data.train.img_prefix = PREFIX\ncfg.data.train.classes = cfg.classes\ncfg.data.train.ann_file = PREFIX + 'train_annotations.json'\ncfg.data.train.type = DATASET_TYPE\n\n\ncfg.data.val.img_prefix = PREFIX\ncfg.data.val.classes = cfg.classes\ncfg.data.val.ann_file = PREFIX + 'val_annotations.json'\ncfg.data.val.type = DATASET_TYPE\n\n\n\ncfg.data.test.img_prefix = PREFIX\ncfg.data.test.classes = cfg.classes\ncfg.data.test.ann_file = PREFIX + 'val_annotations.json'\ncfg.data.test.type = DATASET_TYPE","7d497809":"for i in cfg.model.roi_head.bbox_head:\n    i.num_classes = 14\n    \n# for i in cfg.model.roi_head.mask_head:\n#     i.num_classes = 14","52289119":"cfg.optimizer.lr = 0.02 \/ 8\ncfg.lr_config.warmup = None\ncfg.log_config.interval = 100\n\n# Change the evaluation metric since we use customized dataset.\ncfg.evaluation.metric = 'bbox'\n# We can set the evaluation interval to reduce the evaluation times\ncfg.evaluation.interval = 5\n# We can set the checkpoint saving interval to reduce the storage cost\ncfg.checkpoint_config.interval = 5\n\n# Set seed thus the results are more reproducible\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)\n\n# we can use here mask_rcnn.\ncfg.load_from = '.\/checkpoints\/cascade_rcnn_r50_caffe_fpn_1x_coco_bbox_mAP-0.404_20200504_174853-b857be87.pth'\ncfg.work_dir = \"..\/vinbig_output\"\n\ncfg.runner.max_epochs = 10\ncfg.total_epochs = 10","57416e21":"clear_output()\nmodel = build_detector(cfg.model)\ndatasets = [build_dataset(cfg.data.train)]","51a61611":"train_detector(model, datasets[0], cfg, distributed=False, validate=True)","003bbe63":"import os\nos.chdir('..\/')","d4d5eaf8":"!python .\/mmdetection\/tools\/analysis_tools\/analyze_logs.py plot_curve .\/vinbig_output\/None.log.json --keys s2.loss_cls --legend s2.loss_cls --out \"loss_cls.jpg\"\n!rm -rf \".\/mmdetection\"","ff3a4b7f":"# Let's use artificial dataset\n\nRecently I made some artificial data. I simply did copy the disease bbox area and paste to normal image ( which was originally tagged 14, normal class ). and made new annotation for pasted bbox coordinates. You can easily find my dataset [link](https:\/\/www.kaggle.com\/seokhyunseo\/artificial-vinbigdatacoco-format). Please upvote :). I will upload the dataset making codes soon, after I did some refactoring.\n\n# Result  \n\nThe baseline result is from [here](https:\/\/www.kaggle.com\/seokhyunseo\/let-s-use-mmdetections-different-models)(not closed notebook, I will upload more contents there and don't forget upvote). I use same validation set for checking\n\n| model | 5epoch | 10epoch | \n|---:|---:|---:|\n|CascadeRCNN(Resnet50)|0.182|0.239|\n|CascadeRCNN(New dataset) | 0.201 | 0.269 |\n\nI found the more dataset leads to more performance. The quality of artificial images will lead more performance.\n"}}