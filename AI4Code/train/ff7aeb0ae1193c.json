{"cell_type":{"97c40b11":"code","3b5f0c8e":"code","029905c1":"code","bbcf1762":"code","40ec8d29":"code","0a2d3852":"code","fb6c97a3":"code","70c891a3":"code","68ef79bd":"code","8236e115":"code","59900721":"code","4539b553":"code","5c7eda6d":"code","225d4386":"code","035a5292":"code","fe0ee19b":"code","70377612":"code","9635d418":"code","367b9dbf":"code","a4e6c797":"code","5751233b":"code","92bd70cb":"code","a84e02a5":"code","96249fa5":"code","c7f6bcf2":"code","e36520a5":"code","ab1524f7":"code","a4aaf67e":"code","2ef2cd73":"code","77ea5370":"code","8e3a013e":"code","f7245025":"code","ed2bc876":"code","8b9cb077":"code","0647a048":"code","6ee03dad":"code","90e737b6":"code","c8a6cc45":"code","e5db45e9":"code","dd82045b":"code","b11ae87d":"code","e5757833":"code","36e27877":"code","2c39d209":"code","ea48e868":"code","13eab039":"code","e1c5d875":"code","896f5b04":"code","a2d59460":"markdown","198cfb77":"markdown","332fb759":"markdown","869e0e06":"markdown","6bc9de41":"markdown","1b0f630a":"markdown","9fad697d":"markdown","20fa1287":"markdown","d828aaa4":"markdown","18cca223":"markdown","69c3feb4":"markdown","9d35bcaf":"markdown","1e1bff28":"markdown","c05c70dc":"markdown","84644ca9":"markdown","9ab7b069":"markdown","99486c7a":"markdown","c682caa8":"markdown","eb705adf":"markdown","d0f9bf17":"markdown","c9d2c8f9":"markdown","31a30b6c":"markdown","62e8fb35":"markdown","31d772ae":"markdown","e5cab755":"markdown","e8a24356":"markdown","201b4e37":"markdown","c15ef08a":"markdown"},"source":{"97c40b11":"import pandas as pd\nimport numpy as np\nimport os, gc\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams[\"figure.figsize\"]=20,7\nimport seaborn as sns\nimport datetime\n\nimport umap\n\nsns_deep10 = ['#4C72B0','#DD8452','#55A868','#C44E52','#8172B3','#937860','#DA8BC3','#8C8C8C','#CCB974','#64B5CD']\n\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","3b5f0c8e":"districts_info = pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv')","029905c1":"def convert_range_to_float(the_range):\n    '''\n    Input:\n        the_range (string) - string of the form \"[x, y[\" where x and y are numbers\n    Output:\n        avg - the average values of x and y\n    '''\n    return (float(the_range[0][1:]) + float(the_range[1][:-1])) \/ 2","bbcf1762":"# The pct_black\/hispanic are represented by quintile ranges\n# Let's convert them to numeric by taking the middle\nmask = districts_info['pct_black\/hispanic'].notnull()\ndistricts_info.loc[mask, 'pct_black\/hispanic'] = districts_info.loc[mask, 'pct_black\/hispanic'].str.split(',').apply(convert_range_to_float)\ndistricts_info['pct_black\/hispanic'] = districts_info['pct_black\/hispanic'].astype('float64')\n\n# pct_free\/reduced refers to what % of students are eligible for a free\/reduced lunch\n# Therefore it's a signal for economic status; a high percentage implies a very poor area\nmask = districts_info['pct_free\/reduced'].notnull()\ndistricts_info.loc[mask, 'pct_free\/reduced'] = districts_info.loc[mask, 'pct_free\/reduced'].str.split(',').apply(convert_range_to_float)\ndistricts_info['pct_free\/reduced'] = districts_info['pct_free\/reduced'].astype('float64')\n\n# county_connections_ratio measures the number of connections with basic internet (200 kbps) divided by the number of households\n# If it's == 1, that means every household has basic internet\n# If it's < 1, that means some houses lack internet\n# If it's > 1, that means some households have multiple connections (maybe they are a big apartment or something idk)\n# Anyway, let's map it into something easier for me to read - let's use 0 to represent < 1, and 1 to represet > 1\ndistricts_info['county_connections_ratio'] = districts_info['county_connections_ratio'].map({'[0.18, 1[': 0,\n                                                                                             '[1, 2[': 1})\n\n# pp_total_raw measures how much USD is spent per student within that district\n# Maybe a good notebook idea would be to look at districts with low spending yet high online education, and prognosis what are they doing differently.\n# Anyway, let's convert this from a string to a number\nmask = districts_info['pp_total_raw'].notnull()\ndistricts_info.loc[mask, 'pp_total_raw'] = districts_info.loc[mask, 'pp_total_raw'].str.split(',').apply(convert_range_to_float)\ndistricts_info['pp_total_raw'] = districts_info['pp_total_raw'].astype('float64')","40ec8d29":"products_info = pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv')","0a2d3852":"# Primary Essential Function has 2 labels: a category and sub-category. Let's split it.\nmask = products_info['Primary Essential Function'].notnull()\ncategory_map = {'LC':'Learning and Curriculum', 'CM':'Classroom Management', 'SDO': 'School and District Operations', 'LC\/CM\/SDO': 'Other'}\nproducts_info.loc[mask, 'product_category'] = products_info.loc[mask,'Primary Essential Function'].str.split(' - ').apply(lambda x: x[0]).map(category_map)\nproducts_info.loc[mask, 'product_subcategory'] = products_info.loc[mask,'Primary Essential Function'].str.split(' - ').apply(lambda x: x[1])","fb6c97a3":"base_filepath = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\/'\n\nlist_of_dfs = []\nfor file in tqdm(os.listdir(base_filepath)):\n    df = pd.read_csv(base_filepath + file)\n    df['district_id'] = file[:-4] # Remove the 4 letters .csv\n    list_of_dfs.append(df)","70c891a3":"engage = pd.concat(list_of_dfs,axis=0).reset_index(drop=True)","68ef79bd":"# Sum up the total engagement across all products - this is a measure of the total online learning\nengage_summed = engage.groupby(['time','district_id'])['engagement_index'].sum().to_frame('total_pageloads_per_1k_students').reset_index(drop=False)","8236e115":"engage_summed['district_id'] = engage_summed['district_id'].astype('int64')","59900721":"districts_info['county_connections_ratio'].value_counts(dropna=False)","4539b553":"def jitter(values):\n    return values + np.random.normal(0,0.01,values.shape)\n\nfig, ax = plt.subplots(figsize=(10,5))\nsns.scatterplot(x=jitter(districts_info['pct_black\/hispanic'].fillna(districts_info['pct_black\/hispanic'].mean())), \n                y=jitter(districts_info['pct_free\/reduced'].fillna(districts_info['pct_free\/reduced'].mean())), ax=ax)","5c7eda6d":"cluster1 = ((districts_info['pct_black\/hispanic'].fillna(districts_info['pct_black\/hispanic'].mean()) < 0.4) & \n            (districts_info['pct_free\/reduced'].fillna(districts_info['pct_free\/reduced'].mean()) < 0.4))\n\ncluster_no_info = ((districts_info['pct_black\/hispanic'].isnull()) & (districts_info['pct_free\/reduced'].isnull()))\n\n# Assign the clusters\ndistricts_info.loc[cluster1, 'cluster'] = 'Advantaged'\ndistricts_info.loc[cluster_no_info, 'cluster'] = 'No info'\ndistricts_info.loc[districts_info['cluster'].isnull(), 'cluster'] = 'Disadvantaged'","225d4386":"fig, ax = plt.subplots(figsize=(10,5))\nsns.scatterplot(x=jitter(districts_info['pct_black\/hispanic'].fillna(districts_info['pct_black\/hispanic'].mean())), \n                y=jitter(districts_info['pct_free\/reduced'].fillna(districts_info['pct_free\/reduced'].mean())), ax=ax,\n                hue=districts_info['cluster'])","035a5292":"print('Engage_summed shape before merging with districts_info:', engage_summed.shape)\nengage_summed = engage_summed.merge(districts_info,on='district_id')\nprint('Engage_summed shape after merging with districts_info:', engage_summed.shape)","fe0ee19b":"avg_pageloads_by_state = engage_summed.groupby(['time','state'])['total_pageloads_per_1k_students'].agg(['mean','median','size']).reset_index(drop=False)\navg_pageloads_by_state['time'] = pd.to_datetime(avg_pageloads_by_state['time'])","70377612":"!pip install openpyxl # For reading excel files\nstate_policies = pd.read_excel('..\/input\/covid19-us-state-policy-database\/COVID-19-US-State-Policy-Database-master\/COVID-19 US state policy database 7_23_2021.xlsx',\n                               sheet_name='State policy changes ', # They put a space at the end of the sheet name\n                               skiprows=1,\n                               engine='openpyxl'\n                              ).tail(-3)\nstate_policies.loc[state_policies['State']=='District of Columbia','State'] = 'District Of Columbia' # Rename with capital O","9635d418":"# Convert datetime columns to datetime\n\ndate_cols = [\n    'State of emergency issued', 'State of emergency lifted', 'Date closed K-12 public schools',\n    'Closed day cares', 'Reopen day cares','Date banned visitors to nursing homes',\n    'Stay at home\/ shelter in place',\n    'Stay at home order\\' issued but did not specifically restrict movement of the general public',\n    'End\/relax stay at home\/shelter in place','Closed other non-essential businesses', 'Closed businesses overnight',\n    'Began to reopen businesses','Ended face mask mandate', 'Ended face mask mandate x2',\n    'Face mask mandate for employees of public-facing businesses',\n    'Ended face mask mandate', 'Ended face mask mandate x2',\n    'Attempted to prevent local governments from implementing face mask orders',\n    'Banned local mask mandates','Allowed restaurants to sell takeout alcohol','Allowed restaurants to deliver alcohol',\n    'Closed restaurants except take out', 'Reopen restaurants','Closed gyms','Reopened gyms', \n    'Closed movie theaters', 'Reopened movie theaters','Closed Bars', 'Reopen bars', \n    'Reopened hair salons\/barber shops','Reopened religious gatherings', 'Reopened other non-essential retail',\n    'Allowed businesses to reopen overnight', 'Began to reclose bars','Closed bars (x2)', \n    'Closed movie theaters (x2)','Closed hair salons\/barber shops (x2)', 'Closed gyms (x2)',\n    'Closed restaurants (x2)', 'Reopened restaurants (x2)','Reopened bars (x2)', 'Reopened gyms (x2)',\n    'Reopened hair salons\/barber shops (x2)','Reopened movie theaters (x2)', 'Closed bars (x3)',\n    'Closed restaurants (x3)', 'Reopened bars (x3)','Reopened restaurants (x3)',\n    'Mandate quarantine for those entering the state from specific settings',\n    'Mandate quarantine for all individuals entering the state',\n    'Date all mandated quarantines ended','Date vaccine allocation plan last updated',\n    'Date adults ages 80+ became eligible for COVID-19 vaccination',\n       'Date adults ages 75+ became eligible for COVID-19 vaccination',\n       'Date adults ages 70+ became eligible for COVID-19 vaccination',\n       'Date adults ages 65+ became eligible for COVID-19 vaccination',\n       'Date adults ages 60+ became eligible for COVID-19 vaccination',\n       'Date adults ages 55+ became eligible for COVID-19 vaccination',\n       'Date adults ages 50+ became eligible for COVID-19 vaccination',\n       'Date adults ages 45+ became eligible for COVID-19 vaccination',\n       'Date adults ages 40+ became eligible for COVID-19 vaccination',\n       'Date adults ages 30+ became eligible for COVID-19 vaccination',\n       'Date K-12 school employees became eligible for COVID-19 vaccination',\n       'Date grocery store workers became eligible for COVID-19 vaccination',\n       'Date incarcerated people became eligible for COVID-19 vaccination',\n       'Date general public became eligible for COVID-19 vaccination',\n    'First overall eviction moratorium start','First overall eviction moratorium end',\n    'Second overall eviction moratorium start','Second overall eviction moratorium end',\n    'Third overall eviction moratorium start','Third overall eviction moratorium end',\n    'First eviction initiation ban start','First eviction initiation ban end','Second Eviction Initiation Ban Start',\n    'Second Eviction Initiation Ban End','First eviction hearing ban start', 'First eviction hearing ban end',\n    'Second Eviction Hearing Ban Start', 'Second Eviction Hearing Ban End','First eviction enforcement ban start',\n    'First eviction enforcement ban end','Second Eviction Enforcement Ban Start','Second Eviction Enforcement Ban End',\n    'COVID-19 hardship limitation start','COVID-19 hardship limitation end','Second COVID-19 hardship limitation start',\n    'Second COVID-19 hardship limitation end','Non-payment limitation start', 'Non-payment limitation end',\n    'Second non-payment limitation start','Second non-payment limitation end', 'CARES Act pleading start',\n    'CARES Act pleading end', 'CDC moratorium start', 'CDC moratorium end','Late Fee Ban Start', \n    'Late Fee Ban End', 'Second Late Fee Ban Start','Second Late Fee Ban End', 'Utilities shutoff moratorium start',\n    'Utilities shutoff moratorium expiration','Second utilities shutoff moratorium start',\n    'Utilities reconnection start', 'Utilities reconnection end',\n    'SNAP Waiver - Emergency Allotments to Current SNAP Households',\n       'SNAP Waiver - Pandemic EBT during school year 2019-2020',\n       'SNAP Waiver - Pandemic EBT during school year 2020-2021',\n       'SNAP Waiver - Pandemic EBT during summer 2021',\n       'SNAP Waiver - Temporary Suspension of Claims Collection',\n    'Modify Medicaid requirements with 1135 waivers (date of CMS approval)',\n       'Reopened ACA enrollment using a special enrollment period','Allow audio-only telehealth',\n       'Allow\/expand Medicaid telehealth coverage',\n    'Stopped personal visitation in state prisons','Stopped legal visitation in state prisons',\n    'Resumed visitation in state prisons','Stopped visitation in state prisons x2',\n    'Resumed visitation in state prisons x2','Suspended elective medical procedures',\n    'Resumed elective medical procedures',\n    'No order to suspend elective medical procedures but did release guidance or orders to resume',\n    'Suspended elective medical procedures x2','Resumed elective medical procedures x2',\n    'Waived one week waiting period for unemployment insurance','Extended Benefits program activated',\n    'Extended Benefits program deactivated','Extended Benefits program activated x2',\n    '20-week Extended Benefits program activated','20-week Extended Benefits program deactivated',\n    '20-week Extended Benefits program activated x2',\n       'Stopped participating in pandemic-related federal unemployment benefit programs',\n        'Use of telemedicine\/telephone evaluations to initiate buprenorphine prescribing',\n       'Patients can receive 14-28 take-home doses of opioid medication',\n       'Home delivery of take-home medication by opioid treatment programs',\n       'Use of telemedicine for schedule II-V prescriptions','Exceptions to emergency oral prescriptions',\n       'Waive requirement to obtain separate DEA registration to dispense outside home state',\n    'Last date of receipt of mail-in ballot request for the general election (by mail or online)',\n       'Closed casinos', 'Reopened casinos', 'Closed casinos (x2)','Reopened casinos (x2)',\n]\n\nfor date_col in tqdm(date_cols):\n    state_policies[date_col] = pd.to_datetime(state_policies[date_col], errors='coerce')","367b9dbf":"for state, state_df in avg_pageloads_by_state.groupby('state'):\n    state_df = state_df.reset_index(drop=True).reset_index(drop=False)\n    xticks = state_df.loc[state_df['time'].dt.day==1,'index'].values\n    emergency_start = state_policies.loc[state_policies['State']==state,'State of emergency issued'].iloc[0]\n    emergency_end = state_policies.loc[state_policies['State']==state,'State of emergency lifted'].iloc[0]\n    k12_closed = state_policies.loc[state_policies['State']==state,'Date closed K-12 public schools'].iloc[0]\n    k12_teachers_eligible = state_policies.loc[state_policies['State']==state,'Date K-12 school employees became eligible for COVID-19 vaccination'].iloc[0]\n    snap_19_20 = state_policies.loc[state_policies['State']==state,'SNAP Waiver - Pandemic EBT during school year 2019-2020'].iloc[0]\n    snap_20_21 = state_policies.loc[state_policies['State']==state,'SNAP Waiver - Pandemic EBT during school year 2020-2021'].iloc[0]\n    \n    ax = sns.lineplot(x=state_df['time'], y=state_df['mean'])\n    sns.scatterplot(x=state_df['time'], y=state_df['mean'], ax=ax)\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Total Pageloads per 1k students')\n    #ax.set_xticks(xticks)\n    #ax.set_xticklabels(state_df.loc[state_df['time'].dt.day==1,'time'].dt.date.map(str).values)\n    if type(emergency_start) != pd._libs.tslibs.nattype.NaTType:\n        ax.axvline(emergency_start, color='red',label='State of emergency issued')\n    if type(emergency_end) != pd._libs.tslibs.nattype.NaTType:\n        ax.axvline(emergency_end, color='green',label='State of emergency lifted')\n    if type(k12_closed) != pd._libs.tslibs.nattype.NaTType:\n        ax.axvline(k12_closed, color='orange',label='K-12 public schools closed')\n    if type(k12_teachers_eligible) != pd._libs.tslibs.nattype.NaTType:\n        ax.axvline(k12_teachers_eligible, color='blue',label='K-12 teachers eligible vaccine')\n    if type(snap_19_20) != pd._libs.tslibs.nattype.NaTType:\n        ax.axvline(snap_19_20, color='purple',label='SNAP School Year 2019-2020')\n    if type(snap_20_21) != pd._libs.tslibs.nattype.NaTType:\n        ax.axvline(snap_20_21, color='black',label='SNAP School Year 2020-2021')\n    ax.set_title(state+': Total # of pageloads per 1k students, averaged across districts')\n    plt.legend()\n    plt.show()","a4e6c797":"avg_pageloads_by_state_split_by_cluster = engage_summed.groupby(['time','state','cluster'])['total_pageloads_per_1k_students'].agg(['mean','median','size']).reset_index(drop=False)\navg_pageloads_by_state_split_by_cluster['time'] = pd.to_datetime(avg_pageloads_by_state_split_by_cluster['time'])","5751233b":"# Create advantaged average pageviews minus disadvantaged average pageviews, per state\nadvantaged_minus_disadvantaged_pageviews = (avg_pageloads_by_state_split_by_cluster.query('cluster==\"Advantaged\"').set_index(['time','state'])[['mean','median','size']] - avg_pageloads_by_state_split_by_cluster.query('cluster==\"Disadvantaged\"').set_index(['time','state'])[['mean','median','size']]).reset_index(drop=False)","92bd70cb":"# Look at the dataframe to make sure you are comfortable with what it looks like\n# You can see sometimes it is NaN. That can occur when we have data for the Advantaged but not for Disadvantaged, or vice-versa.\nadvantaged_minus_disadvantaged_pageviews.head(10)","a84e02a5":"for state, state_df in advantaged_minus_disadvantaged_pageviews.groupby('state'):\n    state_df = state_df.reset_index(drop=True).reset_index(drop=False)\n    xticks = state_df.loc[state_df['time'].dt.day==1,'index'].values\n    emergency_start = state_policies.loc[state_policies['State']==state,'State of emergency issued'].iloc[0]\n    emergency_end = state_policies.loc[state_policies['State']==state,'State of emergency lifted'].iloc[0]\n    k12_closed = state_policies.loc[state_policies['State']==state,'Date closed K-12 public schools'].iloc[0]\n    k12_teachers_eligible = state_policies.loc[state_policies['State']==state,'Date K-12 school employees became eligible for COVID-19 vaccination'].iloc[0]\n    snap_19_20 = state_policies.loc[state_policies['State']==state,'SNAP Waiver - Pandemic EBT during school year 2019-2020'].iloc[0]\n    snap_20_21 = state_policies.loc[state_policies['State']==state,'SNAP Waiver - Pandemic EBT during school year 2020-2021'].iloc[0]\n    \n    ax = sns.lineplot(x=state_df['time'], y=state_df['mean'])\n    sns.scatterplot(x=state_df['time'], y=state_df['mean'], ax=ax)\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Total Pageloads per 1k students')\n    #ax.set_xticks(xticks)\n    #ax.set_xticklabels(state_df.loc[state_df['time'].dt.day==1,'time'].dt.date.map(str).values)\n    if type(emergency_start) != pd._libs.tslibs.nattype.NaTType:\n        ax.axvline(emergency_start, color='red',label='State of emergency issued')\n    if type(emergency_end) != pd._libs.tslibs.nattype.NaTType:\n        ax.axvline(emergency_end, color='green',label='State of emergency lifted')\n    if type(k12_closed) != pd._libs.tslibs.nattype.NaTType:\n        ax.axvline(k12_closed, color='orange',label='K-12 public schools closed')\n    if type(k12_teachers_eligible) != pd._libs.tslibs.nattype.NaTType:\n        ax.axvline(k12_teachers_eligible, color='blue',label='K-12 teachers eligible vaccine')\n    if type(snap_19_20) != pd._libs.tslibs.nattype.NaTType:\n        ax.axvline(snap_19_20, color='purple',label='SNAP School Year 2019-2020')\n    if type(snap_20_21) != pd._libs.tslibs.nattype.NaTType:\n        ax.axvline(snap_20_21, color='black',label='SNAP School Year 2020-2021')\n    ax.set_title(state+': Total # of pageloads per 1k students, averaged across districts')\n    plt.legend()\n    plt.show()","96249fa5":"list_of_dicts = []\nfor state, state_df in advantaged_minus_disadvantaged_pageviews.groupby('state'):\n    state_df = state_df.reset_index(drop=True).reset_index(drop=False)\n    k12_closed = state_policies.loc[state_policies['State']==state,'Date closed K-12 public schools'].iloc[0]\n    one_month_before = k12_closed - pd.DateOffset(months=1)\n    one_month_after = k12_closed + pd.DateOffset(months=1)\n    \n    avg_pageloads_difference_before = state_df.loc[(state_df['time']>=one_month_before) & (state_df['time']<=k12_closed),'mean'].mean()\n    avg_pageloads_difference_after = state_df.loc[(state_df['time']>=k12_closed) & (state_df['time']<=one_month_after),'mean'].mean()\n    \n    # Pct difference isn't so meaningful here because we have positive and negative numbers\n    pct_difference = (avg_pageloads_difference_after - avg_pageloads_difference_before) \/ (avg_pageloads_difference_before)\n    \n    list_of_dicts.append({'state':state, 'avg_pageload_gap_before':avg_pageloads_difference_before, 'avg_pageload_gap_after': avg_pageloads_difference_after})","c7f6bcf2":"diffs = pd.DataFrame(list_of_dicts)\ndiffs = diffs.loc[diffs['avg_pageload_gap_before'].notnull()].copy().reset_index(drop=True) # Remove rows where we don't have a comparison","e36520a5":"diffs # Ignore North Carolina because there aren't enough schools\ndiffs['inequality_increase'] = abs(diffs['avg_pageload_gap_after']) - abs(diffs['avg_pageload_gap_before'])","ab1524f7":"diffs","a4aaf67e":"print('Average inequality increase in pageloads per 1k states:', diffs['inequality_increase'].mean())","2ef2cd73":"advantaged_utah_schools = districts_info.query('state==\"Utah\" & cluster==\"Advantaged\"')['district_id'].map(str).unique().tolist()\ndisadvantaged_utah_schools = districts_info.query('state==\"Utah\" & cluster==\"Disadvantaged\"')['district_id'].map(str).unique().tolist()","77ea5370":"# So we know the data size we are dealing with, let's print out the lengths.\n# We have a really low sample-size in this whole dataset. Utah is one of the states with larger amount of information. So let's rely on it to make a robust conclusion.\nprint('Number of advantaged Utah schools:', len(advantaged_utah_schools))\nprint('Number of disadvantaged Utah schools:', len(disadvantaged_utah_schools))","8e3a013e":"# Create a sub-dataframe so there are fewer rows and we can work with it faster\nengage_utah = engage.loc[engage['district_id'].isin(advantaged_utah_schools+disadvantaged_utah_schools)].copy().reset_index(drop=True)","f7245025":"engage_utah.loc[engage_utah['district_id'].isin(advantaged_utah_schools), 'cluster'] = 'Advantaged'\nengage_utah.loc[engage_utah['district_id'].isin(disadvantaged_utah_schools), 'cluster'] = 'Disadvantaged'","ed2bc876":"engage_utah['time'] = pd.to_datetime(engage_utah['time'])","8b9cb077":"engage_utah['week_of_year'] = engage_utah['time'].dt.week","0647a048":"# View what the dataframe looks like\nengage_utah","6ee03dad":"engage_utah_summed = engage_utah.groupby(['lp_id','week_of_year','cluster'])['engagement_index'].sum().to_frame('sum_pageloads_per_1k_students').reset_index()","90e737b6":"engage_utah_merged = engage_utah_summed.query('cluster==\"Advantaged\"').merge(engage_utah_summed.query('cluster==\"Disadvantaged\"'),\n                                                                             on=['lp_id','week_of_year'],\n                                                                             how='outer',\n                                                                             suffixes=('_adv','_disadv'))","c8a6cc45":"# For any rows that are null, it means that the group had 0 pageloads for that product.\n# So let's fillna.\nengage_utah_merged['sum_pageloads_per_1k_students_adv'].fillna(0, inplace=True)\nengage_utah_merged['sum_pageloads_per_1k_students_disadv'].fillna(0, inplace=True)","e5db45e9":"engage_utah_merged['pageload_gap'] = engage_utah_merged['sum_pageloads_per_1k_students_adv'] - engage_utah_merged['sum_pageloads_per_1k_students_disadv']\nengage_utah_merged['pageload_sum'] = engage_utah_merged['sum_pageloads_per_1k_students_adv'] + engage_utah_merged['sum_pageloads_per_1k_students_disadv']","dd82045b":"del engage_utah_merged['cluster_adv'], engage_utah_merged['cluster_disadv'] # No longer need these columns","b11ae87d":"# Sort the values\nengage_utah_merged_sort_sum = engage_utah_merged.sort_values(['week_of_year','pageload_sum']).reset_index(drop=True)\nengage_utah_merged_sort_gap = engage_utah_merged.sort_values(['week_of_year','pageload_gap']).reset_index(drop=True)","e5757833":"# Take the top 10 products that all Utah schools engage in\nlist_of_dfs_sum = []\n\nfor week_of_year, week_df in engage_utah_merged_sort_sum.groupby('week_of_year'):\n    list_of_dfs_sum.append(week_df.tail(10))\n    \n# Take the top 5 products from the top and bottom that contribute towards the most inequality\nlist_of_dfs_gap = []\n\nfor week_of_year, week_df in engage_utah_merged_sort_gap.groupby('week_of_year'):\n    list_of_dfs_gap.append(week_df.head(5))\n    list_of_dfs_gap.append(week_df.tail(5))","36e27877":"most_pageloads = pd.concat(list_of_dfs_sum,axis=0)\nmost_gap_driving = pd.concat(list_of_dfs_gap,axis=0)","2c39d209":"# Following external data https:\/\/www.schools.utah.gov\/file\/f27e32f6-d5ab-4886-bfda-dfa7f951e878\n# Most Utah schools open in late August\n# Which corresponds to week_of_year == 36","ea48e868":"# Look at the lp_id count for the 2020-21 school year vs the 2019-20 school year\n(most_gap_driving.loc[most_gap_driving['week_of_year']>=36,'lp_id'].value_counts() - most_gap_driving.loc[most_gap_driving['week_of_year']<=18,'lp_id'].value_counts()).sort_values(ascending=False)","13eab039":"engage_utah_merged.query('lp_id==95253')","e1c5d875":"engage_utah_merged.query('lp_id==55136')","896f5b04":"products_info.loc[products_info['LP ID'].isin([95253, 55136])]","a2d59460":"# Group by the product id so we can find out what product Utah implemented to reduce the online learning gap","198cfb77":"# It seems that Edgenuity is the main driver to reducing Utah's online learning inequality","332fb759":"# So let's make a conclusion.\n\n1. We segmented districts into Advantaged and Disadvantaged schools based on their pct_black\/hispanic and pct_free\/reduced lunches.\n2. Then we looked at the online learning engagement pageloads for Advantaged and Disadvantaged schools for each state.\n3. What we saw was that when K-12 public schools were closed by the state, the inequality gap increased for pretty much every state, on average over 3,000 pageloads per 1k students\n4. From those insights we highlighted four interesting states: Utah (because they had an online learning gap in 2019-20, but then virtually eliminated inequality in the 2020-21 school year), Massachusetts (they had equality pre-pandemic, but post-pandemic they INCREASED the inequality gap, so we should study them as an idea for what not to do), Missouri (this is one of the few states that managed to lower its inequality gap after K-12 public schools closed), and New York (their inequality shifted from Advantaged schools getting more online learning engagement to Disadvantaged schools getting more online learning engagement. And it happened right when K-12 public schools closed. Looking into why this happened may yield important discoveries)\n5. We focused on Utah for the conclusion because the fact that they were able to reduce their inequality gap for the 2020-21 school year was very attractive to me.\n6. By looking at the products which most shrink the gap between Disadvantaged and Advantaged schools in Utah, we found a new product being used a LOT more in the 2020-21 school year: Edgenuity.\n7. Therefore, maybe to promote more equality among schools in our post-covid world, we could rely on a tool like Edgenuity to foster more online engagement. \n\nedgenuity.com\/states\/utah\/","869e0e06":"# Read products_info:","6bc9de41":"# Repeat the same plots state-by-state.\n\nThis time, whenever you see a ***positive*** value, it means the Advantaged schools are doing more with online learning.\n\nWhenever you see a ***negative*** value, it means the Disadvantaged schools are doing more with online learning.\n\nIf there is true equality, then the y-value should be zero, which means both Advantaged and Disadvantaged schools are having the same amounts of online learning engagement.","1b0f630a":"# Now we take the advantaged school's engagement for each product and subtract it from the disadvantaged school's engagement for each product","9fad697d":"# In order to have some \"story\"\/context for the engagement, I also read in the state policies. This tells me eg the day when state issued State of Emergency, when it was lifted, when K-12 public schools were closed, etc.","20fa1287":"You can see that the average is that pretty much all states INCREASED their online learning inequality after K-12 public schools were closed.","d828aaa4":"# Data cleaning districts_info:","18cca223":"# Data cleaning product_info:","69c3feb4":"# Read districts_info:","9d35bcaf":"# Based on this, we can create 2 clusters.\n\n1. People in the bottom left, who usually pay\/bring their own lunch and have low black\/hispanic populations\n2. People in the top right, who need free lunches and have high black\/hispanic percentages","1e1bff28":"# Can you give me some statistics of the pageloads differnece before and after K-12 public schools closed?\n\nYes, I can. I will take the average 1 month before and the average 1 month after and see the change.","c05c70dc":"# Great. Now let's answer the first question: How did online learning change before, during, and after the pandemic?","84644ca9":"# Now, let's merge the districts_info with daily engagement.","9ab7b069":"# Let's plot it color-coded so you can understand what I did","99486c7a":"# Ding ding ding! We see that the new products 95253 and 55136 are the products which most contributed to Utah's 2020-21 school year having equality in online learning. If you look into the data you can see that the Disadvantaged schools are primarily engaging with these products while the Advantaged schools are not. Therefore this brings the number of pageloads between the two schools more even (because it was previously biased where the Advantaged schools had more pageloads). And just what is this product?","c682caa8":"# So now I am wondering if there was any new product that occurred after the 2021-21 school year started? If yes, then this is probably the product that helped most drive Utah toward online learning equality","eb705adf":"# Read in the engagement data:","d0f9bf17":"# Now for each week, we see which products contributed the biggest gaps","c9d2c8f9":"# Based on those plots, I would encourage further analysis into the education solutions from the following states:\n\n1. Utah. Utah historically had inequality (where Disadvantaged schools had more online learning than Advantaged schools). When covid struck, that inequality gap only got stronger. What makes Utah a good candidate to study is that when the 2020-21 school year started, Utah eliminated that inequality. This means that Utah created some measures for the new school year that helped eliminate inequality for online learning.\n2. Massachusetts. This state had equality pre-pandemic, and once K-12 public schools were shut down, they experienced a gap in online learning between Advantaged and Disadvantaged schools. Massachusetts is probably a case-study of what NOT to do, because things were fine before the pandemic and then they changed it so that Disadvantaged schools began having fewer pageloads compared to Advantaged schools. However, the inequality only lasted for 2 months (or was it because summer came around?) So take this finding with a grain of salt.\n3. Missouri. This state took measures to reduce the gap.\n4. New York. Something funny happened where the inequality gap reversed between Advantaged and Disadvantaged schools. It might be worth it to investigate what measures were taken, and decide if the measures taken were less intense, would we be able to strive closer toward equality?","31a30b6c":"# Plot the average engagement for each school.","62e8fb35":"# The most compelling case to me is Utah. Because of that, let's look into what Utah did to reduce their online learning inequality for the 2020-21 school year.","31d772ae":"# Analysis of these plots:\n\n- If one of the state's plots is empty, that means we did not have both an Advantaged and Disadvantaged school for that state. So we couldn't take the difference between the two (it was all NULL values) so nothing was plotted!\n\n1. California had slightly more online learning engagement from disadvantaged schools, but AFTER the State of emergency was issued and the K-12 public schools were closed, you can clearly see that the Advantaged schools start having more online learning engagement! After summer vacation, the disadvantaged schools have more online learning for about 1 month, and then the advantaged schools have more online learning engagement for the rest of our data period.\n2. Connecticut had more online learning engagement for advantaged schools than disadvantaged schools both before AND after the pandemic. However, similar to California, you can see that the difference between the two nearly doubled when the State of Emergency and K-12 public schools were closed.\n3. Illinois is in a similar situation. You can see that advantaged schools had more online learning, but after the state of emergency and K-12 public schools closed, the advantaged schools had nearly 3-4x more online learning engagement than the disadvantaged schools!\n4. Massachusetts had nearly perfect equality before the State of emergency. Then Advantaged schools had more online engagement than Disadvantaged schools. However, after a period of about 2 months, they came back down to roughly equality measures in May 2020.\n5. Missouri is biased toward Advantaged schools having more engagement. After the State of Emergency and K-12 schools closing, the level of inequality actually lowered.\n6. New York is the opposite from all of the other states. Before the K-12 public schools closing, Advantaged schools by far had 100,000 more pageloads per 1k students on average compared to Disadvantaged schools. Even after the State of Emergency was issued, this bias still existed. However, right when the K-12 public schools closed, we clearly see New York does a complete 180 and now the Disadvantaged schools have 100,000 more pageloads per 1k students compared to the Advanted schools. And this slowly tapered down toward equality as summer rolled along, but actually when school started again in September 2020, Disadvantaged schools are still engaging more with online learning compared to Advantaged schools.\n7. North Carolina - not enough schools to really make a confident statement\n8. Ohio had more engagement by Advanted schools. After K-12 public schools were closed, it took a drop for a few weeks but then went back to the pre-pandemic inequality levels.\n9. Utah is really different compared to the other states. Utah pre-pandemic had Disadvantaged schools engaging in more online learning than Advantaged schools. When K-12 public schools closed, this inequality strengthened, but slowly tapered back to equality during summer 2020. When school resumed back in September 2020, we can actually see this equality being roughly maintained, indicating that Utah was able to solve the inequality online learning gap for the 2020-21 school year.\n10. Virginia doesn't have enough schools to make a confident statement. (But it looks like inequality INCREASED after K-12 public schools were closed).\n11. Washington doesn't have enough schools to make a confident statement.","e5cab755":"# Now we want to measure inequality between groups.\n\nLet's plot all the districts based on their inequality metrics - pct_black\/hispanic and pct_free\/reduced.\n\nWhy didn't I include county_connections_ratio? Because there is only 1 district with a high value. So it's not useful for our dataset.\n\nWhy didn't I include pp_total_raw? Because, I used an unsupervised clustering approach called UMAP before this. And that approach basically split the dataset to where pp_total_raw is NULL vs NOT NULL. So I didn't think it was descriptive enough.","e8a24356":"# Executive Summary\nLearnPlatform (LP henceforth) is frustrated that education is not equal across the ethnicities\/genders. They want to study how the Covid 19 pandemic has exacerbated this inequality. LP was founded to give equal access to education to all students.\n\nYour goal is to look for educational inequalities with respect to district demographics, broadband access, state Covid policies, and then propose a solution to remedy these inequalities.\n\nWhy should I even care? From the Covid 19 pandemic, education became virtual. So you are trying to identify: (1) how did people learn during the 2020 pandemic? and (2) how virtual learning inequality relates to district demographics, broadband access, and state Covid policies.\n\nThis notebook looks at the online learning inequality between advantaged (low minority\/paid lunch) and disadvantaged (high minority\/free lunch) schools within each state. The notebook first looks at the delta before and after K-12 public schools were closed, finding that the online learning gap on average *increased* after K-12 public schools closed. It then proposes four states in which more analysis can be done to discover if we could learn anything from their educational policies. It finally ends with a case study on Utah, because it was a state with high inequality during Covid-19, however for the 2020-21 school year, it basically had online learning equality, and we discover which products drive that change.","201b4e37":"# Summary of previous plots: What happened right after K-12 public schools were closed?\n\n1. Arizona looks like it had a Spring Break, then after it slowly decreased their virtual learning until Summer. After summer, virtual learning was really high, but after a couple months it went back\n2. California looks like it had a Spring Break, then after it slowly decreased their virtual learning until Summer. After summer, virtual learning was really high, and was sustained.\n3. Connecticut increased virtual learning 2x, slow decline towards Summer (but still higher than before). After summer, virtual learning was high and increasing.\n4. Washington DC had low virtual learning even before and after. Then after summer, they had like 5x to 6x increase of virtual learning\n5. Florida has Spring Break, then minor increase of virtual increase which decayed toward Summer. Then after Summer, 2x increase which dipped a little but was sustained.\n6. Illinois had a small bump up in virtual learning which decayed toward Summer. After summer, a small increase in virtual learning which was sustained for months.\n7. Indiana had high virtual learning before the pandemic, then it looks like virtual learning went way down during the pandemic (why?) After Summer, virtual learning was high again.\n8. Massachusetts had a dip when K-12 announced, and then back to regular virtual learning which slowly decayed until summer. After summer, it picked up 2x virtual learning and was sustained.\n9. After K-12 shut down, Michigan was basically 0 virtual learning. Then after summer, it increased 4x and was sustained.\n10. Minnesota: immediately low after K12 closed, then a period of 2 weeks really high, then went to 0. (Not enough data to be honest)\n11. Missouri - they had their Spring break before K12 was closed it seems. Their virtual learning decayed toward summer, then pepped back up and sustained after summer.\n12. New Hampshire - after K-12 shut down, big increase in virtual learning. Then summer. Then sustained virtual learning after summer.\n13. New Jersey - Not much of a change in virtual learning. It appears their virtual learning was increasing before the state of emergency was declared. Then they had a short summer and had sustained & increaasing virtual learning after summer.\n14. New York - appears virtual learning was increasing before state of emergency. Declined toward summer. After summer, it was sustained strong.\n15. North Carolina - after K12 closed, basically 0 virtual learning. After summer, it went back to high & sustained.\n16. North Dakota - not enough data\n17. Ohio - Spring break, then still has high virtual learning. It appears the virtual learning increased before state of emergency declared. Slow decline to summer. Then high and sustained after summer.\n18. Tennessee - low virtual learning, then 0 after State of Emergency. Then like 2.5x increase after summer.\n19. Texas - a week before the state of emergency, virtual learning went 0. Then in the middle it came back up to what we're used to, then back to 0 over the summer. Then after summer it went high, like 2x and sustained.\n20. Utah - after K12 closed, slight bump in virtual learning which then decayed toward summer. After summer, it was high & sustained.\n21. Virginia - after K12 closed, virtual learning became lower. Decayed toward summer. After summer, it was high & sustained.\n22. Washington - After K12 closed, looks like spring break? (cuz it's low). Then it went low and decayed until summer. After summer, it was high & sustained.\n23. Wisconsin - After K12 closed, it was like 1 week closed. Then it was med-high and sustained until summer. After summer it was med, slight decay.","c15ef08a":"# This is all fine and dandy, but remember we are focused on inequality. Therefore we should look at the difference between the average pageviews of Advantaged and Disadvantaged schools in the same state."}}