{"cell_type":{"d348101f":"code","8c3fb78f":"code","8f7bb731":"code","c5dd0a65":"code","dfd101d0":"code","f806e4c5":"code","a04b20d0":"code","c7d57804":"code","4d76129d":"code","d1f062f6":"code","f5466301":"code","3a2dfe9b":"code","8785861f":"code","58ef7417":"code","7db72e32":"code","bccc9718":"code","f203d54d":"code","3e22fdee":"code","0f552b15":"code","6a671864":"code","6bed9ce2":"code","8b7b500d":"code","e7654592":"code","d3499abe":"code","b27ef975":"code","a0176bb4":"code","991ecbe0":"code","6f8b2f79":"code","4bcd6d1b":"code","bb1eb8c0":"code","889576ba":"code","c748ed45":"code","48b7379a":"markdown","64ff2af4":"markdown","ea18a6ae":"markdown","22a72856":"markdown","62a0e6e5":"markdown","e60da51b":"markdown","6a6447f7":"markdown","b9eb7de5":"markdown","ba19fdf1":"markdown","3291da65":"markdown","a81164f6":"markdown","c7a5151d":"markdown","d21ae488":"markdown","0cd25f30":"markdown","b727500e":"markdown","68e11bd9":"markdown","05104a7c":"markdown","f138837f":"markdown","6d9f198c":"markdown","44306aad":"markdown","4be2a219":"markdown","6c706932":"markdown","ef5b31d7":"markdown","bd5589b3":"markdown"},"source":{"d348101f":"import numpy as pd\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n%matplotlib inline","8c3fb78f":"data = pd.read_csv('..\/input\/predicting-a-pulsar-star\/pulsar_stars.csv')","8f7bb731":"data.isnull().any()","c5dd0a65":"data.describe()","dfd101d0":"data.iloc[:, :-1].boxplot(whis = \"range\", vert = False, figsize = (10,7))\nplt.title(\"Range and distribution of the data in each column\")","f806e4c5":"pos = data[data.iloc[:,8] == 1]\nneg = data[data.iloc[:,8] == 0]","a04b20d0":"pos.describe()","c7d57804":"neg.describe()","4d76129d":"for i in range(8):\n    fig = plt.figure(figsize = (6,8))\n    fig = sns.violinplot(data = data, x = data.columns[-1], y = data.columns[i], scale = 'area', palette = {0: 'tab:orange', 1: 'tab:blue'})\n    fig.set_title('Distribution of positive and negative cases')\n    plt.show()\n    ","d1f062f6":"data1 = data.copy()\ndata1.loc[data1['target_class'] == 1, 'target_class'] = \"Positive\"\ndata1.loc[data1['target_class'] == 0, 'target_class'] = \"Negative\"\n\nsns.pairplot(data1, hue = 'target_class', height = 4, markers = '.', vars = data1.columns[:-1], palette = 'bright', hue_order = ['Negative', 'Positive'])","f5466301":"fig, axes = plt.subplots(8, 8, figsize = (60,40))\n\nlabels = data.columns\n\nfor a in range(8):\n    for b in range(8):\n        \n        if a == b:\n            axes[a,b].hist(neg.iloc[:,a], bins = 40, color = 'r', alpha = 0.5, label = 'Negative', density = True)\n            axes[a,b].hist(pos.iloc[:,a], bins = 40, color = 'b', alpha = 0.5, label = 'Positive', density = True)\n            axes[a,b].set_xlabel(labels[a])\n            axes[a,b].legend(markerscale = 20)\n            \n        else:\n            axes[a,b].scatter(neg.iloc[:,a], neg.iloc[:,b], s = 0.1, c = 'red', alpha = 1, label = 'Negative')\n            axes[a,b].scatter(pos.iloc[:,a], pos.iloc[:,b], s = 0.1, c = 'b', alpha = 1, label = 'Positive')\n            axes[a,b].set_xlabel(labels[a])\n            axes[a,b].set_ylabel(labels[b])\n            axes[a,b].legend(markerscale = 20)\n","3a2dfe9b":"plt.figure(figsize = (8,6))\nplt.scatter(neg.iloc[:,2], neg.iloc[:,0], s = 0.1, c = 'red', alpha = 1, label = 'Negative')\nplt.scatter(pos.iloc[:,2], pos.iloc[:,0], s = 0.1, c = 'b', alpha = 1, label = 'Positive')\nplt.xlabel(labels[2])\nplt.ylabel(labels[0])\nplt.legend(markerscale = 20)\n","8785861f":"plt.figure(figsize = (8,6))\nplt.scatter(neg.iloc[:,5], neg.iloc[:,4], s = 0.1, c = 'red', alpha = 1, label = 'Negative')\nplt.scatter(pos.iloc[:,5], pos.iloc[:,4], s = 0.1, c = 'b', alpha = 1, label = 'Positive')\nplt.xlabel(labels[5])\nplt.ylabel(labels[4])\nplt.legend(markerscale = 20)","58ef7417":"\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.cluster import KMeans\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier","7db72e32":"xtrain, xtest, ytrain, ytest = train_test_split(data.iloc[:,0:8], data.iloc[:,8])","bccc9718":"def metrics(test, pred):\n    # tp: true positive, fp: false positive, tn: true negative, fnfalse negative\n    tp, fp, tn, fn, score = 0, 0, 0, 0, 0\n    for a, b in zip(test, pred):\n        if b ==1:\n            if a ==1: tp += 1\n            else: fp +=1\n        else:\n            if a == 0: tn +=1\n            else: fn +=1\n    \n    recall = tp \/ (tp + fn)\n    accu = accuracy_score(test, pred)\n    score = (recall + accu)\/2\n    \n    return accu, tp,fp, tn, fn, recall, score\n\n\ndef print_metrics(test, pred):\n    accu, tp,fp, tn, fn, recall, score = metrics(test,pred)\n    print(f\"Accuracy:       {accu: .3f} \\nTrue positive:   {tp} \\nFalse positive:  {fp} \\nTrue negative:   {tn} \\nFalse negative:  {fn} \\nRecall:         {recall: .3f} \\nScore:          {score: .3f}\")","f203d54d":"results = pd.DataFrame(index = ['Accuracy', 'True positives', 'False positives', 'True negatives', 'False negatives', 'Recall', 'Score'])","3e22fdee":"LR = LogisticRegression()\n\nLR.fit(xtrain, ytrain)\nLR_prediction = LR.predict(xtest)\nresults['Logistic regression'] = metrics(ytest, LR_prediction)\nprint_metrics(ytest, LR_prediction)","0f552b15":"results","6a671864":"GNB = GaussianNB()\n\nGNB.fit(xtrain, ytrain)\nGNB_prediction = GNB.predict(xtest)\nresults['Gaussian Naive Bayes'] = metrics(ytest, GNB_prediction)","6bed9ce2":"KNC = KNeighborsClassifier(n_neighbors = 5)\n\nKNC.fit(xtrain, ytrain)\nKNC_prediction = KNC.predict(xtest)\nresults['K Neaghbors'] = metrics(ytest, KNC_prediction)","8b7b500d":"DTC = DecisionTreeClassifier(criterion = \"entropy\")\n\nDTC.fit(xtrain, ytrain)\nDTC_prediction = DTC.predict(xtest)\nresults['Decision tree'] = metrics(ytest, DTC_prediction)","e7654592":"RFC = RandomForestClassifier(n_estimators = 100)\n\nRFC.fit(xtrain, ytrain)\nRFC_prediction = RFC.predict(xtest)\nresults['Random forest'] = metrics(ytest, RFC_prediction)","d3499abe":"MLPC = MLPClassifier(hidden_layer_sizes = (4), activation = \"tanh\", max_iter = 400)\n\nMLPC.fit(xtrain, ytrain)\nMLPC_prediction = MLPC.predict(xtest)\nresults['Neural Network'] = metrics(ytest, MLPC_prediction)","b27ef975":"results","a0176bb4":"#plotting accuracy and recall in %\n\n\nfig, ax = plt.subplots(figsize = (12,5))\nw = 0.3\nx = np.arange(len(results.columns))\nlabels = results.columns\n\nrects1 = ax.bar(x - w\/2, results.loc['Accuracy'] * 100, width = w, label = 'Accuracy')\nrects2 = ax.bar(x + w\/2, results.loc['Recall'] * 100, width = w, label = 'Recall')\nax.grid(axis = 'y')\nax.set_xticks(x)\nax.set_xticklabels(labels, rotation = 45)\nax.set_ylabel('Ratio (%)')\nax.legend(loc = 4)\nax.set_ylim(0,105)\nax.set_title('Model performance')\n\ndef autolabel(rects):\n    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{:4.1f}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() \/ 2, height),\n                    xytext=(0, 3),\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\n\nautolabel(rects1)\nautolabel(rects2)\n\n\n\n\nplt.show()","991ecbe0":"names = ['DTC', 'RFC', 'MLPC']\nd = {}                                   #the fitted models will be saved in this dictionary\nresults2 = pd.DataFrame(index = ['Accuracy', 'True positives', 'False positives', 'True negatives', 'False negatives', 'Recall', 'Score'])\nnum = 200\n\nfor i in range(num):\n    models = [DecisionTreeClassifier(), RandomForestClassifier(n_estimators = 100), MLPClassifier(hidden_layer_sizes = (4), activation = \"tanh\", max_iter = 400)] #definido dentro del bucle for para que en cada iteraci'on use un estado inicial pseudoaleatorio ditinto\n    for name, model in zip(names, models):\n        name += str(i)\n        model.fit(xtrain, ytrain)\n        prediction= model.predict(xtest)\n        results2[name] = metrics(ytest, prediction)\n        d[name] = model\n\n","6f8b2f79":"\nfor a in range(3):\n    c = []\n    for i in range(num):\n        c.append(a + i*3)\n\n    \n    best = results2.iloc[-1,c].idxmax()\n    results[best] = results2[best]","4bcd6d1b":"results","bb1eb8c0":"#plotting accuracy and recall in %\n\n\nfig, ax = plt.subplots(figsize = (14,5))\nw = 0.3\nx = np.arange(len(results.columns))\nlabels = results.columns\n\nrects1 = ax.bar(x - w\/2, results.loc['Accuracy'] * 100, width = w, label = 'Accuracy')\nrects2 = ax.bar(x + w\/2, results.loc['Recall'] * 100, width = w, label = 'Recall')\nax.grid(axis = 'y')\nax.set_xticks(x)\nax.set_xticklabels(labels, rotation = 45)\nax.set_ylabel('Ratio (%)')\nax.legend(loc = 4)\nax.set_ylim(0,105)\nax.set_title('Model performance')\n\ndef autolabel(rects):\n    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{:4.1f}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() \/ 2, height),\n                    xytext=(0, 3),\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\n\nautolabel(rects1)\nautolabel(rects2)\n\n\n\n\nplt.show()","889576ba":"allDTC = pd.DataFrame(index = ['Accuracy', 'True positives', 'False positives', 'True negatives', 'False negatives', 'Recall', 'Score'])\nallRFC = pd.DataFrame(index = ['Accuracy', 'True positives', 'False positives', 'True negatives', 'False negatives', 'Recall', 'Score'])\nallMLPC = pd.DataFrame(index = ['Accuracy', 'True positives', 'False positives', 'True negatives', 'False negatives', 'Recall', 'Score'])\n\nfor name in results2.columns:\n    if name.startswith('DTC'):\n        allDTC[name] = results2[name]\n        \n    elif name.startswith('RFC'):\n        allRFC[name] = results2[name]\n        \n    else:\n        allMLPC[name] = results2[name]\n\nhistfig, histaxes = plt.subplots(1,3, figsize = (16,4))\nhistaxes[0].hist(allDTC.loc['Score'], bins = 30)\nhistaxes[0].set_title('Histogram of Decision Tree \\nClassifiers scores')\nhistaxes[1].hist(allRFC.loc['Score'], bins = 30)\nhistaxes[1].set_title('Histogram of Random Forest \\nClassifiers scores')\nhistaxes[2].hist(allMLPC.loc['Score'], bins = 30)\nhistaxes[2].set_title('Histogram of Multi Layer Perceptron \\nClassifiers scores')\n\nplt.show()","c748ed45":"worst_idx = allMLPC.loc['Score'].idxmin()\n\nworst = d[worst_idx]\nworst_prediction = worst.predict(xtest)\nprint_metrics(ytest, worst_prediction)","48b7379a":"We define a function to calculate and print the number of true positives, true negatives, false positives, false negatives and the recall, along with the accuracy.\nThe recall is the proportion of true cases labeled correctly.\nSince the data set has many more negative than positive cases, we also want to have a good recall. In a data set with 90% negative cases (like this one), a model that labels all samples as \"negative\" will have 90% accuracy. But it is not useful at all.\nTherefore, we define a metric \"score\" that is the average between accuracy and recall. We will use this to choose the best model\n","64ff2af4":"Data ingestion","ea18a6ae":"# Models","22a72856":"For some pairs, positive cases extend in different regions than negative ones:","62a0e6e5":"Importing usefull packages","e60da51b":"Now let's do something similar with matplotlib that shows the paterns more clearly while showing normalized histograms in the diagonal. Again, you can zoom in.","6a6447f7":"The next cell makes the pairplots using seaborn. You can zoom in","b9eb7de5":"### Some of these models depend on the initial random state. We will build 200 of them and we will keep the best of each.","ba19fdf1":"(Disclaimer: in some runs of the script this case doesn't accur)\nWe can see that some neural networks models have a very low score. If we see the metrics for this model we can see that all the samples has been classified as non pulsars. This is the best to what it has been able to converge given the initial random state, an stil has an accuracy of 90%. This shows why it is important to choose a good metric and to initialize many models when they depend on the initial random state. ","3291da65":"## Data exploration","a81164f6":"### Comparison of the distribution of positive and negative cases for each variable.","c7a5151d":"The returned values of the \"metrics\" function will be saved in the \"results\" dataframe for each model.","d21ae488":"### We can see that for some attributes the positive cases are mostly separated from the negative ones while in other cases they are mostly overlapping","0cd25f30":"#### Distribution of the data","b727500e":"# Results","68e11bd9":"#### We can see that the distributions for positive and negative cases are different but mostly overlaped","05104a7c":"Let's see the distribution of scores of all the models through some histograms","f138837f":"Splitting the data","6d9f198c":"**The goal of this project is to build different classification models to predict whether a star is a pulsar or not, while applying different techniques of the Data Science process.**","44306aad":"Looking for null values","4be2a219":"## Plotting the positive and negative cases by pair of attributes\n","6c706932":"The data set is clean and ready to use","ef5b31d7":"But for other pairs, positive and negative cases extend in the same regions:","bd5589b3":"# Kaggle description\n\n### PREDICTING A PULSAR STAR\nDr Robert Lyon\n\nHTRU2 is a data set which describes a sample of pulsar candidates collected during the High Time Resolution Universe Survey .\n\nPulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter .\n\nAs pulsars rotate, their emission beam sweeps across the sky, and when this crosses our line of sight, produces a detectable pattern of broadband radio emission. As pulsars rotate rapidly, this pattern repeats periodically. Thus pulsar search involves looking for periodic radio signals with large radio telescopes.\n\n<img src=\".\/NRAOPulsar.jpg\" width=300\/>\n\nEach pulsar produces a slightly different emission pattern, which varies slightly with each rotation . Thus a potential signal detection known as a 'candidate', is averaged over many rotations of the pulsar, as determined by the length of an observation. In the absence of additional info, each candidate could potentially describe a real pulsar. However in practice almost all detections are caused by radio frequency interference (RFI) and noise, making legitimate signals hard to find.\n\nMachine learning tools are now being used to automatically label pulsar candidates to facilitate rapid analysis. Classification systems in particular are being widely adopted, which treat the candidate data sets as binary classification problems. Here the legitimate pulsar examples are a minority positive class, and spurious examples the majority negative class.\n\nThe data set shared here contains 16,259 spurious examples caused by RFI\/noise, and 1,639 real pulsar examples. These examples have all been checked by human annotators.\n\nEach row lists the variables first, and the class label is the final entry. The class labels used are 0 (negative) and 1 (positive).\n\nAttribute Information:\nEach candidate is described by 8 continuous variables, and a single class variable. The first four are simple statistics obtained from the integrated pulse profile (folded profile). This is an array of continuous variables that describe a longitude-resolved version of the signal that has been averaged in both time and frequency . The remaining four variables are similarly obtained from the DM-SNR curve . These are summarised below:\n\n- Mean of the integrated profile.\n- Standard deviation of the integrated profile.\n- Excess kurtosis of the integrated profile.\n- Skewness of the integrated profile.\n- Mean of the DM-SNR curve.\n- Standard deviation of the DM-SNR curve.\n- Excess kurtosis of the DM-SNR curve.\n- Skewness of the DM-SNR curve.\n- Class\n\nHTRU 2 Summary  \n17,898 total examples.\n1,639 positive examples. \n16,259 negative examples.\n\nSource: https:\/\/archive.ics.uci.edu\/ml\/datasets\/HTRU2\n\nDr Robert Lyon \nUniversity of Manchester \nSchool of Physics and Astronomy \nAlan Turing Building \nManchester M13 9PL \nUnited Kingdom \nrobert.lyon '@' manchester.ac.uk"}}