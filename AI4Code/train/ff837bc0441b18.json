{"cell_type":{"0bee65a5":"code","c6d1fa70":"code","4ebf1324":"code","d336b43d":"code","7c9c48fb":"code","52de6d44":"code","cff2c001":"code","df839874":"code","bef0d3d3":"code","ef14042e":"code","49e63379":"code","8cc2f9f1":"code","03c2c253":"code","dd7ed02c":"code","1be9198a":"code","8257b631":"code","4783f17d":"code","d4d9dc69":"code","0d0388a5":"code","effb9812":"code","05dc4851":"code","b4ce00b5":"code","ca268ee0":"code","6def45bc":"code","79a49773":"code","4510d461":"code","7595cd63":"code","47ae404e":"code","81eef043":"code","0f71b833":"code","a54e85a3":"code","5c1c324a":"code","523da688":"code","50a23c3a":"code","7a29f108":"code","9d1fc69c":"code","fc357eca":"code","e1237973":"code","2a1e7d03":"code","d6017fcb":"code","8f945033":"code","9f4d7232":"code","9b012e9f":"code","8882f3f8":"code","680fcdff":"code","16ed718a":"code","b4843864":"code","0feb671b":"code","fb9b07c8":"code","154f2816":"markdown","b3446df6":"markdown","3b9999c5":"markdown","f69f0b5f":"markdown","5e9c120d":"markdown","93d484ae":"markdown","5ba7a58e":"markdown","adbdced2":"markdown","547da16e":"markdown","7e57426f":"markdown"},"source":{"0bee65a5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c6d1fa70":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nsample_submission_data = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")","4ebf1324":"train_data.head()","d336b43d":"# an initial decription before cleaning and exploratory data analysis\ntrain_data.describe()","7c9c48fb":"#null data at a glance\ntrain_data.info()\n# just double checking\ntrain_data.isna().sum()","52de6d44":"# maybe the 0 for the fares is because some of them of are babies? let's check\nfare_mask = train_data['Fare']<5\nfree_loaders = train_data[fare_mask]\nprint(free_loaders[['Age','Fare']])","cff2c001":"# ask ta for help\n# ignore for now\n# train_data.Fare = train_data.Fare.map(lambda x: np.nan if x==0 else x)\n# classmeans = train_data.pivot_table('Fare', index='Pclass', aggfunc='mean')\n# print(classmeans)\n# train_data.Fare = train_data[['Fare', 'Pclass']].apply(lambda x: classmeans[x['Pclass']] if pd.isna(x['Fare']) else x['Fare'], axis=0 )\n# print(free_loaders[['Age','Fare']])","df839874":"# replace nan ages with mean age\nmeanAge=np.mean(train_data['Age'])\ntrain_data.Age=train_data.Age.fillna(meanAge)","bef0d3d3":"# Now for the cabin, since the majority of values are missing, it might be best to treat that\n# as a piece of information itself, so we\u2019ll set these to be \u2018Unknown\u2019\ntrain_data.Cabin = train_data.Cabin.fillna('Unknown')","ef14042e":"# Fill embarked with the mean\ntrain_data.Embarked = train_data.Embarked.fillna(method=\"ffill\")","49e63379":"train_data.isna().sum()\ntrain_data.isnull().sum()","8cc2f9f1":"train_data.describe()","03c2c253":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","dd7ed02c":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","1be9198a":"# Let's do some more eda with plotting stuff\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ncorr = train_data.corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# the plotting\nsns.heatmap(corr, mask = mask, center = 0, cmap='cool',linewidths=1,annot=True,fmt=\".2f\")\nplt.show()","8257b631":"# just to see how many survived\nsns.countplot(x='Survived',data=train_data)","4783f17d":"sns.pairplot(data=train_data,hue='Survived')","d4d9dc69":"# see sex against survival\nsns.barplot(x='Sex',y='Survived',data=train_data)","0d0388a5":"# see the number of people who survived or didn't against sex, class, and embarked from\nf, axes = plt.subplots(3,figsize=(9,15))\n#sns.set_style(\"darkgrid\")\nsns.countplot(x='Pclass',hue='Survived',data=train_data,ax=axes[0])\nsns.countplot(x='Sex',hue='Survived',data=train_data,ax=axes[1])\nsns.countplot(x='Embarked',hue='Survived',data=train_data,ax=axes[2])\nplt.show()","effb9812":"# there is a lot of different cabins\n# we can probably reduce this\nprint(train_data['Cabin'].unique())","05dc4851":"# this can probably be reduced as well\nprint(train_data['Ticket'].unique())","b4ce00b5":"# this finds since sex is tied with survival so too is title\ntrain_data['name_title'] = train_data.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\ntrain_data['name_title'].value_counts()","ca268ee0":"# already took of care of null values\ntrain_data['cabin_multiple'] = train_data.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split(' ')))\ntrain_data['cabin_multiple'].value_counts()","6def45bc":"pd.pivot_table(train_data, index = 'Survived', columns = 'cabin_multiple', values = 'Ticket' ,aggfunc ='count')","79a49773":"train_data['cabin_adv'] = train_data.Cabin.apply(lambda x: str(x)[0])\nprint(train_data.cabin_adv.value_counts())","4510d461":"pd.pivot_table(train_data,index='Survived',columns='cabin_adv', values = 'Name', aggfunc='count')","7595cd63":"#understand ticket values better \n#numeric vs non numeric \ntrain_data['numeric_ticket'] = train_data.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\ntrain_data['ticket_letters'] = train_data.Ticket.apply(lambda x: ''.join(x.split(' ')[:-1]).replace('.','').replace('\/','').lower() if len(x.split(' ')[:-1]) >0 else 0)","47ae404e":"train_data['numeric_ticket'].value_counts()","81eef043":"pd.set_option(\"max_rows\", None)\ntrain_data['ticket_letters'].value_counts()","0f71b833":"pd.pivot_table(train_data,index='Survived',columns='numeric_ticket', values = 'Ticket', aggfunc='count')","a54e85a3":"pd.pivot_table(train_data,index='Survived',columns='ticket_letters', values = 'Ticket', aggfunc='count')","5c1c324a":"# dropping irrelvant features first\ntrain_reduced = train_data.drop([\"PassengerId\",\"Name\",\"Cabin\",\"Ticket\",\"ticket_letters\"],axis=1)\ntrain_reduced.head()","523da688":"train_reduced['Sex'] = pd.get_dummies(train_reduced.Sex, drop_first=True)","50a23c3a":"# label encoder will be used for Embarked, name_title, and cabin_adv\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nlr = LabelEncoder()\ntrain_reduced['Embarked']= lr.fit_transform(train_reduced['Embarked'])\ntrain_reduced['name_title']= lr.fit_transform(train_reduced['name_title'])\ntrain_reduced['cabin_adv']= lr.fit_transform(train_reduced['cabin_adv'])\ntrain_reduced.head()","7a29f108":"y = train_reduced['Survived']\nX = train_reduced.drop(\"Survived\",axis=1)\n\nscaler = StandardScaler()\nX_std = scaler.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.30, random_state=0)","9d1fc69c":"from sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error as MSE\n\n# linear regression model\nline_reg = LinearRegression()\n#y_train_array = np.array(y_train)\n#y_train_reg = y_train_array.reshape(-1,1)\n#y_test_array = np.array(y_test)\n#y_test_reg = y_test_array.reshape(-1,1)\nline_reg.fit(X_train, y_train)","fc357eca":"knn = KNN(n_neighbors=4)\nknn.fit(X_train,y_train)","e1237973":"dt = DecisionTreeClassifier(criterion='entropy',random_state=0)\ndt.fit(X_train,y_train)","2a1e7d03":"sgd = SGDClassifier(random_state=0)\nsgd.fit(X_train,y_train)","d6017fcb":"pred_line_reg = line_reg.predict(X_test)\n#acc_line_reg = accuracy_score(y_test_reg, pred_line_reg)\n#acc_line_reg = line_reg.score(y_test, pred_line_reg)\n#acc_line_reg = line_reg.score(y_test,pred_line_reg)\n\n# can not evalute with accuracy score metric will used rmse instead\nrmse = np.sqrt(MSE(y_test,pred_line_reg))\nprint(rmse)","8f945033":"pred_knn = knn.predict(X_test)\nacc_knn = accuracy_score(y_test, pred_knn)\nprint(acc_knn)","9f4d7232":"pred_dt = dt.predict(X_test)\nacc_dt = accuracy_score(y_test, pred_dt)\nprint(acc_dt)","9b012e9f":"pred_sgd = sgd.predict(X_test)\nacc_sgd = accuracy_score(y_test, pred_sgd)\nprint(acc_sgd)","8882f3f8":"print(len(test_data.columns))\nprint(test_data.columns)\ntest_data.head()","680fcdff":"# now we know what needs to be fixed\ntest_data.isna().sum()","16ed718a":"meanAge=np.mean(test_data['Age'])\ntest_data.Age=test_data.Age.fillna(meanAge)\ntest_data.Cabin = test_data.Cabin.fillna('Unknown')\nmeanFare=np.mean(test_data['Fare'])\ntest_data.Fare=test_data.Age.fillna(meanFare)\ntest_data.isna().sum()","b4843864":"# adding the features we engineered\ninbetween = test_data\ninbetween['name_title'] = inbetween.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())\ninbetween['cabin_multiple'] = inbetween.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split(' ')))\ninbetween['cabin_adv'] = inbetween.Cabin.apply(lambda x: str(x)[0])\ninbetween['numeric_ticket'] = inbetween.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\ninbetween['ticket_letters'] = inbetween.Ticket.apply(lambda x: ''.join(x.split(' ')[:-1]).replace('.','').replace('\/','').lower() if len(x.split(' ')[:-1]) >0 else 0)\ninbetween.head()","0feb671b":"id_col = test_data['PassengerId']\ninbetween['Sex'] = pd.get_dummies(inbetween.Sex, drop_first=True)\ninbetween['Embarked']= lr.fit_transform(inbetween['Embarked'])\ninbetween['name_title']= lr.fit_transform(inbetween['name_title'])\ninbetween['cabin_adv']= lr.fit_transform(inbetween['cabin_adv'])\ninbetween.head()","fb9b07c8":"X_semifinal = test_data.drop([\"PassengerId\",\"Name\",\"Cabin\",\"Ticket\",\"ticket_letters\"],axis=1)\nX_final = scaler.fit_transform(X_semifinal)\n\n# error here\npredictions = knn.predict(X_final)\n\noutput = pd.DataFrame({'PassengerId': id_col, 'Survived': predictions})\noutput.head()\n\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","154f2816":"# Models\nWe prepare the models for buliding then bulid them","b3446df6":"# Evaluation\nWe will find the predictions of each model and get the accuracy score. The one with the best accuracy will be used.","3b9999c5":"# EDA","f69f0b5f":"It is strange that the minimum value for fare is zero. Let's look for nans first then take care of it.","5e9c120d":"# Submission\nThe best model is knn. We will use that to generate the submission data.","93d484ae":"We have null data for the age, cabin, and embarked columns.","5ba7a58e":"# Load data","adbdced2":"There is a well known correlation between gender and survival. It is also in the titantic tutorial.","547da16e":"So some people are just not paying. Let's not worry about them.","7e57426f":"All null values are gone. Let's see how that changes are stats."}}