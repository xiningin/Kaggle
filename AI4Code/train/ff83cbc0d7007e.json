{"cell_type":{"76edfe6b":"code","87a133aa":"code","b8720c51":"code","9335127f":"code","5cea50d1":"code","6e7c1662":"code","54490e2e":"code","4e2e5933":"code","27e8f7c2":"code","db2cc20d":"code","69e6e492":"code","55f4017a":"code","55190628":"code","ed5c0a33":"code","78e1043a":"code","ea1de2fc":"code","fe9f3981":"code","e303cfe7":"code","7ca6669b":"code","72422225":"code","ff9469f9":"code","4991508e":"markdown","bb304037":"markdown","06d7a701":"markdown","29a2f6fb":"markdown","b8ad4940":"markdown","8ff7d3aa":"markdown","814fc15a":"markdown","dc46b62d":"markdown","9876db62":"markdown","af141cf5":"markdown","87b4861b":"markdown","4fb15818":"markdown","365b6bb1":"markdown","9f1f3816":"markdown","dc1d96d9":"markdown"},"source":{"76edfe6b":"!pip install spacy\n!python -m spacy download en_core_web_sm","87a133aa":"import torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport re\nimport spacy\nfrom collections import Counter\nimport collections\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nimport string\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nfrom sklearn.metrics import mean_squared_error\nimport torchvision","b8720c51":"data = pd.read_csv('..\/input\/top-video-games-19952021-metacritic\/all_games.csv')\ndata['summary_len'] = data['summary'].apply(lambda x: len(str(x).split()))\ndata = data[data['meta_score'].notna()]\ndata['summary'] = data['name'] + \": \" + data['summary']\ndata = data[[\"meta_score\",\"summary\", \"summary_len\"]]\nprint(data.summary_len.mean())\ndata.sample(6)","9335127f":"tok = spacy.load(\"en_core_web_sm\")\ndef tokenize (text):\n    text = str(text)\n    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]') # remove punctuation and numbers\n    nopunct = regex.sub(\" \", text.lower())\n    return [token.text for token in tok.tokenizer(nopunct)]","5cea50d1":"counts = collections.Counter()\nfor index, row in data.iterrows():\n    counts.update(tokenize(row['summary']))","6e7c1662":"print(\"num_words before:\",len(counts.keys()))\nfor word in list(counts):\n    if counts[word] < 2:\n        del counts[word]\nprint(\"num_words after:\",len(counts.keys()))","54490e2e":"vocab2index = {\"\":0, \"UNK\":1}\nwords = [\"\", \"UNK\"]\nfor word in counts:\n    vocab2index[word] = len(words)\n    words.append(word)","4e2e5933":"def encode_sentence(text, vocab2index, N=100):\n    tokenized = tokenize(text)\n    encoded = np.zeros(N, dtype=int)\n    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n    length = min(N, len(enc1))\n    encoded[:length] = enc1[:length]\n    return encoded, length","27e8f7c2":"data['encoded'] = data['summary'].apply(lambda x: np.array(encode_sentence(x,vocab2index )))\ndata.head()","db2cc20d":"X = list(data['encoded'])\ny = list(data['meta_score'])\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)","69e6e492":"class SummaryDataset(Dataset):\n    def __init__(self, X, Y):\n        self.X = X\n        self.y = Y\n        \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, idx):\n        return torch.from_numpy(self.X[idx][0].astype(np.int32)), self.y[idx], self.X[idx][1]","55f4017a":"train_ds = SummaryDataset(X_train, y_train)\nvalid_ds = SummaryDataset(X_valid, y_valid)","55190628":"def train_model(model, epochs=10, lr=0.001):\n    parameters = filter(lambda p: p.requires_grad, model.parameters())\n    optimizer = torch.optim.Adam(parameters, lr=lr)\n    for i in range(epochs):\n        model.train()\n        sum_loss = 0.0\n        total = 0\n        for x, y, l in train_dl:\n            x = x.long()\n            y = y.float()\n            y_pred = model(x, l)\n            optimizer.zero_grad()\n            loss = F.mse_loss(y_pred, y.unsqueeze(-1))\n            loss.backward()\n            optimizer.step()\n            sum_loss += loss.item()*y.shape[0]\n            total += y.shape[0]\n        val_loss = validation_metrics_regr(model, val_dl)\n        if i % 5 == 1:\n            print(\"train mse %.3f val rmse %.3f\" % (sum_loss\/total, val_loss))\n\ndef validation_metrics (model, valid_dl):\n    model.eval()\n    correct = 0\n    total = 0\n    sum_loss = 0.0\n    for x, y, l in valid_dl:\n        x = x.long()\n        y = y.float()\n        y_hat = model(x, l)\n        loss = np.sqrt(F.mse_loss(y_hat, y.unsqueeze(-1)).item())\n        total += y.shape[0]\n        sum_loss += loss.item()*y.shape[0]\n    return sum_loss\/total","ed5c0a33":"batch_size = 5000\nvocab_size = len(words)\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nval_dl = DataLoader(valid_ds, batch_size=batch_size)","78e1043a":"class Model(torch.nn.Module) :\n    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n        super().__init__()\n        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n        self.linear = nn.Linear(hidden_dim, 1)\n        self.dropout = nn.Dropout(0.2)\n        \n    def forward(self, x, l):\n        x = self.embeddings(x)\n        x = self.dropout(x)\n        lstm_out, (ht, ct) = self.lstm(x)\n        return self.linear(ht[-1])","ea1de2fc":"model =  Model(vocab_size, 100, 100)","fe9f3981":"train_model(model, epochs=30, lr=0.05)","e303cfe7":"train_model(model, epochs=30, lr=0.05)","7ca6669b":"data[\"summary\"][0]","72422225":"my_pitch = \"Ocarina of beer: You play as an alcoholic exploring local bars and pubs.You can fight other people in epic drunk battles! Explore up to 4 jail corners! Get in contact with other well drunk players! Choose up to 100 drinks and drunk fight styles! Your kids and wife will leave you soon, so game becomes hardcore survival! Challenge yourself with depression and anxiety!\"\nprint(f'Word count: {len(str(my_pitch).split())}')","ff9469f9":"import warnings\nwarnings.filterwarnings('ignore')\nmodel.eval()\nl = len(str(my_pitch).split())\nmy_token = torch.tensor([np.array(encode_sentence(my_pitch,vocab2index ))[0].astype(np.int32)])\nmy_token = my_token.long()\npred = model(my_token, l)\nprint(f\"Predicted meta_score: {int(pred[0][0])}\")","4991508e":"![image.png](attachment:2caf6b85-9b3c-4c08-93dc-d783cf20958a.png)","bb304037":"# Preparing dataset","06d7a701":"# Training and eval functions","29a2f6fb":"# Training model","b8ad4940":"# Tokenizing","8ff7d3aa":"## Pretty good game with 74 points at metacritic!","814fc15a":"# Pitching my game\nShould be around 100 words (alcoholism is bad, don't drink, better play my upcoming game)\n### My pitch: **\"Ocarina of beer: You play as an alcoholic exploring local bars and pubs.You can fight other people in epic drunk battles! Explore up to 4 jail corners! Get in contact with other well drunk players! Choose up to 100 drinks and drunk fight styles! Your kids and wife will leave you soon, so game becomes hardcore survival! Challenge yourself with depression and anxiety!\"**","dc46b62d":"## Thank you so much for going trough this notebook!\nLeave an upvote if you like it please \ud83d\udc49\ud83d\udc48","9876db62":"# Loading packages and libraries","af141cf5":"#### An example for reference","87b4861b":"# Loading data\n### Rating should be between 0 and 10 for a classifier","4fb15818":"# Filtering most common words","365b6bb1":"# Defining model\n## LSTM","9f1f3816":"# Predicting meta score based on game description\n#### source notebook https:\/\/jovian.ai\/aakanksha-ns\/lstm-multiclass-text-classification","dc1d96d9":"# Encoding reviews"}}