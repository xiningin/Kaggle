{"cell_type":{"01449a6c":"code","da8e378c":"code","988503ba":"code","cf28b856":"code","c38da8cd":"code","02e68848":"code","f230a4b0":"code","4d6c2813":"code","cd288151":"code","076ec54c":"code","091dabb4":"code","bfcddee2":"code","03bf21a0":"markdown","292f4b16":"markdown","243319ce":"markdown","aa4ecf60":"markdown","2c1413d8":"markdown","f16fc710":"markdown","51ba520e":"markdown","630a38d1":"markdown"},"source":{"01449a6c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport cv2         # For image\nfrom random import shuffle #For shuffling our data cause \n#other way it might be take always run or walk datas to training\n\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt  #for plotting\n\nimport os\n        \nTRAIN_DIR_RUN = \"..\/input\/walk-or-run\/walk_or_run_train\/train\/run\"\nTRAIN_DIR_WALK = \"..\/input\/walk-or-run\/walk_or_run_train\/train\/walk\"\nTEST_DIR_RUN = \"..\/input\/walk-or-run\/walk_or_run_test\/test\/run\"\nTEST_DIR_WALK = \"..\/input\/walk-or-run\/walk_or_run_test\/test\/walk\"\n\n\nIMG_SIZE = 100\nLR = 0.001\nMODEL_NAME = 'Walk_or_Run'","da8e378c":"#run = [1,0], walk = [0,1]\ndef create_train_data():\n    training_data = []\n    for img in tqdm(os.listdir(TRAIN_DIR_RUN)):\n        path = os.path.join(TRAIN_DIR_RUN,img)#here we are giving the path\n        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)#reading as a grayscale\n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))#image size\n        training_data.append([np.array(img),np.array([1,0])])# image data, run or walk\n        \n    for img in tqdm(os.listdir(TRAIN_DIR_WALK)):\n        path = os.path.join(TRAIN_DIR_WALK,img)\n        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        training_data.append([np.array(img),np.array([0,1])])\n    \n    shuffle(training_data)\n    return training_data","988503ba":"def create_test_data():\n    testing_data = []\n    for img in tqdm(os.listdir(TEST_DIR_RUN)):\n        path = os.path.join(TEST_DIR_RUN, img)\n        img_num = img.split('.')[0]#for taking id of the image (you may need to look the data)\n        img_num = img_num.split('_')[1]#for same things\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        testing_data.append([np.array(img), img_num])#image data, image id\n        \n    for img in tqdm(os.listdir(TEST_DIR_WALK)):\n        path = os.path.join(TEST_DIR_WALK, img)\n        img_num = img.split('.')[0]\n        img_num = img_num.split('_')[1]\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        testing_data.append([np.array(img), img_num])\n    \n    shuffle(testing_data)\n    return testing_data","cf28b856":"train_data = create_train_data()","c38da8cd":"import tflearn\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.estimator import regression\n\nconvnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n\nconvnet = conv_2d(convnet, 32, 5, activation='leaky_relu')\nconvnet = max_pool_2d(convnet, 5)\n\nconvnet = conv_2d(convnet, 64, 5, activation='leaky_relu')\nconvnet = max_pool_2d(convnet, 5)\n\nconvnet = conv_2d(convnet, 32, 5, activation='leaky_relu')\nconvnet = max_pool_2d(convnet, 5)\n\nconvnet = conv_2d(convnet, 64, 5, activation='leaky_relu')\nconvnet = max_pool_2d(convnet, 5)\n\nconvnet = conv_2d(convnet, 32, 5, activation='leaky_relu')\nconvnet = max_pool_2d(convnet, 5)\n\nconvnet = conv_2d(convnet, 64, 5, activation='leaky_relu')\nconvnet = max_pool_2d(convnet, 5)\n\nconvnet = conv_2d(convnet, 32, 5, activation='leaky_relu')\nconvnet = max_pool_2d(convnet, 5)\n\nconvnet = conv_2d(convnet, 64, 5, activation='leaky_relu')\nconvnet = max_pool_2d(convnet, 5)\n\nconvnet = fully_connected(convnet, 1024, activation='leaky_relu')\nconvnet = dropout(convnet, 0.8)\n\nconvnet = fully_connected(convnet, 2, activation='softmax')\nconvnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n\nmodel = tflearn.DNN(convnet)","02e68848":"train = train_data[:-500]\ntest = train_data[-100:]","f230a4b0":"X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\nY = [i[1] for i in train]\n\ntest_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\ntest_y = [i[1] for i in test]","4d6c2813":"model.fit({'input': X}, {'targets': Y}, n_epoch=100, validation_set=({'input': test_x}, {'targets': test_y}), \n    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)","cd288151":"test_data = create_test_data()","076ec54c":"def img_data_data(x):\n    for img in tqdm(os.listdir(TEST_DIR_RUN)):\n        path = os.path.join(TEST_DIR_RUN, img)\n        img_num = img.split('.')[0]\n        img_num = img_num.split('_')[1]\n        \n        if img_num == x:\n            imgUMat = cv2.imread(path)\n            data = cv2.cvtColor(imgUMat, cv2.COLOR_BGR2RGB)\n        \n        \n    for img in tqdm(os.listdir(TEST_DIR_WALK)):\n        path = os.path.join(TEST_DIR_WALK, img)\n        img_num = img.split('.')[0]\n        img_num = img_num.split('_')[1]\n        \n        if img_num == x:\n            imgUMat = cv2.imread(path)\n            data = cv2.cvtColor(imgUMat, cv2.COLOR_BGR2RGB)\n                \n    return data","091dabb4":"def img_plt(x):\n    fig=plt.figure(figsize=(50,20))\n\n    for i in range(len(img_numbers)):\n    \n        y = fig.add_subplot(2,6,i+1)\n        orig = img_data_data(img_numbers[i])\n        \n        y.imshow(orig)\n        plt.title(x[i], fontsize=18)\n        y.axes.get_xaxis().set_visible(False)\n        y.axes.get_yaxis().set_visible(False)\n    \n    plt.show()","bfcddee2":"img_numbers = []\nstr_label = []\nfor data in (test_data[:12]):\n    img_numbers.append(data[1])\n    \n    img_data = data[0]\n    img_data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n    \n    model_out = model.predict([img_data])[0]\n    \n    if np.argmax(model_out) == 1: str_label.append('Walk')\n    else: str_label.append('Run')\n    \nimg_plt(str_label)","03bf21a0":"**PART 3:**\nIt's actually not different than the tranin data. \n\nOnly this time we are not giving the run or walk we just give the image data and image id. *","292f4b16":"**Part4:**\n*The CNN part.*\n\n1. First as always we are importing libraries.\n\n2. Than we are giving the parameters.\n\na) Activation: There is lots of activation function we are using activation function for learning part and activation function must be a differentiable function other way our model can not learn(you may want to look at the activation fucntion)\n\nb) Convent: This are our hidden layers here we have 6 layer of CNN with a fully connected layer, and then the output layer.\n\nc) Learning Rate(LR): It's like a little steps if you give this too small it will take lots of time to train a model.\n\n## I may have some mistakes in here just let me know.","243319ce":"**PART 5:**\n*Here diving our training data 500 image for train and 100 image for test and than more diving as x and y.*","aa4ecf60":"**TRAINING THE MODEL:**\n\nEpoch: It's just repeat again and again. It's make your accuract better but be careful you may make a overfitting.\n\n","2c1413d8":"**PART 2:**\n*Here we are creating training data.*\n\n1. In the for loop first we are taking the image path.\n2. we are reading the image with grayscale\n3. Resizing the image \n4. Adding every data to training_data as an array and we also give the what is it(The image is run or walk image)\n5. Doing the same things for the walking image\n6. Shuffle and return","f16fc710":"**WE ARE MAKING A CNN FOR PREDICTING WALK OR RUN**\n\n1. First we are importing libraries, we are giving the path of the datas and we are defining other stuff which we will use in the CNN.\n\n2. Making a fucntion for training data.\n\n3. Doing same things for the testing data (It's has a little bit differences than the second step)\n\n4. Giving the parameters of our model.\n\n5. Dividing the train data for training.\n\n6. Training the model.\n\n7. Predicting and ploting","51ba520e":"**PART 1:**\n*Importing libraries, giving path and defining the parameters.*","630a38d1":"**PART 7:**\n*Predicting and plotting*\n\nPredicting: Just give the image data and take the resulst.\n\nPlotting Part: It's a bit complicated."}}