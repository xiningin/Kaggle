{"cell_type":{"a6d92351":"code","7c2116ee":"code","afb95929":"code","a65e3bb3":"code","0786cecc":"code","6bfd8063":"code","422742f5":"code","0ad76e22":"code","f03ff6bb":"code","5f961f6b":"code","6febc2f9":"code","bff02635":"code","8d5cc95d":"code","f0d97003":"code","687cd0b7":"code","962d26b3":"code","2690ea1c":"code","69005014":"code","4e76e993":"code","441614a8":"code","197f5c8d":"code","5ca84421":"code","6543b1dd":"code","9129f743":"code","36d939ae":"code","331268ed":"code","636bac56":"code","3fd275b7":"code","5cea7725":"code","d0fded40":"code","8d0d1f55":"code","2b1f63a3":"code","055cc7ac":"code","f3789f94":"code","e63a2e2e":"code","d106732e":"code","a5e2a1ba":"code","a63edeba":"code","1c04590c":"markdown","7993a8c2":"markdown","5725ba0a":"markdown","6f73b932":"markdown","dd43ce7f":"markdown","d8df0037":"markdown","948d4ebe":"markdown","4caf81c4":"markdown","f23fee04":"markdown","0591bc32":"markdown","393b02dc":"markdown","fcaa1f26":"markdown","5934edb8":"markdown"},"source":{"a6d92351":"import os #to read and write a file\nimport cv2 #opencv for manipulating images\nfrom glob import glob #finds all the pathnames matching a specified pattern\nimport h5py #will be helpful for storing huge amt of numerical data\nimport shutil #offers a high-level operations on files and collection of files\nimport imgaug as aug #Image augmentation. Helful for creating much more larger dataset from our input.\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns #visualising tool\nimport matplotlib.pyplot as plt #visualising tool\nimport imgaug.augmenters as iaa #Image augmentation.\n\nfrom os import listdir, makedirs, getcwd, remove \n#listdr- return list containing names of the entries given in path\n#make directory named path with the specified numeric mode.\n#getcwd - getting current working directory\n#remove- remove\/delete a file path\n\nfrom os.path import isfile, join, abspath, exists, isdir\n#isfile - to check specified path is available in that file or not.\n#join - to join one or more path.\n#abspath - returns a normalised version of the path\n#isdir- returns true\/false if specified path is there in the directory or not.\n\nfrom pathlib import Path #object oriented file system path.\nfrom skimage.io import imread #image reading\/writing\nfrom skimage.transform import resize #resize\nfrom keras.models import Sequential, Model, load_model #keras NN model\nfrom keras.applications.vgg16 import VGG16, preprocess_input #VGG16\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten #layers to build NN\nfrom keras.optimizers import Adam, SGD, RMSprop #optimizers\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split \nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom keras import backend as K\nimport tensorflow as tf\n\n\ncolor = sns.color_palette()\n%matplotlib inline\n%config InlineBackend.figure_format=\"svg\"","7c2116ee":"columns = ['path', 'label']\nno_xray_df = pd.DataFrame(columns = columns)\nno_imgs_path = {os.path.basename(x): x for x in glob(os.path.join('..', 'input','brain-tumor-detection' ,'no', '*.jpg'))}\n\nprint('Scans found:', len(no_imgs_path))\n\nno_xray_df['path'] = no_imgs_path.values()\n\nno_list = [0]*255 #Labeling 0 for all 255 records\nno_xray_df['label'] = no_list","afb95929":"no_xray_df.head() #no_tumor dataset ready","a65e3bb3":"#For tumor dataset\ncolumns1 = ['path', 'label']\nyes_xray_df = pd.DataFrame(columns = columns1)\nall_imgs_path_yes = {os.path.basename(x): x for x in glob(os.path.join('..', 'input','brain-tumor-detection' ,'yes', '*.jpg'))}\n\nprint('Scans found:', len(all_imgs_path_yes))\n\nyes_xray_df['path'] = all_imgs_path_yes.values()\n#label them 1 i.e. they have tumor\nyes_list = [1]*255\nyes_xray_df['label'] = yes_list ","0786cecc":"yes_xray_df.head()","6bfd8063":"#pred data\n\ncolumns2 = ['path', 'label']\npred_xray_df = pd.DataFrame(columns = columns)\nall_imgs_path_pred = {os.path.basename(x): x for x in glob(os.path.join('..', 'input','brain-tumor-detection' ,'pred','*.jpg'))}\n\nprint('Scans found:', len(all_imgs_path_pred))\n\npred_xray_df['path'] = all_imgs_path_pred.values()\npred_xray_df.head() # there are no Labels for this dataset.","422742f5":"frames = [yes_xray_df, no_xray_df]\nfinal_df = pd.concat(frames)\n\nfinal_df = final_df.sample(frac=1.).reset_index(drop = True) #shuffling the rows\nprint(\"Shuffling the dataset\")\nfinal_df.head(5)","0ad76e22":"#train_test split\nfrom sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(final_df, test_size = 0.25, random_state = 2020)\nprint('train', train_df.shape[0], 'validation', valid_df.shape[0])","f03ff6bb":"train_df #Viewing the training dataset","5f961f6b":"valid_df #Viewing the Valid dataset","6febc2f9":"print(\"Number of traininng samples: \", len(train_df))\nprint(\"Number of validation samples: \", len(valid_df))","bff02635":"# dimensions to consider for the images\nimg_rows, img_cols, img_channels = 224,224,3\n\n# batch size for training  \nbatch_size=8\n\n# total number of classes in the dataset\nnb_classes=2","8d5cc95d":"#augmentation\nseq = iaa.OneOf([\n    iaa.Fliplr(), \n    iaa.Affine(rotate=20), \n    iaa.Multiply((1.2, 1.5))]) \n\n#Fliplr- Horizontal Flips\n#Affine - rotation\n#Multiply - Random Brightness","f0d97003":"def data_generator(data, batch_size, is_validation_data=False):\n    # Get total number of samples in the data\n    n = len(data)\n    nb_batches = int(np.ceil(n\/batch_size))\n\n    # Get a numpy array of all the indices of the input data\n    indices = np.arange(n)\n    \n    # Define two numpy arrays for containing batch data and labels\n    batch_data = np.zeros((batch_size, img_rows, img_cols, img_channels), dtype=np.float32)\n    batch_labels = np.zeros((batch_size, nb_classes), dtype=np.float32)\n    \n    while True:\n        if not is_validation_data:\n            # shuffle indices for the training data\n            np.random.shuffle(indices)\n            \n        for i in range(nb_batches):\n            # get the next batch \n            next_batch_indices = indices[i*batch_size:(i+1)*batch_size]\n            \n            # process the next batch\n            for j, idx in enumerate(next_batch_indices):\n                img = cv2.imread(data.iloc[idx][\"path\"])\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                label = data.iloc[idx][\"label\"]\n                \n                if not is_validation_data:\n                    img = seq.augment_image(img)\n                \n                img = cv2.resize(img, (img_rows, img_cols)).astype(np.float32)\n                batch_data[j] = img\n                batch_labels[j] = to_categorical(label,num_classes=nb_classes)\n            \n            batch_data = preprocess_input(batch_data)\n            yield batch_data, batch_labels","687cd0b7":"#training data generator \ntrain_data_gen = data_generator(train_df, batch_size)\n\n# validation data generator \nvalid_data_gen = data_generator(valid_df, batch_size, is_validation_data=True)","962d26b3":"#Modeling part\n#Transfer Learning\n#Choosing VGG16\n\ndef get_base_model():\n    base_model = VGG16(input_shape=(img_rows, img_cols, img_channels), weights='imagenet', include_top=True)\n    return base_model","2690ea1c":"# get the base model\nbase_model = get_base_model()\n\n#  get the output of the second last dense layer \nbase_model_output = base_model.layers[-2].output\n\n# add new layers \nx = Dropout(0.5,name='drop2')(base_model_output)\noutput = Dense(2, activation='softmax', name='fc3')(x)\n\n# define a new model \nmodel = Model(base_model.input, output)\n\n# Freeze all the base model layers \nfor layer in base_model.layers[:-1]:\n    layer.trainable=False\n\n# compile the model and check it \noptimizer = RMSprop(0.001)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\nmodel.summary()","69005014":"# the restore_best_weights parameter load the weights of the best iteration once the training finishes\nfrom tensorflow.keras.callbacks import EarlyStopping\nes = EarlyStopping(patience=10, restore_best_weights=True)\n\n# checkpoint to save model\nchkpt = ModelCheckpoint(filepath=\"model1\", save_best_only=True)\n\n# number of training and validation steps for training and validation\nnb_train_steps = int(np.ceil(len(train_df)\/batch_size))\nnb_valid_steps = int(np.ceil(len(valid_df)\/batch_size))\n\n# number of epochs \nnb_epochs=30","4e76e993":"# train the model \nhistory1 = model.fit_generator(train_data_gen, \n                              epochs=nb_epochs, \n                              steps_per_epoch=nb_train_steps, \n                              validation_data=valid_data_gen, \n                              validation_steps=nb_valid_steps,\n                              callbacks=es)","441614a8":"#get the training and validation accuracy\ntrain_acc = history1.history['accuracy']\nvalid_acc = history1.history['val_accuracy']\n\n#get the loss\ntrain_loss = history1.history['loss']\nvalid_loss = history1.history['val_loss']\n\n#get the entries\nxvalues = np.arange(len(train_acc))\n\n#visualise\nf, ax = plt.subplots(1,2, figsize = (10,5))\nax[0].plot(xvalues, train_loss)\nax[0].plot(xvalues, valid_loss)\nax[0].set_title(\"Loss curve\")\nax[0].set_xlabel(\"Epoch\")\nax[0].set_ylabel(\"loss\")\nax[0].legend(['train', 'validation'])\n\nax[1].plot(xvalues, train_acc)\nax[1].plot(xvalues, valid_acc)\nax[1].set_title(\"Accuracy\")\nax[1].set_xlabel(\"Epoch\")\nax[1].set_ylabel(\"accuracy\")\nax[1].legend(['train', 'validation'])\n\nplt.show()","197f5c8d":"valid_loss, valid_acc = model.evaluate_generator(valid_data_gen, steps=nb_valid_steps)\nprint(f\"Final validation accuracy: {valid_acc*100:.2f}%\")","5ca84421":"#Model Interpretability\n#Now, we will create new model which will output all the activations for each convolution created. So, for each sample\n#image, we will have outputs of different activations for each convolution in the network","6543b1dd":"#select the layers for which you want to visulaise the outputs and store that in list.\noutputs = [layer.output for layer in model.layers[1:18]]\noutputs #outputs from each intermediate layers","9129f743":"#define new model that generates above outputs\nvis_model = Model(model.input, outputs)\n\nvis_model.summary()","36d939ae":"#now store which all outputs you want in the list\nlayer_names = []\nfor layer in outputs:\n    layer_names.append(layer.name.split(\"\/\")[0])\n    \nprint(\"Layers which will be used for visualisation: \")\nprint(layer_names)","331268ed":"def get_CAM(processed_image, predicted_label):\n    #will be used to generate heatmap for a sample image\n    #processed_image = the image sample which has been preprocessed will come here.\n    #predicted_label = label that was predicted by our model\n    \n    #will return heat map from the last convolution layer output.\n    \n    #we want the activations for predicted_label\n    predicted_output = model.output[:, predicted_label]\n    \n    #choose the last level of our convolution\n    last_conv_layer = model.get_layer('block5_conv3')\n    \n    #get the gradients for that last layer K = keras\n    grads = K.gradients(predicted_output, last_conv_layer.output)[0]\n    \n    #take the mean grads per feature map\n    grads = K.mean(grads, axis = (0,1,2))\n    \n    #define a function that generates the values for the output and gradients #imp\n    evaluation_function = K.function([model.input], [grads, last_conv_layer.output[0]])\n    \n    #get the values\n    grads_values, conv_output_values = evaluation_function([processed_image])\n    \n    #Now, iterate each feature map in your conv O\/P and multiply the gradient values. This can tell\n    #how important a feature is..\n    for i in range(512): #we have 512 channels (features) in the last layer\n        conv_output_values[:,:,i] *= grads_values[i]\n        \n    #create a heatmap now\n    heatmap = np.mean(conv_output_values, axis = -1)\n    \n    #remove negative values\n    heatmap = np.maximum(heatmap, 0)\n    \n    #normalize now\n    heatmap \/= heatmap.max()\n    \n    return heatmap\n   ","636bac56":"def show_random_sample(idx):\n    #This I am creating to select random sample from validation dataframe\n    #It also generates the prediction for the same. It also stores the heatmap and intermediate layers \n    #activation maps\n    \n    #idx: random index to select a sample from validation data\n    \n    #It will return activation values from intermediate layers.\n    \n    #select the sample and read the corresponding image and label\n    sample_image = cv2.imread(valid_df.iloc[idx]['path'])\n    sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n    sample_image = cv2.resize(sample_image, (img_rows, img_cols))\n    sample_label = valid_df.iloc[idx]['label']\n    \n    #preprocess the image\n    sample_image_processed = np.expand_dims(sample_image, axis=0)\n    sample_image_processed = preprocess_input(sample_image_processed)\n    \n    #generate the activation maps from intermediate layers.\n    activations = vis_model.predict(sample_image_processed)\n    \n    #get the label predicted by our original model \n    pred_label = np.argmax(model.predict(sample_image_processed), axis=-1)[0]\n    \n    #choose any random activation map from the activation maps\n    sample_activation = activations[0][0,:,:,32]\n    \n    #normalize the sample activation map\n    sample_activation-=sample_activation.mean()\n    sample_activation\/=sample_activation.std()\n    \n    #convert pixel values between 0-255\n    sample_activation *=255\n    sample_activation = np.clip(sample_activation, 0, 255).astype(np.uint8)\n    \n    #get the heatmap now for class activation\n    heatmap = get_CAM(sample_image_processed, pred_label)\n    heatmap = cv2.resize(heatmap, (sample_image.shape[0], sample_image.shape[1]))\n    heatmap = heatmap * 255\n    heatmap = np.clip(heatmap, 0, 255).astype(np.uint8)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    super_imposed_image = heatmap * 0.5 + sample_image #brightens the image\n    super_imposed_image = np.clip(super_imposed_image, 0, 255).astype(np.uint8)\n    \n    f, ax = plt.subplots(2,2, figsize= (15,8))\n    ax[0,0].imshow(sample_image)\n    ax[0,0].set_title(f\"True Label: {sample_label} \\n Predicted Label: {pred_label}\")\n    ax[0,0].axis('off')\n    \n    ax[0,1].imshow(sample_activation)\n    ax[0,1].set_title(\"Random Feature Map\")\n    ax[0,1].axis('off')\n    \n    ax[1,0].imshow(heatmap)\n    ax[1,0].set_title(\"Class Activation Map\")\n    ax[1,0].axis('off')\n    \n    ax[1,1].imshow(super_imposed_image)\n    ax[1,1].set_title(\"Activation map superimposed\")\n    ax[1,1].axis('off')\n    plt.show()\n    \n    return activations","3fd275b7":"#Creating same function with different name for pred data set. Previously, it was created for Valid Dataframe.\n\ndef show_random_sample1(idx):\n    #This I am creating to select random sample from validation dataframe\n    #It also generates the prediction for the same. It also stores the heatmap and intermediate layers \n    #activation maps\n    \n    #idx: random index to select a sample from validation data\n    \n    #It will return activation values from intermediate layers.\n    \n    #select the sample and read the corresponding image and label\n    sample_image = cv2.imread(pred_xray_df.iloc[idx]['path'])\n    sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n    sample_image = cv2.resize(sample_image, (img_rows, img_cols))\n    sample_label = pred_xray_df.iloc[idx]['label']\n    \n    #preprocess the image\n    sample_image_processed = np.expand_dims(sample_image, axis=0)\n    sample_image_processed = preprocess_input(sample_image_processed)\n    \n    #generate the activation maps from intermediate layers.\n    activations = vis_model.predict(sample_image_processed)\n    \n    #get the label predicted by our original model \n    pred_label = np.argmax(model.predict(sample_image_processed), axis=-1)[0]\n    \n    #choose any random activation map from the activation maps\n    sample_activation = activations[0][0,:,:,32]\n    \n    #normalize the sample activation map\n    sample_activation-=sample_activation.mean()\n    sample_activation\/=sample_activation.std()\n    \n    #convert pixel values between 0-255\n    sample_activation *=255\n    sample_activation = np.clip(sample_activation, 0, 255).astype(np.uint8)\n    \n    #get the heatmap now for class activation\n    heatmap = get_CAM(sample_image_processed, pred_label)\n    heatmap = cv2.resize(heatmap, (sample_image.shape[0], sample_image.shape[1]))\n    heatmap = heatmap * 255\n    heatmap = np.clip(heatmap, 0, 255).astype(np.uint8)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    super_imposed_image = heatmap * 0.5 + sample_image #brightens the image\n    super_imposed_image = np.clip(super_imposed_image, 0, 255).astype(np.uint8)\n    \n    f, ax = plt.subplots(2,2, figsize= (15,8))\n    ax[0,0].imshow(sample_image)\n    ax[0,0].set_title(f\"True Label: {sample_label} \\n Predicted Label: {pred_label}\")\n    ax[0,0].axis('off')\n    \n    ax[0,1].imshow(sample_activation)\n    ax[0,1].set_title(\"Random Feature Map\")\n    ax[0,1].axis('off')\n    \n    ax[1,0].imshow(heatmap)\n    ax[1,0].set_title(\"Class Activation Map\")\n    ax[1,0].axis('off')\n    \n    ax[1,1].imshow(super_imposed_image)\n    ax[1,1].set_title(\"Activation map superimposed\")\n    ax[1,1].axis('off')\n    plt.show()\n    \n    return activations","5cea7725":"#Now showing the some predictions\n#It will also give heatmap and super imposed image to get the details of the X-Ray.\nactivations = show_random_sample(100) #the output","d0fded40":"activations = show_random_sample(123) ","8d0d1f55":"activations = show_random_sample(78) ","2b1f63a3":"activations = show_random_sample(84) ","055cc7ac":"#This is for predicted dataset\nactivations = show_random_sample1(15)","f3789f94":"activations = show_random_sample1(59) ","e63a2e2e":"activations = show_random_sample1(26)","d106732e":"activations = show_random_sample1(59)","a5e2a1ba":"activations = show_random_sample1(24)","a63edeba":"activations = show_random_sample1(28)","1c04590c":"**Plotting the Accuracy and Loss of our model**","7993a8c2":"**Now merging the datasets for both labels and shuffling them**","5725ba0a":"**Train Test split. Making Train and Valid dataframes.**","6f73b932":"**Modeling Part**","dd43ce7f":"**What is the final loss and accuracy of validation data?**","d8df0037":"**Predictions from Valid Datasets**","948d4ebe":"**Creating a dataframe which we will predict later.**","4caf81c4":"**Summary of our NN model**","f23fee04":"**Preparing No-Tumor dataset with Label 0. Reading file from the input and creating a Dataframe**","0591bc32":"**For Prediction Datsets**","393b02dc":"# **The End**","fcaa1f26":"**Preparing Yes-Tumor dataset with Label 1. Reading file from the input and creating a Dataframe**","5934edb8":"**Importing the libraries**"}}