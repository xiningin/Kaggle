{"cell_type":{"adced00b":"code","2cd05df4":"code","08ff51ca":"code","8b38fe12":"code","a72dbb66":"code","55e90a15":"code","b44d0d60":"code","c162ec51":"code","c0c3ea14":"code","9557076c":"code","7392f032":"code","ded685dc":"code","68a4bb4c":"code","7e8f5a8e":"code","ede6140c":"code","a35e4a7e":"code","4e508d4b":"code","e9ff9751":"code","de186416":"code","26575310":"code","18459b91":"code","68f1851f":"code","8fb7af56":"code","a070a9db":"code","74bc063f":"code","3b09dc5a":"code","bf4d45bb":"code","565ffbbe":"code","4e3c0b09":"code","b79dd3e0":"code","c2752db7":"code","ccc9c700":"code","19f1427d":"code","187ac49e":"code","a2600c62":"code","f7e658a2":"code","015795a3":"code","96e6fed8":"code","68b89e38":"code","78c8a21c":"code","2e01d918":"code","5238c0f7":"code","f0a4d109":"code","9875cd30":"code","d04a4a98":"code","9a341561":"code","759cd043":"code","fbffbf34":"code","e43c7762":"code","94c43387":"code","63823cad":"code","144e6f92":"code","e6dab3a1":"code","4f06c093":"code","944a41ed":"code","63219436":"code","f4966531":"code","509eb984":"code","b5d3db8b":"code","18939726":"code","6fec9639":"code","dc724430":"code","fda93174":"code","1547fd13":"code","6e5e3c55":"code","b2213ee0":"code","ba5ee4e5":"code","b6bf3476":"code","ce76baec":"code","977b9dd0":"code","a6bea5f6":"code","32e167e9":"code","23bd6e70":"code","acdf9a35":"code","f0bd7db8":"code","57ba9016":"code","37930ff7":"code","8bdeead0":"code","69476559":"code","7bd97d81":"code","4978b7f7":"code","af358f3c":"code","02e61d5a":"code","e5f616f5":"code","43bfcb36":"code","bea96dd9":"code","d75197bc":"code","5043073c":"code","8c0cba90":"code","1215e9d4":"markdown","0e2e0bfb":"markdown","3efb4e1f":"markdown","a9c5efa1":"markdown","eba67636":"markdown","4f273fcb":"markdown","deba9ad9":"markdown","eb06d34f":"markdown","411308d1":"markdown","3060c149":"markdown","32aa5f76":"markdown","e26e40ed":"markdown","b0174b21":"markdown","e3fbc5d6":"markdown","8c3f1447":"markdown","9538dc99":"markdown","9c4f22b1":"markdown","c8de60bf":"markdown","8826f019":"markdown","10cd7272":"markdown","4dc688fc":"markdown","ec3a95e5":"markdown","d514a97d":"markdown","c6a5cfbc":"markdown","9b8f19d1":"markdown","d546418a":"markdown","e0e156d7":"markdown","383d05e7":"markdown","3949b1e6":"markdown","e37cc42e":"markdown","db90beb9":"markdown","0b89e962":"markdown","0f01ac08":"markdown","b2de3655":"markdown","c049e44d":"markdown","d134cc4b":"markdown","d367d466":"markdown","d4ba6f68":"markdown","f30b8970":"markdown","4bcc2d9c":"markdown"},"source":{"adced00b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting library\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2cd05df4":"data = pd.read_csv('..\/input\/earthquakes-solar-system-objects\/SolarSystemAndEarthquakes.csv')","08ff51ca":"data.head(5)","8b38fe12":"# i used Start, Stop, Step\nearthquake_data = data[data.columns[3:4:1]]\nearthquake_data.head(10)\n\n#i used conditional selection and for loop\nmoon_cols = [col for col in data.columns if 'Moon' in col]\nmoon_data = data[moon_cols]\nmoon_data.head(10)\n\nVenus_cols = [col for col in data.columns if 'Venus' in col]\nVenus_data = data[Venus_cols]\nVenus_data.head(10)\n\n# concat function concatenates data frames\ncorrelation_data = pd.concat([earthquake_data.iloc[::],Venus_data.iloc[::],moon_data.iloc[::]],axis=1)\ncorrelation_data.head(10)","a72dbb66":"#correlation map\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(correlation_data.corr(), annot=True, linewidths=.2, fmt= '.1f',ax=ax)\nplt.show()","55e90a15":"data.dtypes.head(10)","b44d0d60":"# Line Plot\ndata.plot(kind='line', x='earthquake.time', y='earthquake.latitude', alpha = 0.5,color = 'green',grid = True)\nplt.show()","c162ec51":"# Scatter Plot \n# x = attack, y = defense\ndata.plot(kind='scatter', x='Venus.speed', y='earthquake.mag',alpha = 0.2,color = 'blue',figsize = (10,10))\nplt.xlabel('Venus Speed')              # label = name of label\nplt.ylabel('Earthquake Magnitude')\nplt.title('Scatter Plot')            # title = title of plot\nplt.show()","c0c3ea14":"# Histogram\n# bins = number of bar in figure\ndata.plot(kind='hist',  y='earthquake.mag',bins = 45, alpha = 0.7,color = 'green',figsize = (10,10))\nplt.show()","9557076c":"# we retrieved data from a .csv file.\ndata = pd.read_csv('..\/input\/earthquakes-solar-system-objects\/SolarSystemAndEarthquakes.csv')","7392f032":"data.columns","ded685dc":"# DataFrame is a 2-dimensional data structure with columns of potentially different types.\ndata_frame = data[['earthquake.time','earthquake.place']]  \nprint((data_frame.head(10)))\n\n# Series is single column of a dataframe\nseries = data['earthquake.time']        \nprint((series.head(10)))\n","68a4bb4c":"# 1 - Filtering Pandas data frame, i wanted to filter earthquakes after 2016.\n# there are 36 earthquakes after 2016 in our dataset.\nx = data['earthquake.time']>'2016-01-01T00:00:00.000Z'\ndata[x].head(10)","7e8f5a8e":"# 2 - Filtering pandas with logical_and\n# We can see the earthquakes happen which have higher magnitude than 7 and when the moon illumination bigger than 90\ndata[np.logical_and(data['earthquake.mag']>7, data['MoonPhase.illumination']>90 )].head(10)\n\n# and this is also same statement with previous. We just used '&' operator for filtering\n#data[(data['earthquake.mag']>7) & (data['MoonPhase.illumination']>90)]","ede6140c":"def ExtractTuple():\n    \"\"\"This function returns a tuple, defined in function.\"\"\"\n    tuple1 = ('Istanbul','Turkey', 10, 2018 )  \n    return tuple1\n\ncity, country, month, year = ExtractTuple()\ntuple2 = ExtractTuple()\nprint(city, country, month, year)\nprint(tuple2[0])\nprint (tuple2[1:3]) # Start, Stop\n\ndef UpdateTuple(tuple3):\n    \"\"\"This function updates a tuple given\"\"\"\n    # tuple3[0] = \"This value was updated.\" !!! This is not valid. Remember, tuples cannot be changed. !!!\n    tupleNewValue = ('New Value',) # the comma is required for one element tuple\n    tupleNew = tuple3 + tupleNewValue\n    return tupleNew\n\nprint(tuple2)\ntupleResult = UpdateTuple(tuple2)\nprint(tupleResult)\n","a35e4a7e":"thisIsVariable = 9\ndef f():\n    \"\"\"scope example\"\"\"\n    thisIsVariable = 7\n    return thisIsVariable\n\nprint('This is global variable',thisIsVariable)\nprint('This is local variable',f())","4e508d4b":"# builtins are functions and constants that embedded in Python.\n# This module provides direct access to all \u2018built-in\u2019 identifiers of Python.\nimport builtins\n\n# let's look at built-in identifiers\ndir(builtins)","e9ff9751":"def outer(num1):\n    def inner_increment(num1):  # Hidden from outer code\n        return num1 + 1\n    num2 = inner_increment(num1)\n    print(num1, num2)\n\n#inner_increment(10) # try calling this\nouter(10)","de186416":"# b is default argument\ndef defaultArg(name, b='Hello!'):\n    print (name,b)\ndefaultArg('Ensar') \n\n# if we want to change default\ndefaultArg('Ensar','Hi')\n\n# *args can be one or more\ndef myArgs(*args):  \n    for arg in args:  \n        print (arg)           \nmyArgs('Ensar','Turkey','Istanbul')      \n\n# **kwargs is a dictionary\ndef myKwargs(**kwargs):  \n    for key, value in kwargs.items(): \n        print (\"%s == %s\" %(key, value)) \nmyKwargs(one = 'A', two='B', three ='C')\n","26575310":"lambFunction = lambda x,y : x + y\nprint(lambFunction(5,6))","18459b91":"thisIsTuple = (\"orange\", \"mandarin\", \"lemon\")\nthisIsIterator = iter(thisIsTuple)\n\n# next value\nprint(next(thisIsIterator))\n\n# remaining values\nprint(*thisIsIterator)\n\n# Even strings are iterable objects.\naString = \"Incomprehensibilities\"\niterator = iter(aString)\nprint(next(iterator))\nprint(next(iterator))\nprint(*iterator)","68f1851f":"numberList = [1, 2, 3]\nstrList = ['one', 'two', 'three']\n\n# Two iterables are passed\nresult = zip(numberList, strList)\n\n# Converting iterator to list\nresultList = list(result)\nprint(resultList)\n\nun_zip = zip(*resultList)\nun_list1,un_list2 = list(un_zip)\nprint(un_list1)\nprint(un_list2)","8fb7af56":"oldList = [1,2,3,4,5]\nnewList = [ item * 10 for item in oldList if item > 2 ]\n\nprint(newList)","a070a9db":"# Let's return to our Earthquakes data and give an example.\n# I want to show you earthquakes when happened after 2016 and greater than a threshold value.\n\n# i will look at column names and calculate a threshold.\ndata.columns\nthreshold =sum(data['earthquake.mag']) \/ len(data['earthquake.mag'])\n\n# we have classified the earthquakes by threshold.\nstr1 = 'High'\nstr2 = 'Lower'\ndata[\"magnitude_level\"] = [str1 if i > threshold else str2 for i in data['earthquake.mag']]\n\n# loc function can access a group of rows and columns by labels or a boolean array.\ndata.loc[:,[\"magnitude_level\",\"earthquake.mag\",\"earthquake.place\",\"earthquake.time\"]].head(10)\n","74bc063f":"data = pd.read_csv('..\/input\/earthquakes-solar-system-objects\/SolarSystemAndEarthquakes.csv')\n\n# head shows first 5 rows without parameter, otherwise up to parameter\ndata.head()  ","3b09dc5a":"# tail shows last 5 rows without parameter, otherwise up to parameter\ndata.tail()","bf4d45bb":"# columns gives the column labels\ndata.columns","565ffbbe":"# Return a tuple of rows and columns of the dataframe\ndata.shape","4e3c0b09":"# This method prints information about a DataFrame\n# if we want to print a short summary, we use verbose=False. Please try yourself for 'True'.\ndata.info(verbose=False)","b79dd3e0":"# describe() is used to view some basic statistical details \n# like percentile, mean, std etc. of a data frame or a series of numeric values.\n# it ignores NaN values and non-numeric values.\n\ndata.describe()\n\n# count -> number of entries\n# mean --> average of entries\n# std ---> standard deviation\n# min ---> minimum value\n# 25% ---> first quartile, Q1\n# 50% ---> second quartile, median\n# 75% ---> third quartile, Q3\n# max ---> maximum value","c2752db7":"data.boxplot(column=\"earthquake.mag\", by=\"MoonPhase.dynamic\",figsize=(9,9))\nplt.show()","ccc9c700":"# let's achiece a new dataframe from our dataset.\n# i will choose only first 5 rows.\ndata_new = data.head()\ndata_new\n\n# value_vars -> the columns that i want to melt.\nmelted_data = pd.melt(frame=data_new,id_vars='earthquake.time',value_vars=['earthquake.mag','Venus.speed'])\nmelted_data","19f1427d":"# i want to turn variables to columns.\n# values are still values.\nmelted_data.pivot(index='earthquake.time',columns='variable',values='value')","187ac49e":"data1 = data.head()\ndata2 = data.tail()\n# axis = 0 means vertically concat...\nconcatVertically = pd.concat( [ data1, data2 ], axis = 0, ignore_index = True )\nconcatVertically","a2600c62":"# axis = 1 horizontally concat\ndata1 = data['earthquake.mag'].head()\ndata2 = data['Venus.speed'].head()\nconcatHorizontally = pd.concat( [ data1, data2 ], axis = 1, ignore_index = False )\nconcatHorizontally","f7e658a2":"data.dtypes.head(10)","015795a3":"# let's convert somethings.\ndata['earthquake.latitude'] = data['earthquake.latitude'].astype('category')\ndata['MoonPhase.percent'] = data['MoonPhase.percent'].astype('str')\ndata.dtypes.head(10)","96e6fed8":"# For this section, i will change my dataset.\n# This dataset holds data about animal bites.\ndata = pd.read_csv('..\/input\/animal-bites\/Health_AnimalBites.csv')\ndata.info()","68b89e38":"# In the previous scope we see that, we have (9003 - 6477 = )2526 null value in GenderIDDesc column.\n# dropna = False means; show me the also null values.\ndata[\"GenderIDDesc\"].value_counts(dropna = False)\n# According to output, there are 3832 male, 2016 female, 2526 null value.","78c8a21c":"# If we want to drop null values.\ndata1 = data # actually this statement not preferred.\n\n# inplace = True means, after dropna, assign new data to same dataframe, do not generate new dataframe.\n#data1[\"GenderIDDesc\"].dropna( inplace = True ) \n\n# we will see that there is no NaN values in GenderIDDesc column.\ndata1.head(10)","2e01d918":"# Now we will check previous statement with assert.\n# assert statement returns nothing if the statement is true, and returns error if the statement is false.\nassert 1 == 1","5238c0f7":"assert 1 == 2","f0a4d109":"# i expect that the below statement returns nothing, because i dropped all of the NaN values.\nassert data1[\"GenderIDDesc\"].notnull().all()","9875cd30":"data = pd.read_csv('..\/input\/animal-bites\/Health_AnimalBites.csv')\n\n#we can also fill NaN values with 'empty'\ndata[\"GenderIDDesc\"].fillna('empty',inplace = True)\n","d04a4a98":"# We can check a lot ot thing with assert.\n# assert data.columns[0] == 'Name'\nassert data.columns[0] == 'bite_date'","9a341561":"# dataframe from, dictionary from, list\n# it is useful to see each step.\ncountry = [\"Turkey\",\"India\",\"USA\"]\npopulation = [34,56,67]\nlist_label = [\"country\",\"population\"]\nlist_col = [country,population]\nlist_col\n\nzipped = list(zip(list_label,list_col))\nzipped\n\ndictionary = dict(zipped)\ndictionary\n\ndataFrame = pd.DataFrame(dictionary)\ndataFrame","759cd043":"# adding new column\ndataFrame[\"capital\"] = [\"Ankara\",\"New Delhi\",\"Washington\"]\ndataFrame","fbffbf34":"# broadcasting\ndataFrame[\"new column\"] = 0\ndataFrame","e43c7762":"# plotting all data\ndata = pd.read_csv('..\/input\/earthquakes-solar-system-objects\/SolarSystemAndEarthquakes.csv')\ndataPlot = data.head(1000).loc[:,[\"earthquake.mag\",\"earthquake.longitude\",\"Venus.speed\"]]\ndataPlot.plot()\nplt.show()\n# this plot is confusing, let's look at subplots.","94c43387":"dataPlot.plot(subplots=True)\nplt.show()","63823cad":"# scatter plot\ndataPlot.plot(kind=\"scatter\",x = \"Venus.speed\", y=\"earthquake.mag\")\nplt.show()","144e6f92":"# histogram\ndataPlot.plot(kind=\"hist\", y= \"earthquake.mag\", bins=50, range=(6,10), density = True)","e6dab3a1":"# cumulative and non-cumulative histogram plot\ndataPlot.plot(kind=\"hist\", y= \"earthquake.mag\", bins=50, range=(6,10), density = True, cumulative = True)\nplt.show()","4f06c093":"data.head(100).describe()","944a41ed":"timestamp_object = pd.to_datetime(list(data[\"earthquake.time\"]))\ntimestamp_object\nprint(type(data[\"earthquake.time\"][1]))\nprint(type(timestamp_object))","63219436":"# let's make timestamps as index\ndata2 = data.head(10).loc[:]\ntimestampObj = pd.to_datetime(list(data2[\"earthquake.time\"].str.replace(\"T\",\" \").str.replace(\"Z\",\" \")))\ndata2[\"newTime\"] = timestampObj \ndata2 = data2.set_index(\"newTime\")\ndata2","f4966531":"# now we can select data according to my new index\nprint(data2.loc[\"2016-04-20\":\"2016-04-15\"])\n","509eb984":"# resample according to year\ndata2.resample('A').mean()","b5d3db8b":"# resample according to hour\n# Because of some of hours don't have data, we see NaN.\ndata2.resample('H').mean().head()","18939726":"# we use interpolate to estimate values don't have.\n# of course, this function is valid only numeric columns.\ndata2.resample('H').first().interpolate(\"linear\").head()","6fec9639":"# read data\ndata = pd.read_csv('..\/input\/earthquakes-solar-system-objects\/SolarSystemAndEarthquakes.csv')\ndata2 = data.head(10).loc[:]\ndata2.insert(0, '#', range(1, len(data2) + 1))\ndata2.set_index('#',inplace=True)\ndata2\n#   '#' is our new index now.","dc724430":"# after this index refreshing if want to reach some data, for example first index is 1 now.\n#  Indexing using square brackets\nprint(data2[\"earthquake.place\"][1])","fda93174":"#  using column attribute\n# my columns includes '.' char so i will change the name.\ndata2=data2.rename(columns = {'earthquake.place':'earthquake_place'})\nprint(data2.earthquake_place[1])","1547fd13":"#  using loc\nprint(data2.loc[1,\"earthquake_place\"])","6e5e3c55":"# selecting only spesific columns\ndata2[[\"earthquake.time\",\"earthquake_place\"]]","b2213ee0":"# the difference is more square brackets.\nprint(type(data2[\"earthquake_place\"]))\nprint(type(data2[[\"earthquake_place\"]]))","ba5ee4e5":"# slicing and indexing\n# from index 1 to index 3\n# from earthquake.time to earthquake_place\ndata2.loc[1:3,\"earthquake.time\":\"earthquake_place\"]","b6bf3476":"# reverse slicing\ndata2.loc[10:1:-1,\"earthquake.time\":\"earthquake_place\"]","ce76baec":"# from something to end\ndata2.loc[1:10,\"earthquake.mag\":]","977b9dd0":"condition = data2[\"earthquake.mag\"] >= 7\ndata2[condition]","a6bea5f6":"# combining filters\nfirstFilter = data2[\"earthquake.mag\"] >= 7\nsecondFilter = data2[\"Venus.speed\"] >= 1\ndata2[firstFilter & secondFilter ][[\"earthquake.mag\",\"Venus.speed\"]]","32e167e9":"# filtering column based\n# show me Venus.speed that earthquake.mag >= 7\ndata2[\"Venus.speed\"][data2[\"earthquake.mag\"] >= 7]","23bd6e70":"def div(a):\n    return a*10\ndata2[\"earthquake.mag\"].apply(div)\n\n# or use lambda function\ndata2[\"earthquake.mag\"].apply(lambda a: a*10)","acdf9a35":"#definin column using other columns\ndata2[\"new_column\"] = data2[\"earthquake.mag\"]+data2[\"MoonPhase.total\"]\ndata2.head()","f0bd7db8":"# look at our index name and change it\nprint(data2.index.name)\ndata2.index.name = \"index_name\"\ndata2.head()","57ba9016":"# overwrite index\n# if we want to modify, we need to change all of them\ndata2.head()\ndata3 = data2.copy()\ndata3.index = range(100,110,1) # start, stop, step\ndata3","37930ff7":"data = pd.read_csv(\"..\/input\/earthquakes-solar-system-objects\/SolarSystemAndEarthquakes.csv\")\ndata.head()\n\n# outer and inner index\ndata1 = data.set_index([\"earthquake.mag\",\"Venus.speed\"])\ndata1.head(10)","8bdeead0":"data = pd.read_csv(\"..\/input\/earthquakes-solar-system-objects\/SolarSystemAndEarthquakes.csv\")\ndata.head()","69476559":"data.pivot(columns =\"MoonPhase.dynamic\",values =\"earthquake.mag\").head(10)","7bd97d81":"Item = ['Item0', 'Item0', 'Item1', 'Item1']\ncType = ['Gold', 'Bronze', 'Gold', 'Silver']\nUSD = [2, 4, 6, 8]\nEU = ['1', '2', '3', '4']\n\nlist_label = [\"Item\",\"cType\",\"USD\",\"EU\"]\nlist_col = [Item,cType,USD,EU]\nlist_col\n\nzipped = list(zip(list_label,list_col))\nzipped\n\ndictionary = dict(zipped)\ndictionary\n\ndataFrame = pd.DataFrame(dictionary)\ndataFrame\n\ndataFrame1 = dataFrame.set_index([\"Item\",\"cType\"])\ndataFrame1\n\n# and then we will unstack index 0 with level = 0\n#dataFrame1.unstack(level=0)\n\n# unstack index 1 with level = 1\n#dataFrame1.unstack(level=1)\n\n# please try yourself  with comment lines","4978b7f7":"# change inner and outer level index position\ndataSwap = dataFrame1.swaplevel(0,1)\ndataSwap","af358f3c":"dataFrame1","02e61d5a":"pivotted = dataFrame.pivot(index ='Item', columns='cType', values='USD')\npivotted","e5f616f5":"melted = pd.melt(dataFrame, id_vars=\"Item\",value_vars=[\"cType\",\"USD\"])\nmelted","43bfcb36":"dataFrame","bea96dd9":"dataFrameGrouped = dataFrame.groupby('cType').mean()\ndataFrameGrouped","d75197bc":"# we can only choose one of the feature\ndataFrame.groupby(\"Item\").USD.max() ","5043073c":"# Or we can choose multiple features\ndataFrame.groupby(\"Item\")[[\"USD\",\"EU\"]].min() ","8c0cba90":"dataFrame.info()\n# this is show us,\n# A variable is also object, if we use groupby, we can convert it to categorical data.\n# categorical data uses less memory.\ndataFrame[\"Item\"] = dataFrame[\"Item\"].astype(\"category\")\ndataFrame.info()","1215e9d4":"An easier way to see correlation is correlation heat map.","0e2e0bfb":"### Hierarchical Indexing","3efb4e1f":"### List Comprehension\n* List comprehensions provide a concise way to create lists. \n* It consists of brackets containing an expression followed by a for clause, then zero or more for or if clauses. ","a9c5efa1":"### Nested Function\n* Defining a function inside an another function is known as **nested function**\n* There is a LEGB rule. **Local** -> **Enclosed** -> **Global** -> **Built-in**. Arrows show the direction of the namespace-hierarchy search order. ","eba67636":"# The Recruit  |  Python & Pandas and Data Science for Beginners\n** In this notebook, i will write some basics about Pandas and Matplotlib libraries with examples. My aim is to learn and help anyone who wants to learn like me easily.**\n\n**This is not a completely tutorial. It is being written to learn Python for data science and includes only that i understand. **\n\n1. [Introduction to Python](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#1.-Introduction-to-Python)\n    1.  [Matplotlib](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Matplotlib)\n    2.  [Pandas](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Pandas)\n2.  [Python Functions](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#2.-Python-Functions)\n    1.  [User Defined Functions](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#User-Defined-Functions)\n    2.  [Scope](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Scope)\n    3.  [Nested Function](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Nested-Function)\n    4.  [Default and Flexible Arguments](https:\/\/www.kaggleusercontent.com\/kf\/6904357\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..dNr6AgKmjldpZ7kNAFMUew.jWrVI6yscHBTyspZEQtKolotgqt8GWD0mVvlZAOhWxtHesF89ruPhuCr53y_ZvxrXoru69z4VQN3_P1uA0gc_lvFjhFXCPL7IFK1NuplZ74e3F0Cu6VShB-mqp7wcW9HxVLyIqfKRAU37190PlgfXSKkQLlmzZRM5TXYL7mIr35nvDRNOS0SYcYomKJpI1jv.85grCp3k9X7tZX7sQfgI_A\/__results__.html#Default-and-Flexible-Arguments)\n    5.  [Lambda Function](https:\/\/www.kaggleusercontent.com\/kf\/6904357\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..dNr6AgKmjldpZ7kNAFMUew.jWrVI6yscHBTyspZEQtKolotgqt8GWD0mVvlZAOhWxtHesF89ruPhuCr53y_ZvxrXoru69z4VQN3_P1uA0gc_lvFjhFXCPL7IFK1NuplZ74e3F0Cu6VShB-mqp7wcW9HxVLyIqfKRAU37190PlgfXSKkQLlmzZRM5TXYL7mIr35nvDRNOS0SYcYomKJpI1jv.85grCp3k9X7tZX7sQfgI_A\/__results__.html#Lambda-Function)\n    6.  [Iterators](https:\/\/www.kaggleusercontent.com\/kf\/6904357\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..dNr6AgKmjldpZ7kNAFMUew.jWrVI6yscHBTyspZEQtKolotgqt8GWD0mVvlZAOhWxtHesF89ruPhuCr53y_ZvxrXoru69z4VQN3_P1uA0gc_lvFjhFXCPL7IFK1NuplZ74e3F0Cu6VShB-mqp7wcW9HxVLyIqfKRAU37190PlgfXSKkQLlmzZRM5TXYL7mIr35nvDRNOS0SYcYomKJpI1jv.85grCp3k9X7tZX7sQfgI_A\/__results__.html#Iterators)\n    7.  [Zip Function](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Zip-Function)\n    8.  [List Comprehension](https:\/\/www.kaggleusercontent.com\/kf\/6904357\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..dNr6AgKmjldpZ7kNAFMUew.jWrVI6yscHBTyspZEQtKolotgqt8GWD0mVvlZAOhWxtHesF89ruPhuCr53y_ZvxrXoru69z4VQN3_P1uA0gc_lvFjhFXCPL7IFK1NuplZ74e3F0Cu6VShB-mqp7wcW9HxVLyIqfKRAU37190PlgfXSKkQLlmzZRM5TXYL7mIr35nvDRNOS0SYcYomKJpI1jv.85grCp3k9X7tZX7sQfgI_A\/__results__.html#List-Comprehension)\n3. [Data Cleaning](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Data-Cleaning)\n    1. [Diagnosing](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Diagnosing)\n    2. [Exploratory Data Analysis](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Exploratory-Data-Analysis)\n    3. [Visual Exploratory Data Analysis](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Visual-Exploratory-Data-Analysis)\n    4. [Tidy Data](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Tidy-Data)\n    5. [Pivoting Data](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Pivoting-Data)\n    6. [Data Types](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Data-Types)\n    7. [Missing Data and Testing with Assert](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Missing-Data-and-Testing-with-Assert)\n4. [Pandas Foundation](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Pandas-Foundation)\n    1. [Review of Pandas](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Review-of-Pandas)\n    2. [Building Data Frames from Scratch](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Building-Data-Frames-from-Scratch)\n    3. [Visual Exploratory Data Analysis](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Visual-Exploratory-Data-Analysis) \n    4. [Statistical Data Analysis](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Statistical-Data-Analysis)\n    5. [Indexing Pandas Time Series](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Indexing-Pandas-Time-Series) \n    6. [Resampling Pandas Time Series](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Resampling-Pandas-Time-Series)\n5. [Manipulating Data Frames with Pandas](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Manipulating-Data-Frames-with-Pandas)\n      1. [Indexing Data Frames](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Indexing-Data-Frames)\n      2. [Slicing Data Frames](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Slicing-Data-Frames)\n      3. [Filtering Data Frames](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Filtering-Data-Frames)\n      4. [Transforming Data](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Transforming-Data)\n      5. [Index Objects and Labeled Data](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Index-Objects-and-Labeled-Data)\n      6. [Hierarchical Indexing](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Hierarchical-Indexing)\n      7. [Pivoting Data Frames](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Pivoting-Data-Frames)\n      8. [Stacking and Unstacking Data Frames](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Stacking-and-Unstacking-Data-Frames)\n      9. [Melting Data Frames](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Melting-Data-Frames)\n      10. [Categoricals and Group By](https:\/\/www.kaggleusercontent.com\/kf\/6904122\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..eP75wb4_dn_8nsOfJprG8A.Q5rvzc2Cumfv6XvZui6iG6XNHDfE6Nu0IJ5a3rsF5-WEo6bfMbzCLQBrsc_3Vz8vyPritklFsdfd6lsCrk9yc1yhnWcvaAVJ0pUugcLeQSRIHOHW9YLJkD2sQaaGWYO3_1s38ZOXoHzrmuI_YCicIWNlO7RhUSGvYCyuMiCwmNvId9VLnhFH1yVYx_MI8q_H.uzXdL3OVcwtSN3uMb0Nsqw\/__results__.html#Categoricals-and-Group-By)","4f273fcb":"### Concatenating Data\n* Two dataframes can be concatenated.","deba9ad9":"### Zip Function\n* The zip() function take iterables.\n* The purpose of zip() is to map the similar index of multiple containers so that they can be used just using as single entity.","eb06d34f":"### Stacking and Unstacking Data Frames","411308d1":"### Exploratory Data Analysis\n1,4,5,6,8,9,11,12,13,14,15,16,17\n* **Median**; if there is an **odd** number of values, the median is the middle value. If there is an **even** number of values, the median is the average of the two middle values. In this case; median is 11.\n* **The lower quartile**, **Q1** is the median of the lower half of the data set, between the smallest value and median. In this case; the lower quartile is 6.\n* **The upper quartile**, **Q3** is the median of the upper half of a data set, between the greatest value and median. In this case; the upper quartile is 14.\n* **Interquartile range**, **IQR** is the spread of the middle 50% of the values. In the other words,  it is the range between Q3 and Q1. IQR **=** Q3 **-** Q1. The interquartile range is often used to find **outliers** in data. \n* An **outlier** is an observation that lies an abnormal distance from other values. Outliers are defined as that **below** **Q1 \u2212 1.5 IQR** or **above** **Q3 + 1.5 IQR**.","3060c149":"Let's read data source.","32aa5f76":"### Filtering Data Frames\nFiltering with boolean conditions.","e26e40ed":"### Default and Flexible Arguments","b0174b21":"### Statistical Data Analysis\nPlease repeat my previous sections.","e3fbc5d6":"### Visual Exploratory Data Analysis\n* Plot, subplot\n* Histogram\n    * bins: number of bins\n    * range(tuble): min and max values of bins    \n    * density(boolean): normalize or not    \n    * cumulative(boolean): compute cumulative distribution    ","8c3f1447":"Let's examine a few datas and see what we have.","9538dc99":"### Visual Exploratory Data Analysis\n* We will use Pandas.DataFrame.boxplot to make a box plot from DataFrame columns.\nIn the plot;\n* Black line on top is **max**.\n* Blue line on top is **%75**.\n* Green line in the middle is **median**.\n* Blue line at bottom is **%25**\n* Black line at bottom is **min**.\n* The point above the black line are **outliers**.\n","9c4f22b1":"### Iterators\n* Lists, tuples, dictionaries, and sets are all **iterable** containers which you can get an **iterator** from.\n* An iterator returns next value.","c8de60bf":"### Lambda Function\n* A lambda function is a small anonymous function.\n* A lambda function can take any number of arguments, but can only have one expression.\n* lambda arguments : expression","8826f019":"### Missing Data and Testing with Assert\nIf we encounter with missing data, we can;\n* leave as\n* drop them with dropna()\n* fill missing value with fillna()\n\n","10cd7272":"### Pandas\nPandas is a data analysis tool for Python. Let's look at basic subjects.\n* CSV : Comma-separated values","4dc688fc":"## Manipulating Data Frames with Pandas\n### Indexing Data Frames\n* Indexing using square brackets\n* Using column attribute and row label\n* Using loc\n* Selecting only spesific columns","ec3a95e5":"We can look at the data types to get summary information about data.","d514a97d":"### Indexing Pandas Time Series\n* Timestamp is the pandas equivalent of python's Datetime.\n* We need ISO 8601 date format ( yyyy-mm-dd hh:mm:ss.fff )","c6a5cfbc":"\n### Transforming Data Frames","9b8f19d1":"### Pivoting Data\n* Data pivoting enables you to rearrange the columns and rows.\n* We can say reverse of melting.","d546418a":"## Introduction to Python\n### Matplotlib\n Matplotlib is a very useful python library for plotting graphics. Basic plots are line, scatter and histogram plots.\n* You should use **Line Plot** when you chart a continuous data set and preferably when x axis is time..\n* **Scatter Plot** is useful when looking for outliers or for understanding the distribution of your data and when there is correlation between two variables \n*  **Histogram Plot** lets you discover, and show, the distribution of a set of continuous data","e0e156d7":"### Data Types\n* There are 5 basic data types.\n* **Object ( string )** is sequences of character data, *\"this is a string\"*.\n* **Integer**  is a number that can be written without a fractional component, *123*\n* **Float** values are specified with a decimal point, *4.2*\n* **Boolean** type may have one of two values, *True* or *False*.\n* **Categorical** is a pandas data type corresponding to categorical variables in statistics. We will learn with *scikit-learn*.\n* Data types can be conversioned to each other.","383d05e7":"### Scope\n* Scope refers to the visibility of variables.\n* Global variable; a global variable is visible throughout the program, even out of parenthesis\n* Local variable;  a local variable is visible only given scope, i mean parenthetical\n* Built-in function; these are always available in Python, like print, tuple keywords etc.","3949b1e6":"## 2. Python Functions\n### User Defined Functions\n* The first statement of a function can be a documentation string of the function or *docstring*.\n* Function blocks begin with the keyword *def*\n* The code block starts with a colon (:) and is indented.\n    * tuple : A tuple is a sequence of immutable Python objects, just like list. The tuples cannot be changed unlike lists.","e37cc42e":"### Resampling Pandas Time Series\n* **Resampling** is estimating sample statistics (medians, variances, percentiles) by using available data .\n* **Downsampling** is the process of reducing the sampling for slower frequency, like daily to weekly.\n* **Upsampling**  is the process of increasing the sampling for faster frequency, like daily to hourly.\n* **Interpolating** is an estimation of a value within two known values in a sequence of values","db90beb9":"### Categoricals and Group By","0b89e962":"### Tidy Data\n* Tidy data is the data obtained as a result of a process called data tidying.\n* We use pandas.melt function to tidy data.\n* You can understand melting is a process that one or more column are melt in a pot.","0f01ac08":"## Data Cleaning\nCleaning data is the first step of analysis. Because, data never comes in clean. \nUnclean data means:\n* Inconsistent column names (some of them may have upper or lower case, space between words or bad characters. )\n* Missing data\n* Outliers\n* Duplicate rows\n\n### Diagnosing\nWe will look at head, tail, columns, shape and info functions to diagnose data. These will give us summary information about data.","b2de3655":"Filtering rows of a DataFrame is an almost mandatory task for Data Analysis with Python. Given a Data Frame, we may not be interested in the entire dataset but only in specific rows.","c049e44d":"### Melting Data Frames","d134cc4b":"If we want to learn correlation between datas, we use corr function to compute pairwise correlation of columns. The values that i separated with colon mean, Start Index, Stop Index and Step. So, we can look correlation between columns which we want to know. If we write nothing, we see the correlation between all columns. This means, too many data and a bigger chart.\n\n* I want to look at relation between a few thing so, i will select related data with concat function.","d367d466":"## Pandas Foundation\n### Review of Pandas\nLet's learn Pandas more.\n* **series** is a one-dimensional labeled array capable of holding data of any type. \n* **NaN** Not a Number.\n* **DataFrame.values** returns a Numpy representation of the DataFrame.\n### Building Data Frames from Scratch\n* We can build dataframes from **csv**.\n* We can build dataframes from **dictionaries**.\n    * **zip()** function; returns an iterator of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column to existing dataframe.\n* **Broadcasting** is creating new column and assigning a value entire column.\n","d4ba6f68":"\n### Index Objects and Labeled Data","f30b8970":"### Slicing Data Frames\n* Selecting series and dataframes\n* Slicing and indexing series","4bcc2d9c":"### Pivoting Data Frames"}}