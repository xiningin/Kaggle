{"cell_type":{"0378b3a1":"code","b4056f0f":"code","7a39e6b1":"code","ed5cda5f":"code","ec4af830":"code","000e9878":"code","6f5d45fa":"code","7cd9f79f":"code","11fbce8a":"code","0183bae5":"code","413f2fca":"code","02545e5b":"code","61a8978d":"code","0c6ee53d":"code","9120b37f":"code","b2e84149":"code","c117098c":"code","60f170b5":"code","2e175607":"code","fed31d45":"code","1b74fc32":"code","cd7b415b":"code","70b832be":"code","1a18e357":"code","f6bd9df6":"code","96c36734":"code","3370a76b":"code","9521e53c":"code","973804ba":"code","ac761e8f":"code","8a867370":"code","6b1d5d48":"code","7a7f2322":"code","dbfd744c":"code","dd409327":"code","e7f06400":"code","3f7ed7d2":"code","2b83fd0f":"code","696f0dbb":"code","45ad4170":"code","baa94fc6":"code","49eb939f":"code","1fa92db2":"code","3dc1cbe1":"code","a1450bcf":"code","138d8cd2":"code","9bb0a34c":"code","fb5727f2":"code","9198f29e":"code","0a4e79c2":"code","efc99cfa":"code","c430de2e":"code","521d9d17":"code","c4a16146":"code","1e6a0018":"code","679e27c7":"code","32eb5025":"code","d9a2041b":"code","80a62a6e":"code","f6d8d8a3":"code","17a4d108":"code","cab30286":"code","e0ab70bf":"code","0fdfe5cb":"code","23767a19":"markdown","e51e44df":"markdown","44d3ff69":"markdown","acd36dc0":"markdown"},"source":{"0378b3a1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b4056f0f":"#reading excel files\nimport pandas as pd\nJan = pd.read_excel('..\/input\/job-market-reports-sept19jan20\/Jobs Sep 2019.xlsx')\nJan.head(2)","7a39e6b1":"#get other files\nDec=pd.read_excel('..\/input\/job-market-reports-sept19jan20\/Jobs Dec 2019.xlsx')\nNov=pd.read_excel('..\/input\/job-market-reports-sept19jan20\/Jobs Nov 2019.xlsx')\nOct=pd.read_excel('..\/input\/job-market-reports-sept19jan20\/Jobs oct 2019.xlsx')\nSep=pd.read_excel('..\/input\/job-market-reports-sept19jan20\/Jobs Sep 2019.xlsx')\nAug=pd.read_excel('..\/input\/job-market-reports-sept19jan20\/Jobs August 2019.xlsx')","ed5cda5f":"Aug.describe()","ec4af830":"Aug.info()","000e9878":"Aug['Metro'].unique()","6f5d45fa":"Aug['Dimension Type'].unique()","7cd9f79f":"Aug['Dimension'].unique()","11fbce8a":"Aug['Measure'].unique()","0183bae5":"Aug['Value'].unique()","413f2fca":"Sep.head(2)","02545e5b":"#Expand on October\nOkt=Oct[['Metro', 'Dimension', 'Value']]\nOkt.head(2)","61a8978d":"import numpy as np\n#label encode the metro column\nfrom sklearn.preprocessing import LabelEncoder\nOkt['Metro']= Okt['Metro'].astype('category')\nOkt['Metro Catgs']=Okt['Metro'].cat.codes\nOkt.head(3)","0c6ee53d":"import seaborn as sns\nsns.countplot(Okt['Metro Catgs'])","9120b37f":"#group by categories to better understand the df data\nG1= Okt.groupby('Metro Catgs')\nG1.head().head()","b2e84149":"Okt.astype(str)","c117098c":"Okt['Value'] = Okt['Value'].str.replace('$', '')","60f170b5":"Okt['Value']=Okt['Value'].str.replace(',', '').astype(float)","2e175607":"Okt['Value']=Okt['Value'].fillna(0)","fed31d45":"#Verify changes\nOkt['Value'].head()","1b74fc32":"Okt['Metro Catgs'].astype(int)","cd7b415b":"#correlate\nOkt.corr()\n\n##there seem to be no correlation between these columns as they are.","70b832be":"#Visualize it\n#Linear-graph for relationships\nOkt.plot.scatter(\"Value\", \"Metro Catgs\", color='green')","1a18e357":"Okt.corr().plot.bar()","f6bd9df6":"#The original columns have mixed information.\nlist(Nov['Dimension'].unique())","96c36734":"##extract job titles in the column\n#First, find the location of the desired data\n#Nov['Dimension'].head(50) ##job titles start at 42\nNov['Dimension'].tail(80) ##job titles end at 4837","3370a76b":"N=Nov[42:4838] #to include the last row go 1 over\nN.head(3)","9521e53c":"#I want to examine the national data with job titles\nNational=N[(N['Metro']=='National')]\nNational =National[(National['Dimension Type']=='Job Title')]\nNational.head(3)","973804ba":"#Job opening titles with their base salary\nJobs=National[['Dimension','Value']]","ac761e8f":"#replace NaNs with 0s\nJobs['Value']=Jobs['Value'].fillna(0)","8a867370":"#clean data \nJobs['Value'] = Jobs['Value'].str.replace('$', '')\nJobs['Value'] = Jobs['Value'].str.replace(',', '').astype(float)","6b1d5d48":"Jobs.head(2)","7a7f2322":"#Label encode job titles\nfrom sklearn.preprocessing import LabelEncoder\nJobs['Dimension']=Jobs['Dimension'].astype('category')\nJobs['Titles catgs']=Jobs['Dimension'].cat.codes\nJobs.head(2)","dbfd744c":"Jobs.describe()","dd409327":"Jobs.median()","e7f06400":"Jobs.corr()\n#There does not seem to be a correlation between the columns","3f7ed7d2":"#Job title-to-pay distribution\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.scatter(Jobs['Value'], Jobs['Titles catgs'], color='purple')\nplt.show()","2b83fd0f":"Jobs.corr().plot.bar()","696f0dbb":"#A df of monthly US Job Opening and Median pay across all dfs: Aug 2019 - Jan 2020\nmonths = {'Jan20': Jan[0:2], 'Dec19': Dec[0:2], 'Nov19': Nov[0:2], 'Oct19': Oct[0:2], 'Sep19': Sep[0:2], 'Aug19': Aug[0:2]}\n\nMonthly = pd.concat(months)\nJobsNpay= Monthly.drop(['Metro', 'Dimension Type', 'Month', 'Dimension', 'YoY'], axis=1)\nJobsNpay","45ad4170":"#clean data \nJobsNpay['Value'] = JobsNpay['Value'].str.replace('$', '')\nJobsNpay['Value'] = JobsNpay['Value'].str.replace(',', '').astype(float)","baa94fc6":"#Compare monthly US Job Opening and Median pay across all dfs: Aug 2019 - Jan 2020\nMonthly1 = pd.concat([Jan[0:2], Dec[0:2], Nov[0:2], Oct[0:2], Sep[0:2], Aug[0:2]])\nMonthly1","49eb939f":"JobsNpay1= Monthly1.drop(['Metro', 'Dimension Type', 'Month', 'Dimension', 'YoY'], axis=1)\nJobsNpay1","1fa92db2":"#clean data \nJobsNpay1['Value'] = JobsNpay1['Value'].str.replace('$', '')\nJobsNpay1['Value'] = JobsNpay1['Value'].str.replace(',', '').astype(float)","3dc1cbe1":"sns.distplot(JobsNpay1['Value'], color='red', bins=3)\n#Every other row represent something different.\n#Also, the numbers could be normalize to 'even' the data","a1450bcf":"p=JobsNpay1.iloc[[0,2,4,6,8,10]]\np","138d8cd2":"USJobs=p.dropna()","9bb0a34c":"USJobs.median()","fb5727f2":"USJobs.hist()","9198f29e":"q=JobsNpay1.iloc[[1,3,5,7,9,11]]\nSalary=q.dropna()\nSalary","0a4e79c2":"Salary.describe()","efc99cfa":"import matplotlib.pyplot as plotter \n# Months as label\npieLabels = 'Jan2020', 'Dec19', 'Nov19', 'Oct19', 'Sep19', 'Aug19' \n\nfigureObject, axesObject = plotter.subplots()\n\n# Draw the pie chart\naxesObject.pie(USJobs['Value'],\n        labels=pieLabels,\n        autopct='%1.2f',\n        startangle=90)\n\n# Aspect ratio - equal means pie is a circle\naxesObject.axis('equal') \n\nplotter.show()","c430de2e":"Salary['Value'].corr","521d9d17":"USJobs['Value'].corr","c4a16146":"Okt['Dimension']= Okt['Dimension'].astype('category')","1e6a0018":"OctCityJobs=Okt[(Okt['Dimension']=='Metro Job Openings')]\nOctCityJobs=OctCityJobs.drop(['Dimension','Metro Catgs'], axis=1)\nOctCityJobs","679e27c7":"Dec.head(2)","32eb5025":"Dec1= Dec[['Metro','Dimension','Value']]\nDec1['Metro']=Dec1['Metro'].astype('category')\nDec1['Dimension']= Dec1['Dimension'].astype('category')\nDec1.head(2)","d9a2041b":"#clean data \nDec1['Value'] = Dec1['Value'].str.replace('$', '')\nDec1['Value'] = Dec1['Value'].str.replace(',', '').astype(float)","80a62a6e":"DecCityJobs=Dec1[(Dec1['Dimension']=='Metro Job Openings')]\nDecCityJobs=DecCityJobs.drop(['Dimension'], axis=1)\nDecCityJobs.rename(columns={'Value': 'Dec Jobs'}, inplace=True)\nDecCityJobs.head(2)","f6d8d8a3":"result = pd.concat([(DecCityJobs['Dec Jobs']), (OctCityJobs['Value'])], axis=1)\nresult","17a4d108":"result.corr()","cab30286":"#Linear correlation \nx=result['Dec Jobs']\ny=result['Value']\nplt.scatter(x,y)\nplt.show()","e0ab70bf":"result.corr(method=\"spearman\")","0fdfe5cb":"#heatmap\nf, ax = plt.subplots(figsize =(7, 6)) \nsns.heatmap(result, ax = ax, cmap =\"YlGnBu\", linewidths = 0.1) ","23767a19":"According to the above, the **median salaries** offered is $56,194","e51e44df":"**Relationships**   \n1. define the relationships under evaluation   \nThe data provides many opportunities for comparisons. Here, I analyze the relationship city-to-jobs relationship.   \n2. define the data   \nOkt dataframe (the month in the six-month period with the most jobs.) and Dec (the month with the least jobs)","44d3ff69":"**CORRELATE**  \n\nCorrelation coefficients evaluate how two variables are related to each other. The relationship could be linear, negatively linear, or monotonic.    \nIn a monotonic relationship the variables may not change together at the same rate.   \nCorr() helps compute three different correlation coefficients between two variables using either the Pearson correlation method, Kendall Tau correlation method and Spearman correlation method.    \n\nThe correlation coefficients calculated using these methods vary from +1 to -1.   \n\nPearson correlation coefficient: the covariance of two variables divided by the product of their standard deviations. It evaluates the linear relationship between variables. Pearson correlation coefficient has a value between +1 and -1:   \nA result of 1 = a linear correlation between variable x and y. 0 = variables are not related. A -1 = there is an inverse (negative) correlation between variables.   \nKendall Tau correlation coefficient: quantifies the discrepancy between the number of concordant and discordant pairs of two variables.      \nSpearman correlation coefficient:   \na nonparametric evaluation that finds the strength and direction of the monotonic relationship between variables.   \nBest for when the data is not normally distributed or when the sample size is small (**under 30**).     \n\nSource: https:\/\/pythontic.com\/pandas\/dataframe-computations\/correlation","acd36dc0":"There is no overlap among the Job Titles   \n"}}