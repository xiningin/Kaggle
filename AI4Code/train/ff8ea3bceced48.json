{"cell_type":{"71e85521":"code","fb72c5ec":"code","cc19c7c5":"code","b47e5126":"code","83c36005":"code","4d12cc8d":"code","eb72d177":"code","6be3229c":"code","05071553":"code","eb27c5ad":"code","175464bf":"code","99eda8c2":"code","800871c4":"code","5ed9ebbf":"code","a333f89e":"code","9124b041":"code","b938af3a":"code","c4e9b3ca":"code","59be41ba":"code","b95c34b0":"markdown","380ecf2d":"markdown","2c45bf2e":"markdown","8b4b474f":"markdown","8eb67a5d":"markdown","a3cabcb7":"markdown"},"source":{"71e85521":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","fb72c5ec":"mnist_train = pd.read_csv(\"..\/input\/sign-language-mnist\/sign_mnist_train.csv\")\nmnist_test = pd.read_csv(\"..\/input\/sign-language-mnist\/sign_mnist_test.csv\")","cc19c7c5":"print(mnist_train.shape, mnist_test.shape)","b47e5126":"mnist_train.head()","83c36005":"mnist_test.head()","4d12cc8d":"print(mnist_train.isna().any().any(), mnist_test.isna().any().any())\n# Data is completely clean without any missing values.","eb72d177":"mnist_train_data = mnist_train.loc[:, \"pixel1\":]\nmnist_train_label = mnist_train.loc[:, \"label\"]\n\nmnist_test_data = mnist_test.loc[:, \"pixel1\":]\nmnist_test_label = mnist_test.loc[:, \"label\"]","6be3229c":"# Data Normalization\nmnist_train_data = mnist_train_data\/255.0\nmnist_test_data = mnist_test_data\/255.0","05071553":"data_array = np.array(mnist_train_data.loc[2, :])\nshaped_data = np.reshape(data_array, (28, 28))\nsign_img = plt.imshow(shaped_data, cmap=plt.cm.binary)\nplt.colorbar(sign_img)\nprint(\"IMAGE LABEL: {}\".format(mnist_train.loc[2, \"label\"]))\nplt.show()","eb27c5ad":"sns.countplot(mnist_train.label)\nprint(list(mnist_train.label.value_counts().sort_index()))","175464bf":"mnist_train_data = np.array(mnist_train_data)\nmnist_test_data = np.array(mnist_test_data)\n\nmnist_train_data = mnist_train_data.reshape(mnist_train_data.shape[0], 28, 28, 1)\nmnist_test_data = mnist_test_data.reshape(mnist_test_data.shape[0], 28, 28, 1)\n\nprint(mnist_train_data.shape, mnist_train_label.shape)","99eda8c2":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Lambda, Flatten, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, AvgPool2D\nfrom tensorflow.keras.optimizers import Adadelta\nfrom keras.utils.np_utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import LearningRateScheduler","800871c4":"nclasses = mnist_train_label.max() - mnist_train_label.min() + 1\nmnist_train_label = to_categorical(mnist_train_label, num_classes = nclasses)\nprint(\"Shape of ytrain after encoding: \", mnist_train_label.shape)","5ed9ebbf":"nclasses = mnist_test_label.max() - mnist_test_label.min() + 1\nmnist_test_label = to_categorical(mnist_test_label, num_classes = nclasses)\nprint(\"Shape of ytest after encoding: \", mnist_test_label.shape)","a333f89e":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(64, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(128, kernel_size = 4, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(25, activation='softmax'))\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","9124b041":"model_history = model.fit(mnist_train_data, mnist_train_label, batch_size=500, shuffle=True, epochs=20, validation_split=0.1)","b938af3a":"mnist_train_data = mnist_train_data.reshape(mnist_train_data.shape[0], 784)\nprint(mnist_train_data.shape, mnist_train_label.shape)\n\nvc_loss, vc_accuracy = model.evaluate(mnist_test_data, mnist_test_label)\nprint(\"\\nLOSS: {}\\nACCURACY: {}\".format(vc_loss, vc_accuracy))","c4e9b3ca":"plt.plot(model_history.history['accuracy'],label = 'ACCURACY')\nplt.plot(model_history.history['val_accuracy'],label = 'VALIDATION ACCURACY')\nplt.legend()","59be41ba":"plt.plot(model_history.history['loss'],label = 'TRAINING LOSS')\nplt.plot(model_history.history['val_loss'],label = 'VALIDATION LOSS')\nplt.legend()","b95c34b0":"### Data Visualization","380ecf2d":"### Final Result\n* LOSS: 13%\n* ACCURACY: 97%","2c45bf2e":"### Training model","8b4b474f":"### MNIST Image Classification on Sign Language\n* In this project I am using MNIST dataset of hand made sign language images to classify each image into a class of 26 alphabets from A-Z.\n* KAGGLE LINK: https:\/\/www.kaggle.com\/datamunge\/sign-language-mnist","8eb67a5d":"![hand sign](https:\/\/storage.googleapis.com\/kagglesdsdata\/datasets%2F3258%2F5337%2Famer_sign2.png?GoogleAccessId=databundle-worker-v2@kaggle-161607.iam.gserviceaccount.com&Expires=1592174518&Signature=RrlCY6TrfnUgr9AxNjlEyWsp845fJfKHr9ohA6GCgKLQISPdxPXttB9JunDC%2BRHjPBVSyVZQKk6dAPtnxNvqnZHr%2FVucF7Jjpjzfd83N0CHs%2BpVrxZ%2FvqDRq8I4ijBXFz%2F2XxWTDEIAWzt2%2FCx0EMrgvBCWguuLSXHlWLuNVX3luSUS4zHlPCUwNsejkecU88Gu%2BpHJCyz0R9F7pUk1wvhhZvbUrkr0au2%2BXa%2BGzH4VmE0VDzJmjr8sSx7imFh%2BfR%2BJUGnCM5gtLTFKS6nZCEI2WCgSwC%2B4oXKzWEbiOPT39K5%2Bab0jT6EIqmELgbvLv2IMTQdT3MM29B1k0Rc3z%2Fg%3D%3D)","a3cabcb7":"### Please upvote if you find it hekpful! :)"}}