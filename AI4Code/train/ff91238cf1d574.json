{"cell_type":{"b935dd87":"code","165d8dbb":"code","54dc651f":"code","e1504f61":"code","1dbbd03b":"code","4208647b":"code","dae1afce":"code","7850ef29":"code","8e527147":"code","9a802c21":"code","19929794":"code","4931a13f":"code","947c2b69":"code","f128a19d":"code","8f6f5f67":"code","9b76e563":"code","d8620fef":"code","125c8cf8":"code","eac61823":"code","1bdcbcb4":"code","b7097852":"code","93ffc86d":"code","b29d6bb6":"code","193aca7f":"code","bd209b93":"code","4c481be6":"code","38234450":"code","cf912338":"code","f286cb09":"code","9ea6800b":"code","d14dccad":"code","22f4a41c":"code","0c383db5":"code","d2c3df32":"code","1efd9ec8":"code","bb79c727":"markdown","97c617d0":"markdown","20fd121b":"markdown","3440515b":"markdown","485fdf9b":"markdown","943538e0":"markdown","555b5e65":"markdown","123d42bb":"markdown","fae66ef8":"markdown","841f7573":"markdown","317ca334":"markdown","4f5ace4b":"markdown","5df61559":"markdown","9b4f1589":"markdown","e8349d72":"markdown","d4cff4d9":"markdown","eca3c325":"markdown","6587f4d4":"markdown","de5bc237":"markdown","23b3008b":"markdown","7841939b":"markdown","bec98274":"markdown","13616e57":"markdown","12f09f78":"markdown","4312f142":"markdown","68580abd":"markdown","cbfc48e7":"markdown","41e80355":"markdown","6933835f":"markdown","9d2217e4":"markdown","3fb9bd14":"markdown","be9468d0":"markdown","1d811d86":"markdown","e04c9d10":"markdown","f1526b51":"markdown","21c8cd8a":"markdown","cd72f432":"markdown","036681c5":"markdown","c5656aef":"markdown","49790414":"markdown","bf001bb6":"markdown","f1cc8949":"markdown"},"source":{"b935dd87":"import torch\nfrom torch import nn\nimport torchvision\nimport numpy as np\n#!pip install timm\nimport timm\nimport os\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nimport pandas as pd\nfrom timm.data import resolve_data_config\nfrom timm.data.transforms_factory import create_transform\nfrom torchvision.datasets import ImageFolder\nimport operator\nimport torchvision.transforms as transforms \nimport seaborn as sns\n\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nfrom sklearn.metrics import classification_report\nimport matplotlib.ticker as ticker\nimport itertools","165d8dbb":"#create a directory for models to be saved in \/kaggle\/working\nif os.path.exists(\"\/kaggle\/working\/models_archive\") == False:\n    os.mkdir(\"models_archive\")\nos.listdir()","54dc651f":"#test -> validation set\n#pred -> test set (not labelled)\ntrain_dir = \"\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\"\ntest_dir = \"\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test\"\npred_dir = \"\/kaggle\/input\/intel-image-classification\/seg_pred\/seg_pred\/seg_pred\"\n\nBATCH_SIZE = 64\nEPOCHS = 9\nCLASSES = os.listdir(train_dir)\nmetric = 0","e1504f61":"device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\ndevice","1dbbd03b":"def model_adjustment(p_model):\n    for param in p_model.parameters():\n        param.requires_grad=False\n    return p_model","4208647b":"def model_assets(base_model, seed):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(base_model.parameters(), lr=0.001)\n    lrp_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n    if seed == 0 or seed == 1:\n        mls_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[2], gamma=0.1)\n        return criterion, optimizer, lrp_scheduler, mls_scheduler\n    else:\n        return criterion, optimizer, lrp_scheduler","dae1afce":"def model_archive(seed):\n    if seed == 0:\n        model = torchvision.models.vgg19_bn(pretrained=True)\n        model = model_adjustment(model)\n        in_features = model.classifier[0].in_features\n        model.classifier = nn.Sequential(\n            nn.Linear(in_features, out_features=4096),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(in_features=4096, out_features=4096),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(in_features=4096, out_features=len(CLASSES)),\n        )\n        model.to(device)\n        criterion, optimizer, lrp_scheduler, mls_scheduler = model_assets(model, seed) \n        return model, criterion, optimizer, lrp_scheduler, mls_scheduler\n    \n    elif seed == 1:\n        model = timm.create_model('vit_base_patch16_224', pretrained=True)\n        model = model_adjustment(model)\n        in_features = model.head.in_features\n        model.head = nn.Linear(in_features, out_features=len(CLASSES), bias=True)\n        model.to(device)\n        criterion, optimizer, lrp_scheduler, mls_scheduler = model_assets(model, seed)\n        return model, criterion, optimizer, lrp_scheduler, mls_scheduler\n    \n    elif seed == 2:\n        model = timm.create_model('ens_adv_inception_resnet_v2', pretrained=True)\n        model = model_adjustment(model)\n        in_features = model.classif.in_features\n        model.classif = nn.Linear(in_features, out_features=len(CLASSES), bias=True)\n        model.to(device)\n        criterion, optimizer, lrp_scheduler = model_assets(model, seed)\n        return model, criterion, optimizer, lrp_scheduler\n    \n    elif seed == 3:\n        model = torchvision.models.densenet201(pretrained=True)\n        model = model_adjustment(model)\n        in_features = model.classifier.in_features\n        model.classifier = nn.Linear(in_features, out_features=len(CLASSES), bias=True)\n        model.to(device)\n        criterion, optimizer, lrp_scheduler = model_assets(model, seed)\n        return model, criterion, optimizer, lrp_scheduler\n    \n    elif seed == 4:\n        model = torchvision.models.resnext50_32x4d(pretrained=True)\n        model = model_adjustment(model)\n        in_features = model.fc.in_features\n        model.fc = nn.Linear(in_features, out_features=len(CLASSES), bias=True)\n        model.to(device)\n        criterion, optimizer, lrp_scheduler = model_assets(model, seed)\n        return model, criterion, optimizer, lrp_scheduler","7850ef29":"# VGG19 with batch-normalization\nmodel_vgg, criterion_vgg, optimizer_vgg, lrp_scheduler_vgg, mls_scheduler_vgg = model_archive(seed = 0)\n\n# ViT (Vision Transformer)\nmodel_vit, criterion_vit, optimizer_vit, lrp_scheduler_vit, mls_scheduler_vit = model_archive(seed = 1)\n\n# Ensemble Adversarial Inception-ResNet v2\nmodel_eairv, criterion_eairv, optimizer_eairv, lrp_scheduler_eairv = model_archive(seed = 2)\n\n# DenseNet201 classifier\nmodel_dn, criterion_dn, optimizer_dn, lrp_scheduler_dn = model_archive(seed = 3)\n\n# ResNeXt50_32 Classifier\nmodel_rnx, criterion_rnx, optimizer_rnx, lrp_scheduler_rnx = model_archive(seed = 4)","8e527147":"class AddGaussianNoise(object):\n    def __init__(self, mean=0., std=1.):\n        self.std = std\n        self.mean = mean\n        \n    def __call__(self, tensor):\n        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n    \n    def __repr__(self):\n        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)","9a802c21":"transform_train_v1 = torchvision.transforms.Compose([\n    transforms.Resize(size=256, interpolation=transforms.functional.InterpolationMode('bicubic'), max_size=None, antialias=None),\n    transforms.CenterCrop(size=(224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=([0.4850, 0.4560, 0.4060]), std=([0.2290, 0.2240, 0.2250])),\n    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), inplace=False),\n    transforms.RandomApply([AddGaussianNoise(0., 0.156)], p=0.5),\n])\ntransform_test_v1 = torchvision.transforms.Compose([\n    transforms.Resize(size=256, interpolation=transforms.functional.InterpolationMode('bicubic'), max_size=None, antialias=None),\n    transforms.CenterCrop(size=(224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=([0.4850, 0.4560, 0.4060]), std=([0.2290, 0.2240, 0.2250])),\n])","19929794":"config_vit = resolve_data_config({}, model = model_vit)\ntransform_vit = create_transform(**config_vit)\n\nconfig_eairv = resolve_data_config({}, model = model_eairv)\ntransform_eairv = create_transform(**config_eairv)","4931a13f":"train_data_v1 = ImageFolder(train_dir, transform = transform_train_v1)\ntest_data_v1 = ImageFolder(test_dir, transform = transform_test_v1)\n#loading data for VGG19 BatchNorm, DenseNet201, ResNeXt50\ntrain_loader_v1 = torch.utils.data.DataLoader(train_data_v1, BATCH_SIZE, shuffle=True)\ntest_loader_v1 = torch.utils.data.DataLoader(test_data_v1, BATCH_SIZE, shuffle=False)\n\n\ntrain_data_vit = ImageFolder(train_dir, transform = transform_vit)\ntest_data_vit = ImageFolder(test_dir, transform = transform_vit)\n#loading data for ViT\ntrain_loader_vit = torch.utils.data.DataLoader(train_data_vit, BATCH_SIZE, shuffle=True)\ntest_loader_vit = torch.utils.data.DataLoader(test_data_vit, BATCH_SIZE, shuffle=False)\n\n\ntrain_data_eairv = ImageFolder(train_dir, transform = transform_eairv)\ntest_data_eairv = ImageFolder(test_dir, transform = transform_eairv)\n#loading data for Ensemble Adversarial Inception-ResNetV2\ntrain_loader_eairv = torch.utils.data.DataLoader(train_data_eairv, BATCH_SIZE, shuffle=True)\ntest_loader_eairv = torch.utils.data.DataLoader(test_data_eairv, BATCH_SIZE, shuffle=False)","947c2b69":"def predictions_df(dl_model, test_loader, transform_obj):\n    pred_hard, pred_soft = [], []\n    correct_count, all_count = 0,0\n    dl_model.eval()\n    im_dim = transform_obj.transforms[1].size[0]\n    with torch.no_grad():\n        for images, labels in test_loader:\n            if torch.cuda.is_available():\n                images = images.cuda()\n                labels = labels.cuda()\n            for i in range(len(labels)):\n                img = images[i].view(1, 3, im_dim, im_dim)\n                # soft voting\n                output = dl_model(img)\n                sm = nn.Softmax(dim=1)\n                probabilities = sm(output)\n                prob_arr = (probabilities.detach().cpu().numpy())[0]\n                # hard voting\n                logps = dl_model(img)\n                ps = torch.exp(logps)\n                probab = list(ps.cpu()[0])\n                pred_label = probab.index(max(probab))\n                true_label = labels.cpu()[i]\n                #exporting to dataframe\n                pred_hard.append(pred_label)\n                pred_soft.append(prob_arr)\n                ####\n                if(true_label == pred_label):\n                    correct_count += 1\n                all_count += 1\n\n    print(\"Number of images Tested=\", all_count)\n    print(\"Model Accuracy=\",(correct_count\/all_count)*100)\n    print(\"\\n\")\n    return pred_hard, pred_soft","f128a19d":"def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs, seed, model_name, lrp_scheduler, mls_scheduler=None):\n    train_losses = np.zeros(epochs)\n    test_losses = np.zeros(epochs)\n\n    for it in range(epochs):\n        t0 = datetime.now()\n        model.train()\n        train_loss = []\n        train_total = 0\n        train_correct = 0\n        for batch_idx, (inputs, targets) in enumerate(train_loader):\n            # move data to GPU\n            inputs, targets = inputs.to(device), targets.to(device)\n            # zero the parameter gradients\n            optimizer.zero_grad()\n            # Forward pass\n            outputs = model(inputs)\n            _, train_predict = torch.max(outputs.data, 1)\n            loss = criterion(outputs, targets)\n            # Backward and optimize\n            loss.backward()\n            optimizer.step()\n            train_loss.append(loss.item())\n            train_total += targets.size(0)\n            train_correct += (train_predict == targets).sum().item()\n\n        else:\n            model.eval()\n            test_loss = []\n            test_total = 0\n            test_correct = 0\n            for inputs, targets in test_loader:\n                inputs, targets = inputs.to(device), targets.to(device)\n                outputs = model(inputs)\n                _, test_predict = torch.max(outputs.data, 1)\n                loss = criterion(outputs, targets)\n                test_loss.append(loss.item())\n                test_total += targets.size(0)\n                test_correct += (test_predict == targets).sum().item()\n            #get train and test loss\n            test_loss = np.mean(test_loss)\n            train_loss = np.mean(train_loss)\n            #scheduler ReduceLROnPlateau and MultiStepLR\n            lrp_scheduler.step(metric)\n            if seed == 0 or seed == 1:\n                mls_scheduler.step()\n            ###    \n            print('learning_rate: {}'.format(optimizer.state_dict()['param_groups'][0]['lr']))\n            # Save losses\n            train_losses[it] = train_loss\n            test_losses[it] = test_loss\n\n            dt = datetime.now() - t0\n            print(f'Epoch {it+1}\/{epochs}, Train Loss: {train_loss:.4f}, Acc: {(100*train_correct\/train_total):.4f}, \\\n                    Test Loss: {test_loss:.4f}, Test Acc: {(100*test_correct\/test_total):.4f}, Duration: {dt}')\n    return train_losses, test_losses","8f6f5f67":"print('Model: VGG-19-BN')\nloss_train_vgg, loss_test_vgg = batch_gd(model_vgg, criterion_vgg, optimizer_vgg, train_loader_v1, test_loader_v1, EPOCHS, 0, 'vgg_dict.pth', lrp_scheduler_vgg, mls_scheduler_vgg)\nprint('\\nModel: DenseNet201')\nloss_train_dn, loss_test_dn = batch_gd(model_dn, criterion_dn, optimizer_dn, train_loader_v1, test_loader_v1, EPOCHS, 2, 'dn_dict.pth', lrp_scheduler_dn)\nprint('\\nModel: ResNeXt50')\nloss_train_rnx, loss_test_rnx = batch_gd(model_rnx, criterion_rnx, optimizer_rnx, train_loader_v1, test_loader_v1, EPOCHS, 4, 'rnx_dict.pth', lrp_scheduler_rnx)","9b76e563":"print('\\nModel: Vision Transformer - ViT')\nloss_train_vit, loss_test_vit = batch_gd(model_vit, criterion_vit, optimizer_vit, train_loader_vit, test_loader_vit, EPOCHS, 1, 'vit_dict.pth', lrp_scheduler_vit, mls_scheduler_vit)","d8620fef":"print('\\nModel: Ensemble Adverserial Inception-Resnet-V2')\nloss_train_eairv, loss_test_eairv = batch_gd(model_eairv, criterion_eairv, optimizer_eairv, train_loader_eairv, test_loader_eairv, EPOCHS, 3, 'eairv_dict.pth', lrp_scheduler_eairv)","125c8cf8":"#predictions for each model (pred_hard, pred_soft)\nvgg19_bn_hard, vgg19_bn_soft = predictions_df(model_vgg, test_loader_v1, transform_test_v1)\nvit_hard, vit_soft = predictions_df(model_vit, test_loader_vit, transform_vit)\ndensenet201_hard, densenet201_soft = predictions_df(model_dn, test_loader_v1, transform_test_v1)\nensemble_adv_incres_v2_hard, ensemble_adv_incres_v2_soft = predictions_df(model_eairv, test_loader_eairv, transform_eairv)\nresnext50_hard, resnext50_soft = predictions_df(model_rnx, test_loader_v1, transform_test_v1)\ntrue_labels = []\n#getting true labels\nfor _, labels in test_loader_v1:\n    for x in range(len(labels)):\n        true_labels.append(labels[x].item())","eac61823":"def plot_model_accuracies():\n    scores = []\n    model_acc = {'vgg19BN':vgg19_bn_hard, 'ViT':vit_hard, 'DenseNet201':densenet201_hard,\n                 'EAInceptionResNetV2':ensemble_adv_incres_v2_hard, 'ResNeXt50':resnext50_hard}\n    for model_pred in model_acc.values():\n        scores.append((accuracy_score(true_labels, model_pred))*100)\n    sns.set_theme(style=\"whitegrid\")\n    sns.set(rc={'figure.figsize':(12,6)})\n    ax = sns.barplot(y=list(model_acc.keys()), x=scores, palette=\"Blues_d\", orient='h')\n    ax.xaxis.set_major_locator(ticker.MultipleLocator(5))\n    ax.xaxis.set_major_formatter(ticker.ScalarFormatter())\n\nplot_model_accuracies()","1bdcbcb4":"def plot_multi_model_losses():\n    model_acc = {'vgg19BN':[loss_train_vgg, loss_test_vgg], 'ViT':[loss_train_vit, loss_test_vit],\n                 'DenseNet201':[loss_train_dn, loss_test_dn], 'EAInceptionResNetV2':[loss_train_eairv, loss_test_eairv],\n                 'ResNeXt50':[loss_train_rnx, loss_test_rnx]}\n    sns.set()\n    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n    fig.suptitle('Training and Testing losses')\n    idx = 0\n    for x in range(2):\n        for y in range(3):\n            if idx < 5:\n                sns.lineplot(ax=axes[x, y], x=range(1,10), y=model_acc[list(model_acc.keys())[idx]][0])\n                sns.lineplot(ax=axes[x, y], x=range(1,10),\n                             y=model_acc[list(model_acc.keys())[idx]][1]).set_title(list(model_acc.keys())[idx])\n            idx += 1\n    fig.delaxes(ax = axes[1,2])\n            \n            \nplot_multi_model_losses()","b7097852":"def plot_confusion_matrix(preds, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    #getting the standard confusion matrix in text form\n    cm = confusion_matrix(np.asarray(true_labels), np.asarray(preds))\n    #using the matrix generated as means to plot a confusion matrix graphically\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    #print(cm)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","93ffc86d":"plot_confusion_matrix(vgg19_bn_hard, CLASSES)","b29d6bb6":"plot_confusion_matrix(vit_hard, CLASSES)","193aca7f":"plot_confusion_matrix(densenet201_hard, CLASSES)","bd209b93":"plot_confusion_matrix(ensemble_adv_incres_v2_hard, CLASSES)","4c481be6":"plot_confusion_matrix(resnext50_hard, CLASSES)","38234450":"df_hard_voting = pd.DataFrame.from_dict({'vgg19_bn':vgg19_bn_hard, 'vit':vit_hard,\n                    'densenet201':densenet201_hard, 'en_adv_incresv2':ensemble_adv_incres_v2_hard,\n                    'resnext50':resnext50_hard})","cf912338":"df_soft_voting = pd.DataFrame.from_dict({'vgg19_bn_soft':vgg19_bn_soft, 'vit_soft':vit_soft,\n                    'densenet201_soft':densenet201_soft, 'en_adv_incresv2_soft':ensemble_adv_incres_v2_soft,\n                    'resnext50_soft':resnext50_soft})","f286cb09":"ensemble_hard_predictions = np.asarray(df_hard_voting.mode(axis=1)[0])\nensemble_hard_score = accuracy_score(np.asarray(true_labels), ensemble_hard_predictions)\nprint(f\"The Accuracy Score of Hard Voting Ensemble is:  {(ensemble_hard_score*100):.4f} %\")","9ea6800b":"plot_confusion_matrix(ensemble_hard_predictions, CLASSES, cmap=plt.cm.RdPu)","d14dccad":"def get_soft_voting():\n    preds = []\n    for x in range(len(df_soft_voting)):\n        sample = (0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n        for y in range(len(df_soft_voting.columns)):\n            sample = tuple(map(operator.add, sample, (tuple(df_soft_voting.iloc[x,y]))))\n        sample = tuple(ti\/len(sample) for ti in sample)\n        element = max(sample)\n        idx = sample.index(element)\n        preds.append(idx)\n    return preds\n\nensemble_soft_preds = get_soft_voting()\nensemble_soft_score = accuracy_score(np.asarray(true_labels), np.asarray(ensemble_soft_preds))\nprint(f\"The Accuracy Score of Hard Voting Ensemble is:  {(ensemble_soft_score*100):.4f} %\")","22f4a41c":"plot_confusion_matrix(ensemble_soft_preds, CLASSES, cmap=plt.cm.RdPu)","0c383db5":"def get_weighted_average():\n    preds = []\n    weights = [0.2315, 0.973, 0.221, 0.189, 0.123]\n    for x in range(len(df_soft_voting)):\n        sample = (0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n        for y in range(len(df_soft_voting.columns)):\n            ##\n            k = tuple(float(weights[y]) * element for element in (tuple(df_soft_voting.iloc[x,y])))\n            ##\n            sample = tuple(map(operator.add, sample, k))\n        sample = tuple(ti\/len(sample) for ti in sample)\n        element = max(sample)\n        idx = sample.index(element)\n        preds.append(idx)\n    return preds\n\nweighted_soft_preds = get_weighted_average()\nweighted_soft_score = accuracy_score(np.asarray(true_labels), np.asarray(weighted_soft_preds))\nprint(f\"The Accuracy Score of Hard Voting Ensemble is:  {(weighted_soft_score*100):.4f} %\")","d2c3df32":"plot_confusion_matrix(weighted_soft_preds, CLASSES, cmap=plt.cm.RdPu)","1efd9ec8":"def plot_final_accuracies():\n    scores = []\n    model_acc = {'vgg19BN':vgg19_bn_hard, 'ViT':vit_hard, 'DenseNet201':densenet201_hard,\n                 'EAInceptionResNetV2':ensemble_adv_incres_v2_hard, 'ResNeXt50':resnext50_hard,\n                 'ensemble-HV':ensemble_hard_predictions, 'ensemble-SV':ensemble_soft_preds,\n                 'ensemble-WSV':weighted_soft_preds}\n    for model_pred in model_acc.values():\n        scores.append((accuracy_score(true_labels, model_pred))*100)\n    sns.set_theme(style=\"whitegrid\")\n    sns.set(rc={'figure.figsize':(14,7)})\n    ax = sns.barplot(y=list(model_acc.keys()), x=scores, palette=\"magma\", orient='h')\n    ax.xaxis.set_major_locator(ticker.MultipleLocator(5))\n    ax.xaxis.set_major_formatter(ticker.ScalarFormatter())\n\nplot_final_accuracies()","bb79c727":"# Plotting Losses and Accuracies","97c617d0":"# Soft-Voting (Equal Weights) ","20fd121b":"Confusion Matrix: Vision Transformer (ViT)","3440515b":"# Predictions","485fdf9b":"This approach is prefered due it being considered as a more \"information based\" method. This does take into account multiple probabilities associated with each image by each classifier, the probabilities of each image are averaged and highest average is considered to be the classification result.","943538e0":"Confusion Matrix: ensemble adverserial Inception ResNet V2","555b5e65":"*Training the remaining two classifiers*","123d42bb":"Confusion Matrix: densenet201","fae66ef8":"Plotting losses","841f7573":"![1_ptGydg-rxqLVD_mQxQzKlg.png](attachment:15ab1af7-3aa8-4d48-9c78-7c413cbf0bc5.png)","317ca334":"# Soft-Voting (Unequal Weights)","4f5ace4b":"***Function to freeze layers.***","5df61559":"Predictions for each model are returned. The predictions returned are classified in terms of hard and soft (list), the hard predictions are returned as predicted classification labels, whereas, the soft predictions for each model are the probabilities of labels associated with each image. The ground truth for all those images is also collected.  ","9b4f1589":"This is most likely the case in this example since the accuracy of \"ViT\" is 94.833%, whereas Hard-voting ensemble has reduced the accuracy to 93.633%. Another approach would be to consider the probabilities as additional information.","e8349d72":"Confusion Matrix: ResNeXt50","d4cff4d9":"# Hard-Voting (Majority Voting)","eca3c325":"*Training the first three models*","6587f4d4":"Plotting individual confusion matrices of the models.","de5bc237":"# Loading Data","23b3008b":"# Confusion Matrix Plot","7841939b":"Another alternative but better approach would be to issue weights based on the model itself. The weights would signify the priority assigned to that model. For example, a model with better prediction score (accuracy) would be assigned a greater weight than the ones with less accuracy. This notebook was based on trial and error with random values based on the individual model's accuracy.","bec98274":"# Training","13616e57":"The following function returns predictions based on our two methods of Hard Voting and Soft Voting. class predictions are returned in case of hard voting, whereas, in the case of soft voting, probabilities of individual classes are returned.","12f09f78":"***Function to return loss, optimizer and schedulers based on the model.***","4312f142":"Function to plot confusion matrix of a model","68580abd":"# Tweaking Models","cbfc48e7":"# Voting Data","41e80355":"Hard-voting is not considered to be a very reliable method due it being reliant only on classification results of the majority. If the majority is wrong this could lead to less accurate results.","6933835f":"These transformations are applied to the following models:\n* VGG-19 with BatchNormalization\n* DenseNet201 classifier\n* ResNeXt50 classifier","9d2217e4":"***Saving the models for further work if need be.***","3fb9bd14":"***Function to return classifiers. The replacements are done based on best practices and previous experiments that have been generally known to exhibit good results.***","be9468d0":"The notebook contains ensembling methods particularly related to voting techniques:\n* Hard Voting\n* Soft Voting\n* Weighted Average Voting\n\nHard voting involves summing the predictions for each class label and predicting the class label with the most votes. Soft voting involves summing the predicted probabilities (or probability-like scores) for each class label and predicting the class label with the largest probability.\n\nThe voting ensemble is not guaranteed to provide better performance than any single model used in the ensemble. particularly so if multiple classifiers make predictions that are incorrect, therefore, the predictions of the model with greater accuracy will be neglected among the other models. If any of the classifiers in the ensemble perform better than the ensemble, then that model should be used instead of the ensemble.","1d811d86":"# **Imports**","e04c9d10":"As one would expect, this Ensemble Technique has achieved the highest accuracy among individual models and other ensemble approaches. This notebook does not discuss the detailed relationships between bias and variance of models, and is purely focussed on achieving accuracy. Furthermore, advanced ensemble techniques are a topic for another day.","f1526b51":"These transformations are model specific imported from timm:\n* Vision Transformer (ViT)\n* Ensemble Adversarial Inception-ResNet v2","21c8cd8a":"As it is clear that in the same case, soft and hard voting can lead to different decisions. Soft voting can improve on hard voting because it takes into account more information; Using each classifiers certainty and uncertainty in the final decision.","cd72f432":"# Function to return predictions","036681c5":"**Happy Coding \ud83d\ude04**","c5656aef":"Confusion Matrix: VGG 19 BatchNormalization","49790414":"# Transformations and Augmentations","bf001bb6":"Plotting accuracies","f1cc8949":"# Defining Models"}}