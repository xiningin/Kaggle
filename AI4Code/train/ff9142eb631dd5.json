{"cell_type":{"d9a8981d":"code","1f7b1450":"code","b737f380":"code","c5fe03bb":"code","0b0bfd79":"code","a0d1565e":"code","ece85f7e":"code","447923be":"code","e71c0f2e":"code","f8104d74":"markdown","e1ae4770":"markdown","7aaf5ad8":"markdown","c9681598":"markdown","506dafac":"markdown","5908319b":"markdown"},"source":{"d9a8981d":"import sys\n!cp ..\/input\/rapids\/rapids.0.12.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path \n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","1f7b1450":"!git clone https:\/\/github.com\/aerdem4\/rapids-kaggle-utils.git\n%cd rapids-kaggle-utils\/","b737f380":"!pip install lofo-importance","c5fe03bb":"!pip install -U xgboost","0b0bfd79":"import numpy as np \nimport pandas as pd\nfrom sklearn import *\nimport lightgbm as lgb\nimport cudf\n\ntrain = cudf.read_csv('\/kaggle\/input\/liverpool-ion-switching\/train.csv')","a0d1565e":"# rapids-kaggle-utils\nfrom cu_utils.transform import cu_min_transform, cu_max_transform, cu_mean_transform\n\n\nCU_FUNC = {\"min\": cu_min_transform, \"max\": cu_max_transform, \"mean\": cu_mean_transform}","ece85f7e":"%%time\n\n\ndef features(df):\n    df = df.sort_values(by=['time']).reset_index(drop=True)\n    df[\"index\"] = (df[\"time\"] * 10_000) - 1\n    df['batch'] = df[\"index\"] \/\/ 50_000\n    df['batch_index'] = df[\"index\"]  - (df[\"batch\"] * 50_000)\n    df['batch_slices'] = df['batch_index']  \/\/ 5_000\n    df['batch_slices2'] = df['batch'].astype(str) + \"_\" + df['batch_slices'].astype(str)\n    \n    for c in ['batch','batch_slices2']:\n\n        df[\"abs_signal\"] = df[\"signal\"].abs()\n        for abs_val in [True, False]:\n            for func in [\"min\", \"max\", \"mean\"]:\n                output_col = func + c\n                input_col = \"signal\"\n                if abs_val:\n                    output_col = \"abs_\" + output_col\n                    input_col = \"abs_\" + input_col\n                df = df.groupby([c], method='cudf').apply_grouped(CU_FUNC[func],\n                                                                  incols={input_col: 'x'},\n                                                                  outcols=dict(y_out=np.float32),\n                                                                  tpb=32).rename({'y_out': output_col})\n        \n        df['range'+c] = df['max'+c] - df['min'+c]\n        df['maxtomin'+c] = df['max'+c] \/ df['min'+c]\n        df['abs_avg'+c] = (df['abs_min'+c] + df['abs_max'+c]) \/ 2\n\n    for c in [c1 for c1 in df.columns if c1 not in ['time', 'signal', 'open_channels', 'batch', 'batch_index', 'batch_slices', 'batch_slices2']]:\n        df[c+'_msignal'] = df[c] - df['signal']\n        \n    return df\n\ntrain = features(train)\ntrain.shape","447923be":"from lofo import LOFOImportance, Dataset, plot_importance\nfrom sklearn.model_selection import KFold\nimport xgboost\n\n# Convert to pandas for now. Xgboost supports cudf but LOFO doesn't support yet\nsample_df = train.to_pandas().sample(frac=0.1, random_state=0)\nsample_df.sort_values(\"time\", inplace=True)\n\n# define the validation scheme\ncv = KFold(n_splits=5, shuffle=False, random_state=0)\n\n# define the binary target and the features\nfeatures = [c for c in train.columns if c not in ['time', 'open_channels', 'batch', 'batch_index', 'batch_slices', 'batch_slices2']]\ndataset = Dataset(df=sample_df, target=\"open_channels\", features=features)\n\n# define the validation scheme and scorer\nparams ={'learning_rate': 0.8, 'max_depth': 4, \"n_estimators \": 100, \"tree_method\": 'gpu_hist', \"gpu_id\": 0}\nxgb_reg = xgboost.XGBRegressor(**params)\nlofo_imp = LOFOImportance(dataset, cv=cv, scoring=\"neg_mean_squared_error\", model=xgb_reg)\n\n# get the mean and standard deviation of the importances in pandas format\nimportance_df = lofo_imp.get_importance()","e71c0f2e":"plot_importance(importance_df, figsize=(12, 20))","f8104d74":"## Get the current best features and model from:\n\nhttps:\/\/www.kaggle.com\/jazivxt\/physically-possible","e1ae4770":"## Get rapids-kaggle-utils","7aaf5ad8":"## Install RAPIDS for faster feature engineering on GPU\nhttps:\/\/www.kaggle.com\/cdeotte\/rapids","c9681598":"## Install the latest Xgboost for GPU acceleration\n#### 2 times faster than Lightgbm on CPU (4 cores)","506dafac":"## Install LOFO","5908319b":"## Get Feature Importances on Time Split Mean Squared Error"}}