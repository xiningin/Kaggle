{"cell_type":{"5afc69e6":"code","459e2a9d":"code","9702dd57":"code","1f3bc39c":"code","6278cca4":"code","4e77d89a":"code","47de1893":"code","91290f87":"code","f6607de2":"code","9db409ac":"code","209d9558":"code","13a5dd7f":"code","682bc9ab":"code","24b38ec8":"code","39631f36":"code","78e400c1":"code","85116b2b":"code","62785b81":"code","14fedaad":"code","6fa0ef3f":"code","abbeea57":"code","e154ded6":"code","1e28fa86":"code","f4db8c4c":"code","842cea3f":"code","7dfa4374":"code","b38ded3f":"code","95fe4ddc":"code","02b44b79":"code","bf98120b":"code","b00942db":"code","bffc7616":"code","eca3c3ac":"code","7b228572":"code","3ebef778":"code","510da71e":"code","943be1bb":"code","8663d9cb":"code","4f2dc7b0":"code","21a0ef89":"code","89dbe5d9":"code","de4cc8a1":"code","10b5283c":"code","51fac9eb":"code","4e7aba39":"code","40b3425d":"code","d611dc0c":"code","4c0f98c1":"code","5cfbde8d":"code","ed6474fa":"code","f1177575":"code","91869287":"code","465bf1bf":"code","50c4593f":"code","bd3a8086":"code","ba7e783c":"code","ae58aec6":"code","d128cde2":"code","0bad94cb":"code","de79ffc1":"code","9f3b3f2d":"markdown","b40535c6":"markdown","27f3cf8e":"markdown","e9ccf878":"markdown","739f551a":"markdown","cd2764ac":"markdown","00dc2f66":"markdown"},"source":{"5afc69e6":"!cp ..\/input\/gdcm-conda-install\/gdcm.tar .\n!tar -xvzf gdcm.tar\n!conda install --offline .\/gdcm\/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2","459e2a9d":"import pandas as pd \ndf = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\nif df.shape[0] == 2477:\n    fast_sub = True\n    df.to_csv('submission.csv', index=False)\nelse:\n    fast_sub = False","9702dd57":"import os\n\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data\n\ndef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https:\/\/www.kaggle.com\/xhlulu\/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im\n\nimage_id = []\nstudy_id = []\ndim0 = []\ndim1 = []\nsplit = 'test'\nsave_dir = f'\/kaggle\/tmp\/{split}\/image\/'\nos.makedirs(save_dir, exist_ok=True)\n\nfor dirname, _, filenames in tqdm(os.walk(f'..\/input\/siim-covid19-detection\/{split}')):\n    for file in filenames:\n        # set keep_ratio=True to have original aspect ratio\n        xray = read_xray(os.path.join(dirname, file))\n        im = resize(xray, size=512)  \n        im.save(os.path.join(save_dir, file.replace('.dcm', '.png')))\n        image_id.append(file.replace('.dcm', ''))\n        study_id.append(dirname.split('\/')[-2])\n        dim0.append(xray.shape[0])\n        dim1.append(xray.shape[1])\n        \n        if len(dim0) >10 and fast_sub:\n            break\n    if len(dim0) >10 and fast_sub:\n            break\nmeta = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'study_id': study_id})","1f3bc39c":"meta.to_csv('test_meta.csv', index=False)","6278cca4":"!mkdir det_txt\n!mkdir det\n! pip install ..\/input\/siim-libs\/addict-2.4.0-py3-none-any.whl >> \/dev\/null\n! pip install ..\/input\/siim-libs\/timm-0.4.12-py3-none-any.whl >> \/dev\/null\n! pip install ..\/input\/siim-libs\/ensemble_boxes-1.0.6-py3-none-any.whl >> \/dev\/null\n! pip install ..\/input\/siim-libs\/loguru-0.5.3-py3-none-any.whl >> \/dev\/null\n! pip install ..\/input\/siim-libs\/thop-0.0.31.post2005241907-py3-none-any.whl >> \/dev\/null\n! pip install ..\/input\/pycocotools\/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl >> \/dev\/null\n! pip install ..\/input\/omegaconf\/omegaconf-2.0.5-py3-none-any.whl >> \/dev\/null","4e77d89a":"!cp -r ..\/input\/siim-v5-mh\/* .","47de1893":"!python inference.py --is_val 0 --output_path det_txt\/ --input_path '\/kaggle\/tmp\/test\/image\/*png' --weight_path '\/kaggle\/input\/siim-v5-weights\/*\/*\/*\/best.pt'","91290f87":"!cp -r ..\/input\/yolox-inference\/* .","f6607de2":"!python inference.py -f ..\/input\/yolox-weights\/yolox_weights\/yolox_siim_d_f0.py -c ss --path '\/kaggle\/tmp\/test\/image\/*png' \\\n    --wei_dir ..\/input\/yolox-weights\/yolox_weights\/ --conf 0.0001 --nms 0.5 --tsize 384 --save_result --device gpu","9db409ac":"!cp -r ..\/input\/siimeffdet\/* .","209d9558":"!python predict_oof_det.py --is_val 0 --test_path '\/kaggle\/tmp\/test\/image\/*png' --model_dir ..\/input\/siim-det-models\/","13a5dd7f":"! cp det\/* det_txt","682bc9ab":"! python ensemble1.py --input_path  'det_txt\/*txt' --image_path '\/kaggle\/tmp\/test\/image\/*png' --thr 0.001","24b38ec8":"#mask_dir = f'\/kaggle\/tmp\/{split}\/mask\/'\n#os.makedirs(mask_dir, exist_ok=True)","39631f36":"#!cp -r ..\/input\/siimsegs\/* .","78e400c1":"#!python train_seg.py --image_path '\/kaggle\/tmp\/test\/image\/*png' --weight_path best_loss.pth","85116b2b":"!cp -r ..\/input\/siim-cls-code\/* .","62785b81":"!python main.py -C n_cf11_6 -M test -W ..\/input\/siim-cls-weights\/n_cf11_6_f3\/","14fedaad":"!python main.py -C n_cf11 -M test -W ..\/input\/siim-cls-weights\/n_cf11_l1\/","6fa0ef3f":"!python main.py -C n_cf11_7 -M test -W ..\/input\/siim-cls-weights\/n_cf11_7\/","abbeea57":"#!python main.py -C n_cf11_8 -M test -W ..\/input\/siim-cls-weights\/n_cf11_8\/","e154ded6":"!python main.py -C n_cf11_9 -M test -W ..\/input\/siim-cls-weights\/n_cf11_9\/","1e28fa86":"!python main.py -C n_cf11_10 -M test -W ..\/input\/siim-cls-weights\/n_cf11_10\/","f4db8c4c":"!python main.py -C n_cf11_1 -M test -W ..\/input\/siim-cls-weights\/n_cf_11_1\/","842cea3f":"!python main.py -C n_cf11_rot1 -M test -W ..\/input\/siim-cls-weights\/n_cf11_rot1\/","7dfa4374":"!pip install -q ..\/input\/landmark-additional-packages\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master \n!pip install -U ..\/input\/landmark-additional-packages\/timm-0.4.12-py3-none-any.whl # to fix \n!pip install ..\/input\/siim-libs\/segmentation_models_pytorch-0.1.3-py3-none-any.whl --no-deps  ","b38ded3f":"import sys\nsys.path.append('..\/usr\/lib\/siim_cov_model_v0\/')\nfrom siim_cov_model_v0 import *","95fe4ddc":"import numpy as np\nimport pandas as pd\nimport tqdm\nimport cv2\nimport glob\nimport math\nimport csv\nimport torch\nimport operator\nimport sys\nimport os\nfrom path import Path\nfrom skimage.io import imread\nfrom scipy.ndimage.interpolation import zoom\nimport matplotlib.pyplot as plt\nfrom skimage.transform import resize\nimport torchvision\nfrom scipy.stats import rankdata\n\nfrom torchvision.transforms import (\n    ToTensor, Normalize, Compose, Resize, CenterCrop, RandomCrop,\n    RandomHorizontalFlip, RandomAffine, RandomVerticalFlip, RandomChoice, ColorJitter, RandomRotation)\n\nsys.path.append('..\/input\/siim-covid-aggron-eecf6c\/covid19-aggron')\n\n# from utils import parse_args, prepare_for_result\n# from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n# from models import get_model\nfrom losses import get_loss, get_class_balanced_weighted\n# from dataloaders import get_dataloader\n# from utils import load_matched_state\nfrom configs import Config\n# import seaborn as sns\n# from dataloaders.transform_loader import get_tfms\n\nfrom sklearn.metrics import f1_score, roc_auc_score, average_precision_score","02b44b79":"test_path = '\/kaggle\/tmp\/test\/image\/'","bf98120b":"class COVIDDataset(torch.utils.data.Dataset):\n    def __init__(self, df, cfg=None, tfms=None, path='.'):\n        self.df = df\n        self.cfg = cfg\n        self.tfms = tfms\n        self.tensor_tfms = torchvision.transforms.Compose([\n            torchvision.transforms.ToTensor(),\n            torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            # torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n        self.path = '.\/'\n        # self.path = Path('\/home\/sheep\/kaggle\/siim')\n        self.studys = self.df['StudyInstanceUID'].unique()\n        print(len(self.studys))\n        self.cols = ['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\n        self.cols2index = {x: i for i, x in enumerate(self.cols)}\n        self.path = path\n\n    def __len__(self):\n        return len(self.studys)\n\n    def __getitem__(self, idx):\n        study_id = self.studys[idx]\n        sub_df = self.df[self.df.StudyInstanceUID == study_id].copy()\n        images = []\n        masks = []\n        study = [idx for _ in range(sub_df.shape[0])]\n        image_as_study = []\n        bbox = []\n        label_study = 0\n        has_masks = []\n        iids = []\n        for i, row in sub_df.iterrows():\n            img = cv2.imread(str(self.path + f'\/{row.ImageUID}.png'))\n            sz = self.cfg.transform.size\n            mask = np.zeros((sz, sz))\n            has_mask = 1\n            has_masks.append(has_mask)\n            label = 0\n            if self.tfms:\n                tf = self.tfms(image=img, mask=mask)\n                img = tf['image']\n                mask = tf['mask']\n            if not img.shape[0] == self.cfg.transform.size:\n                img = cv2.resize(img, (self.cfg.transform.size, self.cfg.transform.size))\n            # resize to aux\n            if self.cfg.transform.size == 512:\n                msksz = 32\n            elif self.cfg.transform.size == 384:\n                msksz = 24\n            elif self.cfg.transform.size == 640:\n                msksz = 40\n            elif self.cfg.transform.size == 700:\n                msksz = 44\n            elif self.cfg.transform.size == 720:\n                msksz = 45\n            elif self.cfg.transform.size == 768:\n                msksz = 48\n            else:\n                msksz = 32\n            mask = cv2.resize(mask, (msksz, msksz))\n            masks.append(torch.FloatTensor(mask).view(1, mask.shape[0], mask.shape[1]))\n            img = self.tensor_tfms(img)\n            images.append(img)\n            image_as_study.append(label)\n            iids.append(row.ImageUID)\n        images = torch.stack(images)\n        masks = torch.stack(masks)\n        return images, study, label_study, image_as_study, masks, iids\n    \ndef idoit_collect_func(batch):\n    img, study, lbl, image_as_study, bbox, has_masks = [], [], [], [], [], []\n    for im, st, lb, ias, bb, has_m in batch:\n        img.extend(im)\n        study.extend(st)\n        lbl.append(lb)\n        image_as_study.extend(ias)\n        bbox.extend(bb)\n        has_masks.extend(has_m)\n    return torch.stack(img), study, torch.tensor(lbl), torch.tensor(image_as_study), torch.stack(bbox), has_masks","b00942db":"def load_model(cfg):\n    if cfg.model.name == 'v2m_aux':\n        #     def __init__(self, name, dropout=0, pool='AdaptiveAvgPool2d'):\n        drop = cfg.model.param.get('dropout', 0)\n        pool = cfg.model.param.get('last_pool', 'AdaptiveAvgPool2d')\n        return AUXNet(name='tf_efficientnetv2_m', dropout=drop, pool=pool)\n    elif cfg.model.name == 'v2m_aux_v2':\n        drop = cfg.model.param.get('dropout', 0)\n        pool = cfg.model.param.get('last_pool', 'AdaptiveAvgPool2d')\n        return AUXNetV2(name='tf_efficientnetv2_m', dropout=drop, pool=pool)\n    elif cfg.model.name == 'b5_aux':\n        drop = cfg.model.param.get('dropout', 0)\n        pool = cfg.model.param.get('last_pool', 'AdaptiveAvgPool2d')\n        return AUXNetb5(name='tf_efficientnetv2_m', dropout=drop)\n    elif cfg.model.name == 'v2l_aux':\n        drop = cfg.model.param.get('dropout', 0)\n        pool = cfg.model.param.get('last_pool', 'AdaptiveAvgPool2d')\n        return AUXNetL(name='tf_efficientnetv2_l', dropout=drop)","bffc7616":"def predict_run(RUN, test, is_none = False):\n    df = pd.read_csv(f'{RUN}\/train.log', sep='\\t')\n    fold2epochs = {}\n    for i in range(0, 5):\n        eph = df[df.Fold == i].sort_values('F1@0.3', ascending=False).iloc[0].Epochs\n        fold2epochs[i] = int(eph)\n\n    print(fold2epochs.values())\n\n    predicted = []\n    # load the model\n    models = []\n    for f in range(5):\n        cfg = Config.load_json(f'{RUN}\/config.json')\n        cfg.experiment.run_fold = f\n        model = load_model(cfg).cuda()\n        load_matched_state(model, torch.load(\n            glob.glob(f'{RUN}\/checkpoints\/f{f}*-{fold2epochs[f]}*')[0]))\n        model.eval()\n        models.append(model)\n        \n    # inference\n    test_ds = COVIDDataset(test, cfg=cfg, path=test_path)\n    test_dl = torch.utils.data.DataLoader(test_ds, num_workers=2, batch_size=32, collate_fn=idoit_collect_func)\n    with torch.no_grad():\n        results = []\n        predicted, image_ids = [], []\n        for i, (img, study_index, lbl_study, label_image, mask_t, iids) in tqdm.tqdm(enumerate(test_dl)):\n            img = img.cuda()\n            sz = img.size()[0]\n            img = torch.stack([img,img.flip(-1)],0) # hflip\n            img = img.view(-1, 3, img.shape[-1], img.shape[-1])\n            preds = []\n            for m in models:\n                with torch.cuda.amp.autocast():\n                    logits, mask = m(img)\n                logits = logits.float()\n                if cfg.loss.name == 'bce':\n                    logits = torch.sigmoid(logits)\n                else:\n                    logits = torch.softmax(logits, 1)\n                cls = (logits[:sz] + logits[sz:]) \/ 2\n                preds.append(cls)\n            predicted.append(torch.stack(preds).mean(0).cpu())\n            image_ids.extend(iids)\n    if is_none:\n        return pd.DataFrame(torch.cat(predicted).numpy(), index=image_ids,\n             columns=['Negative for Pneumonia', 'Typical Appearance'])\n    else:\n        return pd.DataFrame(torch.cat(predicted).numpy(), index=image_ids,\n             columns=['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance'])","eca3c3ac":"test = pd.read_csv('test_meta.csv')[[\"image_id\", \"study_id\"]]\ntest = test.rename(columns={\"image_id\": \"ImageUID\", \"study_id\": \"StudyInstanceUID\"})\nfor e in ['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']:\n    test[e] = 0","7b228572":"test.head()","3ebef778":"r9 = predict_run(\n    '..\/input\/siim-covid-aux-bce-agg-exp-rot-30-20-v2l-pl\/aux_bce_agg_exp_rot_30_20_v2l_pl.upload', test)","510da71e":"r8 = predict_run(\n    '..\/input\/aux-bce-agg-exp-rot-30-20-b5-pl\/aux_bce_agg_exp_rot_30_20_b5_pl.upload', test)","943be1bb":"r = predict_run(\n    '..\/input\/siim-covid-aux-aug-v2m-lm-aggron-40-clean-cut1\/aux_aug_v2m_lm_aggron_40_clean_cut1.yaml_upload', test)","8663d9cb":"r3 = predict_run(\n    '..\/input\/siim-covid-aux-bce-agg-exp-rot-30-20-pl\/aux_bce_agg_exp_rot_30_20_pl.upload', test)","4f2dc7b0":"r2 = predict_run(\n    '..\/input\/siim-covid-aux-bce-v2m-lm-aggron-40-clean-cut1-pl\/aux_bce_v2m_lm_aggron_40_clean_cut1_bce_pl.upload', test)","21a0ef89":"r4 = predict_run(\n    '..\/input\/siim-cov-dddddd-dbg-1-aux-2\/dddddd_dbg_1_aux_2_upload', test)","89dbe5d9":"r5 = predict_run(\n    '..\/input\/siim-cov-clean-oof-clean-agree-upload\/clean_oof_clean_agree_upload', test)","de4cc8a1":"r6 = predict_run(\n    '..\/input\/siim-cov-aux-aug-agg-exp-rot-30\/aux_aug_agg_exp_rot_30.yaml_upload', test)","10b5283c":"r7 = predict_run(\n    '..\/input\/siim-cov-model-modelv2upload\/model_modelV2.upload', test)","51fac9eb":"image_result = (r + r2 + r3 + 0.5 * r4 + r5 + r6 + 0.75 * r7 + r8 + r9) \/ 8.25","4e7aba39":"image_result = image_result.reset_index()","40b3425d":"image_result.to_csv('sheep_df.csv')","d611dc0c":"class AUXNet(nn.Module):\n    def __init__(self, name, dropout=0, pool='AdaptiveAvgPool2d'):\n        super(AUXNet, self).__init__()\n\n        print('[ AUX model ] dropout: {}, pool: {}'.format(dropout, pool))\n        e = timm.models.__dict__[name](pretrained=False, drop_rate=0.3, drop_path_rate=0.2)\n        self.model = e\n        self.b0 = nn.Sequential(\n            e.conv_stem,\n            e.bn1,\n            e.act1,\n        )\n        self.b1 = e.blocks[0]\n        self.b2 = e.blocks[1]\n        self.b3 = e.blocks[2]\n        self.b4 = e.blocks[3]\n        self.b5 = e.blocks[4]\n        self.b6 = e.blocks[5]\n        self.b7 = e.blocks[6]\n        self.b8 = nn.Sequential(\n            e.conv_head, #384, 1536\n            e.bn2,\n            e.act2,\n        )\n\n        self.logit = nn.Linear(1280,2)\n        self.mask = nn.Sequential(\n            nn.Conv2d(176, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 1, kernel_size=1, padding=0),\n        )\n\n        self.dropout = nn.Dropout(p=dropout)\n\n        if pool == 'AdaptiveAvgPool2d':\n            self.pooling = nn.AdaptiveAvgPool2d(1)\n        elif pool == 'gem':\n            self.pooling = GeM()\n\n    # @torch.cuda.amp.autocast()\n    def forward(self, image):\n        batch_size = len(image)\n        # x = 2*image-1     # ; print('input ',   x.shape)\n        x = image\n\n        x = self.b0(x) #; print (x.shape)  # torch.Size([2, 40, 256, 256])\n        x = self.b1(x) #; print (x.shape)  # torch.Size([2, 24, 256, 256])\n        x = self.b2(x) #; print (x.shape)  # torch.Size([2, 32, 128, 128])\n        x = self.b3(x) #; print (x.shape)  # torch.Size([2, 48, 64, 64])\n        x = self.b4(x) #; print (x.shape)  # torch.Size([2, 96, 32, 32])\n        x = self.b5(x) #; print (x.shape)  # torch.Size([2, 136, 32, 32])\n        #------------\n        mask = self.mask(x)\n        #-------------\n        x = self.b6(x) #; print (x.shape)  # torch.Size([2, 232, 16, 16])\n        x = self.b7(x) #; print (x.shape)  # torch.Size([2, 384, 16, 16])\n        x = self.b8(x) #; print (x.shape)  # torch.Size([2, 1536, 16, 16])\n        # x = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n        x = nn.Flatten()(self.pooling(x))\n        x = self.dropout(x)\n        logit = self.logit(x)\n        return logit, mask","4c0f98c1":"none_1 = predict_run(\n    '..\/input\/two-class-bce-fix-valid-bbox-two-classes-12-pl-2x\/two_class_bce_fix_valid_bbox_two_classes_12_pl_2x.upload', test, True)","5cfbde8d":"none_2 = predict_run(\n    '..\/input\/two-class-bce-fix-valid-bbox-two-classes-12upload\/two_class_bce_fix_valid_bbox_two_classes_12.upload', test, True)","ed6474fa":"none_result = (none_1 + none_2) \/ 2","f1177575":"none_result.to_csv('public_test_sheep_predict_none.csv')","91869287":"! python tocsv.py --input_path  'test_v5neg_2a.txt' --meta_path 'test_meta.csv'","465bf1bf":"def prob2str(row):\n    return f'negative {row.pred_cls1:.6f} 0 0 1 1 typical {row.pred_cls2:.6f} 0 0 1 1 indeterminate {row.pred_cls3:.6f} 0 0 1 1 atypical {row.pred_cls4:.6f} 0 0 1 1'\n    #return f''","50c4593f":"def combine_image(row):\n     return f'none {row.pred_cls5:.6f} 0 0 1 1 {row.PredictionString}'\n        #return f''","bd3a8086":"def tosub(df1):\n    df1_image = df1[['image_id', 'pred_cls1', 'pred_cls5', 'PredictionString']].copy()\n    df1_image.rename(columns={\"image_id\": \"id\"}, inplace=True)\n    df1_image['id'] = df1_image['id'].apply(lambda x: f'{x}_image')\n    df1_image['PredictionString'] = df1_image.apply(lambda r: combine_image(r), axis=1) \n    df1_image = df1_image[['id', 'PredictionString']]\n    \n    df1_study = df1[['study_id', 'pred_cls1', 'pred_cls2', 'pred_cls3', 'pred_cls4']].copy()\n    df1_study = df1_study.groupby('study_id').agg('mean').reset_index()\n    df1_study.rename(columns={\"study_id\": \"id\"}, inplace=True)\n    df1_study['id'] = df1_study['id'].apply(lambda x: f'{x}_study')\n    df1_study[\"PredictionString\"] = df1_study.apply(lambda r: prob2str(r), axis=1) \n    df1_study = df1_study[['id', 'PredictionString']]\n\n    df1_sub = pd.concat([df1_study, df1_image])\n\n    return df1_sub","ba7e783c":"df1 = pd.read_csv('n_cf11_9.csv') \ndf2 = pd.read_csv('n_cf11.csv')#.head(10)\ndf3 = pd.read_csv('n_cf11_6.csv')\ndf4 = pd.read_csv('n_cf11_7.csv')\ndf5 = pd.read_csv('n_cf11_10.csv')\ndf6 = pd.read_csv('n_cf11_rot1.csv')\ndf7 = pd.read_csv('n_cf11_1.csv')\n#df8 = pd.read_csv('n_cf11_8.csv')\n\ndf2 = df1[[\"image_id\"]].merge(df2, on=[\"image_id\"])\ndf3 = df1[[\"image_id\"]].merge(df3, on=[\"image_id\"])\ndf4 = df1[[\"image_id\"]].merge(df4, on=[\"image_id\"])\ndf5 = df1[[\"image_id\"]].merge(df5, on=[\"image_id\"])\ndf6 = df1[[\"image_id\"]].merge(df6, on=[\"image_id\"])\ndf7 = df1[[\"image_id\"]].merge(df7, on=[\"image_id\"])\n#df8 = df1[[\"image_id\"]].merge(df8, on=[\"image_id\"])\n\nsheep_df = pd.read_csv('sheep_df.csv')\nsheep_df = sheep_df.rename(columns={\"index\": \"image_id\", \"Negative for Pneumonia\": \"pred_cls1\", \n                         \"Typical Appearance\": \"pred_cls2\", \"Indeterminate Appearance\": \"pred_cls3\",\n                        \"Atypical Appearance\": \"pred_cls4\"})\nsheep_df = df2[[\"image_id\"]].merge(sheep_df, on=[\"image_id\"])\n\nfor col in ['pred_cls1', 'pred_cls2', 'pred_cls3', 'pred_cls4', 'pred_cls5']:\n    df1[col] = (df1[col] + df2[col] + df3[col] + df4[col] + df5[col] + df6[col] + df7[col])\/7\n    \nfor col in ['pred_cls1', 'pred_cls2', 'pred_cls3', 'pred_cls4']:\n    df1[col] = (1*df1[col] + sheep_df[col])\/2\n    \nsheep_none_df = pd.read_csv('public_test_sheep_predict_none.csv')\nsheep_none_df[\"image_id\"] = sheep_none_df['Unnamed: 0']\nsheep_none_df = df1[[\"image_id\"]].merge(sheep_none_df, on=[\"image_id\"])\n\n#df1['pred_cls5'] = sheep_none_df['Negative for Pneumonia']\ndf1['pred_cls5'] = 2*(1-df1['pred_cls5']) + 1*sheep_df['pred_cls1'] + 1*sheep_none_df['Negative for Pneumonia']\n\nimage_sub = pd.read_csv('v5_50.csv')\nimage_sub = df1[[\"image_id\"]].merge(image_sub, on=[\"image_id\"])\ndf1['PredictionString'] = image_sub['PredictionString']\ndf_sub  = tosub(df1)","ae58aec6":"df_sub.tail()","d128cde2":"df_sub.head()","0bad94cb":"!rm -r .\/*","de79ffc1":"df_sub.to_csv('submission.csv', index=False)","9f3b3f2d":"## BCE loss with pl","b40535c6":"**2 class**","27f3cf8e":"## tools and difinition","e9ccf878":"## Uncompress test data","739f551a":"## Model difinition","cd2764ac":"## CE model","00dc2f66":"## Test assets"}}