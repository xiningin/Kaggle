{"cell_type":{"13f9948b":"code","8c4ed376":"code","4b9171a2":"code","6ca32448":"code","825b6963":"code","3396cf87":"code","64b9f4e9":"code","bde80f0a":"code","9a599a7a":"code","57e4bf86":"code","a6d5ace1":"code","eec2cb6d":"code","4e3ac553":"code","f4932794":"code","1c82ebda":"code","472d9ae6":"code","223a8b08":"code","d79691e3":"code","051557b4":"code","b75984b2":"code","cdb54e8e":"code","ddfc4b4c":"code","35ab828b":"code","0ac743c5":"code","ed62c5b8":"code","53c39cb9":"code","99371f0b":"code","82f4770f":"code","4221a336":"code","0e48de31":"code","da1804ef":"code","75c20a06":"code","65e34542":"code","8297b53e":"code","bf818735":"code","85f0b99b":"code","95271eaa":"code","f0ece7db":"code","1835b7af":"code","59c365d4":"code","9c4fd121":"code","5947ab2a":"code","e13da4e4":"code","6d69b80d":"code","90d4d6ad":"code","67318e60":"code","07838541":"code","f2a168e7":"code","6b065a1a":"code","22a10e6a":"markdown","7f63ca44":"markdown","f1e4f49c":"markdown","86ac2ec4":"markdown","483e81f5":"markdown","6affd1a0":"markdown","c56e7323":"markdown","92321a35":"markdown","26da21c2":"markdown","b2ea5167":"markdown","6b9ae5fb":"markdown","a6f4b8f6":"markdown","85175c70":"markdown","df8d5b9c":"markdown","369e9703":"markdown","1d7984b3":"markdown","49e03fdc":"markdown","59d9bcf3":"markdown","8fedc7a2":"markdown","52a28378":"markdown","04ee363f":"markdown","f393c653":"markdown","377bd86d":"markdown","a50ef1da":"markdown","8e9a913f":"markdown","170cf56c":"markdown","1bb8101c":"markdown","61124d9c":"markdown","7717a5c9":"markdown","19600b9d":"markdown","5fbc8be9":"markdown","0acdc89b":"markdown","d0aa1254":"markdown","8355cce6":"markdown","4ca13fdc":"markdown","355c0dce":"markdown","27de491f":"markdown","a61a80a4":"markdown","caf69e38":"markdown","7d3928c9":"markdown","7afdaf54":"markdown","dd3991d4":"markdown"},"source":{"13f9948b":"import numpy as np\nimport pandas as pd\nimport gc \npd.set_option('display.max_columns', 50)\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8c4ed376":"import scipy\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport numpy as np\nimport random\nimport datetime\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom scipy import stats\nfrom sklearn.preprocessing import LabelEncoder","4b9171a2":"# from google.colab import drive\n# drive.mount('\/content\/drive')","6ca32448":"train = pd.read_csv(r\"https:\/\/raw.githubusercontent.com\/shrikantnarayankar15\/Insaid-ML-advanced-project\/master\/train.csv\")\ntest = pd.read_csv(r\"https:\/\/raw.githubusercontent.com\/shrikantnarayankar15\/Insaid-ML-advanced-project\/master\/test.csv\")","825b6963":"challenge = pd.read_csv(r\"https:\/\/raw.githubusercontent.com\/shrikantnarayankar15\/Insaid-ML-advanced-project\/master\/challenge_data.csv\")","3396cf87":"train.info()","64b9f4e9":"test.info()","bde80f0a":"challenge.info()","9a599a7a":"challenge.isnull().sum()","57e4bf86":"challenge.isnull().sum().plot(kind='barh')","a6d5ace1":"challenge.columns","eec2cb6d":"challenge['total_submissions'] = challenge['total_submissions'].fillna(challenge['total_submissions'].mean())","4e3ac553":"categorical_features = ['challenge_series_ID',\n        'author_ID', 'author_gender',\n       'author_org_ID', 'category_id']","f4932794":"challenge[categorical_features] = challenge[categorical_features].apply(lambda x:x.fillna(x.mode()[0]))","1c82ebda":"challenge.isnull().sum()","472d9ae6":"challenge.info()","223a8b08":"challenge['programming_language'].value_counts().plot(kind='bar')","d79691e3":"challenge['challenge_series_ID'].value_counts().nlargest(10).plot(kind='bar')","051557b4":"challenge.groupby('challenge_series_ID')['total_submissions'].sum().nlargest(10)","b75984b2":"challenge.groupby('challenge_series_ID')['total_submissions'].sum().nlargest(10).plot(kind='bar')","cdb54e8e":"challenge['author_ID'].value_counts().nlargest(10).plot(kind='bar')","ddfc4b4c":"challenge['author_ID'].value_counts().nlargest(10)","35ab828b":"challenge['author_gender'].value_counts().plot(kind='bar')","0ac743c5":"challenge['author_org_ID'].value_counts().nlargest(5).plot(kind='bar')","ed62c5b8":"train['challenge'].value_counts().nlargest(10).plot(kind='bar')","53c39cb9":"train[train['challenge_sequence']==1]['challenge'].value_counts().nlargest(10)","99371f0b":"train[train['challenge_sequence']==2]['challenge'].value_counts().nlargest(10)","82f4770f":"challenge = challenge.rename(columns={'challenge_ID':'challenge'})\nchallenge['publish_year'] = pd.DatetimeIndex(challenge['publish_date']).year\ntrain_challenge = pd.merge(train,challenge,on=[\"challenge\"],how=\"left\")","4221a336":"train_challenge.groupby('programming_language')['user_id'].count().plot(kind='bar')","0e48de31":"train_challenge.groupby('programming_language')['user_id'].count()","da1804ef":"train_challenge.groupby('challenge_series_ID')['user_id'].count().nlargest(10)","75c20a06":"train_challenge.groupby('publish_year')['user_id'].count().reset_index().sort_values(by=['publish_year'],ascending=False).rename(columns={'user_id':'user_count'})[['publish_year','user_count']].plot(x='publish_year')","65e34542":"train_challenge.groupby('publish_year')['user_id'].count().sort_values(ascending=False)","8297b53e":"le =LabelEncoder()\nchallenge[\"challenge_series_ID\"] = le.fit_transform(challenge[\"challenge_series_ID\"].astype(str))\nchallenge[\"total_submissions\"] = challenge[\"total_submissions\"].fillna(challenge[\"total_submissions\"].mean()).astype(int)\nchallenge[\"category_id\"] = challenge[\"category_id\"].fillna(challenge[\"category_id\"].mean()).astype(int)","bf818735":"challenge['publish_date'] = pd.DatetimeIndex(challenge['publish_date']).year","85f0b99b":"combine_set=pd.concat([train,test], ignore_index=True)\nmer_train = pd.merge(train,challenge,on=[\"challenge\"],how=\"left\")\nmer_test = pd.merge(test,challenge,on=[\"challenge\"],how=\"left\")\nmer_df = mer_train.append(mer_test).reset_index(drop=True)","95271eaa":"total_data = mer_df.pivot_table(index='challenge',columns='user_id',values='challenge_sequence').fillna(0)","f0ece7db":"from scipy.sparse import csr_matrix\ntotal_data_matrix = csr_matrix(total_data.values)","1835b7af":"from sklearn.neighbors import NearestNeighbors\n\nmodel_knn = NearestNeighbors(metric='cosine', algorithm = 'brute')\nmodel_knn.fit(total_data_matrix)","59c365d4":"def distance_func(total_data, distances,indices):\n  every = {}\n  for i in range(0, len(distances.flatten())):\n      if i == 0:\n        pass\n      else:\n        every[total_data.index[indices.flatten()[i]]] = distances.flatten()[i]\n  return every","9c4fd121":"all_s = {}\nfor i in total_data.index:\n    distances, indices = model_knn.kneighbors(total_data.loc[i].values.reshape(1, -1), n_neighbors = 10)\n    data = distance_func(total_data, distances,indices)\n    all_s[i] = data","5947ab2a":"final_df = pd.DataFrame(columns=['user_sequence','challenge'])\ncounter = 0\nfor user_id in test.user_id.unique():\n  challenge_ids_of_user = test[test.user_id==user_id]['challenge']\n  all_sss = {}\n  for i in challenge_ids_of_user:\n    # distances, indices = model_knn.kneighbors(total_data_train.loc[i].values.reshape(1, -1), n_neighbors = 4)\n    # data = distance_func(total_data_train, distances,indices)\n    if i in all_s:\n      data = all_s[i]\n      for key, value in data.items():\n        if key in all_sss:\n          if value < all_sss[key]:\n            all_sss.update({key:value})\n        else:\n          all_sss.update({key:value})\n      # all_sss.update(data)\n  for i in challenge_ids_of_user:\n    if i in all_sss:\n      del all_sss[i]\n  challenges = [*dict(sorted(all_sss.items(), key=lambda x:x[1])[:3])]\n  if len(challenges) == 0:\n    final_df.loc[counter,:] = str(user_id)+'_11', '0'\n    final_df.loc[counter+1,:] = str(user_id)+'_12', '0'\n    final_df.loc[counter+2,:] = str(user_id)+'_13', '0'\n    counter += 3\n    continue\n  if len(challenges) != 3:\n    for i in range(3):\n      challenges.append(challenges[0])\n  \n  final_df.loc[counter,:] = str(user_id)+'_11', challenges[0]\n  final_df.loc[counter+1,:] = str(user_id)+'_12', challenges[1]\n  final_df.loc[counter+2,:] = str(user_id)+'_13', challenges[2]\n  counter += 3","e13da4e4":"final_df.to_csv('submit.csv', index=False)","6d69b80d":"!pip install turicreate","90d4d6ad":"import turicreate as tc\ntc.config.set_num_gpus(1)","67318e60":"# user_df and challenge_df is the data which we will pass to the turicreate which will extract features and use it further to increase recommendation\nuser_data = mer_df.groupby(\"user_id\")[\"challenge_series_ID\"].agg(lambda x: pd.Series.mode(x)[0]).to_frame()\nuser_data = user_data.reset_index()\nuser_data = tc.SFrame(user_data)\nchallenge_data = tc.SFrame(challenge)","07838541":"combine_set_tc=tc.SFrame(combine_set)\nm=tc.item_similarity_recommender.create(combine_set_tc, user_id='user_id',\n                                                            item_id='challenge',\n                                                            target='challenge_sequence',\n                                                            user_data=user_data,\n                                                            item_data = challenge_data,\n                                                            similarity_type = \"cosine\",\n                                                            )","f2a168e7":"results = m.recommend(test[\"user_id\"].unique().tolist(),k=3)[\"challenge\"]","6b065a1a":"submission_sample =pd.read_csv(r'https:\/\/raw.githubusercontent.com\/shrikantnarayankar15\/Insaid-ML-advanced-project\/master\/sample_submission.csv')\n\nsubmission_sample[\"challenge\"] = np.array(results).reshape(-1,1)\n\nsubmission_sample.to_csv(\"submit_target.csv\",index=False)","22a10e6a":"## 4.EDA on the data","7f63ca44":"#### 6.1 Simple modelling and using cosine similarity to find the recommendation Using NearestNeighbours (Item to Item similary here our Item is Challenge_ID's) \n\n","f1e4f49c":"#### 5.3 Merging test and train dataset with challenge dataset","86ac2ec4":"- AI565468 author with this ID created 140 challenges\n- most of the authors are Males\n- most of the authors are from A0I100201 organization almost 600 authors","483e81f5":"- The Score which I got from submitting above code is **0.131606060606061**\n- then I used challenge_sequence-13 as rating feature for the dataset which gave me around score of **0.1351565657**","6affd1a0":"- below function will give the cosine similarity distance between the two challenges","c56e7323":"Insights about the dataset\n\n- Your client is a fast-growing mobile platform, for hosting coding challenges. They have a unique business model, where they crowdsource problems from various creators(authors). These authors create the problem and release it on the client's platform. The users then select the challenges they want to solve. The authors make money based on the level of difficulty of their problems and how many users take up their challenge.\n\n\n- The client, on the other hand makes money when the users can find challenges of their interest and continue to stay on the platform. Till date, the client has relied on its domain expertise, user interface and experience with user behaviour to suggest the problems a user might be interested in. You have now been appointed as the data scientist who needs to come up with the algorithm to keep the users engaged on the platform.\n\n- The client has provided you with history of last 10 challenges the user has solved, and you need to predict which might be the next 3 challenges the user might be interested to solve. Apply your data science skills to help the client make a big mark in their user engagements\/revenue.\n","92321a35":"Top 10 challenges that users liked most","26da21c2":"- Challenge series with ID SI2678 have highest number of counts where most of the users interested","b2ea5167":"### 4.1 EDA on the challenge dataset","6b9ae5fb":"### 6.2 Used Turicreate for the recommendation system Item-Item","a6f4b8f6":"- Insights\n  - category id column have more no of missing values\n  - Here  total_submissions are numeric features will fill them by mean values\n  - however  author_ID, author_gender, author_org_ID,challenge_series_ID,category_id are categorical features will fill them by mode values","85175c70":"- below code is written to take the user_ids from the test dataset and suggesting the best challenge_IDS\n- this will give the challenge_sequence 11,12,13 which we want to generate for the user","df8d5b9c":"#### 3.1.Checking the null values","369e9703":"- Most of the challenges are from programming language 1\n- programming language 3 having less number of challenges","1d7984b3":"this are the top challenges which user have selected among the most challenge sequences","49e03fdc":"- this will contain all the user_sequence 11,12,13 and recommended challenge ids","59d9bcf3":"- I took challenge_sequence as rating for my recommendation","8fedc7a2":"#### 5.1 LabelEncoding to the categorical variables","52a28378":"# JanataHack: Recommendation Systems\n","04ee363f":"### Insights about training and testing dataset\nuser_sequence\t-> Unique ID for the sequence<br>\nuser_id\t-> User ID<br>\nchallenge_sequence\t-> Challenge sequence number (1-13)<br>\nchallenge\t-> Challenge ID <br>","f393c653":"## 1.Importing Packages","377bd86d":"- get the best 3 recommendations for the user ","a50ef1da":"### Challenge: \nContains the first 10 challenges solved by a new user set (not in train) in the test set. We need to predict the next 3 sequence of challenges for these users.\n","8e9a913f":"### 4.2 EDA on the training and testing Dataset","170cf56c":"SI2545    80898.000000<br>\nSI2634    79013.000000<br>\nSI2468    54842.000000<br>\nSI2677    51200.000000 <br>\ntop submissions paid by this challenge_series_ids","1bb8101c":"## 5.Data Preprocessing after EDA","61124d9c":"## 7.Conclusion","7717a5c9":"- challenge series id is the category given to the challenge dataset\n- My assumption it represents same problem but with higher difficuly. like sorting algorithm...followed by its no of problems\n- the series ID SI2652 have more no. of challenges (137)","19600b9d":"- Before passing the data to turicreate we need to convert it the SFrame(turicreate dataframe)","5fbc8be9":"### Total records for the datasets\nTrain - 903916 rows <br>\nTest - 397320 rows <br>\nchallenge - 5606  rows <br>","0acdc89b":"#### 5.2 Taking year attribute out of publish date","d0aa1254":"## 3.Data-Preprocessing","8355cce6":"## 2.Importing the dataset","4ca13fdc":"### 4.3 EDA on the training and challenge dataset after merging","355c0dce":"### Insights about challenge dataset\nchallenge_ID->\tChallenge ID<br>\nprogramming_language\t->Programming language for the challenge<br>\nchallenge_series_ID\t->Series for the given challenge<br>\ntotal_submissions\t->Total submissions by all users<br>\npublish_date  ->\tPublishing date for the challenge<br>\nauthor_ID\t->Author ID<br>\nauthor_gender ->\tAuthor gender<br>\nauthor_org_ID\t->Organization ID for author<br>\ncategory_id\t-> Type of challenge<br>","27de491f":"- challenges which are published in 2007, 2006, 2004, 2005 are the most liked challenges ","a61a80a4":"- I have seen the recommendation system with rating but this one was new.\n- I tried SVD and user-to-user collabarative system it also failed gave around 0.02 score after submission\n- Learned new library Turicreate which is very usefull for the recommendation\n- I saw some of the guys used NLP to predict the recommendation, In future I want to try it","caf69e38":"- we will calculate the distance between the items i.e. challenge Id's","7d3928c9":"- The Score which I got from submitting above code is **0.20589702538400853** around something which was higher than the models which i used earlier","7afdaf54":"- Most of the users like challenges with programming language as 1","dd3991d4":"##6.Modelling"}}