{"cell_type":{"d10d8d16":"code","fa8c403a":"code","b8836845":"code","89f9094a":"code","44384d52":"code","c0f0f532":"code","93e79f74":"code","73321678":"code","e712b8ce":"code","1a38372a":"code","d53fbe77":"code","ea5df052":"code","dc886cad":"code","30df3951":"code","671b025d":"code","60116169":"code","92e37a38":"code","bbcc9249":"code","707b09a8":"code","12561ec9":"code","ed178368":"code","a9befe6b":"code","15e8ec6e":"code","84764ec6":"code","c9e1dec4":"code","6c9a7fc8":"code","9d701bba":"code","3d846c23":"code","7e16c4df":"code","4125e1cf":"code","f7e67ec5":"code","25770fbd":"code","92515934":"code","360897b0":"code","6b9a554c":"code","b88a9ae8":"code","53373cc3":"code","7e58666a":"code","3469ae5f":"code","eb3fc56a":"code","72d3b0f9":"code","087025b2":"code","1bc886c5":"code","9de7bd69":"markdown","773e1f8a":"markdown","4c642141":"markdown","9471ca5f":"markdown","1fff54d8":"markdown","e21f1e2a":"markdown","bbcc9e2b":"markdown","89befed1":"markdown","58e3614c":"markdown","7ef7e47d":"markdown","c33e0bb2":"markdown","8b9d964c":"markdown","723b2e69":"markdown","49110bb5":"markdown"},"source":{"d10d8d16":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fa8c403a":"df = pd.read_csv('..\/input\/fake-news\/train.csv')","b8836845":"df.head()","89f9094a":"df.info()","44384d52":"df.describe()","c0f0f532":"df.isnull().sum()","93e79f74":"# Now Drop Nan values\ndf=df.dropna()","73321678":"X=df.drop('label',axis=1)\ny=df['label']","e712b8ce":"X.shape","1a38372a":"y.shape","d53fbe77":"y.value_counts()","ea5df052":"import tensorflow as tf\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Bidirectional\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.preprocessing.text import one_hot","dc886cad":"voc_size=5000","30df3951":"messages=X.copy()","671b025d":"messages['title'][1]","60116169":"messages.reset_index(inplace=True)","92e37a38":"import nltk\nimport re\nfrom nltk.corpus import stopwords","bbcc9249":"nltk.download('stopwords')","707b09a8":"from nltk.stem.porter import PorterStemmer","12561ec9":"port_stem=PorterStemmer()","ed178368":"corpus=[]\n\nfor i in range(0,len(messages)):\n    print(i)\n    review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review=[port_stem.stem(word) for word in review if not word in stopwords.words('english')]\n    \n    review=' '.join(review)\n    corpus.append(review)","a9befe6b":"corpus","15e8ec6e":"onehot_repr=[one_hot(words,voc_size) for words in corpus]","84764ec6":"onehot_repr","c9e1dec4":"sent_length=25\nembedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)","6c9a7fc8":"print(embedded_docs)","9d701bba":"embedded_docs[0]","3d846c23":"embedding_vector_features=42\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(LSTM(110))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model.summary())","7e16c4df":"embedding_vector_features=42\nmodel1=Sequential()\nmodel1.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel1.add(Bidirectional(LSTM(110)))\nmodel1.add(Dropout(0.3))\nmodel1.add(Dense(1,activation='sigmoid'))\nmodel1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model1.summary())","4125e1cf":"len(embedded_docs),y.shape","f7e67ec5":"X_final=np.array(embedded_docs)\ny_final=np.array(y)","25770fbd":"X_final.shape","92515934":"y_final.shape","360897b0":"\nfrom sklearn.model_selection import train_test_split","6b9a554c":"X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.30, random_state=4)","b88a9ae8":"X_train","53373cc3":"y_train","7e58666a":"model1.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=12,batch_size=64)","3469ae5f":"y_pred1=model1.predict_classes(X_test)","eb3fc56a":"from sklearn.metrics import confusion_matrix","72d3b0f9":"confusion_matrix(y_test,y_pred1)","087025b2":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred1)","1bc886c5":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred1))","9de7bd69":"# Now Model Training and final training","773e1f8a":"# Now Reset index","4c642141":"# Get the independent and dependent features","9471ca5f":"# Now Creating Models","1fff54d8":"# Now Vocabulary size","e21f1e2a":"# Now Model Selection","bbcc9e2b":"# Now OneHot ","89befed1":"# Performance Metrics And Accuracy","58e3614c":"# Now Check Length and shape","7ef7e47d":"# Embedding Representation","c33e0bb2":"# Dataset Preprocessing","8b9d964c":"# Onehot Representation","723b2e69":"# Now Check Corpus","49110bb5":"# Checks 0's and 1's"}}