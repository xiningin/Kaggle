{"cell_type":{"a6bd9e03":"code","894aee3d":"code","7d385b87":"code","acc7daef":"code","14757a06":"code","723bd3e4":"code","4c1bd476":"code","ba2acae1":"code","99f265c0":"code","431d3dca":"code","4f7bc365":"code","aeb74fc4":"code","6cdec363":"markdown","d09e2ed2":"markdown"},"source":{"a6bd9e03":"import pandas as pd\nimport numpy as  np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.callbacks import ReduceLROnPlateau,EarlyStopping \n\nimport seaborn as sns\n%matplotlib inline","894aee3d":"# load csv data\ntrain=pd.read_csv('..\/input\/Kannada-MNIST\/train.csv')\ntest=pd.read_csv('..\/input\/Kannada-MNIST\/test.csv')\nsample_sub=pd.read_csv('..\/input\/Kannada-MNIST\/sample_submission.csv')","7d385b87":"# data perparation\ntest=test.drop('id',axis=1)\nX_train=train.drop('label',axis=1)\nY_train=train.label\n\n# normalize\nX_train=X_train\/255\ntest=test\/255\n\n# reshape data\nX_train=X_train.values.reshape(-1,28,28,1)\ntest=test.values.reshape(-1,28,28,1)\n\nprint('The shape of train set now is',X_train.shape)\nprint('The shape of test set now is',test.shape)","acc7daef":"# one-hot-vector\nY_train=to_categorical(Y_train)\n\n# split train and test data\nX_train,X_test,y_train,y_test=train_test_split(X_train,Y_train,random_state=42,test_size=0.1)","14757a06":"# Some examples\ng = plt.imshow(X_train[0][:,:,0])","723bd3e4":"# image augmantaion\ndatagen = ImageDataGenerator(rotation_range = 10,\n                             width_shift_range = 0.3,\n                             height_shift_range = 0.3,\n                             shear_range = 0.15,\n                             zoom_range = 0.3,\n                            )\n\ndatagen.fit(X_train)","4c1bd476":"# model\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(BatchNormalization(momentum=.15))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(BatchNormalization(momentum=0.15))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(BatchNormalization(momentum=.15))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(10, activation = \"softmax\"))","ba2acae1":"# Set hyper paramater\nepochs=100\nbatch_size=1024\n\n# optimizer\noptimizer=Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999)\nmodel.compile(optimizer=optimizer,loss=['categorical_crossentropy'],metrics=['accuracy'])\n\n# learning_rate\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\n# early-stopping\nearly_stopping  = EarlyStopping(monitor='val_loss', \n                                min_delta=0, \n                                patience=10, \n                                verbose=0, \n                                mode='auto')\n\ncallbacks = [learning_rate_reduction, early_stopping]","99f265c0":"# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_test,y_test),\n                              verbose = 2, \n                              steps_per_epoch=X_train.shape[0] \/\/ batch_size\n                              , callbacks=callbacks)","431d3dca":"#predict validation data\ny_pre_test=model.predict(X_test)\ny_pre_test=np.argmax(y_pre_test,axis=1)\ny_test=np.argmax(y_test,axis=1)","4f7bc365":"# check predict result\nx=(y_pre_test-y_test!=0).tolist()\nx=[i for i,l in enumerate(x) if l!=False]\n\nfig,ax=plt.subplots(1,4,sharey=False,figsize=(15,15))\n\nfor i in range(4):\n    ax[i].imshow(X_test[x[i]][:,:,0])\n    ax[i].set_xlabel('Ans {}, Pre {}'.format(y_test[x[i]],y_pre_test[x[i]]))","aeb74fc4":"# output\ny_pre=model.predict(test)     ##making prediction\ny_pre=np.argmax(y_pre,axis=1) ##changing the prediction intro labels\nsample_sub['label']=y_pre\nsample_sub.to_csv('submission.csv',index=False)","6cdec363":"** We hope you will find this notebook useful. **\n\n** Thank you for watching until the end ! **\n","d09e2ed2":"# Thank you for access my Notebook.\n## Kei Takahashi\n\n\nI'm Japanse and a rookie in Kaggle. \n\nAnd I'm not very good at English and Python. \n\nSo you may notice my mistakes. Please go easy on me. \n\nI do my best to write this notebook simply.\n\nI would like as many those as possible to join Kaggle,\nso I wrote clearly and shortly Python code. \n\nIf there are any other particular points, please point them out."}}