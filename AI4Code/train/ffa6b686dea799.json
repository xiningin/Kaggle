{"cell_type":{"94a68588":"code","bf1be290":"code","b5f9e9bd":"code","0a328f35":"code","13ce8da7":"code","840ffe67":"code","e2441e6e":"code","080d797f":"markdown","c8171b68":"markdown","ebcab6af":"markdown","86b7b709":"markdown","540ec023":"markdown","b5ff03c6":"markdown"},"source":{"94a68588":"import numpy as np\nimport pandas as pd","bf1be290":"%%time\ntrain = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/train.csv')\ntrain_labels = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/train_labels.csv')","b5f9e9bd":"train.shape[0], train['installation_id'].unique().shape[0]","0a328f35":"t1 = train.groupby(['installation_id', 'type']).agg({'game_session': 'count'}).reset_index()\nt2 = t1.pivot(index='installation_id', columns='type', values='game_session').reset_index()\nt2","13ce8da7":"t2['Assessment'].isna().sum(), t2['Assessment'].isna().sum() \/ t2.shape[0]","840ffe67":"useful_installation_ids = t2[~t2['Assessment'].isna()]['installation_id'].values\nclean_train = train[train['installation_id'].isin(useful_installation_ids)]\nclean_train.shape[0], clean_train.shape[0] \/ train.shape[0]","e2441e6e":"useful_installation_ids_sl = train_labels['installation_id'].unique()\nclean_train_sl = train[train['installation_id'].isin(useful_installation_ids_sl)]\nclean_train_sl.shape[0], clean_train_sl.shape[0] \/ train.shape[0]","080d797f":"The table above is the **pivot table** that aggregates the count of **activity types** (children either do an activity, do an assessment, watch a clip or play a game) by installation id. From that it's easy to count how many installation ids never did a single assessment:","c8171b68":"# Cleaning useless data to load train.csv faster\nWe can split `train.csv` in 3 groups of installation ids:\n1. Children who tried at least one assessment throughout their game play history (useful)\n2. Children who never tried any assessment (useless)\n3. Children who tried at least one assessment, but for whom we do not have labeled data to train a model (useful in later stages)\n\nGroup 1 is very useful, in what we should focus on. Group 2 is completely useless (if you disagree, please leave a comment!).\nGroup 3 might be useful in a more advanced way to clustering, in later stages of the competition (unsupervised learning\/autoencoders).\nLet's check each group's size and get rid of the useless.","ebcab6af":"As we can see, over **11 million rows**, from **17,000 unique installation ids**. However, most of those ids are useless:","86b7b709":"There it is: **almost 13 thousand installation ids, 75% of them, never did a single assignment**. They are useless. Let's see how much we gain by removing all rows that belong to these ids from the main table:","540ec023":"Removing all unlabelled data from the train DataFrame reduces its size **down to 7.7 million rows, 68% of its original size**.\nIt's much faster to work with this than it is to work with the original file.\n\nCheers!","b5ff03c6":"Removing these useless records brings the train DataFrame **down to 8 million rows, 73% of its original size**.\nThis, imho, is the useful dataset. Now, assuming that (at least for now), we won't use any unsupervised learning technique (i.e. we need labels), we can reduce it even further:"}}