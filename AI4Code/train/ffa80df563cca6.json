{"cell_type":{"e4683085":"code","5ea2dfb2":"code","725e5b96":"code","73b38053":"code","7213e92d":"code","723a185e":"code","45b16154":"code","37c549c1":"code","2304f24f":"code","2a467c22":"markdown","c80731f5":"markdown","20a242d6":"markdown","d688bce6":"markdown"},"source":{"e4683085":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5ea2dfb2":"!git clone https:\/\/github.com\/clovaai\/CRAFT-pytorch","725e5b96":"ls \/kaggle\/input","73b38053":"ls \/kaggle\/input\/craft-pretrained-model","7213e92d":"cd \/kaggle\/working\/CRAFT-pytorch\/","723a185e":"!python3 test.py --trained_model=\/kaggle\/input\/craft-pretrained-model\/craft_ic15_20k.pth --test_folder=\/kaggle\/input\/craft-test-images","45b16154":"ls \/kaggle\/working\/CRAFT-pytorch\/result","37c549c1":"ls \/kaggle\/input\/craft-test-images","2304f24f":"import cv2\nfrom matplotlib import pyplot as plt\nimport matplotlib.image as mpimg\n\n\n# create figure\n\n\nfor img in os.listdir(\"\/kaggle\/input\/craft-test-images\"):\n    fig = plt.figure(figsize=(20, 14))\n    rows = 1\n    columns = 2\n    Image1 = cv2.imread(f'\/kaggle\/input\/craft-test-images\/{img}')\n    Image2 = mpimg.imread(f'\/kaggle\/working\/CRAFT-pytorch\/result\/res_{img}'.replace('jpeg','jpg').replace('png', 'jpg'))\n    fig.add_subplot(rows, columns, 1)\n    plt.imshow(Image1)\n    plt.axis('off')\n    plt.title(\"original\")\n    fig.add_subplot(rows, columns, 2)\n    plt.imshow(Image2)\n    plt.axis('off')\n    plt.title(\"detection\")\n    plt.show()","2a467c22":"**OCR building blocks** \n,is a two step process which includes:\n1. text detection\n2. text recognition\n\nText detection can be implemented using following two methods:\n* region based detectors (region based detection based methods such as R-FCN, [Faster R-CNN](https:\/\/github.com\/rbgirshick\/py-faster-rcnn) )\n* single shot detectors (sinlge shot detection base methods such as [SSD](https:\/\/github.com\/sgrvinod\/a-PyTorch-Tutorial-to-Object-Detection), [YOLO](https:\/\/github.com\/ultralytics\/yolov5))\n\nWhile tesseract, [deep-text-recognition](https:\/\/github.com\/clovaai\/deep-text-recognition-benchmark) can be used for text recognition.","c80731f5":"the images after inference are save inside 'result' folder","20a242d6":"# **Inference**","d688bce6":"the test images are stored at '\/kaggle\/input\/craft-test-images' while the pretrained model file is stored at '\/kaggle\/input\/craft-pretrained-model'"}}