{"cell_type":{"f5ecf8f2":"code","c37c3508":"code","02259db9":"code","f7cb8b19":"code","15e046bb":"code","032036c2":"code","1ffec281":"code","96e4df1c":"code","d9f66e7e":"code","494170fb":"code","01b32197":"code","b6a6e52d":"code","ddc13316":"code","d7f57933":"code","1bd8baed":"code","c7f9c938":"code","bf3ea11a":"markdown","288a050a":"markdown","c05f4e1f":"markdown","68fee5a6":"markdown","4e5d32d8":"markdown","b42447ed":"markdown","dd1455a6":"markdown","a03f0b9e":"markdown","4d869835":"markdown","e57521c9":"markdown"},"source":{"f5ecf8f2":"#import modules\nimport pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport os\n\n\n#visuals\nimport matplotlib.pyplot as plt\n\n#determine class weights\nfrom sklearn.utils import class_weight\n\n#Image Preprocessing\nfrom keras.preprocessing.image import ImageDataGenerator\n\n#Keras\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\nfrom keras.optimizers import Adam\nfrom keras.optimizers import SGD\nfrom keras import initializers\nfrom keras.callbacks import TensorBoard\nfrom keras.utils import np_utils\nfrom keras.constraints import maxnorm\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.layers.normalization import BatchNormalization\n\n#Disable Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","c37c3508":"train = pd.read_csv('..\/\/input\/\/train.csv')\nprint(train.shape)\nprint(train.head(10))","02259db9":"train.has_cactus.value_counts()","f7cb8b19":"\n#set class weights\nclass_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(train['has_cactus']),\n                                                 train['has_cactus'])\nprint(class_weights)","15e046bb":"def create_training_model_data(dataframe, batch_size=32, mode='categorical'):\n    \n        #TypeError: If class_mode=\"binary\", y_col=\"has_cactus\" column values must be strings.\n        dataframe['has_cactus'] = dataframe['has_cactus'].astype(str) #resolve error\n        \n        IDG = ImageDataGenerator(rescale=1.\/255.,      #rescale: make RGB values between 1 and 0\n                                 horizontal_flip=True, #horizontal_flip: Boolean. Randomly flip inputs horizontally.\n                                 vertical_flip=True)   #vertical_flip: Boolean. Randomly flip inputs vertically.\n        \n        #Create Train Data to Feed Into CNN\n        train_data = IDG.flow_from_dataframe(dataframe=dataframe[:15925], #select first 90% of data\n                                             directory='..\/\/input\/\/train\/\/train', #path to the images\n                                             x_col='id', #column in df that contains image names\n                                             y_col='has_cactus', #column in df that contains labels\n                                             class_mode='binary', #binary output\n                                             batch_size=batch_size, #batch size\n                                             color_mode='grayscale', #convert images to gray scale\n                                             target_size=(32,32)) #input image size\n        \n        #Create Validation Data to Feed Into CNN\n        validation_data = IDG.flow_from_dataframe(dataframe=dataframe[15925:], #select last 10% of data\n                                                  directory='..\/\/input\/\/train\/\/train\/\/',\n                                                  x_col='id',\n                                                  y_col='has_cactus',\n                                                  class_mode='binary',\n                                                  batch_size=batch_size,\n                                                  color_mode='grayscale',\n                                                  target_size=(32,32))\n        \n        return train_data, validation_data","032036c2":"train_data, validation_data = create_training_model_data(train)","1ffec281":"model_alexnet = Sequential()\n\n# 1st Convolutional Layer\nmodel_alexnet.add(Conv2D(32,(3,3),                \n                 input_shape=(32, 32, 1), #dimensions = 32X32, color channel = B&W\n                 padding='same',\n                 activation='relu'))\n\n#pooling\nmodel_alexnet.add(MaxPooling2D(pool_size=(2,2), padding='same')) \nmodel_alexnet.add(BatchNormalization())\n\n# 2nd Convolutional Layer\nmodel_alexnet.add(Conv2D(64,(3,3),\n                padding='same',\n                activation='relu'))\n\n#pooling\nmodel_alexnet.add(MaxPooling2D(pool_size=(2,2), padding='same'))\nmodel_alexnet.add(BatchNormalization())\n\n# 3rd Convolutional Layer\nmodel_alexnet.add(Conv2D(64,(3,3),\n                padding='same',\n                activation='relu'))\nmodel_alexnet.add(BatchNormalization())\n\n#4th Convolutional Layer\nmodel_alexnet.add(Conv2D(128,(3,3),\n                padding='same',\n                activation='relu'))\nmodel_alexnet.add(BatchNormalization())\n\n#5th Convolutional Layer\nmodel_alexnet.add(Conv2D(128,(3,3),\n                padding='same',\n                activation='relu'))\n\n#pooling\nmodel_alexnet.add(MaxPooling2D(pool_size=(3,3), padding='same'))\nmodel_alexnet.add(BatchNormalization())\n\n\n#Flatten\nmodel_alexnet.add(Flatten())\n\n#1st Dense Layer\nmodel_alexnet.add(Dense(128,\n               activation='relu', kernel_initializer='glorot_uniform'))\nmodel_alexnet.add(Dropout(0.10))\nmodel_alexnet.add(BatchNormalization())\n\n#2nd Dense Layer\nmodel_alexnet.add(Dense(256,\n               activation='relu', kernel_initializer='glorot_uniform'))\nmodel_alexnet.add(Dropout(0.20))\nmodel_alexnet.add(BatchNormalization())\n\n# # 3rd Dense Layer\nmodel_alexnet.add(Dense(512,\n               activation='relu', kernel_initializer='glorot_uniform'))\nmodel_alexnet.add(Dropout(0.2))\nmodel_alexnet.add(BatchNormalization())\n\n#output layer\nmodel_alexnet.add(Dense(1, activation='sigmoid'))\n\n#Compile \nmodel_alexnet.compile(loss='binary_crossentropy', optimizer='adam',\n metrics=['accuracy'])\n\n# Set callback functions to early stop training and save the best model so far\ncallbacks = [EarlyStopping(monitor='val_loss', patience=20), #stop if no improvment after 10 epochs\n             \n             ModelCheckpoint(filepath='best_model_alexnet.h5', monitor='val_loss', save_best_only=True)] #improvment val_loss\n\n#summary of Model\nmodel_alexnet.summary()","96e4df1c":"#fit model\nhistory = model_alexnet.fit_generator(train_data,\n          epochs=100,\n          steps_per_epoch=(15925\/32),\n          callbacks=callbacks,\n          validation_data = validation_data,\n          validation_steps=(1575\/32),\n          class_weight=class_weights,\n          verbose=2)","d9f66e7e":"accuracy = history.history['acc']\nval_accuracy = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'bo', label='Training Accuracy')\nplt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')\nplt.title('Training and Validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","494170fb":"#Create IDG for test images\ntest_IDG = ImageDataGenerator(rescale=1.\/255.) #rescale test image RGB values\n\n#Perform IDG on images within the test directory\ntest_data = test_IDG.flow_from_directory(\n    directory='..\/\/input\/\/test\/\/',\n    target_size=(32,32),\n    color_mode='grayscale',\n    class_mode='binary',\n    batch_size=1,\n    shuffle=False)","01b32197":"#get prediction probabilities for the 4000 test images\ny_pred = model_alexnet.predict_generator(test_data,steps=4000)\n\n#turn array into a single list\ny_pred = np.hstack(y_pred).tolist()","b6a6e52d":"#get a count of class predictions\nhas_cactus = [0 if proba<0.50 else 1 for proba in y_pred]\nprint(Counter(has_cactus).keys()) # equals to list(set(words))\nprint(Counter(has_cactus).values())","ddc13316":"#get the name of the files in the directory\nfiles=[]\nfiles = [f for f in sorted(os.listdir('..\/\/input\/\/test\/\/test'))]","d7f57933":"submission = pd.DataFrame({'id':files,\n                          'has_cactus':y_pred})","1bd8baed":"submission.head(10)","c7f9c938":"submission.to_csv('submission.csv', index=False)","bf3ea11a":"<h1 align=\"center\"> AlexNet Classifier For 32X32 Grayscale Images Using Keras","288a050a":"# 3) Create Class Weights\n\n### To deal with imbalanced classes & save some time, assigning a larger weight to the minority class makes sure our algoritm isnt learning too much from the majority class. This also saves time as we do not have to perform a synthetic data generation technique like ADASYN or SMOTE.","c05f4e1f":"# 4) Keras ImageDataGenerator","68fee5a6":"# 7) Predict Probabilities on Testing Data","4e5d32d8":"# 5) AlexNet Architecture","b42447ed":"## Program Outline\n1. Import Modules\n2. Data Exploration\n3. Create Class Weights\n4. Keras ImageDataGenerator\n5. AlexNet Architecture\n6. Fit Model\n7. Predict Probabilities on Testing Data\n8. Create Submission df","dd1455a6":"# 2) Data Exploration","a03f0b9e":"# 8) Create Submission df","4d869835":"# 6) Fit Model","e57521c9":"# 1) Import Modules"}}