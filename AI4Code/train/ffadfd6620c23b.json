{"cell_type":{"3a9d54d0":"code","6f0f9fdb":"code","a0c31c53":"code","cb99871d":"code","a19afba2":"code","f00e8458":"code","d664d2a2":"code","190c7875":"code","6bbb7128":"code","38975e5a":"code","64a4f9f7":"code","8fab4e8d":"code","417356d8":"code","0c6b132f":"code","e22f4ddb":"code","15c4da26":"code","f478d88d":"code","74822d12":"code","916a7808":"code","5c9d56b2":"code","d7f5b3b6":"code","3c86af23":"code","3a3aef2f":"code","63535039":"code","5dfab466":"code","ee19462f":"code","81c683e7":"code","d6f58e15":"code","86b1e443":"code","4fd7cd2e":"code","a77cff66":"code","1d5a5476":"code","7b82dde5":"code","a9617e29":"code","c4ec91f7":"code","b8c7cf94":"code","3410e73d":"code","6bda381a":"code","db1777e0":"markdown","fc63de12":"markdown"},"source":{"3a9d54d0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfrom kaggle_datasets import KaggleDatasets\n\n#Visualization Libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob\n#File Accessing Libraries\nimport math, os, re, warnings, random\nimport os.path\nfrom os import path\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6f0f9fdb":"from tensorflow.keras import layers, models, Model\nfrom tensorflow.python.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.losses import MeanAbsoluteError, MeanAbsolutePercentageError\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tensorflow.keras import Model, layers\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Input, Dense, Dropout, GaussianNoise\nfrom tensorflow.keras.applications import ResNet50\nimport tensorflow.keras.backend as K","a0c31c53":"tf.__version__","cb99871d":"! pip install -q efficientnet","a19afba2":"data=pd.read_csv(\"..\/input\/illionis-data-cleaned-csv-data\/Final_Dataset.csv\")","f00e8458":"data","d664d2a2":"data['sex'].value_counts().plot(kind='barh')","190c7875":"def seed_everything(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nseed = 42\nseed_everything(seed)\nwarnings.filterwarnings('ignore')  ","6bbb7128":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","38975e5a":"# The following functions can be used to convert a value to a type compatible\n# with tf.train.Example.\n\ndef _bytes_feature(value):\n  \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n  if isinstance(value, type(tf.constant(0))):\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n  \"\"\"Returns a float_list from a float \/ double.\"\"\"\n  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n    \n\ndef serialize_example(age, bmi, image, sex):\n  \"\"\"\n  Creates a tf.train.Example message ready to be written to a file.\n  \"\"\"\n  # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n  # data type.\n  feature = {\n      'age': _float_feature(age),\n      'bmi': _float_feature(bmi),\n      'image': _bytes_feature(image),\n      'sex': _int64_feature(sex),\n  }\n\n  # Create a Features message using tf.train.Example.\n\n  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n  return example_proto.SerializeToString()\n","64a4f9f7":"filenames=glob.glob(\"..\/input\/illionis-data-cleaned-csv-data\/dataset\/Train\/*.tfrecord\")","8fab4e8d":"from kaggle_datasets import KaggleDatasets\nGCS_PATH = KaggleDatasets().get_gcs_path()\nfilenames=tf.io.gfile.glob(GCS_PATH + '\/dataset\/Train\/*.tfrecord')\nprint(len(filenames))\nrandom.shuffle(filenames)\ntrain_filenames=filenames[0:55]\nval_filenames=filenames[55:60]","417356d8":"def _parse_image_function(example_proto):\n    image_feature_description = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'age': tf.io.FixedLenFeature([], tf.float32),\n        'bmi': tf.io.FixedLenFeature([], tf.float32),\n        'sex': tf.io.FixedLenFeature([], tf.int64),\n       \n    }\n\n    features = tf.io.parse_single_example(example_proto, image_feature_description)\n    image = tf.io.decode_raw(features['image'], tf.uint8)\n    image.set_shape([3 * 256 *256])\n    image = tf.reshape(image, [256,256,3])\n    #image = tf.image.rgb_to_grayscale(image)\n    \n\n    age = tf.cast(features['age'], tf.float32)\n    bmi=tf.cast(features['bmi'], tf.float32) \n    sex = tf.cast(features['sex'], tf.int64)\n\n    \n    return image,age,bmi,sex","0c6b132f":"def read_unlabeled_tfrecord(example_proto):\n    \n    image_feature_description = {\n        'image': tf.io.FixedLenFeature([], tf.string)\n    }\n\n    features = tf.io.parse_single_example(example_proto, image_feature_description)\n    image = tf.io.decode_raw(features['image'], tf.uint8)\n    image.set_shape([3 * 256 *256])\n    image = tf.reshape(image, [256,256,3])\n    return image","e22f4ddb":"epochs=20\nbatch_size=32\n\ndef get_dataset(files,shuffle = True, repeat = True,labeled=True, batch_size=32):\n    AUTO=tf.data.AUTOTUNE\n    REPLICAS=20\n    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n    ds = ds.cache()\n    \n    if repeat:\n        ds = ds.repeat()\n    \n    if shuffle: \n        ds = ds.shuffle(1024*8)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = True\n        ds = ds.with_options(opt)\n        \n    if labeled: \n        ds = ds.map(_parse_image_function, num_parallel_calls=AUTO)\n    else:\n         ds = ds.map(read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n            \n    ds = ds.batch(batch_size * REPLICAS)\n    ds = ds.prefetch(AUTO)\n    return ds","15c4da26":"train_dataset=get_dataset(train_filenames,labeled=True)","f478d88d":"val_dataset=get_dataset(val_filenames,labeled=True)","74822d12":"val_batches = tf.data.experimental.cardinality(val_dataset)\ntest_dataset = val_dataset.take(val_batches \/\/ 2)","916a7808":"def input_gen(image_batch,sex_batch,bmi_batch,age_batch):\n    x=[]\n    y=[]\n    for n in range(len(image_batch)):\n        input_arr = tf.keras.preprocessing.image.img_to_array(image_batch[n])\n        output_arr=[bmi_batch[n],age_batch[n],sex_batch[n]]\n        x.append(input_arr)\n        y.append(output_arr)\n                        \n    return x,y","5c9d56b2":"def show_batch(image_batch,sex_batch,bmi_batch,age_batch):\n    plt.figure(figsize=(25,25))\n    for n in range(10):\n        ax = plt.subplot(5, 5, n + 1)\n        plt.imshow(image_batch[n] \/ 127.0)\n        plt.axis(\"on\")\n        attributes=\"Bmi: \"+str(bmi_batch[n])+\", Age: \"+str(age_batch[n])+\", Sex: \"+str(sex_batch[n])\n        ax.text(10, 10, attributes, bbox={'facecolor': 'white', 'pad': 10})\n        \n        \n\nimage_batch,sex_batch,bmi_batch,age_batch = next(iter(train_dataset))\nshow_batch(image_batch.numpy(),age_batch.numpy(),sex_batch.numpy(), bmi_batch.numpy())","d7f5b3b6":"IMG_SHAPE = (256,256, 3)\nbase_model = tf.keras.applications.EfficientNetB6(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)","3c86af23":"base_model.trainable = False","3a3aef2f":"optimizer = tf.keras.optimizers.Adam()\nmae=tf.keras.metrics.MeanAbsoluteError()","63535039":"def precision(y_true, y_pred): #taken from old keras source code\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    return precision","5dfab466":"model_inputs = tf.keras.Input(shape=(256, 256, 3))\nx = base_model(model_inputs, training=False)\nx = tf.keras.layers.MaxPooling2D()(x)\nx = tf.keras.layers.Flatten()(x)\n#let's add a fully-connected layer\n'''x = tf.keras.layers.Dense(64,activation='relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(64,activation='relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\n'''\n\n\n#start passing that fully connected block output to all the different model heads\ny1 = tf.keras.layers.Dense(32,activation='relu')(x)\ny1 = tf.keras.layers.Dropout(0.2)(y1)\ny1 = tf.keras.layers.Dense(16,activation='relu')(y1)\ny1 = tf.keras.layers.Dropout(0.2)(y1)\n\ny2 = tf.keras.layers.Dense(32,activation='relu')(x)\ny2 = tf.keras.layers.Dropout(0.2)(y2)\ny2 = tf.keras.layers.Dense(16,activation='relu')(y2)\ny2 = tf.keras.layers.Dropout(0.2)(y2)\n\ny3 = tf.keras.layers.Dense(32,activation='sigmoid')(x)\ny3 = tf.keras.layers.Dropout(0.2)(y3)\ny3 = tf.keras.layers.Dense(16,activation='sigmoid')(y3)\ny3 = tf.keras.layers.Dropout(0.2)(y3)\n\n\n# Predictions for each task\ny1 = tf.keras.layers.Dense(units=3,activation=\"linear\",name='bmi')(y1)\ny2 = tf.keras.layers.Dense(units=3,activation=\"linear\",name='age')(y2)\ny3 = tf.keras.layers.Dense(units=3,activation=\"sigmoid\",name='sex')(y3)\n \ncustom_model = tf.keras.Model(inputs=model_inputs,outputs=[y1,y2,y3])\n\ncustom_model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-5),\n              loss={'bmi':'mean_squared_error','age':'mean_squared_error','sex':'hinge'},\n              metrics= {'bmi':mae,'age':mae,'sex': precision})\n","ee19462f":"custom_model.summary()","81c683e7":"custom_model.loss","d6f58e15":"image_batch,age_batch,sex_batch,bmi_batch, = next(iter(train_dataset))\nx_train,y_train=input_gen(image_batch.numpy(),age_batch.numpy(),sex_batch.numpy(), bmi_batch.numpy())","86b1e443":"image_batch,age_batch,sex_batch,bmi_batch, = next(iter(val_dataset))\nx_val,y_val=input_gen(image_batch.numpy(),age_batch.numpy(),sex_batch.numpy(), bmi_batch.numpy())","4fd7cd2e":"y_train=tf.stack(y_train)\ny_val=tf.stack(y_val)","a77cff66":"model_dir = '.\/'\nes = EarlyStopping(patience=5)\nckp = ModelCheckpoint(model_dir, save_best_only=True, save_weights_only=True, verbose=1)\ncallbacks = [es, ckp]","1d5a5476":"history = custom_model.fit(x=np.array(x_train), y=np.array(y_train),epochs=epochs,callbacks = callbacks,batch_size=batch_size,steps_per_epoch=20,validation_data=(np.array(x_val), np.array(y_val)))","7b82dde5":"# list all data in history\nprint(history.history.keys())\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","a9617e29":"#Retrieve a batch of images from the test set\nimage_batch,age_batch,bmi_batch,sex_batch= test_dataset.as_numpy_iterator().next()\nPred_bmi_batch,Pred_age_batch,Pred_sex_batch = custom_model.predict_on_batch(image_batch[0:15])","c4ec91f7":"temp_sex=[min(x,y,z) for x,y,z in Pred_sex_batch]\ntemp_sex=[1 if x >0.5 else 0 for x in temp_sex]","b8c7cf94":"print(temp_sex)\nprint([1 if x >0.5 else 0 for x in sex_batch[0:15]])","3410e73d":"temp_bmi=[max(x,y,z) for x,y,z in Pred_bmi_batch]\nfor i in range(0,15):\n    print(\"Actual %s Predicted- %s\" % (bmi_batch[i], temp_bmi[i]))","6bda381a":"temp_age=[max(x,y,z) for x,y,z in Pred_age_batch]\nfor i in range(0,15):\n    print(\"Actual %s Predicted- %s\" % (age_batch[i], temp_age[i]))","db1777e0":"**TFRecord Data format** - features {\n  feature {\n    key: \"age\"\n    value {\n      float_list {\n        value: 70.0\n      }\n    }\n  }\n  feature {\n    key: \"bmi\"\n    value {\n      float_list {\n        value: 28.970176696777344\n      }\n    }\n  }\n  feature {\n    key: \"image\"\n    value {\n      bytes_list:\"\"\n         }\n    }\n  }\n  feature {\n    key: \"sex\"\n    value {\n      int64_list {\n        value: 0\n      }\n    }\n  }\n}","fc63de12":"#### As per above images Sex=0 means male. As per data\n#### Male -94%\n#### Female-6%,"}}