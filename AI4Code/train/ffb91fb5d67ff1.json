{"cell_type":{"472a087f":"code","56d186a6":"code","415ff852":"code","89d64e0b":"code","c1ccc814":"code","5cac454d":"code","3d4fe1e6":"code","7421d1da":"code","cfa05727":"code","9227e7b5":"code","05ce2e81":"code","c284c643":"code","e2868265":"code","df365439":"code","40f6df17":"code","5ad1f5d6":"code","b9a34480":"code","76e586ac":"code","07d174b0":"markdown","a298be92":"markdown","0802f384":"markdown","5083f19c":"markdown","116c5b88":"markdown"},"source":{"472a087f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","56d186a6":"# load our data\nimport pandas as pd\n\ntest_dir = \"\/kaggle\/input\/kepler-labelled-time-series-data\/exoTest.csv\"\ntrain_dir = \"\/kaggle\/input\/kepler-labelled-time-series-data\/exoTrain.csv\"\n\n\ntrain_dataset = pd.read_csv(train_dir)\ntest_dataset = pd.read_csv(test_dir)","415ff852":"# let's how our data look like\ntrain_dataset.head()","89d64e0b":"# let's normalize our flux values\n\nfor col in train_dataset.columns:\n    if col != \"LABEL\":\n        train_dataset[col] = train_dataset[col]\/train_dataset[col].max()\n        \nfor col in test_dataset.columns:\n    if col != \"LABEL\":\n        test_dataset[col] = test_dataset[col]\/test_dataset[col].max()","c1ccc814":"train_dataset.describe()","5cac454d":"# append zero columns to dataframe to make flux values size to 3249 = 57*57\nfor i in range(3198,3250):\n    colname = \"FLUX.\" + str(i)\n    train_dataset[colname] = pd.DataFrame({colname: len(train_dataset)*[0]})\n    test_dataset[colname] = pd.DataFrame({colname: len(test_dataset)*[0]})","3d4fe1e6":"# extract X and y for our model\n\nX_train = train_dataset.loc[:, train_dataset.columns != 'LABEL']\ny_train = train_dataset['LABEL']\nprint(X_train)\nprint(y_train)","7421d1da":"X_test = test_dataset.loc[:, test_dataset.columns != 'LABEL']\ny_test = test_dataset['LABEL']","cfa05727":"# convert our df to numpy array\n\nX_train = X_train.to_numpy()\ny_train = y_train.to_numpy()\nX_test = X_test.to_numpy()\ny_test = y_test.to_numpy()","9227e7b5":"# check shape\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","05ce2e81":"# reshape our X to 57*57\nX_train = np.reshape(X_train, [X_train.shape[0], 57, 57, 1])\nX_test = np.reshape(X_test, [X_test.shape[0], 57, 57, 1])\nprint(X_train.shape)","c284c643":"# map new value for label\nfor i in range(len(y_train)):\n    y_train[i] = y_train[i]-1\n    \nfor i in range(len(y_test)):\n    y_test[i] = y_test[i]-1\n    \ny_train","e2868265":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(57, 57, 1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\nmodel.summary()","df365439":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","40f6df17":"# train test split\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=42)","5ad1f5d6":"# let's fit our model\nhistory = model.fit(X_train, y_train, epochs=30, \n                    validation_data=(X_val, y_val), verbose=2)","b9a34480":"# model evaluation\n# Evaluate the model on the test data using `evaluate`\nprint(\"Evaluate on test data\")\nresults = model.evaluate(X_test, y_test, batch_size=128)\nprint(\"test loss, test acc:\", results)","76e586ac":"from sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sn\n\ny_pred = model.predict(X_test)\ny_pred = [1 if i >=.5 else 0 for i in y_pred]\n\ncm = confusion_matrix(y_test, y_pred)\ndf_cm = pd.DataFrame(cm, columns=np.unique(y_test), index = np.unique(y_test))\n\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\n\nplt.figure(figsize = (10,7))\nsn.set(font_scale=1.4)#for label size\nsn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16})# font size","07d174b0":"# Model\nLet's use ConvNets","a298be92":"# Model Evaluation","0802f384":"## Confusion Matrix","5083f19c":"# Exploratory Data Analysis\nLet's explore our data","116c5b88":"## Simple Evalution"}}