{"cell_type":{"9db86de6":"code","590181ce":"code","f46ab217":"code","8998c0ff":"code","b8b5f662":"code","df57ec30":"code","758c7625":"code","095906a6":"code","5a06f417":"code","40fab763":"code","efa3438c":"code","00dda679":"code","b7ad8800":"code","bded12f6":"code","5046d98e":"code","512ba5c7":"code","e0a101c7":"code","4248857e":"code","5bab0f76":"code","26fb538f":"code","c57e8304":"code","5922b47f":"code","f825a079":"code","c3243610":"code","88c611e4":"code","2807bdcd":"code","a15dcbf1":"code","618566cc":"code","68908198":"code","fe6b0241":"code","d78e49fa":"code","6e2d7282":"code","73c56701":"code","4bfb3bff":"code","4a21e28c":"code","dc48054c":"code","813b4218":"code","c29ec38b":"code","8fbb5edd":"code","1210cd21":"code","b8edccbb":"code","9579c9a5":"code","3c2b6206":"code","ec885924":"code","edd2d732":"code","2b63e9d4":"code","63c1347d":"code","b52ddb85":"code","dbdf3a30":"code","caff1ae5":"code","8e3db53f":"code","42dd4a75":"code","2106547e":"code","a97c9c5b":"code","d0ae3073":"code","022e2cf7":"code","29f56ef8":"code","d9dd6dcc":"code","44698b05":"markdown","0a22c979":"markdown","78d83cf1":"markdown","0d713e1b":"markdown","72373761":"markdown","8cfc0f4b":"markdown","e0a6ee58":"markdown","ad9f8656":"markdown","b75bf0ca":"markdown"},"source":{"9db86de6":"#1\n\n# Importing Required Packages\nimport pandas as pd\nimport warnings\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.layers import Conv1D\nimport wfdb                            \nfrom sklearn.model_selection import train_test_split\nfrom math import ceil\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import load_model\nfrom sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score,f1_score\nimport warnings\nwarnings.filterwarnings(\"ignore\") \nimport random\nimport torch\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import OneHotEncoder\n# Random Initialization\nrandom.seed(42)\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \nwarnings.filterwarnings('ignore') ","590181ce":"#2\n\n#Note Dont't Change any values here unless you want to train the models from a whole new level\n# In case you want to train all th emodels again the following parameters can be changed\n# num_catogeries-> It determines the number of differnt types of Arrhythmia to clasify \n#                  It can be chosen from 1 to 7 I have chosen 5 as default for training \n# is_train-> Its value must be changed to 1 if you want to train the models again \n\n\n# Parameter Values\nnum_sec = 3\nis_train=1\nfs = 360\nnum_cols=num_sec*fs*2\nnum_catogeries=13\ndata = '..\/input\/mit-bih-arrhythmia-database\/'\nmodel_input='..\/input\/trained-models\/'\nif(is_train):\n    model_input=\"\"","f46ab217":"#3\n\n# Non Beat Symbols\nnonbeat = ['[','!',']','x','(',')','p','t','u','`',\n           '\\'','^','|','~','+','s','T','*','D','=','\"','@','Q','?']\n# Abnormal Beat Symbols\nabnormal = ['L','R','V','\/','A','f','F','j','a','E','J','e','S']#removed S\nprint(len(abnormal))\n\n# abnormal=abnormal[0:num_catogeries]\n# Normal Beat Symbols\nnormal = ['N']\nint_to_category={y:x+1 for x,y in zip([k for k in range(len(abnormal))],abnormal)}\nint_to_category['N']=0\nint_to_category['NB']=14\ncatoegory_to_int={y:x for x,y in zip(int_to_category.keys(),int_to_category.values())}\ndescription={'NB':\"Not Beat\",'N':'Normal Beat','L':'Left bundle branch block beat','R':'Right bundle branch block beat','e':\"unknown_e\",'S':'Unknown S',\n             'V':'Premature ventricular contraction','\/':'Paced beat','A':'Atrial premature beat','f':'Fusion of paced and normal beat','F':'Fusion of ventricular and normal beat','J':'Nodal (junctional) premature beat','a':'Aberrated atrial premature beat','E':'Ventricular escape beat','j':'Nodal (junctional) escape beat','s':'Unknown Beat'}\ncatoegory_to_description={x:description[y] for x,y in zip(int_to_category.keys(),int_to_category.keys())}\nclr={0:'go',1:'bo',2:'co',3:'mo',4:'yo',5:'ko',6:'ro',7:'b+',8:'b+',9:'go',10:'bo',12:'co',13:'mo',14:'yo',15:'ko',16:'ro',17:'b+',11:'b+'}\nclrs={}\nfor i in range(len(abnormal)+2):\n    clrs[i]=clr[i]","8998c0ff":"#4\n\n# List of Patients\npatients = ['100','101','102','103','104','105','106','107',\n           '108','109','111','112','113','114','115','116',\n           '117','118','119','121','122','123','124','200',\n           '201','202','203','205','207','208','209','210',\n           '212','213','214','215','217','219','220','221',\n           '222','223','228','230','231','232','233','234']","b8b5f662":"#5\n\n# catoegory_to_int={1: 'L', 2: 'R', 3: 'V', 4: '\/', 5: 'A', 6: 'f', 7: 'F', 0: 'N', 8: 'NB'}\n# int_to_category={'L': 1, 'R': 2, 'V': 3, '\/': 4, 'A': 5, 'f': 6, 'F': 7, 'N': 0, 'NB': 8}\ndef build_X(file,num_cols,beam_value=5):\n    record = wfdb.rdrecord(file)\n    p_signal = record.p_signal        \n#     p_signal = p_signal[:,0]\n#     print(\"input length = \",len(p_signal))\n    \n    num_rows = (len(p_signal)\/\/num_cols)*beam_value\n#     print('Num Rows = ',num_rows)\n\n    X = np.zeros((num_rows, num_cols))\n    \n    # keep track of rows\n    max_row = 0\n    i=0\n    while i<=(len(p_signal)-num_cols-beam_value):\n        for k in range(beam_value):\n\n            left = i+k\n            right = min([len(p_signal),i+num_cols+k])\n            x = p_signal[left: right,0]\n            x_2=p_signal[left: right,1]\n            if len(x) == num_cols:\n                X[max_row,:] = x\n                max_row += 1\n#                 print('At row ',max_row)\n            i+=num_cols\n#     print('Output length = ',X.shape)\n    print('Returned X shape is ',X.shape)\n    return X","df57ec30":"\ndef predict_batch(model,batch_size,X):\n    shape=(X.shape[0],num_catogeries+2)\n#     print('Got x as ',X.shape)\n    res=np.ones(shape)\n    curr_batch=0;\n    for i in range(ceil(X.shape[0]\/batch_size)):\n        x=X[curr_batch*batch_size:min(X.shape[0],(curr_batch+1)*batch_size)]\n        preds=model.predict(x)\n#         print(\"Batch range = \",curr_batch*batch_size,\" to \",min(X.shape[0],(curr_batch+1)*batch_size))\n        res[curr_batch*batch_size:min(X.shape[0],(curr_batch+1)*batch_size)]=preds\n        curr_batch+=1\n        del(preds)\n    return res","758c7625":"#6\n\ndef predict_crnn(fold,batch_size,X):\n    shape=(X.shape[0],num_catogeries+2)\n#     print('Got x as ',X.shape)\n    res=np.ones(shape)\n    curr_batch=0;\n    model=load_model(model_input+'cnn_model_'+str(fold)+\".h5\")\n    for i in range(ceil(X.shape[0]\/batch_size)):\n        x=X[curr_batch*batch_size:min(X.shape[0],(curr_batch+1)*batch_size)]\n        preds=model.predict(x)\n#         print(\"Batch range = \",curr_batch*batch_size,\" to \",min(X.shape[0],(curr_batch+1)*batch_size))\n        res[curr_batch*batch_size:min(X.shape[0],(curr_batch+1)*batch_size)]=preds\n        curr_batch+=1\n        del(preds)\n    del(model)\n    return res","095906a6":"#7\n\ndef predict(pt,model_name,num_cols,n_split,beam_width=5):\n    x=build_X(pt,num_cols,beam_width)\n    if(model_name==\"cnn_model\"):\n        x=np.reshape(x, (x.shape[0], x.shape[1], 1))\n    if(model_name==\"dense_model\" or model_name==\"cnn_model\"or model_name==\"dense_model_custom\"):\n        y_pred=[]\n        for i in range(1,n_split+1):\n            print('Using model ',model_name+'_fold_'+str(i))\n            if(model_name==\"cnn_model\"):\n                preds=predict_crnn(i,32,x)\n                y_pred.append(preds)\n                del(preds)\n            elif (model_name=='dense_model_custom'):\n                model=load_model(model_input+model_name+\"_\"+str(i)+\".h5\")\n                preds=predict_batch(model,32,x)\n                y_pred.append(preds)\n                del(preds)\n                del(model)\n            else:\n                model=load_model(model_input+model_name+\"_\"+str(i)+\".h5\")\n                preds=model.predict(x)\n                y_pred.append(preds)\n                del(preds)\n                del(model)\n            \n        if n_split>1:\n            y_pred=np.mean(np.array(y_pred),axis=0)\n        else:\n            y_pred=np.array(y_pred)\n            y_pred=y_pred.reshape(y_pred.shape[1],-1)\n        y_pred=np.argmax(y_pred,axis=1)\n        res={}\n        i=0;\n        real_preds=[]\n        while(i<=y_pred.shape[0]-beam_width):\n            dict_res={x:0 for x in range(1,len(abnormal)+1)}\n            dict_res[len(abnormal)+1]=0\n            dict_res[0]=0\n            for k in range(beam_width):\n                dict_res[y_pred[i+k]]+=1\n            int_mx=[0,None]\n            for key,values in zip(dict_res.keys(),dict_res.values()):\n                if int_mx[0]!=0 and (key==0 or key==8):\n                    continue\n                if int_mx[0]<=values:\n                    int_mx=[values,key]\n            real_preds.append(int_mx[1])\n            i+=beam_width\n        for k in range(len(real_preds)):\n            res[str(k+1)]=catoegory_to_int[real_preds[k]]\n        return res;\n        \n    ","5a06f417":"#8\n\ndef plot_ecg_graph(file,model_name,num_cols,n_models=1,beam_width=1,rng=20000):\n    res=predict(file,model_name,num_cols,n_models,beam_width)\n    # Generating evenly spaced values\n    record = wfdb.rdrecord(file)\n    p_signal = record.p_signal        \n    ang=(len(p_signal))\n    x = np.arange(ang)\n    ind=len(res)\/\/2\n    vlu=ind*num_cols\n   \n    left = vlu-rng\n    right = vlu+rng\n\n    plt.figure(figsize=(20,8))\n    plt.plot(x[left:right],p_signal[left:right,0],'-',label='ecg',)\n    bool_leg=[0 for i in range(len(abnormal)+2)]\n    for key,value in zip(res.keys(),res.values()):\n        signal=int(key)*num_cols\n        plt.plot(x[signal],p_signal[signal,0],clrs[int_to_category[value]],label = catoegory_to_description[value] if bool_leg[int_to_category[value]] == 0 else \"\")\n        bool_leg[int_to_category[value]]=1\n    plt.xlim(left,right)\n    plt.ylim(p_signal[left:right].min()-0.05,p_signal[left:right,0].max()+0.05)\n    plt.xlabel('time index')\n    plt.ylabel('ECG signal')\n    plt.legend(bbox_to_anchor = (1.04,1), loc = 'upper left')\n    plt.show()","40fab763":"# #9\n\n# #You will need to call the below method to visualize ECG of the patient\n# # The parameters are\n# # file -> The ecg file (.dat) of the patient I have used file of patient 100 as example below the current input is \"..\/input\/mit-bih-arrhythmia-database\/100\" \n# #          make sure your custom input is something like this\n# # model_name -> The model you want to use currently supproted models are \"cnn_model\" and \"dense_model\"\n# # num_cols -> This is the size of the feature vector no need to change it unless trainig a new moel\n# # n_models -> This specifies the number of models of a kind you want to use for prediction for \"dense_model\" it can go\n# # upto 5 and for \"cnn_model\" it can go upto 4\n# #beam_width-> This parameter sets the beam_width of the beam search algorithm its default value is 1\n# #rng-> This parameter determines the number of signal you want to see in output its value can l;ie between 2000 to 200000\n\n\n# #Below I have shown example to predict the beat type of the ecg  of a patient\n# file=data+patients[0]\n# model_name='cnn_model'\n# plot_ecg_graph(file,model_name,num_cols,n_models=4,beam_width=1,rng=200000)","efa3438c":"# file=data+patients[10]\n# model_name='dense_model_custom'\n# plot_ecg_graph(file,model_name,2*fs*3*2,n_models=2,beam_width=1,rng=20000)","00dda679":"# file=data+patients[0]\n# model_name='cnn_model'\n# plot_ecg_graph(file,model_name,num_cols,n_models=4,beam_width=1,rng=80000)","b7ad8800":"# file=data+patients[12]\n# model_name='dense_model'\n# plot_ecg_graph(file,model_name,num_cols,n_models=5,beam_width=1,rng=120000)","bded12f6":"# file=data+patients[8]\n# model_name='dense_model'\n# plot_ecg_graph(file,model_name,num_cols,n_models=3,beam_width=1,rng=20000)","5046d98e":"# file=data+patients[18]\n# model_name='cnn_model'\n# plot_ecg_graph(file,model_name,num_cols,n_models=4,beam_width=1,rng=80000)","512ba5c7":"# Creating a Empty Dataframe\nsymbols_df = pd.DataFrame()\n\n# Reading all .atr files \nfor pts in patients:\n    # Generating filepath for all .atr file names\n    file = data + pts\n    # Saving annotation object\n    annotation = wfdb.rdann(file, 'atr')\n    # Extracting symbols from the object\n    sym = annotation.symbol\n    # Saving value counts\n    values, counts = np.unique(sym, return_counts=True)\n    # Writing data points into dataframe\n    df_sub = pd.DataFrame({'symbol':values, 'Counts':counts, 'Patient Number':[pts]*len(counts)})\n    # Concatenating all data points  \n    symbols_df = pd.concat([symbols_df, df_sub],axis = 0)","e0a101c7":"# Symbols Dataframe\nsymbols_df","4248857e":"# Value Counts of Different symbols in data\nsymbols_df.groupby('symbol').Counts.sum().sort_values(ascending = False)","5bab0f76":"symbols_df['category'] = -1\nsymbols_df.loc[symbols_df.symbol == 'N','category'] = 0\nfor i in range(len(abnormal)):\n    symbols_df.loc[symbols_df.symbol==abnormal[i], 'category'] = i+1","26fb538f":"# Value counts of different categories\nsymbols_df.groupby('category').Counts.sum()","c57e8304":"symbols_df.head(10)","5922b47f":"def load_ecg(file):    \n    # load the ecg\n    record = wfdb.rdrecord(file)\n    # load the annotation\n    annotation = wfdb.rdann(file, 'atr')\n    \n    # extracting the signal\n    p_signal = record.p_signal\n    p_mx_1=np.max(p_signal[:,0])\n    p_mx_2=np.max(p_signal[:,0])\n    p_mn_1=np.min(p_signal[:,0])\n    p_mn_2=np.min(p_signal[:,0])\n    print(\"Highest and lowes\",p_mx_1,p_mx_2,p_mn_1,p_mn_2)\n\n    # extracting symbols and annotation index\n    atr_sym = annotation.symbol\n    atr_sample = annotation.sample\n    \n    return p_signal, atr_sym, atr_sample","f825a079":"# Accessing the ecg points for \nfile = data + patients[8]","c3243610":"# Accessing the load ECG function and getting annotation.symbol, annotation.sample, signals\np_signal, atr_sym, atr_sample = load_ecg(file)","88c611e4":"p_signal.shape","2807bdcd":"atr_sample.shape","a15dcbf1":"len(atr_sym)","618566cc":"# Analysing annotations value counts for a single record\nvalues, counts = np.unique(sym, return_counts=True)\nfor v,c in zip(values, counts):\n    print(v,c)","68908198":"# get abnormal beat index\nab_index = [b for a,b in zip(atr_sym,atr_sample) if a in abnormal][:10]\nab_index","fe6b0241":"# Generating evenly spaced values\nx = np.arange(len(p_signal))\n\nleft = ab_index[5]-20000\nright = ab_index[5]+20000\n\nplt.figure(figsize=(20,8))\n# plt.plot(x[left:right],p_signal[left:right,0],'-',label='ecg1',)\nplt.plot(x[left:right],p_signal[left:right,1],'-',label='ecg2',)\nplt.plot(x[atr_sample],p_signal[atr_sample,1],'go',label ='normal')\nplt.plot(x[ab_index],p_signal[ab_index,1],'ro',label='abnormal')\n\nplt.xlim(left,right)\nplt.ylim(p_signal[left:right,1].min()-0.05,p_signal[left:right,1].max()+0.05)\nplt.xlabel('time index')\nplt.ylabel('ECG signal')\nplt.legend(bbox_to_anchor = (1.04,1), loc = 'upper left')\nplt.show()","d78e49fa":"def make_dataset(pts, num_sec, fs, abnormal):\n    # function for making dataset ignoring non-beats\n    # input:\n    #   pts - list of patients\n    #   num_sec = number of seconds to include before and after the beat\n    #   fs = frequency\n    # output: \n    #   X_all = signal (nbeats , num_sec * fs columns)\n    #   Y_all = binary is abnormal (nbeats, 1)\n    #   sym_all = beat annotation symbol (nbeats,1)\n    \n    # initialize numpy arrays\n    num_cols = 2*num_sec * fs*2\n    X_all = np.zeros((1,num_cols))\n    print(X_all.shape,'shape of X_all')\n    Y_all = np.zeros((1,1))\n    sym_all = []\n    \n    # list to keep track of number of beats across patients\n    max_rows = []\n    \n    for pt in pts:\n        file = data + pt\n        \n        p_signal, atr_sym, atr_sample = load_ecg(file)\n        \n        # grab the first signal\n#         p_signal = p_signal[:,0]\n        \n        # make df to exclude the nonbeats\n        df_ann = pd.DataFrame({'atr_sym':atr_sym,\n                              'atr_sample':atr_sample})\n        X,Y,sym = build_XY(p_signal,df_ann, num_cols, abnormal)\n        print(\"Returned X shape is \",X.shape)\n        sym_all = sym_all+sym\n        max_rows.append(X.shape[0])\n        X_all = np.append(X_all,X,axis = 0)\n        Y_all = np.append(Y_all,Y,axis = 0)\n        \n    # drop the first zero row\n    X_all = X_all[1:,:]\n    Y_all = Y_all[1:,:]\n\n    return X_all, Y_all, sym_all\n","6e2d7282":"# def build_XY(p_signal, df_ann, num_cols, abnormal):\n#     # this function builds the X,Y matrices for each beat\n#     # it also returns the original symbols for Y\n    \n#     num_rows = len(df_ann)\n\n#     X = np.zeros((num_rows, num_cols))\n#     Y = np.zeros((num_rows,1))\n#     sym = []\n    \n#     # keep track of rows\n#     max_row = 0\n\n#     for atr_sample, atr_sym in zip(df_ann.atr_sample.values,df_ann.atr_sym.values):\n\n#         left = max([0,(atr_sample - num_sec*fs) ])\n#         right = min([p_signal.shape[0],(atr_sample + num_sec*fs) ])\n#         x = p_signal[left: right]\n#         if len(x) == num_cols:\n#             X[max_row,:] = x\n#             if(atr_sym in abnormal or atr_sym=='N'):\n#                 Y[max_row,:] = int_to_category[atr_sym]\n#             else :\n#                 Y[max_row,:] = int_to_category['NB']\n#             sym.append(atr_sym)\n#             max_row += 1\n#     X = X[:max_row,:]\n#     Y = Y[:max_row,:]\n#     return X,Y,sym","73c56701":"def build_XY(p_signal, df_ann, num_cols, abnormal):\n    # this function builds the X,Y matrices for each beat\n    # it also returns the original symbols for Y\n    \n    num_rows = len(df_ann)\n\n    X = np.zeros((num_rows, num_cols))\n    Y = np.zeros((num_rows,1))\n    sym = []\n    \n    # keep track of rows\n    max_row = 0\n\n    for atr_sample, atr_sym in zip(df_ann.atr_sample.values,df_ann.atr_sym.values):\n\n        left = max([0,(atr_sample - num_sec*fs) ])\n        right = min([p_signal.shape[0],(atr_sample + num_sec*fs) ])\n        x_1 = p_signal[left: right,0]\n        x_2 = p_signal[left: right,1]\n        if len(x_1) == num_cols\/\/2:\n            X[max_row,0:num_cols\/\/2] = x_1\n            X[max_row,num_cols\/\/2:num_cols] = x_2\n            if(atr_sym in abnormal or atr_sym=='N'):\n                Y[max_row,:] = int_to_category[atr_sym]\n            else :\n                Y[max_row,:] = int_to_category['NB']\n            sym.append(atr_sym)\n            max_row += 1\n    X = X[:max_row,:]\n    Y = Y[:max_row,:]\n    return X,Y,sym","4bfb3bff":"# Accessing the fuction and creating a dataset with ECG digital Points\nX_all, Y_all, sym_all = make_dataset(patients, num_sec, fs, abnormal)","4a21e28c":"X_all.shape","dc48054c":"int_to_category","813b4218":"enc = OneHotEncoder(handle_unknown='ignore')\nenc.fit(Y_all)\ny_new=Y_all.copy()\ny_new=enc.transform(y_new).toarray()\n","c29ec38b":"y_new.shape","8fbb5edd":"import keras\nimport tensorflow_addons as tfa\nimport tensorflow as tf\ndef get_resnet_model():\n    def residual_block(X, kernels, stride):\n        out = keras.layers.Conv1D(kernels, stride, padding='same')(X)\n        out = keras.layers.ReLU()(out)\n        out = keras.layers.Conv1D(kernels, stride, padding='same')(out)\n        out = keras.layers.add([X, out])\n        out = keras.layers.ReLU()(out)\n        out = keras.layers.MaxPool1D(5, 2)(out)\n        return out\n\n    kernels = 32\n    stride = 5\n\n    inputs = keras.layers.Input((X_all.shape[1],1))\n    X = keras.layers.Conv1D(kernels, stride)(inputs)\n    X = residual_block(X, kernels, stride)\n    X = residual_block(X, kernels, stride)\n    X = residual_block(X, kernels, stride)\n    X = residual_block(X, kernels, stride)\n    X = residual_block(X, kernels, stride)\n    X = keras.layers.Flatten()(X)\n    X = keras.layers.Dense(512, activation='relu')(X)\n    X = keras.layers.Dense(32, activation='relu')(X)\n    output = keras.layers.Dense(15, activation='softmax')(X)\n\n    model = keras.Model(inputs=inputs, outputs=output)\n    optimizer = tf.keras.optimizers.Adam(lr=0.001)\n    model.compile(optimizer=optimizer, loss=tfa.losses.SigmoidFocalCrossEntropy(),metrics=['accuracy'])\n    return model","1210cd21":"mdl=get_resnet_model()\nmdl.summary()","b8edccbb":"# Relu for activation function and drop out for regularization\nimport tensorflow_addons as tfa\ndef dense_model():\n    model = Sequential()\n    model.add(Dense(32, activation = 'relu', input_dim = X_all.shape[1]))\n    model.add(Dropout(rate = 0.25))\n    model.add(Dense(num_catogeries+2, activation = 'softmax'))\n    model.compile(loss = tfa.losses.SigmoidFocalCrossEntropy(),\n                    optimizer = 'adam',\n                    metrics = ['accuracy'])\n    return model","9579c9a5":"mdls=dense_model()\nmdls.summary()","3c2b6206":"def print_report(y_actual, y_pred):\n    auc = roc_auc_score(y_actual, y_pred ,multi_class=\"ovr\",average=\"weighted\")\n    y_actual=np.argmax(y_actual,axis=1)\n    y_pred=np.argmax(y_pred,axis=1)\n    print(y_actual.shape,\" \",y_pred.shape)\n    # Function to print evaluation metrics\n    \n    accuracy = accuracy_score(y_actual, y_pred)\n    recall = recall_score(y_actual, y_pred,average=\"weighted\")\n    precision = precision_score(y_actual,y_pred,average=\"weighted\")\n    f1_score_all=f1_score(y_actual,y_pred,average=None)\n    f1_score_wt=f1_score(y_actual,y_pred,average=\"weighted\")\n    print('AUC:%.3f'%auc)\n    print('Accuracy:%.3f'%accuracy)\n    print('Recall:%.3f'%recall)\n    print('Precision:%.3f'%precision)\n    print('F1 Score Full :',f1_score_all)\n    print('F1 Score Weighted :%.3f'%f1_score_wt)\n    print(' ')\n    return auc, accuracy, recall, precision, f1_score_all,f1_score_wt","ec885924":"\ndef predict_batch(model,batch_size,X):\n    shape=(X.shape[0],num_catogeries+2)\n#     print('Got x as ',X.shape)\n    res=np.ones(shape)\n    curr_batch=0;\n    for i in range(ceil(X.shape[0]\/batch_size)):\n        x=X[curr_batch*batch_size:min(X.shape[0],(curr_batch+1)*batch_size)]\n        preds=model.predict(x)\n#         print(\"Batch range = \",curr_batch*batch_size,\" to \",min(X.shape[0],(curr_batch+1)*batch_size))\n        res[curr_batch*batch_size:min(X.shape[0],(curr_batch+1)*batch_size)]=preds\n        curr_batch+=1\n        del(preds)\n    return res","edd2d732":"X_all.shape","2b63e9d4":"# Fitting the model\ndef fit_model(model_name,batch_size,X_all,Y_all,eph,n_split):\n    i=1\n    kfold = StratifiedKFold(n_splits=n_split, shuffle=True, random_state=1)\n    for train_ix, test_ix in kfold.split(X_all, Y_all):\n        train_X, test_X = X_all[train_ix], X_all[test_ix]\n        train_y, test_y = Y_all[train_ix], Y_all[test_ix]\n        train_y=enc.transform(train_y).toarray()\n        test_y=enc.transform(test_y).toarray()\n        if(model_name==\"dense_model\"):\n            model=dense_model()\n        elif model_name=='resnet_model':\n            model=get_resnet_model()\n        else :\n            model=cnn_model()\n        print('Train_X shape is ',train_X.shape,' train_y shape is ',train_y.shape)\n        model.fit(train_X, train_y, batch_size = batch_size, epochs= eph, verbose = 1)\n        print(\"Done Training Model\\nRunning Evaluation.... \")\n        y_train_preds_dense = predict_batch(model,512,train_X)\n        y_test_preds_dense = predict_batch(model,512,test_X)\n        print('Shape of preds = ',y_test_preds_dense.shape)\n\n        print('On Train Data')\n        print_report(train_y, y_train_preds_dense)\n        print('On Valid Data')\n        print_report(test_y, y_test_preds_dense)\n        print(\"Done Evaluating Model\\nSaving Model.... \")\n        model.save(model_name+\"_custom_\"+str(i)+\".h5\")\n        del(model)\n        i+=1\n        print(\"Saved Model\")\n    \n","63c1347d":"fit_model('dense_model',100,X_all,Y_all,10,2)","b52ddb85":"# X_cnn = np.reshape(X_all, (X_all.shape[0], X_all.shape[1], 1))","dbdf3a30":"# X_cnn.shape","caff1ae5":"# fit_model('resnet_model',32,X_cnn,Y_all,2,2)","8e3db53f":"def predict_test(test_file,num_categories,num_columns,model_name,pair_to_use):\n    # test_file must be a csv file of format ecg1,arthimidya_label(all 0 initailly),ecg2,ecg3\n    # I will be using 2 readings based on variable pair to use \n    # pair_to_use =1 chooses the pair of ecg1 and ecg2\n    # pair_to_use =2 chooses the pair of ecg1 and ecg3\n    # pair_to_use =3 chooses the pair of ecg2 and ecg3\n    test_data=pd.read_csv(test_file)\n    reading_1=[]\n    reading_2=[]\n    if pair_to_use==1:\n        reading_1=test_data.ecg_1\n        reading_2=test_data.ecg_2\n    elif pair_to_use==2:\n        reading_1=test_data.ecg_1\n        reading_2=test_data.ecg_3\n    else :\n        reading_1=test_data.ecg_2\n        reading_2=test_data.ecg_3\n    reading_1=np.array(reading_1)\n    reading_2=np.array(reading_2)\n    p_mx_1=np.max(reading_1)\n    p_mx_2=np.max(reading_2)\n    p_mn_1=np.min(reading_1)\n    p_mn_2=np.min(reading_2)\n    print(\"Highest and lowes\",p_mx_1,p_mx_2,p_mn_1,p_mn_2)\n\n    print(type(reading_1),\" shape of readin 1 is \",reading_1.shape)\n#     model=load_model(model_name)\n    X=np.ones((reading_1.shape[0],num_columns))\n    print('Shape of X is ',X.shape)\n    print(\"Range of iter is \",reading_1.shape[0])\n    x_1=reading_1[0:num_columns\/\/2]\n    x_2=reading_2[0:num_columns\/\/2]\n    for i in range(num_columns\/\/4):\n        X[i,0:num_columns\/\/2]=x_1\n        X[i,0:num_columns\/\/2]=x_2\n    for i in range(num_columns\/\/4,reading_1.shape[0]-num_columns\/\/4):\n        left=max(0,i-num_columns\/\/4)\n        right=min(i+num_columns\/\/4,reading_1.shape[0])\n        rng_left=i-left+1\n        rng_right=right-i-1\n        x_1=reading_1[left:right]\n        x_2=reading_2[left:right]\n#         print('Shape of x1 and x2 are ',x_1.shape,\" \",x_2.shape,\" left ,right are \",left,\" \",right)\n        X[i,0:num_columns\/\/2]=x_1\n        X[i,0:num_columns\/\/2]=x_2\n#         if i==1090 :\n#             break\n    x_1=reading_1[reading_1.shape[0]-num_columns\/\/4:]\n    x_2=reading_2[reading_1.shape[0]-num_columns\/\/4:]\n    for i in range(reading_1.shape[0]-num_columns\/\/4,num_columns):\n        X[i,0:num_columns\/\/2]=x_1\n        X[i,0:num_columns\/\/2]=x_2\n    print(\"Formed dataset Shape is \",X.shape)\n    model=load_model(model_name)\n    res=predict_batch(model,512,X)\n    res=np.argmax(res,axis=1)\n    print(\"Shape of results is \",res.shape)\n    real_preds=[]\n    for i in range(res.shape[0]):\n        real_preds.append(catoegory_to_int[res[i]])\n    print('Len of real_preds = ',len(real_preds))\n    print(\"SAMPLE \/n\",real_preds[0:5])\n    r_1=np.array(test_data.ecg_1)\n#     r_1=r_1[num_columns\/\/4:r_1.shape[0]-num_columns\/\/4]\n    r_1=list(r_1)\n    r_2=np.array(test_data.ecg_2)\n#     r_2=r_2[num_columns\/\/4:r_2.shape[0]-num_columns\/\/4]\n    r_2=list(r_2)\n    r_3=np.array(test_data.ecg_3)\n#     r_3=r_3[num_columns\/\/4:r_3.shape[0]-num_columns\/\/4]\n    r_3=list(r_3)\n    dict_final={'ecg_1':r_1,'arthimydia_id':real_preds,'ecg_2':r_2,'ecg_3':r_3}\n    df_ans=pd.DataFrame(dict_final)\n    df_ans.to_csv('res.csv')\n    return X\n            \n        \n    ","42dd4a75":"X_test=predict_test(\"..\/input\/trained-models\/HumanTest_TXT File 01.csv\",num_catogeries,4320,'.\/dense_model_custom_1.h5',1)","2106547e":"# X_test.shape","a97c9c5b":"# def plot_ecg_custom(result_file,vlu,rng):\n#     res_df=pd.read_csv(result_file)\n#     ecg_1=res_df.ecg_1\n#     ecg_2=res_df.ecg_2\n#     ecg_3=res_df.ecg_3\n#     res_ar=res_df.arthimydia_id\n#     print('Shape of results are ',res_ar.shape)\n#     rd_1=[i for i in range(ecg_1.shape[0])]\n#     res=zip(rd_1,res_ar)\n#     res=dict(res)\n#     print(\"lengthof results is\",len(res))\n#     ang=(ecg_1.shape[0])\n#     x = np.arange(ang)\n# #     ind=len(res)\/\/2\n# #     vlu=ind*num_cols\n#     p_signal=np.ones((ecg_1.shape[0],2))\n#     p_signal[:,0]=ecg_1\n#     p_signal[:,0]=ecg_2\n#     print(p_signal.shape,\" Shape of formed part\")\n#     left = vlu-rng\n#     right = vlu+rng\n#     plt.figure(figsize=(20,8))\n#     plt.plot(x[left:right],p_signal[left:right,0],'-',label='ecg',)\n#     bool_leg=[0 for i in range(num_catogeries+2)]\n#     for key,value in zip(ecg_1,res_ar):\n#         signal=int(key)\n#         plt.plot(x[signal],p_signal[signal,0],clrs[int_to_category[value]],label = catoegory_to_description[value] if bool_leg[int_to_category[value]] == 0 else \"\")\n#         bool_leg[int_to_category[value]]=1\n#     plt.xlim(left,right)\n#     plt.ylim(p_signal[left:right].min()-0.05,p_signal[left:right,0].max()+0.05)\n#     plt.xlabel('time index')\n#     plt.ylabel('ECG signal')\n#     plt.legend(bbox_to_anchor = (1.04,1), loc = 'upper left')\n#     plt.show()\n\n    ","d0ae3073":"# plot_ecg_custom('.\/res.csv',12000,500)","022e2cf7":"# # reshape input to [samples, time steps, features = 1] for CNN\n# X_cnn = np.reshape(X_all, (X_all.shape[0], X_all.shape[1], 1))\n# print(X_cnn.shape)\n","29f56ef8":"# def cnn_model():\n\n# # Relu for activation function & Dropout for reducing overfitting by randomly removing some nodes.\n#     model = Sequential()\n#     model.add(Conv1D(filters = 128, kernel_size = 5, activation = 'relu', input_shape = (X_all.shape[1],1)))\n#     model.add(Dropout(rate = 0.25))\n#     model.add(Flatten())\n#     model.add(Dense(num_catogeries+2, activation = 'softmax'))\n\n# # compile the model with binary crossentropy, and the adam optimizer\n#     model.compile(loss = tfa.SigmoidFocalCrossEntrophy(),\n#                     optimizer = 'adam',\n#                     metrics = ['accuracy'])\n#     return model\n","d9dd6dcc":"\n# fit_model('cnn_model',24,X_cnn,Y_all,2,2)","44698b05":"# **Training Models**","0a22c979":"***The Cnn Model Performs Best On The Dataset***","78d83cf1":"# **Analysing Data**\nNote Training Part of Notebook Begins","0d713e1b":"**Convolutional Neural Networks(CNN)**","72373761":"# **Data Loading **\n","8cfc0f4b":"# **Data Preprocessing**","e0a6ee58":"# **Data Visualization**","ad9f8656":"**Dense Neurel Network**","b75bf0ca":"<center><h1 class=\"list-group-item list-group-item-success\">Arrhythmia Detection<\/h1><\/center>"}}