{"cell_type":{"8aa528b5":"code","b1f346ca":"code","fe4adf56":"code","3958576a":"code","9714ad2d":"code","710772e2":"code","6f1a489d":"code","d539dbbb":"code","4eb4f29a":"code","9a6aa680":"code","12cbd971":"code","ff178844":"code","fc4310e7":"code","e25426ca":"code","31b50023":"code","2c4b245e":"code","856e4251":"code","40fbeb17":"code","cdd0b77d":"code","ebdb4021":"code","5331971b":"code","491d4f85":"code","e9972227":"code","957c571a":"markdown","a0047802":"markdown"},"source":{"8aa528b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b1f346ca":"os.chdir(\"..\/input\")\nos.listdir()","fe4adf56":"df=pd.read_csv(\"..\/input\/qsarbiodegradation\/qsar-biodeg.csv\")","3958576a":"from warnings import filterwarnings\nfilterwarnings('ignore')","9714ad2d":"df.head()","710772e2":"df.info()","6f1a489d":"df.isnull().sum()","d539dbbb":"df[\"Class\"].value_counts() \n# eady biodegradable (RB) and not ready biodegradable (NRB)\n# RB:2 NRB:1","4eb4f29a":"df.Class=[1 if each ==2 else 0 for each in df.Class]","9a6aa680":"df[\"Class\"].value_counts() \n# eady biodegradable (RB) and not ready biodegradable (NRB)\n# RB:1 NRB:0","12cbd971":"y = df[\"Class\"].values\nX = df.drop(['Class'], axis=1)","ff178844":"# Data Standardization\nfrom sklearn.preprocessing import StandardScaler\nScaler=StandardScaler()\nX=Scaler.fit_transform(X)","fc4310e7":"from sklearn.model_selection import train_test_split\n# shuffle and split training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,\n                                                    random_state=42)\n# Multi Layer Perceptron Artificial Neural Network\nfrom sklearn.neural_network import MLPClassifier \n\n# Setting up a primitive (non-validated) model\nmlpc = MLPClassifier(random_state = 0)# ANN model object created\n\nmlpc.fit(X_train, y_train) # ANN model object fit","e25426ca":"# Forecasting on the Unvalidated Model\ny_pred = mlpc.predict(X_test) # model prediction process over test set","31b50023":"import sklearn.metrics as metrics\n\n# Accuracy\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n\n# f1 score\n\nprint(\"f1_weighted:\",metrics.f1_score(y_test, y_pred,average='weighted'))","2c4b245e":"# Cross Validation Process\n# Parameters for CV created in dictionary structure\n# INFORMATION ABOUT THE INPUTED PARAMETERS\n# alpha: float, default = 0.0001 L2 penalty (regularization term) parameter. (penalty parameter)\n   \nmlpc_params = {\"alpha\": [0.1, 0.01, 0.001, 0.0001],\n              \"hidden_layer_sizes\": [(10,),\n                                     (5,32,40),\n                                     (100,100,100),],\n              \"solver\" : [\"lbfgs\",\"adam\",\"sgd\"],\n              \"activation\": [\"relu\",\"logistic\"]}\n\nfrom sklearn.model_selection import GridSearchCV\n\n\n\n\nmlpc = MLPClassifier(random_state = 0) # ANN model object created\n\n# Model CV process \nmlpc_cv_model = GridSearchCV(mlpc, mlpc_params, \n                         cv = 5, # To make a 5-fold CV\n                         n_jobs = -1, # Number of jobs to be run in parallel (-1: means to use all processors)\n                         verbose = 2) # Controls the level of detail: higher means more messages gets value as integer.\n\nmlpc_cv_model.fit(X_train, y_train) \n\n\n# The best parameter obtained as a result of CV process\n\nprint(\"The best parameters: \" + str(mlpc_cv_model.best_params_))","856e4251":"# Setting the Final Model with the best parameter\n\nmlpc_tuned = mlpc_cv_model.best_estimator_\n\n# Fitting Final Model\nmlpc_tuned.fit(X_train, y_train)","40fbeb17":"# K-fold f1_weighted\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n# K fold\nkf = KFold(shuffle=True, n_splits=5) # To make a 5-fold CV\n\ncv_results_kfold = cross_val_score(mlpc_tuned, X_test, y_test, cv=kf, scoring= 'f1_weighted')\n\nprint(\"K-fold Cross Validation f1_weigted Results: \",cv_results_kfold)\nprint(\"K-fold Cross Validation f1_weigted Results Mean: \",cv_results_kfold.mean())\n","cdd0b77d":"# K-fold accuracy\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n# K fold\nkf = KFold(shuffle=True, n_splits=5) # To make a 5-fold CV\n\ncv_results_kfold = cross_val_score(mlpc_tuned, X_test,y_test, cv=kf, scoring= 'accuracy')\n\nprint(\"K-fold Cross Validation accuracy Results: \",cv_results_kfold)\nprint(\"K-fold Cross Validation accuracy Results Mean: \",cv_results_kfold.mean())","ebdb4021":"# Tune Model Prediction\n# Prediction process of Final Model over test set\ny_pred = mlpc_tuned.predict(X_test)\n# Accuracy and f1_weighted value of Final Model\n\n# %% f1 score\nimport sklearn.metrics as metrics\nprint(\"f1_weighted:\",metrics.f1_score(y_test, y_pred,average='weighted'))\n\n# %% Accuracy\n\nprint(\"accuracy:\",metrics.accuracy_score(y_test, y_pred))","5331971b":"#%% Confusion Matrix and Classification Report\nfrom sklearn.metrics import confusion_matrix, classification_report \n\n# Classification Report\nmodel_report = classification_report(y_test, y_pred)\nprint(model_report)","491d4f85":"# Confusion Matrix\n# multilabel-indicator is not supported so np.argmax should be used!\nmodel_conf = confusion_matrix(y_test,y_pred)\nprint(model_conf)","e9972227":"#%% ROC-AUC Curve\nimport matplotlib.pyplot as plt\n\n\n\nprobs=mlpc_tuned.predict_proba(X_test)\nfpr,tpr,threshold=metrics.roc_curve(y_test,y_pred)\nroc_auc=metrics.auc(fpr,tpr)\n\n\n\n\nplt.title(\"ROC\")\nplt.plot(fpr,tpr,label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy',  linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","957c571a":"## Grid Search Cross Validation","a0047802":"## Modeling"}}