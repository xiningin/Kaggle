{"cell_type":{"d030cded":"code","65e8ddf7":"code","02128f16":"code","ddcc379a":"code","ae9e8593":"code","63fe93ef":"code","4e556774":"code","f5cafb3e":"code","a5d839f0":"code","731e1934":"code","8eb06f7c":"code","ad29ba77":"code","a09c2d01":"code","d575c49d":"code","8c072dfa":"code","63356bf6":"code","c91c143e":"markdown","a60b66fb":"markdown","4928e943":"markdown","acd90195":"markdown","239aa9df":"markdown","0d523584":"markdown","aa3776b6":"markdown","6d4d45e9":"markdown","55f1ab1b":"markdown","8fcb0235":"markdown","245c5ffa":"markdown","7c0db662":"markdown","4adfe085":"markdown","717ffbea":"markdown","3f231d17":"markdown","78255250":"markdown","a3ec8d24":"markdown"},"source":{"d030cded":"# Basic\nimport numpy as np \nimport pandas as pd\n\n# Plotting\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# Splitting\nfrom sklearn.model_selection import train_test_split\n\n# Import models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\n# Evaluation metrics\nfrom sklearn.metrics import jaccard_score, f1_score, log_loss, accuracy_score, confusion_matrix, classification_report, roc_auc_score\n\n# Cross validation\nfrom sklearn.model_selection import cross_val_score","65e8ddf7":"records = pd.read_csv('\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv', index_col=False)\nprint(records.shape)\nrecords.head(3)","02128f16":"records.info()","ddcc379a":"records.describe()","ae9e8593":"records.isna().sum()","63fe93ef":"records_corr = records.corr()\nplt.figure(figsize=(14,12))\nsns.heatmap(records_corr, annot=True)\nplt.title('Correlation between features')\nplt.show()","4e556774":"records_corr['DEATH_EVENT'].sort_values(ascending = False)","f5cafb3e":"X = records[['serum_creatinine', 'age', 'time', 'ejection_fraction', 'serum_sodium']].values\ny = records.iloc[:, -1].values\n\nprint('Shape of X ', X.shape)\nprint('Shape of y ', y.shape)","a5d839f0":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n\nprint('Shape of training set ', X_train.shape)\nprint('Shape of test set ', X_test.shape)","731e1934":"classifiers = [XGBClassifier(), LogisticRegression(max_iter=1000), KNeighborsClassifier(n_neighbors = 10, metric='minkowski', p=2), SVC(kernel = 'linear'), SVC(kernel = 'rbf'), DecisionTreeClassifier(criterion='entropy'), RandomForestClassifier(n_estimators = 10, criterion = 'entropy')]\n\nfor classifier in classifiers:\n    classifier.fit(X_train, y_train)\n    y_pred = classifier.predict(X_test)\n    \n    # print classifier name\n    print(str(type(classifier)).split('.')[-1][:-2])\n    \n    # Accuracy Score\n    print('Accuracy Score: {}'.format(accuracy_score(y_test, y_pred)))\n    \n    # jaccard Score\n    print('\\nJaccard Score: {}'.format(jaccard_score(y_test, y_pred)))\n    \n    # F1 score\n    print('\\nF1 Score: {}'.format(f1_score(y_test, y_pred)))\n    \n    # Log Loss\n    print('\\nLog Loss: {}'.format(log_loss(y_test, y_pred)))\n    \n    print('CROSS VALIDATION')\n    accuracy = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv=10)\n    print('Accuracies after CV: ', accuracy)\n    print('Mean Accuracy of the model: ', accuracy.mean()*100)\n    \n    # confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    sns.heatmap(cm, annot=True, lw = 2, cbar=False)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix: {}'.format(str(type(classifier)).split('.')[-1][:-2]))\n    plt.show()","8eb06f7c":"classifier = KNeighborsClassifier(n_neighbors = 10, metric='minkowski', p=2)\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\n\nprint(classification_report(y_test, y_pred))\n\nprint('ROC-AUC Score: ',roc_auc_score(y_test, y_pred))","ad29ba77":"# confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, lw = 2, cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix: {}'.format(str(type(classifier)).split('.')[-1][:-2]))\nplt.show()","a09c2d01":"acc=[]\nfor i in range(1, 20):\n    y_p = KNeighborsClassifier(n_neighbors=i, metric='minkowski', p=2).fit(X_train, y_train).predict(X_test)\n    \n    acc.append(accuracy_score(y_test, y_p))","d575c49d":"plt.figure(figsize=(10,8))\nplt.scatter(np.arange(1,20, step=1), acc)\nplt.xticks(np.arange(1,20, step=1))\nplt.grid(b=True, which='major', axis='both', color='#999999', linestyle='-', alpha=0.1)","8c072dfa":"classifier = KNeighborsClassifier(n_neighbors = 6, metric='minkowski', p=2)\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\n\nprint(classification_report(y_test, y_pred))\n\nprint('ROC-AUC Score: ',roc_auc_score(y_test, y_pred))\nprint('Accuracy: ', accuracy_score(y_test, y_pred)*100)","63356bf6":"# confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, lw = 2, cbar=False)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix: {}'.format(str(type(classifier)).split('.')[-1][:-2]))\nplt.show()","c91c143e":"### Future Work","a60b66fb":"## Final Model","4928e943":"## Tuning Hyperparameter","acd90195":"## Model Training","239aa9df":"### Model Selection","0d523584":"EDA was not implemented in this notebook as I wanted to run quick classification models to see the results. Further work will include that.","aa3776b6":"**We can see that the model on tuning the hyperparameters performs the best when 'n_neighbours' is 6**","6d4d45e9":"## Quick correlation check","55f1ab1b":"There are no null values in the dataset. All the data is in the right format. We are good to go forward!","8fcb0235":"Do comment and let me know if it was of some help or if I could improve in these quick modelling.","245c5ffa":"We can see that the **KNeighbors Classifier** gives us good results overall. Let's see if we can better the performance of this model.","7c0db662":"We can see columns:\n1. 'serum_creatinine' and \n2. 'age'\n\nshow a **positive significant correlation** with the Heart Failure Status\n\nColumns:\n1. 'time'\n2. 'ejection_fraction'\n3. 'serum_sodium'\n\nshow a **negative significant correlation** with the Heart Failure Status.","4adfe085":"Let us first implement the KNeighbors Classification model separately.","717ffbea":"### Model Construction and Evaluation (CV)","3f231d17":"Check the correlation of all features which just the 'DEATH_EVENT' result","78255250":"## Conclusion","a3ec8d24":"We can see our accuracy of the model was bumped up from 90% to 93% by hyperparameter tuning. We also saw that there were 5 significant features that helped predicting the death event."}}