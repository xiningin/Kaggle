{"cell_type":{"758363c7":"code","6019d765":"code","e906a70f":"code","a8841c14":"code","91c4561b":"code","0df92c31":"markdown","85ad0a11":"markdown"},"source":{"758363c7":"# Downloading nltk packages\nimport nltk\nnltk.download('all')","6019d765":"# importing Dataset\nimport pandas as pd\ndf=pd.read_csv('.\/..\/input\/sms-spam-collection-dataset\/spam.csv',usecols=['v1','v2'], encoding='latin-1')\ndf.head()","e906a70f":"import nltk\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\nimport re\ncorpus=[]\n\n# Get all the sentences from the 2nd column\nsentences=df.v2\n\n# I am using stemming for classification\nstemmer=PorterStemmer()\n\n# Loop over all the sentences\nfor i in range(len(sentences)):\n  # Remove non - alphabetical characters from the sentence\n  sent=re.sub('[^A-Za-z]',' ',sentences[i])\n  # Lower the sentence\n  sent=sent.lower()\n  # Convert the sentence to a list of words\n  words=nltk.word_tokenize(sent)\n  # Stem each word which is not in stopwords\n  words=[stemmer.stem(word) for word in words if word not in stopwords.words('english')]\n  # rejoin the sentence\n  sent=' '.join(words)\n  # add the sentence to the corpus\n  corpus.append(sent)\n# One hot encoding the target column i.e,1st column\ny=pd.get_dummies(df.v1,drop_first=True)","a8841c14":"import numpy as np\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# The dataset is imbalanced\n# Random oversampling duplicates examples from the minority class in the training dataset\nfrom imblearn.over_sampling import RandomOverSampler\nos=RandomOverSampler(0.93)\nX_train_ns,y_train_ns=os.fit_resample(np.array(corpus).reshape((-1,1)),(y.values))\n\n# PLotting the original Spam : Non Spam distribution\nprint(\"original Spam : Non Spam distribution 'Imbalanced'\",Counter((y.values).reshape((1,-1))[0]))\nplt.hist(((y.values).reshape((1,-1))[0]),bins=3)\nplt.title(\"original Spam : Non Spam distribution 'Imbalanced'\")\nplt.show()\n\n# PLotting the Randomly Oversampled Spam : Non Spam distribution\nprint(\"Randomly Oversampled Spam : Non Spam distribution 'Balanced'\",Counter((y_train_ns).reshape((1,-1))[0]))\nplt.hist((y_train_ns).reshape((1,-1))[0],bins=3)\nplt.title(\"Randomly Oversampled Spam : Non Spam distribution 'Balanced'\")\nplt.show()\n\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv=CountVectorizer(ngram_range=(1,2),max_features=5000)\nX_train_ns=cv.fit_transform(np.array(X_train_ns).ravel()).toarray()","91c4561b":"# Making a trian test split\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X_train_ns,y_train_ns,test_size=0.2,random_state=42)\n\n# Using Naive bayes Calssifier\nfrom sklearn.naive_bayes import GaussianNB\ng=GaussianNB()\ng.fit(X_train_ns,y_train_ns)\ny_pred=g.predict(X_test)\n\nfrom sklearn.metrics import accuracy_score,classification_report,f1_score,confusion_matrix\nprint(\"Accuracy of the model ==>\",accuracy_score(y_test,y_pred))\nprint(\"classification_report ==>\\n\",classification_report(y_test,y_pred))\nprint(\"f1_score==>\",f1_score(y_test,y_pred))\nprint(\"Confusion Matrix ==>\\n\",confusion_matrix(y_test,y_pred),)\nsns.heatmap(confusion_matrix(y_test,y_pred),annot=True)\nplt.show()","0df92c31":"# Lets gooo \ud83d\ude80.... We got a model with testing accuracy 99.7%","85ad0a11":"# Upvote if Like the Work \ud83d\ude0b"}}