{"cell_type":{"ef2f572d":"code","4a7dbf41":"code","622c8011":"code","ee042ffb":"code","480e4eeb":"code","85d3df42":"code","da266f9d":"code","25a537cc":"code","005f4cb9":"code","99610dd4":"code","92726dcc":"code","f59026a0":"code","ad01f616":"code","e23d5e61":"code","6e341aaf":"code","3656c823":"code","64590672":"code","4f0a4bca":"code","2d8dbdfb":"code","b63753a3":"code","7074f3ce":"code","dc0e53ec":"markdown","bdc1b519":"markdown","fd0bf033":"markdown","a65efd22":"markdown","dc9a1eef":"markdown","0ce2559e":"markdown","403e0d06":"markdown","48faab5a":"markdown","4780eec6":"markdown","fe183daa":"markdown","7705a4b5":"markdown","7bdb8c24":"markdown","cb391b0c":"markdown","2d228478":"markdown","885ad239":"markdown","c4f0f05d":"markdown","9de9bb99":"markdown"},"source":{"ef2f572d":"# Importing the required libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\nimport cv2\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import train_test_split\n\nimport keras\nfrom keras import layers\nfrom keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, Dense, Dropout, Flatten\nfrom keras.models import Sequential","4a7dbf41":"# Importing and Processing the dataset\n\ntrain_dir = '..\/input\/train\/'\n\ntrain_images = []\ntrain_labels = []\n\nfor img in tqdm(os.listdir(train_dir)):\n    try:\n        img_r = cv2.imread(os.path.join(train_dir, img), cv2.IMREAD_GRAYSCALE)\n        train_images.append(np.array(cv2.resize(img_r, (50, 50), interpolation=cv2.INTER_CUBIC)))\n        if 'dog' in img:\n            train_labels.append(1)\n        else:\n            train_labels.append(0)\n    except Exception as e:\n        print('broken image')\n","622c8011":"# Visualising the image\n\nplt.title(train_labels[0])\n_ = plt.imshow(train_images[0])","ee042ffb":"x_train, x_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)","480e4eeb":"x_train = np.array(x_train)\nx_test = np.array(x_test)","85d3df42":"print(\"Train Shape:\" + str(x_train.shape))\nprint(\"Test Shape:\" + str(x_test.shape))","da266f9d":"plt.title(y_train[0])\n_ = plt.imshow(x_train[0])","25a537cc":"def baseline_model():\n    model = Sequential()\n    \n    model.add(Conv2D(32, (3, 3), input_shape=(50, 50, 1), activation='relu'))\n    model.add(Conv2D(32, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    \n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    \n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    \n    model.add(Dropout(0.2))\n\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    \n    model.add(Dropout(0.2))\n    \n    model.add(Dense(1, activation='sigmoid'))\n    \n    return model","005f4cb9":"model = baseline_model()","99610dd4":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","92726dcc":"model.summary()","f59026a0":"x_train = x_train.reshape(-1, 50, 50, 1)\nx_test = x_test.reshape(-1, 50, 50, 1)","ad01f616":"history = model.fit(np.array(x_train), y_train, validation_data=(np.array(x_test), y_test), epochs=20, verbose=1)","e23d5e61":"hist = history.history","6e341aaf":"plt.plot(hist['loss'], 'green', label='Training Loss')\nplt.plot(hist['val_loss'], 'blue', label='Validation Loss')\n_ = plt.legend()","3656c823":"plt.plot(hist['acc'], 'green', label='Training Accuracy')\nplt.plot(hist['val_acc'], 'blue', label='Validation Accuracy')\n_ = plt.legend()","64590672":"test_dir = '..\/input\/test\/'\ntest_images = []\n\nfor img in tqdm(os.listdir(test_dir)):\n    try:\n        img_r = cv2.imread(os.path.join(test_dir, img), cv2.IMREAD_GRAYSCALE)\n        test_images.append(np.array(cv2.resize(img_r, (50, 50), interpolation=cv2.INTER_CUBIC)))\n    except Exception as e:\n        print('broken image')","4f0a4bca":"_ = plt.imshow(test_images[0])","2d8dbdfb":"test_images = np.array(test_images)\ntest_images = test_images.reshape(-1, 50, 50, 1)\npredictions = model.predict(test_images)","b63753a3":"predictions.shape","7074f3ce":"counter = range(1, len(test_images) + 1)\nsolution = pd.DataFrame({\"id\": counter, \"label\":list(predictions)})\ncols = ['label']\n\nfor col in cols:\n    solution[col] = solution[col].map(lambda x: str(x).lstrip('[').rstrip(']')).astype(float)\n\nsolution.to_csv(\"dogsVScats.csv\", index = False)\n","dc0e53ec":"# Cats and Dogs","bdc1b519":"In this kernel we will be training a CNN model in Keras to identify if the image have a cat or a dog. We have a dataset of 25000 images dogs and cats and we will use that to train our model for predicting results","fd0bf033":"Let's import our dataset. We will read images one by one from the **train_dir** and will store them in the **train_images** array. Each image is read in Grayscale and will be resized to (50, 50).\n\n**train_labels** will store the labels for each of the images.","a65efd22":"Finally we will import the test data to make predictions. Note that this is not the same test data set which we created by splitting our training set. That dataset is usually referred as **validation** set. We use validation set to make sure that our model is not overfitting the training data.","dc9a1eef":"# Step 3:\n## Evaluating results and Making Predictions","0ce2559e":"Now, let's visualise the images in our dataset. As you can see in the bottom we have an image of a cute little kitty. Though, it's not very clear to us but model will not have much problems while learning from this image.","403e0d06":"# Step 2:\n## Creating the CNN Model","48faab5a":"We will create this whole Kernel in three basic steps:\n\n* Importing, Preprocessing and Visualising the dataset\n* Creating the CNN model\n* Finally, Evaluating results and Making predictions\n\nIf you found this kernel useful please **UPVOTE**. \n\nSo, let's get started","4780eec6":"To read more about CNNs you can refer to this [link](http:\/\/cs231n.github.io\/convolutional-networks\/)","fe183daa":"Now, we will start to build our Convolutional Neural Network model. We will feed training images to our model and then it will be used to make predictions. This is a very basic model and a much better CNN architecture can be used to increase the accuracy.","7705a4b5":"We have trained our model on the training images and labels. The history object stores all the details in the process of training the model. So, let's move on to analysing our the process of training and the results we have got.","7bdb8c24":"After analysing the model we will make the final predictions and will create the submission file","cb391b0c":"Here, we have used **train_test_split** from **scikit-learn** to split our training images and labels into train and test data. Since, we have our test_size set to 0.2 our initial dataset will be split into 20000 training and 5000 test data elements.","2d228478":"After creating the model we will compile it. Compiling a model means to \"Configure the learning process\". Here, we have defined our optimizer, loss and evaluation metrics.","885ad239":"# Step 1 :\n## Importing, Preprocessing and Visualising","c4f0f05d":"The plot below shows the change in accuracy in all the epochs. From the plot we can clearly see that there is a slight slowdown in the increase in validation accuracy. This is because of the reasons I mentioned previously. In our model, this problem is very much under the control but sometimes it can be very visible. In such cases there are many ways to solve it, just do a quick google search to learn more about it.","9de9bb99":"The plot below shows how the loss in both training(**x_train**) and validation(**x_test**) over the span of ten epochs. We can see how the decrease in the validation loss has slowed down while we approach the final epcohs.This may have happened because of a little bit of variance. You can observe similar trends in training and validation accuracy."}}