{"cell_type":{"3e4a0f6b":"code","5f6b9c95":"code","0abaff5d":"code","ee456280":"code","e81e755a":"code","42b7c8e6":"code","f1be6da5":"code","e2f4b43d":"code","727ab93b":"code","fc55a87e":"code","9d5e7ebe":"markdown","cadcd20d":"markdown","4f1a360f":"markdown","91b1feb2":"markdown","09ded001":"markdown","2e34ca5e":"markdown"},"source":{"3e4a0f6b":"from PIL import Image\npil_im = Image.open('..\/input\/logocanal\/LOGO PNG.png')\npil_im","5f6b9c95":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n","0abaff5d":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import ModelCheckpoint\n\nseed = 42\nnp.random.seed(seed)","ee456280":"\ndf = pd.read_csv('\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndf.head()","e81e755a":"# First - split into Train\/Test\nfrom sklearn.model_selection import train_test_split\n\nX = df.drop(['Outcome'],axis=1)\n\ny = df['Outcome']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n\nprint(X_train.shape)\nprint(X_test.shape)","42b7c8e6":"# Ensure that fieldnames aren't included\nX_train = X_train.values\ny_train = y_train.values\nX_test  = X_test.values\ny_test  = y_test.values","f1be6da5":"NB_EPOCHS = 1000  # num of epochs to test for\nBATCH_SIZE = 16\n\n## Create our model\nmodel = Sequential()\n\n# 1st layer: input_dim=8, 12 nodes, RELU\nmodel.add(Dense(12, input_dim=8, activation='relu'))\n# 2nd layer: 8 nodes, RELU\nmodel.add(Dense(8, activation='relu'))\n# output layer: dim=1, activation sigmoid\nmodel.add(Dense(1, activation='sigmoid' ))\n\n# Compile the model\nmodel.compile(loss='binary_crossentropy',   # since we are predicting 0\/1\n             optimizer='adam',\n             metrics=['accuracy'])\n\n# checkpoint: store the best model\nckpt_model = 'pima-weights.best.hdf5'\ncheckpoint = ModelCheckpoint(ckpt_model, \n                            monitor='val_acc',\n                            verbose=1,\n                            save_best_only=True,\n                            mode='max')\ncallbacks_list = [checkpoint]\n\nprint('Starting training...')\n# train the model, store the results for plotting\nhistory = model.fit(X_train,\n                    y_train,\n                    validation_data=(X_test, y_test),\n                    epochs=NB_EPOCHS,\n                    batch_size=BATCH_SIZE,\n                    callbacks=callbacks_list,\n                    verbose=2)","e2f4b43d":"# Model accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'])\nplt.show()","727ab93b":"# Model Losss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'])\nplt.show()","fc55a87e":"# print final accuracy\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","9d5e7ebe":"## Importando classes","cadcd20d":"## Importando arquivos do Keras","4f1a360f":"# Apresentando hist\u00f3rico do Treino","91b1feb2":"# Pima Indians Diabetes Database\u00b6\n\n## Usando Keras para predi\u00e7\u00e3o de Diabetes\n\n","09ded001":"## Separando em treino e teste","2e34ca5e":"## Lendo arquivo de Diabetes"}}