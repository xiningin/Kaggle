{"cell_type":{"21a2a1e9":"code","01c20797":"code","ac7b8172":"code","700156c9":"code","eccc8c3e":"code","88d6a1cc":"code","c1e38361":"code","5df71558":"code","34325d6b":"code","89756950":"code","68ea0b7c":"code","11993c0e":"code","bea72713":"code","7c5eb1a1":"code","a023960f":"code","14141611":"code","69dd5b9c":"code","f6d81fce":"code","ab7b9050":"code","41f8d210":"code","de9b655f":"markdown","e94b49ec":"markdown","6c9924b3":"markdown","5e53038a":"markdown","5fc897d9":"markdown","421d79ce":"markdown","b1bf66d9":"markdown","8bd49233":"markdown","817047a4":"markdown","757765b0":"markdown","92f1f991":"markdown","59147d40":"markdown","7186d764":"markdown","368d2d6a":"markdown"},"source":{"21a2a1e9":"# Para mostrar todas as sa\u00eddas das c\u00e9lulas do Jupyter\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'","01c20797":"aleatorio = 7","ac7b8172":"import warnings\nwarnings.filterwarnings(\"ignore\")","700156c9":"import pandas as pd","eccc8c3e":"df_treino = pd.read_csv('dataset_treino.csv', \n                        dtype={'feature_1': int, 'feature_2': int, 'feature_3': int})\ndf_treino.shape\ndf_treino.head()","88d6a1cc":"df_teste = pd.read_csv('dataset_teste.csv',\n                      dtype={'feature_1': int, 'feature_2': int, 'feature_3': int})\ndf_teste.shape\ndf_teste.head()","c1e38361":"# Rela\u00e7\u00e3o entre os datasets de teste e treino\ndf_teste.shape[0] \/ df_treino.shape[0]","5df71558":"df_sample_submission = pd.read_csv('sample_submission.csv')\ndf_sample_submission.shape\ndf_sample_submission.head()","34325d6b":"# Garbage collector\nimport gc\ngc.collect()","89756950":"# Vamos utilizar o pandas_profiling para acelerar a an\u00e1lise explorat\u00f3ria inicial\nimport pandas_profiling as pp","68ea0b7c":"# Convers\u00e3o data coluna first_active_month tipo data e extra\u00e7\u00e3o do m\u00eas e ano\ndf_treino['data_ativacao'] = pd.to_datetime(df_treino['first_active_month'])\ndf_treino['mes_ativacao'] = df_treino.data_ativacao.apply(lambda dt: dt.month)\ndf_treino['ano_ativacao'] = df_treino.data_ativacao.apply(lambda dt: dt.year)\n\n# Ajustando tipo dado\n# df_treino.mes_ativacao.astype('int', inplace=True)\n# df_treino.ano_ativacao.astype('int', inplace=True)\n\n# Remo\u00e7\u00e3o da coluna que n\u00e3o precisamos mais\ndf_treino.drop('first_active_month', axis=1, inplace=True)\ndf_treino.drop('data_ativacao', axis=1, inplace=True)\n\n# Reorganizando as colunas\ndf_treino = df_treino[['card_id', 'mes_ativacao', 'ano_ativacao', 'feature_1', 'feature_2', 'feature_3', 'target']]\n\ndf_treino.head()","11993c0e":"# Relat\u00f3rio autom\u00e1tico do dataset\npp.ProfileReport(df_treino)","bea72713":"# Note um outlier antes de -30\n# S\u00e3o 2207 registros (1,093% do total de registros) com valor de -33.21928095\ndf_treino['target'].hist(bins=500)","7c5eb1a1":"df_treino['ano_ativacao'].hist(bins=50)","a023960f":"# Convers\u00e3o para data e extra\u00e7\u00e3o do m\u00eas e ano de ativa\u00e7\u00e3o\ndf_teste['data_ativacao'] = pd.to_datetime(df_teste['first_active_month'])\ndf_teste['mes_ativacao'] = df_teste.data_ativacao.apply(lambda dt: dt.month)\ndf_teste['ano_ativacao'] = df_teste.data_ativacao.apply(lambda dt: dt.year)\n\n# Ajustando tipo dado\n# df_treino.mes_ativacao.astype('int', inplace=True)\n# df_treino.ano_ativacao.astype('int', inplace=True)\n\n# Remo\u00e7\u00e3o da coluna que n\u00e3o precisamos mais\ndf_teste.drop('first_active_month', axis=1, inplace=True)\ndf_teste.drop('data_ativacao', axis=1, inplace=True)\n\n# Reorganizando as colunas\ndf_teste = df_teste[['card_id', 'mes_ativacao', 'ano_ativacao', 'feature_1', 'feature_2', 'feature_3']]","14141611":"# Relat\u00f3rio autom\u00e1tico do dataset\npp.ProfileReport(df_teste)","69dd5b9c":"df_treino.head()\ndf_teste.head()","f6d81fce":"# N\u00e3o precisamos do campo card_id do arquivo de treino\ndf_treino.drop('card_id', axis=1, inplace=True)\ndf_treino.head()","ab7b9050":"import xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Separando as vari\u00e1veis preditoras da vari\u00e1vel predita\nX, y = df_treino.iloc[:, :-1], df_treino.iloc[:, -1]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n                                                    shuffle=True, random_state=aleatorio)\n\n\ngbm_param_grid = {\n    'learning_rate': [0.01, 0.1, 1],\n    'n_estimators': [500, 1000, 2000],\n    'max_features': ['auto', 'sqrt', 'log2', None],\n    'loss': ['huber'],\n    'subsample': [1],\n    'max_depth':[2, 3, 5],\n    'nthread': [4]\n}\n\ngbm = xgb.XGBRegressor()\n\n# n_jobs=-1 \u00e9 usar todos os processadores\ngrid_mse = RandomizedSearchCV(estimator=gbm, param_distributions=gbm_param_grid, \n                        scoring='neg_mean_squared_error', cv=2, verbose=1, n_iter=5, \n                        return_train_score=True, random_state=aleatorio, n_jobs=1)\n\ngrid_mse.fit(X, y)\n\nprint('Melhores par\u00e2metros encontrados no treio: ', grid_mse.best_params_)\nprint('Menor RMSE encontrado no treino: ', np.sqrt(np.abs(grid_mse.best_score_)))\n\n# Predi\u00e7\u00e3o\npreds = grid_mse.predict(X_test)\n\nprint(\"RMSE nos dados de teste: \", np.sqrt(mean_squared_error(y_test, preds)))","41f8d210":"predictions = grid_mse.predict(df_teste[['mes_ativacao', 'ano_ativacao', 'feature_1', 'feature_2', 'feature_3']])\n\nsubmission_df = pd.DataFrame({\"card_id\":df_teste[\"card_id\"].values})\nsubmission_df[\"target\"] = predictions\nsubmission_df.to_csv(\"submission_2.csv\", index=False)","de9b655f":"## Quais arquivos eu preciso?\n\nVoc\u00ea precisar\u00e1, no m\u00ednimo, dos arquivos **dataset_treino.csv** e **dataset_teste.csv**. Eles cont\u00eam os card_ids que usaremos para treinamento e previs\u00e3o.\n\nOs arquivos **transacoes_historicas.csv** e **novas_transacoes_comerciantes.csv** cont\u00eam informa\u00e7\u00f5es sobre as transa\u00e7\u00f5es de cada cart\u00e3o. O arquivo **transacoes_historicas.csv** cont\u00e9m at\u00e9 tr\u00eas meses de transa\u00e7\u00f5es para cada cart\u00e3o em qualquer um dos merchant_ids fornecidos. O arquivo **novas_transacoes_comerciantes.csv** cont\u00e9m as transa\u00e7\u00f5es em novos comerciantes (merchant_ids que este card_id em particular ainda n\u00e3o visitou) durante um per\u00edodo de dois meses.\n\nO arquivo **comerciantes.csv** cont\u00e9m informa\u00e7\u00f5es agregadas para cada merchant_id representado no conjunto de dados.","e94b49ec":"## Treinamento do Modelo","6c9924b3":"## Definindo o problema\n\nImagine estar com fome em uma parte desconhecida da cidade e receber recomenda\u00e7\u00f5es de restaurantes, com base em suas prefer\u00eancias pessoais, no momento certo. A recomenda\u00e7\u00e3o vem com um desconto em anexo da sua operadora de cart\u00e3o de cr\u00e9dito para um local ao virar a esquina!\n\nUma Startup pensou nisso e construiu parcerias com comerciantes para oferecer promo\u00e7\u00f5es ou descontos aos portadores de cart\u00f5es de cr\u00e9dito. Mas essas promo\u00e7\u00f5es funcionam tanto para o consumidor quanto para o comerciante? Os clientes aproveitam a experi\u00eancia? Os comerciantes veem resultado? A personaliza\u00e7\u00e3o \u00e9 fundamental.\n\nOs profissionais da Startup constru\u00edram modelos de aprendizado de m\u00e1quina para entender os aspectos e prefer\u00eancias mais importantes no ciclo de vida de seus clientes, desde alimentos a compras. Mas at\u00e9 agora nenhum deles \u00e9 especificamente adaptado para um indiv\u00edduo ou perfil. \u00c9 aqui que voc\u00ea entra. Precisando de um modelo preditivo mais robusto, a Startup selecionou voc\u00ea como Cientista de Dados.\n\nNesta competi\u00e7\u00e3o, voc\u00ea desenvolver\u00e1 algoritmos para identificar e atender as oportunidades mais relevantes para os indiv\u00edduos, revelando sinais de lealdade dos clientes. Sua contribui\u00e7\u00e3o melhorar\u00e1 a vida dos clientes e ajudar\u00e1 a reduzir as campanhas indesejadas, a fim de criar uma experi\u00eancia mais personalizada para cada cliente e consequentemente aumentar a satisfa\u00e7\u00e3o e claro, as vendas.","5e53038a":"## Carga dos Arquivos para Mem\u00f3ria","5fc897d9":"## An\u00e1lise Explorat\u00f3ria dos Dados","421d79ce":"#### Dataset de treino","b1bf66d9":"## Antes de Tudo","8bd49233":"## O que estou prevendo?\n\nVoc\u00ea est\u00e1 **prevendo um \u00edndice de lealdade para cada card_id representado em dataset_teste.csv e sample_submission.csv**.\n\nDescri\u00e7\u00f5es dos arquivos:\n\n**dataset_treino.csv** - o conjunto de treinamento.\n\n**dataset_teste.csv** - o conjunto de teste.\n\n**sample_submission.csv** - um arquivo de envio de amostra no formato correto - cont\u00e9m todos os card_ids que voc\u00ea deve prever.\n\n**transacoes_historicas.csv** - at\u00e9 tr\u00eas meses de transa\u00e7\u00f5es hist\u00f3ricas para cada card_id\n\n**comerciantes.csv** - informa\u00e7\u00f5es adicionais sobre todos os comerciantes \/ merchant_ids no conjunto de dados.\n\n**novas_transacoes_comerciantes.csv** - dois meses de dados para cada card_id contendo TODAS as compras que card_id fizeram em merchant_ids que n\u00e3o foram visitadas nos dados hist\u00f3ricos.","817047a4":"### RandomizedSearchCV e XGB","757765b0":"## Campos de dados\n\nAs descri\u00e7\u00f5es dos campos de dados s\u00e3o fornecidas no arquivo **Dicionario_de_Dados.xlsx**.","92f1f991":"#### Dataset de teste","59147d40":"## Gerar Arquivo de Envio","7186d764":"# Competi\u00e7\u00e3o DSA de Machine Learning - Edi\u00e7\u00e3o Junho\/2019","368d2d6a":"## O que devo esperar sobre o formato dos dados?\n\nOs dados est\u00e3o formatados da seguinte maneira:\n\nOs arquivos **dataset_treino.csv** e **dataset_teste.csv** cont\u00eam card_ids e informa\u00e7\u00f5es sobre o pr\u00f3prio cart\u00e3o - o primeiro m\u00eas em que o cart\u00e3o estava ativo, etc. O arquivo **dataset_treino.csv** tamb\u00e9m cont\u00e9m o target (\u00edndice de lealdade do cliente).\n\nO arquivos **transacoes_historicas.csv** e o **novas_transacoes_comerciantes.csv** foram projetados para serem associados ao **dataset_treino.csv**, **dataset_teste.csv** e **comerciantes.csv**. Eles cont\u00eam informa\u00e7\u00f5es sobre transa\u00e7\u00f5es para cada cart\u00e3o, conforme descrito acima.\n\nOs comerciantes podem ser associados aos conjuntos de transa\u00e7\u00f5es para fornecer informa\u00e7\u00f5es adicionais no n\u00edvel do comerciante."}}