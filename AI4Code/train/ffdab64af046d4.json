{"cell_type":{"e2a270a0":"code","b7e9edc1":"code","b49c9b2d":"code","7cea9965":"code","c5cf8ff2":"code","597ba2eb":"code","0b9b282c":"code","a7ef4cd6":"code","fc714e3d":"code","407930e1":"code","67364dbd":"code","ef072733":"code","e7351059":"code","1ed43bb2":"markdown","60e0cafd":"markdown","3b35e27e":"markdown","56b32083":"markdown","162b60a3":"markdown"},"source":{"e2a270a0":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nimport torchvision\nimport numbers\nfrom PIL import Image, ImageOps, ImageEnhance\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline","b7e9edc1":"if torch.cuda.is_available():\n    current_device = torch.cuda.current_device()\n    torch.cuda.set_device(current_device)\n    device = torch.device('cuda:{}'.format(current_device))\n    print('Using GPU: {}'.format(torch.cuda.get_device_name(current_device)))\nelse:\n    device = torch.device('cpu')","b49c9b2d":"class RandomRotation(object):\n    def __init__(self, degrees, resample=False, expand=False, center=None):\n        if isinstance(degrees, numbers.Number):\n            if degrees < 0:\n                raise ValueError(\"If degrees is a single number, it must be positive.\")\n            self.degrees = (-degrees, degrees)\n        else:\n            if len(degrees) != 2:\n                raise ValueError(\"If degrees is a sequence, it must be of len 2.\")\n            self.degrees = degrees\n            \n        self.resample = resample\n        self.expand = expand\n        self.center = center\n\n    @staticmethod\n    def get_params(degrees):\n        angle = np.random.uniform(degrees[0], degrees[1])\n        return angle\n\n    def __call__(self, img):\n        \n        def rotate(img, angle, resample=False, expand=False, center=None): \n            return img.rotate(angle, resample, expand, center)\n        \n        angle = self.get_params(self.degrees)\n        return rotate(img, angle, self.resample, self.expand, self.center)","7cea9965":"class RandomShift(object):\n    def __init__(self, shift):\n        self.shift = shift\n        \n    @staticmethod\n    def get_params(shift):\n        hshift, vshift = np.random.uniform(-shift, shift, size=2)\n        return hshift, vshift\n    \n    def __call__(self, img):\n        hshift, vshift = self.get_params(self.shift)\n        return img.transform(img.size, Image.AFFINE, (1,0,hshift,0,1,vshift), resample=Image.BICUBIC, fill=1)","c5cf8ff2":"class MNIST(torch.utils.data.Dataset):    \n    def __init__(self, file_path, train=False,\n                 transform = transforms.Compose(\n                     [transforms.ToPILImage(),transforms.ToTensor(),\n                      transforms.Normalize(mean=(0.5,),std=(0.5,))])\n                ):\n        df = pd.read_csv(file_path)\n        \n        if train:\n             # training data\n            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = torch.from_numpy(df.iloc[:,0].values)\n        else:\n             # test data\n            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = None\n            \n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        if self.y is not None:\n            return self.transform(self.X[idx]), self.y[idx]\n        else:\n            return self.transform(self.X[idx])","597ba2eb":"class Net(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        \n        # feature encoders\/identifiers\n        self.features = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n\n        # classifier MLP\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=0.2),\n            nn.Linear(32 * 7 * 7, 784),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(784, 784),\n            nn.ReLU(),\n            nn.Linear(784, 10))\n\n    def forward(self, X):\n        x = self.features(X)\n        x = x.view(x.size(0), 32 * 7 * 7)\n        x = self.classifier(x)\n        return x\n\nnet = Net()\nprint(net)","0b9b282c":"n_epochs = 105\nlearning_rate = 1e-3\nbatch_size = 1024\nw_decay = 2e-4\n\n# use 80% for training, 20% for validation\ndata_split = 0.8\nrnd_shift = 3\nrnd_rotation = 20\n\nmodel = Net().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=w_decay)\ncriterion = nn.CrossEntropyLoss()","a7ef4cd6":"fulltrainset = MNIST('\/kaggle\/input\/digit-recognizer\/train.csv', train=True,\n                     transform =transforms.Compose([transforms.ToPILImage(),\n                                                    RandomRotation(degrees=rnd_rotation),\n                                                    RandomShift(rnd_shift),\n                                                    transforms.ToTensor(),\n                                                    transforms.Normalize(mean=(0.5,), std=(0.5,))\n                                                   ])\n                    )\n# Split dataset into validation and training set\ntrain_size = int(data_split * len(fulltrainset))\ntest_size = len(fulltrainset) - train_size\ntrainset, validationset = torch.utils.data.random_split(fulltrainset, [train_size, test_size])\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n\nvalidloader = torch.utils.data.DataLoader(validationset, batch_size=batch_size, shuffle=False, num_workers=2)\n\n# Test set\ntestset = MNIST('\/kaggle\/input\/digit-recognizer\/test.csv', train=False)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)","fc714e3d":"def validate(dataloader):\n    model.eval()\n    correct = 0\n    losses = []\n    \n    for data, target in dataloader:\n        with torch.no_grad():\n            data, target = torch.autograd.Variable(data).to(device), torch.autograd.Variable(target).to(device)\n            output = model(data)\n            loss = F.cross_entropy(output, target, reduction='mean')\n            pred = output.max(1, keepdim=True)[1]\n            correct += pred.eq(target.view_as(pred)).sum().item()\n            losses.append(loss.item())\n    \n    acc = 100. * correct \/ len(dataloader.dataset)\n    print('\\nValidation loss: {:.4f}\\tAccuracy: {}\/{} ({:.0f}%)\\n'.format(\n        np.mean(np.array(losses)), correct, len(dataloader.dataset), acc))\n    \n    return np.mean(np.array(losses)), acc","407930e1":"def train(dataloader, epoch):\n    model.train()\n    losses = []\n    \n    for batch_idx, (data, target) in enumerate(dataloader):\n        data, target = torch.autograd.Variable(data).to(device), torch.autograd.Variable(target).to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        losses.append(loss.item())\n        \n        if (batch_idx + 1) % 10 == 0:\n            print('Train Epoch: {} [{}\/{}]\\tLoss: {:.4f}'.format(\n                epoch, ((batch_idx + 1) * len(data)), (len(dataloader.dataset)), np.mean(np.array(losses))))\n\n    return np.mean(np.array(losses))","67364dbd":"train_losses = []\ntest_losses = []\naccuracies = []\n\nfor epoch in range(n_epochs):\n    loss = train(trainloader, epoch)\n    test_loss, acc = validate(validloader)\n    \n    train_losses.append(loss)\n    test_losses.append(test_loss)\n    accuracies.append(acc)","ef072733":"fig,ax = plt.subplots(2,1,figsize=(14,18))\n\nax[0].plot(test_losses, label='Validation loss')\nax[0].plot(train_losses, label='Training loss')\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Loss')\nax[0].legend(loc='upper right')\n\nax[1].plot(accuracies)\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Accuracy')","e7351059":"model.eval()\ntest_pred = torch.LongTensor()\n\nfor i, data in enumerate(testloader):\n    with torch.no_grad():\n        data = torch.autograd.Variable(data)\n        data = data.to(device)\n        output = model(data)\n        pred = output.cpu().data.max(1, keepdim=True)[1]\n        test_pred = torch.cat((test_pred, pred), dim=0)\n        \nout_df = pd.DataFrame(np.c_[np.arange(1, len(testset)+1)[:,None], test_pred.numpy()], \n                      columns=['ImageId', 'Label'])\nout_df.head()\nout_df.to_csv('submission.csv', index=False)","1ed43bb2":"> # CNN Model","60e0cafd":"# Training","3b35e27e":"# Submission","56b32083":"# Data Preparation","162b60a3":"# Training Statistics"}}