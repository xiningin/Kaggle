{"cell_type":{"2123fc20":"code","6bee5eef":"code","f05523e2":"code","d972a8e9":"code","5ef190fd":"code","f09875bf":"code","b5f23771":"code","8b93c8e6":"code","ba46ee98":"code","7a13fea5":"code","9f81de81":"code","a9bc2f1d":"code","4a94a153":"code","984410d8":"code","8134e2f3":"code","174d5d1f":"code","a4a093bd":"code","c144374c":"code","ff38188f":"code","10eea1c7":"code","250982ce":"code","cb70d22e":"code","5a7eef23":"code","ab0286df":"code","2ba53fea":"code","cd67687b":"code","a257a87b":"code","41b3f62d":"code","592f6c84":"code","e04cfa4e":"code","0cdfdf24":"code","e6e3ff64":"code","05db5385":"code","c1a89d58":"code","01d0194f":"code","50d58d69":"code","14dfccd9":"code","75511627":"code","82fb7523":"code","e11a94d8":"code","2b42ca92":"code","48b9a71e":"code","bded4d6f":"code","4f0de4c2":"code","7e6dcbce":"code","ae85d0ab":"code","9c335265":"code","e87a6a76":"code","20445e70":"code","543a3bac":"code","d5a2ed6c":"code","06919eb0":"code","c3914641":"markdown","b1c8b227":"markdown","3821e760":"markdown","5127e021":"markdown","36dfac57":"markdown","a9e594b2":"markdown","950bb093":"markdown","27f691d3":"markdown","59617659":"markdown","951164ce":"markdown","b83be063":"markdown","95fb8c2e":"markdown","28ad44e1":"markdown","4143a18d":"markdown","c93a4af8":"markdown","56e53472":"markdown","2b007e62":"markdown","9aa98c10":"markdown","d59b5092":"markdown","5adef3ed":"markdown","053616a7":"markdown","ebbcac77":"markdown","1a1c7db4":"markdown","a91cf05d":"markdown","c62e41c8":"markdown","4c8d1222":"markdown","0a8ec274":"markdown","9315c27f":"markdown","990b38ea":"markdown","578a43f7":"markdown","491607c9":"markdown","097b7453":"markdown"},"source":{"2123fc20":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6bee5eef":"import matplotlib.pyplot as plt\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nfrom matplotlib import pyplot\nfrom numpy import where\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")","f05523e2":"from collections import Counter\nfrom imblearn.over_sampling import ADASYN\nfrom imblearn.over_sampling import BorderlineSMOTE\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import SVMSMOTE\nfrom lightgbm import LGBMClassifier\nfrom sklearn import metrics\nfrom sklearn.datasets import make_classification\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier","d972a8e9":"data = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')","5ef190fd":"data.head(2)","f09875bf":"data.shape","b5f23771":"data.describe()","8b93c8e6":"plt.figure(figsize=(15,5))\nplt.title('Time Distribution')\nsns.distplot(data.Time)","ba46ee98":"plt.figure(figsize=(15,5))\nplt.title('Distribution of transaction value')\nsns.distplot(data.Amount)","7a13fea5":"#fraud vs. normal transactions \ncounts = data.Class.value_counts()\nnormal = counts[0]\nfraudulent = counts[1]\nperc_normal = (normal\/(normal+fraudulent))*100\nperc_fraudulent = (fraudulent\/(normal+fraudulent))*100\nprint('There were {} non-fraudulent transactions ({:.3f}%) and {} fraudulent transactions ({:.3f}%).'.format(normal, perc_normal, fraudulent, perc_fraudulent))","9f81de81":"plt.figure(figsize=(7,5))\nsns.barplot(x=counts.index, y=counts)\nplt.title('Count of Fraudulent vs. Non-Fraudulent Transactions')\nplt.ylabel('Count')\nplt.xlabel('Class (0:Non-Fraudulent, 1:Fraudulent)')","a9bc2f1d":"style.use('ggplot')\nsns.set_style('whitegrid')\nplt.subplots(figsize = (30,30))\n## Plotting heatmap. Generate a mask for the upper triangle (taken from seaborn example gallery)\nmask = np.zeros_like(data.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(data.corr(), cmap=sns.diverging_palette(20, 220, n=200), annot=True, mask=mask, center = 0, );\nplt.title(\"Heatmap of all the Features of Train data set\", fontsize = 25);","4a94a153":"#visualizing the features w high negative correlation\nf, axes = plt.subplots(nrows=3, ncols=3, figsize=(25,15))\n\nf.suptitle('Features With High Negative Correlation', size=35)\nsns.boxplot(x=\"Class\", y=\"V3\", data=data, ax=axes[0,0])\nsns.boxplot(x=\"Class\", y=\"V7\", data=data, ax=axes[0,1])\nsns.boxplot(x=\"Class\", y=\"V10\", data=data, ax=axes[0,2])\nsns.boxplot(x=\"Class\", y=\"V12\", data=data, ax=axes[1,0])\nsns.boxplot(x=\"Class\", y=\"V14\", data=data, ax=axes[1,1])\nsns.boxplot(x=\"Class\", y=\"V16\", data=data, ax=axes[1,2])\nsns.boxplot(x=\"Class\", y=\"V17\", data=data, ax=axes[2,0])\nsns.boxplot(x=\"Class\", y=\"V18\", data=data, ax=axes[2,1])\nf.delaxes(axes[2,2])","984410d8":"#visualizing the features w high positive correlation\nf, axes = plt.subplots(nrows=1, ncols=2, figsize=(14,5))\n\nf.suptitle('Features With High Positive Correlation', size=20)\nsns.boxplot(x=\"Class\", y=\"V4\", data=data, ax=axes[0])\nsns.boxplot(x=\"Class\", y=\"V11\", data=data, ax=axes[1])","8134e2f3":"def Definedata():\n    # define dataset\n    X=data.drop(columns=['Class']).values\n    y=data['Class'].values\n    return X, y","174d5d1f":"def SMOTE():\n    # borderline-SMOTE for imbalanced dataset\n    from collections import Counter\n    from sklearn.model_selection import train_test_split\n    from sklearn.datasets import make_classification\n    from imblearn.over_sampling import SMOTE\n    from matplotlib import pyplot\n    from numpy import where\n    \n    X, y = Definedata()\n\n# summarize class distribution\n    counter = Counter(y)\n    print(counter)\n# transform the dataset\n    smt = SMOTE(random_state=0)\n    X, y = smt.fit_sample(X, y) \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)\n# summarize the new class distribution\n    counter = Counter(y)\n    print(counter)\n# scatter plot of examples by class label\n    for label, _ in counter.items():\n        row_ix = where(y == label)[0]\n        pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n    pyplot.legend()\n    pyplot.show()\n    return X_train, X_test, y_train, y_test","a4a093bd":"def BSMOTE():\n    from collections import Counter\n    from sklearn.model_selection import train_test_split\n    from imblearn.over_sampling import BorderlineSMOTE\n    from matplotlib import pyplot\n    from numpy import where\n    \n    X, y = Definedata()\n    \n# summarize class distribution\n    counter = Counter(y)\n    print(counter)\n# transform the dataset\n    X, y = BorderlineSMOTE().fit_resample(X, y)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)\n# summarize the new class distribution\n    counter = Counter(y)\n    print(counter)\n# scatter plot of examples by class label\n    for label, _ in counter.items():\n        row_ix = where(y == label)[0]\n        pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n    pyplot.legend()\n    pyplot.show()\n    return X_train, X_test, y_train, y_test","c144374c":"def SMOTESVM():\n    from collections import Counter\n    from sklearn.model_selection import train_test_split\n    from imblearn.over_sampling import SVMSMOTE\n    from matplotlib import pyplot\n    from numpy import where\n\n    X, y = Definedata()\n\n# summarize class distribution\n    counter = Counter(y)\n    print(counter)\n# transform the dataset\n    X, y = SVMSMOTE().fit_resample(X, y)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)\n# summarize the new class distribution\n    counter = Counter(y)\n    print(counter)\n# scatter plot of examples by class label\n    for label, _ in counter.items():\n        row_ix = where(y == label)[0]\n        pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n    pyplot.legend()\n    pyplot.show()\n    return X_train, X_test, y_train, y_test","ff38188f":"def ADASYN():\n    from collections import Counter\n    from sklearn.model_selection import train_test_split\n    from imblearn.over_sampling import ADASYN\n    from matplotlib import pyplot\n    from numpy import where\n\n    X, y = Definedata()\n\n# summarize class distribution\n    counter = Counter(y)\n    print(counter)\n# transform the dataset\n    X, y = ADASYN().fit_resample(X, y)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)\n# summarize the new class distribution\n    counter = Counter(y)\n    print(counter)\n# scatter plot of examples by class label\n    for label, _ in counter.items():\n        row_ix = where(y == label)[0]\n        pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n    pyplot.legend()\n    pyplot.show()\n    return X_train, X_test, y_train, y_test","10eea1c7":"%time X_train1, X_test1, y_train1, y_test1 = SMOTE()\n%time X_train2, X_test2, y_train2, y_test2 = BSMOTE()\n%time X_train3, X_test3, y_train3, y_test3 = SMOTESVM()\n%time X_train4, X_test4, y_train4, y_test4 = ADASYN()","250982ce":"def Models(models, X_train, X_test, y_train, y_test, title):\n    model = models\n    model.fit(X_train,y_train)\n    \n    X, y = Definedata()\n    train_matrix = pd.crosstab(y_train, model.predict(X_train), rownames=['Actual'], colnames=['Predicted'])    \n    test_matrix = pd.crosstab(y_test, model.predict(X_test), rownames=['Actual'], colnames=['Predicted'])\n    matrix = pd.crosstab(y, model.predict(X), rownames=['Actual'], colnames=['Predicted'])\n    \n    f,(ax1,ax2,ax3) = plt.subplots(1,3,sharey=True, figsize=(20, 3))\n    #f = plt.figure(figsize=(20, 3))\n    \n    g1 = sns.heatmap(train_matrix, annot=True, fmt=\".1f\", cbar=False,annot_kws={\"size\": 16},ax=ax1)\n    g1.set_title(title)\n    g1.set_ylabel('Total Fraud = {}'.format(y_train.sum()), fontsize=14, rotation=90)\n    g1.set_xlabel('Accuracy score for Trainingset: {}'.format(accuracy_score(model.predict(X_train), y_train)))\n    \n    g2 = sns.heatmap(test_matrix, annot=True, fmt=\".1f\",cbar=False,annot_kws={\"size\": 16},ax=ax2)\n    g2.set_ylabel('Total Fraud = {}'.format(y_test.sum()), fontsize=14, rotation=90)\n    g2.set_xlabel('Accuracy score for Testingset: {}'.format(accuracy_score(model.predict(X_test), y_test)))\n    \n    g3 = sns.heatmap(matrix, annot=True, fmt=\".1f\",cbar=False,annot_kws={\"size\": 16},ax=ax3)\n    g3.set_ylabel('Total Fraud = {}'.format(y.sum()), fontsize=14, rotation=90)\n    g3.set_xlabel('Accuracy score for Totalset: {}'.format(accuracy_score(model.predict(X), y)))\n    \n    plt.show()\n    return y, model.predict(X)\n    \ndef Featureimportances(models, X_train, y_train):\n    model = models\n    model.fit(X_train,y_train)\n    importances = model.feature_importances_\n    features = df_test.columns[:9]\n    imp = pd.DataFrame({'Features': ftest, 'Importance': importances})\n    imp['Sum Importance'] = imp['Importance'].cumsum()\n    imp = imp.sort_values(by = 'Importance')\n    return imp","cb70d22e":"title = 'LogisticRegression\/SMOTE'\n%time Models(LogisticRegression(),X_train1, X_test1, y_train1, y_test1, title)","5a7eef23":"title = 'LogisticRegression\/BSMOTE'\n%time Models(LogisticRegression(),X_train2, X_test2, y_train2, y_test2, title)","ab0286df":"title = 'LogisticRegression\/SMOTESVM'\n%time Models(LogisticRegression(),X_train3, X_test3, y_train3, y_test3, title)","2ba53fea":"title = 'LogisticRegression\/ADASYN'\n%time Models(LogisticRegression(),X_train4, X_test4, y_train4, y_test4, title)","cd67687b":"title = 'GaussianNB\/SMOTE'\n%time Models(GaussianNB(),X_train1, X_test1, y_train1, y_test1, title)","a257a87b":"title = 'GaussianNB\/BSMOTE'\n%time Models(GaussianNB(),X_train2, X_test2, y_train2, y_test2, title)","41b3f62d":"title = 'GaussianNB\/SMOTESVM'\n%time Models(GaussianNB(),X_train3, X_test3, y_train3, y_test3, title)","592f6c84":"title = 'GaussianNB\/ADASYN'\n%time Models(GaussianNB(),X_train4, X_test4, y_train4, y_test4, title)","e04cfa4e":"title = 'KNeighborsClassifier\/SMOTE'\n%time Models(KNeighborsClassifier(n_neighbors=1),X_train1, X_test1, y_train1, y_test1, title)","0cdfdf24":"title = 'KNeighborsClassifier\/BSMOTE'\n%time Models(KNeighborsClassifier(n_neighbors=1),X_train2, X_test2, y_train2, y_test2, title)","e6e3ff64":"title = 'KNeighborsClassifier\/SMOTESVM'\n%time Models(KNeighborsClassifier(n_neighbors=1),X_train3, X_test3, y_train3, y_test3, title)","05db5385":"title = 'KNeighborsClassifier\/ADASYN'\n%time Models(KNeighborsClassifier(n_neighbors=1),X_train4, X_test4, y_train4, y_test4, title)","c1a89d58":"title = 'DecisionTreeClassifier\/SMOTE'\n%time Models(DecisionTreeClassifier(max_depth=14),X_train1, X_test1, y_train1, y_test1, title)","01d0194f":"title = 'DecisionTreeClassifier\/ADASYN'\n%time Models(DecisionTreeClassifier(max_depth=14),X_train4, X_test4, y_train4, y_test4, title)","50d58d69":"title = 'RandomForestClassifier\/SMOTE'\n%time Models(RandomForestClassifier(),X_train1, X_test1, y_train1, y_test1, title)","14dfccd9":"title = 'RandomForestClassifier\/BSMOTE'\n%time Models(RandomForestClassifier(),X_train2, X_test2, y_train2, y_test2, title)","75511627":"title = 'RandomForestClassifier\/ADASYN'\n%time Models(RandomForestClassifier(),X_train4, X_test4, y_train4, y_test4, title)","82fb7523":"title = 'GradientBoostingClassifier\/SMOTE'\n%time Models(GradientBoostingClassifier(n_estimators=500, learning_rate=1, max_features=2, max_depth=2, random_state=0),X_train1, X_test1, y_train1, y_test1, title)","e11a94d8":"title = 'GradientBoostingClassifier\/SMOTESVM'\n%time Models(GradientBoostingClassifier(n_estimators=500, learning_rate=1, max_features=2, max_depth=2, random_state=0),X_train3, X_test3, y_train3, y_test3, title)","2b42ca92":"title = 'GradientBoostingClassifier\/ADASYN'\n%time Models(GradientBoostingClassifier(n_estimators=500, learning_rate=1, max_features=2, max_depth=2, random_state=0),X_train4, X_test4, y_train4, y_test4, title)","48b9a71e":"title = 'XGBClassifier\/SMOTE'\n%time Models(XGBClassifier(),X_train1, X_test1, y_train1, y_test1, title)","bded4d6f":"title = 'XGBClassifier\/BSMOTE'\n%time Models(XGBClassifier(),X_train2, X_test2, y_train2, y_test2, title)","4f0de4c2":"title = 'XGBClassifier\/SMOTESVM'\n%time Models(XGBClassifier(),X_train3, X_test3, y_train3, y_test3, title)","7e6dcbce":"title = 'XGBClassifier\/ADASYN'\n%time Models(XGBClassifier(),X_train4, X_test4, y_train4, y_test4, title)","ae85d0ab":"title = 'LGBMClassifier\/SMOTE'\n%time Models(LGBMClassifier(),X_train1, X_test1, y_train1, y_test1, title)","9c335265":"title = 'LGBMClassifier\/BSMOTE'\n%time Models(LGBMClassifier(),X_train2, X_test2, y_train2, y_test2, title)","e87a6a76":"title = 'LGBMClassifier\/ADASYN'\n%time Models(LGBMClassifier(),X_train4, X_test4, y_train4, y_test4, title)","20445e70":"title = 'LinearDiscriminantAnalysis\/SMOTE'\n%time Models(LinearDiscriminantAnalysis(),X_train1, X_test1, y_train1, y_test1, title)","543a3bac":"title = 'LinearDiscriminantAnalysis\/BSMOTE'\n%time Models(LinearDiscriminantAnalysis(),X_train2, X_test2, y_train2, y_test2, title)","d5a2ed6c":"title = 'LinearDiscriminantAnalysis\/SMOTESVM'\n%time Models(LinearDiscriminantAnalysis(),X_train3, X_test3, y_train3, y_test3, title)","06919eb0":"from sklearn.metrics import confusion_matrix,auc,roc_curve\n\ntitle = 'RandomForestClassifier\/SMOTE'\ny, ypred =  Models(RandomForestClassifier(),X_train1, X_test1, y_train1, y_test1, title)\n\nfpr, tpr, thresholds = roc_curve(y, ypred)\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b',label='AUC = %0.3f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.0])\nplt.ylim([-0.1,1.01])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","c3914641":"Yeah! All Frauds are well detected, accuracy = 98.9%, but the Bank might not like it, since normal transactions are detected as Fraud. ","b1c8b227":"# We'll use 50% of the data for the test set and the remaining 50% for the training set","3821e760":"As can see, some of our predictors do seem to be correlated with the Class variable. Nonetheless, there seem to be relatively little significant correlations for such a big number of variables. This can probably be attributed to two factors:\n\n+ The data was prepared using a PCA, therefore our predictors are principal components.\n+ The huge class imbalance might distort the importance of certain correlations with regards to our class variable.","5127e021":"# 6. Results\n\nThe 9 fraud detection models were trained and tested using 4 SMOTE approaches.\n\nThe performance results are then recorded and illustrated. This methodological approach ensures that all data were represented once as a test data and several times as a training data producing accurate results.","36dfac57":"# Adaptive Synthetic Sampling (ADASYN) \n\nAnother approach involves generating synthetic samples inversely proportional to the density of the examples in the minority class.\n\nThat is, generate more synthetic examples in regions of the feature space where the density of minority examples is low, and fewer or none where the density is high.\n\nThis modification to SMOTE is referred to as the Adaptive Synthetic Sampling Method, or ADASYN, and was proposed to [Haibo He, et al.](https:\/\/ieeexplore.ieee.org\/document\/4633969) in their 2008 paper named for the method titled \u201cADASYN: Adaptive Synthetic Sampling Approach For Imbalanced Learning.\u201d","a9e594b2":"# SMOTE With Selective Synthetic Sample Generation\n\nIn this section, we will review some extensions to SMOTE that are more selective regarding the examples from the minority class that provide the basis for generating new synthetic examples.\n\nBorderline-SMOTE\nA popular extension to SMOTE involves selecting those instances of the minority class that are misclassified, such as with a k-nearest neighbor classification model. We can then oversample just those difficult instances, providing more resolution only where it may be required.\n\n[Ref](https:\/\/link.springer.com\/chapter\/10.1007\/11538059_91): Borderline-SMOTE: A New Over-Sampling Method in Imbalanced Data Sets Learning, 2005.","950bb093":"# Borderline-SMOTE SVM\n\n[Hien Nguyen](http:\/\/ousar.lib.okayama-u.ac.jp\/en\/19617), et al. suggest using an alternative of Borderline-SMOTE where an SVM algorithm is used instead of a KNN to identify misclassified examples on the decision boundary.\n\nTheir approach is summarized in the 2009 paper titled \u201cBorderline Over-sampling For Imbalanced Data Classification.\u201d An SVM is used to locate the decision boundary defined by the support vectors and examples in the minority class that close to the support vectors become the focus for generating synthetic examples.","27f691d3":"Ss expected, most transactions are non-fraudulent. The following visualization underlines this significant contrast.","59617659":"Or here, we get accuracy = 99.53%, but upto 37% (182\/492) of Frauds are not well detected. ","951164ce":"The data set has 31 features, 28 of which have been anonymized and are labeled V1 through V28. The remaining three features are the time and the amount of the transaction as well as whether that transaction was fraudulent or not.","b83be063":"Unlike Borderline-SMOTE, we can see that the examples that have the most class overlap have the most focus. On problems where these low density examples might be outliers, the ADASYN approach may put too much attention on these areas of the feature space, which may result in worse model performance.","95fb8c2e":"**OR, the same situation we face with this model.**\n\nThe accuracy for Total Dataset is 99.19% but the Fraud prediction rate is 78.4% and NOT 99.2%.","28ad44e1":"# 3. Methodology\n\nFraud detection is a binary classification task in which any transaction will be predicted and labeled as a fraud or legit. In this Notebook state of the art classification techniques were tried for this task and their performances were compared. :\n\n+ LogisticRegression()\n+ LinearDiscriminantAnalysis()\n+ KNeighborsClassifier()\n+ RandomForestClassifier()\n+ DecisionTreeClassifier()\n+ XGBClassifier()\n+ GaussianNB()\n+ GradientBoostingClassifier()\n+ LGBMClassifier()\n\nAs we can see, there are a few algorithms that quite significantly outperformed the others. Probably, choosing Random Forest over XGBoost might be a reasonable approach in order to achieve a higher degree of comprehensiveness while only slightly decreasing performance. But fine, we will apply all of these algorithms to compare the results.","4143a18d":"# 4. Deal with Imbalanced Data using SMOTE\n\nStandard ML techniques such as Decision Tree and Logistic Regression have a bias towards the majority class, and they tend to ignore the minority class. They tend only to predict the majority class, hence, having major misclassification of the minority class in comparison with the majority class. In more technical words, if we have imbalanced data distribution in our dataset then our model becomes more prone to the case when minority class has negligible or very lesser recall.\n\nThere are mainly 2 mainly algorithms that are widely used for handling imbalanced class distribution.\n\n+ SMOTE\n+ Near Miss Algorithm\n\nSMOTE (Synthetic Minority Oversampling Technique) \u2013 Oversampling: \n\nSMOTE is one of the most commonly used oversampling methods to solve the imbalance problem. It aims to balance class distribution by randomly increasing minority class examples by replicating them. SMOTE synthesises new minority instances between existing minority instances. It generates the virtual training records by linear interpolation for the minority class. These synthetic training records are generated by randomly selecting one or more of the k-nearest neighbors for each example in the minority class. After the oversampling process, the data is reconstructed and several classification models can be applied for the processed data.\n\nNearMiss Algorithm \u2013 Undersampling\n\nNearMiss is an under-sampling technique. It aims to balance class distribution by randomly eliminating majority class examples. When instances of two different classes are very close to each other, we remove the instances of the majority class to increase the spaces between the two classes. This helps in the classification process. To prevent problem of information loss in most under-sampling techniques, near-neighbor methods are widely used.","c93a4af8":"And might be, this is the BEST one !","56e53472":"# Creating a Training Set for a Heavily Imbalanced Data Set\n\nCreating a training data set that will allow our algorithms to pick up the specific characteristics that make a transaction more or less likely to be fraudulent. Using the original data set would not prove to be a good idea for a very simple reason: Since over 99% of our transactions are non-fraudulent, an algorithm that always predicts that the transaction is non-fraudulent would achieve an accuracy higher than 99%. Nevertheless, that is the opposite of what we want. We do not want a 99% accuracy that is achieved by never labeling a transaction as fraudulent, we want to detect fraudulent transactions and label them as such.","2b007e62":"# 1. Introduction\n\nIn recent years credit card usage is predominant in modern day society and credit card fraud is keep on growing. Financial losses due to fraud affect not only merchants and banks (e.g. reimbursements), but also individual clients. If the bank loses money, customers eventually pay as well through higher interest rates, higher membership fees, etc. Fraud may also affect the reputation and image of a merchant causing non-financial losses that, though difficult to quantify in the short term, may become visible in the long period. \n\nA Fraud Detection System (FDS) should not only detect fraud cases efficiently, but also be cost-effective in the sense that the cost invested in transaction screening should not be higher than the loss due to frauds [1]. Bhatla [2] shows that screening only 2% of transactions can result in reducing fraud losses accounting for 1% of the total value of transactions. However, a review of 30% of transactions could reduce the fraud losses drastically to 0.06%, but increase the costs exorbitantly. In order to minimize costs of detection it is important to use expert rules and statistical based models (e.g. Machine Learning) to make a first screen between genuine and potential fraud and ask the investigators to review only the cases with high risk.\n\nThe predictive model scores each transaction with high or low risk of fraud and those with high risk generate alerts. Investigators check these alerts and provide a feedback for each alert, i.e. true positive (fraud) or false positive (genuine). These feedbacks can then be used to improve the model. A predictive model can be built upon experts\u2019 rules, i.e. rules based\non knowledge from fraud experts, but these require manual tuning and human supervision. Alternatively, with Machine Learning\n(ML) techniques [3] we can efficiently discover fraudulent patterns and predict transactions that are probably to be fraudulent. ML techniques consist in inferring a prediction model on the basis of a set of examples. The model is in most cases a parametric function, which allows predicting the likelihood of a transaction to be fraud, given a set of features describing the transaction. \n\nMost banks considers huge transactions, among which very few is fraudulent, often less than 0.1% [4]. Also, only a limited number of transactions can be checked by fraud investigators, i.e. we cannot ask a human person to check all transactions one by one if it is fraudulent or not.","9aa98c10":"Accuracy = 99.26%, but I do not love this, we still have 64\/492 Frauds not well predicted (or 13% WRONG).","d59b5092":"# 8. References\n\n[1] Jon TS Quah and M Sriganesh. Real-time credit card fraud detection using computational Intelligence. Expert Systems with Applications, 35(4):1721\u20131732, 2008 (10.1016\/j.eswa.2007.08.093).\n\n[2] Tej Paul Bhatla, Vikram Prabhu, and Amit Dua. Understanding credit card frauds. Cards business review, 1(6), 2003.\n\n[3] Christopher M Bishop et al. Pattern recognition and machine learning, volume 4. Springer New York, 2006.\n\n[4] Piotr Juszczak, Niall M Adams, David J Hand, Christopher Whitrow, and David J Weston. Off the peg and bespoke classifiers for fraud detection. Computational Statistics & Data Analysis, 52(9):4521\u20134532, 2008 (10.1016\/j.csda.2008.03.014).\n\n[5] Zaki, M., & Meira, W. (2014). Data Mining and Analysis: Fundamental Concepts and Algorithms. New York City, New York: Cambridge University Press (10.1017\/CBO9780511810114).","5adef3ed":"This might be also a BEST selection. ","053616a7":"Yes, this is what we wanted. Only 18 normal transactions are wrong detected.","ebbcac77":"**Wow, let stop here.**\n\nThe accuracy comes out to be 99.2% but the Fraud prediction rate is 83.4% and NOT 99%. The recall of the minority class in very less. It proves that the model is more biased towards majority class. So, it proves that this is not the best model.","1a1c7db4":"# 2. Data importing","a91cf05d":"# Outlier Detection & Removal\n\nOutlier detection is a complex topic. The trade-off between reducing the number of transactions and thus volume of information available to my algorithms and having extreme outliers skew the results of your predictions is not easily solvable and highly depends on your data and goals. In my case, I decided to focus exclusively on ML methods and will not focus on this topic. Other Kaggle Notebook have well discussed this topic.\n\nIt may help to remove outliers prior to applying the oversampling procedure, and this might be a helpful heuristic to use more generally.","c62e41c8":"# 7. Conclusion & Future Work\n\nIn total of 9 algorithms combined with 4 SMOTE approaches were used in developing fraud detection models to classify a transaction as fraudulent or legitimate. Three metrics were used in evaluating their performances. The results showed that there is probably no data mining technique that is universally better than others. Performance improvement could be achieved through developing a fraud detection model using a combination of different algorithm and SMOTE approches. It could be observed that 4 following algorithms outperformed other models in terms of the Accuracy.\n\n1. RandomForestClassifier using the SMOTE\n2. RandomForestClassifier using the ADASYN\n3. XGBClassifier using the SMOTE\n4. XGBClassifier using the ADASYN\n\nFraud detection is a complex issue that requires a substantial amount of planning before throwing machine learning algorithms at it. Nonetheless, it is also an application of data science and machine learning for the good, which makes sure that the customer\u2019s money is safe and not easily tampered with.\n\nFuture work will include a comprehensive tuning of these 4 algorithms. Having a data set with non-anonymized features would make this particularly interesting as outputting the feature importance would enable one to see what specific factors are most important for detecting fraudulent transactions.","4c8d1222":"# 5. Machine Learning Algorithms\n\n**Performance metrics**\n\nA number of performance metrics could be used to report the performance of the fraud detection classifiers including the confusion matrix, Sensitivity, Specificity, false positive rate, balanced classification Rate and Matthews correlation coefficient.\n\nConfusion matrix\n\nA confusion matrix of a binary classifier is a table that shows the number of instances classified correctly\/incorrectly in each class. The Confusion Matrix of a Binary Classifier.\n\n_______________________________________________________________________\nActual |  Predicted\n\nPositive (Legit)     |  true positive (TP)     |     false positive (FP)\n\nNegative (Fraud)     |  false negative (FN)    |     true negative (TN)\n_______________________________________________________________________\n\nSpecificity is defined as the number of fraud case predictions to the total number of fraud cases.\n\nSpecificity =TN\/ (TN + FP)\n\nSensitivity is defined as the number of legit predictions compared to the total number of legit transactions. In fraud detection, the most important measure is specificity or fraud detection rate, as a higher value of recall means a lowest financial loss to the company.\n\nSensitivity =TP\/ (TP + FN)\n\nAccuracy gives the overall efficacy of the proposed system. It is defined as the total number of predictions to the total number of cases.\n\nAccuracy = (TP + TN) \/ (TP + TN + FP + FN)\n\nAccuracy of the model can be misleading in case of credit card fraud detection, where the numbers of fraudulent transactions is\nmuch lower than the legitimate transactions and the dataset is highly imbalanced. Selecting the right performance metrics depends on the business objective because one measure can help to prevent financial losses and the other can help to gain customer satisfaction.","0a8ec274":"Finally, it would be interesting to know if there are any significant correlations between our predictors, especially with regards to our class variable. One of the most visually appealing ways to determine that is by using a heatmap.","9315c27f":"Libraries for illustration","990b38ea":"# Introduction\n\nWith the extensive use of credit cards, fraud appears as a major issue in the credit card business. It is hard to have some figures on the impact of fraud, since companies and banks do not like to disclose the amount of losses due to frauds. At the same time, public data are scarcely available for confidentiality issues, leaving unanswered many questions about what is the best strategy. Another problem in creditcard fraud loss estimation is that we can measure the loss of only those frauds that have been detected, and it is not possible to assess the size of unreported\/undetected frauds. Fraud patterns are changing rapidly where fraud detection needs to be re-evaluated from a reactive to a proactive approach. \n\nIn recent years, machine learning has gained lot of popularity in image analysis, natural language processing and speech recognition. In this regard, implementation of efficient fraud detection algorithms using machine-learning techniques is key for\nreducing these losses, and to assist fraud investigators. In this Notebook, machine learning methods are used to detect credit card fraud. The main purpose of this Notebook is to learn how to use, apply and review options for using machine learning and to receive additional comments, recommendations from Kaggle experts, other data scientists. \n\nThe results show logistic regression based approaches outperforms with the highest accuracy and it can be effectively used for fraud investigators.","578a43f7":"The data set contains 284,807 transactions. The mean value of all transactions is 88.35USD while the largest transaction recorded in this data set amounts to 25,691USD. However, as you might be guessing right now based on the mean and maximum, the distribution of the monetary value of all transactions is heavily right-skewed. The vast majority of transactions are relatively small and only a tiny fraction of transactions comes even close to the maximum.","491607c9":"<img src=\"https:\/\/i.ibb.co\/F4PS1b0\/False-True.jpg\" alt=\"False-True\" border=\"0\"><\/a>","097b7453":"Librairies for ML"}}