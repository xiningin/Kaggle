{"cell_type":{"63d3f2db":"code","9461549d":"code","a890434a":"code","8dd67101":"code","f85a819d":"code","e8d95a8f":"code","4460d5dd":"code","c63366c1":"code","adcb517a":"code","eb911f91":"code","2fe91d58":"code","14273829":"code","7a8d4da5":"markdown","e62316cf":"markdown","838f2617":"markdown","f1304e95":"markdown","5a4421e8":"markdown","c250c346":"markdown","346afedf":"markdown"},"source":{"63d3f2db":"import tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow_addons as tfa\nimport numpy as np\nimport cv2\n\nfrom tensorflow.data.experimental import AUTOTUNE\nfrom matplotlib import pyplot as plt\n\nimport os\nimport datetime\n\nfrom glob import glob\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\n\n%load_ext tensorboard\n\nAUTO = tf.data.experimental.AUTOTUNE","9461549d":"IMAGE_SIZE = [48, 48]\n\nEPOCHS = 150\nBATCH_SIZE = 128\n\n# directory path for training data\nDATA_PATH = '..\/input\/mma-facial-expression\/MMAFEDB'\n\nTRAIN_PATH = DATA_PATH + '\/train\/'\nVALID_PATH = DATA_PATH + '\/valid\/'\nTEST_PATH = DATA_PATH + '\/test\/'\n\n# names of classes\nCLASSES = os.listdir(DATA_PATH + '\/train')\nprint(CLASSES)\n\nnumber_of_classes = len(CLASSES)\nlearning_rate = .1","a890434a":"def get_dataset(path, shuffle=True):\n    \"\"\"Load dataset from directory\"\"\"\n    generator = tf.keras.preprocessing.image.ImageDataGenerator(\n        rescale=1\/255,\n        rotation_range=15,\n        width_shift_range=0.15,\n        height_shift_range=0.15,\n        shear_range=0.15,\n        zoom_range=0.15,\n        horizontal_flip=True,\n    )\n    dataset = generator.flow_from_directory(\n        path,\n        classes=CLASSES,\n        class_mode='categorical',\n        batch_size=BATCH_SIZE,\n        shuffle=shuffle,\n        target_size=IMAGE_SIZE\n    )\n    return dataset","8dd67101":"train = get_dataset(TRAIN_PATH)\nvalid = get_dataset(VALID_PATH)\ntest = get_dataset(TEST_PATH)","f85a819d":"plt.figure(figsize=(48, 4))\ndatasets = [('train', TRAIN_PATH), ('valid', VALID_PATH), ('test', TEST_PATH)]\n\n# plot dataset class distribution\nfor i in range(len(datasets)):\n    name, path = datasets[i]\n    counts = {subdir: len(os.listdir(f'{path}\/{subdir}')) for subdir in os.listdir(path)}\n    nclasses = len(counts)\n    \n    x = range(nclasses)\n    plt.subplot(1, nclasses, i + 1)\n    plt.bar(x, counts.values(), color='lightcyan', edgecolor='grey')\n    plt.xticks(x, counts.keys())\n    plt.title(name)\n\nplt.show()\n","e8d95a8f":"def plot_samples(data):\n    # plot dataset sample images\n    plt.figure(figsize=(16, 16))\n    X_batch, y_batch = next(data)\n    for i in range(0, 16):\n        plt.subplot(4, 4, i + 1)\n        plt.imshow(X_batch[i])\n        plt.title(CLASSES[np.argmax(y_batch[i])])\n    plt.show()\n\nplot_samples(train)","4460d5dd":"class layers:\n    class ResidualUnit(keras.layers.Layer):\n        def __init__(self, filters, strides, activation='relu', **kwargs):\n            super().__init__(**kwargs)\n\n            self.activation = keras.activations.get(activation)\n            self.layers = [\n                keras.layers.Conv2D(filters, 3, strides, padding='same', use_bias=False),\n                keras.layers.BatchNormalization(),\n                self.activation,\n                keras.layers.Conv2D(filters, 3, 1, padding='same', use_bias=False),\n                keras.layers.BatchNormalization(),\n            ]\n\n            if strides == 1:\n                self.skip = []\n            else:\n                self.skip = [\n                    keras.layers.Conv2D(filters, 1, strides, padding='same', use_bias=False),\n                    keras.layers.BatchNormalization(),\n                ]\n\n        def __call__(self, inputs):\n            Z = Z_skip = inputs\n            for layer in self.layers:\n                Z = layer(Z)\n            for layer in self.skip:\n                Z_skip = layer(Z_skip)\n            return self.activation(Z + Z_skip)\n\n\n\n    class DeepResidualUnit(keras.layers.Layer):\n        def __init__(self, filters, strides, activation='relu', **kwargs):\n            super().__init__(**kwargs)\n\n            self.activation = keras.activations.get(activation)\n            self.layers = [\n                keras.layers.Conv2D(filters \/\/ 4, 1, strides, padding='same', use_bias=False),\n                keras.layers.BatchNormalization(),\n                self.activation,\n                keras.layers.Conv2D(filters \/\/ 4, 3, 1, padding='same', use_bias=False),\n                keras.layers.BatchNormalization(),\n                self.activation,\n                keras.layers.Conv2D(filters, 1, 1, padding='same', use_bias=False),\n                keras.layers.BatchNormalization(),\n            ]\n\n            if strides == 1:\n                self.skip = []\n            else:\n                self.skip = [\n                    keras.layers.Conv2D(filters, 1, strides, padding='same', use_bias=False),\n                    keras.layers.BatchNormalization(),\n                ]\n\n        def __call__(self, inputs):\n            Z = Z_skip = inputs\n            for layer in self.layers:\n                Z = layer(Z)\n            for layer in self.skip:\n                Z_skip = layer(Z_skip)\n            return self.activation(Z + Z_skip)\n\n\n\ndef ResNet34():\n    model = keras.models.Sequential()\n    model.add(keras.layers.Conv2D(64, 7, strides=2, padding='same', input_shape=(None, None, 3)))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.Activation('relu'))\n    model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\"))\n\n    filters = [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3\n\n    prev_filters = filters[0]\n    for filters in filters:\n        strides = 1 if filters == prev_filters else 2\n        model.add(layers.ResidualUnit(filters, strides))\n        prev_filters = filters\n\n    model.add(keras.layers.GlobalAveragePooling2D())\n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(number_of_classes, 'softmax'))\n\n    return model\n\n\n\ndef ResNet152():\n    model = keras.models.Sequential()\n    model.add(keras.layers.Conv2D(64, 7, strides=2, padding='same', input_shape=(None, None, 3)))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.Activation('relu'))\n    \n    model.add(keras.layers.Conv2D(256, 1, strides=1, padding='same', input_shape=(None, None, 3)))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.Activation('relu'))\n    \n    model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\"))\n\n    filters = [256] * 3 + [512] * 8 + [1024] * 36 + [2048] * 3\n\n    prev_filters = filters[0]\n    for filters in filters:\n        strides = 1 if filters == prev_filters else 2\n        model.add(layers.DeepResidualUnit(filters, strides))\n        prev_filters = filters\n\n    model.add(keras.layers.GlobalAveragePooling2D())\n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(number_of_classes, 'softmax'))\n\n    return model\n\n\n\ndef ResNet(filters):\n    model = keras.models.Sequential()\n    model.add(keras.layers.Conv2D(64, 7, strides=2, padding='same', input_shape=(None, None, 3)))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.Activation('relu'))\n    model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\"))\n\n    prev_filters = filters[0]\n    for filters in filters:\n        strides = 1 if filters == prev_filters else 2\n        model.add(layers.ResidualUnit(filters, strides))\n        prev_filters = filters\n\n    model.add(keras.layers.GlobalAveragePooling2D())\n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(number_of_classes, 'elu'))\n    model.add(keras.layers.Dropout(.4))\n    model.add(keras.layers.Dense(number_of_classes, 'softmax'))\n\n    return model\n\n\n\ndef SimpleCNN(activation='relu'):\n    model = keras.models.Sequential()\n    params = {\n            'activation': activation,\n            'padding': 'same',\n            'kernel_initializer': 'he_normal',\n    }\n    \n    model.add(keras.layers.Conv2D(64, 7, strides=2, input_shape=(None, None, 3), **params))\n    \n    model.add(keras.layers.Conv2D(128, 5, strides=2, **params))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.Conv2D(128, 5, strides=1, **params))\n    model.add(keras.layers.BatchNormalization())\n    \n    model.add(keras.layers.Conv2D(256, 3, strides=2, **params))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.Conv2D(256, 3, strides=1, **params))\n    model.add(keras.layers.BatchNormalization())\n\n    model.add(keras.layers.GlobalAveragePooling2D())\n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(number_of_classes, 'softmax'))\n\n    return model","c63366c1":"log_dir = 'logs\/' + datetime.datetime.now().strftime('%Y-%m-%d_%H:%M:%S')\n\ndef compile_model(model):\n    model.compile(\n        optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n        loss='categorical_crossentropy',\n        metrics=[keras.metrics.CategoricalAccuracy(name='accuracy'),\n                 tfa.metrics.F1Score(num_classes=len(CLASSES))],\n    )\n\n    return model\n\n#         12px     6px       3px\n# filters = 1*[64] + 2*[128] + 1*[256]\n# model = ResNet(filters) # 48 40\n\n# model = ResNet34() # 56, 48\n\nmodel = SimpleCNN(activation='elu') # 50 51\nmodel = compile_model(model)\nprint(f'number of parameters: {model.count_params()}')\n\n\n# define callbacks\ntensor_board = keras.callbacks.TensorBoard(log_dir='..\/output\/logs')\nlr_schedule = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=7, verbose=1)\nearly_stopping = tf.keras.callbacks.EarlyStopping(patience=10, verbose=1, restore_best_weights=True)\n\n# training constants\nVALIDATION_STEPS = 100\nSTEPS_PER_EPOCH = 500\nEPOCHS = 50\n\n# train model\nhistory = model.fit(\n    train, \n    validation_data=valid,\n    epochs=EPOCHS, \n    validation_steps=VALIDATION_STEPS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_schedule, early_stopping],\n)","adcb517a":"def display_training_curves(training, validation, title, subplot):\n    plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'validation'])\n    \ndisplay_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 212)\ndisplay_training_curves(history.history['f1_score'], history.history['val_f1_score'], 'f1 score', 211)\nplt.show()","eb911f91":"# evaluate model performance\ntest_it = iter(test)\ntest_sample = [next(test_it) for _ in range(10)]\nx = [sample for batch in test_sample for sample in batch[0]]\ny = [sample for batch in test_sample for sample in batch[1]]\n# images, labels\nx, y = np.array(x), np.array(y)\n\nprint('test shapes', x.shape, y.shape)\np = model.predict(x) # probabilities\nP = np.argmax(p, axis=-1) # prediction classes\nY = y.argmax(axis=-1) # target classes","2fe91d58":"def display_confusion_matrix(cmat, score, precision, recall):\n    plt.figure(figsize=(15,15))\n    ax = plt.gca()\n    ax.matshow(cmat, cmap='Reds')\n    ax.set_xticks(range(len(CLASSES)))\n    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n    ax.set_yticks(range(len(CLASSES)))\n    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n    titlestring = \"\"\n    if score is not None:\n        titlestring += 'f1 = {:.3f} '.format(score)\n    if precision is not None:\n        titlestring += '\\nprecision = {:.3f} '.format(precision)\n    if recall is not None:\n        titlestring += '\\nrecall = {:.3f} '.format(recall)\n    if len(titlestring) > 0:\n        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n    plt.show()\n\ncmat = confusion_matrix(Y, P)\nscore = f1_score(Y, P, average='macro')\nprecision = precision_score(Y, P, average='macro')\nrecall = recall_score(Y, P, average='macro')\ncmat = (cmat.T \/ cmat.sum(axis=1)).T \ndisplay_confusion_matrix(cmat, score, precision, recall)\nprint('f1 score: {:.3f}, precision: {:.3f}, recall: {:.3f}'.format(score, precision, recall))","14273829":"def display_batch_of_images(x, Y, P, nsamples=20):\n    plt.figure(figsize=(20, 16))\n    for i in range(nsamples):\n        plt.subplot(4, 5, i+1)\n        plt.imshow(x[i])\n        plt.title(CLASSES[Y[i]])\n\n# plot image and predicted class\ndisplay_batch_of_images(x, Y, P)","7a8d4da5":"# Results","e62316cf":"# Training","838f2617":"# Predictions Visual validation","f1304e95":"# Dataset","5a4421e8":"# Model","c250c346":"# Configuration","346afedf":"# Dataset visualizations"}}