{"cell_type":{"752634c4":"code","aba26ba7":"code","613c6715":"code","4052ab3e":"code","02fe0ef1":"code","4a291c08":"code","f8e54f9a":"code","3f6252e3":"code","d3381435":"code","88b69c5d":"code","19dabf51":"code","b550b493":"code","a51a8453":"code","cb863fdc":"code","2b2558cc":"code","a4353bfb":"markdown","33cf0337":"markdown","c2f2f952":"markdown","2638b0f4":"markdown","93cbeaa2":"markdown","33ff07a3":"markdown","b887d78c":"markdown","be40a636":"markdown"},"source":{"752634c4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndata1=pd.read_csv('..\/input\/titanic\/train.csv')\ndata1.head()","aba26ba7":"mean_prob_for_survival=data1['Survived'].mean()\nprint (mean_prob_for_survival)\nstd_for_survival=data1['Survived'].std()\nsns.countplot(np.random.binomial(n=1, p=mean_prob_for_survival, size=1000))","613c6715":"import pymc3 as pm\nwith pm.Model() as model_survived:\n    p=pm.Uniform('p', lower=0, upper=1)\n    y=pm.Binomial('survived',n=1,p=p, observed=data1[~data1['Survived'].isna()]['Survived'].values)\n    trace_survived=pm.sample(1000, tune=1000)","4052ab3e":"import arviz as az\nfrom theano import shared\naz.plot_trace(trace_survived)","02fe0ef1":"az.summary(trace_survived)\n#Highest Posterior Density\n#Below is the plot for the same","4a291c08":"az.plot_posterior(trace_survived);","f8e54f9a":"ppc = pm.sample_posterior_predictive(trace_survived, samples=1, model=model_survived)\nage_samples=np.asarray(ppc['survived'])\n","3f6252e3":"import pymc3 as pm\nwith pm.Model() as model_age:\n    mue=pm.Uniform('mue', lower=0, upper=150)\n    sigma=pm.HalfNormal('sigma', sd=10)\n    y=pm.Normal('Age', mu=mue, sd=sigma, observed=data1[~data1['Age'].isna()]['Age'].values)\n    trace_age=pm.sample(1000, tune=1000)","d3381435":"import arviz as az\nfrom theano import shared\naz.summary(trace_age)","88b69c5d":"az.plot_trace(trace_age);","19dabf51":"az.plot_joint(trace_age, kind='kde', fill_last=False);","b550b493":"with model_age:\n    short_trace = pm.sample(600, chains=4, random_seed=1234)","a51a8453":"ppc = pm.sample_posterior_predictive(trace_age, samples=1000, model=model_age)\nage_samples=np.asarray(ppc['Age'])","cb863fdc":"age_samples.shape","2b2558cc":"More to follow...","a4353bfb":"![image.png](attachment:image.png)\n\n\non the right data with no outliers. We can all of them agree in terms of fit fot distribution. But the plot on left has some outliers. Gaussian has been affected a lot, whereas student T hardly changed. ","33cf0337":"Below we are doing the same using Pymc3\n* We have defined a uniform prior on probability p (one of the parameter of Binomial distribution)\n* y is observed variable representing the data that comes from  a binomial distrbution with paramter p (likelihood function)\n* With Likelihood function we are telling pymc3 we want to condition the unknown on the data\n* in trace_survived we are drawing 1000 posterior samples for the parameter p\n","c2f2f952":"![image.png](attachment:image.png)","2638b0f4":"# Different kinds of Distributions:\n\n* Discrete- \n    * Binomial Distribution\n    * Bernoulli Distribution\n    * Multinomial Distrbution\n    * Poisson Distribution\n* Continuous-\n    * Gaussian Distribution\n    * Laplace Distribution\n    * Gamma Distribution\n    * Beta Distribution\n* Multivariate Distribution\n* Montecarlo Approximation\n* Information theory\n\n","93cbeaa2":"# Gaussian Distribution\nIt is the most widely used distribution in statistics. \n    * has only two paramters, easy to interpret\n    * Sum of independent Gaussians is a Gaussian- makes it a good choice for modelling noise\/errors\n    * Gaussian dist is convinient\n    \n![image.png](attachment:image.png)\n    \n    \n# Student T Distribution\nOne of the problems with Gaussian is that they are sensitive to outliers. The log probability only decays quadratically with distance from the center. Student T is one robust distribution with heavy tails. \n","33ff07a3":"# Binomial Distribution \nSuppose we toss coin n times and $X\\in \\{0,...,n\\}$ be the number of heads. if the probability of getting heads is $p(\\theta)$, then we can say that X has a binomial distribution. In the above dataset if we take the columns Survived. Survived can be described as a coin toss if heads(say) \ncomes, person survives otherwise he dies. let's model the above using Binomial Distribution","b887d78c":"![image.png](attachment:image.png)","be40a636":"* As we can see above the mean of the parameter p is at 0.38, which is close to the data probability we calculated\n* both the chains have converged"}}