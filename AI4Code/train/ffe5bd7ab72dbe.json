{"cell_type":{"aa9af6d9":"code","a2c44e73":"code","54f09006":"code","de4ea10d":"code","39023670":"code","9a891fe7":"code","730589f5":"code","bdc1d0f8":"code","35f0fc21":"code","c453ec5b":"code","e0345c13":"code","5aca8e69":"code","8114ece9":"code","45e4a350":"code","b78ee2e4":"code","adc1bdfd":"code","38241eda":"code","520a7117":"code","55915c7d":"code","62f31ea5":"code","e7501940":"code","bae6014e":"code","b19f7e0c":"code","0099ac70":"code","1b76f453":"code","260accbe":"code","956ba461":"code","41865830":"code","9e8b3e62":"code","1c801c33":"code","49170cf5":"code","4cb96acc":"markdown","94287e67":"markdown","f0093d12":"markdown","fbf579a1":"markdown","a2346dd6":"markdown","a6d03f66":"markdown","3c502f09":"markdown","28bef1b5":"markdown","4518c73b":"markdown","056bd295":"markdown","35266fe6":"markdown","b6bc03ad":"markdown","03666a74":"markdown","255d0a38":"markdown","5b532b08":"markdown","a9b395f9":"markdown","31c510c4":"markdown","a69823c4":"markdown","6f6c2685":"markdown","18f14395":"markdown","41b85d7e":"markdown","91d73ccf":"markdown","99130cb5":"markdown","1cd999b3":"markdown","0eb8938a":"markdown"},"source":{"aa9af6d9":"# Common\nimport numpy as np\nimport pandas as pd\n# Spliting\nfrom sklearn.model_selection import train_test_split\n# Feture Selection\nfrom sklearn.ensemble import RandomForestClassifier\n# Visualization\nimport matplotlib.pyplot as plt\n# Models\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nimport xgboost\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.cluster import KMeans\nfrom sklearn.mixture import GaussianMixture\n# Evaluation\nfrom sklearn.metrics import confusion_matrix, f1_score\n# Tuning\nfrom sklearn.model_selection import GridSearchCV\n# Scaler\nfrom sklearn.preprocessing import StandardScaler","a2c44e73":"df = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")\ndf.head()","54f09006":"df.isnull().sum()","de4ea10d":"X_data = df.iloc[:,:-1]\nY_data = df['target']\nprint(f\" CD : {np.bincount(Y_data)}\")","39023670":"X_train,X_test,Y_train,Y_test = train_test_split(X_data,Y_data,test_size=0.2)","9a891fe7":"print(f\"X Train : {X_train.shape}\")\nprint(f\"Y Train : {Y_train.shape}\")\nprint(f\"X Test : {X_test.shape}\")\nprint(f\"Y Test : {Y_test.shape}\")","730589f5":"RFC = RandomForestClassifier().fit(X_train,Y_train)\nfeature_imp_ = RFC.feature_importances_","bdc1d0f8":"X_cols = X_data.columns\nX_cols","35f0fc21":"plt.figure(figsize=(10,8))\nplt.bar(X_cols,feature_imp_,color=\"steelblue\",label=\"Features\")\nplt.bar(X_cols[np.where(feature_imp_==feature_imp_.max())],feature_imp_.max(),color=\"green\",label=\"Max\")\nplt.bar(X_cols[np.where(feature_imp_==feature_imp_.min())],feature_imp_.min(),color=\"purple\",label=\"Min\")\nplt.xticks(rotation=70)\nplt.legend()\nplt.ylabel(\"Importnace Score\")\nplt.title(\"Feature Importnace\")\nplt.show()","c453ec5b":"def evaluation(model):\n  y_pred_model = model.predict(X_test)\n  print(f\"Accuracy : {model.score(X_test,Y_test)}\")\n  print(f\"CM : \\n {confusion_matrix(Y_test,y_pred_model)}\")\n  print(f\"F1 Score  : {f1_score(Y_test,y_pred_model)}\")","e0345c13":"vector_machine = SVC()\nvector_machine.fit(X_train,Y_train)\nevaluation(vector_machine)","5aca8e69":"gs_svc = GridSearchCV(vector_machine,param_grid={\"C\":[0.001,0.01,0.1,1.0,10.0,100.0]},cv=10)\ngs_svc.fit(X_train,Y_train)","8114ece9":"gs_svc.best_params_","45e4a350":"best_svc = gs_svc.best_estimator_\nbest_svc.fit(X_train,Y_train)\nevaluation(best_svc)","b78ee2e4":"Sc = StandardScaler()\nX_train_sc, X_test_sc = Sc.fit_transform(X_train), Sc.transform(X_test) ","adc1bdfd":"scaled_svc = gs_svc.best_estimator_\nscaled_svc.fit(X_train_sc,Y_train)\nevaluation(scaled_svc)","38241eda":"RFC = RandomForestClassifier(max_depth=10)\nRFC.fit(X_train,Y_train)\nevaluation(RFC)","520a7117":"gs_rfc = GridSearchCV(RFC,param_grid={\"max_depth\":[10,30,50,70,100],\"n_estimators\":[100,200,300,500]},cv=5)\ngs_rfc.fit(X_train,Y_train)","55915c7d":"gs_rfc.best_params_","62f31ea5":"best_rfc = gs_rfc.best_estimator_\nbest_rfc.fit(X_train,Y_train)\nevaluation(best_rfc)","e7501940":"AdaBC = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=10),n_estimators=100,learning_rate=1.0)\nAdaBC.fit(X_train,Y_train)\nevaluation(AdaBC)","bae6014e":"gs_ada = GridSearchCV(AdaBC,param_grid={\"learning_rate\":[0.001,0.01,0.1,1.0,10.0,100.0],\"n_estimators\":[50,100,200,300,500]},cv=5,scoring=\"accuracy\")\ngs_ada.fit(X_train,Y_train)","b19f7e0c":"gs_ada.best_params_","0099ac70":"gs_ada.best_score_","1b76f453":"best_ada = gs_ada.best_estimator_\nbest_ada.fit(X_train,Y_train)\nevaluation(best_ada)","260accbe":"DTC = DecisionTreeClassifier(max_depth=10)\nDTC.fit(X_train,Y_train)\nevaluation(DTC)","956ba461":"gs_dtc = GridSearchCV(DTC,param_grid={\"max_depth\":[50,10,20,30,80,100]},cv=5,scoring=\"accuracy\")\ngs_dtc.fit(X_train,Y_train)","41865830":"best_dtc = gs_dtc.best_estimator_\nbest_dtc.fit(X_train,Y_train)\nevaluation(best_dtc)","9e8b3e62":"Kmeans = KMeans(n_clusters=2)\nKmeans.fit(X_train,Y_train)\nevaluation(Kmeans) # Accuracy(i.e. score) gives -ve of inertia.","1c801c33":"gmm = GaussianMixture(n_components=2)\ngmm.fit(X_train,Y_train)\nevaluation(gmm) # Accuracy(i.e. score) gives -ve of inertia.","49170cf5":"def best_model(models,X_test,Y_test,n_):\n  acc_ = []\n  for i in models:\n    acc = i.score(X_test,Y_test)\n    acc_.append(acc)\n  plt.bar(n_,acc_,color=\"green\",label=\"Models\")\n  plt.bar(n_[acc_.index(np.max(acc_))],np.max(acc_),color=\"red\",label=\"Max\")\n  plt.bar(n_[acc_.index(np.min(acc_))],np.min(acc_),color=\"blue\",label=\"Min\")\n  plt.title(\"Model Comparision\")\n  plt.legend()\n  plt.xticks(rotation=45)\n  plt.ylabel(\"Accuracy Score\")\n  plt.show()\nmodels = [vector_machine,best_svc,scaled_svc,RFC,best_rfc,AdaBC,best_ada,DTC,best_dtc]\nbest_model(models,X_test,Y_test,n_=[\"SVC\",\"GS_SVC\",\"Scaled_SVC\",\"RFC\",\"GS_RFC\",\"AdaBoost\",\"GS_AdaBoost\",\"DTC\",\"GS_DTC\"])","4cb96acc":"#$Imports$","94287e67":"A little better not much. Scaling the input may help.","f0093d12":"This time too, let's keep the normal one.","fbf579a1":"##$Kmeans$","a2346dd6":"##$RandomForest$","a6d03f66":"<table align=\"left\">\n  <td>\n    <a href=\"https:\/\/colab.research.google.com\/drive\/1hR92YKQZ6_PWoeOEH8TWe9MjPbFx5FAr\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>\n  <\/td>\n  <td>\n    <a target=\"_blank\" href=\"https:\/\/www.kaggle.com\/coderyug\/heart-disease-multiple-models-rfc\">\n  <img src=\"https:\/\/kaggle.com\/static\/images\/open-in-kaggle.svg\" \/><\/a>\n  <\/td>\n<\/table>","3c502f09":"#$Cause$\n---\nInteresting, no one is able to perform more than 80%\n\n----\nCause for such a low accuracy :\n1. $Small$ $Dataset$\n\n---","28bef1b5":"##$Gausian$ $Mixture$","4518c73b":"As we can see $\"fbs\"$ and $\"restecg\"$ are `not that important` compare to others, we can `remove` them from the `dataset`. This will `save training time` and `model` will `generalize better`. But this is a `small dataset` that's why I am `not removing it`.","056bd295":"Let's Try tuning it","35266fe6":"##$DecisionTree$","b6bc03ad":"There is `not` much `Class Imbalance`. Hence, `no need` of `Resampling or Stratifying`.","03666a74":"#$Data$","255d0a38":"Yeah!!, good let's move to feature selection\/importnace.","5b532b08":"$Great!!$ There are `no null values`. I think some of the `features` like the `\"sex\"` does `not affect` the `data`, so in `order` to `check` it let's do `feature selection`.","a9b395f9":"#$Feature$ $Importance$","31c510c4":"We can `conclude` that $RFC$ works `best` for this `problem`.\n\n----","a69823c4":"Ahhh great!!, the data is good as it does not have categorical values. Let's check for the null values.","6f6c2685":"Nahh!!!. Let's keep the previous version only.","18f14395":"#$Spliting$ $Data$","41b85d7e":"My expectations was more than the results","91d73ccf":"#$Models$","99130cb5":"##$AdaBoost$","1cd999b3":"##Function","0eb8938a":"##$SVC$"}}