{"cell_type":{"63657bad":"code","8c6b2733":"code","72f1c2e4":"code","12483a0c":"code","69a2e340":"code","bdb4cd32":"code","3c8ba4c2":"code","80e3b120":"code","ad3e65c9":"code","1b7c81b7":"code","aa59c8ad":"code","e82470c5":"code","12bb8297":"code","24ecd176":"code","1dbf7b23":"code","aac3725f":"code","11655436":"code","abec4f56":"code","e6426e5e":"code","b6590a44":"code","45b44d22":"code","4bb5c0ed":"code","124c2994":"code","e6db71d7":"code","54915ef6":"code","1a0d1b8e":"code","afd86763":"code","05e81b9e":"code","d043fc7e":"code","2c6aefb9":"code","0657485a":"code","b5352da8":"code","4956879c":"code","685a666f":"code","3194490f":"code","75c119d4":"code","0fa96028":"code","c6f3cd51":"code","ff0ba8ae":"code","643ddff7":"markdown","d4f90626":"markdown","fe18d0ca":"markdown","162498f0":"markdown"},"source":{"63657bad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn.linear_model\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8c6b2733":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","72f1c2e4":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","12483a0c":"train_data.isnull().sum()","69a2e340":"train_data.fillna({'Age':train_data['Age'].mean()}, inplace = True)\ntrain_data = train_data.drop(['Cabin'], axis = 1) #most of the data in cabin is missing...\ntrain_data.isnull().sum()","bdb4cd32":"test_data.isnull().sum()","3c8ba4c2":"test_data.fillna({'Age':test_data['Age'].mean(), 'Fare':test_data['Fare'].mean()}, inplace = True)\ntest_data = test_data.drop(['Cabin'], axis = 1)\ntest_data.isnull().sum()","80e3b120":"sns.set_style('whitegrid')\nsns.countplot(x = \"Survived\", hue = \"Sex\", data = train_data)","ad3e65c9":"train_test_data = [train_data, test_data]\nsex = {\"male\":0, \"female\":1}\nfor dataset in train_test_data:\n    dataset[\"Sex\"] = dataset[\"Sex\"].map(sex)\n","1b7c81b7":"sns.set_style('whitegrid')\nsns.countplot(x = \"Survived\", hue = \"Pclass\", data = train_data)","aa59c8ad":"sns.set_style('whitegrid')\nsns.countplot(x = 'Survived', hue = 'Embarked', data = train_data)","e82470c5":"train_data.fillna({'Embarked': 'S'}, inplace = True)\ntrain_data.info()","12bb8297":"sns.countplot(x = \"Survived\", hue = \"SibSp\", data = train_data)","24ecd176":"embarked = {'S':0, 'Q':1, 'C':2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked)","1dbf7b23":"test_data.head()","aac3725f":"train_data.drop(['PassengerId', 'Name', 'Ticket'], axis = 1, inplace = True)\nsurvived = train_data['Survived']\ntrain_data.drop(['Survived'], axis = 1, inplace = True)\ntrain_data","11655436":"for i in train_data:\n    train_data[i] \/= max(train_data[i])","abec4f56":"train_data.head()","e6426e5e":"passenger_id = test_data['PassengerId']\ntest_data.drop(['PassengerId', 'Name', 'Ticket'], axis = 1, inplace = True)","b6590a44":"for i in test_data:\n    test_data[i] \/= max(test_data[i])","45b44d22":"X_train = train_data.to_numpy()","4bb5c0ed":"X_train = X_train.T\nY_train = np.array([survived])\nY_train.shape","124c2994":"X_test = test_data.to_numpy()","e6db71d7":"X_test = X_test.T\nX_test.shape","54915ef6":"def sigmoid(z):\n    s = 1\/(1+np.exp(-z))\n    return s","1a0d1b8e":"def initialize_with_zeros(dim):\n    w = np.zeros((dim, 1))\n    b = 0\n    \n    assert (w.shape == (dim, 1))\n    assert (isinstance(b, float) or isinstance(b, int))\n    \n    return w, b","afd86763":"def propagate(w, b, X, Y):\n    \n    m = X.shape[1]\n    \n    A = sigmoid(np.dot(w.T, X)+b)                                   \n    cost = -(1\/m) * np.sum(Y * np.log(A) + (1-Y) * np.log(1-A)) \n    \n    dw = 1\/m * np.dot(X, (A-Y).T)\n    db = 1\/m * np.sum(A-Y)\n\n    assert(dw.shape == w.shape)\n    assert(db.dtype == float)\n    cost = np.squeeze(cost)\n    assert(cost.shape == ())\n    \n    grads = {\"dw\": dw,\n             \"db\": db}\n    \n    return grads, cost","05e81b9e":"def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n    \n    costs = []\n    \n    for i in range(num_iterations):\n        \n        \n        grads, cost = propagate(w, b, X, Y)\n        \n        \n        dw = grads[\"dw\"]\n        db = grads[\"db\"]\n        \n        w = w - learning_rate * dw\n        b = b - learning_rate * db\n    \n        if i % 100 == 0:\n            costs.append(cost)\n        \n        if print_cost and i % 100 == 0:\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n    \n    params = {\"w\": w,\n              \"b\": b}\n    \n    grads = {\"dw\": dw,\n             \"db\": db}\n    \n    return params, grads, costs","d043fc7e":"def predict(w, b, X):\n    \n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    #print(w.shape)\n    w = w.reshape(X.shape[0], 1)\n    #print(w.shape)\n    A = sigmoid(np.dot(w.T, X) + b)\n    #print(A.shape[1])\n    for i in range(A.shape[1]):\n        #print(A[0, i])\n        if A[0, i] <= 0.5:\n            Y_prediction[0, i] = 0\n        else:\n            Y_prediction[0, i] = 1\n    \n    assert(Y_prediction.shape == (1, m))\n    \n    return Y_prediction","2c6aefb9":"w = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\nprint (\"predictions = \" + str(predict(w, b, X)))\npred = predict(w, b, X)\ntype(pred)","0657485a":"def model(X_train, Y_train, X_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n    \n    w, b = initialize_with_zeros(X_train.shape[0])\n\n    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost = False)\n    \n    w = parameters[\"w\"]\n    b = parameters[\"b\"]\n    \n    \n    Y_prediction_test = predict(w, b, X_test)\n    Y_prediction_train = predict(w, b, X_train)\n\n\n    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n    #print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n\n    \n    d = {\"costs\": costs,\n         \"Y_prediction_test\": Y_prediction_test, \n         \"Y_prediction_train\" : Y_prediction_train, \n         \"w\" : w, \n         \"b\" : b,\n         \"learning_rate\" : learning_rate,\n         \"num_iterations\": num_iterations}\n    \n    return d['Y_prediction_test']","b5352da8":"d = model(X_train, Y_train, X_test, num_iterations = 3000, learning_rate = 0.3, print_cost = True)\nd","4956879c":"Y_prediction = d\nY_prediction = Y_prediction.astype('int32')\nY_prediction = Y_prediction.T\nY_prediction","685a666f":"data_f = pd.DataFrame(data = Y_prediction,columns = ['Survived'])\ndata_f.head()","3194490f":"data_f['PassengerId'] = passenger_id","75c119d4":"data_f= data_f[['PassengerId','Survived']]","0fa96028":"data_f.head()","c6f3cd51":"sns.countplot(x = \"Survived\", data = data_f)","ff0ba8ae":"data_f.to_csv('mycsvfile.csv',index=False)","643ddff7":"* 1st class passengers have high chances of survival\n* 2nd class passengers have less chances of survival\n* 3rd class passengers have very little chance of survival","d4f90626":"* Passenger with no sibling or spouse has low chance of survival\n* Passenger with 1 sibling or spouse has higher chances of survival","fe18d0ca":"### Females survived more than males","162498f0":"* Passengers embarked from Southampton have very little chances of survival\n* Passengers embarked from Cherbourg have higher chances of survival\n* Passengers embarked from Queenstown have less chances of survival\n* Maximum Passengers has embarked from Southampton port so we can fill the two missing data with S."}}