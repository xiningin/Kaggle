{"cell_type":{"e47579ee":"code","69adbc43":"code","f57d5e2f":"code","90769f7b":"code","75280f89":"code","cdf5a2f2":"code","8c8e29dd":"code","97f97c18":"code","e3f8187e":"code","28d66724":"code","ab6098e6":"code","c8348e7b":"code","92aa7e5d":"code","46058ef1":"code","58f31f95":"code","989d130c":"code","0636956f":"code","5bbf73ad":"code","897a5378":"code","029a1e89":"code","47a185fc":"code","7b3ad929":"code","e6a2b11b":"code","3902ef88":"code","51f8576d":"code","dcd1f031":"code","a43d2a1c":"code","2c74f0e0":"code","fdeade71":"code","19ccf9ff":"code","860ecada":"code","ed426460":"code","d1b75d80":"code","c78627fd":"code","e41b45cc":"markdown","805b77e1":"markdown","9e6b0b95":"markdown","f217937d":"markdown","bc535145":"markdown","eb6cfdf0":"markdown","f8ad1a83":"markdown","bbd9db70":"markdown","c9eb15e2":"markdown","0199aba3":"markdown"},"source":{"e47579ee":"# Dataset\nfrom sklearn import datasets\n\nimport sys\nsys.path.insert(0, '..\/')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\n%matplotlib inline\n%load_ext autoreload","69adbc43":"!pip install MiniSom\nfrom minisom import MiniSom","f57d5e2f":"# carregar dados\niris = datasets.load_iris()\ndata = iris.data\n# data normalization\ndata = np.apply_along_axis(lambda x: x\/np.linalg.norm(x), 1, data)","90769f7b":"classes = iris.target_names\nfeatures = iris.feature_names\niris_target = iris.target\n\ndf_iris = pd.DataFrame(data, columns=features)\ndf_iris[\"class_id\"] = iris_target\ndf_iris[\"class\"] = 0\n\n# Creating numeric class identifiers (0,1,2) \ndf_iris.loc[df_iris[\"class_id\"]==0, 'class'] = str(classes[0])\ndf_iris.loc[df_iris[\"class_id\"]==1, 'class'] = str(classes[1])\ndf_iris.loc[df_iris[\"class_id\"]==2, 'class'] = str(classes[2])","75280f89":"sns.pairplot(df_iris.drop(\"class_id\", axis=1), hue=\"class\", height=3, diag_kind=\"kde\")","cdf5a2f2":"# Inicializa\u00e7\u00e3o e treinamento\nsom3x3 = MiniSom(x= 3, y = 3, input_len = 4, sigma=3, learning_rate=0.5,\n             neighborhood_function='triangle', random_seed=10)\n\n# Inicializa\u00e7\u00e3o e treinamento\nsom7x7 = MiniSom(x= 7, y = 7, input_len = 4, sigma=3, learning_rate=0.5,\n             neighborhood_function='triangle', random_seed=10)\n\n# Inicializa\u00e7\u00e3o e treinamento\nsom9x9 = MiniSom(x= 9, y = 9, input_len = 4, sigma=3, learning_rate=0.5,\n             neighborhood_function='triangle', random_seed=10)","8c8e29dd":"som3x3.pca_weights_init(data)\nprint(\"Training...3x3\")\nsom3x3.train_batch(data, 1000, verbose=True)\nprint(\"\\n...ready!3x3\")\n\nsom7x7.pca_weights_init(data)\nprint(\"Training...7x7\")\nsom7x7.train_batch(data, 1000, verbose=True)\nprint(\"\\n...ready!7x7\")\n\nsom9x9.pca_weights_init(data)\nprint(\"Training...9x9\")\nsom9x9.train_batch(data, 1000, verbose=True)\nprint(\"\\n...ready!9x9\")","97f97c18":"import matplotlib.patches as mpatches","e3f8187e":"t = np.zeros(len(iris_target),dtype=int)\nt[iris_target == 0] = 0\nt[iris_target == 1] = 1\nt[iris_target == 2] = 2\n# use different coalors and markers for each label\nmarkers = ['o','s','D']\ncolors = ['r','g','b']\n\nred_patch = mpatches.Patch(color='red', label='setosa')\nblue_patch = mpatches.Patch(color='blue', label='versicolor')\ngreen_patch = mpatches.Patch(color='green', label='virginica')","28d66724":"plt.figure(figsize=(8,5))\nplt.title('Som 3x3')\nplt.pcolor(som3x3.distance_map().T) # distance map as background\nplt.colorbar()\n\nfor cnt,xx in enumerate(data):\n    w = som3x3.winner(xx) # getting the winner\n    plt.plot(w[0]+.5,w[1]+.5,markers[t[cnt]],markerfacecolor='None',\n             markeredgecolor=colors[t[cnt]],markersize=12,markeredgewidth=2)\n    \nplt.axis([0,som3x3.get_weights().shape[0],0,som3x3.get_weights().shape[1]])\nplt.legend(handles=[red_patch, blue_patch,green_patch])\nplt.show() # show the figure","ab6098e6":"plt.figure(figsize=(8,5))\nplt.title('Som 7x7')\nplt.pcolor(som7x7.distance_map().T) # distance map as background\nplt.colorbar()\n\nfor cnt,xx in enumerate(data):\n    w = som7x7.winner(xx) # getting the winner\n    plt.plot(w[0]+.5,w[1]+.5,markers[t[cnt]],markerfacecolor='None',\n             markeredgecolor=colors[t[cnt]],markersize=12,markeredgewidth=2)\n    \nplt.axis([0,som7x7.get_weights().shape[0],0,som7x7.get_weights().shape[1]])\nplt.legend(handles=[red_patch, blue_patch,green_patch])\nplt.show() # show the figure","c8348e7b":"plt.figure(figsize=(8,5))\nplt.title('Som 9x9')\nplt.pcolor(som9x9.distance_map().T) # distance map as background\nplt.colorbar()\n\nfor cnt,xx in enumerate(data):\n    w = som9x9.winner(xx) # getting the winner\n    plt.plot(w[0]+.5,w[1]+.5,markers[t[cnt]],markerfacecolor='None',\n             markeredgecolor=colors[t[cnt]],markersize=12,markeredgewidth=2)\n    \nplt.axis([0,som9x9.get_weights().shape[0],0,som9x9.get_weights().shape[1]])\nplt.legend(handles=[red_patch, blue_patch,green_patch])\nplt.show() # show the figure","92aa7e5d":"plt.figure(figsize=(5,5))\nplt.title('Heatmap para 3x3')\nsns.heatmap(som3x3.distance_map(), annot=True)\nplt.show()","46058ef1":"plt.figure(figsize=(8,8))\nplt.title('Heatmap para 7x7')\nsns.heatmap(som7x7.distance_map(), annot=True)\nplt.show()","58f31f95":"plt.figure(figsize=(8,8))\nplt.title('Heatmap para 9x9')\nsns.heatmap(som9x9.distance_map(), annot=True)\nplt.show()","989d130c":"som3x3.pca_weights_init(data)\nmax_iter = 10000\nq_error_pca_init = []\niter_x = []\nfor i in range(max_iter):\n    percent = 100*(i+1)\/max_iter\n    rand_i = np.random.randint(len(data)) # Corresponde ao treinamento randomico\n    som3x3.update(data[rand_i], som3x3.winner(data[rand_i]), i, max_iter)\n    if (i+1) % 100 == 0:\n        error = som3x3.quantization_error(data)\n        q_error_pca_init.append(error)\n        iter_x.append(i)\n        sys.stdout.write(f'\\riteration={i:2d} status={percent:0.2f}% error={error}')\n\nplt.title('Erro de quantiza\u00e7\u00e3o 3x3')\nplt.plot(iter_x, q_error_pca_init)\nplt.ylabel('quantization error')\nplt.xlabel('iteration index')\nplt.show()","0636956f":"som7x7.pca_weights_init(data)\nmax_iter = 10000\nq_error_pca_init = []\niter_x = []\nfor i in range(max_iter):\n    percent = 100*(i+1)\/max_iter\n    rand_i = np.random.randint(len(data)) # Corresponde ao treinamento randomico\n    som7x7.update(data[rand_i], som7x7.winner(data[rand_i]), i, max_iter)\n    if (i+1) % 100 == 0:\n        error = som7x7.quantization_error(data)\n        q_error_pca_init.append(error)\n        iter_x.append(i)\n        sys.stdout.write(f'\\riteration={i:2d} status={percent:0.2f}% error={error}')\n\nplt.title('Erro de quantiza\u00e7\u00e3o 7x7')\nplt.plot(iter_x, q_error_pca_init)\nplt.ylabel('quantization error')\nplt.xlabel('iteration index')\nplt.show()","5bbf73ad":"som9x9.pca_weights_init(data)\nmax_iter = 10000\nq_error_pca_init = []\niter_x = []\nfor i in range(max_iter):\n    percent = 100*(i+1)\/max_iter\n    rand_i = np.random.randint(len(data)) # Corresponde ao treinamento randomico\n    som9x9.update(data[rand_i], som9x9.winner(data[rand_i]), i, max_iter)\n    if (i+1) % 100 == 0:\n        error = som9x9.quantization_error(data)\n        q_error_pca_init.append(error)\n        iter_x.append(i)\n        sys.stdout.write(f'\\riteration={i:2d} status={percent:0.2f}% error={error}')\n\nplt.title('Erro de quantiza\u00e7\u00e3o 9x9')\nplt.plot(iter_x, q_error_pca_init)\nplt.ylabel('quantization error')\nplt.xlabel('iteration index')\nplt.show()","897a5378":"class_assignments = som3x3.labels_map(data, df_iris['class'])\n\ndef classify(som, data, class_assignments):\n    winmap = class_assignments\n    default_class = np.sum(list(winmap.values())).most_common()[0][0]\n    result = []\n    for d in data:\n        win_position = som3x3.winner(d)\n        if win_position in winmap:\n            result.append(winmap[win_position].most_common()[0][0])\n        else:\n            result.append(default_class)\n    return result","029a1e89":"X_train, X_test, y_train, y_test = train_test_split(data, df_iris['class'])\n\nsom3x3.pca_weights_init(X_train)\nsom3x3.train_random(X_train, 5000, verbose=False)\nclass_assignments = som3x3.labels_map(X_train, y_train)\n\nprint(classification_report(y_test, classify(som3x3, X_test, class_assignments)))","47a185fc":"X_train, X_test, y_train, y_test = train_test_split(data, df_iris['class'])\n\nsom7x7.pca_weights_init(X_train)\nsom7x7.train_random(X_train, 5000, verbose=False)\nclass_assignments = som7x7.labels_map(X_train, y_train)\n\nprint(classification_report(y_test, classify(som7x7, X_test, class_assignments)))","7b3ad929":"X_train, X_test, y_train, y_test = train_test_split(data, df_iris['class'])\n\nsom9x9.pca_weights_init(X_train)\nsom9x9.train_random(X_train, 5000, verbose=False)\nclass_assignments = som9x9.labels_map(X_train, y_train)\n\nprint(classification_report(y_test, classify(som9x9, X_test, class_assignments)))","e6a2b11b":"import sys\nsys.path.insert(0, '..\/')\n\nfrom minisom import MiniSom\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n%load_ext autoreload","3902ef88":"%autoreload 2\nfrom sklearn import datasets\nfrom sklearn.preprocessing import scale\n\n# Carregar base de dados do sklearn\ndigits = datasets.load_digits(n_class=10)\ndata = digits.data  # matrix onde cada linha \u00e9 o vetor que representa um digito\ndata = scale(data)\nnum = digits.target  # num[i] \u00e9 o digito representado em data[i]\n\nsom = MiniSom(30, 30, 64, sigma=4,\n              learning_rate=0.5, neighborhood_function='triangle')\nsom.pca_weights_init(data)\nprint(\"Treinando...\")\nsom.train_random(data, 5000, verbose=True)  # treinamento randomico\nprint(\"\\n...pronto!\")","51f8576d":"plt.figure(figsize=(8, 8))\nplt.title('SOM 30x30 para Digitos')\nwmap = {}\nim = 0\nfor x, t in zip(data, num):  # scatterplot\n    w = som.winner(x)\n    wmap[w] = im\n    plt. text(w[0]+.5,  w[1]+.5,  str(t),\n              color=plt.cm.rainbow(t \/ 10.), fontdict={'weight': 'bold',  'size': 11})\n    im = im + 1\nplt.axis([0, som.get_weights().shape[0], 0,  som.get_weights().shape[1]])\nplt.show()","dcd1f031":"plt.figure(figsize=(10, 10), facecolor='white')\nplt.title('SOM 30x30 para Resultado')\ncnt = 0\nfor j in reversed(range(20)):  # images mosaic\n    for i in range(20):\n        plt.subplot(20, 20, cnt+1, frameon=False,  xticks=[],  yticks=[])\n        if (i, j) in wmap:\n            plt.imshow(digits.images[wmap[(i, j)]],\n                       cmap='Greys', interpolation='nearest')\n        else:\n            plt.imshow(np.zeros((8, 8)),  cmap='Greys')\n        cnt = cnt + 1\n\nplt.tight_layout()\nplt.show()","a43d2a1c":"import sys\nsys.path.insert(0, '..\/')\n\nfrom minisom import MiniSom\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\n%matplotlib inline\n\n%load_ext autoreload\n%autoreload 2","2c74f0e0":"from sklearn.datasets import make_blobs\nfrom sklearn.preprocessing import scale","fdeade71":"outliers_percentage = 0.35\ninliers = 300\noutliers = int(inliers * outliers_percentage)\n\n\ndata = make_blobs(centers=[[2, 2], [-2, -2]], cluster_std=[.3, .3],\n                  n_samples=inliers, random_state=0)[0]\n\n\ndata = scale(data)\ndata = np.concatenate([data, \n                       (np.random.rand(outliers, 2)-.5)*4.])\n\n\nsom = MiniSom(2, 1, data.shape[1], sigma=1, learning_rate=0.5,\n              neighborhood_function='triangle', random_seed=10)\n\n\nsom.train_batch(data, 100, verbose=True)  # random training","19ccf9ff":"quantization_errors = np.linalg.norm(som.quantization(data) - data, axis=1)\nerror_treshold = np.percentile(quantization_errors, \n                               100*(1-outliers_percentage)+5)\nis_outlier = quantization_errors > error_treshold","860ecada":"plt.hist(quantization_errors)\nplt.axvline(error_treshold, color='k', linestyle='--')\nplt.xlabel('error')\nplt.ylabel('frequency')","ed426460":"plt.figure(figsize=(8, 8))\nplt.scatter(data[~is_outlier, 0], data[~is_outlier, 1],\n            label='inlier')\nplt.scatter(data[is_outlier, 0], data[is_outlier, 1],\n            label='outlier')\nplt.legend()\nplt.show()","d1b75d80":"from sklearn.datasets import make_circles\ndata = make_circles(noise=.1, n_samples=inliers, random_state=0)[0]\ndata = scale(data)\ndata = np.concatenate([data, \n                       (np.random.rand(outliers, 2)-.5)*4.])\n\n\nsom = MiniSom(5, 5, data.shape[1], sigma=1, learning_rate=0.5,\n              neighborhood_function='triangle', random_seed=10)\n\n\nsom.train_batch(data, 100, verbose=True)  \nquantization_errors = np.linalg.norm(som.quantization(data) - data, axis=1)\nerror_treshold = np.percentile(quantization_errors, \n                               100*(1-outliers_percentage)+5)\nis_outlier = quantization_errors > error_treshold","c78627fd":"plt.figure(figsize=(8, 8))\nplt.scatter(data[~is_outlier, 0], data[~is_outlier, 1],\n            label='inlier')\nplt.scatter(data[is_outlier, 0], data[is_outlier, 1],\n            label='outlier')\nweights = som._weights.reshape(5*5, 2)\nplt.scatter(weights[:, 0], weights[:,1],\n           marker='+', s=320, c='g', label='weights')\nplt.legend()\nplt.show()","e41b45cc":"### Erros de Quantiza\u00e7\u00e3o","805b77e1":"### Heatmap 3x3","9e6b0b95":"### HITMAP","f217937d":"Discente: Helvecio Neto\nDocente: Dr. Marcos Quiles\n\n## PROJECT 2 - SOM\n\n- Realizar experimentos com pelo menos 3 datasets (usar o Iris para debug). Variar a vizinhan\u00e7a e taxa de aprendizagem\n- Apresentar, pelo menos, os seguintes mapas:\n    - U-Matrix\n    - Hit map e Heat maps\n    - Erro de quantiza\u00e7\u00e3o e topogr\u00e1fico\n- Entregar relat\u00f3rio descrevendo os experimentos\n\n## Exemplo 01 Dataset: IRIS","bc535145":"### Exemplo 02\n\nExemplo usando minist digitos","eb6cfdf0":"### Treinamento\n\nPara inicializa\u00e7\u00e3o de um objeto da biblioteca Minisom \u00e9 necess\u00e1rio atribu\u00edr os parametros uma vari\u00e1vel.\n\nO primeiro parametro est\u00e1 relacionado as dimenss\u00f5es do dataset, no caso do exemplo Iris as dimenss\u00f5es s\u00e3o **(x = 7, y=7)** o que significa que ao final teremos 7 * 7 valores de sa\u00edda, por tanto, quanto maior o mapa auto-organizado maior o tempo de treinamento.\n\nO segundo parametro **input_len** \u00e9 o n\u00famero de caracteristicas (features, caso do exemplo da iris coorresponde aos sepal length (cm), sepal width (cm), petal length (cm),petal width (cm)]) neste caso o valor de entrada \u00e9 igual a 4.\n\nO parametro **sigma** corresponde ao raio dos diferentes vizinhos no som, o padr\u00e3o \u00e9 1.0.\n\nO parametro **learning_rate** determina a taxa de ajuste dos pesos durante cada itera\u00e7\u00e3o.\n\nO ultimo parametro \u00e9 a fun\u00e7\u00e3o de pesos da vizinhan\u00e7a **neighborhood** de uma posi\u00e7\u00e3o no mapa valores poss\u00edveis: 'gaussian', 'mexican_hat', 'bubble' ou 'triangle'","f8ad1a83":"### Classifica\u00e7\u00e3o para SOM 7x7","bbd9db70":"#### Exemplo 03\n\nRemo\u00e7\u00e3o de Outliers","c9eb15e2":"### Classifica\u00e7\u00e3o para SOM 9x9","0199aba3":"### Classifica\u00e7\u00e3o para SOM 3x3"}}