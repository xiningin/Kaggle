{"cell_type":{"e0f1fd9b":"code","7815b352":"code","60683478":"code","207e307d":"code","3df606b9":"code","d78bc20f":"code","787ebeb4":"code","b9cb1f5c":"code","3c13611e":"code","b253ac3c":"code","a2926dcd":"code","2a90226c":"code","62c693eb":"code","97cab3a3":"code","cb781840":"code","ccfe4369":"code","6bd1657f":"code","879e2aa1":"code","b3e3cf57":"code","67566d20":"code","633439ac":"code","aa71db11":"code","613c8158":"code","ecb42c94":"code","1f306fb0":"code","344cbd08":"code","80780a9d":"code","e717ce27":"code","4c4e7f65":"code","d465eb55":"code","fe042279":"code","a74debb8":"code","c5442e77":"code","9f79779a":"code","23acb00c":"code","ebe268a6":"code","a7469b5e":"code","c2b8131c":"code","8a942c41":"code","56aa7b45":"code","d28b57be":"code","29c0ae2e":"code","562b3e77":"code","6f553307":"code","ae9dfbe5":"code","fd31b863":"code","ea409faa":"code","af088349":"code","a255f660":"code","00ccb54d":"code","b88dedea":"code","bc4553e8":"code","859c182b":"code","6c82977d":"code","8814ecec":"code","aa569652":"code","db099c84":"code","164d23be":"code","50c662e6":"code","66ba510a":"code","5aacd909":"code","31e6c1da":"code","1dd77bc3":"code","a8baa5ce":"code","dfa647a2":"code","7bbb1d19":"code","0f80d37a":"code","da7094a4":"code","be476eac":"code","039b47af":"code","bf875f93":"code","589419e2":"code","83a3ea79":"code","a9f6623f":"code","393107b3":"code","f1dcb7c6":"code","22388914":"code","65111148":"code","99016e21":"code","dce953d5":"code","a198f927":"code","10151040":"code","3675eaaa":"markdown","5b0f7457":"markdown","1d8912b1":"markdown","a4d00686":"markdown","f1fea886":"markdown","9ac7a4dd":"markdown","91cc5736":"markdown","f127d457":"markdown","2ab5efe4":"markdown","1cdd76f3":"markdown","35894ee2":"markdown","50cbd805":"markdown","4ac1f501":"markdown","e600f0c1":"markdown","4e42f499":"markdown","cc0f272d":"markdown","58f457f9":"markdown","328718db":"markdown","df4ce44d":"markdown","6ad5cabc":"markdown","41bd4d72":"markdown","19b09161":"markdown","0e16f93c":"markdown","36f7d007":"markdown","18422e24":"markdown","4dc6400e":"markdown","3f8a5f6d":"markdown","06528337":"markdown","870eeddc":"markdown","b77bf3d1":"markdown","5e184105":"markdown","0f89ce6b":"markdown","84cc0e82":"markdown","c0a0fece":"markdown","943aa48b":"markdown"},"source":{"e0f1fd9b":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use(\"fivethirtyeight\")","7815b352":"data = pd.read_csv(\"\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv\")","60683478":"data.shape","207e307d":"data.head()","3df606b9":"data.describe().T","d78bc20f":"data.isna().sum()","787ebeb4":"bp_zeros = data[data['BloodPressure'] == 0].shape[0]\nst_zeros = data[data['SkinThickness'] == 0].shape[0]\nglucos_zeros = data[data['Glucose'] == 0].shape[0]\nbmi_zeros = data[data['BMI'] == 0].shape[0]\ninsulin_zeros = data[data['Insulin'] == 0].shape[0]","b9cb1f5c":"print(f\"Number of zeros 'BloodPressure' column have : {bp_zeros}\")\nprint(f\"Number of zeros 'SkinThickness' column have : {st_zeros}\")\nprint(f\"Number of zeros 'Glucos' column have : {glucos_zeros}\")\nprint(f\"Number of zeros 'BMI' column have : {bmi_zeros}\")\nprint(f\"Number of zeros 'Insulin' column have : {insulin_zeros}\")","3c13611e":"data.hist(color='red', figsize=(20,15));","b253ac3c":"from IPython.display import Image ","a2926dcd":"Image(url=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/9\/9b\/Measures_of_Central_Tendency.png\")","2a90226c":"data_2 = data.copy()","62c693eb":"data_2['Insulin'].replace(0, data_2['Insulin'].median(), inplace=True)\ndata_2['SkinThickness'].replace(0, data_2['SkinThickness'].median(), inplace=True)\ndata_2['BMI'].replace(0, data_2['BMI'].mean(), inplace=True)\ndata_2['Glucose'].replace(0, data_2['Glucose'].median(), inplace=True)\ndata_2['BloodPressure'].replace(0, data_2['BloodPressure'].mean(), inplace=True)","97cab3a3":"data_2.head()","cb781840":"data_2.describe().T","ccfe4369":"##\u00a0You can find the source code here : \n# https:\/\/github.com\/manukalia\/handy_data_viz_functions\/blob\/master\/handy_data_visualization_functions.ipynb\ndef half_corr_heatmap(data, title=None):\n    plt.figure(figsize=(9,9))\n    sns.set(font_scale=1)\n    \n    mask = np.zeros_like(data.corr())\n    mask[np.tril_indices_from(mask)] = True\n    \n    with sns.axes_style(\"white\"):\n        sns.heatmap(data.corr(), mask=mask, annot=True, cmap=\"coolwarm\")\n    \n    if title: plt.title(f\"\\n{title}\\n\", fontsize=18)\n    plt.show()\n    return","6bd1657f":"half_corr_heatmap(data_2, 'Correlation Between Variables')","879e2aa1":"def corr_to_target(dataframe, target, title=None, file=None):\n    plt.figure(figsize=(4,6))\n    sns.set(font_scale=1)\n    \n    sns.heatmap(dataframe.corr()[[target]].sort_values(target,\n                                                ascending=False)[1:],\n                annot=True,\n                cmap='coolwarm')\n    \n    if title: plt.title(f'\\n{title}\\n', fontsize=18)\n    plt.xlabel('')    # optional in case you want an x-axis label\n    plt.ylabel('')    # optional in case you want a  y-axis label\n    if file: plt.savefig(file, bbox_inches='tight')\n    plt.show();\n    \n    return","b3e3cf57":"corr_to_target(data_2, 'Outcome', 'Outcome');","67566d20":"def gen_boxplots(dataframe, cols=1, file=None):\n    rows      = math.ceil(len(dataframe.columns)\/cols)\n    figwidth  = 5 * cols\n    figheight = 4 * rows\n\n    fig, ax = plt.subplots(nrows   = rows,\n                           ncols   = cols,\n                           figsize = (figwidth, figheight))\n    \n    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n    ax = ax.ravel()         # Ravel turns a matrix into a vector... easier to iterate\n\n    for i, column in enumerate(dataframe.columns):\n        ax[i].boxplot(dataframe[column])\n        \n        ax[i].set_title(f'{dataframe[column].name}', fontsize=18)\n        ax[i].set_ylabel('', fontsize=14)\n        ax[i].set_xlabel('', fontsize=14)\n        ax[i].tick_params(labelbottom=False)\n        \n    fig.suptitle('\\nBoxplots for All Variables in Dataframe', size=24)\n    fig.tight_layout()\n    fig.subplots_adjust(bottom=0, top=0.88)\n    if file: plt.savefig(file, bbox_inches='tight')\n    plt.show();\n\n    return","633439ac":"import math\ngen_boxplots(data_2, 3);","aa71db11":"data_2.groupby('Outcome')[['BMI', 'Age', 'Insulin', 'Pregnancies']].agg(['min', 'max', 'mean'])","613c8158":"Image(url=\"https:\/\/www.cdc.gov\/healthyweight\/images\/assessing\/bmi-adult-fb-600x315.jpg\")","ecb42c94":"sns.scatterplot(data = data_2, x = 'DiabetesPedigreeFunction', y = 'Pregnancies', hue = 'Outcome');","1f306fb0":"data_2.groupby('Pregnancies').Pregnancies.count()","344cbd08":"data_2.groupby('Pregnancies').size().plot(kind = 'line', color = 'red', linewidth = 1.2);","80780a9d":"sns.countplot(data_2['Outcome']);","e717ce27":"Q1 = data_2.quantile(0.25)\nQ2 = data_2.quantile(0.75)\nIQR = Q2 - Q1\nIQR","4c4e7f65":"data2_out = data_2[~((data_2 < (Q1 - 1.5 * IQR)) |(data_2 > (Q2 + 1.5 * IQR))).any(axis=1)]","d465eb55":"data2_out.shape","fe042279":"gen_boxplots(data2_out,3)","a74debb8":"g = sns.FacetGrid(data2_out, col=\"Outcome\", height=3.5, aspect=1.6)\ng.map_dataframe(sns.scatterplot, x=\"Glucose\", y=\"Insulin\", hue=\"Pregnancies\", size = 'Pregnancies', sizes=(20, 200))\ng.set_axis_labels(\"Glucose Level\", \"Insulin Level\")\ng.add_legend();","c5442e77":"g2 = sns.FacetGrid(data2_out, col=\"Outcome\", height=3.5, aspect=1.6)\ng2.map(sns.countplot, \"Pregnancies\", color = 'red');","9f79779a":"g3 = sns.FacetGrid(data2_out, col=\"Outcome\", height=3.5, aspect=1.6)\ng3.map(sns.distplot, \"BMI\", color = 'green');","23acb00c":"g4 = sns.FacetGrid(data2_out, col=\"Outcome\", height=3.5, aspect=1.6)\ng4.map(sns.distplot, \"SkinThickness\", color = 'black');","ebe268a6":"sns.pairplot(data = data2_out, hue = 'Outcome');","a7469b5e":"X = data2_out.drop('Outcome', axis = 1)\ny = data2_out['Outcome']","c2b8131c":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split","8a942c41":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .33, random_state = 0)","56aa7b45":"sc = StandardScaler()\nX_train_sc = sc.fit_transform(X_train)\nX_test_sc = sc.transform(X_test)","d28b57be":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, roc_auc_score","29c0ae2e":"TestScores = []\nTrainScores = []\n\nfor i in range(1, 20):\n    knn = KNeighborsClassifier(i)\n    knn.fit(X_train, y_train)\n    \n    TrainScores.append(knn.score(X_train, y_train))\n    TestScores.append(knn.score(X_test, y_test))","562b3e77":"plt.figure(figsize=(12,6))\n\nsns.lineplot(range(1, 20), TrainScores, marker = 'o', color = 'red', label = 'Train Score')\nsns.lineplot(range(1, 20), TestScores, marker = '+', color = 'blue', label = 'Test Score');","6f553307":"knn = KNeighborsClassifier(12)\nknn.fit(X_train_sc, y_train)\nknn_y_pred = knn.predict(X_test_sc)\nknn_y_pred_train = knn.predict(X_train_sc)","ae9dfbe5":"knn_as = accuracy_score(knn_y_pred, y_test)\nknn_as_train = accuracy_score(knn_y_pred_train, y_train)\nknn_as_train","fd31b863":"print(classification_report(knn_y_pred, y_test))","ea409faa":"knn_cm = confusion_matrix(knn_y_pred, y_test)\nknn_cm","af088349":"y_pred_proba = knn.predict_proba(X_test_sc)[:,1]\nfpr, tpr, threshold = roc_curve(y_test, y_pred_proba)","a255f660":"plt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr, label = 'KNN')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('Knn(n_neighbors=12) ROC curve');","00ccb54d":"roc_auc_score(y_test, y_pred_proba)","b88dedea":"gscv = GridSearchCV(LogisticRegression(solver='liblinear', multi_class = 'auto'), \n                    {'C' : [1, 10, 20]}, \n                    cv = 5, return_train_score=False)\ngscv.fit(X, y)","bc4553e8":"gscv.best_params_","859c182b":"gscv.best_score_","6c82977d":"log = LogisticRegression(C = 10)\nlog.fit(X_train_sc, y_train)\nlog_y_pred = log.predict(X_test_sc)\nlog_y_pred_train = log.predict(X_train_sc)","8814ecec":"log_as = accuracy_score(y_test, log_y_pred)\nlog_as_train = accuracy_score(log_y_pred_train, y_train)\nlog_as_train","aa569652":"log_as","db099c84":"print(classification_report(log_y_pred, y_test))","164d23be":"log_cm = confusion_matrix(log_y_pred, y_test)","50c662e6":"svc = SVC()\n\nparameters = [{'C': [1, 10, 100], 'kernel': ['linear']},\n              {'C': [1, 10, 100], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\ngrid_search = GridSearchCV(estimator = svc,\n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv = 10,\n                           n_jobs = -1)\ngrid_search.fit(X_train_sc, y_train)\n\nprint(f\"Best parameters for SVC : {grid_search.best_params_}\")\nprint(f\"Best score for SVC : {grid_search.best_score_}\")","66ba510a":"svc_best = grid_search.best_params_","5aacd909":"svc = SVC(**svc_best)\nsvc.fit(X_train_sc, y_train)\nsvc_y_pred = svc.predict(X_test_sc)\nsvc_y_pred_train = svc.predict(X_train_sc)\nsvc_cm = confusion_matrix(svc_y_pred, y_test)","31e6c1da":"svc_as = accuracy_score(svc_y_pred, y_test)","1dd77bc3":"accuracy_score(svc_y_pred_train, y_train)","a8baa5ce":"svc_as","dfa647a2":"gradient_boosting = GradientBoostingClassifier(n_estimators=100, random_state=0)","7bbb1d19":"gradient_boosting.fit(X_train_sc, y_train)","0f80d37a":"gb_y_pred = gradient_boosting.predict(X_test_sc)\ngb_y_pred_train = gradient_boosting.predict(X_train_sc)","da7094a4":"gb_as = accuracy_score(gb_y_pred, y_test)\ngb_as_train = accuracy_score(gb_y_pred_train, y_train)\nconfusion_matrix(gb_y_pred, y_test)","be476eac":"confusion_matrix(gb_y_pred_train, y_train)","039b47af":"print(f\"Accuracy score of train data : {accuracy_score(gb_y_pred_train, y_train)}\")\nprint(f\"Accuracy score of test data : {accuracy_score(gb_y_pred, y_test)}\")","bf875f93":"extra = ExtraTreesClassifier(n_estimators=1000, max_depth = 7, random_state = 0)","589419e2":"extra.fit(X_train_sc, y_train)\nextra_y_pred = extra.predict(X_test_sc)\nextra_y_pred_train = extra.predict(X_train_sc)","83a3ea79":"print(f\"Accuracy score of train data : {accuracy_score(extra_y_pred, y_test)}\")\nprint(f\"Accuracy score of test data : {accuracy_score(extra_y_pred_train, y_train)}\")","a9f6623f":"extra_as = accuracy_score(extra_y_pred, y_test)","393107b3":"extra_cm = confusion_matrix(extra_y_pred, y_test)\nextra_cm","f1dcb7c6":"extra_as_train = accuracy_score(extra_y_pred_train, y_train)\nconfusion_matrix(extra_y_pred_train, y_train)","22388914":"ada = AdaBoostClassifier(n_estimators=40)","65111148":"ada.fit(X_train_sc, y_train)","99016e21":"ada_y_pred = ada.predict(X_test_sc)\nada_y_pred_train = ada.predict(X_train_sc)","dce953d5":"ada_as_train = accuracy_score(ada_y_pred_train, y_train)\nada_as = accuracy_score(ada_y_pred, y_test)\nada_as_train","a198f927":"accuracy_score(ada_y_pred, y_test)","10151040":"print(f\"KNN model accuracy score for test data : {knn_as}\")\nprint(f\"KNN model accuracy score for train data : {knn_as_train}\\n\")\nprint(f\"Logistic Regression model accuracy score for test data : {log_as}\")\nprint(f\"Logistic Regression model accuracy score for train data : {log_as_train}\\n\")\nprint(f\"SVC model accuracy score for test data : {log_as}\")\nprint(f\"SVC model accuracy score for train data : {log_as_train}\\n\")\nprint(f\"Gradient Boosting Classifier model accuracy score for test data : {gb_as}\")\nprint(f\"Gradient Boosting Classifier model accuracy score for train data : {gb_as_train}\\n\")\nprint(f\"Extra Tree Classifier model accuracy score for test data : {extra_as}\")\nprint(f\"Extra Tree Classifier model accuracy score for train data : {extra_as_train}\\n\")\nprint(f\"Adaboost Classifier model accuracy score for test data : {ada_as}\")\nprint(f\"Adaboost Classifier model accuracy score for train data : {ada_as_train}\")","3675eaaa":"We should first determine which variables cannot have '0' as their values.","5b0f7457":"## ABOUT DATA","1d8912b1":"* SkinThickness, Insulin is right skewed.\n* BMI, and BloodPressure is normally distributed.\n* Glucose is left skewed.","a4d00686":"#### DiabetesPedigreeFunction:  It provides information about diabetes history in relatives and genetic relationship of those relatives with patients. Higher Pedigree Function means patient is more likely to have diabetes.\nhttps:\/\/github.com\/niharikagulati\/diabetesprediction","f1fea886":"## Model Building","9ac7a4dd":"### Logistic Regression","91cc5736":"#### It's time for detecting, and removing outliers.","f127d457":"### SVC","2ab5efe4":"#### Model Tunning","1cdd76f3":"### Adaboost Classifier","35894ee2":"After k = 15 model score goes down. k = 12 looks fine.","50cbd805":"For 'BMI' : Body Mass Index cannot be 0 too. This is beyond unhealty.\n####\u00a0It is impossible too.","4ac1f501":"* a is normally distributed like BMI, and BloodPressure. If we fill zeros with median of that columns, we wouldn't disrupt the data.\n* For left, and right skewed data, we can fill zeros with median of that columns.","e600f0c1":"### Extra Tree Classification","4e42f499":"#### Something is off. As you can see above, more than one columns has 0 as 'Insulin' value. Also, we have 0 as 'SkinThickness' value. Is that possible?","cc0f272d":"* Number of people with 17 pregnancies is 1.","58f457f9":"#### Insulin, DiabetesPedigreeFunction, BMI, SkinThickness has outliers.","328718db":"* Slightly more than half of the insulin column has zero as value.","df4ce44d":"#### As you can see, model is overfitting.","6ad5cabc":"For 'BloodPressure' Wikipedia says : If the heart is stopped, blood pressure falls, but it does not fall to zero.\n#### So, it is quite impossible.","41bd4d72":"#### Model Tunning","19b09161":"### Let's check how many zeros we have.","0e16f93c":"#### First, we import the libraries.","36f7d007":"#### There is no high correlation between variables.","18422e24":"For 'Insulin' : A person can live with zero insulin in rare situation.\n#### Not that impossible.","4dc6400e":"For 'Glucos' : Glucos can't be zero too.\n#### Impossible.","3f8a5f6d":"#### Looks good!","06528337":"### Gradient Boosting Classifier","870eeddc":"### Model Performance Analysis","b77bf3d1":"Now, we can check the correlations.","5e184105":"### KNeighborsClassifier","0f89ce6b":"Looks like, we don't have null values. How lovely!\nBut, lets check it again.","84cc0e82":"For 'SkinThickness' : Skin thickness of a human being cannot be less than 10 mm.\n#### Being 0 is impossible too.","c0a0fece":"* BMI should be between 30, and 34.9, for you to be counted as obese. Greater than 35 shows that you are extremely obese. As we see above, mean of the BMI values shows us that excess weight can cause diabetes.\n* With age mean, which 37 is very young, means that high weight, and young age with diabetes is in the majority in this data.\n* Someone has 13, and 17 children which is incredible. Since, we do not know how many of them has children with that amount, we cannot decide whether this is decisive for them to being diabetes. But, average number of children across two possibilities is low.","943aa48b":"### Context\nThis dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n\n### Content\nThe datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n\n### Acknowledgements\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261--265). IEEE Computer Society Press.\n\n### Inspiration\nCan you build a machine learning model to accurately predict whether or not the patients in the dataset have diabetes or not?"}}