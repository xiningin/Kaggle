{"cell_type":{"89265f23":"code","34d8c128":"code","323883fb":"code","561d7438":"code","8869f729":"code","d2d0cf47":"code","7514d917":"code","7df0aceb":"code","10928ca6":"code","9bc486fc":"code","811d09dc":"code","7cbf0097":"code","b75bf104":"code","da8798ee":"code","4cd3f811":"code","2f1c7b0e":"code","2457575c":"code","774b5ffc":"code","6d7702fe":"code","18deee1b":"code","3e799266":"code","26b3252d":"code","3bae3b41":"markdown","358afd94":"markdown","ba5926ec":"markdown","52d9704b":"markdown","73440efc":"markdown","90d3f027":"markdown","3f7f2eb0":"markdown","b6ddf63a":"markdown","a87fcea2":"markdown","a4a9dbf9":"markdown","41e3217c":"markdown","698bcf95":"markdown","be8219bc":"markdown","914c800f":"markdown","2a49cc79":"markdown","6244d07d":"markdown","a1fab4bb":"markdown"},"source":{"89265f23":"from torchvision import transforms, datasets, models\nimport torch\nfrom torch import optim, cuda\nfrom torch.utils.data import DataLoader, sampler, random_split\nimport torch.nn as nn\n\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport xml.etree.ElementTree as ET","34d8c128":"def crop_image(breed, dog, data_dir):\n  img = plt.imread(data_dir + 'images\/Images\/' + breed + '\/' + dog + '.jpg')\n  tree = ET.parse(data_dir + 'annotations\/Annotation\/' + breed + '\/' + dog)\n  xmin = int(tree.getroot().findall('object')[0].find('bndbox').find('xmin').text)\n  xmax = int(tree.getroot().findall('object')[0].find('bndbox').find('xmax').text)\n  ymin = int(tree.getroot().findall('object')[0].find('bndbox').find('ymin').text)\n  ymax = int(tree.getroot().findall('object')[0].find('bndbox').find('ymax').text)\n  img = img[ymin:ymax, xmin:xmax, :]\n  return img","323883fb":"data_dir = '..\/input\/stanford-dogs-dataset\/'\nbreed_list = os.listdir(data_dir + 'images\/Images\/')\n\nplt.figure(figsize=(20, 20))\nfor i in range(4):\n  plt.subplot(421 + (i*2))\n  breed = np.random.choice(breed_list)\n  dog = np.random.choice(os.listdir(data_dir + 'annotations\/Annotation\/' + breed))\n  img = plt.imread(data_dir + 'images\/Images\/' + breed + '\/' + dog + '.jpg')\n  plt.imshow(img)  \n  \n  tree = ET.parse(data_dir + 'annotations\/Annotation\/' + breed + '\/' + dog)\n  xmin = int(tree.getroot().findall('object')[0].find('bndbox').find('xmin').text)\n  xmax = int(tree.getroot().findall('object')[0].find('bndbox').find('xmax').text)\n  ymin = int(tree.getroot().findall('object')[0].find('bndbox').find('ymin').text)\n  ymax = int(tree.getroot().findall('object')[0].find('bndbox').find('ymax').text)\n  plt.plot([xmin, xmax, xmax, xmin, xmin], [ymin, ymin, ymax, ymax, ymin])\n  crop_img = crop_image(breed, dog, data_dir)\n  plt.subplot(422 + (i*2))\n  plt.imshow(crop_img)","561d7438":"if 'data' not in os.listdir():\n    os.mkdir('data')\nfor breed in breed_list:\n    os.mkdir('data\/' + breed)\nprint('Created {} folders to store cropped images of the different breeds.'.format(len(os.listdir('data'))))","8869f729":"for breed in os.listdir('data'):\n    for file in os.listdir(data_dir + 'annotations\/Annotation\/' + breed):\n        img = Image.open(data_dir + 'images\/Images\/' + breed + '\/' + file + '.jpg')\n        tree = ET.parse(data_dir + 'annotations\/Annotation\/' + breed + '\/' + file)\n        xmin = int(tree.getroot().findall('object')[0].find('bndbox').find('xmin').text)\n        xmax = int(tree.getroot().findall('object')[0].find('bndbox').find('xmax').text)\n        ymin = int(tree.getroot().findall('object')[0].find('bndbox').find('ymin').text)\n        ymax = int(tree.getroot().findall('object')[0].find('bndbox').find('ymax').text)\n        img = img.crop((xmin,ymin,xmax,ymax))\n        img = img.convert('RGB')\n        img.save('data\/' + breed + '\/' + file + '.jpg')","d2d0cf47":"img_count = 0\nfor folder in os.listdir('data'):\n    for _ in os.listdir('data\/' + folder):\n        img_count += 1\nprint('No. of Images: {}'.format(img_count))","7514d917":"image_transforms = {\n    # Train uses data augmentation\n    'train':\n    transforms.Compose([\n        transforms.RandomResizedCrop(size=315, scale=(0.95, 1.0)),\n        transforms.RandomRotation(degrees=15),\n        transforms.ColorJitter(),\n        transforms.RandomHorizontalFlip(),\n        transforms.CenterCrop(size=299),  # Image net standards\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])  # Imagenet standards\n    ]),\n    'test':\n    transforms.Compose([\n        transforms.Resize(size=299),\n        transforms.CenterCrop(size=299),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n}","7df0aceb":"batch_size = 128\n\nall_data = datasets.ImageFolder(root='data')\ntrain_data_len = int(len(all_data)*0.8)\nvalid_data_len = int((len(all_data) - train_data_len)\/2)\ntest_data_len = int(len(all_data) - train_data_len - valid_data_len)\ntrain_data, val_data, test_data = random_split(all_data, [train_data_len, valid_data_len, test_data_len])\ntrain_data.dataset.transform = image_transforms['train']\nval_data.dataset.transform = image_transforms['test']\ntest_data.dataset.transform = image_transforms['test']\nprint(len(train_data), len(val_data), len(test_data))\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)","10928ca6":"trainiter = iter(train_loader)\nfeatures, labels = next(trainiter)\nprint(features.shape, labels.shape)","9bc486fc":"model = models.inception_v3(pretrained=True)\nmodel.aux_logits=False\nmodel","811d09dc":"# Freeze early layers\nfor param in model.parameters():\n    param.requires_grad = False","7cbf0097":"n_classes = 120\nn_inputs = model.fc.in_features\n# n_inputs will be 4096 for this case\n# Add on classifier\nmodel.fc = nn.Sequential(\n    nn.Linear(n_inputs, 1024),\n    nn.ReLU(),\n    nn.Dropout(0.4),\n    nn.Linear(1024, n_classes),\n    nn.LogSoftmax(dim=1))\n\nmodel.fc","b75bf104":"model.cuda()\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0005)","da8798ee":"model.class_to_idx = all_data.class_to_idx\nmodel.idx_to_class = {\n    idx: class_\n    for class_, idx in model.class_to_idx.items()\n}\n\nlist(model.idx_to_class.items())","4cd3f811":"def train(model,\n         criterion,\n         optimizer,\n         train_loader,\n         val_loader,\n         save_location,\n         early_stop=3,\n         n_epochs=20,\n         print_every=2):\n    #Initializing some variables\n    valid_loss_min = np.Inf\n    stop_count = 0\n    valid_max_acc = 0\n    history = []\n    model.epochs = 0\n\n    #Loop starts here\n    for epoch in range(n_epochs):\n        \n        train_loss = 0\n        valid_loss = 0\n\n        train_acc = 0\n        valid_acc = 0\n\n        model.train()\n        ii = 0\n\n        for data, label in train_loader:\n            ii += 1\n            data, label = data.cuda(), label.cuda()\n            optimizer.zero_grad()\n            output = model(data)\n\n            loss = criterion(output, label)\n            loss.backward()\n            optimizer.step()\n\n            # Track train loss by multiplying average loss by number of examples in batch\n            train_loss += loss.item() * data.size(0)\n\n            # Calculate accuracy by finding max log probability\n            _, pred = torch.max(output, dim=1) # first output gives the max value in the row(not what we want), second output gives index of the highest val\n            correct_tensor = pred.eq(label.data.view_as(pred)) # using the index of the predicted outcome above, torch.eq() will check prediction index against label index to see if prediction is correct(returns 1 if correct, 0 if not)\n            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor)) #tensor must be float to calc average\n            train_acc += accuracy.item() * data.size(0)\n            if ii%10 == 0:\n                print(f'Epoch: {epoch}\\t{100 * (ii + 1) \/ len(train_loader):.2f}% complete.')\n\n        model.epochs += 1\n        with torch.no_grad():\n            model.eval()\n\n            for data, label in val_loader:\n                data, label = data.cuda(), label.cuda()\n\n                output = model(data)\n                loss = criterion(output, label)\n                valid_loss += loss.item() * data.size(0)\n\n                _, pred = torch.max(output, dim=1)\n                correct_tensor = pred.eq(label.data.view_as(pred))\n                accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n                valid_acc += accuracy.item() * data.size(0)\n\n            train_loss = train_loss \/ len(train_loader.dataset)\n            valid_loss = valid_loss \/ len(val_loader.dataset)\n\n            train_acc = train_acc \/ len(train_loader.dataset)\n            valid_acc = valid_acc \/ len(val_loader.dataset)\n\n            history.append([train_loss, valid_loss, train_acc, valid_acc])\n\n            if (epoch + 1) % print_every == 0:\n                print(f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}')\n                print(f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%')\n\n            if valid_loss < valid_loss_min:\n                torch.save({\n                    'state_dict': model.state_dict(),\n                    'idx_to_class': model.idx_to_class\n                }, save_location)\n                stop_count = 0\n                valid_loss_min = valid_loss\n                valid_best_acc = valid_acc\n                best_epoch = epoch\n\n            else:\n                stop_count += 1\n\n                # Below is the case where we handle the early stop case\n                if stop_count >= early_stop:\n                    print(f'\\nEarly Stopping Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%')\n                    model.load_state_dict(torch.load(save_location)['state_dict'])\n                    model.optimizer = optimizer\n                    history = pd.DataFrame(history, columns=['train_loss', 'valid_loss', 'train_acc','valid_acc'])\n                    return model, history\n\n    model.optimizer = optimizer\n    print(f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%')\n\n    history = pd.DataFrame(history, columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n    return model, history","2f1c7b0e":"model, history = train(\n    model,\n    criterion,\n    optimizer,\n    train_loader,\n    val_loader,\n    save_location='.\/dog_inception.pt',\n    early_stop=3,\n    n_epochs=30,\n    print_every=2)","2457575c":"history","774b5ffc":"def test(model, test_loader, criterion):\n    with torch.no_grad():\n        model.eval()\n        test_acc = 0\n        for data, label in test_loader:\n            data, label = data.cuda(), label.cuda()\n\n            output = model(data)\n\n            _, pred = torch.max(output, dim=1)\n            correct_tensor = pred.eq(label.data.view_as(pred))\n            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n            test_acc += accuracy.item() * data.size(0)\n\n        test_acc = test_acc \/ len(test_loader.dataset)\n        return test_acc","6d7702fe":"model.load_state_dict(torch.load('.\/dog_inception.pt')['state_dict'])\ntest_acc = test(model.cuda(), test_loader, criterion)\nprint(f'The model has achieved an accuracy of {100 * test_acc:.2f}% on the test dataset')","18deee1b":"def evaluate(model, test_loader, criterion):\n  \n    classes = []\n    acc_results = np.zeros(len(test_loader.dataset))\n    i = 0\n\n    model.eval()\n    with torch.no_grad():\n        for data, labels in test_loader:\n            data, labels = data.cuda(), labels.cuda()\n            output = model(data)\n\n            for pred, true in zip(output, labels):\n                _, pred = pred.unsqueeze(0).topk(1)\n                correct = pred.eq(true.unsqueeze(0))\n                acc_results[i] = correct.cpu()\n                classes.append(model.idx_to_class[true.item()][10:])\n                i+=1\n\n    results = pd.DataFrame({\n      'class': classes,\n      'results': acc_results    \n    })\n    results = results.groupby(classes).mean()\n\n    return results","3e799266":"print(evaluate(model, test_loader, criterion))","26b3252d":"!rm -rf  data\/*\n#deleting the data of the cropped images we saved earlier on so this notebook can be posted","3bae3b41":"The accuracy we achieved is not too bad considering that some dog breeds can be extremely similar and we may not be able to distinguish them with our eyes ourselves","358afd94":"Next, we'll create new folders to store all the cropped images, which we will use to train the classifier","ba5926ec":"Sending the model to GPU, if not it'll take forever to train. This is followed by defining the criterion and optimizer.","52d9704b":"Great, now all our cropped images are in place. We'll now define the data augmentation and normalizations for the data. The training data will have augmentations to increase the variability of training images. We'll use random rotations, random crops and some other augmentations for the training transforms. Both training and test data will then be resized to 299 * 299 as this is the standard input size for the inception model. The images will be normalized as well according to the ImageNet standards.\n\n","73440efc":"Now, we'll define the training function which will run over the specified number of epochs. It will take the data from the train loader and update the weights of the fc layer according to the labels.\n\nEvery 2 epochs, the function will do validation using the data from the validation loader and ensure that the loss is still decreasing. If the loss stops decreasing for a certain number of epochs (which is defined through the early_stop hyper-parameter), the model will stop training and save the previous the best weights instead","90d3f027":"To-Do:\n- Improve the model by possibly unfreezing some layers and training them.","3f7f2eb0":"Creating an index for the 120 different classes\/breeds below","b6ddf63a":"And we'll save the cropped images to their breed folders","a87fcea2":"After importing the necessary modules, we'll first define a function that finds the bounding boxes using the maximum and minimum x and y values from the annotation files and crops the images accordingly","a4a9dbf9":"In this kernel, I'll be using an object detection model (YOLOv3) to detect the location of the dogs within the images, followed by using the InceptionV3 model re-trained specifically on this dataset to classify the dogs into their unique breeds.\n\nNOTE: As I'm unable to include the YOLO model in this kernel, this [link](https:\/\/github.com\/gabrielloye\/yolov3-stanford-dogs\/blob\/master\/main.ipynb) to my repository includes the training script for YOLO and how it can be combined with the model trained in this kernel.\n\nAny feedback on areas of improvement and better practices that I should adopt is definitely welcome.","41e3217c":"To help visualise and ensure that we are cropping correctly, I've randomly chosen 4 images and displayed how the images are cropped with the annotations below.","698bcf95":"Instead, the only layers which we will be training is the classifier layer, or defined as the fc layer for the case of the Inception model. We have to ensure that the final output will be 120 as we have 120 possible different classes.","be8219bc":"Next, we'll freeze the earlier layers in the model as we do not want to re-train these weights, which are responsible for the model's success in picking out key features of the image.","914c800f":"After training for just a few epochs, we can see that the accuracy on the validation training set is around 75%. To ensure that the model isn't overfitting for the training and validation data, let's test the model out using the test data which it has not seen at all yet.","2a49cc79":"We'll now define the batch size (which can be modified depending on how you want to train your model) and split the data into training, validation and test sets.","6244d07d":"The table above shows the accuracy of our model on the specific breeds, with a score of 1 showing that our model classified that breed correctly. As we can see, some of the breeds have rather bad accuracy, probably because of their similarities, which the model could not pick out the fine-grained differences.","a1fab4bb":"After making sure that our data loaders are outputting data of the correct dimensions (batch_size, 3, 299, 299), we can now instantiate the model by loading it with pre-trained weights. Specifically for the Inception model, we'll have to set the aux_logits property to False. We can then see the model architecture(which is very long)."}}