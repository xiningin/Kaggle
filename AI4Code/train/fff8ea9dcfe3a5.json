{"cell_type":{"8b39641b":"code","4edeaf47":"code","e30355a0":"code","ce591fe5":"code","23bfba85":"code","ce1c9851":"code","fcb87f06":"code","a59dfbb4":"code","8594b687":"code","80c9250d":"code","e0118a55":"code","6b9a77c5":"code","6a74e3ef":"code","e4538047":"code","09feec7d":"code","a269e44c":"code","5390ecf0":"code","80091452":"code","51afd2c3":"markdown","2b98519a":"markdown","5eefa202":"markdown","198153e1":"markdown","e92947d2":"markdown","b7e38572":"markdown","653397ea":"markdown","753ff7f8":"markdown","1c791799":"markdown","f83996b3":"markdown","93c24e56":"markdown","fe313bf0":"markdown","e59358d1":"markdown","07cc2bb2":"markdown"},"source":{"8b39641b":"!pip install autogluon.tabular[all] -q --progress-bar off","4edeaf47":"!pip install scikit-learn-intelex -q --progress-bar off","e30355a0":"import pandas as pd\n\nid_column = 'id'\ntrain_data = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-oct-2021\/train.csv\", index_col=id_column)\ntest_data = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-oct-2021\/test.csv\", index_col=id_column)\nsubmission = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-oct-2021\/sample_submission.csv\", index_col=id_column)","ce591fe5":"train_data[:5]","23bfba85":"train_data.info()","ce1c9851":"label = 'target'\nfeatures = [col for col in train_data.columns if 'f' in col]\n\ncont_features = []\ndisc_features = []\n\nfor col in features:\n    if train_data[col].dtype=='float64':\n        cont_features.append(col)\n    else:\n        disc_features.append(col)\n\ntrain_data[cont_features] = train_data[cont_features].astype('float32')\ntrain_data[disc_features] = train_data[disc_features].astype('uint8')\ntrain_data[cont_features] = train_data[cont_features].astype('float32')\ntrain_data[disc_features] = train_data[disc_features].astype('uint8')","fcb87f06":"train_data.info()","a59dfbb4":"from sklearnex import patch_sklearn\npatch_sklearn()","8594b687":"import logging\n\nlogger = logging.getLogger()\nfh = logging.FileHandler('log.txt')\nfh.setLevel(10)\nlogger.addHandler(fh)","80c9250d":"from sklearn.model_selection import train_test_split\n\nrandom_state = 42\ntrain_data, valid_data = train_test_split(train_data, test_size=0.1, random_state=random_state)","e0118a55":"import gc\n\ngc.collect()","6b9a77c5":"from autogluon.tabular import TabularPredictor\n\n\n# use only Gradient Boosting and Random Forest to reduce execution time\nhyperparameters = {\n    'GBM': [\n        {'extra_trees': True, 'seed': random_state, 'ag_args': {'name_suffix': 'XT'}},\n        {}\n    ],\n    'RF': [\n        {'criterion': 'gini', 'random_state': random_state, 'max_features': 'log2', 'n_estimators': 500,\n         'ag_args': {'name_suffix': 'Gini_Log2', 'problem_types': ['binary']},\n         'ag_args_fit': {'use_daal': True}},\n        {'criterion': 'gini', 'random_state': random_state, 'max_features': 'sqrt', 'n_estimators': 500,\n         'ag_args': {'name_suffix': 'Gini_Sqrt', 'problem_types': ['binary']},\n         'ag_args_fit': {'use_daal': True}},\n        {'criterion': 'gini', 'random_state': random_state, 'max_features': (train_data.shape[1] - 1) \/\/ 8, 'n_estimators': 500,\n         'ag_args': {'name_suffix': 'Gini_Div8', 'problem_types': ['binary']},\n         'ag_args_fit': {'use_daal': True}}\n    ]\n}\n\nautogluon_predictor = TabularPredictor(\n    label=label,\n    eval_metric=\"roc_auc\",\n    learner_kwargs={'ignored_columns': [id_column]}\n).fit(\n    train_data=train_data,\n    hyperparameters=hyperparameters,\n    verbosity=2\n)","6a74e3ef":"leaderboard = autogluon_predictor.leaderboard(valid_data)\nleaderboard","e4538047":"predictions = autogluon_predictor.predict_proba(test_data)\nsubmission.target = predictions.iloc[:, 1]\nsubmission[:5]","09feec7d":"submission.to_csv(\"submission.csv\")","a269e44c":"logger.removeHandler(fh)","5390ecf0":"!rm -rf AutogluonModels","80091452":"!cat log.txt | grep 'running accelerated version' | sort | uniq","51afd2c3":"### Reduce DataFrame memory usage\n\nSince data is quite big for Kaggle notebook instance RAM, we need to reduce memory usage by switching data types.","2b98519a":"# Other notebooks with sklearnex usage\n\n### [[predict sales] Stacking with scikit-learn-intelex](https:\/\/www.kaggle.com\/alexeykolobyanin\/predict-sales-stacking-with-scikit-learn-intelex)\n\n### [[TPS-Aug] NuSVR with Intel Extension for Sklearn](https:\/\/www.kaggle.com\/alexeykolobyanin\/tps-aug-nusvr-with-intel-extension-for-sklearn)\n\n### [Using scikit-learn-intelex for What's Cooking](https:\/\/www.kaggle.com\/kppetrov\/using-scikit-learn-intelex-for-what-s-cooking?scriptVersionId=58739642)\n\n### [Fast KNN using \u202fscikit-learn-intelex for MNIST](https:\/\/www.kaggle.com\/kppetrov\/fast-knn-using-scikit-learn-intelex-for-mnist?scriptVersionId=58738635)\n\n### [Fast SVC using scikit-learn-intelex for MNIST](https:\/\/www.kaggle.com\/kppetrov\/fast-svc-using-scikit-learn-intelex-for-mnist?scriptVersionId=58739300)\n\n### [Fast SVC using scikit-learn-intelex for NLP](https:\/\/www.kaggle.com\/kppetrov\/fast-svc-using-scikit-learn-intelex-for-nlp?scriptVersionId=58739339)","5eefa202":"AutoML significantly simplifies building of high quality models but sometimes has insufficient performance, especially for big problems. In this notebook, we will show how to accelerate AutoML framework [AutoGluon](https:\/\/github.com\/awslabs\/autogluon) using [**Intel\u00ae Extension for Scikit-learn***](https:\/\/github.com\/intel\/scikit-learn-intelex) which speedups Scikit-learn's algorithms in seamless way with one pip package installation and two lines of code.\n\nThis notebook solves binary classification task, but you can use it as template for many other competitions with few changes depending on task type (multiclass or regression) and your needs.","198153e1":"### List of algorithms which are accelerated by sklearnex","e92947d2":"### Reading data","b7e38572":"# \ud83d\ude80\ud83d\ude80\ud83d\ude80 Fast AutoML with AutoGluon and Intel\u00ae Extension for Scikit-learn* - Kaggle Tabular Playground Series - October 2021","653397ea":"### Intel\u00ae Extension for Scikit-learn installation:","753ff7f8":"# AutoGluon with Intel\u00ae Extension for Scikit-learn\n\nRun just two lines of code to accelerate Scikit-learn:","1c791799":"I will show you how to **speed up** your kernel and get predictions with **better quality** using **Intel\u00ae Extension for Scikit-learn**.","f83996b3":"### AutoGluon installation:","93c24e56":"Enable logging with INFO level to track usage of sklearnex:","fe313bf0":"Collect garbage to reduce memory usage","e59358d1":"# Conclusions\n\nIntel\u00ae Extension for Scikit-learn gives you opportunities to:\n\n* Use your Scikit-learn code for training and inference without modification.\n* Get speed up your kernel\n* Get predictions of the better quality as the other tested frameworks.\n\n*Please upvote if you liked it.*","07cc2bb2":"Memory usage was reduced from 2.1 GB to 974 MB"}}