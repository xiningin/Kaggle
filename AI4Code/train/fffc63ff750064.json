{"cell_type":{"5015c300":"code","8238198c":"code","f4781d1d":"code","b5532930":"code","e1f223e5":"code","4aaf741d":"code","7229cce6":"code","a7fa3628":"code","e4c2fa86":"code","1f8f9d14":"code","7a52357a":"code","e9b6265c":"code","b32dc5d2":"code","41ccef58":"code","6aff1ae7":"code","29e1f39d":"code","37cbd460":"code","79e4e69f":"code","ee9b8d31":"code","deead32c":"code","56ee6e4c":"code","56aa8da7":"code","411b85d9":"markdown","e7e67119":"markdown","8b54cf58":"markdown","b3c6bc16":"markdown"},"source":{"5015c300":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8238198c":"train_set = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_set = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsample_sub = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')","f4781d1d":"sns.distplot(train_set['SalePrice'])","b5532930":"missing_train = train_set.isnull().sum()\nmissing_train = missing_train[missing_train > 0]\nmissing_train.sort_values(inplace = True)\nmissing_train.plot.bar()","e1f223e5":"missing_test = test_set.isnull().sum()\nmissing_test = missing_test[missing_test > 0]\nmissing_test.sort_values(inplace = True)\nmissing_test.plot.bar()","4aaf741d":"# Take k features with highest correlation\nk = 10\nlabel = 'SalePrice'\ncolumns = correlation_matrix.nlargest(k, label)[label].index\ncorrelation_matrix = np.corrcoef(train_set[columns].values.T)\n\nf, ax = plt.subplots(figsize=(20, 20))\n\nheatmap = sns.heatmap(correlation_matrix, cbar = True, annot = True, square = True, yticklabels = columns.values, xticklabels = columns.values)\n\nplt.show()","7229cce6":"##### fill NaN values\nfor i in train_set:\n    if train_set[i].dtype == 'object':\n        train_set[i] = train_set[i].fillna(train_set[i].mode())\n    else:\n        train_set[i] = train_set[i].fillna(train_set[i].median())","a7fa3628":"def label_encoder(df_train, df_test):\n    le_count = 0\n    \n    for col in df_train:\n        if df_train[col].dtype == 'object':\n            if len(list(df_train[col].unique())) <= 2:\n                le = LabelEncoder()\n                le.fit(list(df_train[col].unique())+list(df_test[col].unique()))\n\n                df_train[col] = le.transform(df_train[col].astype(str))\n                df_test[col] = le.transform(df_test[col].astype(str))\n                le_count +=1;\n               \n    \n    print(\"Total label encoded columns : %d \" %le_count)\n\nlabel_encoder(train_set, test_set)","e4c2fa86":"train_set.head()","1f8f9d14":"train_len = len(train_set)\n\ndata = pd.concat(objs = [train_set, test_set], axis = 0)\n\ndata = pd.get_dummies(data)","7a52357a":"import copy\ntrain_set = copy.copy(data[:train_len])\n\ntest_set = copy.copy(data[train_len:])\n\ntest_set = test_set.drop([label], axis = 1)","e9b6265c":"# Extract labels\ncorr = train_set.corr().sort_values(label)\ncols = corr[label][corr[label].values > 0.05].index.values\ntrain_label = train_set[label]\ncols = np.delete(cols, len(cols) - 1)\ntrain_sample = train_set[cols]\ntest_sample = test_set[cols]","b32dc5d2":"# Imputation\nimputer = SimpleImputer(strategy = 'median')\nimputer.fit(train_sample)\n\ntrain_sample = imputer.transform(train_sample)\ntest_sample = imputer.transform(test_sample)","41ccef58":"# Normalization\nscaler = StandardScaler()\n\nscaler.fit(train_sample)\n\ntrain_sample = scaler.transform(train_sample)\ntest_sample = scaler.transform(test_sample)","6aff1ae7":"# train test split\n\nX_train, X_test , y_train, y_test = train_test_split(train_sample, train_label, train_size = 0.8, random_state = 64)","29e1f39d":"X_train.shape, X_test.shape, test_sample.shape","37cbd460":"rf = RandomForestRegressor(n_estimators = 10000, random_state = 64)\nrf.fit(X_train, y_train)","79e4e69f":"y_pred = rf.predict(X_test)","ee9b8d31":"sns.set()\nplt.figure(figsize = (16, 16))\nplt.scatter(y_test, y_pred)\nplt.title('Actual vs Predicted')\nplt.xlabel('Actual Sale Price')\nplt.ylabel('Predicted Sale Price')\n\nplt.plot()","deead32c":"test_pred = rf.predict(test_sample)\n\nsubmission = pd.DataFrame()\n\nsubmission['ID'] = testID\n\nsubmission['SalePrice'] = test_pred","56ee6e4c":"submission.head()","56aa8da7":"\nsubmission.to_csv('house_price_rf.csv', index = False)","411b85d9":"1. # Data exploration","e7e67119":"# # Data preprocessing","8b54cf58":"# Post-process for submission","b3c6bc16":"# Define and fit model"}}